[{"content":"友邦拓 乌班图\n During the first ten years of this HOWTO\u0026rsquo;s life, I reported that from a new user\u0026rsquo;s point of view, all Linux distributions are almost equivalent. But in 2006-2007, an actual best choice emerged: Ubuntu. While other distros have their own areas of strength, Ubuntu is far and away the most accessible to Linux newbies. Beware, though, of the hideous and nigh-unusable \u0026ldquo;Unity\u0026rdquo; desktop interface that Ubuntu introduced as a default a few years later; the Xubuntu or Kubuntu variants are better.\nEric Steven Raymond - How To Become A Hacker\n CONF Settings DNS GUI\n 打开设置窗口 如果你连接到了 WiFi 网络，点击“Wi-FI”标签栏。否则，如果你有一个有线连接，点击『Network』标签栏。 选择你要设置 DNS 的网络连接，并且点击齿轮状的按钮，打开网络管理器。 选择 IPv4 设置标签栏。 禁用自动开关，并且输入 DNS 的 IP 地址，用逗号隔开。我们使用 Google DNS 域名解析服务器。 点击“Apply”按钮，保存修改。  这个修改应该会立即有效，除非那些已经缓存了的 DNS 条目。如果你想切换回旧的设置，打开网络管理器，IPv4 设置，并且启用自动开关。\nCLI\n# 显示当前网络连接 $ nmcli connection show # 修改当前网络连接对应的DNS服务器，这里的网络连接可以用名称或者UUID来标识 $ nmcli con mod ens160 ipv4.dns \u0026#34;114.114.114.114 8.8.8.8 8.8.4.4\u0026#34; # 配置生效 $ nmcli con up ens160 或者\n# Config File $ vi /etc/netplan/01-network-manager-all.yaml network: version: 2 renderer: NetworkManager ethernets: ens3: dhcp4: no addresses: - 192.168.100.199/24 gateway4: 192.168.100.1 nameservers: address: [114.114.114.114, 8.8.8.8] wifis: ... # Apply the changes you made in the config file $ sudo netplan apply # To check if the system successfully applied the changes $ systemd-resolve --status | grep \u0026#39;DNS Servers\u0026#39; -A2 DNS Servers: 114.114.114.114 8.8.8.8 8.8.4.4s 注意：您系统上的文件可能缺少整个以太网或 wifi 部分。 在这种情况下，添加缺少的行，确保遵守示例中提供的缩进。\nOthers  Bluetooth: OFF Formats: United States Blank screen: Never Night Light: On Touchpad: OFF Fractional Scaling  SoftWare\u0026amp;Updates   Ubuntu Software 栏 Download from 选择 USTC MIRRORS。\n  Other Software 栏下开启 Canonical Partner Repositories (The partner repositories offer access to proprietary and closed-source software)。\n  Ubuntu 自动下载并安装对你的系统至关重要的安全更新。而这个自动更新经常导致你“无法锁定管理目录”错误。在 Updates 栏下选择\n For other packages, subscribe to: All updates Automatically check for updates: Every two weeks When there are security updates: Display immediately When there are other updates: Display immediately Notify me of a new Ubuntu version: For long-term support versions    更新系统:\n$ sudo apt update $ sudo apt upgrade $ sudo apt autoremove   Livepatch: Enable\n  Ubuntu Software \u0026amp; Update 卡在 cache refresh\n通过 apt update 可以看见是 Connecting to security.ubuntu.com Failed，解决办法是更改 /etc/hosts 文件添加其 IP，可通过 EASYCOUNTER 查找：\n## security.ubuntu.com 91.189.88.142 security.ubuntu.com 91.189.88.152 security.ubuntu.com 91.189.91.38 security.ubuntu.com 91.189.91.39 security.ubuntu.com ## archive.canonical.com 91.189.92.150 archive.canonical.com 91.189.92.191 archive.canonical.com 91.189.91.15 archive.canonical.com ## downloads.sourceforge.net 216.105.38.13 downloads.sourceforge.net ubuntu下如何获取源码包和源码\n  在 Software \u0026amp; Updates 中选中 Source code，不要 Reload，因为很慢，在命令行中 update。或者在软件源配置文件 /etc/apt/sources.list 中添加 deb-src 项。\n  获取 xxx 源码包的详细信息\n$ sudo apt-cache showsrc xxx   获取源码包，并将源码包解压到同名目录\n$ sudo apt-get source xxx   Upgrade Ubuntu version\n 打开 Software Updater 更新软件 打开 Software \u0026amp; Updates 选择 Updates 栏，在 Notify me of a new Ubuntu Version 中选择 For any new version 。 打开 Software Updater 更新到新 Ubuntu 版本。 使用 lsb_release -a 确认 Ubuntu 版本。  Input Method Editor 在 Language Support 中下载语言包\nibus\nubuntu libpinyin 输入法支持云拼音，只需要开启就可以了。\nfcitx\n在Ubuntu Wayland 桌面中使用fictx管理中文输入法\n$ sudo apt install fcitx -y 设置 fcitx：\n  在 Language Support 中选择 fcitx，全局应用，并恢复 ibus 自定义切换语言快捷键设置。\n  (可选）wayland桌面默认不读取/etc/profile中的环境变量，而是从/etc/environment文件中读取，这是导致fcitx不能正常工作的原因。\n$ sudo vim /etc/environment INPUT_METHOD=fcitx GTK_IM_MODULE=fcitx QT_IM_MODULE=fcitx XMODIFIERS=@im=fcitx   输入法框架：\n 搜狗输入法 for Linux 百度输入法Linux版 Google拼音  其他：\n 百度输入法不能安装用于更换皮肤的 fcitx-ui-qimpanel，否则乱码。需要手动安装 fcitx-libs，否则开机不自动启动。 在 fcitx 与 sogoupinyin 安装完之后，需要重启才能使用。  皮肤：\n fcitx 皮肤：/usr/share/fcitx/skin sogoupinyin 皮肤：/usr/share/sogou-qimpanel/skin。  旧：可以改名为 zip 解压 新：受版权保护    搜狗细胞词库\n经过与ibus开发者协商，ibus-pinyin的词库查找规则做了一些更改，只要在词库目录（就是有一个.db文件的那个目录，一般是/usr/share/ibus-pinyin/db目录）把新词库复制过来并改名为local.db就可以使用了，如果感觉词库不好直接删除掉local.db就可以让ibus使用原来的词库。\n覆盖以后，你把ibus重启一下，如果你能打出下面的这个词组，说明生效了：\n弗雷德霍姆行列式 这个词库，基于ibus原有的android词库文件，另外增加了搜狗的细胞词库。\n源码\nAutomatically switch wallpapers 软件\nShotwell：在侧边栏 Photos 中 Ctrl + A，在菜单栏 File 中选择 Set as Desktop SlideShow\u0026hellip;；这会把图片复制到 .local/share/shotwell/wallpaper，并在该目录生成 wallpaper.xml，wallpaper.xml 定义自动切换壁纸动画。\n替代软件 Variety、BingWall 等。\nunsplash\n  gsettings set org.gnome.desktop.background picture-uri file://$HOME/Wallpaper\n  添加脚本\n$ vi $HOME/.unsplash.sh #!/bin/bash SAVE_DIR=$HOME/DataOne/Unsplash FILE_NAME=daily$(date \u0026#39;+%Y%m%d\u0026#39;).jpeg wget -O $SAVE_DIR/$FILE_NAME https://source.unsplash.com/1920x1080/daily cp $SAVE_DIR/$FILE_NAME $HOME/Wallpaper 在 Unsplash Source 查看更多 API。\n  crontab -e\n0 12 * * * /home/vane/.unsplash.sh   wallhaven\n  gsettings set org.gnome.desktop.background picture-uri $HOME/Wallpaper\n一般文件内容开头都会有一个文件类型的标记，根据文件名后缀只是一个快捷的方法，不用读取文件内容就判断文件类型，但不是唯一的方法。\n  vi $HOME/.wallhaven/wallhaven.sh\n#!/bin/bash  WORK_DIR=$HOME/.wallhaven SAVE_DIR=$HOME/Pictures/wallhaven IMG_URL=https://w.wallhaven.cc/full function GetListing() { echo \u0026#39;get listing\u0026#39; listing=$(curl https://wallhaven.cc/api/v1/search?apikey=\u0026lt;API KEY\u0026gt;\u0026amp;categories=010\u0026amp;purity=111\u0026amp;atleast=1920x1080\u0026amp;ratios=16x9\u0026amp;sorting=random\u0026amp;order=desc\u0026amp;page=1) echo \u0026#39;save listing\u0026#39; echo $listing | jq -r \u0026#39;.data[].path\u0026#39; | awk -F \u0026#39;/\u0026#39; \u0026#39;{print $NF}\u0026#39; \u0026gt; $WORK_DIR/listing echo \u0026#39;save res\u0026#39; cat $WORK_DIR/listing | wc -l \u0026gt; $WORK_DIR/res SetWallpaper } function SetWallpaper() { if [ -a $WORK_DIR/res ]; then echo \u0026#39;read res\u0026#39; read res \u0026lt; $WORK_DIR/res if [ $res -ne 0 ]; then echo \u0026#39;get img\u0026#39; img=$(cat $WORK_DIR/listing | tail -${res} | head -1) echo \u0026#34;down $imgfrom $IMG_URL/${img:10:2}/$img\u0026#34; curl -o $SAVE_DIR/$img $IMG_URL/${img:10:2}/$img if [ $? -eq 0 ]; then echo \u0026#39;set wallpaper\u0026#39; cp $SAVE_DIR/$img $HOME/Wallpaper echo \u0026#39;res-1\u0026#39; echo $(($res - 1)) \u0026gt; $WORK_DIR/res echo \u0026#39;exit\u0026#39; exit 0 else echo \u0026#39;download error\u0026#39; SetWallpaper fi else echo \u0026#39;res=0\u0026#39; GetListing fi else echo \u0026#39;no res\u0026#39; GetListing fi } SetWallpaper 使用 Shell 脚本来处理 JSON，jq Manual，wallhaven API v1 Documentation\n  crontab -e\n0 12 * * * /home/vane/.wallhaven/wallhaven.sh Gsettings 无法在 Cron 中使用：出现此问题是因为 cron 仅使用一组非常有限的环境变量。 唯一一个负责在将其设置为 cron 作业时以正确方式运行问题脚本的环境变量是 DBUS_SESSION_BUS_ADDRESS。\n  Beautify Oh My Zsh $ sh -c \u0026#34;$(wget https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)\u0026#34; oh-my-zsh应该对通配符作了限制，需要用跳脱字符\nsudo apt remove fcitx\\* Zsh theme：Powerlevel10kUSER\n尽量用开源代替闭源（CopyLeft alternative to CopyRight）。\n这部分程序都是需要手动安装的——即不是系统自带的。\nVIMRC The ultimate Vim configuration (vimrc)\nTmux Tmux 是一个终端复用器（terminal multiplexer），非常有用，属于常用的开发工具。\n简介 会话与进程\n命令行的典型使用方式是，打开一个终端窗口（terminal window，以下简称\u0026quot;窗口\u0026quot;），在里面输入命令。用户与计算机的这种临时的交互，称为一次\u0026quot;会话\u0026quot;（session） 。\n会话的一个重要特点是，窗口与其中启动的进程是连在一起的。打开窗口，会话开始；关闭窗口，会话结束，会话内部的进程也会随之终止，不管有没有运行完。\n一个典型的例子就是，SSH 登录远程计算机，打开一个远程窗口执行命令。这时，网络突然断线，再次登录的时候，是找不回上一次执行的命令的。因为上一次 SSH 会话已经终止了，里面的进程也随之消失了。\n为了解决这个问题，会话与窗口可以\u0026quot;解绑\u0026quot;：窗口关闭时，会话并不终止，而是继续运行，等到以后需要的时候，再让会话\u0026quot;绑定\u0026quot;其他窗口。\nTmux 的作用\nTmux 就是会话与窗口的\u0026quot;解绑\u0026quot;工具，将它们彻底分离。\n 它允许在单个窗口中，同时访问多个会话。这对于同时运行多个命令行程序很有用。 它可以让新窗口\u0026quot;接入\u0026quot;已经存在的会话。 它允许每个会话有多个连接窗口，因此可以多人实时共享会话。 它还支持窗口任意的垂直和水平拆分。  类似的终端复用器还有 GNU Screen。Tmux 与它功能相似，但是更易用，也更强大。\n基本用法 安装\nTmux 一般需要自己安装。\n$ sudo apt-get install tmux 启动与退出\n安装完成后，键入tmux命令，就进入了 Tmux 窗口。\n$ tmux Tmux 窗口，底部有一个状态栏。状态栏的左侧是窗口信息（编号和名称），右侧是系统信息。\n按下Ctrl+d或者显式输入exit命令，就可以退出 Tmux 窗口。\n$ exit 前缀键\nTmux 窗口有大量的快捷键。所有快捷键都要通过前缀键唤起。默认的前缀键是Ctrl+b，即先按下Ctrl+b，快捷键才会生效。\n举例来说，帮助命令的快捷键是Ctrl+b ?。它的用法是，在 Tmux 窗口中，先按下Ctrl+b，再按下?，就会显示帮助信息。\n然后，按下 ESC 键或q键，就可以退出帮助。\n会话管理 新建会话\n第一个启动的 Tmux 窗口，编号是0，第二个窗口的编号是1，以此类推。这些窗口对应的会话，就是 0 号会话、1 号会话。\n使用编号区分会话，不太直观，更好的方法是为会话起名。\n$ tmux new -s \u0026lt;session-name\u0026gt; 上面命令新建一个指定名称的会话。\n分离会话\n在 Tmux 窗口中，按下Ctrl+b d或者输入tmux detach命令，就会将当前会话与窗口分离。\n$ tmux detach 上面命令执行后，就会退出当前 Tmux 窗口，但是会话和里面的进程仍然在后台运行。\ntmux ls命令或Ctrl+b s可以查看当前所有的 Tmux 会话。\n$ tmux ls # or $ tmux list-session 接入会话\ntmux attach命令用于重新接入某个已存在的会话。\n# 使用会话编号 $ tmux attach -t 0 # 使用会话名称 $ tmux attach -t \u0026lt;session-name\u0026gt; 杀死会话\ntmux kill-session命令用于杀死某个会话。\n# 使用会话编号 $ tmux kill-session -t 0 # 使用会话名称 $ tmux kill-session -t \u0026lt;session-name\u0026gt; 切换会话\ntmux switch命令用于切换会话。\n# 使用会话编号 $ tmux switch -t 0 # 使用会话名称 $ tmux switch -t \u0026lt;session-name\u0026gt; 重命名会话\ntmux rename-session命令或Ctrl+b $用于重命名会话。\n$ tmux rename-session -t 0 \u0026lt;new-name\u0026gt; 上面命令将0号会话重命名。\n最简操作流程 综上所述，以下是 Tmux 的最简操作流程。\n 在服务器端新建会话tmux new -s my_session。 在 Tmux 窗口运行所需的程序。 按下快捷键Ctrl+b d将会话分离。 下次使用时，重新连接到会话tmux attach-session -t my_session。  窗格操作 Tmux 可以将窗口分成多个窗格（pane），每个窗格运行不同的命令。以下命令都是在 Tmux 窗口中执行。\n划分窗格\ntmux split-window命令用来划分窗格。\n# 划分上下两个窗格，或 Ctrl+b \u0026#34; $ tmux split-window # 划分左右两个窗格，或 Ctrl+b % $ tmux split-window -h 移动光标\ntmux select-pane命令或Ctrl+b \u0026lt;arrow key\u0026gt;用来移动光标位置。\n# 光标切换到上方窗格，或 Ctrl+b ; $ tmux select-pane -U # 光标切换到下方窗格，或 Ctrl+b o $ tmux select-pane -D # 光标切换到左边窗格 $ tmux select-pane -L # 光标切换到右边窗格 $ tmux select-pane -R  Ctrl+b x：关闭当前窗格。 Ctrl+b !：将当前窗格拆分为一个独立窗口。 Ctrl+b z：当前窗格全屏显示，再使用一次会变回原来大小。 Ctrl+b Ctrl+\u0026lt;arrow key\u0026gt;：按箭头方向调整窗格大小。 Ctrl+b q：显示窗格编号。  交换窗格位置\ntmux swap-pane命令用来交换窗格位置。\n# 当前窗格上移，或 Ctrl+b { $ tmux swap-pane -U # 当前窗格下移，或 Ctrl+b } $ tmux swap-pane -D  Ctrl+b Ctrl+o：所有窗格向前移动一个位置，第一个窗格变成最后一个窗格。 Ctrl+b Alt+o：所有窗格向后移动一个位置，最后一个窗格变成第一个窗格。  窗口管理 除了将一个窗口划分成多个窗格，Tmux 也允许新建多个窗口。\n新建窗口\ntmux new-window命令用来创建新窗口。\n$ tmux new-window # 新建一个指定名称的窗口 $ tmux new-window -n \u0026lt;window-name\u0026gt; Ctrl+b c：创建一个新窗口，状态栏会显示多个窗口的信息。\n切换窗口\ntmux select-window命令用来切换窗口。\n# 切换到指定编号的窗口 $ tmux select-window -t \u0026lt;window-number\u0026gt; # 切换到指定名称的窗口 $ tmux select-window -t \u0026lt;window-name\u0026gt;  Ctrl+b p：切换到上一个窗口（按照状态栏上的顺序）。 Ctrl+b n：切换到下一个窗口。 Ctrl+b \u0026lt;number\u0026gt;：切换到指定编号的窗口，其中的\u0026lt;number\u0026gt;是状态栏上的窗口编号。 Ctrl+b w：从列表中选择窗口。  重命名窗口\ntmux rename-window命令或Ctrl+b ,用于为当前窗口起名（或重命名）。\n$ tmux rename-window \u0026lt;new-name\u0026gt; 其他命令 下面是一些其他命令。\n# 列出所有快捷键，及其对应的 Tmux 命令 $ tmux list-keys # 列出所有 Tmux 命令及其参数 $ tmux list-commands # 列出当前所有 Tmux 会话的信息 $ tmux info # 重新加载当前的 Tmux 配置 $ tmux source-file ~/.tmux.conf Fish 命令行是程序员的必备技能。图形界面虽然好看，解决问题还是要靠命令行。\n命令行由 Shell 提供。各种命令通过 Shell，传递给操作系统的内核。学习命令行就是在学习 Shell。\nShell 有好几种，目前最常用是 Bash 和 zsh。但是，在我看来，它们都不如 Fish Shell 好用。\n五年前，我第一次尝试 Fish，感到很惊艳，一直用到现在。本文介绍 Fish 的主要特点，希望你也来尝试它。\n简介 Fish 是\u0026quot;the friendly interactive shell\u0026quot;的简称，最大特点就是方便易用。很多其他 Shell 需要配置才有的功能，Fish 默认提供，不需要任何配置。\n如果你想拥有一个方便好用的 Shell，又不想学习一大堆语法，或者花费很多时间配置，那么你一定要尝试一下 Fish。\n安装 Ubuntu 的安装方法。\n$ sudo apt install fish 其他系统的安装请参考官方网站。\n启动与帮助 安装完成后，就可以启动 Fish。\n$ fish 由于 Fish 的语法与 Bash 有很大差异，Bash 脚本一般不兼容。因此，我建议不要将 Fish 设为默认 Shell，而是每次手动启动它。\n使用过程中，如果需要帮助，可以输入help命令。浏览器就会自动打开，显示在线文档。\n$ help 彩色显示 进入 Fish 以后，你注意到的第一件事，可能就是它默认彩色显示。\n# 无效命令为红色 $ mkd # 有效命令为蓝色 $ mkdir 有效路径会有下划线。\n$ cat ~/somefi 上面代码表示，存在以~/somefi开头的路径。如果没有下划线，你就知道这个路径不存在。\n自动建议 Fish 会自动在光标后面给出建议，表示可能的选项，颜色为灰色。\n# 命令建议 $ /bin/hostname # 参数建议 $ grep --ignore-case # 路径建议 $ ls node_modules 如果采纳建议，可以按下→或Control + F。如果只采纳一部分，可以按下Alt + →。\n自动补全 输入命令时，Fish 会自动显示匹配的上一条历史记录。\n$ git commit -m \u0026#34;feat: first commit\u0026#34; 如果没有匹配的历史记录，Fish 会猜测可能的结果，自动补全各种输入。比如，输入pyt再按下Tab，就会自动补全为python命令。\n如果有多个可能的结果，Fish 会把它们都列出，还带有简要介绍。\n$ vi[按下 Tab 键] vi (Executable link, 2.7MB) view (Vi IMproved, 一个程序员的文本编辑器) viewer.py (Executable, 967B) viewres (Graphical class browser for Xt) ...and 12 more rows 这时，再按一次tab，就可以在这些命令之中选择。\n除了补全命令，Fish 还可以补全参数。比如，ls命令的-l参数后面按下Tab键，就会显示可以连用的其他参数。\n$ ls -l[按下 Tab 键] -l1 (List one file per line) -lA (Show hidden except . and ..) -la (Show hidden) -lB (Ignore files ending with ~) ...and 16 more rows``` Fish 还可以自动补全 Git 分支。\n$ git checkout master 易懂的语法 Fish 的语法非常自然，一眼就能看懂。\nif语句：\nif grep fish /etc/shells echo Found fish else if grep bash /etc/shells echo Found bash else echo Got nothing end switch语句：\nswitch (uname) case Linux echo Hi Tux! case Darwin echo Hi Hexley! case FreeBSD NetBSD DragonFly echo Hi Beastie! case \u0026#39;*\u0026#39; echo Hi, stranger! end while循环：\nwhile true echo \u0026#34;Loop forever\u0026#34; end for循环：\nfor file in *.txt cp $file $file.bak end 函数 Fish 的函数用来封装命令，或者为现有的命令起别名。\nfunction ll ls -lhG $argv end 上面代码定义了一个ll函数。命令行执行这个函数以后，就可以用ll命令替代ls -lhG。其中，变量$argv表示函数的参数。\n下面是另一个例子。\nfunction ls command ls -hG $argv end 上面的代码重新定义ls命令。注意，函数体内的ls之前，要加上command，否则会因为无限循环而报错。\n提示符 fish_prompt函数用于定义命令行提示符（prompt）。\nfunction fish_prompt set_color purple date \u0026#34;+%m/%d/%y\u0026#34; set_color FF0 echo (pwd) \u0026#39;\u0026gt;\u0026#39; set_color normal end 执行上面的函数以后，你的命令行提示符就会变成下面这样。\n02/06/13 /home/tutorial \u0026gt; 配置 Fish 的配置文件是~/.config/fish/config.fish，每次 Fish 启动，就会自动加载这个文件。\n我们可以在这个文件里面写入各种自定义函数，它们会被自动加载。比如，上面的fish_prompt函数就可以写在这个文件里面，这样每次启动 Fish，就会出现自定义的提示符。\nFish 还提供 Web 界面配置该文件。\n$ fish_config 输入上面的命令以后，浏览器就会自动打开本机的 8000 端口，用户可以在网页上对 Fish 进行配置，比如选择提示符和配色主题。\nClash for linux 下载 clash\n$ gzip -d clash-linux-amd64-v1.6.5.gz $ mkdir ~/.clash \u0026amp;\u0026amp; mv clash-linux-amd64-v1.6.5 ~/.clash/clash 下载配置\n$ wget -O config.yaml [订阅链接] 运行 clash\n$ chmod 770 clash./clash -d . 使用 clash dashboard 选择节点\n设置系统代理：\n  GUI：打开系统设置，点击网络代理右边的 ⚙ 按钮，选择手动\n HTTP 和 HTTPS 代理为 127.0.0.1:7890 Socks 主机为 127.0.0.1:7891    CLI：change system proxy settings from the command line\n# To modify a DConf setting: $ gsettings set \u0026lt;schema\u0026gt; \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; # To read a DConf setting: $ gsettings get \u0026lt;schema\u0026gt; \u0026lt;key\u0026gt;   相关软件：\n Qv2ray：很好的工具，但已停止维护。 v2ray-core：可以直接用命令行 v2rayA glider proxychains-ng 开热点：相关软件一般有“允许来自局域网的连接”  更新（20211201）：chrome 更新后（Version 96），访问 Clash Web UI 报 Access to XMLHttpRequest at 'http://localhost:9090/providers/proxies' from origin 'http://clash.razord.top' has been blocked by CORS policy 错误，如果节点可访问的话，就没有这个问题；如果节点不可访问，也可以通过 firefox 访问 Clash Web UI（firefox 需设置 No Proxy）。\n实例一 $ vi ~/.clash/run-clash.sh #!/bin/bash CLASH_HOME=/home/vane/.clash subscription=\u0026#34;订阅连接\u0026#34; # 设置系统代理 function setting { gsettings set org.gnome.system.proxy.http host \u0026#39;127.0.0.1\u0026#39; gsettings set org.gnome.system.proxy.http port \u0026#39;7890\u0026#39; gsettings set org.gnome.system.proxy.https host \u0026#39;127.0.0.1\u0026#39; gsettings set org.gnome.system.proxy.https port \u0026#39;7890\u0026#39; gsettings set org.gnome.system.proxy.socks host \u0026#39;127.0.0.1\u0026#39; gsettings set org.gnome.system.proxy.socks port \u0026#39;7891\u0026#39; } # 更新订阅 function update { wget -O $CLASH_HOME/config.yaml $subscription } # 运行 clash function run { # 打开系统代理（之前已经设置了） gsettings set org.gnome.system.proxy mode \u0026#39;manual\u0026#39; $CLASH_HOME/clash-linux-amd64 -d $CLASH_HOME/ } # 停止运行 clash function stop { # 关闭系统代理  gsettings set org.gnome.system.proxy mode \u0026#39;none\u0026#39; } if [ \u0026#34;$1\u0026#34; = \u0026#34;-u\u0026#34; ]; then update elif [ \u0026#34;$1\u0026#34; = \u0026#34;-r\u0026#34; ]; then run elif [ \u0026#34;$1\u0026#34; = \u0026#34;-s\u0026#34; ]; then setting else if [ \u0026#34;$1\u0026#34; ]; then $CLASH_HOME/clash $1 else echo Plese run clash -r fi fi trap stop EXIT How to change system proxy settings from the command line on Ubuntu desktop\n$ chmod 700 run-clash.sh 实例二 $ vi ~/.clash/rc.sh #!/bin/bash /usr/bin/wget -O /home/vane/.clash/config.yaml \u0026#34;订阅连接\u0026#34; /home/vane/.clash/clash-linux-amd64 -d /home/vane/.clash/ clash as a daemon：\n$ sudo vi /usr/lib/systemd/system/clash.service [Unit] Description=Clash daemon, A rule-based proxy in Go. After=network.target [Service] Type=simple Restart=always RestartSec=10 ExecStart=/bin/bash /home/vane/.clash/rc.sh [Install] WantedBy=multi-user.target 运行\n$ systemctl enable clash.service $ systemctl start clash.service $ systemctl status clash.service 如果不想代理了，可以直接在 clash dashboard 的 Proxy （如果有的话）或者 Settting 里选择 DIRECT，而不是关闭 clash.service。根据设置的规则，有的流量会走代理，有的流量直接走。\nWireGuard 官方文档：https://github.com/pirate/wireguard-docs\nWireGuard 是由 Jason Donenfeld 等人用 C 语言编写的一个开源 VPN 协议，被视为下一代 VPN 协议，旨在解决许多困扰 IPSec/IKEv2、OpenVPN 或 L2TP 等其他 VPN 协议的问题。它与 Tinc 和 MeshBird 等现代 VPN 产品有一些相似之处，即加密技术先进、配置简单。从 2020 年 1 月开始，它已经并入了 Linux 内核的 5.6 版本，这意味着大多数 Linux 发行版的用户将拥有一个开箱即用的 WireGuard。\n术语 Peer/Node/Device\n连接到 VPN 并为自己注册一个 VPN 子网地址（如 192.0.2.3）的主机。还可以通过使用逗号分隔的 CIDR 指定子网范围，为其自身地址以外的 IP 地址选择路由。\n中继服务器（Bounce Server）\n一个公网可达的对等节点，可以将流量中继到 NAT 后面的其他对等节点。Bounce Server 并不是特殊的节点，它和其他对等节点一样，唯一的区别是它有公网 IP，并且开启了内核级别的 IP 转发，可以将 VPN 的流量转发到其他客户端。\n子网（Subnet）\n一组私有 IP，例如 192.0.2.1-255 或 192.168.1.1/24，一般在 NAT 后面，例如办公室局域网或家庭网络。\nCIDR 表示法\nCIDR中文全称是无分类域间路由选择，英文全称是Classless Inter-Domain Routing，在平常，大家多称之为无分类编址，它也是构成超网的一种技术实现。CIDR在一定程度上解决了路由表项目过多过大的问题。CIDR之所以称为无分类编址，就是因为CIDR完全放弃了之前的分类IP地址表示法，它真正消除了传统的A类、B类、C类地址以及划分子网的概念，它使用如下的IP地址表示法：\nIP地址 ::= {\u0026lt;网络前缀\u0026gt;， \u0026lt;主机号\u0026gt;} / 网络前缀所占位数 CIDR仅将IP地址划分为网络前缀和主机号两个部分，可以说又回到了二级IP地址的表示，不过大家要注意，最后面用“/”斜线分隔，在其后写上了网络前缀所占的位数，这样就不需要告知路由器地址掩码，仅需要通过网络前缀所占的位数就可以得到地址掩码，为了统一，CIDR中的地址掩码依然称为子网掩码。\nNAT\n子网的私有 IP 地址由路由器提供，通过公网无法直接访问私有子网设备，需要通过 NAT 做网络地址转换。路由器会跟踪发出的连接，并将响应转发到正确的内部 IP。\n公开端点（Public Endpoint）\n节点的公网 IP 地址:端口，例如 123.124.125.126:1234，或者直接使用域名 some.domain.tld:1234。如果对等节点不在同一子网中，那么节点的公开端点必须使用公网 IP 地址。\n私钥（Private key）\n单个节点的 WireGuard 私钥，生成方法是：wg genkey \u0026gt; example.key。\n公钥（Public key）\n单个节点的 WireGuard 公钥，生成方式为：wg pubkey \u0026lt; example.key \u0026gt; example.key.pub。\nDNS\n域名服务器，用于将域名解析为 VPN 客户端的 IP，不让 DNS请求泄漏到 VPN 之外。\n工作原理 中继服务器工作原理\n中继服务器（Bounce Server）和普通的对等节点一样，它能够在 NAT 后面的 VPN 客户端之间充当中继服务器，可以将收到的任何 VPN 子网流量转发到正确的对等节点。事实上 WireGuard 并不关心流量是如何转发的，这个由系统内核和 iptables 规则处理。\n如果所有的对等节点都是公网可达的，则不需要考虑中继服务器，只有当有对等节点位于 NAT 后面时才需要考虑。\n*在 WireGuard 里，客户端和服务端基本是平等的，差别只是谁主动连接谁而已。*双方都会监听一个 UDP 端口，谁主动连接，谁就是客户端。主动连接的客户端需要指定对端的公网地址和端口，被动连接的服务端不需要指定其他对等节点的地址和端口。如果客户端和服务端都位于 NAT 后面，需要加一个中继服务器，客户端和服务端都指定中继服务器作为对等节点，它们的通信流量会先进入中继服务器，然后再转发到对端。\nWireGuard 是支持漫游的，也就是说，双方不管谁的地址变动了，WireGuard 在看到对方从新地址说话的时候，就会记住它的新地址（跟 mosh 一样，不过是双向的）。所以双方要是一直保持在线，并且通信足够频繁的话（比如配置 persistent-keepalive），两边的 IP 都不固定也不影响的。\n流量路由\n利用 WireGuard 可以组建非常复杂的网络拓扑，这里主要介绍几个典型的拓扑：\n 端到端直接连接  这是最简单的拓扑，所有的节点要么在同一个局域网，要么直接通过公网访问，这样 WireGuard 可以直接连接到对端，不需要中继跳转。\n一端位于 NAT 后面，另一端直接通过公网暴露  这种情况下，最简单的方案是：通过公网暴露的一端作为服务端，另一端指定服务端的公网地址和端口，然后通过 persistent-keepalive 选项维持长连接，让 NAT 记得对应的映射关系。\n两端都位于 NAT 后面，通过中继服务器连接  大多数情况下，当通信双方都在 NAT 后面的时候，NAT 会做源端口随机化处理，直接连接可能比较困难。可以加一个中继服务器，通信双方都将中继服务器作为对端，然后维持长连接，流量就会通过中继服务器进行转发。\n两端都位于 NAT 后面，通过 UDP NAT 打洞  上面也提到了，当通信双方都在 NAT 后面的时候，直接连接不太现实，因为大多数 NAT 路由器对源端口的随机化相当严格，不可能提前为双方协调一个固定开放的端口。必须使用一个信令服务器（STUN），它会在中间沟通分配给对方哪些随机源端口。通信双方都会和公共信令服务器进行初始连接，然后它记录下随机的源端口，并将其返回给客户端。这其实就是现代 P2P 网络中 WebRTC 的工作原理。有时候，即使有了信令服务器和两端已知的源端口，也无法直接连接，因为 NAT 路由器严格规定只接受来自原始目的地址（信令服务器）的流量，会要求新开一个随机源端口来接受来自其他 IP 的流量（比如其他客户端试图使用原来的通信源端口）。运营商级别的 NAT 就是这么干的，比如蜂窝网络和一些企业网络，它们专门用这种方法来防止打洞连接。更多细节请参考下一部分的 NAT 到 NAT 连接实践的章节。\n如果某一端同时连接了多个对端，当它想访问某个 IP 时，如果有具体的路由可用，则优先使用具体的路由，否则就会将流量转发到中继服务器，然后中继服务器再根据系统路由表进行转发。你可以通过测量 ping 的时间来计算每一跳的长度，并通过检查对端的输出（wg show wg0）来找到 WireGuard 对一个给定地址的路由方式。\n报文格式\nWireGuard 使用加密的 UDP 报文来封装所有的数据，UDP 不保证数据包一定能送达，也不保证按顺序到达，但隧道内的 TCP 连接可以保证数据有效交付。WireGuard 的报文格式如下图所示：\n性能\nWireGuard 声称其性能比大多数 VPN 协议更好，但这个事情有很多争议，比如某些加密方式支持硬件层面的加速。\nWireGuard 直接在内核层面处理路由，直接使用系统内核的加密模块来加密数据，和 Linux 原本内置的密码子系统共存，原有的子系统能通过 API 使用 WireGuard 的 Zinc 密码库。WireGuard 使用 UDP 协议传输数据，在不使用的情况下默认不会传输任何 UDP 数据包，所以比常规 VPN 省电很多，可以像 55 一样一直挂着使用，速度相比其他 VPN 也是压倒性优势。\n安全模型\nWireGuard 使用以下加密技术来保障数据的安全：\n 使用 ChaCha20 进行对称加密，使用 Poly1305 进行数据验证。 利用 Curve25519 进行密钥交换。 使用 BLAKE2 作为哈希函数。 使用 HKDF 进行解密。  WireGuard 的加密技术本质上是 Trevor Perrin 的 Noise 框架的实例化，它简单高效，其他的 VPN 都是通过一系列协商、握手和复杂的状态机来保障安全性。WireGuard 就相当于 VPN 协议中的 qmail，代码量比其他 VPN 协议少了好几个数量级。\n密钥管理\nWireGuard 通过为每个对等节点提供简单的公钥和私钥来实现双向认证，每个对等节点在设置阶段生成密钥，且只在对等节点之间共享密钥。每个节点除了公钥和私钥，不再需要其他证书或预共享密钥。\n在更大规模的部署中，可以使用 Ansible 或 Kubernetes Secrets 等单独的服务来处理密钥的生成、分发和销毁。\n如果你不想在 wg0.conf 配置文件中直接硬编码，可以从文件或命令中读取密钥，这使得通过第三方服务管理密钥变得更加容易：\n[Interface] ... PostUp = wg set %i private-key /etc/wireguard/wg0.key \u0026lt;(cat /some/path/%i/privkey) 从技术上讲，多个服务端之间可以共享相同的私钥，只要客户端不使用相同的密钥同时连接到两个服务器。但有时客户端会需要同时连接多台服务器，例如，你可以使用 DNS 轮询来均衡两台服务器之间的连接，这两台服务器配置相同。大多数情况下，每个对等节点都应该使用独立的的公钥和私钥，这样每个对等节点都不能读取到对方的流量，保障了安全性。\n搭建使用与配置详解 快速开始 安装\n# Ubuntu ≥ 18.04 $ apt install wireguard 在中继服务器上开启 IP 地址转发：\n$ echo \u0026#34;net.ipv4.ip_forward = 1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf $ echo \u0026#34;net.ipv4.conf.all.proxy_arp = 1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf $ sysctl -p /etc/sysctl.conf 添加 iptables 规则，允许本机的 NAT 转换：\n$ iptables -A INPUT -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT $ iptables -A FORWARD -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT $ iptables -A FORWARD -i wg0 -o wg0 -m conntrack --ctstate NEW -j ACCEPT $ iptables -t nat -A POSTROUTING -s 192.0.2.0/24 -o eth0 -j MASQUERADE 需要把 eth0 改成你实际使用的网卡接口名称。\n配置文件\n配置文件可以放在任何路径下，但必须通过绝对路径引用。默认路径是 /etc/wireguard/wg0.conf。\n生成密钥\n#生成私钥 $ wg genkey \u0026gt; example.key # 生成公钥 $ wg pubkey \u0026lt; example.key \u0026gt; example.key.pub 启动与停止\n$ wg-quick up /full/path/to/wg0.conf $ wg-quick down /full/path/to/wg0.conf # 启动/停止 VPN 网络接口 $ ip link set wg0 up $ ip link set wg0 down # 注册/注销 VPN 网络接口 $ ip link add dev wg0 type wireguard $ ip link delete dev wg0 # 注册/注销 本地 VPN 地址 $ ip address add dev wg0 192.0.2.3/32 $ ip address delete dev wg0 192.0.2.3/32 # 添加/删除 VPN 路由 $ ip route add 192.0.2.3/32 dev wg0 $ ip route delete 192.0.2.3/32 dev wg0 查看信息\n# 查看系统 VPN 接口信息 $ ip link show wg0 # 查看 VPN 接口详细信息 $ wg show all $ wg show wg0 # 查看 VPN 接口地址 $ ip address show wg0 路由\n# 查看系统路由表 $ ip route show table main $ ip route show table local # 获取到特定 IP 的路由 $ ip route get 192.0.2.3 一键安装\n一键安装请参考这个项目：WireGuard installer\n配置详解 WireGuard 使用 INI 语法作为其配置文件格式。配置文件可以放在任何路径下，但必须通过绝对路径引用。默认路径是 /etc/wireguard/wg0.conf。\n配置文件的命名形式必须为 ${WireGuard 接口的名称}.conf。通常情况下 WireGuard 接口名称以 wg 为前缀，并从 0 开始编号，但你也可以使用其他名称，只要符合正则表达式 ^[a-zA-Z0-9_=+.-]{1,15}$ 就行。\n你可以选择使用 wg 命令来手动配置 VPN，但一般建议使用 wg-quick，它提供了更强大和用户友好的配置体验，可以通过配置文件来管理配置。\n下面是一个配置文件示例：\n[Interface] # Name = node1.example.tld Address = 192.0.2.3/32 ListenPort = 51820 PrivateKey = localPrivateKeyAbcAbcAbc= DNS = 1.1.1.1,8.8.8.8 Table = 12345 MTU = 1500 PreUp = /bin/example arg1 arg2 %i PostUp = /bin/example arg1 arg2 %i PreDown = /bin/example arg1 arg2 %i PostDown = /bin/example arg1 arg2 %i [Peer] # Name = node2-node.example.tld AllowedIPs = 192.0.2.1/24 Endpoint = node1.example.tld:51820 PublicKey = remotePublicKeyAbcAbcAbc= PersistentKeepalive = 25 [Interface]\n这一节定义本地 VPN 配置。例如：\n本地节点是客户端，只路由自身的流量，只暴露一个 IP。\n[Interface] # Name = phone.example-vpn.dev Address = 192.0.2.5/32 PrivateKey = \u0026lt;private key for phone.example-vpn.dev\u0026gt; 本地节点是中继服务器，它可以将流量转发到其他对等节点（peer），并公开整个 VPN 子网的路由。\n[Interface] # Name = public-server1.example-vpn.tld Address = 192.0.2.1/24 ListenPort = 51820 PrivateKey = \u0026lt;private key for public-server1.example-vpn.tld\u0026gt; DNS = 1.1.1.1  Name  这是 INI 语法中的标准注释，用于展示该配置部分属于哪个节点。这部分配置会被 WireGuard 完全忽略，对 VPN 的行为没有任何影响。\nAddress  定义本地节点应该对哪个地址范围进行路由。如果是常规的客户端，则将其设置为节点本身的单个 IP（使用 CIDR 指定，例如 192.0.2.3/32）；如果是中继服务器，则将其设置为可路由的子网范围。\n例如：\n 常规客户端，只路由自身的流量：Address = 192.0.2.3/32 中继服务器，可以将流量转发到其他对等节点（peer）：Address = 192.0.2.1/24 也可以指定多个子网或 IPv6 子网：Address = 192.0.2.1/24,2001:DB8::/64  ListenPort  当本地节点是中继服务器时，需要通过该参数指定端口来监听传入 VPN 连接，默认端口号是 51820。常规客户端不需要此选项。\nPrivateKey  本地节点的私钥，所有节点（包括中继服务器）都必须设置。不可与其他服务器共用。\n私钥可通过命令 wg genkey \u0026gt; example.key 来生成。\nDNS  通过 DHCP 向客户端宣告 DNS 服务器。客户端将会使用这里指定的 DNS 服务器来处理 VPN 子网中的 DNS 请求，但也可以在系统中覆盖此选项。例如：\n 如果不配置则使用系统默认 DNS 可以指定单个 DNS：DNS = 1.1.1.1 也可以指定多个 DNS：DNS = 1.1.1.1,8.8.8.8  Table  定义 VPN 子网使用的路由表，默认不需要设置。该参数有两个特殊的值需要注意：\n Table = off : 禁止创建路由 Table = auto（默认值） : 将路由添加到系统默认的 table 中，并启用对默认路由的特殊处理。  例如：Table = 1234\nMTU  定义连接到对等节点（peer）的 MTU（Maximum Transmission Unit，最大传输单元），默认不需要设置，一般由系统自动确定。\nPreUp  启动 VPN 接口之前运行的命令。这个选项可以指定多次，按顺序执行。\n例如添加路由：PreUp = ip rule add ipproto tcp dport 22 table 1234\nPostUp  启动 VPN 接口之后运行的命令。这个选项可以指定多次，按顺序执行。\n例如：\n  从文件或某个命令的输出中读取配置值：\nPostUp = wg set %i private-key /etc/wireguard/wg0.key \u0026lt;(some command here)   添加一行日志到文件中：\nPostUp = echo \u0026#34;$(date +%s) WireGuard Started\u0026#34; \u0026gt;\u0026gt; /var/log/wireguard.log   调用 WebHook：\nPostUp = curl https://events.example.dev/wireguard/started/?key=abcdefg   添加路由：\nPostUp = ip rule add ipproto tcp dport 22 table 1234   添加 iptables 规则，启用数据包转发：\nPostUp = iptables -A FORWARD -i %i -j ACCEPT; iptables -A FORWARD -o %i -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE   强制 WireGuard 重新解析对端域名的 IP 地址：\nPostUp = resolvectl domain %i \u0026#34;~.\u0026#34;; resolvectl dns %i 192.0.2.1; resolvectl dnssec %i yes   PreDown  停止 VPN 接口之前运行的命令。这个选项可以指定多次，按顺序执行。\n例如：\n  添加一行日志到文件中：\nPreDown = echo \u0026#34;$(date +%s) WireGuard Going Down\u0026#34; \u0026gt;\u0026gt; /var/log/wireguard.log   调用 WebHook：\nPreDown = curl https://events.example.dev/wireguard/stopping/?key=abcdefg   PostDown  停止 VPN 接口之后运行的命令。这个选项可以指定多次，按顺序执行。\n例如：\n  添加一行日志到文件中：\nPostDown = echo \u0026#34;$(date +%s) WireGuard Going Down\u0026#34; \u0026gt;\u0026gt; /var/log/wireguard.log   调用 WebHook：\nPostDown = curl https://events.example.dev/wireguard/stopping/?key=abcdefg   删除 iptables 规则，关闭数据包转发：\nPostDown = iptables -D FORWARD -i %i -j ACCEPT; iptables -D FORWARD -o %i -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE   [Peer]\n定义能够为一个或多个地址路由流量的对等节点（peer）的 VPN 设置。对等节点（peer）可以是将流量转发到其他对等节点（peer）的中继服务器，也可以是通过公网或内网直连的客户端。\n中继服务器必须将所有的客户端定义为对等节点（peer），除了中继服务器之外，其他客户端都不能将位于 NAT 后面的节点定义为对等节点（peer），因为路由不可达。对于那些只为自己路由流量的客户端，只需将中继服务器作为对等节点（peer），以及其他需要直接访问的节点。\n举个例子，在下面的配置中，public-server1 作为中继服务器，其他的客户端有的是直连，有的位于 NAT 后面：\n  public-server1（中继服务器）\n[peer] : public-server2, home-server, laptop, phone\n  public-server2（直连客户端）\n[peer] : public-server1\n  home-server（客户端位于 NAT 后面）\n[peer] : public-server1, public-server2\n  laptop（客户端位于 NAT 后面）\n[peer] : public-server1, public-server2\n  phone（客户端位于 NAT 后面）\n[peer] : public-server1, public-server2\n  配置示例：\n  对等节点（peer）是路由可达的客户端，只为自己路由流量\n[Peer] # Name = public-server2.example-vpn.dev Endpoint = public-server2.example-vpn.dev:51820 PublicKey = \u0026lt;public key for public-server2.example-vpn.dev\u0026gt; AllowedIPs = 192.0.2.2/32   对等节点（peer）是位于 NAT 后面的客户端，只为自己路由流量\n[Peer] # Name = home-server.example-vpn.dev Endpoint = home-server.example-vpn.dev:51820 PublicKey = \u0026lt;public key for home-server.example-vpn.dev\u0026gt; AllowedIPs = 192.0.2.3/32   对等节点（peer）是中继服务器，用来将流量转发到其他对等节点（peer）\n[Peer] # Name = public-server1.example-vpn.tld Endpoint = public-server1.example-vpn.tld:51820 PublicKey = \u0026lt;public key for public-server1.example-vpn.tld\u0026gt; # 路由整个 VPN 子网的流量 AllowedIPs = 192.0.2.1/24 PersistentKeepalive = 25    Endpoint  指定远端对等节点（peer）的公网地址。如果对等节点（peer）位于 NAT 后面或者没有稳定的公网访问地址，就忽略这个字段。通常只需要指定中继服务器的 Endpoint，当然有稳定公网 IP 的节点也可以指定。例如：\n  通过 IP 指定：\nEndpoint = 123.124.125.126:51820   通过域名指定：\nEndpoint = public-server1.example-vpn.tld:51820   AllowedIPs  允许该对等节点（peer）发送过来的 VPN 流量中的源地址范围。同时这个字段也会作为本机路由表中 wg0 绑定的 IP 地址范围。如果对等节点（peer）是常规的客户端，则将其设置为节点本身的单个 IP；如果对等节点（peer）是中继服务器，则将其设置为可路由的子网范围。可以使用 , 来指定多个 IP 或子网范围。该字段也可以指定多次。\n当决定如何对一个数据包进行路由时，系统首先会选择最具体的路由，如果不匹配再选择更宽泛的路由。例如，对于一个发往 192.0.2.3 的数据包，系统首先会寻找地址为 192.0.2.3/32 的对等节点（peer），如果没有再寻找地址为 192.0.2.1/24 的对等节点（peer），以此类推。\n例如：\n  对等节点（peer）是常规客户端，只路由自身的流量：\nAllowedIPs = 192.0.2.3/32   对等节点（peer）是中继服务器，可以将流量转发到其他对等节点（peer）：\nAllowedIPs = 192.0.2.1/24   对等节点（peer）是中继服务器，可以转发所有的流量，包括外网流量和 VPN 流量，可以用来干嘛你懂得：\nAllowedIPs = 0.0.0.0/0,::/0   对等节点（peer）是中继服务器，可以路由其自身和其他对等节点（peer）的流量：\nAllowedIPs = 192.0.2.3/32,192.0.2.4/32   对等节点（peer）是中继服务器，可以路由其自身的流量和它所在的内网的流量：\nAllowedIPs = 192.0.2.3/32,192.168.1.1/24   PublicKey  对等节点（peer）的公钥，所有节点（包括中继服务器）都必须设置。可与其他对等节点（peer）共用同一个公钥。\n公钥可通过命令 wg pubkey \u0026lt; example.key \u0026gt; example.key.pub 来生成，其中 example.key 是上面生成的私钥。\n例如：PublicKey = somePublicKeyAbcdAbcdAbcdAbcd=\nPersistentKeepalive  如果连接是从一个位于 NAT 后面的对等节点（peer）到一个公网可达的对等节点（peer），那么 NAT 后面的对等节点（peer）必须定期发送一个出站 ping 包来检查连通性，如果 IP 有变化，就会自动更新Endpoint。\n例如：\n 本地节点与对等节点（peer）可直连：该字段不需要指定，因为不需要连接检查。 对等节点（peer）位于 NAT 后面：该字段不需要指定，因为维持连接是客户端（连接的发起方）的责任。 本地节点位于 NAT 后面，对等节点（peer）公网可达：需要指定该字段 PersistentKeepalive = 25，表示每隔 25 秒发送一次 ping 来检查连接。  FFmpeg  powershell 执行与在 cmd 执行不一样，poweshell 某些 -c:v 会报错 ffmpeg 输出参数含义  frame: 编码的帧数量 fps：每秒编码的帧数 q：质量因子 size/ Lsize：视频和音频编码后的大小，即基本等于视频和音频 之和 time：输出帧的显示时间 bitrate：输出视频的比特率 dup：输入帧重复（duplicate）的数量 drop：输入帧丢弃（drop）的个数 speed：编码速度    视频文件本身其实是一个容器（container），里面包括了视频和音频，也可能有字幕等其他内容。\n视频和音频都需要经过编码，才能保存成文件。不同的编码格式（CODEC），有不同的压缩率，会导致文件大小和清晰度的差异。\n编码器（encoders）是实现某种编码格式的库文件。只有安装了某种格式的编码器，才能实现该格式视频/音频的编码和解码。\nFFmpeg 的命令行参数非常多，可以分成五个部分：\n$ ffmpeg [全局参数] [输入文件参数] -i 输入文件 [输出文件参数] [输出文件] 常用参数  -c：指定编码器 -c copy：直接复制，不经过重新编码（这样比较快） -c:v：指定视频编码器 -c:a：指定音频编码器 -i：指定输入文件 -an：去除音频流 -vn： 去除视频流 -preset：指定输出的视频质量，会影响文件的生成速度，有以下几个可用的值 ultrafast, superfast, veryfast, faster, fast, medium, slow, slower, veryslow。 -y：不经过确认，输出时直接覆盖同名文件。  查看视频文件的元信息 $ ffmpeg -i input.mp4 -hide_banner 转换编码格式 $ ffmpeg -i [input.file] -c:v libx264 output.mp4 转成 H.264 编码，一般使用编码器 libx264\n转换容器格式 $ ffmpeg -i input.mp4 -c copy output.mkv 改变分辨率 $ ffmpeg -i input.mp4 -vf scale=720:-1 output.mp4 提取视频 $ ffmpeg -i input.mp4 -an -c:v copy ouput.mp4 -vcodec codec 强制使用codec编解码方式。如果用copy表示原始编解码数据必须被拷贝。\n提取音频 $ ffmpeg -i input.mp4 -vn -c:a copy output.aac -c:a copy表示不改变音频编码，直接拷贝。\n添加音轨 $ ffmpeg -i input.aac -i input.mp4 output.mp4 音视频合成 $ ffmpeg -i video.mp4 -i audio.aac -c:v copy -c:a copy output.mp4 截图 从指定时间开始，连续对1秒钟的视频进行截图\n$ ffmpeg -y -i input.mp4 -ss 00:01:24 -t 00:00:01 output_%3d.jpg 指定只截取一帧\n$ ffmpeg -ss 01:23:45 -i input.mp4 -vframes 1 -q:v 2 output.jpg -vframes 1指定只截取一帧，-q:v 2表示输出的图片质量，一般是1到5之间（1 为质量最高）。\n裁剪 $ ffmpeg -ss [start] -i [input] -t [duration] -c copy [output] $ ffmpeg -ss [start] -i [input] -to [end] -c copy [output] 裁剪（cutting）指的是，截取原始视频里面的一个片段，输出为一个新视频。可以指定开始时间（start）和持续时间（duration），也可以指定结束时间（end）。\n添加字幕  外挂字幕：一个单独的外部字幕文件，格式类型一般有srt、vtt、ass等等。播放视频时，需要把外挂字幕和视频放在同一目录下，并在播放器中选择字幕文件才可以在视频中看到字幕。 软字幕：也叫内挂字幕、封装字幕、内封字幕，字幕流等，就是把前面的外挂字幕的字幕文件嵌入到视频中作为流的一部分，如果一个视频有多个字幕流那么播放视频是还得选择对应的字幕流 硬字幕：是嵌入到视频帧里面的字幕，它就像视频水印一样作为视频帧的一分部分了，不管再任何平台字幕看起来都是一样的，而且也不再要求播放器单独对字母进行渲染  常见的字幕格式有：\n SRT（标准外挂字幕格式）：只包含文字和时间码，没有样式，显示效果由播放器决定，不同的播放器显示出的效果可能差别很大。 ASS（高级外挂字幕格式）：支持样式、字体、字幕定位、淡入淡出、简单的特效。如果不缺字体，不同的播放器显示效果基本一致。  ffmpeg字幕处理流程(容器是否支持字幕流指的是输出容器)\n添加软字幕：\n$ ffmpeg -i video.mp4 -i subtitle.srt -c copy output.mkv 软字幕只有部分容器格式比如(mkv)才支持，MP4/MOV等不支持，而且也只有部分播放器支持软字幕或者外挂字幕(如VLC播放器)。\n添加多个字幕：\nffmpeg -i input.mp4 -i zh_CN.srt -i en_US.srt -map 0:v -map 0:a -map 1 -map 2 -c:v copy -c:a copy -metadata:s:s:0 language=chn -metadata:s:s:1 language=eng \u0026#34;output.mp4\u0026#34;  -map 是轨道参数，如果只有一个字幕，就不需要这个参数。-map 0:v 表示第一个文件输入视频轨道，-map 0:a 表示第二个轨道是第一个文件输入的音频轨道，-map 1 建立第三个轨道，-map 2 建立第四个轨道。如果没添加 map 参数，默认就只有一个字幕轨道，第二个英文字幕会覆盖第一个中文字幕轨道。 -metadata:s:s:0 language=chn 第一条字幕的语言设置为中文，-metadata:s:s:1 language=eng 第二条字幕的语言设置为英文。 language 不能自定义，只能设置成固定的缩写。  添加硬字幕：\n$ ffmpeg -i video.mkv -vf subtitles=subtitle.srt out.mp4 Mutt Mutt 是一个基于文本的邮件客户端，因其强大的功能而闻名。 Mutt虽然已诞生二十多年了，但仍然是大量用户的首选邮件客户端。\nMutt主要侧重于作为邮件用户代理（MUA），最初是为了查看邮件而编写的。 与其他邮件应用程序相比，稍后实现的功能（检索，发送和过滤邮件）比较简单，因此用户可能希望使用外部应用程序来扩展Mutt的功能。\n模块搭配方案 就像穿衣搭配一样，收件发件过滤邮件转发邮件各种功能都有很多种程序可以用，mutt怎么搭配呢？\n常用选项有这些(User/Transport/Delivery)：\n MUA 收件：fetchmail或getmail或OfflineIMAP MTA 发件：sendmail或msmtp或postfix。其中msmtp兼容强，postfix对国内不友好 MDA 分类: procmail或maildrop 邮件编辑：VIM。  一般搭配是：\n 老式搭配：mutt + getmail + sendmail + procmail 新式搭配：mutt + fetchmail + msmtp + maildrop  这里我们用：mutt + fetchmail + msmtp + procmail\n安装：\n$ sudo apt install mutt fetchmail msmtp procmail -y Mutt或各个写协作程序在配置前都是不能使用的，学习曲线还是比较陡峭的，所以要做好准备去花好一段去了解和学习各个部件。\n大概的配置流程是：\n 配置收件：~/.fetchmailrc 配置过滤：~/.procmailrc 配置发件：~/.msmtprc 配置mutt框架本身：~/.muttrc  注意：初学过程中，不要一上来就配置mutt。最好是先从各个部件开始：收件-\u0026gt;过滤邮件-\u0026gt;阅读邮件-\u0026gt;发件-\u0026gt;mutt界面，按照这种顺序。\n收件：配置Fetchmail  Fetchmail是由著名的《大教堂与集市》作者 Eric Steven Raymond 编写的。\n Fetchmail是一个非常简单的收件程序，而且是前台运行、一次性运行的，意思是：你每次手动执行fetchmail命令，都是在前台一次收取完，程序就自动退出了，不是像一般邮件客户端一直在后台运行。\n注意：fetchmail只负责收件，而不负责存储！所以它是要调用另一个程序如procmail来进行存储的。\nfetchmail的配置文件为~/.fetchmailrc。然后文件权限最少要设置chmod 600 ~/.fetchmailrc\n比如我们要设置多个邮箱账户同时收取，那么配置如下：\npoll pop.AAA.com protocol POP3 user \u0026#34;me@AAA.com\u0026#34; password \u0026#34;123\u0026#34; poll pop.BBB.com protocol POP3 user \u0026#34;me\u0026#34; there with password \u0026#34;123\u0026#34; is falko here fetchall poll pop.CCC.com protocol POP3 user \u0026#34;me\u0026#34; there with password \u0026#34;123\u0026#34; is till here keep poll pop.DDD.com protocol POP3 user \u0026#34;me\u0026#34; password \u0026#34;123\u0026#34; ## QQ 邮箱 poll pop.qq.com port 995 protocol POP3 user \u0026#34;1664548605@qq.com\u0026#34; password [授权码] ssl keep # 全局选项 mimedecode # 不加 -d %T 就会报 ~/Mail/inbox is not a mailbox. 错误 mda \u0026#34;/usr/bin/procmail -d %T\u0026#34; 其中：\n 各种参数可以不按顺序，也可以不在一行。 空格隔开每个参数，poll隔开每个账户。 here, there, with, is等等，都不是关键词，随便写不影响参数。 以下是必填  poll后面是邮件服务器的地址，一般是pop.xxx.com protocol后面是收件协议，一般是pop或pop3 user后面是用户名，可以是username，也可以是邮箱地址 password后面是密码   sslproto：可能会报错 fetchmail: pop.qq.com: upgrade to TLS failed.，故可以禁掉SSL，同 man 手册查到  加上option --nosslcertck，虽然有报错，但至少可以收邮件了。 加--sslprotocl '', 注意要用空字符串   四选一：  nofetchall ：仅检索新消息（默认）。 fetchall ：获取所有消息，无论是否看到。 keep ：不要从服务器上删除看到的消息。 nokeep ：从服务器中删除看到的消息。   mimedecode用来自动解码MIME mda后面指定本机安装的邮件过滤分类程序。如果不填，则收取的邮件在本地不会保存。注意用which procmail查一下路径。 QQ 邮箱客户端设置 Outlook 设置：失败了  配置完成后，可以运行fetcmail -v来看看是否有错误信息，如果能够正常显示很多行的收取信息，那么就能正确登录邮箱收取了。\n一般收取的命令如下：\n# 只收取未读邮件 $ fetchmai # 收取所有邮件 $ fetchmail -a # （重要）收取新邮件，但不在服务器端删除已经收取的邮件 $ fetchmail -k 但是fetchmail只负责收取，不负责“下载”部分，你找不到邮件存在哪了。 所以还需要配置MDA分类器，如procmail，才能看到下载后的邮件。\n注意：Fetch其实不是在Mutt“里”使用的，而是脱离mutt之外的！也就是说，Mutt只负责读取本地存储邮件的文件夹更新，而不会自动帮你去执行fetchmail命令。\n你必须自己手动执行，或者用Crontab定期收取，或者设为Daemon守护进程，还可以在Mutt中设置快捷键执行Shell命令：\n  要使fetchmail作为守护进程运行，我们必须编辑/etc/default/fetchmail并将START_DAEMON设置为yes\n$ vi /etc/default/fetchmail START_DAEMON=yes 接下来，必须创建配置文件/etc/fetchmailrc并设置 set daemon 300 （这意味着fetchmail应该每300秒检索一次电子邮件）。\n  设置Mutt快捷键收取邮件的方法是在~/.muttrc中加入macro：\nmacro index,pager I \u0026#39;\u0026lt;shell-escape\u0026gt; fetchmail -vk\u0026lt;enter\u0026gt;\u0026#39; 这样的话，你就可以在index邮件列表中按I执行外部shell命令收取邮件了。\n  邮件过滤：配置Procmail Procmail是单纯负责邮件的存储、过滤和分类的，一般配合fetchmail收件使用。\n在Pipline中，fetchmail把收到的邮件全部传送到Procmail进行过滤筛选处理，然后Procmail就会把邮件存到本地形成文件，然后给邮件分类为工作、生活、重要、垃圾等。\n当然，分类规则是自己可以指定的。可以根据发信人、主题、长度以及关键字 等对邮件进行排序、分类、整理。\nProcmail 的配置文件是 ~/.procmailrc ，记得改权限：chmod 600 ~/.procmailrc。\n内容也非常简单，前面是邮件位置、日志等默认选项，后面则是一块一块的过滤规则。\n基本配置：\n# 邮件存储地址 MAILDIR=$HOME/Mail # 默认：收件箱 DEFAULT=$MAILDIR/inbox VERBOSE=off LOGFILE=/tmp/procmaillog # 某个垃圾邮件规则 :0 * ^From: webmaster@st\\.zju\\.edu\\.cn # 垃圾文件的存储位置 /dev/null # 其它所有都存到收件箱中 :0: inbox/ 其中，$HOME/Mail是设定的邮件存储位置。\n我们需要手动创建mkdir ~/Mail，否则程序会报错。\n配置好后，我们再测试一下就会看到：\n$ fetchmail -a 78 messages for 1664548605@qq.com at pop.qq.com (2843793 octets). reading message 1664548605@qq.com@pop.qq.com:1 of 78 (36692 octets) not flushed ... $ tree ~/Mail /home/vane/Mail └── inbox 0 directories, 1 file $ du -h Mail/inbox 2.1M\tMail/inbox 可以看到，所有邮件都保存在了inbox这个单一文件中。这个文件可以打开看到MIME格式(协议)的邮件源码。就像HTML一样，展示给我们的和背后的源码不一样。\n那么怎么把这个类似HTML的MIME格式邮件解析为我们人能读懂的内容呢？——这个我们就要靠mutt自己了，mutt自身具备基本的MIME邮件解析功能（不包括HTML格式邮件读取）。\n发件：配置msmtp msmtp是作为sendmail发邮件程序更好的替代品。\nmsmtp的配置文件为~/.msmtprc，记得改权限：chmod 600 ~/.msmtprc\n配置内容比收件还简单，因为发件永远比收件简单。\n基本配置：\naccount default auth login host smtp.XXX.com port 587 from ME@XXX.com user ME password passwd # 关于tls，如果是阿里云则不用写，如果是Outlook的话，必须写 tls on tls_starttls off tls_certcheck off # QQ 邮箱例子 account default # QQ邮箱这里必须是 on，否则会 535 Login Fail auth on host smtp.qq.com port 587 from 1664548605@qq.com # user 必须是 @ 之前的部分，不能自定义，否则会 535 Login Fail user 1664548605 password [授权码] tls on tls_starttls off tls_certcheck off logfile /tmp/msmtp.log QQ 邮箱例子：使用mutt+msmtp在Linux命令行界面下发邮件。\n总之，哪怕QQ 邮箱设置对了，也要多试几次才能发送成功。\n主界面：配置Mutt Mutt的配置文件为~/.muttrc，记得改权限：chmod 600 ~/.muttrc\n另外：mutt的配置文件还可以放在~/.mutt/muttrc。这种方法有一个好处，即~/.mutt/目录下可以放很多主题、插件等文件。\n基本配置：\n# 通用设定 set use_from=yes set envelope_from=yes #移动已读邮件 set move=yes #回复的时候调用原文 set include set charset=\u0026#34;utf-8\u0026#34; #自动显示HTML auto_view text/html # 发送者账号 set realname=\u0026#34;Vane Hsiung\u0026#34; set from=\u0026#34;1664548605@qq.com\u0026#34; # 分类邮箱 #Mail box type set mbox_type = Maildir set folder = \u0026#34;$HOME/Mail\u0026#34; #INBOX set spoolfile = \u0026#34;$HOME/Mail/inbox\u0026#34; #Seen box set mbox=\u0026#34;$HOME/Mail/seen\u0026#34; #Sent box set record=\u0026#34;$HOME/Mail/sent\u0026#34; #Draft box set postponed=\u0026#34;$HOME/Mail/draft\u0026#34; # 关联程序（需要自己用which命令确定一下） # 默认使用 nano set editor=\u0026#34;vim\u0026#34; set sendmail=\u0026#34;/usr/bin/msmtp\u0026#34; 以上如果有什么问题，可参考etchmail + proc + msmtp + mutt configuration samples。\n确认邮箱服务器 即使上面配置一切OK，也不一定能正常收发邮件。因为你用的Gmail、QQ、网易、阿里云等等，后台都有一系列的第三方收取设置。这是各不相同的。\n除了第三方客户端的允许，我们还要设置POP。最好放开全部邮件或者最近30天，然后禁止客户端删信。这是什么意思呢？POP默认客户端在收件后，服务器上的邮件就自动删除了！这个不太合适，所以必须要禁止。\n基本操作 邮件列表操作：\n 基本：q:Quit, d:删除当前邮件, s:将邮件移动至指定文件夹, m:创建新邮件, r:回复当前邮件, ?:帮助 移动：j/k 上下移动邮件, z/Z上下翻页, \u0026lt;Number\u0026gt; 跳至序号处（不进入邮件） \u0026lt;Enter\u0026gt; 打开选中的邮件 /在当前文件夹搜索 d 将选中邮件标记为删除, N 将选中邮件标记为未读, $ 让标记的东西生效，如删除、未读等。 f 转发选中邮件, e 编辑选中邮件 c切换文件夹(inbox/seen/draft等), 需要输入文件夹名称，或按?在列表里选择，j/k上下移动。  在邮件中的操作：\n j/k 上一封／下一封邮件, \u0026lt;Space\u0026gt;: 向下翻页, \u0026lt;Enter\u0026gt;: 向下滚动 e 编辑当前邮件, t编辑TO，c编辑CC，b编辑BCC，y发送邮件，a添加附件，Return查看附件，E编辑附件，D删除附件  使用命令操作：\nMutt如同Vim一样，不光可以把命令绑定为快捷键，还能直接输入:直接输入命令。 但是稍有不同的是，Mutt称之为Action，而且需要用:exec \u0026lt;命令\u0026gt;这样格式执行。\n比如sidebar侧边栏的移动，命令是：sidebar-next, sidebar-prev。 那么我们可以直接输入:exec sidebar-next，按下回车执行。\nIRC 简介 芬兰人雅尔可·欧伊卡利宁（Jarkko Oikarinen）于1988年8月创造了IRC来取代一个叫做MUT的程序。\n IRC（Internet Relay Chat的缩写，“因特网中继聊天”）是一个位于应用层的协议。 其主要用于群体聊天，但同样也可以用于个人对个人的聊天。 一个IRC服务器可以连接其他的IRC服务器以扩展为一个IRC网络。 IRC 不强制注册；但如果你注册了，就可以强制把占用自己唯一 ID 的人踢下线。 IRC 协议简单，开源实现多，其第三方机器人程序非常众多，几乎每种语言都有一个实现。 IRC 是开源社区会议标准；因此，许多开源世界的技术大牛混在那里。  irchelp：一个致力于帮助用户了解IRC的网站。\nIRC：Linux文档项目的IRC HOWTO\n服务器 首先要区分一些概念：\n Networks：是指的互相隔离的网络，如Freenode和DALnet这些是世界知名的网络，但互相隔离，频道不共享。 Servers：Network网络中的某一台电脑服务器，你加入世界上任何一个server都能加入这个Network。IRC是一个分布式的客户端/服务器结构。通过连接到一个IRC服务器，我们可以访问这个服务器以及它所连接的其他服务器上的频道（即这个 Network 中所有频道）。  频道存在于一个IRC服务器上。一个频道类似于一个聊天室，频道名称必须以#符号开始，例如#irchelp。\n要使用IRC，必须先登录到一个IRC服务器上，最常见的为irc.freenode.net——最大的IRC网络，为免费和开源软件社区，非营利组织和相关社区提供讨论设施。\nFreenode 用户模式。\nIRC使用的服务器端口有:\n 6667（明文传输，如irc://irc.freenode.net） 6697（SSL加密传输，如ircs://irc.freenode.net:6697）。  IRCD: 简称互联网中继聊天守护，是服务器软件实现了IRC 协议，使人们通过上网彼此交谈（交换文本即时消息）。\n客户端 IRC用户透过客户端软件和服务器相连。\nInternet Relay Chat客户端的比较：\n   Client Homepage Description     Irssi https://irssi.org/ 支持IPv6的模块化文本UI IRC客户端。轻量级流行客户端。   WeeChat https://weechat.org/ 便携式和多接口（文本，Web和GUI）IRC客户端。    Irssi 安装\n$ apt install irssi 命令行输入irssi即进入了聊天室。\n和一般Linux程序的一般命令、格式都不同，IRC客户端一般有自己的命令。窗口右下方[(status)]是输入命令的地方。\n一般命令(不区分大小写)：\n /quit，退出程序。一般的ctrl-c, ctrl-d, esc, q之类的都不管用 /help，帮助 /network list 查看已保存的服务器列表 /connect xxx.xxx.xxx 连接某服务器。连接 freenode，需要到 https://irc.com/login/sso 注册，然后按照 https://freenode.net/kb/answer/sasl 进行设置。 /join xxx 加入某channel /leave或/part 离开当前channel /normal或/n 查看当前channel的人数 /list -YES 查看当前服务器的所有chennels (慎用) /nick NewNickName 更改当前昵称 /msg NickName Content 给某人发送消息，一般都是给/msg nickserv管理人NPC发送消息  常用快捷键：\n Alt + 1/2/3/4...，切换window窗口，一般一个channel一个窗口 Alt + n/p，上下滚动屏幕  IRC 常用缩写词\n配置\n如果想长期保存、备份一个固定的程序配置，那么就需要修改配置文件。\nirssi默认的配置文件为~/.irssi/config。\n配置中，会在第一次运行时就自动设置了一些，包括根据当前电脑账户的用户名设置nickname等。整个配置，是一直“类似”JSON的格式。\nsettings ：记录自己的名字：nick, real_name, user_name\nservers ：这是指的Network而不是具体某台server，如Freenode、Dal、ESPer、EFnet等大型网络。服务器配置案例：\nservers = ( { address = \u0026#34;irc.dal.net\u0026#34;; chatnet = \u0026#34;DALnet\u0026#34;; port = \u0026#34;6667\u0026#34;; }, { address = \u0026#34;路径\u0026#34;; chatnet = \u0026#34;下面chatnet对应的名称\u0026#34;; port = \u0026#34;端口\u0026#34;; autoconnect = true; use_ssl = \u0026#34;yes\u0026#34;; password = \u0026#34;用户名:密码\u0026#34;; } ); chatnets：记录各个网络的登录信息，也可以作为“别名”，这样每次/connect不用输入全路径了。配置完每个服务器后，还要配置相应的chatnets，每一条的名称都要与servers中的对应。\nchatnets = { DALnet = { type = \u0026#34;IRC\u0026#34;; max_kicks = \u0026#34;4\u0026#34;; max_msgs = \u0026#34;20\u0026#34;;max_whois = \u0026#34;30\u0026#34;; }; Freenode = { type = \u0026#34;IRC\u0026#34;; max_kicks = \u0026#34;4\u0026#34;; max_msgs = \u0026#34;20\u0026#34;;max_whois = \u0026#34;30\u0026#34;; autosendcmd = \u0026#34;/msg nickserv identify MyName MyPassword\u0026#34;; }; }; channels ：记录自己收藏的频道名。RC的频道不是用URL之类很复杂的东西，全都是用#tag这种简单一个标签来区分的，非常好记。\nchannels = ( { name = \u0026#34;#lobby\u0026#34;; chatnet = \u0026#34;EsperNet\u0026#34;; autojoin = \u0026#34;No\u0026#34;; }, { name = \u0026#34;#freenode\u0026#34;; chatnet = \u0026#34;Freenode\u0026#34;; autojoin = \u0026#34;No\u0026#34;; }, ); statusbar：界面美化的设置。目前IRSSI的世界里，唯一知名的主题只有weed。\nAria2 Aria2是一款开源下载工具，可帮助简化不同设备和服务器之间的下载过程。它支持磁力链接、BT种子、http等类型的文件下载，与迅雷相比，Aria2有着优秀的性能及较低的资源占用，架构本身非常轻巧，通常只需要4兆字节（HTTP下载）到9兆字节（用于BitTorrent交互）之间。最重要的一点是Aria2完全免费！\n# Install $ sudo apt-get install aria2 下载安装完成之后，可以通过输入 aria2c -v 来验证是否安装成功。\nUsage 命令行使用\n使用Aria2下载文件，只需在命令后附加地址即可：\n$ aria2c URL 下载后以其他名称保存文件\n$ aria2c -o fileName URL 下载多个文件\n$ aria2c -Z URL URL 从列表下载文件：\n$ aria2c -i URLs.txt 限制下载速度：\n# 单个文件 aria2c –max-download-limit=500k URL # 全局 aria2c –max-overall-download-limit=500k URL 断点续传：\n$ aria2c -c URL 下载磁力链接文件：要下载磁力链接文件，如果下载没有速度，可以添加--bt-tracker=选项，tracker 中用 , 隔开，重新获取 最新 trackers：\n$ aria2c --bt-tracker=tracker,tracker torrent 分段下载：可以加快文件的下载速度，对于下载大文件时特别有用，-s 后面的参数值介于1~5之间，你可以根据实际情况选择。下面命令将使用2连接来下载该文件：\n$ aria2c -s 2 URL 后台下载：\n$ aria2c -D url $ aria2c –deamon=true url 验证文件：\n$ aria2c –checksum=md5=提供的md5 设置dht端口：\n$ aria2c –dht-listen-port=1234 torrent 下载需要引用页的文件：\n$ aria2c –referer=referurl URL 下载需要Cookie验证的文件：\n$ aria2c –essay-header=’Cookie:key=value’ URL $ aria2c –load-cookies=cookie文件 URL 从密码保护的网站下载一个文件：\n$ aria2c --http-user=xxx --http-password=xxx URL $ aria2c --ftp-user=xxx --ftp-password=xxx URL 注意：当源地址存在诸如\u0026amp;,*等shell的特殊字符，请使用单引号或双引号把URI包含起来。\nRPC Server 模式\n该模式可以配合 Web UI 进行图形管理。默认启动是 6800 端口，怕别人盗用，可以设置用户名和密码(1.18.4以上版本支持密钥)。\n$ aria2c --enable-rpc --rpc-listen-all --rpc-allow-origin-all -c --dir ~/Download Configuration 默认情况下，aria2 检查旧路径 $HOME/.aria2/aria2.conf 是否存在，否则它会将 $XDG_CONFIG_HOME/aria2/aria2.conf 解析为它的配置文件。 您可以使用 --conf-path 选项指定配置文件的路径。 如果您不想使用配置文件，请使用 --no-conf 选项。\n配置详解：\n## \u0026#39;#\u0026#39;开头为注释内容, 选项都有相应的注释说明, 根据需要修改 ## ## 被注释的选项填写的是默认值, 如为空则无默认设置，请自行选取需要更改的添加到你的配置文件中 ## # 下载路径(可使用绝对路径或相对路径), 默认: 当前启动位置 #dir= dir=/home/vane/Downloads # 日志文件 # 日志文件的路径. 如果设置为 \u0026#34;-\u0026#34;, 日志则写入到 stdout. 如果设置为空字符串(\u0026#34;\u0026#34;), 日志将不会记录到磁盘上. #log= log=/home/vane/.aria2/aria2.log # 最大同时下载数 #max-concurrent-downloads=5 # 检查完整性 # 通过对文件的每个分块或整个文件进行哈希验证来检查文件的完整性. 此选项仅对BT、Metalink及设置了 --checksum 选项的 HTTP(S)/FTP 链接生效. #check-integrity=false # 断点续传 # 继续下载部分完成的文件. 启用此选项可以继续下载从浏览器或其他程序按顺序下载的文件. 此选项目前只支持 HTTP(S)/FTP 下载的文件. #continue=true # 代理服务器 # 设置所有协议的代理服务器地址. 如果覆盖之前设置的代理服务器, 使用 \u0026#34;\u0026#34; 即可. 您还可以针对特定的协议覆盖此选项, 即使用 --http-proxy, --https-proxy 和 --ftp-proxy 选项. 此设置将会影响所有下载. 代理服务器地址的格式为 [http://][USER:PASSWORD@]HOST[:PORT]. #all-proxy= # 代理服务器用户名 #all-proxy-user= # 代理服务器密码 #all-proxy-passwd= # 连接超时时间 # 设置建立 HTTP/FTP/代理服务器 连接的超时时间(秒). 当连接建立后, 此选项不再生效, 请使用 --timeout 选项. #connect-timeout=60 # 模拟运行 # 如果设置为\u0026#34;是\u0026#34;, aria2 将仅检查远程文件是否存在而不会下载文件内容. 此选项仅对 HTTP/FTP 下载生效. 如果设置为 true, BT 下载将会直接取消. #dry-run=false # 最小速度限制 # 当下载速度低于此选项设置的值(B/s) 时将会关闭连接. 0 表示不设置最小速度限制. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). 此选项不会影响 BT 下载. #lowest-speed-limit=0 # 单服务器最大连接数 #max-connection-per-server=1 max-connection-per-server=5 # 文件未找到重试次数 # 如果 aria2 从远程 HTTP/FTP 服务器收到 \u0026#34;文件未找到\u0026#34; 的状态超过此选项设置的次数后下载将会失败. 设置为 0 将会禁用此选项. 此选项仅影响 HTTP/FTP 服务器. 重试时同时会记录重试次数, 所以也需要设置 --max-tries 这个选项. #max-file-not-found=0 # 最大尝试次数 # 设置最大尝试次数. 0 表示不限制. #max-tries=5 # 最小文件分片大小 # aria2 不会分割小于 2*SIZE 字节的文件. 例如, 文件大小为 20MB, 如果 SIZE 为 10M, aria2 会把文件分成 2 段 [0-10MB) 和 [10MB-20MB), 并且使用 2 个源进行下载 (如果 --split \u0026gt;= 2). 如果 SIZE 为 15M, 由于 2*15M \u0026gt; 20MB, 因此 aria2 不会分割文件并使用 1 个源进行下载. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). 可以设置的值为: 1M-1024M. #min-split-size=20M min-split-size=10M # .netrc 文件路径 #netrc-path=$(HOME)/.netrc # 禁用 netrc #no-netrc=false # 不使用代理服务器列表 # 设置不使用代理服务器的主机名, 域名, 包含或不包含子网掩码的网络地址, 多个使用逗号分隔. #no-proxy= # 文件名 # 下载文件的文件名. 其总是相对于 --dir 选项中设置的路径. 当使用 --force-sequential 参数时此选项无效. #out= # 代理服务器请求方法 # 设置用来请求代理服务器的方法. 方法可设置为 GET 或 TUNNEL. HTTPS 下载将忽略此选项并总是使用 TUNNEL. #proxy-method=get # 获取服务器文件时间 # 从 HTTP/FTP 服务获取远程文件的时间戳, 如果可用将设置到本地文件 #remote-time=false # URI 复用 # 当所有给定的 URI 地址都已使用, 继续使用已经使用过的 URI 地址. #reuse-uri=true # 重试等待时间 # 设置重试间隔时间(秒). 当此选项的值大于 0 时, aria2 在 HTTP 服务器返回 503 响应时将会重试. #retry-wait=0 # 服务器状态保存文件 # 指定用来保存服务器状态的文件名. 您可以使用 --server-stat-if 参数读取保存的数据. #server-stat-of= # 服务器状态超时 # 指定服务器状态的过期时间 (单位为秒). #server-stat-timeout=86400 # 单任务连接数 # 下载时使用 N 个连接. 如果提供超过 N 个 URI 地址, 则使用前 N 个地址, 剩余的地址将作为备用. 如果提供的 URI 地址不足 N 个, 这些地址多次使用以保证同时建立 N 个连接. 同一服务器的连接数会被 --max-connection-per-server 选项限制. #split=5 split=10 # 分片选择算法 # 指定 HTTP/FTP 下载使用的分片选择算法. 分片表示的是并行下载时固定长度的分隔段. 如果设置为\u0026#34;默认\u0026#34;, aria2 将会按减少建立连接数选择分片. 由于建立连接操作的成本较高, 因此这是合理的默认行为. 如果设置为\u0026#34;顺序\u0026#34;, aria2 将选择索引最小的分片. 索引为 0 时表示为文件的第一个分片. 这将有助于视频的边下边播. --enable-http-pipelining 选项有助于减少重连接的开销. 请注意, aria2 依赖于 --min-split-size 选项, 所以有必要对 --min-split-size 选项设置一个合理的值. 如果设置为\u0026#34;随机\u0026#34;, aria2 将随机选择一个分片. 就像\u0026#34;顺序\u0026#34;一样, 依赖于 --min-split-size 选项. 如果设置为\u0026#34;几何\u0026#34;, aria2 会先选择索引最小的分片, 然后会为之前选择的分片保留指数增长的空间. 这将减少建立连接的次数, 同时文件开始部分将会先行下载. 这也有助于视频的边下边播. #stream-piece-selector=default # 超时时间 #timeout=60 # URI 选择算法 # 指定 URI 选择的算法. 可选的值包括 \u0026#34;按顺序\u0026#34;, \u0026#34;反馈\u0026#34; 和 \u0026#34;自适应\u0026#34;. 如果设置为\u0026#34;按顺序\u0026#34;, URI 将按列表中出现的顺序使用. 如果设置为\u0026#34;反馈\u0026#34;, aria2 将根据之前的下载速度选择 URI 列表中下载速度最快的服务器. 同时也将有效跳过无效镜像. 之前统计的下载速度将作为服务器状态文件的一部分, 参见 --server-stat-of 和 --server-stat-if 选项. 如果设置为\u0026#34;自适应\u0026#34;, 将从最好的镜像和保留的连接里选择一项. 补充说明, 其返回的镜像没有被测试过, 同时如果每个镜像都已经被测试过时, 返回的镜像还会被重新测试. 否则, 其将不会选择其他镜像. 例如\u0026#34;反馈\u0026#34;, 其使用服务器状态文件. #uri-selector=feedback # 检查证书 #check-certificate=true # 支持 GZip # 如果远程服务器的响应头中包含 Content-Encoding: gzip 或 Content-Encoding: deflate , 将发送包含 Accept: deflate, gzip 的请求头并解压缩响应. #http-accept-gzip=false # 认证质询 # 仅当服务器需要时才发送 HTTP 认证请求头. 如果设置为\u0026#34;否\u0026#34;, 每次都会发送认证请求头. 例外: 如果用户名和密码包含在 URI 中, 将忽略此选项并且每次都会发送认证请求头. #http-auth-challenge=false # 禁用缓存 # 发送的请求头中将包含 Cache-Control: no-cache 和 Pragma: no-cache header 以避免内容被缓存. 如果设置为\u0026#34;否\u0026#34;, 上述请求头将不会发送, 同时您也可以使用 --header 选项将 Cache-Control 请求头添加进去. #http-no-cache=false # HTTP 默认用户名 #http-user= # HTTP 默认密码 #http-passwd= # HTTP 代理服务器 #http-proxy= # HTTP 代理服务器用户名 #http-proxy-user= # HTTP 代理服务器密码 #http-proxy-passwd= # HTTPS 代理服务器 #https-proxy= # HTTPS 代理服务器用户名 #https-proxy-user= # HTTPS 代理服务器密码 #https-proxy-passwd= # 请求来源 # 设置 HTTP 请求来源 (Referer). 此选项将影响所有 HTTP/HTTPS 下载. 如果设置为 *, 请求来源将设置为下载链接. 此选项可以配合 --parameterized-uri 选项使用. #referer= # 启用持久连接 # 启用 HTTP/1.1 持久连接. #enable-http-keep-alive=true # 启用 HTTP 管线化 # 启用 HTTP/1.1 管线化. #enable-http-pipelining=false # 自定义请求头 # 增加 HTTP 请求头内容. #header= # Cookies 保存路径 # 以 Mozilla/Firefox(1.x/2.x)/Netscape 格式将 Cookies 保存到文件中. 如果文件已经存在, 将被覆盖. 会话过期的 Cookies 也将会保存, 其过期时间将会设置为 0. #save-cookies= # 启用 HEAD 方法 # 第一次请求 HTTP 服务器时使用 HEAD 方法. #use-head=false # 自定义 User Agent #user-agent=aria2/$VERSION # FTP 默认用户名 #ftp-user=anonymous # FTP 默认密码 # 如果 URI 中包含用户名单不包含密码, aria2 首先会从 .netrc 文件中获取密码. 如果在 .netrc 文件中找到密码, 则使用该密码. 否则, 使用此选项设置的密码. #ftp-passwd=ARIA2USER@ # 被动模式 # 在 FTP 中使用被动模式. 如果设置为\u0026#34;否\u0026#34;, 则使用主动模式. 此选项不适用于 SFTP 传输. #ftp-pasv=true # FTP 代理服务器 #ftp-proxy= # FTP 代理服务器用户名 #ftp-proxy-user= # FTP 代理服务器密码 #ftp-proxy-passwd= # 传输类型 #ftp-type=binary # 连接复用 #ftp-reuse-connection=true # SSH 公钥校验和 # 设置 SSH 主机公钥的校验和. TYPE 为哈希类型. 支持的哈希类型为 sha-1 和 md5. DIGEST 是十六进制摘要. 例如: sha-1=b030503d4de4539dc7885e6f0f5e256704edf4c3. 此选项可以在使用 SFTP 时用来验证服务器的公钥. 如果此选项不设置, 即保留默认, 不会进行任何验证。 #ssh-host-key-md= # 分离仅做种任务 # 统计当前活动下载任务(参见 -j 选项) 时排除仅做种的任务. 这意味着, 如果参数设置为 -j3, 此选项打开并且当前有 3 个正在活动的任务, 并且其中有 1 个进入做种模式, 那么其会从正在下载的数量中排除(即数量会变为 2), 在队列中等待的下一个任务将会开始执行. 但要知道, 在 RPC 方法中, 做种的任务仍然被认为是活动的下载任务. #bt-detach-seed-only=false # 启用哈希检查完成事件 # 允许 BT 下载哈希检查(参见 -V 选项) 完成后调用命令. 默认情况下, 当哈希检查成功后, 通过 --on-bt-download-complete 设置的命令将会被执行. 如果要禁用此行为, 请设置为\u0026#34;否\u0026#34;. #bt-enable-hook-after-hash-check=true # 启用本地节点发现 (LPD),PT需要禁用，BT需启用 #bt-enable-lpd=false bt-enable-lpd=true # BT 排除服务器地址 # 逗号分隔的 BT 排除服务器地址. 您可以使用 * 匹配所有地址, 因此将排除所有服务器地址. 当在 shell 命令行使用 * 时, 需要使用转义符或引号. #bt-exclude-tracker= # 外部 IP 地址 # 指定用在 BitTorrent 下载和 DHT 中的外部 IP 地址. 它可能被发送到 BitTorrent 服务器. 对于 DHT, 此选项将会报告本地节点正在下载特定的种子. 这对于在私有网络中使用 DHT 非常关键. 虽然这个方法叫外部, 但其可以接受各种类型的 IP 地址. #bt-external-ip= # 强制加密 # BT 消息中的内容需要使用 arc4 加密. 此选项是设置 --bt-require-crypto --bt-min-crypto-level=arc4 这两个选项的快捷方式. 此选项不会修改上述两个选项的内容. 如果设置为\u0026#34;是\u0026#34;, 将拒绝以前的 BT 握手, 并仅使用模糊握手及加密消息. #bt-force-encryption=false # 做种前检查文件哈希 # 如果设置为\u0026#34;是\u0026#34;, 当使用 --check-integrity 选项完成哈希检查及文件完成后才继续做种. 如果您希望仅当文件损坏或未完成时检查文件, 请设置为\u0026#34;否\u0026#34;. 此选项仅对 BT 下载有效 #bt-hash-check-seed=true # 加载已保存的元数据文件 # 当使用磁链下载时, 在从 DHT 获取种子元数据之前, 首先尝试加载使用 --bt-save-metadata 选项保存的文件. 如果文件加载成功, 则不会从 DHT 下载元数据. #bt-load-saved-metadata=false # 最多打开文件数 # 设置 BT/Metalink 下载全局打开的最大文件数. #bt-max-open-files=100 # 最大连接节点数 # 设置每个 BT 下载的最大连接节点数. 0 表示不限制. #bt-max-peers=55 # 仅下载种子文件 # 仅下载种子文件. 种子文件中描述的文件将不会下载. 此选项仅对磁链生效. #bt-metadata-only=false # 最低加密级别 # 设置加密方法的最小级别. 如果节点提供多种加密方法, aria2 将选择满足给定级别的最低级别. #bt-min-crypto-level=plain # 优先下载 # 尝试先下载每个文件开头或结尾的分片. 此选项有助于预览文件. 参数可以包括两个关键词: head 和 tail. 如果包含两个关键词, 需要使用逗号分隔. 每个关键词可以包含一个参数, SIZE. 例如, 如果指定 head=SIZE, 每个文件的最前 SIZE 数据将会获得更高的优先级. tail=SIZE 表示每个文件的最后 SIZE 数据. SIZE 可以包含 K 或 M (1K = 1024, 1M = 1024K). #bt-prioritize-piece= # 删除未选择的文件 # 当 BT 任务完成后删除未选择的文件. 要选择需要下载的文件, 请使用 --select-file 选项. 如果没有选择, 则所有文件都默认为需要下载. 此选项会从磁盘上直接删除文件, 请谨慎使用此选项. #bt-remove-unselected-file=false # 需要加密 # 如果设置为\u0026#34;是\u0026#34;, aria 将不会接受以前的 BitTorrent 握手协议(\\\\19BitTorrent 协议)并建立连接. 因此 aria2 总是模糊握手. #bt-require-crypto=false # 期望下载速度 # 如果一个 BT 下载的整体下载速度低于此选项设置的值, aria2 会临时提高连接数以提高下载速度. 在某些情况下, 设置期望下载速度可以提高您的下载速度. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). #bt-request-peer-speed-limit=50K # 保存种子文件 # 保存种子文件为 \u0026#34;.torrent\u0026#34; 文件. 此选项仅对磁链生效. 文件名为十六进制编码后的哈希值及 \u0026#34;.torrent\u0026#34;后缀. 保存的目录与下载文件的目录相同. 如果相同的文件已存在, 种子文件将不会保存. #bt-save-metadata=false bt-save-metadata=true # 不检查已经下载的文件 # 不检查之前下载文件中每个分片的哈希值. #bt-seed-unverified=false bt-seed-unverified=true # 无速度时自动停止时间 # 当 BT 任务F下载速度持续为 0, 达到此选项设置的时间后停止下载. 如果设置为 0, 此功能将禁用. #bt-stop-timeout=0 # BT 服务器地址 # 逗号分隔的 BT 服务器地址. 如果服务器地址在 --bt-exclude-tracker 选项中, 其将不会生效. #bt-tracker= bt-tracker=udp://tracker.opentrackr.org:1337/announce,udp://9.rarbg.com:2810/announce,udp://tracker.openbittorrent.com:6969/announce,udp://exodus.desync.com:6969/announce,http://tracker.openbittorrent.com:80/announce,http://openbittorrent.com:80/announce,udp://www.torrent.eu.org:451/announce,udp://vibe.community:6969/announce,udp://tracker.torrent.eu.org:451/announce,udp://tracker.tiny-vps.com:6969/announce,udp://retracker.lanta-net.ru:2710/announce,udp://open.stealth.si:80/announce,udp://movies.zsw.ca:6969/announce,udp://mail.realliferpg.de:6969/announce,udp://inferno.demonoid.is:3391/announce,udp://fe.dealclub.de:6969/announce,udp://discord.heihachi.pw:6969/announce,udp://bt2.archive.org:6969/announce,udp://bt1.archive.org:6969/announce,https://tracker.nanoha.org:443/announce # BT 服务器连接超时时间 # 设置 BT 服务器的连接超时时间 (秒). 当连接建立后, 此选项不再生效, 请使用 --bt-tracker-timeout 选项. #bt-tracker-connect-timeout=60 # BT 服务器连接间隔时间 # 设置请求 BT 服务器的间隔时间 (秒). 此选项将完全覆盖服务器返回的最小间隔时间和间隔时间, aria2 仅使用此选项的值.如果设置为 0, aria2 将根据服务器的响应情况和下载进程决定时间间隔. #bt-tracker-interval=0 # BT 服务器超时时间 #bt-tracker-timeout=60 # DHT (IPv4) 文件 # 修改 IPv4 DHT 路由表文件路径. #dht-file-path=$HOME/.aria2/dht.dat # DHT (IPv6) 文件 # 修改 IPv6 DHT 路由表文件路径. #dht-file-path6=$HOME/.aria2/dht6.dat # DHT 监听端口 # 设置 DHT (IPv4, IPv6) 和 UDP 服务器使用的 UCP 端口. 多个端口可以使用逗号 \u0026#34;,\u0026#34; 分隔, 例如: 6881,6885. 您还可以使用短横线 \u0026#34;-\u0026#34; 表示范围: 6881-6999, 或可以一起使用: 6881-6889, 6999. #dht-listen-port=6881-6999 # DHT 消息超时时间 #dht-message-timeout=10 # 启用 DHT (IPv4) # 启用 IPv4 DHT 功能. 此选项同时会启用 UDP 服务器支持. 如果种子设置为私有, 即使此选项设置为\u0026#34;是\u0026#34;, aria2 也不会启用 DHT. #enable-dht=true # 启用 DHT (IPv6) # 启用 IPv6 DHT 功能. 如果种子设置为私有, 即使此选项设置为\u0026#34;是\u0026#34;, aria2 也不会启用 DHT. 使用 --dht-listen-port 选项设置监听的端口. #enable-dht6= # 启用节点交换 # 启用节点交换扩展. 如果种子设置为私有, 即使此选项设置为\u0026#34;是\u0026#34;, aria2 也不会启用此功能. #enable-peer-exchange=true # 下载种子中的文件 # 如果设置为\u0026#34;是\u0026#34;或\u0026#34;仅内存\u0026#34;, 当后缀为 .torrent 或内容类型为 application/x-bittorrent 的文件下载完成时, aria2 将按种子文件读取并下载该文件中提到的文件. 如果设置为\u0026#34;仅内存\u0026#34;, 该种子文件将不会写入到磁盘中, 而仅会存储在内存中. 如果设置为\u0026#34;否\u0026#34;, 则 .torrent 文件会下载到磁盘中, 但不会按种子文件读取并且其中的文件不会进行下载. #follow-torrent=true # 监听端口 # 设置 BT 下载的 TCP 端口. 多个端口可以使用逗号 \u0026#34;,\u0026#34; 分隔, 例如: 6881,6885. 您还可以使用短横线 \u0026#34;-\u0026#34; 表示范围: 6881-6999, 或可以一起使用: 6881-6889, 6999. #listen-port=6881-6999 listen-port=51413 # 全局最大上传速度 # 设置全局最大上传速度 (字节/秒). 0 表示不限制. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). #max-overall-upload-limit=0 # 最大上传速度 # 设置每个任务的最大上传速度 (字节/秒). 0 表示不限制. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). #max-upload-limit=0 # 节点 ID 前缀 # 指定节点 ID 的前缀. BT 中节点 ID 长度为 20 字节. 如果超过 20 字节, 将仅使用前 20 字节. 如果少于 20 字节, 将在其后不足随机的数据保证为 20 字节. #peer-id-prefix=A2-1-33-0- # Peer Agent # 指定 BT 扩展握手期间用于节点客户端版本的字符串. #peer-agent=aria2/1.33.0 # 最小分享率 # 指定分享率. 当分享率达到此选项设置的值时会完成做种. 强烈建议您将此选项设置为大于等于 1.0. 如果您想不限制分享比率, 可以设置为 0.0. 如果同时设置了 --seed-time 选项, 当任意一个条件满足时将停止做种. #seed-ratio=1.0 seed-ratio=0.0 # 最小做种时间 # 此选项设置为 0 时, 将在 BT 任务下载完成后不进行做种. #seed-time= # 下载 Metalink 中的文件 # 如果设置为\u0026#34;是\u0026#34;或\u0026#34;仅内存\u0026#34;, 当后缀为 .meta4 或 .metalink 或内容类型为 application/metalink4+xml 或 application/metalink+xml 的文件下载完成时, aria2 将按 Metalink 文件读取并下载该文件中提到的文件. 如果设置为\u0026#34;仅内存\u0026#34;, 该 Metalink 文件将不会写入到磁盘中, 而仅会存储在内存中. 如果设置为\u0026#34;否\u0026#34;, 则 .metalink 文件会下载到磁盘中, 但不会按 Metalink 文件读取并且其中的文件不会进行下载. #follow-metalink=true # 基础 URI # 指定基础 URI 以便解析本地磁盘中存储的 Metalink 文件里 metalink:url 和 metalink:metaurl 中的相对 URI 地址. 如果 URI 表示的为目录, 最后需要以 / 结尾. #metalink-base-uri= # 语言 #metalink-language= # 首选服务器位置 # 首选服务器所在的位置. 可以使用逗号分隔的列表, 例如: jp,us. #metalink-location= # 操作系统 # 下载文件的操作系统. #metalink-os= # 版本号 # 下载文件的版本号. #metalink-version= # 首选使用协议 # 指定首选使用的协议. 可以设置为 http, https, ftp 或\u0026#34;无\u0026#34;. 设置为\u0026#34;无\u0026#34;时禁用此选项. #metalink-preferred-protocol=none # 仅使用唯一协议 # 如果一个 Metalink 文件可用多种协议, 并且此选项设置为\u0026#34;是\u0026#34;, aria2 将只会使用其中一种. 使用 --metalink-preferred-protocol 参数指定首选的协议. #metalink-enable-unique-protocol=true # 启用 JSON-RPC/XML-RPC 服务器 #enable-rpc=false enable-rpc=true # 种子文件下载完后暂停 # 当种子文件下载完成后暂停后续的下载. 在 aria2 中有 3 种种子文件的下载类型: (1) 下载 .torrent 文件. (2) 通过磁链下载的种子文件. (3) 下载 Metalink 文件. 这些种子文件下载完后会根据文件内容继续进行下载. 此选项会暂停这些后续的下载. 此选项仅当 --enable-rpc 选项启用时生效. #pause-metadata=false # 接受所有远程请求 # 在 RPC 响应头增加 Access-Control-Allow-Origin 字段, 值为 * .web界面跨域权限需要 #rpc-allow-origin-all=false rpc-allow-origin-all=true # 在所有网卡上监听 # 在所有网络适配器上监听 JSON-RPC/XML-RPC 的请求, 如果设置为\u0026#34;否\u0026#34;, 仅监听本地网络的请求. #rpc-listen-all=false rpc-listen-all=true # 监听端口 #rpc-listen-port=6800 # 最大请求大小 # 设置 JSON-RPC/XML-RPC 最大的请求大小. 如果 aria2 检测到请求超过设定的字节数, 会直接取消连接. #rpc-max-request-size=2M # 保存上传的种子文件 # 在 dir 选项设置的目录中保存上传的种子文件或 Metalink 文件. 文件名包括 SHA-1 哈希后的元数据和扩展名两部分. 对于种子文件, 扩展名为 \u0026#39;.torrent\u0026#39;. 对于 Metalink 为 \u0026#39;.meta4\u0026#39;. 如果此选项设置为\u0026#34;否\u0026#34;, 通过 aria2.addTorrent() 或 aria2.addMetalink() 方法添加的下载将无法通过 --save-session 选项保存. #rpc-save-upload-metadata=true # 设置的RPC授权令牌, v1.18.4新增功能, 取代 --rpc-user 和 --rpc-passwd 选项 rpc-secret=000000 # 设置的RPC访问用户名, 此选项新版已废弃, 建议改用 --rpc-secret 选项 #rpc-user=\u0026lt;USER\u0026gt; # 设置的RPC访问密码, 此选项新版已废弃, 建议改用 --rpc-secret 选项 #rpc-passwd=\u0026lt;PASSWD\u0026gt; # 启用 SSL/TLS # RPC 将通过 SSL/TLS 加密传输. RPC 客户端需要使用 https 协议连接服务器. 对于 WebSocket 客户端, 使用 wss 协议. 使用 --rpc-certificate 和 --rpc-private-key 选项设置服务器的证书和私钥. #rpc-secure= # 在 RPC 服务中启用 SSL/TLS 加密时的证书文件, # 使用 PEM 格式时，您必须通过 --rpc-private-key 指定私钥 #rpc-certificate=/path/to/certificate.pem # 在 RPC 服务中启用 SSL/TLS 加密时的私钥文件 #rpc-private-key=/path/to/certificate.key # 允许覆盖 # 如果相应的控制文件不存在时从头重新下载文件. 参见 --auto-file-renaming 选项. #allow-overwrite=false # 允许分片大小变化 # 如果设置为\u0026#34;否\u0026#34;, 当分片长度与控制文件中的不同时, aria2 将会中止下载. 如果设置为\u0026#34;是\u0026#34;, 您可以继续, 但部分下载进度将会丢失. #allow-piece-length-change=false # 始终断点续传 # 始终断点续传. 如果设置为\u0026#34;是\u0026#34;, aria2 始终尝试断点续传, 如果无法恢复, 则中止下载. 如果设置为\u0026#34;否\u0026#34;, 对于不支持断点续传的 URI 或 aria2 遇到 N 个不支持断点续传的 URI (N 为 --max-resume-failure-tries 选项设置的值), aria2 会从头下载文件. 参见 --max-resume-failure-tries 参数. #always-resume=true # 异步 DNS #async-dns=true # 文件自动重命名 # 重新命名已经存在的文件. 此选项仅对 HTTP(S)/FTP 下载有效. 新的文件名后会在文件名后、扩展名 (如果有) 前追加句点和数字(1..9999). #auto-file-renaming=true # 自动保存间隔 # 每隔设置的秒数自动保存控制文件(*.aria2). 如果设置为 0, 下载期间控制文件不会自动保存. 不论设置的值为多少, aria2 会在任务结束时保存控制文件. 可以设置的值为 0 到 600. #auto-save-interval=60 # 条件下载 # 仅当本地文件比远程文件旧时才进行下载. 此功能仅适用于 HTTP(S) 下载. 如果在 Metalink 中文件大小已经被指定则功能无法生效. 同时此功能还将忽略 Content-Disposition 响应头. 如果存在控制文件, 此选项将被忽略. 此功能通过 If-Modified-Since 请求头获取较新的文件. 当获取到本地文件的修改时间时, 此功能将使用用户提供的文件名 (参见 --out 选项), 如果没有指定 --out 选项则使用 URI 中的文件名. 为了覆盖已经存在的文件, 需要使用 --allow-overwrite 参数. #conditional-get=false # 配置文件路径 #conf-path=$HOME/.aria2/aria2.conf # 控制台日志级别 #console-log-level=notice # 使用 UTF-8 处理 Content-Disposition # 处理 \u0026#34;Content-Disposition\u0026#34; 头中的字符串时使用 UTF-8 字符集来代替 ISO-8859-1, 例如, 文件名参数, 但不是扩展版本的文件名. #content-disposition-default-utf8= # 启用后台进程 #daemon=false # 延迟加载 # 如果设置为\u0026#34;是\u0026#34;, aria2 在启动时不会读取 --input-file 选项设置的文件中的所有 URI 地址, 而是会在之后需要时按需读取. 如果输入文件中包含大量要下载的 URI, 此选项可以减少内存的使用. 如果设置为\u0026#34;否\u0026#34;, aria2 会在启动时读取所有的 URI. 当 -save-session 使用时将会禁用 --deferred-input 选项. #deferred-input=false # 禁用 IPv6 #disable-ipv6=false # 磁盘缓存 # 启用磁盘缓存. 如果设置为 0, 将禁用磁盘缓存. 此功能将下载的数据缓存在内存中, 最多占用此选项设置的字节数. 缓存存储由 aria2 实例创建并对所有下载共享. 由于数据以较大的单位写入并按文件的偏移重新排序, 所以磁盘缓存的一个优点是减少磁盘的 I/O. 如果调用哈希检查时并且数据缓存在内存中时, 将不需要从磁盘中读取. 大小可以包含 K 或 M (1K = 1024, 1M = 1024K). #disk-cache=16M # 下载结果 # 此选项将修改下载结果的格式. 如果设置为\u0026#34;默认\u0026#34;, 将打印 GID, 状态, 平均下载速度和路径/URI. 如果涉及多个文件, 仅打印第一个请求文件的路径/URI, 其余的将被忽略. 如果设置为\u0026#34;完整\u0026#34;, 将打印 GID, 状态, 平均下载速度, 下载进度和路径/URI. 其中, 下载进度和路径/URI 将会每个文件打印一行. 如果设置为\u0026#34;隐藏\u0026#34;, 下载结果将会隐藏. #download-result=default # DSCP # 为 QoS 设置 BT 上行 IP 包的 DSCP 值. 此参数仅设置 IP 包中 TOS 字段的 DSCP 位, 而不是整个字段. 如果您从 /usr/include/netinet/ip.h 得到的值, 需要除以 4 (否则值将不正确, 例如您的 CS1 类将会转为 CS4). 如果您从 RFC, 网络供应商的文档, 维基百科或其他来源采取常用的值, 可以直接使用. #dscp= # 最多打开的文件描述符 # 设置打开的文件描述符的软限制 (soft limit). 此选项仅当满足如下条件时开放: a. 系统支持它 (posix). b. 限制没有超过硬限制 (hard limit). c. 指定的限制比当前的软限制高. 这相当于设置 ulimit, 除了其不能降低限制. 此选项仅当系统支持 rlimit API 时有效. #rlimit-nofile= # 终端输出使用颜色 #enable-color=true # 启用 MMap # 内存中存放映射文件. 当文件空间没有预先分配至, 此选项无效. 参见 --file-allocation. #enable-mmap=false # 事件轮询方法 # 设置事件轮训的方法. 可选的值包括 epoll, kqueue, port, poll 和 select. 对于 epoll, kqueue, port 和 poll, 只有系统支持时才可用. 最新的 Linux 支持 epoll. 各种 *BSD 系统包括 Mac OS X 支持 kqueue. Open Solaris 支持 port. 默认值根据您使用的操作系统不同而不同. #event-poll= # 文件分配方法 # 指定文件分配方法. \u0026#34;无\u0026#34; 不会预先分配文件空间. \u0026#34;prealloc\u0026#34;会在下载开始前预先分配空间. 这将会根据文件的大小需要一定的时间. 如果您使用的是较新的文件系统, 例如 ext4 (带扩展支持), btrfs, xfs 或 NTFS (仅 MinGW 构建), \u0026#34;falloc\u0026#34; 是最好的选择. 其几乎可以瞬间分配大(数 GiB)文件. 不要在旧的文件系统, 例如 ext3 和 FAT32 上使用 falloc, 因为与 prealloc 花费的时间相同, 并且其会阻塞 aria2 知道分配完成. 当您的系统不支持 posix_fallocate(3) 函数时, falloc 可能无法使用. \u0026#34;trunc\u0026#34; 使用 ftruncate(2) 系统调用或平台特定的实现将文件截取到特定的长度. 在多文件的 BitTorrent 下载中, 若某文件与其相邻的文件共享相同的分片时, 则相邻的文件也会被分配. #file-allocation=prealloc file-allocation=falloc # 强制保存 # 即使任务完成或删除时使用 --save-session 选项时也保存该任务. 此选项在这种情况下还会保存控制文件. 此选项可以保存被认为已经完成但正在做种的 BT 任务. #force-save=false # 保存未找到的文件 # 当使用 --save-session 选项时, 即使当任务中的文件不存在时也保存该下载任务. 此选项同时会将这种情况保存到控制文件中. #save-not-found=true # 仅哈希检查 # 如果设置为\u0026#34;是\u0026#34;, 哈希检查完使用 --check-integrity 选项, 根据是否下载完成决定是否终止下载. #hash-check-only=false # 控制台可读输出 # 在控制台输出可读格式的大小和速度 (例如, 1.2Ki, 3.4Mi). #human-readable=true # 保留未完成的任务 # 保留所有未完成的下载结果, 即使超过了 --max-download-result 选项设置的数量. 这将有助于在会话文件中保存所有的未完成的下载 (参考 --save-session 选项). 需要注意的是, 未完成任务的数量没有上限. 如果不希望这样, 请关闭此选项. #keep-unfinished-download-result=true # 最多下载结果 # 设置内存中存储最多的下载结果数量. 下载结果包括已完成/错误/已删除的下载. 下载结果存储在一个先进先出的队列中, 因此其可以存储最多指定的下载结果的数量. 当队列已满且有新的下载结果创建时, 最老的下载结果将从队列的最前部移除, 新的将放在最后. 此选项设置较大的值后如果经过几千次的下载将导致较高的内存消耗. 设置为 0 表示不存储下载结果. 注意, 未完成的下载将始终保存在内存中, 不考虑该选项的设置. 参考 --keep-unfinished-download-result 选项. #max-download-result=1000 # MMap 最大限制 # 设置启用 MMap (参见 --enable-mmap 选项) 最大的文件大小. 文件大小由一个下载任务中所有文件大小的和决定. 例如, 如果一个下载包含 5 个文件, 那么文件大小就是这些文件的总大小. 如果文件大小超过此选项设置的大小时, MMap 将会禁用. #max-mmap-limit=9223372036854775807 # 最大断点续传尝试次数 # 当 --always-resume 选项设置为\u0026#34;否\u0026#34;时, 如果 aria2 检测到有 N 个 URI 不支持断点续传时, 将从头开始下载文件. 如果 N 设置为 0, 当所有 URI 都不支持断点续传时才会从头下载文件. 参见 --always-resume 选项. #max-resume-failure-tries=0 # 最低 TLS 版本 # 指定启用的最低 SSL/TLS 版本. #min-tls-version=TLSv1 # 日志级别 #log-level=debug # 优化并发下载 # 根据可用带宽优化并发下载的数量. aria2 使用之前统计的下载速度通过规则 N = A + B Log10 (速度单位为 Mbps) 得到并发下载的数量. 其中系数 A 和 B 可以在参数中以冒号分隔自定义. 默认值 (A=5, B=25) 可以在 1Mbps 网络上使用通常 5 个并发下载, 在 100Mbps 网络上为 50 个. 并发下载的数量保持在 --max-concurrent-downloads 参数定义的最大之下. #optimize-concurrent-downloads=false # 文件分片大小 # 设置 HTTP/FTP 下载的分配大小. aria2 根据这个边界分割文件. 所有的分割都是这个长度的倍数. 此选项不适用于 BitTorrent 下载. 如果 Metalink 文件中包含分片哈希的结果此选项也不适用. #piece-length=1M # 显示控制台输出 #show-console-readout=true # 下载摘要输出间隔 # 设置下载进度摘要的输出间隔(秒). 设置为 0 禁止输出. #summary-interval=60 # 全局最大下载速度 # 设置全局最大下载速度 (字节/秒). 0 表示不限制. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). #max-overall-download-limit=0 # 最大下载速度 # 设置每个任务的最大下载速度 (字节/秒). 0 表示不限制. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). #max-download-limit=0 # 禁用配置文件 #no-conf= # 文件分配限制 # 不对比此参数设置大小小的分配文件. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). #no-file-allocation-limit=5M # 启用参数化 URI 支持 # 启用参数化 URI 支持. 您可以指定部分的集合: http://{sv1,sv2,sv3}/foo.iso. 同时您也可以使用步进计数器指定数字化的序列: http://host/image[000-100:2].img. 步进计数器可以省略. 如果所有 URI 地址不指向同样的文件, 例如上述第二个示例, 需要使用 -Z 选项. #parameterized-uri=false # 禁用控制台输出 #quiet=false # 实时数据块验证 # 如果提供了数据块的校验和, 将在下载过程中通过校验和验证数据块. #realtime-chunk-checksum=true # 删除控制文件 # 在下载前删除控制文件. 使用 --allow-overwrite=true 选项时, 总是从头开始下载文件. 此选项将有助于使用不支持断点续传代理服务器的用户. #remove-control-file= # 状态保存文件 # 当退出时保存错误及未完成的任务到指定的文件中. 必须用绝对路径 # 您可以在重启 aria2 时使用 --input-file 选项重新加载. 如果您希望输出的内容使用 GZip 压缩, 您可以在文件名后增加 .gz 扩展名. 请注意, 通过 aria2.addTorrent() 和 aria2.addMetalink() RPC 方法添加的下载, 其元数据没有保存到文件的将不会保存. 通过 aria2.remove() 和 aria2.forceRemove() 删除的下载将不会保存. #save-session= save-session=/home/vane/.aria2/aria2.session # 保存状态间隔 # 每隔此选项设置的时间(秒)后会保存错误或未完成的任务到 --save-session 选项指定的文件中. 如果设置为 0, 仅当 aria2 退出时才会保存. #save-session-interval=0 # Socket 接收缓冲区大小 # 设置 Socket 接收缓冲区最大的字节数. 指定为 0 时将禁用此选项. 当使用 SO_RCVBUF 选项调用 setsockopt() 时此选项的值将设置到 Socket 的文件描述符中. #socket-recv-buffer-size=0 # 自动关闭时间 # 在此选项设置的时间(秒)后关闭应用. 如果设置为 0, 此功能将禁用. #stop=0 # 缩短控制台输出内容 # 缩短控制台输出的内容在一行中. #truncate-console-readout=true # 部分事件hook # BT下载完成(如有做种将包含做种，如需调用请务必确定设定完成做种条件) #on-bt-download-complete= # 下载完成 #on-download-complete= # 下载错误 #on-download-error= # 下载暂停 #on-download-pause= # 下载开始 #on-download-start= # 下载停止 #on-download-stop= Aria2 Web 控制台\nAira2 没有软件界面，程序员可以用代码执行任务，但普通用户怎样添加下载任务呢？——打开浏览器，输入网址aria2c.com（YAAW 的中文版）就可以打开 Aria2 Web 控制台。\nJSON-RPC Path 默认为: http://localhost:6800/jsonrpc，如果提示 “Aria2 RPC 服务器错误”，按照以下方法修改：\n 普通情况设置为: http://host:port/jsonrpc  host: 指运行 Aria2 所在机器的 IP 或者名字 port: 使用 --rpc-listen-port 选项设置的端口, 未设置则是 6800；可通过 lsof -i:6800 查看端口是否被占用   使用 --rpc-secret=xxxxxx 选项设置为: http://token:xxxxxx@host:port/jsonrpc 使用 --rpc-user=user --rpc-passwd=pwd 选项设置为: http://user:pwd@host:port/jsonrpc 以上JSON-RPC Path 中的 http 可以用 ws 替代, 代表使用 WebSocket 协议。换用 ws 也可能解决 “Aria2 RPC 服务器错误”。 当使用 https://aria2c.com 访问时, 可能需要使用 https 或 wss 协议。  在 Web UI 中对 Aria2 的设置会在 Aria2 重启后丢失, 必要的设置请写入配置文件。\n已经下载完成的任务会在 Aria2 重启后消失, 除非启用了 --force-save 选项。\nProtocol **HTTP / HTTPS / FTP / SFTP **\n超文本传输协议（HTTP / HTTPS）和 文件传输协议（FTP / SFTP）将文件放到服务器上，然后由服务器传送到不同的用户机器上，称为Client-Server Model简称C/S模式，或者叫一对多模式。\n缺点是：当非常多的用户同时访问和下载服务器上的文件时，由于服务器处理能力和带宽的限制，下载速度会急剧下降，有的用户可能访问不了服务器。\nBitTorrent 协议\nBitTorrent(简称BT)是一个文件分发协议，每个下载者在下载的同时不断向其他下载者上传已下载的数据。BT协议与FTP协议不同，特点是下载的人越多，下载速度越快，原因在于每个下载者将已下载的数据提供给其他下载者下载，充分利用了用户的上载带宽。通过一定的策略保证上传速度越快，下载速度也越快。在很短时间内，BitTorrent协议成为一种新的变革技术。\nBitTorrent 的发展依赖于对等网络 (Peer - to - Peer 简称 P2P)。P2P技术体现了互联网最根本的内涵——自由和免费，它的主要优点如下：\n 对等性高：非中心化，互联网回归本色——联系和传输； 扩展性强：用户扩展与资源、服务、系统同步扩展； 健壮性高：服务分散和自适应，耐攻击、高容错性； 性价比高：P2P成本低、存储和技术能力强； 负载均衡：分布存储和技术，整个网络负载得以均衡。  在P2P网络中，每个参与的节点既是服务器又是客户端，既是信息的提供者又是信息的消费者。P2P信息检索的目的就是网络中的任意节点都可以提交检索的请求，然后这些检索通过相关信息的节点将会回应请求，按照某种路由机制路由到本地相关的内容，以对等的形式直接传送到请求节点上。\n检索过程分为以下几个阶段：每个节点在加入网络的时候，会对存储在本节点上的内容进行索引，以满足本地内容检索的目的。然后按某种预定的规则选择一些节点作为自己的邻居，加入到P2P网络当中。发起者P提出检索请求q，并将q发送给自己的邻居，P的邻居收到q后，再按照某种策略转发给它在网络中的其它邻居节点。这样，q就在整个网络中传播开来。收到请求q的节点如果存储有相应内容信息 , 则将对应的内容返回。\n普通的HTTP/FTP下载使用TCP/IP协议，BitTorrent协议是架构于TCP/IP协议之上的一个P2P文件传输协议，处于TCP/IP结构的应用层。 BitTorrent协议本身也包含了很多具体的内容协议和扩展协议，并在不断扩充中。\n根据BitTorrent协议，文件发布者会根据要发布的文件生成提供一个.torrent文件，即种子文件，也简称为“种子”。\n种子还有如下相关概念：\n 发布BT种子的人，做种多少天指的就是持续多少天不撤种。这期间如果有别人下完了，就叫出种。下完的人可以继续做种。这时发布种子的人就可以不做种了，叫撤种。 一个资源只要有一个人在做种，那就其他人就可以继续下。如果没人做种了，叫断种，这是资源就死了，下不了了。某人长时间一直做种，叫保种。  .torrent文件本质上是文本文件，包含Tracker信息和文件信息两部分。Tracker信息主要是BT下载中需要用到的Tracker服务器的地址和针对Tracker服务器的设置，文件信息是根据对目标文件的计算生成的，计算结果根据BitTorrent协议内的B编码规则进行编码。它的主要原理是需要把提供下载的文件虚拟分成大小相等的块，块大小必须为2k的整数次方（由于是虚拟分块，硬盘上并不产生各个块文件），并把每个块的索引信息和Hash验证码写入种子文件（.torrent）中。所以，种子文件（.torrent）就是被下载文件的“索引”。\n下载者要下载文件内容，需要先得到相应的.torrent文件，然后使用BT客户端软件进行下载。\n下载时，BT客户端首先解析.torrent文件得到Tracker地址，然后连接Tracker服务器。Tracker服务器回应下载者的请求，提供下载者其他下载者（包括发布者）的IP。下载者再连接其他下载者，根据.torrent文件，两者分别对方告知自己已经有的块，然后交换对方没有的数据。此时不需要其他服务器参与，分散了单个线路上的数据流量，因此减轻了服务器负担。\n下载者每得到一个块，需要算出下载块的Hash验证码与.torrent文件中的对比，如果一样则说明块正确，不一样则需要重新下载这个块。这种规定是为了解决下载内容准确性的问题。\n从 BT 客户端角度考虑，下载原理分为以下几步：\n 根据 BitTorrent 协议，文件发布者会根据要发布的文件生成提供一个 .torrent 文件。客户端可从 Web 服务器上下载种子文件，并从中得到 Tracker 服务器 URL。 根据 Tracker URL 与 Tracker 服务器建立连接，并从服务器上得到 Peers 信息。 根据 Peers 信息与一个 Peer 建立连接，依据 Peer wire 协议完成握手，并从 Peer 端下载数据文件。同时监听 Peer 的连接，并给 Peer 上传数据文件。  迅雷，俗称吸血雷：\n 吸血就是指一些客户端在进行P2P下载时，从其它客户端下载的数据量非常多，但是分享给其它客户端的数据非常少，下载完成后立即关机走人的行为 而迅雷就是这样的一个下载器，迅雷的服务器疯狂索取资源，但自己又不上传资源给别人），当收集了大量资源后，进而下载限速，开启付费会员制度  BT下载讲究共享精神，这跟互联网的共享精神一脉相承，所以请不要在BT下载器设置里面限制上传速度。\n鉴于这类自私行为对其它合理使用P2P网络的用户的伤害，现在的很多P2P软件都加入反吸血功能。就是说检测到特定用户的吸血行为或者吸血软件时自动对这些用户降权处理，简单来说就是你的上传速度低的话，你的下载速度也不会特别快。\n这里又要多嘴一句\n 迅雷靠着自身在国内多年的发展，服务器里囤积了大量资源，所以很多其他BT下载器下载不动的资源，可能只有迅雷下载的动（因为它原来从别人那里下载了后存在了它的服务器上） 同理，很多文件可能只有115才能能离线下载，也是因为当年的115就存储了大量的资源在它服务器上 这里顺便可以说一下，所谓的百度云秒离线功能，不过是在你离线下载之前，已经有人把这个文件离线下载到百度云服务器中了  BT下载带来的好处\n 快。减少了网路传输节点。 减轻服务器压力。如果某公司有新版本软件推出（如LOL游戏更新时），服务器必定会人山人海，而使用BT能大大减轻服务器的负担，节约服务器的购置成本。 保护隐私。与有http那种中央服务器的网络系统不同，BT下载节点能遍布整个互联网（每个人都是分享者与下载者），给包括开发者在内的任何人、组织、或政府带来监控难题。  坏处当然也有，从上面第3点不难得出，BT下载很容易导致一个问题：盗版泛滥——海盗湾。\n上面说过了，想加入BT下载的无中心网络，首先需要找Tracker服务器问路，于是Tracker服务器成为了版权组织打击的重点，他们的想法很明确，只要除掉了Tracker，BT下载就完了。\n然而魔高一尺道高一丈，需求带动发展，这反而促使了BT技术的一次大升级，这带来了磁力链接。\nMagNet 协议\nMagNet协议，也就是磁力链接，简称磁链。 Magnet不需要Tracker服务器，也不需要.torrent文件，仅需要一串字符就可以进行文件下载。\n磁力链接基于的是DHT网络技术，因此可以在无固定Tracker服务器的情况下下载，实际过程是把所有下载者都变成一个小型Tracker服务。\nDHT技术：2002年，纽约大学的两个教授Petar Maymounkov和David Mazières发表了一篇论文，提出了一种真正去中心化的“点对点”下载模型，他们将其称为Kademlia方法。2005年，BT软件开始引入这种技术，在BT中被称为DHT协议（Distributed Hash Table，分布式哈希表）。\nDHT是一种分布式存储方法。DHT的作用是找到那些与本机正在下载（上传）相同文件的对端主机（Peer），当然，实现这一过程并不依赖Tracker服务器。在DHT网络中的每个客户端负责一个小范围的路由，并负责存储一小部分数据，从而实现整个DHT网络的寻址和存储。这种信息获取方式保证了整个网络没有单个的中心，即使一个节点下线，依然可以通过其他节点来获取文件，因此也就不需要Tracker服务器来告诉你，其他节点在什么地方。\nPEX：是Peer Exchange的简写，我们可以将其理解为“节点信息交换”。虽然DHT解决了去中心化的问题，但要在没有“中心协调员”（Tracker）的情况下实现高效寻址，就要借助PEX。PEX所提供的功能有点类似于以前的Tracker服务器，但工作方式却非常不同，我们可以打个比方来说明：\n 当你得到一个磁力链接并进行下载时，使用比如迅雷，迅雷就会实例化出一个DHT节点，加入DHT网络 把DHT网络比作一个朋友圈子，当你被A带进这个朋友圈，此刻你就只认识A而已 但是你的目的是想找唐纳德·特朗普（川普）总统，所以你就问A要川普的联系方式，但是A也没有川普的联系方式， 他介绍了一个美国朋友B给你认识 于是你去问B要川普的联系方式，B其实也没有川普的联系方式，但是B认识一个美国州长C 于是你又得到了C的联系方式，C把川普的联系方式告诉你之后，你就可以写信或者致电给川普了  这里相关的有个有趣的理论「六度分隔理论」（也叫六度空间理论）：简单来说，就是最多通过6个中间人你就能够认识世界上任何一个陌生人。\nMagnet links（磁力链接）示例：\nmagnet:?xt=urn:btih:36684b463ca2aa2f9347b18e9f6b1a9090bdb073\u0026amp;dn=Microsoft+iSCSI+Initiator  magnet：协议名。 xt：exact topic的缩写，表示资源定位点。BTIH（BitTorrent Info Hash）表示哈希方法名，这里还可以使用SHA1和MD5。这个值是文件的标识符，是不可缺少的。 dn：display name的缩写，表示向用户显示的文件名。这是一个可选项。 tr：tracker的缩写，表示tracker服务器的地址。这是一个可选项，本例中并未出现。  可能看出了DHT+PEX+Magnet Link模式中的一个问题——BT客户端的“第一步是如何迈出的”，套用在介绍PEX时使用的例子，那就是你怎怎么进入A的这个朋友圈的（即DHT节点如何进入DHT网络）？这确实是个问题。解决这个问题依然需要一台服务器（bootstrap node），不过这台服务器所起的作用与Tracker不同，它仅负责接纳DHT节点如何进入DHT网络，当DHT节点与其它DHT节点“搭上了话”，之后这台服务器就没有什么用处了。bootstrap node可以是不同BT客户端厂商独立运营的，也可以是几家联合共用，总之，它是分散的，只要在客户端软件中内置一张表单，那客户端就将有非常多的入口可供选择。\neD2k 协议\nBT / 磁力 / eD2k都是P2P技术 。eD2k链接对应的客户端，如eMule电骡是共享软件，而Magnet磁链对应的BT软件则是下载软件。这让它们在使用上，有着很多根本性的区别：\n BT使用的时候，只要你不下载东西你就不会上传 eMule电骡不同，比如，开启eMule电骡后，第一件事做的并不是什么下载，而是设置共享目录，该目录中的所有文件，都会实时共享到eD2k网络和KAD网络中。 目录中共享了的文件都会生成eD2k链接，所有人通过相应的eD2k链接，都能够拿到你共享的文件，一旦有人下载相应文件，那么你的eMule客户端就会上传数据，换言之，你想下载别人的文件，需要别人开着eMule客户端 我们平时使用eD2k链接下载，资源也是来自他人eMule所共享的文件的。当然，共享目录中也可以啥都不放，但很多eMule客户端都拥有队列优先级机制，上传得少，下载速度也会被限制。  电驴可以说是进化版的BT，用户不需要下载什么种子文件了，直接在“电驴”软件上输入eD2k开头的一长串代码一样的链接，就能下载。\n电驴以及后来的电骡、VERYCD电驴还有各种类似的软件，采用的eD2k网络仍是基于服务器的，你需要连接到服务器并从服务器索引 / 查找用户或者文件\n重要的是电驴提供的其中一种模式——KAD网络（类似磁力下载中的DHT网络），能够脱离中央服务器，直接实现网络来用户之间的点对点传输\n历史证明，这个脱离中央服务器的革新，真的十分十分的重要——这是电驴软件在面对盗版问题时，能够生存下来的主要原因，因为他们可以说，那是用户之间的自发传输行为，没有经过服务器\n但是，尽管电驴做了如此多的革新，但还是逃不过被时代淘汰的命运，客户端对于大部分人来说配置起来十分复杂，愿意一直开着服务器上传资源的人越来越少，更多人只想单纯的索取（类似上文提到的迅雷吸血行为），如今使用eD2k分享资源的人实在算少数，远不如磁力下载。\nOthers AriaNg\nAriaNg 是一个让 aria2 更容易使用的现代 Web 前端\n 使用很简单，将文件下载解压即可，可以本地打开 index.html 文件，也可上传到服务器。 如果您懒得部署 AriaNg ，可以直接访问现成的 http://a2.ssss.fun 。 打开后需要配置 AriaNg，打开 AriaNg 设置 - RPC，修改 Aria2 RPC 地址 和 Aria2 RPC 密钥 ，点击 重新加载 AriaNg 即可。  WebUI-Aria2\n这个项目的目标是创建世界上最好和最热门的界面来与 aria2 交互。\n使用非常简单，只需在任何网络浏览器中下载并打开 index.html。\nAria2 for \u0026hellip;.\n比如 YAAW for Chrome、Aria2 for Chrome 、Aria2 for Edge 之类的。\n在浏览器中直接内置一个 AriaNg，用于直接管理 Aria2。\nUsing Aria2 as a Daemon\n运行 gnome-session-properties打开应用程序首选项管理，添加：\n Name: Aria2 Daemon Command: /usr/bin/aria2c --conf-path=/home/vane/.aria2/aria2.conf -D  会建立 .config/autostart/aria2c.desktop\n[Desktop Entry] Type=Application Exec=/usr/bin/aria2c --conf-path=/home/vane/.aria2/aria2.conf -D Hidden=false NoDisplay=false X-GNOME-Autostart-enabled=true Name[en_US]=Aria2 Daemon Name=Aria2 Daemon Comment[en_US]= Comment= BT 下载预热\n是这样滴，和很多BT客户端一样，Aria2有个dht.dat文件(开启ipv6还有个dht6.dat)，这玩意用于存储一种叫做DHT Routing Table的东西，DHT网络由无数节点组成，你接触到一个后能通过它接触到更多的节点，Aria2我记得是有内置的节点，但是！如果你在Aria2第一次运行的时候直接下载磁力链接或者冷门种子，你很可能遇到连MetaData都无法获取的情况，这就是因为第一次只是初始化dht.dat文件，你本地不存在DHT Routing Table的缓存，所以你无法从DHT网络中获取足够的数据。\n那么怎么办？我的建议是，找个热门种子(千万建议是种子，而不是磁力链接)，然后下一波，挂着做种，过几个小时后退出Aria2，或者等Aria2会话自动保存，你会发现dht.dat从空文件变成有数据了，这时候你下载就会正常很多。\n什么是PT，PT和BT有什么不同？\n答：PT（Private Tracker）下载其实也是Bt下载的一种，但有两个明显的改进：一是私密的小范围下载，二是进行流量统计，根据上载量决定你的权限。\nBT下载时，软件会分析.torrent种子文件得到Tracker地址，然后连接Tracker服务器，服务器返回其他下载者的IP，下载者再与这些IP联系进行下载，从而减轻了服务器的负担，BT下载的Tracker是公开的，而Private Tracker 下载(PT下载)的Tracker则是私有的，每个人的Tracker是不同的，即passkey不同，passkey对PT下载者很重要，所以不要轻易泄露出去。\n其实和通常BT相比，PT就是多了一个passkey验证，这样就能保证未注册的用户不能下载。所以passkey很重要，一旦发现有问题，就要到站点上去重置passkey。Tracker Server根据passkey把BT客户端上传量和下载量进行计算，从而算出分享率(上传量/下载量)。如果分享率太小，将会被删除帐号，从而不能下载。\n这样Private Tracker 下载(PT下载)是一种小范围的BT下载，通过禁用DHT有要求地选择并控制用户数量，这样，在有限的范围内，下载的用户基本上都可以达到自己的宽带上限，Private Tracker 下载(PT下载)下载还通过论坛等方式的约束机制将BT下载的理念现实化，真正让用户做到下载的过程中努力上传。因此，Private Tracker 下载(PT下载)的速度很快，能够让用户款待得到最大程度的使用。\nPT通过对做种时间和流量的要求在一定程度上避免了BT中存在的下完不做种的现象，因此在网络上，尤其是需要大文件（如高清）资源交换的时候广受欢迎，在PT站里，“水管”代表上传带宽的大小，大水管可以通过快速的上传获得积分，PT站点也会采取措施（比如做种时间，优惠等）使上传较慢的小水管能够参与贡献和共享资源。\nRPC\n首先了解什么叫RPC，为什么要RPC，RPC是指远程过程调用，也就是说两台服务器A，B，一个应用部署在A服务器上，想要调用B服务器上应用提供的函数/方法，由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义和传达调用的数据。\n比如说，一个方法可能是这样定义的：\nEmployee getEmployeeByName(String fullName) 那么：\n 首先，要解决通讯的问题，主要是通过在客户端和服务器之间建立TCP连接，远程过程调用的所有交换的数据都在这个连接里传输。连接可以是按需连接，调用结束后就断掉，也可以是长连接，多个远程过程调用共享同一个连接。 第二，要解决寻址的问题，也就是说，A服务器上的应用怎么告诉底层的RPC框架，如何连接到B服务器（如主机或IP地址）以及特定的端口，方法的名称名称是什么，这样才能完成调用。比如基于Web服务协议栈的RPC，就要提供一个endpoint URI，或者是从UDDI服务上查找。如果是RMI调用的话，还需要一个RMI Registry来注册服务的地址。 第三，当A服务器上的应用发起远程过程调用时，方法的参数需要通过底层的网络协议如TCP传递到B服务器，由于网络协议是基于二进制的，内存中的参数的值要序列化成二进制的形式，也就是序列化（Serialize）或编组（marshal），通过寻址和传输将序列化的二进制发送给B服务器。 第四，B服务器收到请求后，需要对参数进行反序列化（序列化的逆操作），恢复为内存中的表达方式，然后找到对应的方法（寻址的一部分）进行本地调用，然后得到返回值。 第五，返回值还要发送回服务器A上的应用，也要经过序列化的方式发送，服务器A接到后，再反序列化，恢复为内存中的表达方式，交给A服务器上的应用  为什么RPC呢？就是无法在一个进程内，甚至一个计算机内通过本地调用的方式完成的需求，比如比如不同的系统间的通讯，甚至不同的组织间的通讯。由于计算能力需要横向扩展，需要在多台机器组成的集群上部署应用，\nRPC的协议有很多，比如最早的CORBA，Java RMI，Web Service的RPC风格，Hessian，Thrift，甚至Rest API。\n其他下载工具\n qBittorrent Transmission rTorrent Deluge  youtube-dl youtube-dl 是一个命令行程序，用于从 YouTube.com 和更多其他网站下载视频。 基于 Python 实现，不限于特定平台。\n# 安装 $ pip install -i https://pypi.tuna.tsinghua.edu.cn/simple youtube-dl # 使用 $ youtube-dl [OPTIONS] URL [URL...] 当前版本（2021.06.06）不能下载哔哩哔哩播放列表，可以用类似软件如 you-get， annie 代替。\nUsage 下载视频或整个视频播放列表\n 要从 Youtube 下载视频或整个视频播放列表，只需直接使用 URL 即可：youtube-dl [url]。程序自动选择一个最清晰的格式下载。 如果要指定视频下载之后的名称，可以使用如下方式：youtube-dl -o '名称' [url]。 还可以在下载视频时附加更多详细信息，可用的参数有标题、上传者名称（频道名称）和视频上传日期等：youtube-dl -o '%(title)s by %(uploader)s on %(upload_date)s in %(playlist)s.%(ext)s' [ul]。  查看视频的所有类型，只看不下载\n命令：youtube-dl -F [url]或者youtube-dl --list-formats [url]。 这是一个列清单参数，执行后并不会下载视频，但能知道这个目标视频都有哪些格式存在，以便有选择的下载。\n下载指定质量的视频和音频并自动合并\n下载最佳/最差质量的音/视频文件：\n默认情况下，youtube-dl将自主选择最佳质量的视频下载。 但是，也可以以特定的质量或格式来下载视频或播放列表\nYoutube-dl 支持以下品质：\n best选择最佳质量的音/视频文件 worst选择质量最差的格式（视频和音频） bestvideo选择最佳质量的仅视频格式（例如DASH视频），可能无法使用。 worstvideo选择质量最差的纯视频格式，可能无法使用。 bestaudio选择最优质的音频格式，可能无法使用。 worstaudio选择质量最差的音频格式，可能无法使用。  例如，如果要自动选择并下载最佳质量格式（音频和视频），只需使用以下命令：youtube-dl -f best [url]。\n您还可以组合使用以下不同的格式选项：youtube-dl -f bestvideo+bestaudio [ul]。该命令将分别下载最高质量的仅视频和最高质量的纯音频格式，再用ffmpeg或avconv合并成一个最佳质量的mkv文件；如果您不想合并，请将+（加号）替换为,（逗号）即可分别得到最高质量的音频和视频（两个文件）：youtube-dl -f 'bestvideo,bestaudio' [url]。\n 下载指定质量的音/视频文件：\n-F 获取的所有视频格式的清单，最左边一列就是编号对应着不同的格式。由于YouTube的1080p及以上的分辨率都是音视频分离的，所以我们需要分别下载视频和音频，可以使用137+140这样的组合。如果系统中安装了ffmpeg的话，youtube-dl 会自动合并下好的视频和音频，然后自动删除单独的音视频文件：youtube-dl -f [format code] [url]。\n从播放列表下载视频时，某些视频可能没有相同的格式。 在这种情况下，可以按首选顺序指定多个格式代码，例如：命令youtube-dl -f 22/17/18 \u0026lt;playlist_url\u0026gt;将以格式 22 下载视频（如果可用）；如果格式 22不可用，则它将下载格式 17（如果可用）；如果格式 22 和 17 都不可用，最后尝试下载格式 18。如果所有格式代码都不匹配，Youtube-dl 会报出提示。还需要注意的是，斜杠是左关联的，即最左侧的格式代码是首选。\n下载字幕\n youtube-dl --write-sub [url]这样会下载一个vtt格式的英文字幕和mkv格式的1080p视频下来 youtube-dl --write-sub --skip-download [url]下载单独的vtt字幕文件,而不会下载视频 youtube-dl --write-sub --all-subs [url]下载所有语言的字幕(如果有的话) youtube-dl --write-auto-sub [url]下载自动生成的字幕(YouTube only)  下载多个视频\n youtube-dl \u0026lt;url1\u0026gt; \u0026lt;url2\u0026gt;有时我们需要一次下载多个不同的视频，此时我们只需用空格将多个URL分隔开即可。 youtube-dl -a url.txt也可以将要下载视频的URL全部放在文本文件中，并将其作为参数传递给youtube-dl。此命令将下载url.txt文件中所有URL指向的视频。  只下载（视频中的）音频\n youtube-dl -x [url]仅从视频网站下载其音频。 youtube-dl -x --audio-format mp3 [ul]默认情况下，youtube-dl 将以Ogg （opus）格式保存音频。此命令将从给定的视频/播放列表下载音频，将其转换为 MP3 并将其保存在当前目录中。应注意：您应该安装 ffmpeg 或 avconv 将文件转换为 mp3 格式。  下载带有描述、元数据、注释、字幕和缩略图的视频\n要下载视频及其他详细信息，如：说明、元数据、注释、字幕和缩略图等，请使用以下命令： youtube-dl --write-description --write-info-json --write-annotations --write-sub --write-thumbnail [url]\n通过文件扩展名下载音/视频\n 以您的首选格式下载视频，例如 MP4，只需执行：youtube-dl --format mp4 [url]或者youtube-dl -f mp4 [url]。 某些视频可能无法以您的首选格式提供。 在这种情况下，youtube-dl 将下载其他最佳可用格式。例如： youtube-dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best' [ul] 此命令将下载最佳质量的MP4格式文件。如果 MP4 格式不可用，则它将下载其他最佳可用格式。  限制下载视频的大小\n从YouTube播放列表下载多个视频时，您可能只想下载特定大小的视频。例如：\n 此命令不会下载任何小于指定大小（例如100MB）的视频：youtube-dl --min-filesize 100M \u0026lt;playlist_url\u0026gt;。 如果您不想下载大于给定大小的视频，可以这样：youtube-dl --max-filesize 100M \u0026lt;playlist_url\u0026gt;。  我们还可以用组合格式，选择运算符来下载特定大小的视频。例如：\n 以下命令将下载最佳视频格式但不大于 100MB 的视频：youtube-dl -f 'best[filesize\u0026lt;100M]' [url]。  按日期下载视频\nYoutube-dl 允许我们按照上传日期来筛选和下载视频或播放列表，例如：\n 要下载 2019 年 8 月 1 日上传的视频，可以使用：youtube-dl --date 20190801 [URL]； 下载在特定日期或之前上传的视频：youtube-dl --datebefore 20190801 [URL]； 下载在特定日期或之后上传的视频：youtube-dl --dateafter 20190101 [URL]； 仅下载过去 6 个月内上传的视频：youtube-dl --dateafter now-6months [URL]； 下载特定时间段内（例如 2018 年 1 月 1 日至 2019 年 1 月 1 日）上传的视频：youtube-dl --dateafter 20180101 --datebefore 20190101 [URL]。  从播放列表下载特定的视频\n从播放列表下载特定的视频，是youtube-dl 的另一个非常有用的功能。例如：\n 要从播放列表下载第 10 个文件，可使用：youtube-dl --playlist-items 10 [playlist_url]； 要下载多个指定的文件，只需用逗号分隔：youtube-dl --playlist-items 2,3,7,10 [playlist_url]；  也可以按序号来指定要下载范围，例如：\n 从第 10 个开始，直接下载完整个列表：youtube-dl --playlist-start 10 [playlist_url]； 在播放列表中仅下载从第 2 到第 5 的文件：youtube-dl --playlist-start 2 --playlist-end 5 [playlist_url]。  Configuration 在 Linux 和 macOS 上，系统配置文件位于 /etc/youtube-dl.conf，用户配置文件位于 ~/.config/youtube-dl/config。\n# Continue on download errors, for example to skip unavailable videos in a playlist --ignore-errors # Time to wait before giving up, in seconds --socket-timeout 10 # Download only videos not listed in the archive file. Record the IDs of all downloaded videos in it. #--download-archive /path/archive.txt # Number of retries (default is 10), or \u0026#34;infinite\u0026#34;. --retries infinite # Give these arguments to the external downloader --external-downloader aria2c --external-downloader-args \u0026#34;--no-conf -c\u0026#34; # Output filename template, see the \u0026#34;OUTPUT TEMPLATE\u0026#34; for all the info -o \u0026#39;~/Videos/%(id)s.%(ext)s\u0026#39; # Write thumbnail image to disk #--write-thumbnail # download best 30hz mp4 file , h264+aac ,use http or https protocol,because we can use aria2c downloader to have a faster speed --format \u0026#39;(bestvideo[ext=mp4][fps\u0026lt;31]+bestaudio[ext=m4a]/best[ext=mp4]/bestvideo+bestaudio/best)[protocol^=http]\u0026#39; # Embed thumbnail in the audio as cover art #--embed-thumbnail # Write metadata to the video file --add-metadata MPV MPV 是一个基于 MPlayer 和 mplayer2 的开源极简全能播放器。支持各种视频格式、音频解码、支持特效字幕（电影动漫的ass特效字幕都没啥问题），不仅支持本地播放，同样支持网络播放（mpv 集成了 youtube-dl）。重点是 MPV 具有多系统平台支持、命令行、自定义、GPU 解码、脚本支持等特点……\nOSC 界面 由于默认情况下，MPV 播放器简约到连 GUI 界面都没有提供，因此需要通过命令行或配置文件设置。\n虽然 MPV 并没有提供官方的 GUI 界面，没有菜单，但它提供 OSC 操作界面和快捷键用于操作，只要关联好文件格式，使用 mpv 打开视频后，使用上其实也非常的简单方便。\n快捷键 操作主要通过键盘快捷键（区分大小写）调整。下面介绍一些常用的 mpv 快捷键（更多的快捷键请阅读官方参考手册）。\n鼠标操作\n   快捷键 作用说明     鼠标左键双击 进入/退出全屏   鼠标右键单击 暂停/继续播放   鼠标滚轮 快进/快退    播放控制\n   快捷键  作用说明     p Space 暂停、继续播放   / * 减少/增加音量   9 0 减少/增加音量（数字键盘区的9、0不可用）   m  静音   ← → 快退/快进5秒   ↑ ↓ 快进/快退1分钟   \u0026lt; \u0026gt; 上一个/下一个（播放列表中）   Enter  下一个（播放列表中）   l  设定/清除 A-B循环点   L  循环播放   s  截屏   q  停止播放并退出   Q  保存当前播放进度并退出，播放同样文件从上次保存进度继续播放。    视频控制\n   快捷键 作用说明     _(下划线) 循环切换可用视频轨   A 循环切换视频画面比例   Alt+0 0.5倍源视频画面大小   Alt+1 1倍源视频画面大小   Alt+2 2倍源视频画面大小    音频控制\n   快捷键  作用说明     #  循环切换可用音频轨   Ctrl + Ctrl - 音轨延迟+/- 0.1秒    字幕控制\n   快捷键  作用说明     V  关闭/开启字幕   j J 循环切换可用字幕轨   x z 字幕延迟 +/- 0.1秒   r t 上移/下移字幕位置    窗口控制\n   快捷键 作用说明     T 窗口始终置顶   f 进入/退出全屏   ESC 退出全屏    配置 因为mpv本身不具有图形化前端，绝大多数的设置选项都是靠在主设置文件 ~/.config/mpv/mpv.conf 中输入参数实现的。\n## 部分选项之间有关联作用，MPV读取参数时由上往下读，所以注意书写通用参数的顺序，可查看手册[02]的顺序逻辑部分的错误示范 ## 基础 ## # 视频硬件解码API选择 # 因系统环境、显卡、驱动等差异硬件解码API方式（阅读官方参考手册查询）各有不同，建议实际测试验证后再填入可用API。 # 默认值为 no（使用软件解码），auto 为自动。 hwdec=auto # 尽可能所有格式先尝试上面指定视频硬件解码API #hwdec-codecs=all  # 输出log， # ~~/ 意思是 mpv config dir(for example ~/.config/mpv/) log-file=\u0026#34;~~/mpv.log\u0026#34; ## 功能 ## # --fs 等效 --fullscreen。运行MPV自动进入全屏 #fs=yes  # 默认为系统原生窗口界面，启用此项使用无边框界面 #border=no # 窗口置顶 #ontop=yes  # 窗口模式下最大占屏幕的百分比 # 例如在FHD屏上打开4k视频初始窗口过大 #autofit-larger=80%x80%  # 窗口模式下最小占屏幕的百分比 # 例如在4k屏上打开720p视频初始窗口过小 #autofit-smaller=50%x50%  # 默认yes，默认情况下MPV的窗口比例锁定为视频比例。启用此项以实现窗口自由拉伸行为 # 当 keepaspect=yes 时四周填充黑边 # keepaspect-window=no  # 以暂停状态启动播放器 #pause=yes  # 始终循环播放当前文件\u0026lt;N|inf|no\u0026gt; #loop=inf  # 播放列表循环\u0026lt;N|inf|force|no\u0026gt; #loop-playlist=no  # 默认情况下播完列表所有文件MPV自动关闭，设置为 yes 所有播放完毕不退出，设置为 always 可以实现类似“每个文件播完都暂停”的效果\u0026lt;yes|默认no|always\u0026gt;  keep-open=yes # 退出时记住播放状态。缓存目录默认在设置文件夹中的 \u0026#34;watch_later\u0026#34; save-position-on-quit=yes # 播放网络视频时的向后缓存大小（KiB或MiB） demuxer-max-bytes=20MiB ## OSD ## ## OSD 即 On-Screen-Display ，通常为屏幕上弹出显示的信息。  ## OSC 即 on-screen-controller ，MPV中指的是简易操控界面 # \u0026lt;no,bar,msg,msg-bar\u0026gt; 在跳转时间轴时显示的信息类型 osd-on-seek=msg-bar # 更改OSD字体大小（全局，影响多个功能显示的文本）（默认值：55） #osd-font-size=40  # 以秒为单位显示OSD时间（毫秒精度），有助于查看视频帧的确切时间戳 osd-fractions=yes # 开始播放时短暂显示的信息：文件名 osd-playing-msg=\u0026#34;${filename}\u0026#34; # 设置OSD文本信息的持续时间（毫秒）（默认值：1000） osd-duration=2000 ## 音频 ## # 最大音量。默认值130（130的响度约为100的两倍）\u0026lt;100.0-1000.0\u0026gt; volume-max=120 # 播放器启动音量。0为静音，默认100 #volume=100  # 自动加载同名外挂音轨（fuzzy为模糊名，exact为精确名）\u0026lt;默认no|exact|fuzzy|all\u0026gt;  audio-file-auto=fuzzy ## 视频 ## # 如果做过专业校色应开启（系统目录存在对应的icm校色文档）。未做校色的广色域屏应手动指定 --target-prim=\u0026lt;value\u0026gt; #icc-profile-auto=yes  ## 脚本 滤镜 着色器 ## ## 内置脚本开关（如果没有必要的目的，那就不要屏蔽mpv内建的功能 # 控制台 #load-osd-console=no # 统计信息 #load-stats-overlay=no  ## 字幕 ## # 自动加载当前播放文件的同名外挂字幕 sub-auto=fuzzy # 在指定的额外目录中寻找匹配的字幕，支持相对和绝对路径。 # 示例即自动搜索当前文件路径下名为\u0026#34;sub\u0026#34;,\u0026#34;subtitles\u0026#34;,\u0026#34;字幕\u0026#34;和C盘的\u0026#34;字幕库\u0026#34;文件夹内 #sub-file-paths=sub;subtitles;字幕;C:/字幕库 # 字幕首选语言为中文，但MPV优先加载外挂轨道，此项参数可能实际用处不大 slang=chs,sc,zh,chi,zho # 在插值和颜色管理之前，将字幕混合到视频帧上\u0026lt;yes|video|默认no\u0026gt;。值video类似于yes，但是以视频的原始分辨率绘制字幕，并与视频一起缩放 # 启用此功能会将字幕限制在视频的可见部分（不能出现在视频下方的黑色空白处） # 还会让字幕受 --icc-profile --target-prim --target-trc --interpolation --gamma-factor --glsl-shaders 的影响 # 与 --interpolation 一起使用时，可提高字幕渲染性能  #blend-subtitles=video  # [当 --blend-subtitles=yes/video 时无效] 使ASS字幕尽可能输出在黑边上 sub-ass-force-margins=yes ## 截图 ## ## 以下预设参数只是为了截取最高质量的图片（高质量截图处理效率较低） # \u0026lt;默认 jpg|png|webp\u0026gt; screenshot-format=png # JPEG的最高质量，默认为90\u0026lt;0-100\u0026gt;  #screenshot-jpeg-quality=100  # 用与源视频相同的色度半采样写入JPEG，默认yes #screenshot-jpeg-source-chroma=yes  # PNG压缩等级，过高的等级影响性能，默认为7\u0026lt;0-9\u0026gt;  #screenshot-png-compression=5  # PNG的压缩过滤器。默认5即可实现最佳压缩率\u0026lt;0-5\u0026gt;  #screenshot-png-filter=5  # 使用适当的色彩空间标记屏幕截图（并非所有格式受支持）默认no #screenshot-tag-colorspace=yes  # 主要影响PNG，尽可能使用和视频输出时相同的位深，默认yes #screenshot-high-bit-depth=yes # 若直接在模板中设置路径，此时无需 --screenshot-directory screenshot-template=\u0026#34;MPV-%P-N%n\u0026#34; # 截屏文件保存路径 # ~/ 意思是 user home directory root (similar to shell, $HOME) screenshot-directory=\u0026#34;~/Pictures\u0026#34; Google Keep Now I am using Google Keep.\nGoogle Keep键盘快捷键\n   hortcut Action     J/K Next/previous note   Shift + J/K Move note to next/previous position   N/P Next/previous list item   Shift + N/P Move list item to next/previous position   C New note   L New list   / Search   Ctrl + A Select all   E Archive   # Delete   F Pin/unpin   X Select   Ctrl + G Toggle list and grid view   Esc Close editor   Ctrl + Shift + 8 Toggle checkboxes   Ctrl + ] / [ Indent/dedent list item   ? Open shortcut list   @ Send feedback    Joplin+Typora+OneDrive Joplin $ wget -O - https://raw.githubusercontent.com/laurent22/joplin/dev/Joplin_install_and_update.sh | bash Typora 安装：\n# sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys BA300B7755AFCFAE $ wget -qO - https://typora.io/linux/public-key.asc | $ sudo apt-key add - # add Typora\u0026#39;s repository $ sudo add-apt-repository \u0026#39;deb https://typora.io/linux ./\u0026#39; $ sudo apt-get update # install typora $ sudo apt-get install typora 如果安装的时二进制包，则建立 typora.desktop\n$ vi ~/.local/share/applications/typora.desktop [Desktop Entry] Version=1.0 Type=Application StartupNotify=true Terminal=false Name=Typora GenericName=Markdown Editor Comment=A minimal Markdown reading and writing app Categories=Office;WordProcessor; MimeType=text/markdown;text/x-markdown; Icon=/home/vane/.typora/typora.png Exec=/home/vane/.typora/bin/Typora %U typora 有时会出现丢数据的现象，很困扰；特别是围栏代码块，失去了缩进，成了一行，完全不可阅读了。但是其他的 Markdown Editor 用的不习惯，例如 VSCode、Sublime、ghostwriter、marktext。因此最好通过 ppa 安装，获取 Typora 最新的版本。\n在Joplin下，菜单Tools-\u0026gt;Options-\u0026gt;General\u0026gt;Text editor command可以设置第三方编辑软件。\n配置 File \u0026gt; Preferences：\n General \u0026gt; Auto Save: on Editor \u0026gt; Spell Check: Disable Image \u0026gt; Use relative path if possible: on Markdown \u0026gt; Syntax Support \u0026gt; Inline Math: on  VSCode 中国国内下载 VSCode 速度慢问题解决：使用 azure 中国 cdn 镜像地址加速下载 VSCode\n将默认下载地址\nhttps://az764295.vo.msecnd.net/stable/ 替换为 vscode.cdn.azure.cn\nhttps://vscode.cdn.azure.cn/stable/ Telegram 先通过手机登录，再在电脑端登录。电脑先登录，手机老是收不到验证码。\n简介   Telegram —— 中文名又称\u0026quot;电报\u0026quot;，或简称\u0026quot;TG\u0026quot;。\n  Telegram 是跨平台的即时通信软件，其客户端是自由及开放源代码软件，但服务器是专有软件。\n  Telegram 在中国大陆境内无法直接连接，注册和使用都需要科学上网，请自备节点和工具。\n  下载：Telegram 有官方版和第三方版本，但出于安全和隐私的考虑，推荐大家使用 Telegram 官方版客户端\n  推荐设置  Privacy and Security  Phone Number  谁能看见我的手机号码：Nobody 谁能通过手机号码找到我：My Contacts   Forwarded Messages：Nobody Calls：Nobody Groups：My Contacts   Local Passcode：本地密码只是本设备打开 Telegram 的应用密码 Two-Step Verification：为了账号安全，强烈推荐您设置两步验证密码。 Delete my account：推荐您设置为一年  隐私保护注意事项  资料设置  昵称及用户名：避免使用与其他社交平台相同或相似的昵称及用户名 手机号码：在\u0026quot;设置——隐私——电话号码\u0026quot;中设置\u0026quot;不允许任何人查看我的手机号码\u0026quot;和\u0026quot;仅允许联系人通过手机号码找到我\u0026quot;。   群组聊天：Telegram 的群聊是\u0026quot;不安全\u0026quot;的。 公开群组的所有聊天内容都可被其他人查看，即使他人并未注册 Telegram； 对于群组内的机器人，它们可以收集群组内的绝大部分消息。 媒体文件：在分享照片时，请注意使用专业修图软件打码处理关键信息，并清除照片包含的地理位置信息 分享链接：从其他平台分享内容至 Telegram 时，请注意清除分享链接中的用户 UserID 识别信息，他人完全有可能从您的分享链接中获取您的用户信息。 第三方客户端：如无特殊需要，请使用官方 Telegram 客户端。第三方客户端有能力获取和控制您的账户，读取您全部的聊天记录，收集您设备的可识别信息，包括但不限于：手机号、设备型号、IMEI码、MAC码等。  常见问题及解答  无法给他人发送私聊：“Sorry, you can only send messages to mutual contacts at the momet.”  @SpamBot But I can\u0026rsquo;t message non-contacts！ No，I\u0026rsquo;ll never do any of this   群组和频道有什么类型？有什么特点？  群组(Group)或者频道(Channel)有两种类型。  一种是公开群组(Public Group/Channel) 一种是私有群组(Private Group/Channel)   公开群组(Public Group/Channel) 有自定义设置的ID，所有人可以通过搜索功能，输入id查询到相应的群组。公开群组的历史消息对所有人可见，即使没加入公开群组，也可以查看群组历史消息。 私有群组(Private Group/Channel) 没有自定义的ID，要加入只能通过点击邀请链接或者被邀请入群， 在私有群组，群主可以设定历史消息的可见性。而对于没有加入群组的人，则不可以查看群组的消息。   Telegram 用户名是什么？  其他用户可以通过用户名找到您，您将出现在“全局结果”下的联系人搜索中。这样人们就可以在不知道您的电话号码的情况下通过 Telegram 与您联系。 由于用户名的唯一性，可以防止他人盗用你的头像和昵称冒充你。   如何添加联系人？：添加和删除联系人都是单向操作，对方设备并不会同步。 添加非手机号码联系人后，对方能知道自己的手机号码吗？：如果想取消分享你的手机号，请到隐私设置(Privacy and Security)中找到手机号码(Phone Number)的设置，在里面移除对方即可。 不登陆 Telegram 如何查看频道消息？：Telegram 公开频道可以直接通过浏览器输入 https://t.me/s/频道id 访问，不需要拥有TG账号。  进阶知识 什么是 MTProxy 代理？\n MTProxy 是 Telegram 的官方项目，仅能用于代理 Telegram 软件 MTP 代理是在 Telegram 中内置的代理程序，可以直接在软件内配置，而不需要下载任何其他 App 来配置代理  主题与美化 美化主题频道\n 官方 Desktop 桌面版主题频道 @themes 官方 Android 安卓主题频道 @Androidthemes  fdupes You can call it like fdupes -r /dir/ect/ory and it will print out a list of dupes. fdupes has also a simple Homepage and a Wikipedia article, which lists some more programs.\nCodec 主要用于 Firefox，安装媒体解码器来播放 MP3、MPEG4 和其他格式媒体文件。由于各个国家的版权问题， Ubuntu 在默认情况下不会安装它。\n$ sudo apt-get install ubuntu-restricted-extras 这种方式会安装 .exe 程序，不如直接安装\n$ sudo apt-get install h264enc bypy bypy info 认证特别慢，而授权码又只有10分钟，导致后面授权码过期 Heroku server 认证失败失败。\n如此，可以通过手动认证。\n  通过 bypy -dv 查看详细输出，得到 Full URL，如 https://bypyoauth.herokuapp.com/auth?code=...\u0026amp;bypy_version=1.7.2\u0026amp;redirect_uri=oob，在浏览器中打开，获得token。\n  将其放在 ~/.bypy/bypy.json 中。\n  源码仓库也有示例。\n我下载一个大文件，总共12G左右，已用了两个晚上，中途没关（由于不是立马就要的东西，就用时间换金钱了），一次看进度时，Terminal 就卡退了，重新运行后，bypy会继续上次下载，而不是重新开始（这样话太可怕了）。\nFRP frp 是一个专注于内网穿透的高性能的反向代理应用，支持 TCP、UDP、HTTP、HTTPS 等多种协议。可以将内网服务以安全、便捷的方式通过具有公网 IP 节点的中转暴露到公网。\n其他内网穿透工具\n ngrok ZeroTier N2N Dog Tunnel Tinc  Git $ vi .gitignore_default $ vi .auto-git.sh #!/bin/bash BLOG_DIR=$HOME/Documents/BlogSrc NOTE_DIR=$HOME/Documents/vNotebook TIME=\u0026#34;$(date \u0026#39;+%Y%m%d%H%M%S\u0026#39;)\u0026#34; echo \u0026#39;###BlogSrc###\u0026#39; cd $BLOG_DIR git pull git add . git commit -m \u0026#34;Update-${TIME}\u0026#34; git push echo \u0026#39;###vNotebook###\u0026#39; cd $NOTE_DIR git pull echo \u0026#39;#Tree DataOne\u0026#39; tree $HOME/DataOne \u0026gt; $NOTE_DIR/DataOne.tree echo \u0026#39;#Ignore files larger than 100MB\u0026#39; cat .gitignore_default \u0026gt; .gitignore # We need to remove the \u0026#34;./\u0026#34; then, .gitignore works, this command does that. find . -size +100M | sed \u0026#39;s|^./||g\u0026#39; | cat \u0026gt;\u0026gt; .gitignore git add . git commit -m \u0026#34;Update-${TIME}\u0026#34; git push exit 0 $ crontab -e 0 12 * * * /home/vane/.auto-git.sh  A collection of useful .gitignore templates Ignore files \u0026gt;100MB in your Git repos About large files on GitHub  libguestfs libguestfs 支持几乎所有类型的磁盘镜像。\n在基于 Debian 的系统上：\n$ apt-get install libguestfs-tools 我们可以像下面这样挂载一个 qcow2 格式的磁盘镜像：\n$ guestmount -a /path/to/qcow2/image -m \u0026lt;device\u0026gt; /path/to/mount/point 要卸载它，则执行：\n$ guestunmount qcow2_mount_poin Oracle JDK   解压缩到目录\n$ tar -zxv -f jdk-7u60-linux-x64.gz -C dir   修改环境变量\n$ vi ~/.bashrc export JAVA_HOME=/usr/lib/jvm/jdk1.7.0_60 # 这里换成自己解压的jdk 目录 export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib export PATH=${JAVA_HOME}/bin:$PATH   使环境变量生效\n$ source ~/.bashrc   Snapper Snapper 是一个由 openSUSE 的 Arvin Schnell 开发的工具，用于管理 Btrfs 子卷和 LVM 精简配置(thin-provisioned)卷。它可以创建和比较快照，在快照间回滚，并支持自动按时间序列创建快照。\n列出子卷列表\n$ sudo btrfs subvolume list -p / ID 256 gen 7746 parent 5 top level 5 path @ ID 258 gen 7746 parent 5 top level 5 path @home 安装 snapper\n$ sudo apt install snapper snapper-gui 创建配置文件，启用自动快照\n$ sudo snapper -c root create-config / $ sudo snapper -c home create-config /home Snapshots on boot\n$ sudo systemctl status snapper-boot.timer 管理 snapshot\n$ sudo snapper-gui Rhythmbox Music\n搜 \u0026ldquo;无损音乐\u0026rdquo; \u0026ldquo;车载音乐\u0026rdquo; 打包下载。\n电台\n很多电台是基于mms协议的，如果rhythmbox无法播放mms协议的电台，则需要安装支持mms协议的gstreamer插件——因为rhymbox使用gstreamer做后台解码。支持mms协议的插件为gstreamer bad插件，所以执行命令：\n$ sudo apt-get install gstreamer0.10-plugins-bad 同样的，如果需要播放mp3文件则安装ugly插件，需要播放wma文件则安装ffmpeg插件。\n电视台和电台MMS地址\n分享Rhythmbox电台列表\n最终还是没什么无法播放mms，因为 Rhythmbox 报错了。\nSpotify 作为世界上最大的音乐流媒体服务商，Spotify 因优秀的设计和精准的音乐推荐算法让不少人为之倾心。\n在正式注册 Spotify 之前，我们先来看一看曲库的问题。由于不同地区的歌曲版权差异，Spotify 在不同地区提供服务时，其相应的曲库也有所不同。例如港区的曲库中，粤语歌就要比美区多，相反美区的英文歌就要比港区多。同理，若你喜欢听其他语种的歌，注册当地的 Spotify 则是最好的选择。\n注册后要是发现当前的地区选择并不是很理想，想要换区也是可行的。首先要挂上自己想要换到地区的代理，然后进入自己的「Profile/资料」界面，点击「Edit Profile/修改资料」，「Country/国家」这个选项就会出现你当前所挂代理地区，保存更改即可换区成功。\n登录的话，需要先在登录界面设置Proxy重启。登录后在设置里改回来，不再需要Proxy了。\nVSCode 自动换行\n将word wrap的off改成on\n最适合程序员的笔记软件\nhttps://github.dev/[用户名]/[仓库名] Chrome Import Passwords\n Launch Chrome on your computer. Type the following in the address bar and pressEnter: chrome://flags On the flags screen, put your cursor in the search box and type Password import. You should see the Password import flag in the search results. To enable this flag, click the dropdown menu next to the flag and select Enabled. Click Relaunch at the bottom to relaunch Chrome. This will restore all of your open tabs. When Chrome opens, click the three dots in the top-right corner, and select Settings \u0026gt; Passwords on the following screen. Click the three dots next to Saved Passwords and select Import. Navigate to your CSV passwords file and select it to import it into Chrome.  VirtualBox virtualbox VM 磁盘大小扩容\n点击 virtualbox 软件的菜单，管理 -\u0026gt; 选择虚拟介质管理\n执行 .vbs 文件\n$ cscript test.vbs 删除备份\n删除虚拟机备份，当前状态前一个备份删除得快，两个备份之间的备份删除得慢。\n共享文件夹\n固定分配的共享文件夹对于定义共享文件夹的虚拟机是永久存在的；\n临时分配的共享文件夹在虚拟机运行时添加/删除，虚拟机关闭后消失。\n把img系统镜像转为VDI或VMDK格式文件\n$ VBoxManage convertdd *.img *.vdi 在 virtualbox 新建虚拟机时指定 vdi 硬盘文件，就可以安装系统\nPlay On Linux PlayOnLinux simplifies much of this and makes installing and using Windows programs in Ubuntu easier.\n最适合程序员的笔记软件 程序员的笔记软件，应该满足下面几个条件。\n 跨平台，同时支持桌面电脑（Windows，Mac，Linux）和手机（Android，iOS）。 随时同步，打开任何一台机器，都能接着上一次的工作继续写。 实时存储，如果软件突然关闭，也不会丢失内容。 支持 Markdown 格式，便于后期直接发布。 支持推送到远程 Git 仓库，产生历史版本，同时作为远程备份。  Stackedit.io 和 HackMD.io，都不是很理想。\nGitHub 官方推出的 github.dev。只要访问 https://github.dev/[用户名]/[仓库名]，你就能在浏览器里面，使用 VS Code 编辑指定仓库。它实际上就是 VS Code 编辑器的 Web 版，并且与 Git 高度集成。GitHub 提供了一个快捷入口。 打开 GitHub 仓库主页，按一下小数点（.）这个键， 页面就会自动跳转到 VS Code 编辑环境。\n如果你更希望使用手机原生 App，我推荐 Obsidian。它有全平台的客户端，并且可以参考这篇文章设置 Git 集成。\n评论里还有很多推荐，选择一个合适的就行。\nUbuntu Packages Search List of applications—Arch 常用软件—openSUSE 应用程序—Ubuntu 生态适配清单—UOS QEMU KVM 创建新虚拟系统 创建硬盘镜像 除非直接从 CD-ROM 或网络引导（并且不安装系统到本地），运行 QEMU 时都需要硬盘镜像。硬盘镜像是一个文件，存储虚拟机硬盘上的内容。\n一个硬盘镜像可能是 raw镜像, 和客户机器上看到的内容一模一样，并且将始终使用主机上的来宾硬盘驱动器的全部容量。此方法提供的I / O开销最小，但可能会浪费大量空间，因为guest虚拟机上未使用的空间无法在主机上使用。\n另外一种方式是qcow2 格式，仅当客户系统实际写入内容的时候，才会分配镜像空间。对客户机器来说，硬盘大小表现为完整大小，即使它可能仅占用主机系统上的非常小的空间。此映像格式还支持QEMU快照功能。但是，使用此格式而不是 raw 可能会影响性能。\nQEMU 提供 qemu-img命令创建硬盘镜像.例如创建一个 4 GB raw 格式的镜像:\n$ qemu-img create -f raw image_file 4G 您也可以用 -f qcow2 创建一个 qcow2 镜像。\n用 dd 或 fallocate 也可以创建一个 raw 镜像。\n警告： 如果硬盘镜像存储在 Btrfs 系统上，则应在创建任何映像之前考虑禁用该目录的 写时复制。\n调整镜像大小\n警告： 调整包含NTFS引导文件系统的镜像将无法启动已安装的操作系统，推荐在操作之前进行备份\n执行 qemu-img 带 resize 选项调整硬盘驱动镜像的大小.它适用于 raw 和 qcow2. 例如, 增加镜像 10 GB 大小, 运行:\n$ qemu-img resize disk_image +10G 在磁盘映像扩容后，必须使用虚拟机内部系统的分区工具对该镜像进行分区并格式化后才能真正开始使用新空间。 在收缩磁盘映像时，必须首先使用虚拟机内部系统的分区工具减少分该分区的大小，然后相应地收缩磁盘映像，否则收缩磁盘映像将导致数据丢失！\n安装操作系统 这是你第一次需要去启动模拟器的步骤，为了在磁盘镜像上安装操作系统，你必须同时将磁盘镜像与安装介质装载到虚拟机上，从安装介质中启动操作系统。\n以i386的客户机为例，为了从CD-ROM内的把可用于启动的ISO文件安装到磁盘镜像上，你需要：\n$ qemu-system-x86_64 -cdrom iso_image -boot order=d -drive file=disk_image,format=raw 在安装完操作系统后，就可以直接从QEMU镜像内启动了。\n注意： 默认情况下仅分配给虚拟机128MB的内存， 分配的内存大小可以通过 -m 调整， 比如 -m 512M 或 -m 2G。\n提示：\n 相较于指定 -boot order=x ，一部分用户感觉使用 -boot menu=on 启用boot菜单的体验更舒服些，至少在配置和实验时是这样的。 当使用无界面（headless）模式时， 将会默认在本地5900端口启动一个VNC服务器， 可以用 TigerVNC 连接到客户机的系统上: vncviewer :5900 若你在安装过程中需要替换软盘或CD，可以使用QEMU机器监视器（在虚拟机窗口中按Ctrl + Alt + 2）来删除存储设备并将其连接到虚拟机。使用info block查看块设备，然后使用change命令换出设备。按下Ctrl + Alt + 1返回虚拟机。  运行虚拟化的系统 qemu-system-* 程序 (例如 qemu-system-i386 或 qemu-system-x86_64, 取决于客户机架构)用来运行虚拟化的客户机. 用法是:\n$ qemu-system-i386 options disk_image 所有 qemu-system-*的选项是相同的。\n默认 QEMU会在窗口中显示虚拟机的视频输出.有一点要记住:当您单击QEMU窗口,鼠标指针被捕获。要放开，按 Ctrl+Alt+g.\n警告： QEMU 不应以 root 身份运行. 如果必须以root身份在某个脚本中运行QEMU，那么你需要使用 -runas 选项让QEMU放弃root权限\n启用 KVM KVM 必须要您处理器和内核支持, 和必要的 kernel modules加载.\n要在KVM模式中启动QEMU, 追加 -enable-kvm到启动选项. 要检查是否为正在运行的 VM 启用了 KVM，请使用 Ctrl+Alt+Shift+2 进入 QEMU Monitor，然后键入 info kvm。\n注意：\n -machine 选项中的 accel=kvm 参数与-enable-kvm 或 -accel kvm 选项是等价的。 CPU模型 host 需要 KVM。 如果你使用GUI工具去启动QEMU，但是性能体验极差，那么最好检查一下是否真的开启了KVM支持，因为QEMU可能选择了备用的模拟模式，即软件级模拟。 需要启用KVM才能正常启动windows7和windows8，否则会出现“蓝屏”.  启用 IOMMU (Intel VT-d/AMD-Vi) 的支持 首先启用IOMMU。\n确保您的 CPU 支持 AMD-Vi/Intel Vt-d 并且已经在 BIOS 中打开。通常这个选项会在类似“其他 CPU 特性”的菜单里，也有可能隐藏在超频选项之中。选项可能就叫做 “VT-d” 或者 “AMD-Vi” ，也有可能是更通用的名称，比如“虚拟化技术”之类。有可能您主板的手册并不会解释这些。\n设置内核参数以启用 IOMMU，注意不同品牌的 CPU 所需的内核参数并不同。\n 对于 Intel CPU(VT-d)，使用 intel_iommu=on。 对于 AMD CPU(AMD-Vi)，使用 amd_iommu=on。  您同时需要设置iommu=pt，这将防止Linux试图接触(touching)无法直通的设备。\n在重启之后，检查 dmesg 以确认 IOMMU 已经被正确启用：\n$ dmesg | grep -e DMAR -e IOMMU ... [ 0.000000] Intel-IOMMU: enabled ... 添加 -device intel-iommu 选项创建IOMMU设备:\n$ qemu-system-x86_64 -enable-kvm -machine q35 -device intel-iommu -cpu host .. 注意： 在基于Intel CPU的系统上用 -device intel-iommu 创建QEMU内的IOMMU设备将会禁用PCI直通， 如果需要PCI直通，则不应设置-device intel-iommu。\n宿主机和虚拟机数据交互 网络 我们可以利用任何支持文件传输的网络协议实现客户机和宿主机之间的数据交互, 例如 NFS, SMB, NBD, HTTP, FTP, 或 SSH, 当然这么做的前提是你已经配置好二者之间的网络，且在系统上启动了相应的服务程序。\n在默认情况下，用户模式的客户机能够通过10.0.2.2这个IP访问到宿主机。任何运行于宿主机上的服务端程序都可以通过这个地址被访问到，比如说我们可以通过这个IP访问到宿主机上的SSH服务器或SMB服务器。因此在这种情况下，客户机能够挂载宿主机通过SMB or NFS暴露出来的目录，也可以访问宿主机上的HTTP服务器等。 通常情况下宿主机无法访问客户机上的服务，不过你也可以通过一些特殊的网络配置达到这个目的 (参阅#Tap 网络)\nQEMU 端口转发 QEMU能够将宿主机的端口转发到客户机上以实现一些功能，例如从宿主机上访问客户机的SSH端口。\n举个例子，将宿主机上的10022端口与客户机上的22 (SSH) 端口进行绑定， 对应的QEMU命令如下：\n$ qemu-system-x86_64 disk_image -nic user,hostfwd=tcp::10022-:22 确认你客户机上的sshd程序正在运行，然后可以通过如下命令连接到客户机的SSH端口\n$ ssh guest-user@localhost -p 10022 你可以用 SSHFS 把客户机的整个文件系统都挂到宿主机上，这样就可以在宿主机上对客户机的文件系统进行读写了。\n想进行多端口转发的话, 只需要在-nic参数中指定多个hostfwd, 以VNC端口为例:\n$ qemu-system-x86_64 disk_image -nic user,hostfwd=tcp::10022-:22,hostfwd=tcp::5900-:5900 QEMU 的内置SMB服务器 QEMU的文档中指出它有一个内置的SMB服务器，但实际上，它只是在宿主机上加载一个自动生成的smb.conf配置文件 (位于/tmp/qemu-smb.random_string)，然后启动宿主机上的Samba，使得客户机能够通过一个IP地址进行访问 (默认的IP地址是10.0.2.4)。这个方法只适用于用户网络，在你不想在宿主机开启通常的Samba服务 (客户机同样能访问这类Samba服务) 时这个方法还挺好用的。\n宿主机上必须安装 Samba。通过如下QEMU命令启用这项特性:\n$ sudo apt install samba $ qemu-system-x86_64 disk_image -net nic -net user,smb=shared_dir_path shared_dir_path 就是你想要在宿主机和客户机之间共享的目录。\n接着，在客户机内，你应该能够通过10.0.2.4访问到名为qemu的共享文件夹。例如在Windows Explorer中前往 \\\\10.0.2.4\\qemu 这个地址。\n注意：\n 如果你像这样多次指定共享选项 -net user,smb=shared_dir_path1 -net user,smb=shared_dir_path2 or -net user,smb=shared_dir_path1,smb=shared_dir_path2 qemu只会共享参数中最后的一个目录。 如果你不能访问共享文件夹且客户机系统为 Windows, 请检查 NetBIOS 协议是否被启用 并确认防火墙没有屏蔽NetBIOS协议的 端口 如果你不能访问共享文件夹且客户机系统为 Windows 10 Enterprise 或 Education 或 Windows Server 2016, 请启用游客访问.  网络 采用TAP设备（tun 与 tap 设备，都是虚拟网络设备，tun 设备用来实现三层隧道（三层 ip 数据报），tap 设备用来实现二层隧道（二层以太网数据帧）。）和网桥（使用网桥可以将多个接口连接到同一网段内，这一功能等同于交换式集线器。）的虚拟网络的性能应该会比使用用户模式网络或VDE要好，原因在于TAP设备和网桥是在内核中实现的。\n此外，虚拟网络的性能可以通过将网络设备直接注册到虚拟机中改善，这比默认情况下模拟e1000 NIC的性能表现要更好，参阅 #安装 virtio 驱动 获得更多相关信息。\n关于链路层地址的限制 若在QEMU启动中指定了 -net nic 参数，QEMU将会为虚拟机注册一块虚拟网卡，其链路层地址为 52:54:00:12:34:56 。然而，当在多台虚拟机之间搭建桥接网络时，每台虚拟机在tap设备的虚拟机端都需要拥有一个独一无二的链路层地址 (MAC)，否则网桥会因为收到多个不同源却拥有相同MAC地址的数据包而无法正常工作。即使你为多个tap设备配置了不同的MAC地址也依旧会出现这个问题，因为当数据包通过tap设备时，tap设备并不会改写包内的链路层地址。\n因此请确保每个虚拟机拥有自己独一无二的网卡地址, 并且它们都以 52:54: 开头。 可以通过如下命令手动设置虚拟机的MAC地址, 下面的\u0026rsquo;X\u0026rsquo;可以替换成任何16进制字符:\n$ qemu-system-x86_64 -net nic,macaddr=52:54:XX:XX:XX:XX -net vde disk_image 用户模式 默认情况下，没有任何-netdev参数，QEMU将使用带有内置DHCP服务器的用户模式网络。当您的虚拟机运行其DHCP客户端时，将为其分配IP地址，它们将能够通过QEMU伪装的IP来访问物理主机的网络。\n警告： 仅适用于TCP和UDP协议，因此ICMP协议（包括ping）将不起作用。 请勿使用ping测试网络连接。\n如果主机已连接Internet，则此默认配置可以使您的虚拟机轻松访问Internet。但是如果您同时启动多个虚拟机，则虚拟机将无法在外部网络上直接看到，虚拟机也将无法相互通信。\nQEMU的用户模式网络可以提供更多功能，例如内置TFTP或SMB服务器，将主机端口重定向到虚拟机（例如，允许SSH连接到虚拟机）或将虚拟机连接到VLAN（vlan 全程 virtual lan，能够用来虚拟分配以太网。归属于不同的 VLAN ID 的设备之间需要一个路由才能够通信，这意味这不同的 VLAN ID 将以太网划分成了不同的分组。），以便它们可以彼此通信。 有关更多详细信息，请参见-net user标志上的QEMU文档。\n但是，用户模式网络在效用和性能上都有局限性。更高级的网络配置需要使用TAP设备或其他方法。\nTap 网络 Tap devices是一个Linux内核特性，允许您创建作为真实网络接口的虚拟网络接口。发送到tap接口的包将被传递到一个用户空间程序(如QEMU)，该程序将自己绑定到该接口。\nQEMU可以为虚拟机使用tap网络，因此发送到tap接口的包将被发送到虚拟机，并显示为来自虚拟机中的网络接口(通常是以太网接口)。相反，虚拟机通过其网络接口发送的所有内容都将出现在tap接口上。\nLinux桥接驱动程 序支持Tap设备，因此可以将Tap设备彼此桥接在一起，也可以连接其他主机接口，如eth0。如果您希望您的虚拟机能够相互通信，或者希望LAN上的其他机器能够与虚拟机通信，那么这是非常理想的方案。\n警告： 如果您将tap设备和一些主机接口桥接在一起，例如eth0，您的虚拟机将直接出现在外部网络上，这将使它们遭受攻击的可能。根据您的虚拟机可以访问的资源，您可能需要采取所有precautions来保护您的虚拟机。如果风险太大,虚拟机没有资源或您设置多个虚拟机,一个更好的解决方案可能是使用host-only networking建立NAT。在这种情况下，您只需要在主机上安装一个防火墙，而不是为每个虚拟机安装多个防火墙。\n正如在用户模式网络部分中指出的，tap设备提供比用户模式具有更高的网络性能。如果虚拟机中的操作系统支持virtio网络驱动程序，那么网络性能也会显著提高。假设使用tap0设备，virtio驱动程序在客户端上使用，并且没有使用脚本来帮助启动/停止网络，使用下面的qemu命令：\n-net nic,model=virtio -net tap,ifname=tap0,script=no,downscript=no 但是，如果已经使用带有virtio网络驱动程序的Tap设备，则甚至可以通过启用vhost来提高网络性能，例如：\n-net nic,model=virtio -net tap,ifname=tap0,script=no,downscript=no,vhost=on 仅主机网络\n如果为网桥提供了IP地址，并且使能发往该网桥的流量允许，但没有实际接口（例如eth0）连接到网桥，则虚拟机与虚拟机间，虚拟机与主机间能够相互通信。但是，如果您没有在物理主机上设置IP掩蔽，则他们将无法与外部网络进行通信。 此配置被其他虚拟化软件（例如VirtualBox）称为“仅主机网络模式”。\n提示：\n  如果你想设置IP掩蔽，例如虚拟机的NAT，请查看Internet sharing#Enable NAT页面。\n  您也许想在网桥接口上运行一个DHCP服务器来服务虚拟网络。例如，使用172.20.0.1/16子网，dnsmasq作为DHCP服务器:\n# ip addr add 172.20.0.1/16 dev br0 # ip link set br0 up # dnsmasq --interface=br0 --bind-interfaces --dhcp-range=172.20.0.2,172.20.255.254   内部网络\n如果您不为网桥提供IP地址并在iptables添加INPUT规则链，将所有流向网桥中的数据丢弃，则虚拟机将能够彼此通信，但无法与物理主机或外部网络通信。此配置被其他虚拟化软件（例如VirtualBox）称为“内部网络”。您将需要为虚拟机分配静态IP地址，或在其中一个虚拟机上运行DHCP服务器。\n在默认情况下，iptables将丢弃桥接网络中的数据包。您可能需要使用这样的iptables规则来允许桥接网络中的数据包:\n# iptables -I FORWARD -m physdev --physdev-is-bridged -j ACCEPT 使用 qemu-bridge-helper 桥接网络\n这种方法不需要启动脚本，并且很容易适应多个tap和多个桥。它使用/usr/lib/qemu/qemu-bridge-helper，允许在现有桥上创建tap设备。\n提示： 参见 Network bridge 获取创建网桥的信息.\n首先，创建一个配置文件，包含QEMU使用的所有网桥的名称:\n/etc/qemu/bridge.conf allow bridge0 allow bridge1 ... 现在启动虚拟机：\n$ qemu-system-i386 -net nic -net bridge,br=bridge0 [...] 在多个TAP设备的情况下，最基本的用法是要为所有NIC指定VLAN：\n$ qemu-system-i386 -net nic -net bridge,br=bridge0 -net nic,vlan=1 -net bridge,vlan=1,br=bridge1 [...] 手工创建网桥\n将虚拟机连接到主机接口，如eth0，这可能是最常见的配置。这种配置使虚拟机看起来直接位于外部网络，与物理主机位于同一以太网段。\n物理设备和Tap设备之间通过iptables进行网络共享\n桥接网络能在有线接口(例如eth0)之间工作，并且很容易设置。但是，如果主机通过无线设备连接到网络，则无法进行桥接。\n解决这个问题的一种方法是，给tap设备设置一个静态IP，使linux自动处理它的路由，然后通过iptables规则转发tap接口和连接到网络的设备之间的通信。\n通过 VDE2 配置网络 VDE全称为Virtual Distributed Ethernet，作为uml_switch的一个扩展，是一个用于管理虚拟网络的工具包\n其基本的思想是创建一个虚拟的开关，就如插座那样，允许虚拟机和物理机通过\u0026quot;插入\u0026quot;连接彼此。下面的配置非常简单，然而，VDE的功能远比展示的更强大，其能够接入虚拟开关，在不同的主机上运行它们并监听开关上的通信。\n本方法的优点在于无需sudo特权，普通用户一般没有运行modprobe的权限。\nVDE2 网桥 任何连接到vde上的虚拟机都会暴露给外部。举个例子，每台虚拟机都能直接从ADSL路由器那收到DHCP的配置信息。\n简化配置参数 如果你经常需要以不同的网络配置选项运行QEMU，就会发现时常得输入大量的-netdev和-device选项组合，这些是大量重复性的劳动。可以用-nic选项将二者结合，就如下面这样，底下这些参数：\n-netdev tap,id=network0,ifname=tap0,script=no,downscript=no,vhost=on -device virtio-net-pci,netdev=network0 可简化为:\n-nic tap,script=no,downscript=no,vhost=on,model=virtio-net-pci 要注意的是缺失了网络ID，因此将会以model=创建这些设备。{ic|-nic}}命令的前半部分参数正是-netdev的参数，而后半部分参数（model=之后的部分）则与设备有关，原本设备所提供的参数同样可以在此使用（例如，可以指定smb=）。若要完全禁用网络，可以用-nic none。\n图形 QEMU 可以使用一下几个图形输出：std, cirrus, vmware, qxl, xenfs 和 vnc。\n使用 vnc 选项，你可以单独运行客户机，并且通过 VNC 连接。\nstd 使用 -vga std 你可以得到最高 2560 x 1600 像素的分辨率。从 QEMU 2.2 开始是默认选项。\nqxl QXL是一个支持2D的并行虚拟化图形驱动。需要在客户机中安装驱动并在启动QEMU时设置-vga qxl选项。你可能也会想使用#SPICE优化QXL的图形表现。\n在Linux客户机中，需要加载qxl和bochs_drm这两个内核模块，以获得一个比较好的效果。\nQXL设备的默认VGA内存大小为16M，这样的内存大小最高支持QHD (2560x1440)的分辨率，如果想要一个更高的分辨率，请增加vga_memmb。\nvmware 尽管Bug有点多，但相比于std和cirrus它的表现会更好。对于Arch Linux客户机来说可以安装xf86-video-vmware和xf86-input-vmmouse获取VMware驱动。\nvirtio virtio-vga / virtio-gpu 是一个基于virgl的3D并行虚拟化图形驱动。目前依旧处于开发中，仅支持最近的（\u0026gt;= 4.4）的Linux客户机，且需要以gallium-drivers=virgl选项编译mesa (\u0026gt;=11.2)。\n若要在客户机上启用3D加速，那么需要用-vga virtio选项选择此vga，并用-display sdl,gl=on或-display gtk,gl=on在显示设备上启用opengl上下文，这两个选项分别适用于sdl输出和gtk输出。如果配置成功了，那么在客户机的kernel log里可以看到：\n# dmesg | grep drm [drm] pci: virtio-vga detected [drm] virgl 3d acceleration enabled cirrus cirrus是2.2之前默认的图形选项，不应当在现代操作系统中使用它。\nnone 这就像一台完全没有VGA卡的PC，无法通过-vnc访问它。另外，这种情况与使用-nographic选项不同，-nographic会让QEMU模拟VGA卡，只是关闭了SDL输出。\nSPICE SPICE project旨在为用户提供一种完全开源的方式，无缝地对虚拟机进行远程访问。\nVNC 可以用-vnc :*X*选项将QEMU的VGA输出重定向至VNC会话中。将*X*替换为输出目标的编号（0代表之后监听在5900，1代表监听在5901\u0026hellip;）。\n$ qemu-system-x86_64 -vnc :0 警告： 默认的VNC服务器没有使用任何验证手段，用户可以从任何主机上连接到VNC。\n基本的口令验证\n可以通过使用password选项很容易地设置访问口令。必须在QEMU Monitor中指定口令，仅当用户提供口令时才有可能连接到VNC。\n$ qemu-system-x86_64 -vnc :0,password -monitor stdio 在QEMU Monitor中设置口令需使用change vnc password命令，然后指定一个口令。\n底下的命令将在启动VNC时直接为其设置口令：\n$ printf \u0026quot;change vnc password\\n%s\\n\u0026quot; MYPASSWORD | qemu-system-x86_64 -vnc :0,password -monitor stdio 注意： 口令被限制在8个字符内，可以用暴力破解的方式猜到口令。因此在公网上推荐使用更细致的保护措施。\n音频 -audiodev标识用于设定后端音频驱动及其相关选项。最简单的情况下，你需要选择一个驱动并设置一个id。\n-audiodev pa,id=snd0 使用音频设备 Intel HD Audio\n模拟Intel HD Audio需要添加控制器和编解码器设备。可以用如下命令列出可用的Intel HDA Audio设备：\n$ qemu-system-x86_64 -device help | grep hda 添加音频控制器：\n-device ich9-intel-hda 添加音频编解码器并将其映射到宿主机的音频后端id上。\n-device hda-output,audiodev=snd0 Intel 82801AA AC97\n模拟AC97需要添加声卡设备并将其映射到宿主机的一个音频后端id上。\n-device AC97,audiodev=snd0 无音频设备 通过如下命令获取支持模拟的音频驱动列表：\n$ qemu-system-x86_64 -soundhw help 比如，要在客户机上模拟hda驱动，需要使用-device intel-hda -device hda-duplex选项启动QEMU。\n注意： 客户机的显卡模拟驱动可能也会导致客户机中的音频质量出现问题，需要一个个进行排查。使用qemu-system-x86_64 -h | grep vga列出可用的选项\n安装 virtio 驱动 QEMU为用户提供并行虚拟化块设备和网络设备的能力，其是借助virtio驱动实现的，拥有更好的性能表现以及更低的开销。\nvirtio块设备需要使用-drive指定一个disk image的参数，且需要带上if=virtio参数：\n$ qemu-system-x86_64 -boot order=c -drive file=disk_image,if=virtio 网络配置也是类似的：\n$ qemu-system-x86_64 -nic user,model=virtio-net-pci 注意： 仅有当客户机有virtio设备对应的驱动时该方法才能起效，Linux是有这方面支持的，不过无法保证这些驱动能够兼容其他操作系统。\n以下以windows为例。\n块设备驱动 Windows没有自带virtio驱动，因此需要在安装时加载该驱动。镜像文件可以从Fedora 仓库下载。\n通过ISO加载只对Windows Vista和Windows Server 2008及其之后的版本有效。这个方法的具体操作是在主磁盘设备和Windows安装盘外挂载一个额外的cdrom设备，将系统镜像与virtio驱动一同加载：\n$ qemu-system-x86_64 ... \\ -drive file=windows_disk_image,index=0,media=disk,if=virtio \\ -drive file=windows.iso,index=2,media=cdrom \\ -drive file=virtio.iso,index=3,media=cdrom \\ ... 在安装过程中，Windows Installer会询问你“Where do you want to install Windows?”，其会返回一个警告表示没有找到任何磁盘设备。接下来跟着如下示例中的步骤进行操作（基于Windows Server 2012 R2 with Update）：\n Select the option Load Drivers. Uncheck the box for Hide drivers that are not compatible with this computer\u0026rsquo;s hardware. Click the browse button and open the CDROM for the virtio iso, usually named \u0026ldquo;virtio-win-XX\u0026rdquo;. Now browse to E:\\viostor\\[your-os]\\amd64, select it, and confirm.  现在应该能看到virtio磁盘出现在列表中了，等待着被选中、格式化并安装。\n网络驱动 安装virtio网络驱动程序要容易一些，只需如上所述添加-net参数即可。\n$ qemu-system-i386 -m 4G -vga std -drive file=windows_disk_image,if=virtio -net nic,model=virtio-net-pci -cdrom virtio-win-0.1-185.iso Windows将检测网络适配器并尝试为其找到驱动程序。如果失败，请转到“设备管理器”，找到带有感叹号图标的网络适配器（双击打开），切换到驱动程序并单击“更新驱动程序”，然后选择虚拟CD-ROM。别忘了选中显示要递归搜索目录的复选框。\nBalloon 驱动 如果想要追踪客户机内存状态（比如通过virsh的dommemstat命令）或者在运行时改变客户机内存大小（尽管依然无法改变实际的内存大小，不过可以通过inflating balloon驱动限制内存的使用），那么请在客户机上安装balloon驱动吧。\nQEMU 监视器 QEMU运行时会提供一个监视器console界面以方便用户同虚拟机进行交互。QEMU监视器提供了许多有趣的功能，例如获取当前虚拟机的信息，热插拔设备，创建快照等。在QEMU监视器console中运行help或?命令获得完整的命令列表。\n访问QEMU监视器Console 图形化界面\n当使用默认的std图形选项时，可以通过按下Ctrl+Alt+2组合键或从QEMU窗口上的View \u0026gt; compatmonitor0访问到QEMU监视器。若要返回到虚拟机的图形界面，那么按下Ctrl+Alt+1或者View \u0026gt; VGA就行。\n然而，这种标准的访问方式不够方便，而且并不是在QEMU的所有图形化输出方式中都适用。\nTelnet\n启动QEMU时带上-monitor telnet:127.0.0.1:*port*,server,nowait参数可以启用telnet。虚拟机启动后可以通过telnet访问到监视器：\n$ telnet 127.0.0.1 port 注意： 如果指定 127.0.0.1 作为监听地址，那么只能在运行QEMU的宿主机上连接到该监视器。如果想要远程访问，QEMU需要在0.0.0.0上进行监听：-monitor telnet:0.0.0.0:*port*,server,nowait。还要记住的是，最好对firewall进行配置，该连接是完全不进行认证和加密的，因此需要通过防火墙确保本地网络环境是可信的。\nUNIX socket\n通过-monitor unix:*socketfile*,server,nowait参数运行QEMU，之后就可以通过socat或openbsd-netcat连接到监视器上。\n例如，如果QEMU是通过如下命令启动：\n$ qemu-system-x86_64 [...] -monitor unix:/tmp/monitor.sock,server,nowait [...] 就可以像这样连接到监视器上：\n$ socat - UNIX-CONNECT:/tmp/monitor.sock 或者通过这种方式:\n$ nc -U /tmp/monitor.sock TCP\n可以使用-monitor tcp:127.0.0.1:*port*,server,nowait参数将监视器暴露于TCP端口上，然后用netcat（openbsd-netcat或gnu-netcat都可）进行连接：\n$ nc 127.0.0.1 port 注意： 为了能够从其它设备上通过TCP socket访问到监视器，而不仅仅从运行QEMU的主机上连接，需要像前面Telnet中描述的那样，在0.0.0.0地址上进行监听。\n标准 I/O\n如果以-monitor stdio参数运行QEMU，那么其实是可以在运行QEMU的终端下访问到监视器的。\n在Monitor conosle下向虚拟机发送按键行为 由于在某些配置下，宿主机可能会拦截一些按键组合另作他用，这导致要在虚拟机中触发一些特定按键组合变得有些困难（一个显然的例子就是Ctrl+Alt+F*组合，该组合用于改变当前的tty）。我们采用在monitor console下发送按键组合的方式解决该问题。只需切换到monitor console下，然后使用sendkey命令，即可将按键转发至虚拟机中，例如：\n(qemu) sendkey ctrl-alt-f2 通过 monitor console 创建快照和管理快照 注意： 该特性\u0026quot;只\u0026quot;支持qcow2格式的虚拟机磁盘镜像，对于raw是无效的。\n有时候我们很需要将虚拟机的当前状态进行保存，或是将虚拟机重置到之前的快照状态，而且最好是随时能进行这些操作。QEMU monitor console为用户提供了必要的功能，进行快照创建，快照管理，以及快照恢复。\n Use savevm name 用于创建一个名为name的快照。 Use loadvm name 用于将虚拟机状态恢复至快照name。 Use delvm name 用于删除快照name。 Use info snapshots 用于查看保存的快照列表，这些快照由一个自增长的ID和标签名（用户创建快照时赋予）进行标识。  以冻结模式运行虚拟机 QEMU支持以冻结态运行虚拟机（需使用-snapshot参数），换句话说，虚拟机关闭时，对于虚拟机的一切修改都会丢弃。当用户对磁盘镜像写入时，这些变动最终写入的位置是/tmp目录下的一个临时文件，QEMU关机时将会把他们丢弃。\n不过，即使虚拟机运行于冻结状态下，依旧可以通过monitor console将这些变化写入磁盘镜像（如果你想的话）。使用下面的命令：\n(qemu) commit all 另外如果在冻结状态下创建快照，这些快照在QEMU退出时都会被丢弃，除非你显式地commit了他们。\nmonitor console中的开机和暂停命令 在QEMU monitor console下也可以模拟对物理机的一些操作：\n system_powerdown 会向虚拟机发送ACPI关机信号，效果就类似物理机上按下电源按钮。 system_reset 会重置虚拟机，类似物理机上的重置按钮。该操作可能导致数据丢失或文件系统的损坏，这是因为虚拟机并不是\u0026quot;干净地\u0026quot;重启的。 stop 会暂停虚拟机。 cont 使暂停的虚拟机恢复运行。  虚拟机截屏 可以在monitor console下运行该命令，获取PPM格式的截屏图片：\n(qemu) screendump file.ppm QEMU 机器协议 QEMU机器协议（QMP）是一个基于JSON格式的协议，使得其他应用程序可以通过该协议控制QEMU实例。类似#QEMU 监视器，其提供了与运行中的虚拟机进行交互的能力，且能够编程进行控制。关于QMP各命令的描述可以在这个qmp-commands链接中找到。\n技巧 改善虚拟机的性能表现 底下是一些可以改善虚拟机性能表现的技术，例如：\n  启用#启用 KVM：QEMU的启动命令加上-enable-kvm选项。\n  通过-cpu host选项让QEMU模拟宿主机上的特定CPU，如果没有该选项QEMU尝试模拟的是一个更为通用的CPU。\n  特别的，如果客户机是Windows，启用Hyper-V enlightenments可以改善性能：-cpu host,hv_relaxed,hv_spinlocks=0x1fff,hv_vapic,hv_time.\n  如果宿主机有多个核心，可以用-smp选项为客户机分配更多核心。\n  检查是否为虚拟机分配的足够的内存。默认情况下，QEMU仅仅为每台虚拟机分配128MiB的内存，可以使用-m选项分配更多的内存。例如，-m 1024代表启动一台内存为1024MiB的虚拟机。\n  如果客户机操作系统支持相关的驱动，可以使用virtio创建网络设备或块设备。\n  使用TAP设备代替user-mode网络，参阅#Tap 网络。\n  如果客户机需要进行大量的磁盘写工作，在宿主机文件系统上设置合适的挂载选项可以优化该工作。例如，可以用barrier=0选项挂载一个ext4 file system。在使用这些性能强化选项之前最好阅读相关文档，因为性能上的提升通常伴随着数据完整性下降的代价。\n  如果有一块原始磁盘镜像，你可能会想要禁用cache：\n$ qemu-system-x86_64 -drive file=disk_image,if=virtio,cache=none   使用原生的Linux AIO：\n$ qemu-system-x86_64 -drive file=disk_image,if=virtio,aio=native,cache.direct=on   如果正同时运行多台虚拟机，而它们拥有同样的操作系统，可以通过启用内核页归并节省内存。参阅#开启KSM。\n  在一些情况下，可以在运行时从安装了balloon驱动的客户机上回收内存，这需要QEMU启动该客户机时使用-device virtio-balloon选项。\n  允许使用一个ICH-9 AHCI控制器的仿真层，尽管它并不稳定。AHCI的仿真模拟支持NCQ，因此可以同时处理多个读写请求：\n$ qemu-system-x86_64 -drive id=disk,file=disk_image,if=none -device ich9-ahci,id=ahci -device ide-drive,drive=disk,bus=ahci.0   参阅 https://www.linux-kvm.org/page/Tuning_KVM 获取更多信息\n开机时启动QEMU虚拟机 通过libvirt实现\n如果虚拟机是通过libvirt设置的，可以用virsh autostart将其配置为开机自启，或者通过virt-managerGUI中虚拟机的Boot Options，选择\u0026quot;Start virtual machine on host boot up\u0026quot;实现开机自启。\n通过systemd service实现\n可以用如下的systemd unit和config配置开机时启动QEMU VM。\n/etc/systemd/system/qemu@.service [Unit] Description=QEMU virtual machine [Service] Environment=\u0026quot;haltcmd=kill -INT $MAINPID\u0026quot; EnvironmentFile=/etc/conf.d/qemu.d/%i ExecStart=/usr/bin/qemu-system-x86_64 -name %i -enable-kvm -m 512 -nographic $args ExecStop=/bin/bash -c ${haltcmd} ExecStop=/bin/bash -c 'while nc localhost 7100; do sleep 1; done' [Install] WantedBy=multi-user.target 注意： 为了方便地结束任务，该service会等待至console端口被释放（这意味着VM已被关闭）。\n接着创建per-VM配置文件，命名为/etc/conf.d/qemu.d/*vm_name*，在其中设置好args和haltcmd变量，配置示例：\n/etc/conf.d/qemu.d/one args=\u0026quot;-hda /dev/vg0/vm1 -serial telnet:localhost:7000,server,nowait,nodelay \\ -monitor telnet:localhost:7100,server,nowait,nodelay -vnc :0\u0026quot; haltcmd=\u0026quot;echo 'system_powerdown' | nc localhost 7100\u0026quot; # or netcat/ncat /etc/conf.d/qemu.d/two args=\u0026quot;-hda /srv/kvm/vm2 -serial telnet:localhost:7001,server,nowait,nodelay -vnc :1\u0026quot; haltcmd=\u0026quot;ssh powermanager@vm2 sudo poweroff\u0026quot; 对该变量的描述如下：\n args - 使用的QEMU命令行参数。 haltcmd - 安全关闭虚拟机的命令，在第一个例子中，QEMU monitor是通过-monitor telnet:..选项暴露至telnet，因而关闭虚拟机是通过nc命令在monitor console中发送system_powerdown，完成ACPI关机的工作。在另一个例子里，使用的则是SSH。  若要设置启动时运行哪个虚拟机，enable qemu@*vm_name*.service这个systemd单元\n鼠标整合 添加-usb -device usb-tablet选项以避免点击客户机系统的窗口时鼠标被捕获。该选项代表QEMU能够在不捕获鼠标的情况下，向系统报告鼠标的位置，该选项启用时还会覆盖PS/2鼠标模拟功能。 命令示例：\n$ qemu-system-x86_64 -hda disk_image -m 512 -usb -device usb-tablet 宿主机的USB设备传递至虚拟机 从客户机访问连接到宿主机USB口的设备是可能的，首先需要识别设备连接的位置，可以用lsusb命令找到设备连接位置，例如：\n$ lsusb ... Bus 003 Device 007: ID 0781:5406 SanDisk Corp. Cruzer Micro U3 上面以显示的数字分别用于标识\n 003 host_bus 007 host_addr 0781 vendor_id 5406 product_id  基本的思想是在QEMU中-device usb-ehci,id=ehci或-device qemu-xhci,id=xhci分别对EHCI (USB 2)或XHCI (USB 3)（在win7无法自动安装 USB3 驱动，因此应用 USB2）控制器进行模拟，然后将物理设备通过-device usb-host,..选项进行添加。\n识别出该设备，并将其连接至任一总线以及宿主机上的地址，通用的语法如下：\n-device usb-host,bus=controller_id.0,vendorid=0xvendor_id,productid=0xproduct_id 应用于上面例子中使用的设备，它变成：\n-device usb-ehci,id=ehci -device usb-host,bus=ehci.0,vendorid=0x0781,productid=0x5406 运行QEMU时会遇到 libusb couldn't open USB device Permission denied 权限错误，可以通过 udev 为设备设定合适的权限。\n$ vi /etc/udev/rules.d/50-usbtinyisp.rules SUBSYSTEMS==\u0026#34;usb\u0026#34;, ATTRS{idVendor}==\u0026#34;0781\u0026#34;, ATTRS{idProduct}==\u0026#34;5406\u0026#34;, GROUP=\u0026#34;vane\u0026#34;, MODE=\u0026#34;0660\u0026#34; $ ls -al /dve/bus/usb/003/007 crw-rw---- 1 root vane 189, 11 Nov 7 12:37 /dev/bus/usb/003/007 使用SPICE进行USB重定向 使用#SPICE时可以将USB设备从客户端重定向至虚拟机中，无需使用QEMU命令。还支持为配置USB重定向插槽数（插槽数将决定可同时重定向的最大设备数）。相比于前面那种使用-usbdevice进行重定向的方法，SPICE方法的优势在于可以在虚拟机启动后USB设备热插拔，移除或添加USB设备时无需停机。这个方法还允许通过网络将客户端的USB设备重定向至服务端。总之，其是在QEMU虚拟机中使用USB设备最灵活的方法。\n开启KSM Kernel Samepage Merging (KSM) 是Linux内核的一个特性，允许应用程序向内核申请同其他申请页归并的进程进行页归并，KSM机制允许客户虚拟机之间进行页共享。当许多客户机运行相似的操作系统时，这个机制可以节省客观的内存。\n多屏支持 Linux的QXL驱动支持默认支持四头（虚拟屏幕），可以通过qxl.heads=N这一内核参数进行变更。\n复制和粘贴 在宿主机和客户机之间共享剪贴板的方法之一是使用SPICE远程桌面协议，通过SPICE客户端访问客户机，你需要遵照#SPICE节中描述的步骤，通过该方式运行的客户机将支持与宿主机进行复制粘贴的操作。\nQEMU-KVM Win7 环境准备   安装QEMU：sudo apt install qemu-kvm\n  下载 Windows virtio driver iso：https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/archive-virtio/virtio-win-0.1.102/，因为要将磁盘挂接为 virtio 磁盘。\n需使用 virtio-win-0.1.102，我使用最新的 virtio-win-0.1.208.iso，Windows安装程序会提示驱动没有包含签名错误No signed device drivers were found. Make sure that the installation media contains the correct drivers, and then click OK\n  创建系统盘 qemu-img create -f qcow2 Windows7-VM.img 30G，这将作为Win7的操作系统盘。\n  创建启动脚本\n$ vi start_Windows7_VM.sh #!/bin/bash DISKIMG=$HOME/VirtualMachine/Windows7-VM.img exec qemu-system-x86_64 --enable-kvm \\ \t-cpu host,hv_relaxed,hv_spinlocks=0x1fff,hv_vapic,hv_time \\ \t-drive file=${DISKIMG},if=virtio \\ \t-net nic,model=virtio-net-pci -net user,smb=/home/vane/Downloads \\ \t-m 4096 \\ \t-smp cores=2,threads=4 \\ \t-vga std \\ \t-audiodev pa,id=snd0 -device ich9-intel-hda -device hda-output,audiodev=snd0 \\ \t-usb -device usb-tablet \\ \t-rtc base=localtime,clock=host \\ \t-name \u0026#39;Windows7 VM\u0026#39; \\ \t$@ $ chmod u+x start_Windows7_VM.sh   ./start_Windows7_VM.sh -boot d -cdrom $HOME/Downloads/cn_windows_7_ultimate_x64_dvd_x15-66043.iso -drive file=$HOME/Downloads/virtio-win-0.1.102.iso,index=3,media=cdrom\n  安装 Win 7  选择 Custom（advanced）  选择 virtio 磁盘  选择 virtio disk driver  安装 Win7 Virtio SCSI Driver  安装好以后，就可以看到安装的目标磁盘了  进入常规的 Win7 安装流程  安装 Virtio 网络驱动 但是安装失败：\n尝试 device manager：\n[QEMU 的内置SMB服务器](#QEMU 的内置SMB服务器) 宿主机的USB设备传递至虚拟机 SYSTEM fstab /etc/fstab是用来存放文件系统的静态信息的文件。当系统启动的时候，系统会自动地从这个文件读取信息，并且会自动将此文件中指定的文件系统挂载到指定的目录。\n查看/etc/fstab\n# cat /etc/fstab \u0026lt;file system\u0026gt; \u0026lt;dir\u0026gt; \u0026lt;type\u0026gt; \u0026lt;options\u0026gt; \u0026lt;dump\u0026gt; \u0026lt;pass\u0026gt; tmpfs /tmp tmpfs nodev,nosuid 0 0 /dev/sda1 / ext4 defaults,noatime 0 1 /dev/sda2 none swap defaults,nodelalloc 0 0 /dev/sda3 /home ext4 defaults,noatime 0 2 分别解释一下各字段的用处：\n \u0026lt;file system\u0026gt; 要挂载的分区或存储设备 \u0026lt;dir\u0026gt; 挂载的目录位置 \u0026lt;type\u0026gt; 挂载分区的文件系统类型，比如：ext3、ext4、xfs、swap \u0026lt;options\u0026gt; 挂载使用的参数有哪些。举例如下：  auto - 在启动时或键入了 mount -a 命令时自动挂载。 noauto - 只在你的命令下被挂载。 exec - 允许执行此分区的二进制文件。 noexec - 不允许执行此文件系统上的二进制文件。 ro - 以只读模式挂载文件系统。 rw - 以读写模式挂载文件系统。 user - 允许任意用户挂载此文件系统，若无显示定义，隐含启用 noexec, nosuid, nodev 参数。 users - 允许所有 users 组中的用户挂载文件系统. nouser - 只能被 root 挂载。 owner - 允许设备所有者挂载。 sync - I/O 同步进行。 async - I/O 异步进行。 dev - 解析文件系统上的块特殊设备。 nodev - 不解析文件系统上的块特殊设备。 suid - 允许 suid 操作和设定 sgid 位。这一参数通常用于一些特殊任务，使一般用户运行程序时临时提升权限。 nosuid - 禁止 suid 操作和设定 sgid 位。 noatime - 不更新文件系统上 inode 访问记录，可以提升性能。 nodiratime - 不更新文件系统上的目录 inode 访问记录，可以提升性能(参见 atime 参数)。 relatime - 实时更新 inode access 记录。只有在记录中的访问时间早于当前访问才会被更新。（与 noatime 相似，但不会打断如 mutt 或其它程序探测文件在上次访问后是否被修改的进程。），可以提升性能。 flush - vfat 的选项，更频繁的刷新数据，复制对话框或进度条在全部数据都写入后才消失。 defaults - 使用文件系统的默认挂载参数，例如 ext4 的默认参数为:rw, suid, dev, exec, auto, nouser, async.   \u0026lt;dump\u0026gt; dump 工具通过它决定何时作备份。dump 会检查其内容，并用数字来决定是否对这个文件系统进行备份。 允许的数字是 0 和 1 。0 表示忽略， 1 则进行备份。大部分的用户是没有安装 dump 的 ，对他们而言 \u0026lt;dump\u0026gt; 应设为 0。 \u0026lt;pass\u0026gt; fsck 读取 \u0026lt;pass\u0026gt; 的数值来决定需要检查的文件系统的检查顺序。允许的数字是0, 1, 和2。 根目录应当获得最高的优先权 1, 其它所有需要被检查的设备设置为 2。 0 表示设备不会被 fsck 所检查。  示例：\n/dev/sda1 /mnt/LinuxOSBuckup ext4 defaults 0 2 UUID of Storage Devices Finding UUID with blkid\n$ sudo blkid Finding UUID with ls\n$ ls -l /dev/disk/by-uuid Finding UUID with lsblk\n$ sudo lsblk -f Package Management APT Debian 使用一套名为 Advanced Packaging Tool（APT）的工具来管理包系统。在基于 Debian 的 Linux 发行版中，有各种工具可以与 APT 进行交互，以方便用户安装、删除和管理的软件包。apt-get 便是其中一款广受欢迎的命令行工具，但是最常用的命令都被分散在了 apt-get、apt-cache 和 apt-config 这三条命令当中，apt 命令的引入就是为了解决命令过于分散的问题。（简单来说就是：apt = apt-get、apt-cache 和 apt-config 中最常用命令选项的集合）\n   apt 命令 取代的命令 命令的功能     apt install apt-get install 安装软件包   apt remove apt-get remove 移除软件包   apt purge apt-get purge 移除软件包及配置文件   apt update apt-get update 刷新存储库索引   apt upgrade apt-get upgrade 升级所有可升级的软件包   apt autoremove apt-get autoremove 自动删除不需要的包   apt full-upgrade apt-get dist-upgrade 在升级软件包时自动处理依赖关系   apt search apt-cache search 搜索应用程序   apt show apt-cache show 显示装细节   apt list  列出包含条件的包（已安装，可升级等）   apt edit-sources  编辑源列表    列出所有手动安装软件\n$ apt-mark showmanual snap \u0026amp; flatpak A fundamental difference between Snap and Flatpak\nFlatpak is designed to install and update “apps”; user-facing software such as video editors, chat programs and more.\nsnaps can install anything which contains a kernel, printer drivers, audio subsystems and more.\nSnap and Flatpak are the software behind two universal Linux app stores: the Snap Store and Flathub.\nopenSUSE 群讨论\nFlatpak使用bubblewrap来隔离应用程序，bwrap是非常轻量化的沙箱程序，因此攻击面极小。但bwrap需要用户对Linux程序工作方式有准确的了解（使用哪些syscall），Flatpak相当于充当了一个bwrap的前端帮助控制bwrap权限。\n目前Flatpak的问题在于seccomp权限太过广泛，但目前Flatpak维护者已经意识到了这个问题（注释：在他们踩了一次坑之后），已经计划打算解决了。\n另一个问题是程序请求的权限过于广泛，但这更多是一个决策问题而不是技术问题，而且你可以用Flatseal手动调整权限。\nFlatpak你不能用常规程序方式来理解，每个程序都是一个完全独立的空间，只有给予了权限才有对应访问权，也可以用Portals调用文件选择器来获得单独一个文件的完全访问权，Flatpak版的Steam是把所有程序配置文件放在~/.var/app里面了，类似安卓下面的分区存储做法。\nAppImage就只是个自挂载程序，自带的文件透明挂载到它自己的根文件系统下面，所以依然依赖主机的一部分库。所以是的，跟打包者用的系统有关系。\nFlatpak不是这种机制，每个Flatpak空间是完全空白的，需要打包者自己选择加入哪些东西，所以Flatpak跨发行版的兼容性也更好。\n良好打包的AppImage可以有很好的跨发行版兼容性，但是代价就是需要手工测试每个发行版下面的效果。在跨发行版兼容性这点上我更看好Flatpak。\n最后，不要跟我提Snap，我不想碰那个东西，也对它没有研究的兴趣。\nFlatpak确实有很多可取之处，或者不能说是Flatpak可取，而是Linux桌面软件生态现状决定了，只有更激进的手段才能改变现状。\nAppImage那种策略还是过于不痛不痒了，结果就是程序仅仅是被打包成一个个单文件，但背后的库依赖地狱、权限隔离问题一个都没解决。\n但AppImage作者的想法本来也不是靠AppImage颠覆，他是希望Linux能够重新恢复LSB，确保发行版之间的兼容性本身可靠而不是依赖Flatpak这些技术，就类似于Windows上的软件不需要什么沙箱模拟器，你几乎可以保证旧版本的软件能在新版本运行。\n其实也可以说明，微软那种在桌面上采取的策略，很可能难以在Linux社区里推广开来，微软那种做法，确保绝对的向下兼容性，不是谁都有精力来做的。\n比如说如果让微软来做Wayland，那微软根本就不会把Wayland做出来，而是把X11一直迭代、削减臃肿功能直到性能和现代化图形技术栈的性能相匹敌，同时确保向下兼容性。而最新一代的X11很可能和最早的X11已经彻底不一样了，甚至会有“检测程序版本然后自动匹配对应的X11功能”这些奇怪的兼容性策略出来。或许有一天微软会把新项目叫做Wayland，但这个改名也仅仅是营销目的而不是技术目的。\n毕竟LSB已经没了，Ubuntu甚至砍掉32位兼容性，也可以说明其实Linux这边并没有太多人在乎这问题。\n毕竟“反正源代码都在那，重新编译一遍不就好了吗”\nsnap \u0026ldquo;canonical-livepatch\u0026rdquo; has \u0026ldquo;install-snap\u0026rdquo; change in progress\nSnap 包是 Ubuntu 16.04 LTS 发布时引入的新应用格式包。目前已流行在很多 Linux 发行版上。并且可以很方便地安装常用软件，如 VLC、Sublime Text、VSCode、Node、WPS等\n当你在安装完 Snap 后，你会发现在在根目录下会出现如 /dev/loop0 的挂载点，这些挂载点正是 Snap 软件包的目录。\n  原因是软件之前安装了一次，只是安装失败。\n$ snap changessnap abort 5\t## 5 为安装失败软件的 ID   现在重新安装\n  一些软件最好在官网下载或在 Snap 中下载，官方 Repository 可能并不新，比如 VLC。\ntasksel: Install Group Software 安装\n$ sudo apt install tasksel list tasks\n$ tasksel --list-tasks displays description\n$ tasksel --task-desc dns-server install\n$ sudo apt install dns-server LVM 在对磁盘分区的大小进行规划时，往往不能确定这个分区要使用的空间的大小。而使用 fdisk、gdisk 等工具对磁盘分区后，每个分区的大小就固定了。如果分区设置的过大，就白白浪费了磁盘空间；如果分区设置的过小，就会导致空间不够用的情况出现。对于分区过小的问题，可以从新划分磁盘的分区，或者通过软连接的方式将此分区的目录链接到另外一个分区。这样虽然能够临时解决问题，但是给管理带来了麻烦。类似的问题可以通过 LVM 来解决。\nLVM 是什么 LVM 是 Logical Volume Manager 的缩写，中文一般翻译为 \u0026ldquo;逻辑卷管理\u0026rdquo;，它是 Linux 下对磁盘分区进行管理的一种机制。LVM 是建立在磁盘分区和文件系统之间的一个逻辑层，系统管理员可以利用 LVM 在不重新对磁盘分区的情况下动态的调整分区的大小。如果系统新增了一块硬盘，通过 LVM 就可以将新增的硬盘空间直接扩展到原来的磁盘分区上。\nLVM 的优点如下：\n 文件系统可以跨多个磁盘，因此大小不再受物理磁盘的限制。 可以在系统运行状态下动态地扩展文件系统大小。 可以以镜像的方式冗余重要数据到多个物理磁盘上。 可以很方便地导出整个卷组，并导入到另外一台机器上。  LVM 也有一些缺点：\n 在从卷组中移除一个磁盘的时候必须使用 reducevg 命令(这个命令要求root权限，并且不允许在快照卷组中使用)。 当卷组中的一个磁盘损坏时，整个卷组都会受影响。 因为增加了一个逻辑层，存储的性能会受影响。  LVM 的优点对服务器的管理非常有用，但对于桌面系统的帮助则没有那么显著，所以需要我们根据使用的场景来决定是否应用 LVM。\nLVM 中的基本概念 通过 LVM 技术，可以屏蔽掉磁盘分区的底层差异，在逻辑上给文件系统提供了一个卷的概念，然后在这些卷上建立相应的文件系统。下面是 LVM 中主要涉及的一些概念。\n **物理存储设备(Physical Media)：**指系统的存储设备文件，比如 /dev/sda、/dev/sdb 等。 **PV(物理卷 Physical Volume)：**指硬盘分区或者从逻辑上看起来和硬盘分区类似的设备(比如 RAID 设备)。 **VG(卷组 Volume Group)：**类似于非 LVM 系统中的物理硬盘，一个 LVM 卷组由一个或者多个 PV(物理卷)组成。 **LV(逻辑卷 Logical Volume)：**类似于非 LVM 系统上的磁盘分区，LV 建立在 VG 上，可以在 LV 上建立文件系统。 **PE(Physical Extent)：**PV(物理卷)中可以分配的最小存储单元称为 PE，PE 的大小是可以指定的。 **LE(Logical Extent)：**LV(逻辑卷)中可以分配的最小存储单元称为 LE，在同一个卷组中，LE 的大小和 PE 的大小是一样的，并且一一对应。  可以这么理解，LVM 是把硬盘的分区分成了更小的单位(PE)，再用这些单元拼成更大的看上去像分区的东西(PV)，进而用 PV 拼成看上去像硬盘的东西(VG)，最后在这个新的硬盘上创建分区(LV)。文件系统则建立在 LV 之上，这样就在物理硬盘和文件系统中间添加了一层抽象(LVM)。下图大致描述了这些概念之间的关系：\n对上图中的结构做个简单的介绍：\n两块物理硬盘 A 和 B 组成了 LVM 的底层结构，这两块硬盘的大小、型号可以不同。PV 可以看做是硬盘上的分区，因此可以说物理硬盘 A 划分了两个分区，物理硬盘 B 划分了三个分区。然后将前三个 PV 组成一个卷组 VG1，后两个 PV 组成一个卷组 VG2。接着在卷组 VG1 上划分了两个逻辑卷 LV1 和 LV2，在卷组 VG2 上划分了一个逻辑卷 LV3。最后，在逻辑卷 LV1、LV2 和 LV3 上创建文件系统，分别挂载在 /usr、/home 和 /var 目录。\nLVM 工具 在安装 Linux 时，如果选择使用 LVM 创建分区，就会安装 LVM 相关的工具。当前这个软件包的名称为 lvm2，其中包含了大量 LVM 工具。比如单是查看 LVM 相关实体状态的命令就有如下一些：\n$ sudo pvscan $ sudo pvs $ sudo pvdisplay $ sudo vgscan $ sudo vgs $ sudo vgdisplay $ sudo lvscan $ sudo lvs $ sudo lvdisplay 如果安装系统时没有默认安装 LVM 工具包，可以通过下面的命令安装它们：\n$ sudo apt update $ sudo apt install lvm2 接下来我们通过例子来演示如何使用 LVM 来一步步的创建出逻辑卷(LV)，然后在 LV 上创建文件系统并挂载到 Linux 系统中。\n使用 gdisk 对物理磁盘进行分区 目前常见的磁盘分区格式有两种，MBR 分区和 GPT 分区。\nMBR 分区，MBR 的意思是 \u0026ldquo;主引导记录\u0026rdquo;。MBR 最大支持 2TB 容量，在容量方面存在着极大的瓶颈。\nGPT 分区，GPT 意为 GUID 分区表，它支持的磁盘容量比 MBR 大得多。这是一个正逐渐取代 MBR 的新标准，它是由 UEFI 辅住而形成的，将来 UEFI 用于取代老旧的 BIOS，而 GPT 则取代老旧的 MBR。\n使用 fdisk 工具创建 MBR 磁盘分区，而 gdisk 是 Linux 系统中 GPT 格式的磁盘分区管理工具。\n假设我们的 Linux 系统中增加了一块新的磁盘，系统对应的设备名为 /dev/sdb，下面我们通过 gdisk 命令对这个磁盘进行分区。\n在用 gdisk 命令对磁盘分区前，我们先用 parted 命令查看 /dev/sdb 当前的分区情况：\n$ sudo parted /dev/sdb print 下面通过 gdisk 命令创建分区：\n$ sudo gdisk /dev/sdb 通过 p 命令可以查看磁盘当前的状态：输出中的前几行是磁盘的基本信息，比如总大小，一共有多少个扇区(sector)，每个扇区的大小，当前剩余的空间等等。\n然后是已经存在的分区信息：\n 第一列 Number 显示了分区的编号，比如 1 号指 /dev/sdb1。 第二列 Start 表示磁盘分区的起始位置。 第三列 End 表示磁盘分区的结束位置。 第四列 Size 显示分区的容量。 第五列 Code 和第六列 Name 显示分区类型的 ID和名称，比如 Linux filesystem 为 8300，Linux swap 为 8200，Linux LVM 为 8e00。  通过 n 命令来创建新分区：\n分区编号和开始/结束的扇区都直接通过回车选择默认值，这样所有的磁盘空间都划分到了一个分区中，然后输入 8e00 说明我们要创建的分区类型为 Linux LVM。最后输入 w 命令并确认执行分区操作。分区成功后可通过 p 命令查看我们创建的分区的信息。\n创建物理卷 PV # pvcreate DEVICE 现在我们可以基于磁盘分区 /dev/sdb1 来创建 LVM 物理卷(LV)，可以通过 pvcreate 命令来完成：\n$ sudo pvcreate /dev/sdb1 此时 /dev/sdb1 已经完成了从磁盘分区到 PV 的华丽转身！注意上面的命令，磁盘分区被直接转换成了 PV，连名称都没有变化！我们可以通过 pvs 命令查看 /dev/sdb1，目前它还没有被加入到 VG 中。\n创建卷组 VG # vgcreate \u0026lt;volume_group\u0026gt; \u0026lt;physical_volume1\u0026gt; \u0026lt;physical_volume2\u0026gt; ... 基于一个或多个 PV，可以创建 VG。我们使用刚才创建的 PV /dev/sdb1 来创建一个名称为 nickvg 的 VG：\n$ sudo vgcreate -s 32G nickvg /dev/sdb1 注意 vgcreate 命令中的 -s 选项，它指定了 PE(Physical Extent) 的大小。可以通 vgs 命令观察 VG 的信息：\n$ sudo vgs nickvg 如果目标 VG 已经存在，则使用 vgextend 把 PV 加入到 VG 中即可。\n# vgextend \u0026lt;卷组名\u0026gt; \u0026lt;物理卷\u0026gt; 创建逻辑卷 LV # lvcreate -L \u0026lt;卷大小\u0026gt; \u0026lt;卷组名\u0026gt; -n \u0026lt;卷名\u0026gt; 有了 VG 就可以创建逻辑卷 LV 了，lvcreate 命令用来创建 LV，让我们在前面创建的 nickvg 上创建名称为 nicklv00 的 LV：\n$ sudo lvcreate -L 15G -n nicklv00 nickvg 选项 -L 指定新建 LV 的容量，这里是 15G；选项 -n 则指定新建 LV 的名称，这里为 nicklv00。可以通过 lvs 命令观察 LV 的信息，注意需要同时指出 LV 所在的 VG：\n$ sudo lvs nickvg/nicklv00 如果你想让要创建的逻辑卷拥有卷组（VG）的所有未使用空间，请使用以下命令：\n# lvcreate -l +100%FREE \u0026lt;volume_group\u0026gt; -n \u0026lt;logical_volume\u0026gt; 格式化逻辑卷(创建文件系统) # mkfs.\u0026lt;类型\u0026gt; /dev/mapper/\u0026lt;卷组名\u0026gt;-\u0026lt;卷名\u0026gt; # mount /dev/mapper/\u0026lt;卷组名\u0026gt;-\u0026lt;卷名\u0026gt; \u0026lt;挂载点\u0026gt; 当我们创建 LV nickvg/nicklv00 时，其实是创建了名称为 /dev/nickvg/nicklv00 的设备文件。\n现在你的逻辑卷应该已经在/dev/mapper/和/dev/YourVolumeGroupName中了。\n现在我们来格式化这个逻辑卷(在该 LV 上创建文件系统)，目标为比较常见的 ext4 格式：\n$ sudo mkfs.ext4 /dev/nickvg/nicklv00 然后创建个目录，比如 /home/doc，并把新建的文件系统挂载到这个目录上：\n$ sudo mkdir /home/doc $ sudo mount /dev/nickvg/nicklv00 /home/doc 最后可以通过 df 命令查看这个文件系统的使用情况。\n开机自动挂载 编辑 /etc/fstab 文件：\n$ sudo vim /etc/fstab 把下面的行添加的文件末尾并保存文件：\n/dev/mapper/nickvg-nicklv00 /home/doc ext4 defaults 0 2 调整逻辑卷 同时缩小逻辑卷和其文件系统\n 注意： 只有ext2，ext3，ext4，ReiserFS和 XFS 文件系统支持以下操作。\n 将MyVolGroup组中的逻辑卷mediavol扩大10GiB，并同时扩大其文件系统：\n# lvresize -L +10G --resizefs MyVolGroup/mediavol 将MyVolGroup组中的逻辑卷mediavol大小调整为15GiB，并同时调整其文件系统：\n# lvresize -L 15G --resizefs MyVolGroup/mediavol 将卷组中的所有剩余空间分配给mediavol：\n# lvresize -l +100%FREE --resizefs MyVolGroup/mediavol 重命名卷 重命名卷组\n要重命名一个卷组，请使用vgrename(8)命令。\n可使用下面的任意一条命令将卷组vg02重命名为my_volume_group\n# vgrename /dev/vg02 /dev/my_volume_group # vgrename vg02 my_volume_group 重命名逻辑卷\n要重命名一个逻辑卷，请使用lvrename(8)命令。\n可使用下面的任意一条命令将vg02组中的逻辑卷lvold重命名为lvnew.\n# lvrename /dev/vg02/lvold /dev/vg02/lvnew # lvrename vg02 lvold lvnew 移除逻辑卷 警告： 在移除逻辑卷之前，请先备份好数据以免丢失！\n首先，找到你所要移除的逻辑卷的名称。你可以使用以下命令来查看系统的所有逻辑卷：\n# lvs 接下来，找到你所要移除的逻辑卷的挂载点\n$ lsblk 并卸载它：\n# umount /\u0026lt;mountpoint\u0026gt; 最后，使用以下命令来移除逻辑卷：\n# lvremove \u0026lt;volume_group\u0026gt;/\u0026lt;logical_volume\u0026gt; 例如：\n# lvremove VolGroup00/lvolhome 请输入y来确定你要执行移除逻辑卷操作。\n此外，请不要忘了更新/etc/fstab。\n你可以再次使用lvs命令来确认你的逻辑卷已被移除。\nLVM 快照 LVM 机制还提供了对 LV 做快照的功能，也就是说可以给文件系统做一个备份，这也是设计 LVM 快照的主要目的。LVM 的快照功能采用写时复制技术(Copy-On-Write，COW)，这比传统的备份技术的效率要高很多。创建快照时不用停止服务，就可以对数据进行备份。说明：LVM 还支持 thin 类型的快照，但是本文中的快照都是指 COW 类型的快照。\nLVM 采用的写时复制，是指当 LVM 快照创建的时候，仅创建到实际数据的 inode 的硬链接(hark-link)而已。只要实际的数据没有改变，快照就只包含指向数据的 inode 的指针，而非数据本身。快照会跟踪原始卷中块的改变，一旦你更改了快照对应的文件或目录，这个时候原始卷上将要改变的数据会在改变之前拷贝到快照预留的空间。\nLVM 快照的原理\n创建快照实际上也是创建了一个逻辑卷，只不过该卷的属性与普通逻辑卷的属性有些不一样。我们可以通过下图来理解快照数据卷(图中的实线框表示快照区域，虚线框表示文件系统)：\n左图为最初创建的快照数据卷状况，LVM 会预留一个区域 (比如左图的左侧三个 PE 区块) 作为数据存放处。 此时快照数据卷内并没有任何数据，而快照数据卷与源数据卷共享所有的 PE 数据， 因此你会看到快照数据卷的内容与源数据卷中的内容是一模一样的。 等到系统运行一阵子后，假设 A 区域的数据被更新了(上面右图所示)，则更新前系统会将该区域的数据移动到快照数据卷中， 所以在右图的快照数据卷中被占用了一块 PE 成为 A，而其他 B 到 I 的区块则还是与源数据卷共享！\n由於快照区与原本的 LV 共享很多 PE 区块，因此快照区与被快照的 LV 必须要在同一个 VG 上头，下面两点非常重要：\n VG中需要预留存放快照本身的空间，不能全部被占满。 快照所在的 VG 必须与被备份的 LV 的 VG 相同，否则创建快照会失败。  创建 LVM 快照\n其实快照就是一个特殊类型的数据卷，所以创建快照的命令和创建数据卷的命令相同，也是 lvcreate：\n# lvcreate --size 100M --snapshot --name snap01 /dev/vg0/lv 此时如果把 LV snap01 挂载到系统中，里面的内容和 LV /dev/vg0/lv 中的内容是一样的。\n创建的快照的大小可以比源数据卷小，但是当源数据卷中的数据更新过多时会导致快照容量不足而引起的错误并丢失数据。如上你可以修改少于100M的数据，直到该快照逻辑卷空间不足为止。\n创建快照后，如果源数据卷中的文件被更新了，快照系统中则保存着其创建快照时的版本。\n还原部分数据\n如果我们明确的知道需要还原某个文件，可以挂载快照数据卷，直接拷贝其中旧版本的文件即可。\n合并快照(merge snapshot)\n要将逻辑卷卷\u0026rsquo;lv' 恢复到创建快照\u0026rsquo;snap01\u0026rsquo;时的状态，即还原整个数据卷上的数据，请使用：\n# lvconvert --merge /dev/vg0/snap01 如果逻辑卷处于活动状态，则在下次重新启动时将进行合并（merging）(合并（merging）甚至可在LiveCD中进行)。\n注意： 合并后快照将被删除。\n可以拍摄多个快照，每个快照都可以任意与对应的逻辑卷合并。\n快照可以被挂载，并可用dd或者tar备份。使用dd备份的快照的大小为拍摄快照后对应逻辑卷中变更过文件的大小。 要使用备份，只需创建并挂载一个快照，并将备份写入或解压到其中。再将快照合并到对应逻辑卷即可。\n快照主要用于提供一个文件系统的拷贝，以用来备份; 比起直接备份分区，使用快照备份可以提供一个更符合原文件系统的镜像。\nSystemd LINUX PID 1 和 SYSTEMD 要说清 Systemd，得先从Linux操作系统的启动说起。Linux 操作系统的启动首先从 BIOS 开始，然后由 Boot Loader 载入内核，并初始化内核。内核初始化的最后一步就是启动 init 进程。这个进程是系统的第一个进程，PID 为 1，又叫超级进程，也叫根进程。它负责产生其他所有用户进程。所有的进程都会被挂在这个进程下，如果这个进程退出了，那么所有的进程都被 kill 。如果一个子进程的父进程退了，那么这个子进程会被挂到 PID 1 下面。（注：PID 0 是内核的一部分，主要用于内进换页，参看：Process identifier）\nSysV Init PID 1 这个进程非常特殊，其主要就任务是把整个操作系统带入可操作的状态。比如：启动 UI – Shell 以便进行人机交互，或者进入 X 图形窗口。传统上，PID 1 和传统的 Unix System V 相兼容的，所以也叫 sysvinit，这是使用得最悠久的 init 实现。Unix System V 于1983年 release。\n在 sysvint 下，有好几个运行模式，又叫 runlevel。比如：常见的 3 级别指定启动到多用户的字符命令行界面，5 级别指定启起到图形界面，0 表示关机，6 表示重启。其配置在 /etc/inittab 文件中。\n与此配套的还有 /etc/init.d/ 和 /etc/rc[X].d，前者存放各种进程的启停脚本（需要按照规范支持 start，stop子命令），后者的 X 表示不同的 runlevel 下相应的后台进程服务，如：/etc/rc3.d 是 runlevel=3 的。 里面的文件主要是 link 到 /etc/init.d/ 里的启停脚本。其中也有一定的命名规范：S 或 K 打头的，后面跟一个数字，然后再跟一个自定义的名字，如：S01rsyslog，S02ssh。S 表示启动，K表示停止，数字表示执行的顺序。\nUpStart Unix 和 Linux 在 sysvint 运作多年后，大约到了2006年的时候，Linux内核进入2.6时代，Linux有了很多更新。并且，Linux开始进入桌面系统，而桌面系统和服务器系统不一样的是，桌面系统面临频繁重启，而且，用户会非常频繁的使用硬件的热插拔技术。于是，这些新的场景，让 sysvint 受到了很多挑战。\n比如，打印机需要CUPS等服务进程，但是如果用户没有打机印，启动这个服务完全是一种浪费，而如果不启动，如果要用打印机了，就无法使用，因为sysvint 没有自动检测的机制，它只能一次性启动所有的服务。另外，还有网络盘挂载的问题。在 /etc/fstab 中，负责硬盘挂载，有时候还有网络硬盘（NFS 或 iSCSI）在其中，但是在桌面机上，有很可能开机的时候是没有网络的， 于是网络硬盘都不可以访问，也无法挂载，这会极大的影响启动速度。sysvinit 采用 netdev 的方式来解决这个问题，也就是说，需要用户自己在 /etc/fstab 中给相应的硬盘配置上 netdev 属性，于是 sysvint 启动时不会挂载它，只有在网络可用后，由专门的 netfs 服务进程来挂载。这种管理方式比较难以管理，也很容易让人掉坑。\n所以，Ubuntu 开发人员在评估了当时几个可选的 init 系统后，决定重新设计这个系统，于是，这就是我们后面看到的 upstart 。 upstart 基于事件驱动的机制，把之前的完全串行的同步启动服务的方式改成了由事件驱动的异步的方式。比如：如果有U盘插入，udev 得到通知，upstart 感知到这个事件后触发相应的服务程序，比如挂载文件系统等等。因为使用一个事件驱动的玩法，所以，启动操作系统时，很多不必要的服务可以不用启动，而是等待通知，lazy 启动。而且事件驱动的好处是，可以并行启动服务，他们之间的依赖关系，由相应的事件通知完成。\nupstart 有着很不错的设计，其中最重要的两个概念是 Job 和 Event。\nJob 有一般的Job，也有service的Job，并且，upstart 管理了整个 Job 的生命周期，比如：Waiting, Starting, pre-Start, Spawned, post-Start, Running, pre-Stop, Stopping, Killed, post-Stop等等，并维护着这个生命周期的状态机。\nEvent 分成三类，signal, method 和 hooks。signal 就是异步消息，method 是同步阻塞的。hooks 也是同步的，但介于前面两者之间，发出hook事件的进程必须等到事件完成，但不检查是否成功。\n但是，upstart 的事件非常复杂，也非常纷乱，各种各样的事件（事件没有归好类）导致有点凌乱。不过因为整个事件驱动的设计比之前的 sysvinit 来说好太多，所以，也深得欢迎。\nSystemd 直到2010的有一天，一个在 RedHat工作的工程师 Lennart Poettering 和 Kay Sievers ，开始引入了一个新的 init 系统—— systemd。这是一个非常非常有野心的项目，这个项目几乎改变了所有的东西，systemd 不但想取代已有的 init 系统，而且还想干更多的东西。\nLennart 同意 upstart 干的不错，代码质量很好，基于事件的设计也很好。但是他觉得 upstart 也有问题，其中最大的问题还是不够快，虽然 upstart 用事件可以达到一定的启动并行度，但是，本质上来说，这些事件还是会让启动过程串行在一起。 如：NetworkManager 在等 D-Bus 的启动事件，而 D-Bus 在等 syslog 的启动事件。\nLennart 认为，实现上来说，upstart 其实是在管理一个逻辑上的服务依赖树，但是这个服务依赖树在表现形式上比较简单，你只需要配置——“启动 B好了就启动A”或是“停止了A后就停止B”这样的规则。但是，Lennart 说，这种简单其实是有害的（this simplification is actually detrimental）。他认为，\n  从一个系统管理的角度出来，他一开始会设定好整个系统启动的服务依赖树，但是这个系统管理员要人肉的把这个本来就非常干净的服务依整树给翻译成计算机看的懂的 Event/Action 形式，而且 Event/Action 这种配置方式是运行时的，所以，你需要运行起来才知道是什么样的。\n  Event逻辑从头到脚到处都是，这个事件扩大了运维的复杂度，还不如之前的 sysvint。 也就是说，当用户配置了 “启动 D-Bus 后请启动 NetworkManager”， 这个 upstart 可以干，但是反过来，如果，用户启动 NetworkManager，我们应该先去启动他的前置依赖 D-Bus，然而你还要配置相应的反向 Event。本来，我只需要配置一条依赖的，结果现在我要配置很多很多情况下的Event。\n  最后，upstart 里的 Event 的并不标准，很混乱，没有良好的定义。比如：既有，进程启动，运行，停止的事件，也有USB设备插入、可用、拔出的事件，还有文件系统设备being mounted、 mounted 和 umounted 的事件，还有AC电源线连接和断开的事件。你会发现，这进程启停的、USB的、文件系统的、电源线的事件，看上去长得很像， 但是没有被标准化抽像出来掉，因为绝大多数的事件都是三元组：start, condition, stop 。这种概念设计模型并没有在 upstart 中出现。因为 upstart 被设计为单一的事件，而忽略了逻辑依赖。\n  当然，如果 systemd 只是解决 upstart 的问题，他就改造 upstart 就好了，但是 Lennart 的野心不只是想干个这样的事，他想干的更多。\n首先，systemd 清醒的认识到了 init 进程的首要目标是要让用户快速的进入可以操作OS的环境，所以，这个速度一定要快，越快越好，所以，systemd 的设计理念就是两条：\n To start less. And to start more in parallel.  也就是说，按需启动，能不启动就不启动，如果要启动，能并行启动就并行启动，包括你们之间有依赖，我也并行启动。按需启动还好理解，那么，有依赖关系的并行启动，它是怎么做到的？这里，systemd 借鉴了 MacOS 的 Launchd 的玩法（在Youtube上有一个分享——Launchd: One Program to Rule them All，在苹果的开源网站上也有相关的设计文档——About Daemons and Services）\n要解决这些依赖性，systemd 需要解决好三种底层依赖—— Socket， D-Bus ，文件系统。\n  Socket依赖。如果服务C依赖于服务S的socket，那么就要先启动S，然后再启动C，因为如果C启动时找不到S的Socket，那么C就会失败。systemd 可以帮你在S还没有启动好的时候，建立一个socket，用来接收所有的C的请求和数据，并缓存之，一旦S全部启动完成，把systemd替换好的这个缓存的数据和Socket描述符替换过去。\n  D-Bus依赖。D-Bus 全称 Desktop Bus，是一个用来在进程间通信的服务。除了用于用户态进程和内核态进程通信，也用于用户态的进程之前。现在，很多的现在的服务进程都用 D-Bus 而不是Socket来通信。比如：NetworkManager 就是通过 D-Bus 和其它服务进程通讯的，也就是说，如果一个进程需要知道网络的状态，那么就必需要通过 D-Bus 通信。D-Bus 支持 “Bus Activation”的特性。也就是说，A要通过 D-Bus 服务和B通讯，但是B没有启动，那么 D-Bus 可以把B起来，在B启动的过程中，D-Bus 帮你缓存数据。systemd 可以帮你利用好这个特性来并行启动 A 和 B。\n  文件系统依赖。系统启动过程中，文件系统相关的活动是最耗时的，比如挂载文件系统，对文件系统进行磁盘检查（fsck），磁盘配额检查等都是非常耗时的操作。在等待这些工作完成的同时，系统处于空闲状态。那些想使用文件系统的服务似乎必须等待文件系统初始化完成才可以启动。systemd 参考了 autofs 的设计思路，使得依赖文件系统的服务和文件系统本身初始化两者可以并发工作。autofs 可以监测到某个文件系统挂载点真正被访问到的时候才触发挂载操作，这是通过内核 automounter 模块的支持而实现的。比如一个 open() 系统调用作用在某个文件系统上的时候，而这个文件系统尚未执行挂载，此时 open() 调用被内核挂起等待，等到挂载完成后，控制权返回给 open() 系统调用，并正常打开文件。这个过程和 autofs 是相似的。\n  下图来自 Lennart 的演讲里的一页PPT，展示了不同 init 系统的启动。\n除此之外，systemd 还在启动时管理好了一些下面的事。\n用C语言取代传统的脚本式的启动。前面说过，sysvint 用 /etc/rcX.d 下的各种脚本启动。然而这些脚本中需要使用 awk, sed, grep, find, xargs 等等这些操作系统的命令，这些命令需要生成进程，生成进程的开销很大，关键是生成完这些进程后，这个进程就干了点屁大的事就退了。换句话说就是，我操作系统干了那么多事为你拉个进程起来，结果你就把个字串转成小写就退了，把我操作系统当什么了？\n在正常的一个 sysvinit 的脚本里，可能会有成百上千个这样的命令。所以，慢死。因此，systemd 全面用 C 语言全部取代了。一般来说，sysvinit 下，操作系统启动完成后，用 echo $$ 可以看到，pid 被分配到了上千的样子，而 systemd 的系统只是上百。\n另外，systemd 是真正一个可以管住服务进程的——可以跟踪上服务进程所fork/exec出来的所有进程。\n  我们知道， 传统 Unix/Linux 的 Daemon 服务进程的最佳实践基本上是这个样子的（具体过程可参看这篇文章“[SysV Daemon](http://0pointer.de/public/systemd-man/daemon.html#SysV Daemons)”）\n 进程启动时，关闭所有的打开的文件描述符（除了标准描述符0,1,2），然后重置所有的信号处理。 调用 fork() 创建子进程，在子进程中 setsid()，然后父进程退出（为了后台执行） 在子进程中，再调用一次 fork()，创建孙子进程，确定没有交互终端。然后子进程退出。 在孙子进程中，把标准输入标准输出标准错误都连到 /dev/null 上，还要创建 pid 文件，日志文件，处理相关信号 …… 最后才是真正开始提供服务。    在上面的这个过程中，服务进程除了两次 fork 外还会 fork 出很多很多的子进程（比如说一些Web服务进程，会根据用户的请求链接来 fork 子进程），这个进程树是相当难以管理的，因为，一旦父进程退出来了，子进程就会被挂到 PID 1下，所以，基本上来说，你无法通过服务进程自已给定的一个pid文件来找到所有的相关进程（这个对开发者的要求太高了），所以，在传统的方式下用脚本启停服务是相当相当的 Buggy 的，因为无法做对所有的服务生出来的子子孙孙做到监控。\n  为了解决这个问题，upstart 通过变态的 strace 来跟踪进程中的 fork() 和 exec() 或 exit() 等相关的系统调用。这种方法相当笨拙。 systemd 使用了一个非常有意思的玩法来 tracking 服务进程生出来的所有进程，那就是用 cgroup （我在 Docker 的基础技术“cgroup篇”中讲过这个东西）。cgroup主要是用来管理进程组资源配额的事，所以，无论服务如何启动新的子进程，所有的这些相关进程都会同属于一个 cgroup，所以，systemd 只需要简单的去遍历一下相应的 cgroup 的那个虚文件系统目录下的文件，就可以正确的找到所有的相关进程，并将他们一一停止。\n  另外，systemd 简化了整个 daemon 开发的过程：\n 不需要两次 fork()，只需要实现服务本身的主逻辑就可以了。 不需要 setsid()，systemd 会帮你干 不需要维护 pid文件，systemd 会帮处理。 不需要管理日志文件或是使用syslog，或是处理HUP的日志reload信号。把日志打到 stderr 上，systemd 帮你管理。 处理 SIGTERM 信号，这个信号就是正确退出当前服务，不要做其他的事。 ……  除此之外，systemd 还能——\n 自动检测启动的服务间有没有环形依赖。 内建 autofs 自动挂载管理功能。 日志服务。systemd 改造了传统的 syslog 的问题，采用二进制格式保存日志，日志索引更快。 快照和恢复。对当前的系统运行的服务集合做快照，并可以恢复。 ……  还有好多好多，他接管很多很多东西，于是就让很多人不爽了，因为他在干了很多本不属于 PID 1 的事。\nSystemd 争论和八卦 于是 systemd 这个东西成了可能是有史以来口水战最多的一个开源软件了。systemd 饱受各种争议，最大的争议就是他破坏了 Unix 的设计哲学（相关的哲学可以读一下《Unix编程艺术》），干了一个大而全而且相当复杂的东西。当然，Lennart 并不同意这样的说法，他后来又写一篇blog “The Biggest Myths”来解释 systemd 并不是这样的，大家可以前往一读。\n这个争议大到什么样子呢？2014 年，Debian Linux 因为想准备使用 systemd 来作为标准的 init 守护进程来替换 sysvinit 。而围绕这个事的争论达到了空前的热度，争论中充满着仇恨，systemd 的支持者和反对者都在互相辱骂，导致当时 Debian 阵营开始分裂。还有人给 Lennart 发了死亡威胁的邮件，用比特币雇凶买杀手，扬言要取他的性命，在Youbute上传了侮辱他的歌曲，在IRC和各种社交渠道上给他发下流和侮辱性的消息。这已经不是争议了，而是一种不折不扣的仇恨！\n于是，Lennart 在 Google Plus 上发了贴子，批评整个 Linux 开源社区和 Linus 本人。他大意说，\n 这个社区太病态了，全是 ass holes，你们不停用各种手段在各种地方用不同的语言和方式来侮辱和漫骂我。我还是一个年轻人，我从来没有经历过这样的场面，但是今天我已经对这种场面很熟悉了。我有时候说话可能不准确，但是我不会像他样那样说出那样的话，我也没有被这些事影响，因为我脸皮够厚，所以，为什么我可以在如何大的反对声面前让 systemd 成功，但是，你们 Linux 社区太可怕了。你们里面的有精神病的人太多了。另外，对于Linus Torvalds，你是这个社区的 Role Model，但可惜你是一个 Bad Role Model，你在社区里的刻薄和侮辱性的言行，基本从一定程度上鼓励了其它人跟你一样，当然，并不只是你一个人的问题，而是在你周围聚集了一群和你一样的这样干的人。送你一句话—— A fish rots from the head down ！一条鱼是从头往下腐烂的……\n 这篇契文很长，喜欢八卦的同学可以前往一读。感受一下 Lennart 当时的心态（我觉得能算上是非常平稳了）。\nLinus也在被一媒体问起 systemd 这个事来（参看“Torvalds says he has no strong opinions on systemd”），Linus在采访里说，\n 我对 systemd 和 Lennart 的贴子没有什么强烈的想法。虽然，传统的 Unix 设计哲学—— “Do one thing and Do it well”，很不错，而且我们大多数人也实践了这么多年，但是这并不代表所有的真实世界。在历史上，也不只有systemd 这么干过。但是，我个人还是 old-fashioned 的人，至少我喜欢文本式的日志，而不是二进制的日志。但是 systemd 没有必要一定要有这样的品味。哦，我说细节了……\n 今天，systemd 占据了几乎所有的主流的 Linux 发行版的默认配置，包括：Arch Linux、CentOS、CoreOS、Debian、Fedora、Megeia、OpenSUSE、RHEL、SUSE企业版和 Ubuntu。而且，对于 CentOS, CoreOS, Fedora, RHEL, SUSE这些发行版来说，不能没有 systemd。（Ubuntu 还有一个不错的wiki – Systemd for Upstart Users 阐述了如何在两者间切换）\n其它 还记得在《缓存更新的套路》一文中，我说过，如果你要做好架构，首先你得把计算机体系结构以及很多老古董的基础技术吃透了。因为里面会有很多可以借鉴和相通的东西。那么，你是否从这篇文章里看到了一些有分布式架构相似的东西？\n比如：从 sysvinit 到 upstart 再到 systemd，像不像是服务治理？Linux系统下的这些服务进程，是不是很像分布式架构中的微服务？还有那个D-Bus，是不是很像SOA里的ESB？而 init 系统是不是很像一个控制系统？甚至像一个服务编排（Service Orchestration）系统？\n分布式系统中的服务之间也有很多依赖，所以，在启动一个架构的时候，如果我们可以做到像 systemd 那样并行启动的话，那么是不是就像是一个微服务的玩法了？\n嗯，你会发现，技术上的很多东西是相通的，也是互相有对方的影子，所以，其实技术并不多。关键是我们学在了表面还是看到了本质。\n命令 Systemd 是 Linux 系统工具，用来启动守护进程，已成为大多数发行版的标准配置。\n系统管理 Systemd 并不是一个命令，而是一组命令，涉及到系统管理的方方面面。\nsystemctl\nsystemctl是 Systemd 的主命令，用于管理系统。\n# 重启系统 $ sudo systemctl reboot # 关闭系统，切断电源 $ sudo systemctl poweroff # CPU停止工作 $ sudo systemctl halt # 暂停系统 $ sudo systemctl suspend # 让系统进入冬眠状态 $ sudo systemctl hibernate # 让系统进入交互式休眠状态 $ sudo systemctl hybrid-sleep # 启动进入救援状态（单用户状态） $ sudo systemctl rescue systemd-analyze\nsystemd-analyze命令用于查看启动耗时。\n# 查看启动耗时 $ systemd-analyze # 查看每个服务的启动耗时 $ systemd-analyze blame # 显示瀑布状的启动过程流$ $ systemd-analyze critical-chain # 显示指定服务的启动流 $ systemd-analyze critical-chain atd.service hostnamectl\nhostnamectl命令用于查看当前主机的信息。\n# 显示当前主机的信息 $ hostnamectl # 设置主机名。 $ sudo hostnamectl set-hostname rhel7 localectl\nlocalectl命令用于查看本地化设置。\n# 查看本地化设置 $ localectl # 设置本地化参数。 $ sudo localectl set-locale LANG=en_GB.utf8 $ sudo localectl set-keymap en_GB timedatectl\ntimedatectl命令用于查看当前时区设置。\n# 查看当前时区设置 $ timedatectl # 显示所有可用的时区 $ timedatectl list-timezones # 设置当前时区 $ sudo timedatectl set-timezone America/New_York $ sudo timedatectl set-time YYYY-MM-DD $ sudo timedatectl set-time HH:MM:SS loginctl\nloginctl命令用于查看当前登录的用户。\n# 列出当前session $ loginctl list-sessions # 列出当前登录用户 $ loginctl list-users # 列出显示指定用户的信息 $ loginctl show-user ruanyf Unit 含义\nSystemd 可以管理所有系统资源。不同的资源统称为 Unit（单元）。简单说，单元就是 Systemd 的最小功能单位，是单个进程的描述。一个个小的单元互相调用和依赖，组成一个庞大的任务管理系统，这就是 Systemd 的基本思想。\n由于 Systemd 要做的事情太多，导致单元有很多不同的种类，大概一共有12种。\n Service unit：系统服务 Target unit：多个 Unit 构成的一个组 Device Unit：硬件设备 Mount Unit：文件系统的挂载点 Automount Unit：自动挂载点 Path Unit：文件或路径 Scope Unit：不是由 Systemd 启动的外部进程 Slice Unit：进程组，资源分配 Snapshot Unit：Systemd 快照，可以切回某个快照 Socket Unit：进程间通信的 socket Swap Unit：swap 文件 Timer Unit：定时器  systemctl list-units命令可以查看当前系统的所有 Unit 。\n# 列出正在运行的 Unit $ systemctl list-units # 列出所有Unit，包括没有找到配置文件的或者启动失败的 $ systemctl list-units --all # 列出所有没有运行的 Unit $ systemctl list-units --all --state=inactive # 列出所有加载失败的 Unit $ systemctl list-units --failed # 列出所有正在运行的、类型为 service 的 Unit $ systemctl list-units --type=service Unit 的状态\nsystemctl status命令用于查看系统状态和单个 Unit 的状态。\n# 显示系统状态 $ systemctl status # 显示单个 Unit 的状态 $ sysystemctl status bluetooth.service # 显示远程主机的某个 Unit 的状态 $ systemctl -H root@rhel7.example.com status httpd.service 例如查看 httpd 状态\n$ sudo systemctl status httpd httpd.service - The Apache HTTP Server Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled) Active: active (running) since 金 2014-12-05 12:18:22 JST; 7min ago Main PID: 4349 (httpd) Status: \u0026#34;Total requests: 1; Current requests/sec: 0; Current traffic: 0 B/sec\u0026#34; CGroup: /system.slice/httpd.service ├─4349 /usr/sbin/httpd -DFOREGROUND ├─4350 /usr/sbin/httpd -DFOREGROUND ├─4351 /usr/sbin/httpd -DFOREGROUND ├─4352 /usr/sbin/httpd -DFOREGROUND ├─4353 /usr/sbin/httpd -DFOREGROUND └─4354 /usr/sbin/httpd -DFOREGROUND 12月 05 12:18:22 localhost.localdomain systemd[1]: Starting The Apache HTTP Server... 12月 05 12:18:22 localhost.localdomain systemd[1]: Started The Apache HTTP Server. 12月 05 12:22:40 localhost.localdomain systemd[1]: Started The Apache HTTP Server. 上面的输出结果含义如下。\n Loaded行：配置文件的位置，是否设为开机启动 Active行：表示正在运行 Main PID行：主进程ID Status行：由应用本身（这里是 httpd ）提供的软件当前状态 CGroup块：应用的所有子进程 日志块：应用的日志  除了status命令，systemctl还提供了三个查询状态的简单方法，主要供脚本内部的判断语句使用。\n# 显示某个 Unit 是否正在运行 $ systemctl is-active application.service # 显示某个 Unit 是否处于启动失败状态 $ systemctl is-failed application.service # 显示某个 Unit 服务是否建立了启动链接 $ systemctl is-enabled application.service Unit 管理\n对于用户来说，最常用的是下面这些命令，用于启动和停止 Unit（主要是 service）。\n# 立即启动一个服务 $ sudo systemctl start apache.service # 立即停止一个服务 $ sudo systemctl stop apache.service # 重启一个服务 $ sudo systemctl restart apache.service # 杀死一个服务的所有子进程 $ sudo systemctl kill apache.service # 重新加载一个服务的配置文件 $ sudo systemctl reload apache.service # 重载所有修改过的配置文件 $ sudo systemctl daemon-reload # 显示某个 Unit 的所有底层参数 $ systemctl show httpd.service # 显示某个 Unit 的指定属性的值 $ systemctl show -p CPUShares httpd.service # 设置某个 Unit 的指定属性 $ sudo systemctl set-property httpd.service CPUShares=500 有时候，该命令可能没有响应，执行systemctl stop服务停不下来。这时候就不得不\u0026quot;杀进程\u0026quot;了，向正在运行的进程发出kill信号，执行systemctl kill。\n依赖关系\nUnit 之间存在依赖关系：A 依赖于 B，就意味着 Systemd 在启动 A 的时候，同时会去启动 B。\nsystemctl list-dependencies命令列出一个 Unit 的所有依赖。\n$ systemctl list-dependencies nginx.service 上面命令的输出结果之中，有些依赖是 Target 类型（详见下文），默认不会展开显示。如果要展开 Target，就需要使用--all参数。\n$ systemctl list-dependencies --all nginx.service Unit 的配置文件 概述\n每一个 Unit 都有一个配置文件，告诉 Systemd 怎么启动这个 Unit 。\n除了系统默认的单元文件/lib/systemd/system，Systemd 默认从目录/etc/systemd/system/读取配置文件。但是，里面存放的大部分文件都是符号链接，指向目录/usr/lib/systemd/system/。那些支持 Systemd 的软件，安装的时候，也会自动在/usr/lib/systemd/system目录添加一个配置文件。\nsystemctl enable命令用于在/etc/systemd/system/和/usr/lib/systemd/system之间，建立符号链接关系。\n$ sudo systemctl enable clamd@scan.service # 等同于 $ sudo ln -s \u0026#39;/usr/lib/systemd/system/clamd@scan.service\u0026#39; \u0026#39;/etc/systemd/system/multi-user.target.wants/clamd@scan.service\u0026#39; 如果配置文件里面设置了开机启动，systemctl enable命令相当于激活开机启动。\n与之对应的，systemctl disable命令用于在两个目录之间，撤销符号链接关系，相当于撤销开机启动。\n$ sudo systemctl disable clamd@scan.service 配置文件的后缀名，就是该 Unit 的种类，比如sshd.socket。如果省略，Systemd 默认后缀名为.service，所以sshd会被理解成sshd.service。\n设置开机启动以后，软件并不会立即启动，必须等到下一次开机。如果想现在就运行该软件，那么要执行systemctl start命令。\n配置文件的状态\nsystemctl list-unit-files命令用于列出所有配置文件。\n# 列出所有配置文件 $ systemctl list-unit-files # 列出指定类型的配置文件 $ systemctl list-unit-files --type=service 这个命令会输出一个列表。\n$ systemctl list-unit-filesUNIT FILE STATEchronyd.service enabledclamd@.service staticclamd@scan.service disabled 这个列表显示每个配置文件的状态，一共有四种。\n enabled：已建立启动链接 disabled：没建立启动链接 static：该配置文件没有[Install]部分（无法执行），只能作为其他配置文件的依赖 masked：该配置文件被禁止建立启动链接  注意，从配置文件的状态无法看出，该 Unit 是否正在运行。这必须执行前面提到的systemctl status命令。\n$ systemctl status bluetooth.service 一旦修改配置文件，就要让 Systemd 重新加载配置文件，然后重新启动，否则修改不会生效。\n$ sudo systemctl daemon-reload $ sudo systemctl restart httpd.service 配置文件的格式\n配置文件就是普通的文本文件，可以用文本编辑器打开。\nsystemctl cat命令可以查看配置文件的内容。\n$ systemctl cat sshd.service [Unit] Description=OpenSSH server daemon Documentation=man:sshd(8) man:sshd_config(5) After=network.target sshd-keygen.service Wants=sshd-keygen.service [Service] EnvironmentFile=/etc/sysconfig/sshd ExecStart=/usr/sbin/sshd -D $OPTIONS ExecReload=/bin/kill -HUP $MAINPID Type=simpleKill Mode=process Restart=on-failure RestartSec=42s [Install] WantedBy=multi-user.target 从上面的输出可以看到，配置文件分成几个区块。每个区块的第一行，是用方括号表示的区别名，比如[Unit]。注意，配置文件的区块名和字段名，都是大小写敏感的。\n每个区块内部是一些等号连接的键值对。\n[Section] Directive1=value Directive2=value . . . 注意，键值对的等号两侧不能有空格。\n配置文件的区块\n[Unit]区块通常是配置文件的第一个区块，用来定义 Unit 的元数据，以及配置与其他 Unit 的关系。它的主要字段如下。\n  Description：当前服务的简单描述\n  Documentation：文档地址\n  启动顺序\n Before：如果该字段指定的 Unit 也要启动，那么必须在当前 Unit 之后启动 After：如果该字段指定的 Unit 也要启动，那么必须在当前 Unit 之前启动。如network.target或sshd-keygen.service需要启动，那么sshd.service应该在它们之后启动。    依赖关系：\n举例来说，某 Web 应用需要 postgresql 数据库储存数据。在配置文件中，Before、After 只定义要在 postgresql 之后启动，而没有定义依赖 postgresql 。上线后，由于某种原因，postgresql 需要重新启动，在停止服务期间，该 Web 应用就会无法建立数据库连接。\n注意，Wants字段与Requires字段只涉及依赖关系，与启动顺序无关，默认情况下是同时启动的。\n Wants：与当前 Unit 配合的其他 Unit，如果它们没有运行，当前 Unit 不会启动失败。如sshd.service与sshd-keygen.service之间存在\u0026quot;弱依赖\u0026quot;关系，即如果\u0026quot;sshd-keygen.service\u0026quot;启动失败或停止运行，不影响sshd.service继续执行。 Requires：当前 Unit 依赖的其他 Unit，如果它们没有运行，当前 Unit 会启动失败。Requires字段则表示\u0026quot;强依赖\u0026quot;关系，即如果该服务启动失败或异常退出，那么sshd.service也必须退出。    BindsTo：与Requires类似，它指定的 Unit 如果退出，会导致当前 Unit 停止运行\n  Conflicts：这里指定的 Unit 不能与当前 Unit 同时运行\n  Condition...：当前 Unit 运行必须满足的条件，否则不会运行\n  Assert...：当前 Unit 运行必须满足的条件，否则会报启动失败\n  StartLimitIntervalSec=interval, StartLimitBurst=burst：设置单元的启动频率限制。 也就是该单元在 interval 时间内最多允许启动 burst 次。\n   [Service]区块用来定义如何启动当前服务，只有 Service 类型的 Unit 才有这个区块。它的主要字段如下。\n EnvironmentFile字段：指定当前服务的环境参数文件。该文件内部的key=value键值对，可以用$key的形式，在当前配置文件中获取。sshd 的环境参数文件是/etc/sysconfig/sshd。 ExecStart字段：定义启动进程时执行的命令。是配置文件里面最重要的字段。上面的例子中，启动sshd，执行的命令是/usr/sbin/sshd -D $OPTIONS，其中的变量$OPTIONS就来自EnvironmentFile字段指定的环境参数文件。与之作用相似的，还有如下这些字段。  ExecReload字段：重启服务时执行的命令 ExecStop字段：停止服务时执行的命令 ExecStartPre字段：启动服务之前执行的命令 ExecStartPost字段：启动服务之后执行的命令 ExecStopPost字段：停止服务之后执行的命令   Type：字段定义启动类型。它可以设置的值如下。  simple（默认值）：ExecStart字段启动的进程为主进程 forking：ExecStart字段将以fork()方式启动，此时父进程将会退出，子进程将成为主进程 oneshot：类似于simple，但只执行一次，Systemd 会等它执行完，才启动其他服务 dbus：类似于simple，但会等待 D-Bus 信号后启动 notify：类似于simple，启动结束后会发出通知信号，然后 Systemd 再启动其他服务 idle：类似于simple，但是要等到其他任务都执行完，才会启动该服务。一种使用场合是为让该服务的输出，不与其他服务的输出相混合   KillMode字段：定义 Systemd 如何停止服务。  control-group（默认值）：当前控制组里面的所有子进程，都会被杀掉 process：只杀主进程。比如sshd的KillMode设为process，子进程打开的 SSH session 仍然保持连接。 mixed：主进程将收到 SIGTERM 信号，子进程收到 SIGKILL 信号 none：没有进程会被杀掉，只是执行服务的 stop 命令。   Restart：Restart字段：定义了服务退出后，Systemd 重启该服务的方式。  no（默认值）：退出后不会重启 on-success：只有正常退出时（退出状态码为0），才会重启 on-failure：非正常退出时（退出状态码非0），包括被信号终止和超时，才会重启。比如sshd任何意外的失败，都将重启sshd；如果 sshd 正常停止（比如执行systemctl stop命令），它就不会重启。对于守护进程，推荐设为on-failure。 on-abnormal：只有被信号终止和超时，才会重启。对于那些允许发生错误退出的服务，可以设为on-abnormal。 on-abort：只有在收到没有捕捉到的信号终止时，才会重启 on-watchdog：超时退出，才会重启 always：不管是什么退出原因，总是重启   RestartSec字段：表示 Systemd 重启服务之前，需要等待的秒数。 TimeoutSec：定义 Systemd 停止当前服务之前等待的秒数  所有的启动设置之前，都可以加上一个连词号（-），表示\u0026quot;抑制错误\u0026quot;，即发生错误的时候，不影响其他命令的执行。比如，EnvironmentFile=-/etc/sysconfig/sshd（注意等号后面的那个连词号），就表示即使/etc/sysconfig/sshd文件不存在，也不会抛出错误。\n [Install]通常是配置文件的最后一个区块，定义如何安装这个配置文件，即怎样做到开机启动。它的主要字段如下。\n WantedBy字段：表示该服务所在的 Target，它的值是一个或多个 Target。Target的含义是服务组，表示一组服务。WantedBy=multi-user.target指的是，sshd 所在的 Target 是multi-user.target。当前 Unit 激活时（enable）符号链接会放入/etc/systemd/system目录下面 [Target 名].wants子目录中，如multi-user.target.wants子目录。 RequiredBy：它的值是一个或多个 Target，当前 Unit 激活时，符号链接会放入/etc/systemd/system目录下面以 Target 名 + .required后缀构成的子目录中 Alias：当前 Unit 可用于启动的别名 Also：当前 Unit 激活（enable）时，会被同时激活的其他 Unit  Unit 配置文件的完整字段清单，请参考官方文档。\nTarget 启动计算机的时候，需要启动大量的 Unit。如果每一次启动，都要一一写明本次启动需要哪些 Unit，显然非常不方便。Systemd 的解决方案就是 Target。\n简单说，Target 就是一个 Unit 组，包含许多相关的 Unit 。启动某个 Target 的时候，Systemd 就会启动里面所有的 Unit。从这个意义上说，Target 这个概念类似于\u0026quot;状态点\u0026quot;，启动某个 Target 就好比启动到某种状态。\n传统的init启动模式里面，有 RunLevel 的概念，跟 Target 的作用很类似。不同的是，RunLevel 是互斥的，不可能多个 RunLevel 同时启动，但是多个 Target 可以同时启动。\n# 查看当前系统的所有 Target $ systemctl list-unit-files --type=target # 查看一个 Target 包含的所有 Unit $ systemctl list-dependencies multi-user.target # 查看启动时的默认 Target，在这个组里的所有服务，都将开机启动。 $ systemctl get-default # 设置启动时的默认 Target $ sudo systemctl set-default multi-user.target # 切换 Target 时，默认不关闭前一个 Target 启动的进程， # systemctl isolate 命令改变这种行为， # 关闭前一个 Target 里面所有不属于后一个 Target 的进程 $ sudo systemctl isolate multi-user.target Target 与 传统 RunLevel 的对应关系如下。\nTraditional runlevel New target name Symbolically linked to... Runlevel 0 | runlevel0.target -\u0026gt; poweroff.target Runlevel 1 | runlevel1.target -\u0026gt; rescue.target Runlevel 2 | runlevel2.target -\u0026gt; multi-user.target Runlevel 3 | runlevel3.target -\u0026gt; multi-user.target Runlevel 4 | runlevel4.target -\u0026gt; multi-user.target Runlevel 5 | runlevel5.target -\u0026gt; graphical.target Runlevel 6 | runlevel6.target -\u0026gt; reboot.target 它与init进程的主要差别如下。\n（1）默认的 RunLevel（在/etc/inittab文件设置）现在被默认的 Target 取代，位置是/etc/systemd/system/default.target，通常符号链接到graphical.target（图形界面）或者multi-user.target（多用户命令行）。\n（2）启动脚本的位置，以前是/etc/init.d目录，符号链接到不同的 RunLevel 目录 （比如/etc/rc3.d、/etc/rc5.d等），现在则存放在/lib/systemd/system和/etc/systemd/system目录。\n（3）配置文件的位置，以前init进程的配置文件是/etc/inittab，各种服务的配置文件存放在/etc/sysconfig目录。现在的配置文件主要存放在/lib/systemd目录，在/etc/systemd目录里面的修改可以覆盖原始设置。\n日志管理 Systemd 统一管理所有 Unit 的启动日志。带来的好处就是，可以只用journalctl一个命令，查看所有日志（内核日志和应用日志）。日志的配置文件是/etc/systemd/journald.conf。\njournalctl功能强大，用法非常多。\n# 查看所有日志（默认情况下 ，只保存本次启动的日志） $ sudo journalctl # 查看内核日志（不显示应用日志） $ sudo journalctl -k # 查看系统本次启动的日志 $ sudo journalctl -b $ sudo journalctl -b -0 # 查看上一次启动的日志（需更改设置） $ sudo journalctl -b -1 # 查看指定时间的日志 $ sudo journalctl --since=\u0026#34;2012-10-30 18:17:16\u0026#34; $ sudo journalctl --since \u0026#34;20 min ago\u0026#34; $ sudo journalctl --since yesterday $ sudo journalctl --since \u0026#34;2015-01-10\u0026#34; --until \u0026#34;2015-01-11 03:00\u0026#34; $ sudo journalctl --since 09:00 --until \u0026#34;1 hour ago\u0026#34; # 显示尾部的最新10行日志 $ sudo journalctl -n # 显示尾部指定行数的日志 $ sudo journalctl -n 20 # 实时滚动显示最新日志 $ sudo journalctl -f # 查看指定服务的日志 $ sudo journalctl /usr/lib/systemd/systemd # 查看指定进程的日志 $ sudo journalctl _PID=1 # 查看某个路径的脚本的日志 $ sudo journalctl /bin/bash # 查看指定用户的日志 $ sudo journalctl _UID=33 --since today # 查看某个 Unit 的日志 $ sudo journalctl -u nginx.service $ sudo journalctl -u nginx.service --since today # 实时滚动显示某个 Unit 的最新日志 $ sudo journalctl -u nginx.service -f # 合并显示多个 Unit 的日志 $ journalctl -u nginx.service -u php-fpm.service --since today # 查看指定优先级（及其以上级别）的日志，共有8级 # 0: emerg # 1: alert # 2: crit # 3: err # 4: warning # 5: notice # 6: info # 7: debug $ sudo journalctl -p err -b # 日志默认分页输出，--no-pager 改为正常的标准输出 $ sudo journalctl --no-pager # 以 JSON 格式（单行）输出 $ sudo journalctl -b -u nginx.service -o json # 以 JSON 格式（多行）输出，可读性更好 $ sudo journalctl -b -u nginx.serviceqq -o json-pretty # 显示日志占据的硬盘空间 $ sudo journalctl --disk-usage # 指定日志文件占据的最大空间 $ sudo journalctl --vacuum-size=1G # 指定日志文件保存多久 $ sudo journalctl --vacuum-time=1years 定时器示例 邮件脚本 先写一个发邮件的脚本mail.sh。\n#!/usr/bin/env bash echo \u0026#34;This is the body\u0026#34; | /usr/bin/mail -s \u0026#34;Subject\u0026#34; someone@example.com 上面代码的someone@example.com，请替换成你的邮箱地址。\n然后，执行这个脚本。\n$ bash mail.sh 执行后，你应该就会收到一封邮件，标题为Subject。\n如果你的 Linux 系统不能发邮件，建议安装 ssmtp 或者 msmtp。另外，mail命令的用法，可以参考这里。\nService 单元 Service 单元就是所要执行的任务，比如发送邮件就是一种 Service。\n新建 Service 非常简单，就是在/usr/lib/systemd/system目录里面新建一个文件，比如mytimer.service文件，你可以写入下面的内容。\n[Unit] Description=MyTimer [Service] ExecStart=/bin/bash /path/to/mail.sh 注意，定义的时候，所有路径都要写成绝对路径，比如bash要写成/bin/bash，否则 Systemd 会找不到。\n现在，启动这个 Service。\n$ sudo systemctl start mytimer.service 如果一切正常，你应该就会收到一封邮件。\nTimer 单元 Service 单元只是定义了如何执行任务，要定时执行这个 Service，还必须定义 Timer 单元。\n/usr/lib/systemd/system目录里面，新建一个mytimer.timer文件，写入下面的内容。\n[Unit] Description=Runs mytimer every hour [Timer] OnUnitActiveSec=1h Unit=mytimer.service [Install] WantedBy=multi-user.target 这个 Timer 单元文件分成几个部分。\n[Timer]部分定制定时器。Systemd 提供以下一些字段。\n OnActiveSec：定时器生效后，多少时间开始执行任务 OnBootSec：系统启动后，多少时间开始执行任务 OnStartupSec：Systemd 进程启动后，多少时间开始执行任务 OnUnitActiveSec：该单元上次执行后，等多少时间再次执行 OnUnitInactiveSec： 定时器上次关闭后多少时间，再次执行 OnCalendar：基于绝对时间，而不是相对时间执行 AccuracySec：如果因为各种原因，任务必须推迟执行，推迟的最大秒数，默认是60秒 Unit：真正要执行的任务，默认是同名的带有.service后缀的单元 Persistent：如果设置了该字段，即使定时器到时没有启动，也会自动执行相应的单元 WakeSystem：如果系统休眠，是否自动唤醒系统  上面的脚本里面，OnUnitActiveSec=1h表示一小时执行一次任务。其他的写法还有OnCalendar=*-*-* 02:00:00表示每天凌晨两点执行，OnCalendar=Mon *-*-* 02:00:00表示每周一凌晨两点执行，具体请参考中文手册。\n防火墙 保障数据的安全性是继保障数据的可用性之后最为重要的一项工作。防火墙作为公网与内网之间的保护屏障，在保障数据的安全性方面起着至关重要的作用。\n防火墙管理工具 众所周知，相较于企业内网，外部的公网环境更加恶劣，罪恶丛生。在公网与企业内网之间充当保护屏障的防火墙虽然有软件或硬件之分，但主要功能都是依据策略对穿越防火墙自身的流量进行过滤。就像家里安装的防盗门一样，目的是保护亲人和财产安全。防火墙策略可以基于流量的源目地址、端口号、协议、应用等信息来定制，然后防火墙使用预先定制的策略规则监控出入的流量，若流量与某一条策略规则相匹配，则执行相应的处理，反之则丢弃。这样一来，就能够保证仅有合法的流量在企业内网和外部公网之间流动了。\n从RHEL 7系统开始，firewalld防火墙正式取代了iptables防火墙。对于接触Linux系统比较早或学习过RHEL 5/6系统的读者来说，当他们发现曾经掌握的知识在RHEL 7/8中不再适用，需要全新学习firewalld时，难免会有抵触心理。其实，iptables与firewalld都不是真正的防火墙，它们都只是用来定义防火墙策略的防火墙管理工具而已；或者说，它们只是一种服务。iptables服务会把配置好的防火墙策略交由内核层面的netfilter网络过滤器来处理，而firewalld服务则是把配置好的防火墙策略交由内核层面的nftables包过滤框架来处理。换句话说，当前在Linux系统中其实存在多个防火墙管理工具，旨在方便运维人员管理Linux系统中的防火墙策略，我们只需要配置妥当其中的一个就足够了。\n虽然这些工具各有优劣，但它们在防火墙策略的配置思路上是保持一致的。大家甚至可以不用完全掌握本章介绍的内容，只要在这多个防火墙管理工具中任选一款并将其学透，就足以满足日常的工作需求了。\nIptables 在早期的Linux系统中，默认使用的是iptables防火墙管理服务来配置防火墙。尽管新型的firewalld防火墙管理服务已经被投入使用多年，但是大量的企业在生产环境中依然出于各种原因而继续使用iptables。\n策略与规则链 防火墙会按照从上到下的顺序来读取配置的策略规则，在找到匹配项后就立即结束匹配工作并去执行匹配项中定义的行为（即放行或阻止）。如果在读取完所有的策略规则之后没有匹配项，就去执行默认的策略。一般而言，防火墙策略规则的设置有两种：“通”（即放行）和“堵”（即阻止）。当防火墙的默认策略为拒绝时（堵），就要设置允许规则（通），否则谁都进不来；如果防火墙的默认策略为允许，就要设置拒绝规则，否则谁都能进来，防火墙也就失去了防范的作用。\niptables服务把用于处理或过滤流量的策略条目称之为规则，多条规则可以组成一个规则链，而规则链则依据数据包处理位置的不同进行分类，具体如下：\n 在进行路由选择前处理数据包（PREROUTING）； 处理流入的数据包（INPUT）； 处理流出的数据包（OUTPUT）； 处理转发的数据包（FORWARD）； 在进行路由选择后处理数据包（POSTROUTING）。  一般来说，从内网向外网发送的流量一般都是可控且良性的，因此使用最多的就是INPUT规则链，该规则链可以增大黑客人员从外网入侵内网的难度。\n比如在您居住的社区内，物业管理公司有两条规定：禁止小商小贩进入社区；各种车辆在进入社区时都要登记。显而易见，这两条规定应该是用于社区的正门的（流量必须经过的地方），而不是每家每户的防盗门上。根据前面提到的防火墙策略的匹配顺序，可能会存在多种情况。比如，来访人员是小商小贩，则直接会被物业公司的保安拒之门外，也就无须再对车辆进行登记。如果来访人员乘坐一辆汽车进入社区正门，则“禁止小商小贩进入社区”的第一条规则就没有被匹配到，因此按照顺序匹配第二条策略，即需要对车辆进行登记。如果是社区居民要进入正门，则这两条规定都不会匹配到，因此会执行默认的放行策略。\n但是，仅有策略规则还不能保证社区的安全，保安还应该知道采用什么样的动作来处理这些匹配的流量，比如“允许”“拒绝”“登记”“不理它”。这些动作对应到iptables服务的术语中分别是ACCEPT（允许流量通过）、REJECT（拒绝流量通过）、LOG（记录日志信息）、DROP（拒绝流量通过）。“允许流量通过”和“记录日志信息”都比较好理解，这里需要着重讲解的是REJECT和DROP的不同点。就DROP来说，它是直接将流量丢弃而且不响应；REJECT则会在拒绝流量后再回复一条“信息已经收到，但是被扔掉了”信息，从而让流量发送方清晰地看到数据被拒绝的响应信息。\n下面举一个例子，让各位读者更直观地理解这两个拒绝动作的不同之处。比如有一天您正在家里看电视，突然听到有人敲门，您透过防盗门的猫眼一看是推销商品的，便会在不需要的情况下开门并拒绝他们（REJECT）。但如果看到的是债主带了十几个小弟来讨债，此时不仅要拒绝开门，还要默不作声，伪装成自己不在家的样子（DROP）。\n当把Linux系统中的防火墙策略设置为REJECT动作后，流量发送方会看到端口不可达的响应：\n[root@linuxprobe ~]# ping -c 4 192.168.10.10 PING 192.168.10.10 (192.168.10.10) 56(84) bytes of data. From 192.168.10.10 icmp_seq=1 Destination Port Unreachable From 192.168.10.10 icmp_seq=2 Destination Port Unreachable From 192.168.10.10 icmp_seq=3 Destination Port Unreachable From 192.168.10.10 icmp_seq=4 Destination Port Unreachable --- 192.168.10.10 ping statistics --- 4 packets transmitted, 0 received, +4 errors, 100 packet loss, time 3002ms 而把Linux系统中的防火墙策略修改成DROP动作后，流量发送方会看到响应超时的提醒。但是流量发送方无法判断流量是被拒绝，还是接收方主机当前不在线：\n[root@linuxprobe ~]# ping -c 4 192.168.10.10 PING 192.168.10.10 (192.168.10.10) 56(84) bytes of data. --- 192.168.10.10 ping statistics --- 4 packets transmitted, 0 received, 100 packet loss, time 3000ms 基本的命令参数 iptables是一款基于命令行的防火墙策略管理工具，具有大量的参数，学习难度较大。好在对于日常的防火墙策略配置来讲，大家无须深入了解诸如“四表五链”的理论概念，只需要掌握常用的参数并做到灵活搭配即可，这就足以应对日常工作了。\n根据OSI七层模型的定义，iptables属于数据链路层的服务，所以可以根据流量的源地址、目的地址、传输协议、服务类型等信息进行匹配；一旦匹配成功，iptables就会根据策略规则所预设的动作来处理这些流量。另外，再次提醒一下，防火墙策略规则的匹配顺序是从上到下的，因此要把较为严格、优先级较高的策略规则放到前面，以免发生错误。表8-1总结归纳了常用的iptables命令参数。再次强调，无须死记硬背这些参数，只需借助下面的实验来理解掌握即可。\n   参数 作用     -P 设置默认策略   -F 清空规则链   -L 查看规则链   -A 在规则链的末尾加入新规则   -I num 在规则链的头部加入新规则   -D num 删除某一条规则   -s 匹配来源地址IP/MASK，加叹号“!”表示除这个IP外   -d 匹配目标地址   -i 网卡名称 匹配从这块网卡流入的数据   -o 网卡名称 匹配从这块网卡流出的数据   -p 匹配协议，如TCP、UDP、ICMP   \u0026ndash;dport num 匹配目标端口号   \u0026ndash;sport num 匹配来源端口号    1．在iptables命令后添加-L参数查看已有的防火墙规则链。\n[root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination ACCEPT udp -- anywhere anywhere udp dpt:domain ACCEPT tcp -- anywhere anywhere tcp dpt:domain ACCEPT udp -- anywhere anywhere udp dpt:bootps ACCEPT tcp -- anywhere anywhere tcp dpt:bootps Chain FORWARD (policy ACCEPT) target prot opt source destination ACCEPT all -- anywhere 192.168.122.0/24 ctstate RELATED,ESTABLISHED ACCEPT all -- 192.168.122.0/24 anywhere ACCEPT all -- anywhere anywhere REJECT all -- anywhere anywhere reject-with icmp-port-unreachable REJECT all -- anywhere anywhere reject-with icmp-port-unreachable Chain OUTPUT (policy ACCEPT) target prot opt source destination ACCEPT udp -- anywhere anywhere udp dpt:bootpc 2．在iptables命令后添加-F参数清空已有的防火墙规则链。\n[root@linuxprobe ~]# iptables -F [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination 3．把INPUT规则链的默认策略设置为拒绝。\n[root@linuxprobe ~]# iptables -P INPUT DROP [root@linuxprobe ~]# iptables -L Chain INPUT (policy DROP) target prot opt source destination Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination 前文提到，防火墙策略规则的设置无非有两种方式：“通”和“堵”。当把INPUT链设置为默认拒绝后，就要往里面写入允许策略了，否则所有流入的数据包都会被默认拒绝掉。同学们需要留意的是，规则链的默认策略拒绝动作只能是DROP，而不能是REJECT。\n4．向INPUT链中添加允许ICMP流量进入的策略规则。\n在日常运维工作中，经常会使用ping命令来检查对方主机是否在线，而向防火墙的INPUT规则链中添加一条允许ICMP流量进入的策略规则就默认允许了这种ping命令检测行为。\n[root@linuxprobe ~]# iptables -I INPUT -p icmp -j ACCEPT [root@linuxprobe ~]# ping -c 4 192.168.10.10 PING 192.168.10.10 (192.168.10.10) 56(84) bytes of data. 64 bytes from 192.168.10.10: icmp_seq=1 ttl=64 time=0.154 ms 64 bytes from 192.168.10.10: icmp_seq=2 ttl=64 time=0.041 ms 64 bytes from 192.168.10.10: icmp_seq=3 ttl=64 time=0.038 ms 64 bytes from 192.168.10.10: icmp_seq=4 ttl=64 time=0.046 ms --- 192.168.10.10 ping statistics --- 4 packets transmitted, 4 received, 0 packet loss, time 104ms rtt min/avg/max/mdev = 0.038/0.069/0.154/0.049 ms 5．删除INPUT规则链中刚刚加入的那条策略（允许ICMP流量），并把默认策略设置为允许。\n使用-F参数会清空已有的所有防火墙策略；使用-D参数可以删除某一条指定的策略，因此更加安全和准确。\n[root@linuxprobe ~]# iptables -D INPUT 1 [root@linuxprobe ~]# iptables -P INPUT ACCEPT [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination 6．将INPUT规则链设置为只允许指定网段的主机访问本机的22端口，拒绝来自其他所有主机的流量。\n要对某台主机进行匹配，可直接写出它的IP地址；如需对网段进行匹配，则需要写为子网掩码的形式（比如192.168.10.0/24）。\n[root@linuxprobe ~]# iptables -I INPUT -s 192.168.10.0/24 -p tcp --dport 22 -j ACCEPT [root@linuxprobe ~]# iptables -A INPUT -p tcp --dport 22 -j REJECT [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination ACCEPT tcp -- 192.168.10.0/24 anywhere tcp dpt:ssh REJECT tcp -- anywhere anywhere tcp dpt:ssh reject-with icmp-port-unreachable ………………省略部分输出信息……………… 再次重申，防火墙策略规则是按照从上到下的顺序匹配的，因此一定要把允许动作放到拒绝动作前面，否则所有的流量就将被拒绝掉，从而导致任何主机都无法访问我们的服务。另外，这里提到的22号端口是ssh服务使用的。\n在设置完上述INPUT规则链之后，使用IP地址在192.168.10.0/24网段内的主机访问服务器（即前面提到的设置了INPUT规则链的主机）的22端口，效果如下：\n[root@Client A ~]# ssh 192.168.10.10 The authenticity of host \u0026#39;192.168.10.10 (192.168.10.10)\u0026#39; can\u0026#39;t be established. ECDSA key fingerprint is SHA256:5d52kZi1la/FJK4v4jibLBZhLqzGqbJAskZiME6ZXpQ. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added \u0026#39;192.168.10.10\u0026#39; (ECDSA) to the list of known hosts. root@192.168.10.10\u0026#39;s password: 此处输入服务器密码 Activate the web console with: systemctl enable --now cockpit.socket Last login: Wed Jan 20 16:30:28 2021 from 192.168.10.1 然后，再使用IP地址在192.168.20.0/24网段内的主机访问服务器的22端口（虽网段不同，但已确认可以相互通信），效果如下：\n[root@Client B ~]# ssh 192.168.10.10 Connecting to 192.168.10.10:22... Could not connect to \u0026#39;192.168.10.10\u0026#39; (port 22): Connection failed. 由上可以看到，提示连接请求被拒绝了（Connection failed）。\n7．向INPUT规则链中添加拒绝所有人访问本机12345端口的策略规则。\n[root@linuxprobe ~]# iptables -I INPUT -p tcp --dport 12345 -j REJECT [root@linuxprobe ~]# iptables -I INPUT -p udp --dport 12345 -j REJECT [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination REJECT udp -- anywhere anywhere udp dpt:italk reject-with icmp-port-unreachable REJECT tcp -- anywhere anywhere tcp dpt:italk reject-with icmp-port-unreachable ACCEPT tcp -- 192.168.10.0/24 anywhere tcp dpt:ssh REJECT tcp -- anywhere anywhere tcp dpt:ssh reject-with icmp-port-unreachable ………………省略部分输出信息……………… 8．向INPUT规则链中添加拒绝192.168.10.5主机访问本机80端口（Web服务）的策略规则。\n[root@linuxprobe ~]# iptables -I INPUT -p tcp -s 192.168.10.5 --dport 80 -j REJECT [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination REJECT tcp -- 192.168.10.5 anywhere tcp dpt:http reject-with icmp-port-unreachable REJECT udp -- anywhere anywhere udp dpt:italk reject-with icmp-port-unreachable REJECT tcp -- anywhere anywhere tcp dpt:italk reject-with icmp-port-unreachable ACCEPT tcp -- 192.168.10.0/24 anywhere tcp dpt:ssh REJECT tcp -- anywhere anywhere tcp dpt:ssh reject-with icmp-port-unreachable ………………省略部分输出信息……………… 9．向INPUT规则链中添加拒绝所有主机访问本机1000～1024端口的策略规则。\n前面在添加防火墙策略时，使用的是-I参数，它默认会把规则添加到最上面的位置，因此优先级是最高的。如果工作中需要添加一条最后“兜底”的规则，那就用-A参数吧。这两个参数的效果差别还是很大的：\n[root@linuxprobe ~]# iptables -A INPUT -p tcp --dport 1000:1024 -j REJECT [root@linuxprobe ~]# iptables -A INPUT -p udp --dport 1000:1024 -j REJECT [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination REJECT tcp -- 192.168.10.5 anywhere tcp dpt:http reject-with icmp-port-unreachable REJECT udp -- anywhere anywhere udp dpt:italk reject-with icmp-port-unreachable REJECT tcp -- anywhere anywhere tcp dpt:italk reject-with icmp-port-unreachable ACCEPT tcp -- 192.168.10.0/24 anywhere tcp dpt:ssh REJECT tcp -- anywhere anywhere tcp dpt:ssh reject-with icmp-port-unreachable REJECT tcp -- anywhere anywhere tcp dpts:cadlock2:1024 reject-with icmp-port-unreachable REJECT udp -- anywhere anywhere udp dpts:cadlock2:1024 reject-with icmp-port-unreachable ………………省略部分输出信息……………… 有关iptables命令的知识讲解到此就结束了，大家是不是意犹未尽？考虑到Linux防火墙的发展趋势，大家只要能把上面的实例吸收消化，就可以完全搞定日常的iptables配置工作了。但是请特别注意，使用iptables命令配置的防火墙规则默认会在系统下一次重启时失效，如果想让配置的防火墙策略永久生效，还要执行保存命令：\n[root@linuxprobe ~]# iptables-save  # Generated by xtables-save v1.8.2 on Wed Jan 20 16:56:27 2021 ………………省略部分输出信息……………… 对了，如果公司服务器是5/6/7版本的话，对应的保存命令应该是：\n[root@linuxprobe ~]# service iptables save iptables: Saving firewall rules to /etc/sysconfig/iptables: [ OK ] Firewalld RHEL 8系统中集成了多款防火墙管理工具，其中firewalld（Dynamic Firewall Manager of Linux systems，Linux系统的动态防火墙管理器）服务是默认的防火墙配置管理工具，它拥有基于CLI（命令行界面）和基于GUI（图形用户界面）的两种管理方式。\nRHEL 8系统中集成了多款防火墙管理工具，其中firewalld（Dynamic Firewall Manager of Linux systems，Linux系统的动态防火墙管理器）服务是默认的防火墙配置管理工具，它拥有基于CLI（命令行界面）和基于GUI（图形用户界面）的两种管理方式。\n相较于传统的防火墙管理配置工具，firewalld支持动态更新技术并加入了区域（zone）的概念。简单来说，区域就是firewalld预先准备了几套防火墙策略集合（策略模板），用户可以根据生产场景的不同而选择合适的策略集合，从而实现防火墙策略之间的快速切换。例如，我们有一台笔记本电脑，每天都要在办公室、咖啡厅和家里使用。按常理来讲，这三者的安全性按照由高到低的顺序来排列，应该是家庭、公司办公室、咖啡厅。当前，我们希望为这台笔记本电脑制定如下防火墙策略规则：在家中允许访问所有服务；在办公室内仅允许访问文件共享服务；在咖啡厅仅允许上网浏览。在以往，我们需要频繁地手动设置防火墙策略规则，而现在只需要预设好区域集合，然后轻点鼠标就可以自动切换了，从而极大地提升了防火墙策略的应用效率。firewalld中常见的区域名称（默认为public）以及相应的策略规则如表所示。\n   区域 默认规则策略     trusted 允许所有的数据包   home 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh、mdns、ipp-client、amba-client与dhcpv6-client服务相关，则允许流量   internal 等同于home区域   work 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh、ipp-client与dhcpv6-client服务相关，则允许流量   public 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh、dhcpv6-client服务相关，则允许流量   external 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh服务相关，则允许流量   dmz 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh服务相关，则允许流量   block 拒绝流入的流量，除非与流出的流量相关   drop 拒绝流入的流量，除非与流出的流量相关    终端管理工具 命令行终端是一种极富效率的工作方式，firewall-cmd是firewalld防火墙配置管理工具的CLI（命令行界面）版本。它的参数一般都是以“长格式”来提供的。大家不要一听到长格式就头大，因为RHEL 8系统支持部分命令的参数补齐，其中就包含这条命令（很酷吧）。也就是说，现在除了能用Tab键自动补齐命令或文件名等内容之外，还可以用Tab键来补齐表所示的长格式参数。这太棒了！\n   参数 作用     \u0026ndash;get-default-zone 查询默认的区域名称   \u0026ndash;set-default-zone=\u0026lt;区域名称\u0026gt; 设置默认的区域，使其永久生效   \u0026ndash;get-zones 显示可用的区域   \u0026ndash;get-services 显示预先定义的服务   \u0026ndash;get-active-zones 显示当前正在使用的区域与网卡名称   \u0026ndash;add-source= 将源自此IP或子网的流量导向指定的区域   \u0026ndash;remove-source= 不再将源自此IP或子网的流量导向某个指定区域   \u0026ndash;add-interface=\u0026lt;网卡名称\u0026gt; 将源自该网卡的所有流量都导向某个指定区域   \u0026ndash;change-interface=\u0026lt;网卡名称\u0026gt; 将某个网卡与区域进行关联   \u0026ndash;list-all 显示当前区域的网卡配置参数、资源、端口以及服务等信息   \u0026ndash;list-all-zones 显示所有区域的网卡配置参数、资源、端口以及服务等信息   \u0026ndash;add-service=\u0026lt;服务名\u0026gt; 设置默认区域允许该服务的流量   \u0026ndash;add-port=\u0026lt;端口号/协议\u0026gt; 设置默认区域允许该端口的流量   \u0026ndash;remove-service=\u0026lt;服务名\u0026gt; 设置默认区域不再允许该服务的流量   \u0026ndash;remove-port=\u0026lt;端口号/协议\u0026gt; 设置默认区域不再允许该端口的流量   \u0026ndash;reload 让“永久生效”的配置规则立即生效，并覆盖当前的配置规则   \u0026ndash;panic-on 开启应急状况模式   \u0026ndash;panic-off 关闭应急状况模式    与Linux系统中其他的防火墙策略配置工具一样，使用firewalld配置的防火墙策略默认为运行时（Runtime）模式，又称为当前生效模式，而且会随着系统的重启而失效。如果想让配置策略一直存在，就需要使用永久（Permanent）模式了，方法就是在用firewall-cmd命令正常设置防火墙策略时添加\u0026ndash;permanent参数，这样配置的防火墙策略就可以永久生效了。但是，永久生效模式有一个“不近人情”的特点，就是使用它设置的策略只有在系统重启之后才能自动生效。如果想让配置的策略立即生效，需要手动执行firewall-cmd \u0026ndash;reload命令。\n接下来的实验都很简单，但是提醒大家一定要仔细查看使用的是Runtime模式还是Permanent模式。如果不关注这个细节，就算正确配置了防火墙策略，也可能无法达到预期的效果。\n1．查看firewalld服务当前所使用的区域。\n这是一步非常重要的操作。在配置防火墙策略前，必须查看当前生效的是哪个区域，否则配置的防火墙策略将不会立即生效。\n[root@linuxprobe ~]# firewall-cmd --get-default-zone public 2．查询指定网卡在firewalld服务中绑定的区域。\n在生产环境中，服务器大多不止有一块网卡。一般来说，充当网关的服务器有两块网卡，一块对公网，另外一块对内网，那么这两块网卡在审查流量时所用的策略肯定也是不一致的。因此，可以根据网卡针对的流量来源，为网卡绑定不同的区域，实现对防火墙策略的灵活管控。\n[root@linuxprobe ~]# firewall-cmd --get-zone-of-interface=ens160 public 3．把网卡默认区域修改为external，并在系统重启后生效。\n[root@linuxprobe ~]# firewall-cmd --permanent --zone=external --change-interface=ens160 The interface is under control of NetworkManager, setting zone to \u0026#39;external\u0026#39;. success [root@linuxprobe ~]# firewall-cmd --permanent --get-zone-of-interface=ens160 external 4．把firewalld服务的默认区域设置为public。\n默认区域也叫全局配置，指的是对所有网卡都生效的配置，优先级较低。在下面的代码中可以看到，当前默认区域为public，而ens160网卡的区域为external。此时便是以网卡的区域名称为准。\n通俗来说，默认区域就是一种通用的政策。例如，食堂为所有人准备了一次性餐具，而环保主义者则会自己携带碗筷。如果您自带了碗筷，就可以用自己的；反之就用食堂统一提供的。\n[root@linuxprobe ~]# firewall-cmd --set-default-zone=public Warning: ZONE_ALREADY_SET: public success [root@linuxprobe ~]# firewall-cmd --get-default-zone  public [root@linuxprobe ~]# firewall-cmd --get-zone-of-interface=ens160 external 5．启动和关闭firewalld防火墙服务的应急状况模式。\n如果想在1s的时间内阻断一切网络连接，有什么好办法呢？大家下意识地会说：“拔掉网线！”这是一个物理级别的高招。但是，如果人在北京，服务器在异地呢？panic紧急模式在这个时候就派上用场了。使用\u0026ndash;panic-on参数会立即切断一切网络连接，而使用\u0026ndash;panic-off则会恢复网络连接。切记，紧急模式会切断一切网络连接，因此在远程管理服务器时，在按下回车键前一定要三思。\n[root@linuxprobe ~]# firewall-cmd --panic-on success [root@linuxprobe ~]# firewall-cmd --panic-off success 6．查询SSH和HTTPS协议的流量是否允许放行。\n在工作中可以不使用\u0026ndash;zone参数指定区域名称，firewall-cmd命令会自动依据默认区域进行查询，从而减少用户输入量。但是，如果默认区域与网卡所绑定的不一致时，就会发生冲突，因此规范写法的zone参数是一定要加的。\n[root@linuxprobe ~]# firewall-cmd --zone=public --query-service=ssh yes [root@linuxprobe ~]# firewall-cmd --zone=public --query-service=https no 7．把HTTPS协议的流量设置为永久允许放行，并立即生效。\n默认情况下进行的修改都属于Runtime模式，即当前生效而重启后失效，因此在工作和考试中尽量避免使用。而在使用\u0026ndash;permanent参数时，则是当前不会立即看到效果，而在重启或重新加载后方可生效。于是，在添加了允许放行HTTPS流量的策略后，查询当前模式策略，发现依然是不允许放行HTTPS协议的流量：\n[root@linuxprobe ~]# firewall-cmd --permanent --zone=public --add-service=https success [root@linuxprobe ~]# firewall-cmd --zone=public --query-service=https no 不想重启服务器的话，就用\u0026ndash;reload参数吧：\n[root@linuxprobe ~]# firewall-cmd --reload success [root@linuxprobe ~]# firewall-cmd --zone=public --query-service=https yes 8．把HTTP协议的流量设置为永久拒绝，并立即生效。\n由于在默认情况下HTTP协议的流量就没有被允许，所以会有“Warning: NOT_ENABLED: http”这样的提示信息，因此对实际操作没有影响。\n[root@linuxprobe ~]# firewall-cmd --permanent --zone=public --remove-service=http Warning: NOT_ENABLED: http success [root@linuxprobe ~]# firewall-cmd --reload  success 9．把访问8080和8081端口的流量策略设置为允许，但仅限当前生效。\n[root@linuxprobe ~]# firewall-cmd --zone=public --add-port=8080-8081/tcp success [root@linuxprobe ~]# firewall-cmd --zone=public --list-ports 8080-8081/tcp 10．把原本访问本机888端口的流量转发到22端口，要且求当前和长期均有效。\nSSH远程控制协议是基于TCP/22端口传输控制指令的，如果想让用户通过其他端口号也能访问ssh服务，就可以试试端口转发技术了。通过这项技术，新的端口号在收到用户请求后会自动转发到原本服务的端口上，使得用户能够通过新的端口访问到原本的服务。\n来举个例子帮助大家理解。假设小强是电子厂的工人，他喜欢上了三号流水线上的工人小花，但不好意思表白，于是写了一封情书并交给门卫张大爷，希望由张大爷转交给小花。这样一来，情书（信息）的传输由从小强到小花，变成了小强到张大爷再到小花，情书（信息）依然能顺利送达。\n使用firewall-cmd命令实现端口转发的格式有点长，这里为大家总结好了：\nfirewall-cmd --permanent --zone=\u0026lt;区域\u0026gt; --add-forward-port=port=\u0026lt;源端口号\u0026gt;:proto=\u0026lt;协议\u0026gt;:toport=\u0026lt;目标端口号\u0026gt;:toaddr=\u0026lt;目标IP地址\u0026gt; 上述命令中的目标IP地址一般是服务器本机的IP地址：\n[root@linuxprobe ~]# firewall-cmd --permanent --zone=public --add-forward-port=port=888:proto=tcp:toport=22:toaddr=192.168.10.10 success [root@linuxprobe ~]# firewall-cmd --reload success 在客户端使用ssh命令尝试访问192.168.10.10主机的888端口，访问成功：\n[root@client A ~]# ssh -p 888 192.168.10.10 The authenticity of host \u0026#39;[192.168.10.10]:888 ([192.168.10.10]:888)\u0026#39; can\u0026#39;t be established. ECDSA key fingerprint is b8:25:88:89:5c:05:b6:dd:ef:76:63:ff:1a:54:02:1a. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added \u0026#39;[192.168.10.10]:888\u0026#39; (ECDSA) to the list of known hosts. root@192.168.10.10\u0026#39;s password:此处输入远程root管理员的密码 Last login: Sun Jul 19 21:43:48 2021 from 192.168.10.10 11．富规则的设置。\n富规则也叫复规则，表示更细致、更详细的防火墙策略配置，它可以针对系统服务、端口号、源地址和目标地址等诸多信息进行更有针对性的策略配置。它的优先级在所有的防火墙策略中也是最高的。比如，我们可以在firewalld服务中配置一条富规则，使其拒绝192.168.10.0/24网段的所有用户访问本机的ssh服务（22端口）：\n[root@linuxprobe ~]# firewall-cmd --permanent --zone=public --add-rich-rule=\u0026#34;rule family=\u0026#34;ipv4\u0026#34; source address=\u0026#34;192.168.10.0/24\u0026#34; service name=\u0026#34;ssh\u0026#34; reject\u0026#34; success [root@linuxprobe ~]# firewall-cmd --reload success 在客户端使用ssh命令尝试访问192.168.10.10主机的ssh服务（22端口）：\n[root@client A ~]# ssh 192.168.10.10 Connecting to 192.168.10.10:22... Could not connect to \u0026#39;192.168.10.10\u0026#39; (port 22): Connection failed. 图形管理工具 在各种版本的Linux系统中，几乎没有能让刘遄老师欣慰并推荐的图形化工具，但是firewall-config做到了。它是firewalld防火墙配置管理工具的GUI（图形用户界面）版本，几乎可以实现所有以命令行来执行的操作。毫不夸张地说，即使读者没有扎实的Linux命令基础，也完全可以通过它来妥善配置RHEL 8中的防火墙策略。\n成功 firewall-config 安装后，其工具的界面如图所示：\n其功能具体如下。\n1：选择运行时（Runtime）或永久（Permanent）模式的配置。\n2：可选的策略集合区域列表。\n3：常用的系统服务列表。\n4：主机地址的黑白名单。\n5：当前正在使用的区域。\n6：管理当前被选中区域中的服务。\n7：管理当前被选中区域中的端口。\n8：设置允许被访问的协议。\n9：设置允许被访问的端口。\n10：开启或关闭SNAT（源网络地址转换）技术。\n11：设置端口转发策略。\n12：控制请求icmp服务的流量。\n13：管理防火墙的富规则。\n14：被选中区域的服务，若勾选了相应服务前面的复选框，则表示允许与之相关的流量。\n15：firewall-config工具的运行状态。\n除了图中列出的功能，还有用于将网卡与区域绑定的Interfaces选项，以及用于将IP地址与区域绑定的Sources选项。另外再啰唆一句。在使用firewall-config工具配置完防火墙策略之后，无须进行二次确认，因为只要有修改内容，它就自动进行保存。\n下面进行动手实践环节。\n先将当前区域中请求http服务的流量设置为允许放行，但仅限当前生效。具体配置如图所示：\n尝试添加一条防火墙策略规则，使其放行访问8080～8088端口（TCP协议）的流量，并将其设置为永久生效，以达到系统重启后防火墙策略依然生效的目的。在按照下图所示的界面配置完毕之后，还需要在Options菜单中单击Reload Firewalld命令，让配置的防火墙策略立即生效。这与在命令行中使用\u0026ndash;reload参数的效果一样。\n放行访问8080～8088端口的流量：\n让配置的防火墙策略规则立即生效：\n前面在讲解firewall-config工具的功能时，曾经提到了SNAT（Source Network Address Translation，源网络地址转换）技术。SNAT是一种为了解决IP地址匮乏而设计的技术，它可以使得多个内网中的用户通过同一个外网IP接入Internet。该技术的应用非常广泛，甚至可以说我们每天都在使用，只不过没有察觉到罢了。比如，当通过家中的网关设备（无线路由器）访问本书配套站点www.linuxprobe.com时，就用到了SNAT技术。\n大家可以看一下在网络中不使用SNAT技术和使用SNAT技术时的情况。在没有使用SNAT技术的局域网中有多台PC，如果网关服务器没有应用SNAT技术，则互联网中的网站服务器在收到PC的请求数据包，并回送响应数据包时，将无法在网络中找到这个私有网络的IP地址，所以PC也就收不到响应数据包了。在使用SNAT技术处理过的局域网中，由于网关服务器应用了SNAT技术，所以互联网中的网站服务器会将响应数据包发给网关服务器，再由后者转发给局域网中的PC。\n没有使用SNAT技术的网络：\n使用SNAT技术处理过的网络：\n使用iptables命令实现SNAT技术是一件很麻烦的事情，但是在firewall-config中却是小菜一碟了。用户只需按照下图进行配置，并选中Masquerade zone复选框，就自动开启了SNAT技术。\n为了让大家直观查看不同工具在实现相同功能时的区别，针对前面使用firewall-cmd配置的防火墙策略规则，这里使用firewall-config工具进行了重新演示：将本机888端口的流量转发到22端口，且要求当前和长期均有效，具体如下图所示：\n配置本地的端口转发：\n让防火墙效策略规则立即生效：\n用命令配置富规则可真辛苦，幸好我们现在有了图形用户界面的工具。让192.168.10.20主机访问本机的1234端口号，如下图所示。其中Element选项能够根据服务名称、端口号、协议等信息进行匹配；Source与Destination选项后的inverted复选框代表反选功能，将其选中则代表对已填写信息进行反选，即选中填写信息以外的主机地址；Log复选框在选中后，日志不仅会被记录到日志文件中，而且还可以在设置日志的级别（Level）后，再将日志记录到日志文件中，以方便后续的筛查。\n如果生产环境中的服务器有多块网卡在同时提供服务（这种情况很常见），则对内网和对外网提供服务的网卡要选择的防火墙策略区域也是不一样的。也就是说，可以把网卡与防火墙策略区域进行绑定，这样就可以使用不同的防火墙区域策略，对源自不同网卡的流量进行有针对性的监控，效果会更好。\n把网卡与防火墙策略区域进行绑定：\n网卡与策略区域绑定完成：\n最后再提一句，firewall-config工具真的非常实用，很多原本复杂的长命令被图形化按钮替代，设置规则也简单明了，足以应对日常工作。所以再次向大家强调配置防火墙策略的原则—只要能实现所需的功能，用什么工具请随君便。\n服务的访问控制列表 TCP Wrapper是RHEL 6/7系统中默认启用的一款流量监控程序，它能够根据来访主机的地址与本机的目标服务程序做出允许或拒绝的操作。在RHEL 8版本中，它已经被firewalld正式替代。换句话说，Linux系统中其实有两个层面的防火墙，第一种是前面讲到的基于TCP/IP协议的流量过滤工具，而TCP Wrapper服务则是能允许或禁止Linux系统提供服务的防火墙，从而在更高层面保护了Linux系统的安全运行。\nTCP Wrapper服务的防火墙策略由两个控制列表文件所控制，用户可以编辑允许控制列表文件来放行对服务的请求流量，也可以编辑拒绝控制列表文件来阻止对服务的请求流量。控制列表文件修改后会立即生效，系统将会先检查允许控制列表文件（/etc/hosts.allow），如果匹配到相应的允许策略则放行流量；如果没有匹配，则会进一步匹配拒绝控制列表文件（/etc/hosts.deny），若找到匹配项则拒绝该流量。如果这两个文件都没有匹配到，则默认放行流量。\n由于RHEL 8版本已经不再支持TCP Wrapper服务程序，因此我们接下来选择在一台老版本的服务器上进行实验。TCP Wrapper服务的控制列表文件配置起来并不复杂，常用的参数如表所示。\n   客户端类型 示例 满足示例的客户端列表     单一主机 192.168.10.10 IP地址为192.168.10.10的主机   指定网段 192.168.10. IP段为192.168.10.0/24的主机   指定网段 192.168.10.0/255.255.255.0 IP段为192.168.10.0/24的主机   指定DNS后缀 .linuxprobe.com 所有DNS后缀为.linuxprobe.com的主机   指定主机名称 www.linuxprobe.com 主机名称为www.linuxprobe.com的主机   指定所有客户端 ALL 所有主机全部包括在内    在配置TCP Wrapper服务时需要遵循两个原则：\n 编写拒绝策略规则时，填写的是服务名称，而非协议名称； 建议先编写拒绝策略规则，再编写允许策略规则，以便直观地看到相应的效果。  下面编写拒绝策略规则文件，禁止访问本机sshd服务的所有流量（无须修改/etc/hosts.deny文件中原有的注释信息）：\n[root@linuxprobe ~]# vim /etc/hosts.deny # # hosts.deny This file contains access rules which are used to # deny connections to network services that either use # the tcp_wrappers library or that have been # started through a tcp_wrappers-enabled xinetd. # # The rules in this file can also be set up in # /etc/hosts.allow with a \u0026#39;deny\u0026#39; option instead. # # See \u0026#39;man 5 hosts_options\u0026#39; and \u0026#39;man 5 hosts_access\u0026#39; # for information on rule syntax. # See \u0026#39;man tcpd\u0026#39; for information on tcp_wrappers sshd:* [root@linuxprobe ~]# ssh 192.168.10.10 ssh_exchange_identification: read: Connection reset by peer 接下来，在允许策略规则文件中添加一条规则，使其放行源自192.168.10.0/24网段，且访问本机sshd服务的所有流量。可以看到，服务器立刻就放行了访问sshd服务的流量，效果非常直观：\n[root@linuxprobe ~]# vim /etc/hosts.allow # # hosts.allow This file contains access rules which are used to # allow or deny connections to network services that # either use the tcp_wrappers library or that have been # started through a tcp_wrappers-enabled xinetd. # # See \u0026#39;man 5 hosts_options\u0026#39; and \u0026#39;man 5 hosts_access\u0026#39; # for information on rule syntax. # See \u0026#39;man tcpd\u0026#39; for information on tcp_wrappers sshd:192.168.10. [root@linuxprobe ~]# ssh 192.168.10.10 The authenticity of host \u0026#39;192.168.10.10 (192.168.10.10)\u0026#39; can\u0026#39;t be established. ECDSA key fingerprint is 70:3b:5d:37:96:7b:2e:a5:28:0d:7e:dc:47:6a:fe:5c. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added \u0026#39;192.168.10.10\u0026#39; (ECDSA) to the list of known hosts. root@192.168.10.10\u0026#39;s password: Last login: Wed May 4 07:56:29 2021 [root@linuxprobe ~]#  Cockpit 驾驶舱管理工具 首先，Cockpit是一个英文单词，即“（飞机、船或赛车的）驾驶舱、驾驶座”，它用名字传达出了功能丰富的特性。其次，Cockpit是一个基于Web的图形化服务管理工具，对用户相当友好，即便是新手也可以轻松上手。而且它天然具备很好的跨平台性，因此被广泛应用于服务器、容器、虚拟机等多种管理场景。最后，红帽公司对Cockpit也十分看重，直接将它默认安装到了RHEL 8系统中，由此衍生的CentOS和Fedora也都标配有Cockpit。\nCockpit在默认情况下就已经被安装到系统中。下面执行dnf命令对此进行确认：\n[root@linuxprobe ~]# dnf install cockpit Updating Subscription Management repositories. Unable to read consumer identity This system is not registered to Red Hat Subscription Management. You can use subscription-manager to register. AppStream 3.1 MB/s | 3.2 kB 00:00 BaseOS 2.7 MB/s | 2.7 kB 00:00 Package cockpit-185-2.el8.x86_64 is already installed. Dependencies resolved. Nothing to do. Complete! 但是，Cockpit服务程序在RHEL 8版本中没有自动运行，下面将它开启并加入到开机启动项中：\n[root@linuxprobe ~]# systemctl start cockpit [root@linuxprobe ~]# systemctl enable cockpit.socket Created symlink /etc/systemd/system/sockets.target.wants/cockpit.socket → /usr/lib/systemd/system/cockpit.socket. 在Cockpit服务启动后，打开系统自带的浏览器，在地址栏中输入“本机地址:9090”即可访问。由于访问Cockpit的流量会使用HTTPS进行加密，而证书又是在本地签发的，因此还需要进行添加并信任本地证书的操作。\n添加额外允许的证书：\n确认信任本地证书：\n进入Cockpit的登录界面后，输入root管理员的账号与系统密码，单击Log In按钮后即可进入：\n进入Cockpit的Web界面，发现里面可谓“别有洞天”。Cockpit总共分为13个功能模块：系统状态（System）、日志信息（Logs）、硬盘存储（Storage）、网卡网络（Networking）、账户安全（Accounts）、服务程序（Services）、软件仓库（Applications）、报告分析（Diagnostic Reports）、内核排错（Kernel Dump）、SElinux、更新软件（Software Updates）、订阅服务（Subscriptions）、终端界面（Terminal）。下面逐一进行讲解。\n1．System\n进入Cockpit界面后默认显示的便是System（系统）界面，在该界面中能够看到系统架构、版本、主机名与时间等信息，还能够动态地展现出CPU、硬盘、内存和网络的复杂情况，这有点类似于Web版的“Winodws系统任务管理器”，属实好用。\n系统状态界面：\n2．Logs\n这个模块能够提供系统的全部日志，但是同学们可能会好奇，“为什么下图中的内容这么有限呢”？原因出在图中的两个选项中：时间和日志级别。通过这两个选项可以让用户更快地找到所需信息，而不是像/var/log/message文件那样一股脑儿地都抛给用户。\n日志信息界面：\n3．Storage\n这个功能模块是同学们最喜欢的一个模块，原因不是这个模块显示了硬盘的I/O读写负载情况，而是可以让用户通过该界面，用鼠标创建出RAID、LVM、VDO和iSCSI等存储设备。是的，您没有看错，RAID和LVM都可以用鼠标进行创建了，是不是很开心呢？\n硬盘存储界面：\n4．Networking\n既然名为Networking模块，那么动态看网卡的输出和接收值肯定是这个模块的标配功能了。我们不仅可以在这里进行网卡的绑定（Bonding）和聚合（Team），还可以创建桥接网卡及添加VLAN。最下方会单独列出与网卡相关的日志信息。\n网卡网络界面：\n**5．**Accounts\n大家千万别小看Accounts模块，虽然它的账户安全界面有些简陋，只有一个用于创建账户的按钮，但只要点击进入某个用户的管理界面中，马上会发现“别有洞天”——账户管理界面，这个界面中的功能非常丰富，我们在这里可以对用户进行重命名，设置用户的权限，还可以锁定、修改密码以及创建SSH密钥信息。\n账户安全界面：\n账户管理界面：\n6．Services\n在Services功能模块的界面中，可以查看系统中已有的服务列表和运行状态。单击某一服务，进入该服务的管理界面后，可以对具体的服务进行开启、关闭操作。在Services功能模块中设置了服务并将其加入到开机启动项后，在系统重启后也依然会为用户提供服务。\n服务程序界面：\n服务管理界面：\n7．Applications\n后期采用Cockpit或红帽订阅服务安装的软件都会显示在这个功能模块中。\n软件仓库界面：\n8．Diagnostic Report\nDiagnostic Report模块的功能是帮助用户收集及分析系统的信息，找到系统出现问题的原因。单击Create Report按钮后大约两分钟左右，会出现报告生成完毕的弹窗。好吧，摊牌了，这个功能其实很鸡肋，就是将sosreport命令做成了一个网页按钮。\n报告分析界面：\n报告生成完毕：\n9．Kernel Dump\nKernel Dump（Kdump）是一个在系统崩溃、死锁或死机时用来收集内核参数的一个服务。举例来说，如果有一天系统崩溃了，这时Kdump服务就会开始工作，将系统的运行状态和内核数据收集到一个名为dump core的文件中，以便后续让运维人员分析并找出问题所在。由于我们在安装系统时没有启动该服务，所以可以等到后续使用时再开启该功能界面。\n内核排错界面：\n10．SElinux\n下图所示为SELinux服务的控制按钮和警告信息界面。\nSElinux管理界面：\n11．Software Updates\n这里提到的Software Updates并不是我们用来更新其他常规软件的一个界面，而是用来对红帽客户订阅的服务进行更新的界面。用户只有在购买了红帽第三方服务后才能使用这里面的功能。在购买了红帽订阅服务后，用户便可以在这里下载到相应服务程序的最新版本和稳定版本。\n更新软件界面：\n12．Subscriptions\n这里依然是一则红帽公司的“小广告”—如果想成为尊贵的红帽服务用户，要付费购买订阅服务。个人用户无须购买，而且这对我们的后续实验没有任何影响。\n订阅服务界面：\n12．Terminal\n压轴的总是在最后。Cockpit服务提供了Shell终端的在线控制平台，可方便用户通过网页上的终端功能管理服务器。这个功能深受运维人员喜爱。\n终端管理界面\n至此，相信各位读者已经充分掌握了防火墙的管理能力。防火墙管理工具有很多种，我们任选其一即可。在配置后续的服务前，大家要记得检查网络和防火墙的状态，以避免出现服务明明配置正确，但无法从外部访问的情况，最终影响实验效果。\n在 Ubuntu 上使用 UFW Ubuntu 20.04 随附了一个称为UFW（非复杂防火墙）的防火墙配置工具。 它是用于管理iptables防火墙规则的用户友好型前端。 它的主要目标是使防火墙的管理变得更容易，或者顾名思义，变得简单。\n检查UFW状态 UFW默认情况下处于禁用状态。 您可以使用以下命令检查UFW服务的状态：\n$ sudo ufw status verbose 输出将显示防火墙状态为非活动：\nStatus: inactive 如果UFW已激活，则输出将类似于以下内容：\nStatus: active UFW默认策略 UFW防火墙的默认行为是阻止所有传入和转发流量，并允许所有出站流量。 这意味着除非您专门打开端口，否则任何尝试访问您的服务器的人都将无法连接。 服务器上运行的应用程序和服务将可以访问外界。\n默认策略在/etc/default/ufw文件中定义，可以通过手动修改文件或使用sudo ufw default \u0026lt;policy\u0026gt; \u0026lt;chain\u0026gt;命令来更改。\n防火墙策略是建立更复杂和用户定义的规则的基础。 通常，最初的UFW默认策略是一个很好的起点。\n应用配置文件 应用程序配置文件是INI格式的文本文件，描述了服务并包含该服务的防火墙规则。 在安装软件包期间，会在/etc/ufw/applications.d目录中创建应用程序配置文件。\n您可以通过键入以下内容列出服务器上所有可用的应用程序配置文件：\n$ sudo ufw app list Available applications: Nginx Full Nginx HTTP Nginx HTTPS OpenSSH 要查找有关特定配置文件和包含的规则的更多信息，请使用以下命令：\n$ sudo ufw app info \u0026#39;Nginx Full\u0026#39; Profile: Nginx Full Title: Web Server (Nginx, HTTP + HTTPS) Description: Small, but very powerful and efficient web server Ports: 80,443/tcp 输出显示“ Nginx Full”配置文件打开了端口80和443。\n您也可以为应用创建自定义配置文件。\n启用UFW 如果要从远程位置连接到Ubuntu，则在启用UFW防火墙之前，必须明确允许传入的SSH连接。 否则，您将无法连接到计算机。\n要将您的UFW防火墙配置为允许传入的SSH连接，请键入以下命令：\n$ sudo ufw allow ssh Rules updated Rules updated (v6) 如果SSH在非标准端口上运行，则需要打开该端口。\n例如，如果您的ssh守护程序侦听端口7722，请输入以下命令以允许该端口上的连接：\n$ sudo ufw allow 7722/tcp 现在已将防火墙配置为允许传入的SSH连接，您可以通过键入以下内容来启用它：\n$ sudo ufw enable Command may disrupt existing ssh connections. Proceed with operation (y|n)? y Firewall is active and enabled on system startup 将警告您启用防火墙可能会破坏现有的ssh连接，只需键入y并单击Enter。\n打开端口 根据系统上运行的应用程序，您可能还需要打开其他端口。 打开端口的一般语法如下：\n$ ufw allow port_number/protocol 以下是有关如何允许HTTP连接的几种方法。\n第一种选择是使用服务名称。 UFW检查/etc/services文件中指定服务的端口和协议：\n$ sudo ufw allow http 您还可以指定端口号和协议：\n$ sudo ufw allow 80/tcp 如果未给出协议，则UFW会同时为tcp和udp创建规则。\n另一个选择是使用应用程序配置文件； 在这种情况下，“ Nginx HTTP”：\n$ sudo ufw allow \u0026#39;Nginx HTTP\u0026#39; UFW还支持使用proto关键字指定协议的另一种语法：\n$ sudo ufw allow proto tcp to any port 80 端口范围\nUFW还允许您打开端口范围。 起始端口和结束端口用冒号（:）分隔，并且您必须指定协议tcp或udp。\n例如，如果要同时在tcp和udp上允许端口从7100到7200，则可以运行以下命令：\n$ sudo ufw allow 7100:7200/tcp 特定的IP地址和端口\n要允许来自给定源IP的所有端口上的连接，请使用from关键字，后跟源地址。\n以下是将IP地址列入白名单的示例：\n$ sudo ufw allow from 64.63.62.61 如果要仅允许给定IP地址访问特定端口，请使用to any port关键字，后跟端口号。\n例如，要允许IP地址为64.63.62.61的计算机访问端口22，请输入：\n$ sudo ufw allow from 64.63.62.61 to any port 22 子网\n允许连接到IP地址子网的语法与使用单个IP地址时的语法相同。 唯一的区别是您需要指定子网掩码。\n下面是一个示例，显示了如何允许访问从192.168.1.1到192.168.1.254的IP地址到端口3360（MySQL ）：\n$ sudo ufw allow from 192.168.1.0/24 to any port 3306 特定网络接口\n要允许在特定的网络接口上进行连接，请使用in on关键字，后跟网络接口(网卡)的名称：\n$ sudo ufw allow in on eth2 to any port 3306 拒绝连接 所有传入连接的默认策略均设置为deny，如果您未更改默认策略，除非您专门打开连接，否则UFW会阻止所有传入连接。\n撰写拒绝规则与撰写允许规则相同； 您只需要使用deny关键字而不是allow。\n假设您打开了端口80和443，并且服务器受到23.24.25.0/24网络的攻击。 要拒绝来自23.24.25.0/24的所有连接，您可以运行以下命令：\n$ sudo ufw deny from 23.24.25.0/24 以下是拒绝访问23.24.25.0/24中的端口80和443的示例，您可以使用以下命令：\n$ sudo ufw deny proto tcp from 23.24.25.0/24 to any port 80,443 删除UFW规则 有两种方法可以通过规则编号和指定实际规则来删除UFW规则。\n按规则号删除规则比较容易，尤其是当您不熟悉UFW时。 要首先通过规则编号删除规则，您需要找到要删除的规则的编号。 要获取编号规则的列表，请使用ufw status numbered命令：\n$ sudo ufw status numbered Status: active To Action From -- ------ ---- [ 1] 22/tcp ALLOW IN Anywhere [ 2] 80/tcp ALLOW IN Anywhere [ 3] 8080/tcp ALLOW IN Anywhere 要删除规则号3，该规则号允许连接到端口8080，请输入：\n$ sudo ufw delete 3 第二种方法是通过指定实际规则来删除规则。 例如，如果您添加了打开端口8069的规则，则可以使用以下命令将其删除：\n$ sudo ufw delete allow 8069 禁用UFW 如果出于任何原因要停止UFW并停用所有规则，则可以使用：\n$ sudo ufw disable 以后，如果您想重新启用UTF并激活所有规则，只需键入：\n$ sudo ufw enable 重设UFW 重置UFW将禁用UFW，并删除所有活动规则。 如果您想还原所有更改并重新开始，这将很有帮助。\n要重置UFW，请输入以下命令：\n$ sudo ufw reset IP伪装 IP伪装是Linux内核中NAT（网络地址转换）的一种变体，它通过重写源IP地址和目标IP地址和端口来转换网络流量。 借助IP伪装，您可以使用一台充当网关的Linux计算机，允许专用网络中的一台或多台计算机与Internet通信。\n使用UFW配置IP伪装涉及几个步骤。\n首先，您需要启用IP转发。 为此，请打开/etc/ufw/sysctl.conf文件，查找并取消注释以下行：net.ipv4.ip_forward = 1：\n$ sudo nano /etc/ufw/sysctl.conf net/ipv4/ip_forward=1 接下来，您需要配置UFW以允许转发数据包。 打开UFW配置文件，找到DEFAULT_FORWARD_POLICY键，然后将值从DROP更改为ACCEPT：\n$ sudo nano /etc/default/ufw DEFAULT_FORWARD_POLICY=\u0026#34;ACCEPT\u0026#34; 现在，您需要在nat表中设置POSTROUTING链的默认策略和伪装规则。 为此，请打开/etc/ufw/before.rules文件，附加以下几行：\n$ sudo nano /etc/ufw/before.rules #NAT table rules *nat :POSTROUTING ACCEPT [0:0] # Forward traffic through eth0 - Change to public network interface -A POSTROUTING -s 10.8.0.0/16 -o eth0 -j MASQUERADE # don\u0026#39;t delete the \u0026#39;COMMIT\u0026#39; line or these rules won\u0026#39;t be processed COMMIT 别忘了在-A POSTROUTING行中替换eth0以匹配公共网络接口的名称：\n完成后，保存并关闭文件。\n最后，通过禁用和重新启用UFW重新加载UFW规则：\n$ sudo ufw disable $ sudo ufw e Diff diff是Unix系统的一个很重要的工具程序。\n它用来比较两个文本文件的差异，是代码版本管理的基石之一。你在命令行下，输入：\n$ diff \u0026lt;变动前的文件\u0026gt; \u0026lt;变动后的文件\u0026gt; diff就会告诉你，这两个文件有何差异。它的显示结果不太好懂，下面我就来说明，如何读懂diff。\n三种格式 由于历史原因，diff有三种格式：\n 正常格式（normal diff） 上下文格式（context diff） 合并格式（unified diff）  我们依次来看。\n示例文件 为了便于讲解，先新建两个示例文件。\n第一个文件叫做f1，内容是每行一个a，一共7行。\na a a a a a a 第二个文件叫做f2，修改f1而成，第4行变成b，其他不变。\na a a b a a a 正常格式 现在对f1和f2进行比较：\n$ diff f1 f2 这时，diff就会显示正常格式的结果：\n4c4 \u0026lt; a --- \u0026gt; b 第一行是一个提示，用来说明变动位置。\n4c4 它分成三个部分：前面的\u0026quot;4\u0026quot;，表示f1的第4行有变化；中间的\u0026quot;c\u0026quot;表示变动的模式是内容改变（change），其他模式还有\u0026quot;增加\u0026quot;（a，代表addition）和\u0026quot;删除\u0026quot;（d，代表deletion）；后面的\u0026quot;4\u0026quot;，表示变动后变成f2的第4行。\n第二行分成两个部分。\n\u0026lt; a 前面的小于号，表示要从f1当中去除该行（也就是第4行），后面的\u0026quot;a\u0026quot;表示该行的内容。\n第三行用来分割f1和f2。\n--- 第四行，类似于第二行。\n\u0026gt; b 前面的大于号表示f2增加了该行，后面的\u0026quot;b\u0026quot;表示该行的内容。\n最早的Unix（即AT\u0026amp;T版本的Unix），使用的就是这种格式的diff。\n上下文格式 上个世纪80年代初，加州大学伯克利分校推出BSD版本的Unix时，觉得diff的显示结果太简单，最好加入上下文，便于了解发生的变动。因此，推出了上下文格式的diff。\n它的使用方法是加入c参数（代表context）。\n$ diff -c f1 f2 显示结果如下：\n*** f1 2012-08-29 16:45:41.000000000 +0800 --- f2 2012-08-29 16:45:51.000000000 +0800 *************** *** 1,7 **** a a a !a a a a --- 1,7 ---- a a a !b a a a 这个结果分成四个部分。\n第一部分的两行，显示两个文件的基本情况：文件名和时间信息。\n*** f1 2012-08-29 16:45:41.000000000 +0800 --- f2 2012-08-29 16:45:51.000000000 +0800 ***表示变动前的文件，---表示变动后的文件。\n第二部分是15个星号，将文件的基本情况与变动内容分割开。\n*************** 第三部分显示变动前的文件，即f1。\n*** 1,7 **** a a a !a a a a 这时不仅显示发生变化的第4行，还显示第4行的前面三行和后面三行，因此一共显示7行。所以，前面的*** 1,7 ****就表示，从第1行开始连续7行。\n另外，文件内容的每一行最前面，还有一个标记位。如果为空，表示该行无变化；如果是感叹号（!），表示该行有改动；如果是减号（-），表示该行被删除；如果是加号（+），表示该行为新增。\n第四部分显示变动后的文件，即f2。\n--- 1,7 ---- a a a !b a a a 除了变动行（第4行）以外，也是上下文各显示三行，总共显示7行。\n合并格式 如果两个文件相似度很高，那么上下文格式的diff，将显示大量重复的内容，很浪费空间。1990年，GNU diff率先推出了\u0026quot;合并格式\u0026quot;的diff，将f1和f2的上下文合并在一起显示。\n它的使用方法是加入u参数（代表unified）。\n$ diff -u f1 f2 显示结果如下：\n--- f1 2012-08-29 16:45:41.000000000 +0800 +++ f2 2012-08-29 16:45:51.000000000 +0800 @@ -1,7 +1,7 @@ a a a -a +b a a a 它的第一部分，也是文件的基本信息。\n--- f1 2012-08-29 16:45:41.000000000 +0800 +++ f2 2012-08-29 16:45:51.000000000 +0800 ---表示变动前的文件，+++表示变动后的文件。\n第二部分，变动的位置用两个@作为起首和结束。\n@@ -1,7 +1,7 @@ 前面的\u0026quot;-1,7\u0026quot;分成三个部分：减号表示第一个文件（即f1），\u0026ldquo;1\u0026quot;表示第1行，\u0026ldquo;7\u0026quot;表示连续7行。合在一起，就表示下面是第一个文件从第1行开始的连续7行。同样的，\u0026quot;+1,7\u0026quot;表示变动后，成为第二个文件从第1行开始的连续7行。\n第三部分是变动的具体内容。\na a a -a +b a a a 除了有变动的那些行以外，也是上下文各显示3行。它将两个文件的上下文，合并显示在一起，所以叫做\u0026quot;合并格式\u0026rdquo;。每一行最前面的标志位，空表示无变动，减号表示第一个文件删除的行，加号表示第二个文件新增的行。\ngit格式 版本管理系统git，使用的是合并格式diff的变体。\n$ git diff 显示结果如下：\ndiff --git a/f1 b/f1 index 6f8a38c..449b072 100644 --- a/f1 +++ b/f1 @@ -1,7 +1,7 @@ a a a -a +b a a a 第一行表示结果为git格式的diff。\ndiff --git a/f1 b/f1 进行比较的是，a版本的f1（即变动前）和b版本的f1（即变动后）。\n第二行表示两个版本的git哈希值（index区域的6f8a38c对象，与工作目录区域的449b072对象进行比较），最后的六位数字是对象的模式（普通文件，644权限）。　index 6f8a38c..449b072 100644 第三行表示进行比较的两个文件。\n--- a/f1 +++ b/f1 ---表示变动前的版本，+++表示变动后的版本。\n后面的行都与官方的合并格式diff相同。\n@@ -1,7 +1,7 @@ a a a -a +b a a a Crontab 使用 crontab 命令来执行定时任务。所谓定时任务，就是未来的某个或多个时点，预定要执行的任务，比如每五分钟收一次邮件、每天半夜两点分析一下日志等等。\nInstalling Cron $ sudo apt install cronie Running the Crond Service $ systemctl enable crond.service $ systemctl start crond.service crontab 命令详解 crontab 命令通过 /etc/cron.allow 和 /etc/cron.deny 文件来限制某些用户是否可以使用 crontab 命令：\n 当系统中有 /etc/cron.allow 文件时，只有写入此文件的用户可以使用 crontab 命令，没有写入的用户不能使用 crontab 命令。 当系统中只有 /etc/cron.deny 文件时，写入此文件的用户不能使用 crontab 命令，没有写入文件的用户可以使用 crontab 命令。 /etc/cron.allow 文件比 /etc/cron.deny 文件的优先级高，Linux 系统中默认只有 /etc/cron.deny 文件。  crontab 命令的基本格式如下：\ncrontab [选项] [file] 注意，这里的 file 指的是命令文件的名字，表示将 file 作为 crontab 的任务列表文件并载入 crontab，若在命令行中未指定文件名，则此命令将接受标准输入（键盘）上键入的命令，并将它们键入 crontab。\n常用选项    选项 功能     -u user 用来设定某个用户的 crontab 服务，例如 \u0026ldquo;-u demo\u0026rdquo; 表示设备 demo 用户的 crontab 服务，此选项一般有 root 用户来运行。   -e 编辑某个用户的 crontab 文件内容。如果不指定用户，则表示编辑当前用户的 crontab 文件。   -l 显示某用户的 crontab 文件内容，如果不指定用户，则表示显示当前用户的 crontab 文件内容。   -r 从 /var/spool/cron 删除某用户的 crontab 文件，如果不指定用户，则默认删除当前用户的 crontab 文件。   -i 在删除用户的 crontab 文件时，给确认提示。    crontab 文件格式 * * * * * 执行的任务 执行的任务字段既可以定时执行系统命令，也可以定时执行某个 Shell 脚本。\n执行时间\n   项目 含义 范围     第一个\u0026rdquo;*\u0026quot; 一小时当中的第几分钟（minute） 0~59   第二个\u0026quot;*\u0026quot; 一天当中的第几小时（hour） 0~23   第三个\u0026quot;*\u0026quot; 一个月当中的第几天（day） 1~31   第四个\u0026quot;*\u0026quot; 一年当中的第几个月（month） 1~12   第五个\u0026quot;*\u0026quot; 一周当中的星期几（week） 0~7（0和7都代表星期日）    时间特殊符号\n   特殊符号 含义     *（星号） 代表任何时间。比如第一个\u0026quot;*\u0026ldquo;就代表一小时种每分钟都执行一次的意思。   ,（逗号） 代表不连续的时间。比如\u0026quot;0 8，12，16***命令\u0026quot;就代表在每天的 8 点 0 分、12 点 0 分、16 点 0 分都执行一次命令。   -（中杠） 代表连续的时间范围。比如\u0026quot;0 5 ** 1-6命令\u0026rdquo;，代表在周一到周六的凌晨 5 点 0 分执行命令。   /（正斜线） 代表每隔多久执行一次。比如\u0026quot;*/10****命令\u0026quot;，代表每隔 10 分钟就执行一次命令。    当“crontab -e”编辑完成之后，一旦保存退出，那么这个定时任务实际就会写入 /var/spool/cron/ 目录中，每个用户的定时任务用自己的用户名进行区分。而且 crontab 命令只要保存就会生效，只要 crond 服务是启动的。\ncrontab举例\n   时间 含义     45 22 ***命令 在每天 22 点 45 分执行命令   0 17 ** 1命令 在每周一的 17 点 0 分执行命令   0 5 1，15**命令 在每月 1 日和 15 日的凌晨 5 点 0 分执行命令   40 4 ** 1-5命令 在每周一到周五的凌晨 4 点 40 分执行命令   */10 4 ***命令 在每天的凌晨 4 点，每隔 10 分钟执行一次命令   0 0 1，15 * 1命令 在每月 1 日和 15 日，每周一 0 点 0 分都会执行命令    注意事项\n 6 个选项都不能为空，必须填写。如果不确定，则使用“*”代表任意时间。 crontab 定时任务的最小有效时间是分钟，最大有效时间是月。像 2018 年某时执行、3 点 30 分 30 秒这样的时间都不能被识别。 在定义时间时，日期和星期最好不要在一条定时任务中出现，因为它们都以天为单位，非常容易让管理员混淆。 在定时任务中，不管是直接写命令，还是在脚本中写命令，最好都使用绝对路径。有时使用相对路径的命令会报错。  GPG 前两篇文章，我介绍了RSA算法。\n今天，就接着来看，现实中怎么使用这个算法，对信息加密和解密。这要用到GnuPG软件（简称GPG），它是目前最流行、最好用的加密工具之一。\n什么是GPG 要了解什么是GPG，就要先了解PGP。\n1991年，程序员Phil Zimmermann为了避开政府监视，开发了加密软件PGP。这个软件非常好用，迅速流传开来，成了许多程序员的必备工具。但是，它是商业软件，不能自由使用。所以，自由软件基金会决定，开发一个PGP的替代品，取名为GnuPG。这就是GPG的由来。\nGPG有许多用途，本文主要介绍文件加密。至于邮件的加密，不同的邮件客户端有不同的设置，请参考Ubuntu网站的介绍。\n本文的使用环境为Linux命令行。如果掌握了命令行，Windows 或 Mac OS 客户端，就非常容易掌握。GPG并不难学，学会了它，从此就能轻松传递加密信息。建议读者一步步跟着教程做，对每条命令都自行测试。\n安装 GPG有两种安装方式。可以下载源码，自己编译安装。\n$ ./configuremakemake install 也可以安装编译好的二进制包。\n$ sudo apt-get install gnupg 安装完成后，键入下面的命令：\n$ gpg --help 如果屏幕显示GPG的帮助，就表示安装成功。\n生成密钥 安装成功后，使用 --full-generate-key 参数生成自己的密钥。\n$ gpg --full-generate-key 或用 gpg --gen-key 快速生成。以下使用 gpg2 --full-generate-key 演示。\n回车以后，会跳出一大段文字：\ngpg (GnuPG) 2.2.19; Copyright (C) 2019 Free Software Foundation, Inc. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Please select what kind of key you want: (1) RSA and RSA (default) (2) DSA and Elgamal (3) DSA (sign only) (4) RSA (sign only) (14) Existing key from card Your selection? 第一段是版权声明，然后让用户自己选择加密算法。默认选择第一个选项，表示加密和签名都使用RSA算法。\n然后，系统就会问你密钥的长度。\nRSA keys may be between 1024 and 4096 bits long. What keysize do you want? (3072) 密钥越长越安全。\n接着，设定密钥的有效期。\nPlease specify how long the key should be valid. 0 = key does not expire \u0026lt;n\u0026gt; = key expires in n days \u0026lt;n\u0026gt;w = key expires in n weeks \u0026lt;n\u0026gt;m = key expires in n months \u0026lt;n\u0026gt;y = key expires in n years Key is valid for? (0) 如果密钥只是个人使用，并且你很确定可以有效保管私钥，建议选择第一个选项，即永不过期。回答完上面三个问题以后，系统让你确认。\nIs this correct? (y/N) 输入y，系统就要求你提供个人信息。\nGnuPG needs to construct a user ID to identify your key. Real name: Email address Comment: \u0026ldquo;真实姓名\u0026quot;填入你姓名的英文写法，\u0026ldquo;电子邮件地址\u0026quot;填入你的邮件地址，\u0026ldquo;注释\u0026quot;这一栏可以空着。\n然后，你的\u0026quot;用户ID\u0026quot;生成了。\nYou selected this USER-ID: \u0026#34;Vane Hsiung \u0026lt;1664548605@qq.com\u0026gt;\u0026#34; 系统会让你最后确认一次。\nChange (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? 输入O表示\u0026quot;确定\u0026rdquo;。\n接着，系统会要求你做一些随机的举动，以生成一个随机数。同时系统会让你设定一个私钥的密码。这是为了防止误操作，或者系统被侵入时有人擅自动用私钥。\nWe need to generate a lot of random bytes. It is a good idea to performsome other action (type on the keyboard, move the mouse, utilize thedisks) during the prime generation; this gives the random numbergenerator a better chance to gain enough entropy. 然后，系统就开始生成密钥了，\n几分钟以后，系统提示密钥已经生成了。\ngpg: key B893B73ABC92D2CA marked as ultimately trusted gpg: revocation certificate stored as \u0026#39;\u0026#39;public and secret key created and signed. 请注意上面的字符串\u0026quot;B893B73ABC92D2CA\u0026rdquo;，这是\u0026quot;用户ID\u0026quot;的Hash字符串，可以用来替代\u0026quot;用户ID\u0026rdquo;。\n这时，最好再生成一张\u0026quot;撤销证书\u0026quot;，以备以后密钥作废时，可以请求外部的公钥服务器撤销你的公钥。\n$ gpg --gen-revoke [用户ID] 上面的\u0026quot;用户ID\u0026quot;部分，可以填入你的邮件地址或者Hash字符串（以下同）。\n密钥管理 列出密钥\nlist-keys参数列出系统中已有的密钥．\n$ gpg --list-keys 显示结果如下：\ngpg: checking the trustdb gpg: marginals needed: 3 completes needed: 1 trust model: pgp gpg: depth: 0 valid: 1 signed: 0 trust: 0-, 0q, 0n, 0m, 0f, 1u /home/vane/.gnupg/pubring.kbx ----------------------------- pub rsa3072 2021-10-17 [SC] BC158F7500033355B5324CF14C701F8BF2E03463 uid [ultimate] Vane Hsiung \u0026lt;1664548605@qq.com\u0026gt; sub rsa3072 2021-10-17 [E] 第一行显示公钥文件名（pubring.gpg），第二行显示公钥特征（4096位，Hash字符串和生成时间），第三行显示\u0026quot;用户ID\u0026quot;，第四行显示私钥特征。\n如果你要从密钥列表中删除某个密钥，可以使用如下参数。\n$ gpg --delete-secret-keys [用户ID] $ gpg --delete-key [用户ID] 输出密钥\n公钥文件（.gnupg/pubring.gpg）以二进制形式储存，armor参数可以将其转换为ASCII码显示。\n$ gpg --armor --output public-key.txt --export [用户ID] \u0026ldquo;用户ID\u0026quot;指定哪个用户的公钥，output参数指定输出文件名（public-key.txt）。\n类似地，export-secret-keys参数可以转换私钥。\n$ gpg --armor --output private-key.txt --export-secret-keys 上传公钥\n公钥服务器是网络上专门储存用户公钥的服务器。send-keys参数可以将公钥上传到服务器。\n$ gpg --send-keys [用户ID] --keyserver hkp://subkeys.pgp.net 使用上面的命令，你的公钥就被传到了服务器subkeys.pgp.net，然后通过交换机制，所有的公钥服务器最终都会包含你的公钥。\n由于公钥服务器没有检查机制，任何人都可以用你的名义上传公钥，所以没有办法保证服务器上的公钥的可靠性。通常，你可以在网站上公布一个公钥指纹，让其他人核对下载到的公钥是否为真。fingerprint参数生成公钥指纹。\n$ gpg --fingerprint [用户ID] 输入密钥\n除了生成自己的密钥，还需要将他人的公钥或者你的其他密钥输入系统。这时可以使用import参数。\n$ gpg --import [密钥文件] 为了获得他人的公钥，可以让对方直接发给你，或者到公钥服务器上寻找。\n$ gpg --keyserver hkp://subkeys.pgp.net --search-keys [用户ID] 正如前面提到的，我们无法保证服务器上的公钥是否可靠，下载后还需要用其他机制验证．\n加密和解密 加密\n假定有一个文本文件demo.txt，怎样对它加密呢？\nencrypt参数用于加密。\n$ gpg --recipient [用户ID] --output demo.en.txt --encrypt demo.txt recipient参数指定接收者的公钥，output参数指定加密后的文件名，encrypt参数指定源文件。运行上面的命令后，demo.en.txt就是已加密的文件，可以把它发给对方。\n解密\n对方收到加密文件以后，就用自己的私钥解密。\n$ gpg --output demo.de.txt --decrypt demo.en.txt output 指定解密后生成的文件，decrypt参数指定需要解密的文件。运行上面的命令，demo.de.txt就是解密后的文件。\nGPG允许省略decrypt参数。\n$ gpg demo.en.txt 签名 对文件签名\n有时，我们不需要加密文件，只需要对文件签名，表示这个文件确实是我本人发出的。sign参数用来签名。\n$ gpg --sign demo.txt 运行上面的命令后，当前目录下生成demo.txt.gpg文件，这就是签名后的文件。这个文件默认采用二进制储存，如果想生成ASCII码的签名文件，可以使用clearsign参数。\n$ gpg --clearsign demo.txt 运行上面的命令后 ，当前目录下生成demo.txt.asc文件，后缀名asc表示该文件是ASCII码形式的。\n如果想生成单独的签名文件，与文件内容分开存放，可以使用detach-sign参数。　$ gpg --detach-sign demo.txt 运行上面的命令后，当前目录下生成一个单独的签名文件demo.txt.sig。该文件是二进制形式的，如果想采用ASCII码形式，要加上armor参数。　$ gpg --armor --detach-sign demo.txt 签名+加密\n上一节的参数，都是只签名不加密。如果想同时签名和加密，可以使用下面的命令。\n$ gpg --local-user [发信者ID] --recipient [接收者ID] --armor --sign --encrypt demo.txt local-user参数指定用发信者的私钥签名，recipient参数指定用接收者的公钥加密，armor参数表示采用ASCII码形式显示，sign参数表示需要签名，encrypt参数表示指定源文件。\n验证签名\n我们收到别人签名后的文件，需要用对方的公钥验证签名是否为真。verify参数用来验证。\n$ gpg --verify demo.txt.asc demo.txt 举例来说，openvpn网站就提供每一个下载包的gpg签名文件。你可以根据它的说明，验证这些下载包是否为真。\nps 简介 要对进程进行监测和控制，首先必须要了解当前进程的情况，也就是需要查看当前进程，而 ps 命令（Process Status）就是最基本同时也是非常强大的进程查看命令。使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等等。总之大部分信息都是可以通过执行该命令得到的。ps命令列出的是当前那些进程的快照，就是执行ps命令的那个时刻的那些进程，如果想要动态的显示进程信息，就可以使用top命令。\nlinux上进程有5种状态：\n  就绪状态和运行状态\n就绪状态的状态标志state的值为TASK_RUNNING。此时，程序已被挂入运行队列，处于准备运行状态。一旦获得处理器使用权，即可进入运行状态。\n当进程获得处理器而运行时 ，state的值仍然为TASK_RUNNING，并不发生改变；但Linux会把一个专门用来指向当前运行任务的指针current指向它，以表示它是一个正在运行的进程。\n  可中断等待状态\n状态标志state的值为TASK_INTERRUPTIBL。此时，由于进程未获得它所申请的资源而处在等待状态。一旦资源有效或者有唤醒信号，进程会立即结束等待而进入就绪状态。\n  不可中断等待状态\n状态标志state的值为TASK_UNINTERRUPTIBL。此时，进程也处于等待资源状态。一旦资源有效，进程会立即进入就绪状态。这个等待状态与可中断等待状态的区别在于：处于TASK_UNINTERRUPTIBL状态的进程不能被信号量或者中断所唤醒，只有当它申请的资源有效时才能被唤醒。\n这个状态被应用在内核中某些场景中，比如当进程需要对磁盘进行读写，而此刻正在DMA中进行着数据到内存的拷贝，如果这时进程休眠被打断（比如强制退出信号）那么很可能会出现问题，所以这时进程就会处于不可被打断的状态下。\n  停止状态\n状态标志state的值为TASK_STOPPED。当进程收到一个SIGSTOP信号后，就由运行状态进入停止状态，当受到一个SIGCONT信号时，又会恢复运行状态。这种状态主要用于程序的调试，又被叫做“暂停状态”、“挂起状态”。\n  中止状态\n状态标志state的值为TASK_DEAD。进程因某种原因而中止运行，进程占有的所有资源将被回收，除了task_struct结构（以及少数资源）以外，并且系统对它不再予以理睬，所以这种状态也叫做“僵死状态”，进程成为僵尸进程。\n  ps 标识进程状态对应的 5 种状态码：\n R：就绪状态和运行状态 runnable (on run queue) S：可中断等待状态 sleeping D：不可中断等待状态 uninterruptible sleep (usually IO) T：停止状态 traced or stopped Z：中止状态 a defunct (”zombie”) process  ps 标识进程的其他状态码：\n X：死掉的进程 Dead （应该不会出现） W：内存交互状态Paging （从 2.6 内核开始无效） N：高优先级 \u0026lt;：低优先级 s：包含子进程 L：被锁入内存 l：多线程状态 +：前台进程  命令参数 在不同的 Linux 发行版上，ps 命令的语法各不相同，为此，Linux 采取了一个折中的方法，即融合各种不同的风格，兼顾那些已经习惯了其它系统上使用 ps 命令的用户。ps命令支持三种使用的语法格式：\n UNIX 风格，选项可以组合在一起，并且选项前必须有“-”连字符； BSD 风格，选项可以组合在一起，但是选项前不能有“-”连字符； GNU 风格的选项，选项前有两个“-”连字符；  ps 命令常用的参数：\nps -a 显示所有终端下执行的进程，包含其他用户的进程 ps -A 显示所有进程 ps -e 和-A功能一样 ps -H 显示树状结构，表示程序间的相互关系 ps -f 全格式显示进程 ps a 显示当前终端下执行的进程 ps c 显示进程的真实名称 ps e 列出程序所使用的环境变量 ps f 用ASCII字符显示树状结构，表达程序间的相互关系 ps x 显示所有进程，无论是否运行在终端上 ps u 显示用户相关的进程或者与用户相关的属性 ps r 只显示正在运行的进程 使用实例 大家如果执行 man ps 命令，则会发现 ps 命令的帮助为了适应不同的类 UNIX 系统，可用格式非常多，不方便记忆。所以，我建议大家记忆几个固定选项即可。\nps aux 查看系统中所有的进程\n# ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.2 2872 1416 ? Ss Jun04 0:02 /sbin/init root 2 0.0 0.0 0 0 ? S Jun04 0:00 [kthreadd] root 3 0.0 0.0 0 0 ? S Jun04 0:00 [migration/0] root 4 0.0 0.0 0 0 ? S Jun04 0:00 [ksoftirqd/0] …省略部分输出… 输出信息中各列的具体含义：\n   表头 含义     USER 该进程是由哪个用户产生的。   PID 进程的 ID。   %CPU 该进程占用 CPU 资源的百分比，占用的百分比越高，进程越耗费资源。   %MEM 该进程占用物理内存的百分比，占用的百分比越高，进程越耗费资源。   VSZ 该进程占用虚拟内存的大小，单位为 KB。   RSS 该进程占用实际物理内存的大小，单位为 KB。   TTY 该进程是在哪个终端运行的。其中，tty1 ~ tty7 代表本地控制台终端（可以通过 Alt+F1 ~ F7 快捷键切换不同的终端），tty1~tty6 是本地的字符界面终端，tty7 是图形终端。pts/0 ~ 255 代表虚拟终端，一般是远程连接的终端，第一个远程连接占用 pts/0，第二个远程连接占用 pts/1，依次増长。   STAT 进程状态。   START 该进程的启动时间。   TIME 该进程占用 CPU 的运算时间，注意不是系统时间。   COMMAND 产生此进程的命令名。    ps -le 查看系统中所有的进程\nps aux 命令可以看到系统中所有的进程，ps -le 命令也能看到系统中所有的进程。由于 -l 选项的作用，所以 ps -le 命令能够看到更加详细的信息，比如父进程的 PID、优先级等。但是这两个命令的基本作用是一致的，掌握其中一个就足够了。\n# ps -le F S UID PID PPID C PRI Nl ADDR SZ WCHAN TTY TIME CMD 4 S 0 1 0 0 80 0 - 718 - ? 00:00:02 init 1 S 0 2 0 0 80 0 - 0 - ? 00:00:00 kthreadd 1 S 0 3 2 0 -40 - - 0 - ? 00:00:00 migration/0 1 S 0 4 2 0 80 0 - 0 - ? 00:00:00 ksoflirqd/0 1 S 0 5 2 0 -40 - - 0 - ? 00:00:00 migration/0 …省略部分输出… 输出信息中各列的含义：\n   表头 含义     F 进程标志，说明进程的权限，常见的标志有两个: 1：进程可以被复制，但是不能被执行；4：进程使用超级用户权限；   S 进程状态。具体的状态和\u0026quot;psaux\u0026quot;命令中的 STAT 状态一致；   UID 运行此进程的用户的 ID；   PID 进程的 ID；   PPID 父进程的 ID；   C 该进程的 CPU 使用率，单位是百分比；   PRI 进程的优先级，数值越小，该进程的优先级越高，越早被 CPU 执行；   NI 进程的优先级，数值越小，该进程越早被执行；   ADDR 该进程在内存的哪个位置；   SZ 该进程占用多大内存；   WCHAN 该进程是否运行。\u0026quot;-\u0026ldquo;代表正在运行；   TTY 该进程由哪个终端产生；   TIME 该进程占用 CPU 的运算时间，注意不是系统时间；   CMD 产生此进程的命令名；    ps -l 查看当前 Shell 产生的进程\n# ps -l F S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD 4 S 0 18618 18614 0 80 0 - 1681 - pts/1 00:00:00 bash 4 R 0 18683 18618 4 80 0 - 1619 - pts/1 00:00:00 ps top 简介 top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。\ntop显示系统当前的进程和其他状况，是一个动态显示过程，即可以通过用户按键来不断刷新当前状态。如果在前台执行该命令，它将独占前台，直到用户终止该程序为止。\n比较准确的说，top命令提供了实时的对系统处理器的状态监视。它将显示系统中CPU最“敏感”的任务列表。该命令可以按CPU使用、内存使用和执行时间对任务进行排序；而且该命令的很多特性都可以通过交互式命令或者在个人定制文件中进行设定。\n命令参数 top 命令的基本格式如下：\n#top [选项] 选项：\n -d 秒数：指定 top 命令每隔几秒更新。默认是 3 秒； -b：使用批处理模式输出。一般和\u0026rdquo;-n\u0026quot;选项合用，用于把 top 命令重定向到文件中； -n 次数：指定 top 命令执行的次数。一般和\u0026rdquo;-b\u0026quot;选项合用； -p 进程PID：仅查看指定 ID 的进程； -s：使 top 命令在安全模式中运行，避免在交互模式中出现错误； -u 用户名：只监听某个用户的进程；  交互操作指令 在 top 命令的显示窗口中，还可以使用如下按键，进行一下交互操作：\n ? 或 h：显示交互模式的帮助 P：按照 CPU 的使用率排序，默认就是此选项 M：按照内存的使用率排序 N：按照 PID 排序 T：按照 CPU 的累积运算时间排序，也就是按照 TIME+ 项排序 k：按照 PID 给予某个进程一个信号。一般用于中止某个进程，信号 9 是强制中止的信号 r：按照 PID 给某个进程重设优先级（Nice）值 \u0026lt;Space\u0026gt;：立即刷新 s：设置刷新时间间隔 c：显示命令完全模式 t:：显示或隐藏进程和CPU状态信息 m：显示或隐藏内存状态信息 l：显示或隐藏uptime信息 f：增加或减少进程显示标志 S：累计模式，会把已完成或退出的子进程占用的CPU时间累计到父进程的TIME+ u：指定显示用户进程 i：只显示正在运行的进程 W：保存对top的设置到文件 ~/.toprc，下次启动将自动调用toprc文件的设置。 q：退出  使用实例 # top top - 12:26:46 up 1 day, 13:32, 2 users, load average: 0.00, 0.00, 0.00 Tasks: 95 total, 1 running, 94 sleeping, 0 stopped, 0 zombie Cpu(s): 0.1%us, 0.1%sy, 0.0%ni, 99.7%id, 0.1%wa, 0.0%hi, 0.1%si, 0.0%st Mem: 625344k total, 571504k used, 53840k free, 65800k buffers Swap: 524280k total, 0k used, 524280k free, 409280k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 19002 root 20 0 2656 1068 856 R 0.3 0.2 0:01.87 top 1 root 20 0 2872 1416 1200 S 0.0 0.2 0:02.55 init 2 root 20 0 0 0 0 S 0.0 0.0 0:00.03 kthreadd 第一行为任务队列信息\n   内 容 说 明     12:26:46 系统当前时间   up 1 day, 13:32 系统的运行时间.本机己经运行 1 天 13 小时 32 分钟   2 users 当前登录了两个用户   load average: 0.00,0.00，0.00 系统在之前 1 分钟、5 分钟、15 分钟的平均负载。如果 CPU 是单核的，则这个数值超过 1 就是高负载：如果 CPU 是四核的，则这个数值超过 4 就是高负载 （这个平均负载完全是依据个人经验来进行判断的，一般认为不应该超过服务器 CPU 的核数）    第二行为进程信息\n   内 容 说 明     Tasks: 95 total 系统中的进程总数   1 running 正在运行的进程数   94 sleeping 睡眠的进程数   0 stopped 正在停止的进程数   0 zombie 僵尸进程数。如果不是 0，则需要手工检查僵尸进程    第三行为 CPU 信息\n   内 容 说 明     Cpu(s): 0.1 %us 用户模式占用的 CPU 百分比   0.1%sy 系统模式占用的 CPU 百分比   0.0%ni 改变过优先级的用户进程占用的 CPU 百分比   99.7%id 空闲 CPU 占用的 CPU 百分比   0.1%wa 等待输入/输出的进程占用的 CPU 百分比   0.0%hi 硬中断请求服务占用的 CPU 百分比   0.1%si 软中断请求服务占用的 CPU 百分比   0.0%st st（steal time）意为虚拟时间百分比，就是当有虚拟机时，虚拟 CPU 等待实际 CPU 的时间百分比    第四行为物理内存信息\n   内 容 说 明     Mem: 625344k total 物理内存的总量，单位为KB   571504k used 己经使用的物理内存数量   53840k free 空闲的物理内存数量。我们使用的是虚拟机，共分配了 628MB内存，所以只有53MB的空闲内存   65800k buffers/cache 作为缓冲的内存数量    缓冲（buffer）和缓存（cache）的区别：\n 缓存（cache）是在读取硬盘中的数据时，把最常用的数据保存在内存的缓存区中，再次读取该数据时，就不去硬盘中读取了，而在缓存中读取。 缓冲（buffer）是在向硬盘写入数据时，先把数据放入缓冲区,然后再一起向硬盘写入，把分散的写操作集中进行，减少磁盘碎片和硬盘的反复寻道，从而提高系统性能。  简单来说，缓存（cache）是用来加速数据从硬盘中\u0026quot;读取\u0026quot;的，而缓冲（buffer）是用来加速数据\u0026quot;写入\u0026quot;硬盘的。\n第五行为交换分区（swap）信息\n   内 容 说 明     Swap: 524280k total 交换分区（虚拟内存）的总大小   Ok used 已经使用的交换分区的大小   524280k free 空闲交换分区的大小   409280k cached 作为缓存的交换分区的大小    第六行为系统进程信息\n再来看 top 命令的第二部分输出，主要是系统进程信息，各个字段的含义如下：\n PID：进程的 ID。 USER：该进程所属的用户。 PR：优先级，数值越小优先级越高。 NI：优先级，数值越小、优先级越高。 VIRT：该进程使用的虚拟内存的大小，单位为 KB。 RES：该进程使用的物理内存的大小，单位为 KB。 SHR：共享内存大小，单位为 KB。 S：进程状态。 %CPU：该进程占用 CPU 的百分比。 %MEM：该进程占用内存的百分比。 TIME+：该进程共占用的 CPU 时间。 COMMAND：进程的命令名。  htop htop 是一个 Linux 下的交互式的进程浏览器，可以用来替换Linux下的top命令。\n与Linux传统的top相比，htop更加人性化。它可让用户交互式操作，支持颜色主题，可横向或纵向滚动浏览进程列表，并支持鼠标操作。\nlsof 简介 lsof 命令，“list opened files”的缩写，直译过来，就是列举系统中已经被打开的文件。通过 lsof 命令，我们就可以根据文件找到对应的进程信息，也可以根据进程信息找到进程打开的文件。\n在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。\n在终端下输入lsof即可显示系统打开的文件，因为 lsof 需要访问核心内存和各种文件，所以必须以 root 用户的身份运行它才能够充分地发挥其功能。\n$ sudo lsof | less COMMAND PID TID TASKCMD USER FD TYPE DEVICE SIZE/OFF NODE NAME systemd 1 root cwd DIR 8,2 4096 2 / systemd 1 root rtd DIR 8,2 4096 2 / systemd 1 root txt REG 8,2 1620224 2491035 /usr/lib/systemd/systemd systemd 1 root mem REG 8,2 1369352 2498532 /usr/lib/x86_64-linux-gnu/libm-2.31.so systemd 1 root mem REG 8,2 178528 2490726 /usr/lib/x86_64-linux-gnu/libudev.so.1.6.17 输出各列信息的意义如下：\n  COMMAND：进程的名称\n  PID：进程标识符\n  PPID：父进程标识符（需要指定-R参数）\n  USER：进程所有者\n  PGID：进程所属组\n  FD：文件描述符（filedescriptor，简称 fd），应用程序通过文件描述符识别该文件类型。\n例如 cwd 表示current work dirctory，即应用程序的当前工作目录，这是该应用程序启动的目录，除非它本身对这个目录进行更改。txt 表示该类型的文件是程序代码，如应用程序二进制文件本身或共享库，如上列表中显示的 /usr/lib/systemd/systemd 程序。\n  TYPE：文件类型，如DIR、REG等，常见的文件类型:\n DIR：目录 REG：普通文件 CHR：字符 BLK：块设备类型 UNIX： UNIX 域套接字 FIFO：先进先出 (FIFO) 队列 IPv4：网际协议 (IP) 套接字    DEVICE：指定磁盘的名称\n  SIZE：文件的大小\n  NODE：索引节点（文件在磁盘上的标识）\n  NAME：打开文件的确切名称\n  命令参数    参数 含义     -a 列出打开文件存在的进程   -c \u0026lt;进程名\u0026gt; 列出指定进程名所打开的文件   -g 列出GID号进程详情   -d \u0026lt;文件号\u0026gt; 列出占用该文件号的进程   +d \u0026lt;目录\u0026gt; 列出目录下被打开的文件   +D \u0026lt;目录\u0026gt; 递归列出目录下被打开的文件   -n \u0026lt;目录\u0026gt; 列出使用NFS的文件   -i \u0026lt;条件\u0026gt; 列出符合条件的进程   -p \u0026lt;进程号\u0026gt; 列出指定进程号所打开的文件   -u 列出UID号进程详情   -h 显示帮助信息   -v 显示版本信息    使用实例 查询某个文件被哪个进程调用\n$ lsof /bin/bash 查询某个目录下所有的文件是被哪些进程调用的\n$ lsof +d /usr/lib 查看以httpd开头的进程调用了哪些文件\n$ lsof -c httpd 查询PID是1的进程调用的文件\n$ lsof -p 1 按照用户名查询某个用户的进程调用的文件\n$ lsof -u username 列出某个用户以及某个进程所打开的文件信息\n$ lsof -u test -c mysql 列出所有的网络连接\n$ lsof -i 列出所有tcp 网络连接信息\n$ lsof -i tcp 列出谁在使用某个端口\n$ lsof -i :3306 列出某个用户的所有活跃的网络端口\n$ lsof -a -u test -i 根据文件描述列出对应的文件信息\n$ lsof -d txt 列出被进程号为1234的进程所打开的所有 IPV4 network files\n$ lsof -i 4 -a -p 1234 列出目前连接主机nf5260i5-td上端口为：20，21，80相关的所有文件信息，且每隔3秒重复执行\n$ lsof -i @nf5260i5-td:20,21,80 -r 3 curl 简介 curl 是常用的命令行工具，用来请求 Web 服务器。它的名字就是客户端（client）的 URL 工具的意思。\n它的功能非常强大，命令行参数多达几十种。如果熟练的话，完全可以取代 Postman 这一类的图形界面工具。\n本文介绍它的主要命令行参数，作为日常的参考，方便查阅。\n不带有任何参数时，curl 就是发出 GET 请求。\n$ curl https://www.example.com 上面命令向www.example.com发出 GET 请求，服务器返回的内容会在命令行输出。\n-A -A参数指定客户端的用户代理标头，即User-Agent。curl 的默认用户代理字符串是curl/[version]。\n$ curl -A \u0026#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36\u0026#39; https://google.com 上面命令将User-Agent改成 Chrome 浏览器。\n$ curl -A \u0026#39;\u0026#39; https://google.com 上面命令会移除User-Agent标头。\n也可以通过-H参数直接指定标头，更改User-Agent。\n$ curl -H \u0026#39;User-Agent: php/1.0\u0026#39; https://google.com -b -b参数用来向服务器发送 Cookie。\n$ curl -b \u0026#39;foo=bar\u0026#39; https://google.com 上面命令会生成一个标头Cookie: foo=bar，向服务器发送一个名为foo、值为bar的 Cookie。\n$ curl -b \u0026#39;foo1=bar;foo2=bar2\u0026#39; https://google.com 上面命令发送两个 Cookie。\n$ curl -b cookies.txt https://www.google.com 上面命令读取本地文件cookies.txt，里面是服务器设置的 Cookie（参见-c参数），将其发送到服务器。\n-c -c参数将服务器设置的 Cookie 写入一个文件。\n$ curl -c cookies.txt https://www.google.com 上面命令将服务器的 HTTP 回应所设置 Cookie 写入文本文件cookies.txt。\n-d -d参数用于发送 POST 请求的数据体。\n$ curl -d \u0026#39;login=emma＆password=123\u0026#39;-X POST https://google.com/login # 或者 $ curl -d \u0026#39;login=emma\u0026#39; -d \u0026#39;password=123\u0026#39; -X POST https://google.com/login 使用-d参数以后，HTTP 请求会自动加上标头Content-Type : application/x-www-form-urlencoded。并且会自动将请求转为 POST 方法，因此可以省略-X POST。\n-d参数可以读取本地文本文件的数据，向服务器发送。\n$ curl -d \u0026#39;@data.txt\u0026#39; https://google.com/login 上面命令读取data.txt文件的内容，作为数据体向服务器发送。\n\u0026ndash;data-urlencode --data-urlencode参数等同于-d，发送 POST 请求的数据体，区别在于会自动将发送的数据进行 URL 编码。\n$ curl --data-urlencode \u0026#39;comment=hello world\u0026#39; https://google.com/login 上面代码中，发送的数据hello world之间有一个空格，需要进行 URL 编码。\n-e -e参数用来设置 HTTP 的标头Referer，表示请求的来源。\ncurl -e \u0026#39;https://google.com?q=example\u0026#39; https://www.example.com 上面命令将Referer标头设为https://google.com?q=example。\n-H参数可以通过直接添加标头Referer，达到同样效果。\ncurl -H \u0026#39;Referer: https://google.com?q=example\u0026#39; https://www.example.com -F\n-F参数用来向服务器上传二进制文件。\n$ curl -F \u0026#39;file=@photo.png\u0026#39; https://google.com/profile 上面命令会给 HTTP 请求加上标头Content-Type: multipart/form-data，然后将文件photo.png作为file字段上传。\n-F参数可以指定 MIME 类型。\n$ curl -F \u0026#39;file=@photo.png;type=image/png\u0026#39; https://google.com/profile 上面命令指定 MIME 类型为image/png，否则 curl 会把 MIME 类型设为application/octet-stream。\n-F参数也可以指定文件名。\n$ curl -F \u0026#39;file=@photo.png;filename=me.png\u0026#39; https://google.com/profile 上面命令中，原始文件名为photo.png，但是服务器接收到的文件名为me.png。\n-G -G参数用来构造 URL 的查询字符串。\n$ curl -G -d \u0026#39;q=kitties\u0026#39; -d \u0026#39;count=20\u0026#39; https://google.com/search 上面命令会发出一个 GET 请求，实际请求的 URL 为https://google.com/search?q=kitties\u0026amp;count=20。如果省略--G，会发出一个 POST 请求。\n如果数据需要 URL 编码，可以结合--data--urlencode参数。\n$ curl -G --data-urlencode \u0026#39;comment=hello world\u0026#39; https://www.example.com -H -H参数添加 HTTP 请求的标头。\n$ curl -H \u0026#39;Accept-Language: en-US\u0026#39; https://google.com 上面命令添加 HTTP 标头Accept-Language: en-US。\n$ curl -H \u0026#39;Accept-Language: en-US\u0026#39; -H \u0026#39;Secret-Message: xyzzy\u0026#39; https://google.com 上面命令添加两个 HTTP 标头。\n$ curl -d \u0026#39;{\u0026#34;login\u0026#34;: \u0026#34;emma\u0026#34;, \u0026#34;pass\u0026#34;: \u0026#34;123\u0026#34;}\u0026#39; -H \u0026#39;Content-Type: application/json\u0026#39; https://google.com/login 上面命令添加 HTTP 请求的标头是Content-Type: application/json，然后用-d参数发送 JSON 数据。\n-i -i参数打印出服务器回应的 HTTP 标头。\n$ curl -i https://www.example.com 上面命令收到服务器回应后，先输出服务器回应的标头，然后空一行，再输出网页的源码。\n-I -I参数向服务器发出 HEAD 请求，然会将服务器返回的 HTTP 标头打印出来。\n$ curl -I https://www.example.com 上面命令输出服务器对 HEAD 请求的回应。\n--head参数等同于-I。\n$ curl --head https://www.example.com -k -k参数指定跳过 SSL 检测。\n$ curl -k https://www.example.com 上面命令不会检查服务器的 SSL 证书是否正确。\n-L -L参数会让 HTTP 请求跟随服务器的重定向。curl 默认不跟随重定向。\n$ curl -L -d \u0026#39;tweet=hi\u0026#39; https://api.twitter.com/tweet \u0026ndash;limit-rate4 --limit-rate用来限制 HTTP 请求和回应的带宽，模拟慢网速的环境。\n$ curl --limit-rate 200k https://google.com 上面命令将带宽限制在每秒 200K 字节。\n-o -o参数将服务器的回应保存成文件，等同于wget命令。\n$ curl -o example.html https://www.example.com 上面命令将www.example.com保存成example.html。\n-O -O参数将服务器回应保存成文件，并将 URL 的最后部分当作文件名。\n$ curl -O https://www.example.com/foo/bar.html 上面命令将服务器回应保存成文件，文件名为bar.html。\n-s -s参数将不输出错误和进度信息。\n$ curl -s https://www.example.com 上面命令一旦发生错误，不会显示错误信息。不发生错误的话，会正常显示运行结果。\n如果想让 curl 不产生任何输出，可以使用下面的命令。\n$ curl -s -o /dev/null https://google.com -S -S参数指定只输出错误信息，通常与-s一起使用。\n$ curl -s -o /dev/null https://google.com 上面命令没有任何输出，除非发生错误。\n-u -u参数用来设置服务器认证的用户名和密码。\n$ curl -u \u0026#39;bob:12345\u0026#39; https://google.com/login 上面命令设置用户名为bob，密码为12345，然后将其转为 HTTP 标头Authorization: Basic Ym9iOjEyMzQ1。\ncurl 能够识别 URL 里面的用户名和密码。\n$ curl https://bob:12345@google.com/login 上面命令能够识别 URL 里面的用户名和密码，将其转为上个例子里面的 HTTP 标头。\n$ curl -u \u0026#39;bob\u0026#39; https://google.com/login 上面命令只设置了用户名，执行后，curl 会提示用户输入密码。\n-v -v参数输出通信的整个过程，用于调试。\n$ curl -v https://www.example.com --trace参数也可以用于调试，还会输出原始的二进制数据。\n$ curl --trace - https://www.example.com -x -x参数指定 HTTP 请求的代理。\n$ curl -x socks5://james:cats@myproxy.com:8080 https://www.example.com 上面命令指定 HTTP 请求通过myproxy.com:8080的 socks5 代理发出。\n如果没有指定代理协议，默认为 HTTP。\n$ curl -x james:cats@myproxy.com:8080 https://www.example.com 上面命令中，请求的代理使用 HTTP 协议。\n-X -X参数指定 HTTP 请求的方法。\n$ curl -X POST https://www.example.com 上面命令对https://www.example.com发出 POST 请求。\nwrite 在服务器上，有时会有多个用户同时登录，一些必要的沟通就显得尤为重要。比如,我必须关闭某个服务，或者需要重启服务器，当然需要通知同时登录服务器的用户，这时就可以使用 write 命令。\nwrite 命令的信息如下：\n 命令名称：write。 英文原意：send a message to another user。 所在路径：/usr/bin/write。 执行权限：所有用户。 功能描述：向其他用户发送信息。  write 命令的基本格式如下:\n$ write 用户名 [终端号] write 命令没有多余的选项，我们要向在某个终端登录的用户发送信息，就可以这样来执行命令：\n# 向在pts/1 (远程终端1)登录的user1用户发送信息，使用\u0026#34;Ctrl+D\u0026#34;快捷键保存发送的数据 $ write user1 pts/1 hello I will be in 5 minutes to restart, please save your data 这时，user1 用户就可以收到你要在 5 分钟之后重启系统的信息了。\nxargs 标准输入与管道命令 Unix 命令都带有参数，有些命令可以接受\u0026quot;标准输入\u0026quot;（stdin）作为参数。\n$ cat /etc/passwd | grep root 上面的代码使用了管道命令（|）。管道命令的作用，是将左侧命令（cat /etc/passwd）的标准输出转换为标准输入，提供给右侧命令（grep root）作为参数。\n因为grep命令可以接受标准输入作为参数，所以上面的代码等同于下面的代码。\n$ grep root /etc/passwd 但是，大多数命令都不接受标准输入作为参数，只能直接在命令行输入参数，这导致无法用管道命令传递参数。举例来说，echo命令就不接受管道传参。\n$ echo \u0026#34;hello world\u0026#34; | echo 上面的代码不会有输出。因为管道右侧的echo不接受管道传来的标准输入作为参数。\nxargs 命令的作用 xargs命令的作用，是将标准输入转为命令行参数。\n$ echo \u0026#34;hello world\u0026#34; | xargs echo hello world 上面的代码将管道左侧的标准输入，转为命令行参数hello world，传给第二个echo命令。\nxargs命令的格式如下。\n$ xargs [-options] [command] 真正执行的命令，紧跟在xargs后面，接受xargs传来的参数。\nxargs的作用在于，大多数命令（比如rm、mkdir、ls）与管道一起使用时，都需要xargs将标准输入转为命令行参数。\n$ echo \u0026#34;one two three\u0026#34; | xargs mkdir 上面的代码等同于mkdir one two three。如果不加xargs就会报错，提示mkdir缺少操作参数。\nxargs 的单独使用 xargs后面的命令默认是echo。\n$ xargs # 等同于 $ xargs echo 大多数时候，xargs命令都是跟管道一起使用的。但是，它也可以单独使用。\n输入xargs按下回车以后，命令行就会等待用户输入，作为标准输入。你可以输入任意内容，然后按下Ctrl d，表示输入结束，这时echo命令就会把前面的输入打印出来。\n$ xargs hello (Ctrl + d) hello 再看一个例子。\n$ xargs find -name \u0026#34;*.txt\u0026#34; ./foo.txt ./hello.txt 上面的例子输入xargs find -name以后，命令行会等待用户输入所要搜索的文件。用户输入\u0026quot;*.txt\u0026quot;，表示搜索当前目录下的所有 TXT 文件，然后按下Ctrl d，表示输入结束。这时就相当执行find -name *.txt。\n-d 参数与分隔符 默认情况下，xargs将换行符和空格作为分隔符，把标准输入分解成一个个命令行参数。\n$ echo \u0026#34;one two three\u0026#34; | xargs mkdir 上面代码中，mkdir会新建三个子目录，因为xargs将one two three分解成三个命令行参数，执行mkdir one two three。\n-d参数可以更改分隔符。\n$ echo -e \u0026#34;a\\tb\\tc\u0026#34; | xargs -d \u0026#34;\\t\u0026#34; echo a b c 上面的命令指定制表符\\t作为分隔符，所以a\\tb\\tc就转换成了三个命令行参数。echo命令的-e参数表示解释转义字符。\n-p 参数，-t 参数 使用xargs命令以后，由于存在转换参数过程，有时需要确认一下到底执行的是什么命令。\n-p参数打印出要执行的命令，询问用户是否要执行。\n$ echo \u0026#39;one two three\u0026#39; | xargs -p touch touch one two three ?... 上面的命令执行以后，会打印出最终要执行的命令，让用户确认。用户输入y以后（大小写皆可），才会真正执行。\n-t参数则是打印出最终要执行的命令，然后直接执行，不需要用户确认。\n$ echo \u0026#39;one two three\u0026#39; | xargs -t rm rm one two three -0 参数与 find 命令 由于xargs默认将空格作为分隔符，所以不太适合处理文件名，因为文件名可能包含空格。\nfind命令有一个特别的参数-print0，指定输出的文件列表以null分隔。然后，xargs命令的-0参数表示用null当作分隔符。\n$ find /path -type f -print0 | xargs -0 rm 上面命令删除/path路径下的所有文件。由于分隔符是null，所以处理包含空格的文件名，也不会报错。\n还有一个原因，使得xargs特别适合find命令。有些命令（比如rm）一旦参数过多会报错\u0026quot;参数列表过长\u0026quot;，而无法执行，改用xargs就没有这个问题，因为它对每个参数执行一次命令。\n$ find . -name \u0026#34;*.txt\u0026#34; | xargs grep \u0026#34;abc\u0026#34; 上面命令找出所有 TXT 文件以后，对每个文件搜索一次是否包含字符串abc。\n-L 参数 如果标准输入包含多行，-L参数指定多少行作为一个命令行参数。\n$ xargs find -name \u0026#34;*.txt\u0026#34; \u0026#34;*.md\u0026#34; find: paths must precede expression: `*.md\u0026#39; 上面命令同时将\u0026quot;*.txt\u0026quot;和*.md两行作为命令行参数，传给find命令导致报错。\n使用-L参数，指定每行作为一个命令行参数，就不会报错。\n$ xargs -L 1 find -name \u0026#34;*.txt\u0026#34; ./foo.txt ./hello.txt \u0026#34;*.md\u0026#34; ./README.md 上面命令指定了每一行（-L 1）作为命令行参数，分别运行一次命令（find -name）。\n下面是另一个例子。\n$ echo -e \u0026#34;a\\nb\\nc\u0026#34; | xargs -L 1 echo a b c 上面代码指定每行运行一次echo命令，所以echo命令执行了三次，输出了三行。\n-n 参数 -L参数虽然解决了多行的问题，但是有时用户会在同一行输入多项。\n$ xargs find -name \u0026#34;*.txt\u0026#34; \u0026#34;*.md\u0026#34; find: paths must precede expression: `*.md\u0026#39; 上面的命令将同一行的两项作为命令行参数，导致报错。\n-n参数指定每次将多少项，作为命令行参数。\n$ xargs -n 1 find -name 上面命令指定将每一项（-n 1）标准输入作为命令行参数，分别执行一次命令（find -name）。\n下面是另一个例子。\n$ echo {0..9} | xargs -n 2 echo 0 12 34 56 78 9 上面命令指定，每两个参数运行一次echo命令。所以，10个阿拉伯数字运行了五次echo命令，输出了五行。\n-I 参数 如果xargs要将命令行参数传给多个命令，可以使用-I参数。\n-I指定每一项命令行参数的替代字符串。\n$ cat foo.txt one two three $ cat foo.txt | xargs -I file sh -c \u0026#39;echo file; mkdir file\u0026#39; one two three $ ls one two three 上面代码中，foo.txt是一个三行的文本文件。我们希望对每一项命令行参数，执行两个命令（echo和mkdir），使用-I file表示file是命令行参数的替代字符串。执行命令时，具体的参数会替代掉echo file; mkdir file里面的两个file。\n\u0026ndash;max-procs 参数 xargs默认只用一个进程执行命令。如果命令要执行多次，必须等上一次执行完，才能执行下一次。\n--max-procs参数指定同时用多少个进程并行执行命令。--max-procs 2表示同时最多使用两个进程，--max-procs 0表示不限制进程数。\n$ docker ps -q | xargs -n 1 --max-procs 0 docker kill 上面命令表示，同时关闭尽可能多的 Docker 容器，这样运行速度会快很多。\nawk awk是处理文本文件的一个应用程序，几乎所有 Linux 系统都自带这个程序。\n它依次处理文件的每一行，并读取里面的每一个字段。对于日志、CSV 那样的每行格式相同的文本文件，awk可能是最方便的工具。\nawk其实不仅仅是工具软件，还是一种编程语言。不过，本文只介绍它的命令行用法，对于大多数场合，应该足够用了。\n基本用法 awk的基本用法就是下面的形式。\n# 格式 $ awk 动作 文件名 # 示例 $ awk \u0026#39;{print $0}\u0026#39; demo.txt 上面示例中，demo.txt是awk所要处理的文本文件。前面单引号内部有一个大括号，里面就是每一行的处理动作print $0。其中，print是打印命令，$0代表当前行，因此上面命令的执行结果，就是把每一行原样打印出来。\n下面，我们先用标准输入（stdin）演示上面这个例子。\n$ echo \u0026#39;this is a test\u0026#39; | awk \u0026#39;{print $0}\u0026#39; this is a test 上面代码中，print $0就是把标准输入this is a test，重新打印了一遍。\nawk会根据空格和制表符，将每一行分成若干字段，依次用$1、$2、$3代表第一个字段、第二个字段、第三个字段等等。\n$ echo \u0026#39;this is a test\u0026#39; | awk \u0026#39;{print $3}\u0026#39; a 上面代码中，$3代表this is a test的第三个字段a。\n下面，为了便于举例，我们把/etc/passwd文件保存成demo.txt。\nroot❌0:0:root:/root:/usr/bin/zsh daemon❌1:1:daemon:/usr/sbin:/usr/sbin/nologin bin❌2:2:bin:/bin:/usr/sbin/nologin sys❌3:3:sys:/dev:/usr/sbin/nologin sync❌4:65534:sync:/bin:/bin/sync 这个文件的字段分隔符是冒号（:），所以要用-F参数指定分隔符为冒号。然后，才能提取到它的第一个字段。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{ print $1 }\u0026#39; demo.txt root daemon bin sys sync 变量 除了$ + 数字表示某个字段，awk还提供其他一些变量。\n变量NF表示当前行有多少个字段，因此$NF就代表最后一个字段。\n$ echo \u0026#39;this is a test\u0026#39; | awk \u0026#39;{print $NF}\u0026#39; test $(NF-1)代表倒数第二个字段。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{print $1, $(NF-1)}\u0026#39; demo.txt root /root daemon /usr/sbin bin /bin sys /dev sync /bin 上面代码中，print命令里面的逗号，表示输出的时候，两个部分之间使用空格分隔。\n变量NR表示当前处理的是第几行。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{print NR \u0026#34;) \u0026#34; $1}\u0026#39; demo.txt 1) root 2) daemon 3) bin 4) sys 5) sync 上面代码中，print命令里面，如果原样输出字符，要放在双引号里面。\nawk的其他内置变量如下。\n FILENAME：当前文件名 FS：字段分隔符，默认是空格和制表符。 RS：行分隔符，用于分割每一行，默认是换行符。 OFS：输出字段的分隔符，用于打印时分隔字段，默认为空格。 ORS：输出记录的分隔符，用于打印时分隔记录，默认为换行符。 OFMT：数字输出的格式，默认为％.6g。  函数 awk还提供了一些内置函数，方便对原始数据的处理。\n函数toupper()用于将字符转为大写。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{ print toupper($1) }\u0026#39; demo.txt ROOT DAEMON BIN SYS SYNC 上面代码中，第一个字段输出时都变成了大写。\n其他常用函数如下。\n tolower()：字符转为小写。 length()：返回字符串长度。 substr()：返回子字符串。 sin()：正弦。 cos()：余弦。 sqrt()：平方根。 rand()：随机数。  awk内置函数的完整列表，可以查看手册。\n条件 awk允许指定输出条件，只输出符合条件的行。\n输出条件要写在动作的前面。\n$ awk \u0026#39;条件 动作\u0026#39; 文件名 请看下面的例子。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;/usr/ {print $1}\u0026#39; demo.txt root daemon bin sys 上面代码中，print命令前面是一个正则表达式，只输出包含usr的行。\n下面的例子只输出奇数行，以及输出第三行以后的行。\n# 输出奇数行 $ awk -F \u0026#39;:\u0026#39; \u0026#39;NR % 2 == 1 {print $1}\u0026#39; demo.txt root bin sync # 输出第三行以后的行 $ awk -F \u0026#39;:\u0026#39; \u0026#39;NR \u0026gt;3 {print $1}\u0026#39; demo.txt sys sync 下面的例子输出第一个字段等于指定值的行。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;$1 == \u0026#34;root\u0026#34; {print $1}\u0026#39; demo.txt root $ awk -F \u0026#39;:\u0026#39; \u0026#39;$1 == \u0026#34;root\u0026#34; || $1 == \u0026#34;bin\u0026#34; {print $1}\u0026#39; demo.txt root bin if 语句 awk提供了if结构，用于编写复杂的条件。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{if ($1 \u0026gt; \u0026#34;m\u0026#34;) print $1}\u0026#39; demo.txt root sys sync 上面代码输出第一个字段的第一个字符大于m的行。\nif结构还可以指定else部分。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{if ($1 \u0026gt; \u0026#34;m\u0026#34;) print $1; else print \u0026#34;---\u0026#34;}\u0026#39; demo.txt root --- --- sys sync TIPS BackupYourSystem Remote backup 用于那些不常用、体积大、但是必要的资料，比如多媒体（视频、音频、图片等）、电子书、游戏、软件等等。本地存储的话成本太高，百度云有2T的完全免费空间（虽然下载慢）。\nLocal backup 本地同一硬盘备份\n目的在于恢复系统出现的错误。类似于虚拟机的快照。我使用 rsync\n#!/bin/bash  set -o errexit set -o nounset set -o pipefail readonly SOURCE_DIR=\u0026#34;/\u0026#34; readonly BACKUP_DIR=\u0026#34;/backup\u0026#34; readonly DATETIME=\u0026#34;$(date \u0026#39;+%Y-%m-%d_%H:%M:%S\u0026#39;)\u0026#34; readonly BACKUP_PATH=\u0026#34;${BACKUP_DIR}/${DATETIME}\u0026#34; readonly LATEST_LINK=\u0026#34;${BACKUP_DIR}/latest\u0026#34; rsync -av \\ \t--delete \u0026#34;${SOURCE_DIR}/\u0026#34; \\ \t--link-dest \u0026#34;${LATEST_LINK}\u0026#34; \\ \t--exclude={\u0026#34;dev\u0026#34;,\u0026#34;proc\u0026#34;,\u0026#34;sys\u0026#34;,\u0026#34;tmp\u0026#34;,\u0026#34;run\u0026#34;,\u0026#34;mnt\u0026#34;,\u0026#34;media\u0026#34;,\u0026#34;lost+found\u0026#34;,\u0026#34;.cache\u0026#34;,\u0026#34;Trash\u0026#34;,\u0026#34;你的备份目录\u0026#34;} \\ \t\u0026#34;${BACKUP_PATH}\u0026#34; rm -rf \u0026#34;${LATEST_LINK}\u0026#34; ln -s \u0026#34;${BACKUP_PATH}\u0026#34; \u0026#34;${LATEST_LINK}\u0026#34; 注意：\n ${SOURCE_DIR}/必须带反斜杠，否则会备份SOURCE_DIR这个目录，而不是这个目录里的内容。 --exclude=\u0026quot;Trash\u0026quot;，Trash被认为为目录，而非文件或文件和目录，并且，它不支持路径~/.local/share/Trash 还原的时候，如果带 --delete，那么就会删除备份时 --exclude= 不包含的内容。还原的时候，同名文件内容会恢复到备份时候的状态。  $ rsync -av 备份目录 源目录 $ rsync -av /backup/latest/ / 查看备份大小\n$ sudo du -hs /backup/ 16G\t/backup/ 整个备份为16GB，所花时间 12m。\n通过 crontab 使之每周一12点自动备份：\n$ sudo crontab -e 0 12 * * 1 /path/.backup.sh 本地不同硬盘备份\n目的在于保存重要数据，以防硬盘损坏。\n#!/bin/bash rsync -av --delete --exclude={\u0026#39;Backup\u0026#39;,\u0026#39;lost+found\u0026#39;} DataToo/ DataOne/Backup/ 清理系统 删除不再需要的包 $ sudo apt autoremove APT cache # see the size of this cache $ sudo du -sh /var/cache/apt # remove only the outdated packages $ sudo apt-get autoclean # delete apt cache in its entirety $ sudo apt-get clean apt-get 和软件中心下载的软件包一般放在 /var/cache/apt/archives/ 目录，一般都安装在 /usr/\nJournal logs # check the log size $ journalctl --disk-usage # clear the logs that are older than a certain days $ journalctl --vacuum-time=3d Thumbnails cache # check the size of thumbnail cache $ du -sh ~/.cache/thumbnails $ rm -rf ~/.cache/thumbnails/* Duplicate files Find and remove duplicate files：You can use a GUI tool like FSlint or a command line tool like FDUPES for this task\nOld Linux kernels Remove old Linux kernels\n# List all installed Linux kernels $ sudo dpkg --list \u0026#39;linux-image*\u0026#39; $ apt-get remove linux-image-VERSION 命令行技巧 Bash 快捷键 编辑命令\n Ctrl + a ：移到命令行首 Ctrl + e ：移到命令行尾 Ctrl + f ：按字符前移（右向） Ctrl + b ：按字符后移（左向） Alt + f ：按单词前移（右向） Alt + b ：按单词后移（左向） Ctrl + xx：在命令行首和光标之间移动 Ctrl + u ：从光标处删除至命令行首 Ctrl + k ：从光标处删除至命令行尾 Ctrl + w ：从光标处删除至字首 Alt + d ：从光标处删除至字尾 Ctrl + d ：删除光标处的字符 Ctrl + h ：删除光标前的字符 Ctrl + y ：粘贴至光标后 Alt + c ：从光标处更改为首字母大写的单词 Alt + u ：从光标处更改为全部大写的单词 Alt + l ：从光标处更改为全部小写的单词 Ctrl + t ：交换光标处和之前的字符 Alt + t ：交换光标处和之前的单词 Alt + Backspace：与 Ctrl + w 类似，分隔符有些差别  重新执行命令\n Ctrl + r：逆向搜索命令历史 Ctrl + g：从历史搜索模式退出 Ctrl + p：历史中的上一条命令 Ctrl + n：历史中的下一条命令 Alt + .：使用上一条命令的最后一个参数  控制命令\n Ctrl + l：清屏 Ctrl + o：执行当前命令，并选择上一条命令 Ctrl + s：阻止屏幕输出 Ctrl + q：允许屏幕输出 Ctrl + c：终止命令 Ctrl + z：挂起命令  Bang (!) 命令\n !!：执行上一条命令 !blah：执行最近的以 blah 开头的命令，如 !ls !blah:p：仅打印输出，而不执行 !$：上一条命令的最后一个参数，与 Alt + . 相同 !$:p：打印输出 !$ 的内容 !*：上一条命令的所有参数 !*:p：打印输出 !* 的内容 ^blah：删除上一条命令中的 blah ^blah^foo：将上一条命令中的 blah 替换为 foo ^blah^foo^：将上一条命令中所有的 blah 都替换为 foo  你可能不知道的SHELL Shell也叫做命令行界面，它是*nix操作系统下用户和计算机的交互界面。Shell这个词是指操作系统中提供访问内核服务的程序。\n这篇文章向大家介绍Shell一些非广为人知、但却实用有趣的知识，权当品尝shell主食后的甜点吧。\n科普\n先科普几个你可能不知道的事实：\n  Shell几乎是和Unix操作系统一起诞生，第一个Unix Shell是肯·汤普逊（Ken Thompson）以Multics上的Shell为模范在1971年改写而成，并命名Thompson sh。即便是后来流行的bash（shell的一种变体），它的年龄实际上比当前流行的所有的Linux kernel都大，可谓在Linux系统上是先有Shell再有Kernel。\n  当前绝大部分*nix和MacOS操作系统里的默认的Shell都是bash，bash由Brian Fox在1987年创造，全称Bourne Again shell ( bash)。\n  你或许听说除了bash之外，还有Bourne shell ( sh)，Korn shell ( ksh)，C shell （包括 csh and tcsh），但是你知道这个星球上一共存在着大约50多种不同的shell么？想了解他们，请参考 http://www.freebsd.org/ports/shells.html。\n  一些强大的命令\n  在命令行前加空格，该命令不会进入history里。\n  ctrl-x e\n快速启动你的默认编辑器（由变量$EDITOR设置）。\n  为什么说 zsh 是 shell 中的极品？ 色彩高亮\n并不是传统基于正则表达式的色彩高亮，而是真的会判断你输入的是啥的色彩高亮。\n比如一个主题白色代表普通命令或者程序，红色代表错误命令，青色的代表内建命令或者 alias （echo 和 ls ），这些都不是正则判断出来的，是真的去检查的。非零的错误码（上一条命令错误），也可以高亮显示。\n命令提示\n注意，命令提示和补全是两个完全不同的系统，很多时候提示比补全更有用。你输入命令，后面就用灰色给你提示命令的参数，而且是随着你动态输入完每一个字母不断修正变化。\n这个命令提示是基于你的历史命令数据库进行分析的，随着你输入的命令越来越多，提示将会越来越准确和顺手。\n如果你觉得它提示的正确，你可以 CTRL+F 表示采纳，后面就会自动帮你一次性全部输入完了。\n智能补全\n缩写路径补全：\n$ cd /v/w/h 敲一个TAB\n$ cd /var/www/html/ 补全目录、命令参数补全连敲两次TAB进入选择模式，除了 tab/shift+tab 可以前后切换外，你还可以使用光标键上下左右移动。回车表示确认选择，用 CTRL+G 表示退出。\n快速跳转\n输入 cd 后面加一个减号后，按一次 tab 马上就列出本次登陆后去过的最近几次路径，接着根据下面的提示输入数字按回车就过去了，比如输入：\n$ cd -5 \u0026lt;回车\u0026gt; 当然你还可以不输入数字，而是再按一次 tab 进入选择模式，上下键或者 ctrl+n/p 来选择，回车确认，ctrl+g 返回。\n自动跳转\n敲入 z 命令，列出了自从我开始用zsh进入过的目录和他们的权重，进入次数越多，权重越大。z 后面加一个关键词就能跳转到所有匹配的历史路径中权重最高的那个了。空格分隔多个关键字，z会先匹配出第一个来，然后再匹配第二个\u0026hellip;\n使用：“z -l foo\u0026quot; 可以列出包含 foo 的所有历史路径。\n# 按下ALT+O 就执行 cd .. 命令 bindkey -s \u0026#39;\\eo\u0026#39; \u0026#39;cd ..\\n\u0026#39; # 按下 ALT+; 就执行 ls -l 命令 bindkey -s \u0026#39;\\e;\u0026#39; \u0026#39;ls -l\\n\u0026#39; 热键绑定\nzsh 里面使用 bindkey 命令可以设置一系列热键，用来运行某一个 zsh 内部命令或者某个 shell 命令。\n应该知道的LINUX技巧 首先，我想告诉大家，在Unix/Linux下，最有效率技巧的不是操作图形界面，而是命令行操作，因为命令行意味着自动化。\n日常\n  请man bash后查找Readline Key Bindings一节来看看bash的默认热键，比如：Alt-. 把上一次命令的最后一个参数打出来，而Alt-* 则列出你可以输入的命令。\n  回到上一次的工作目录： cd – （回到home是 cd ~）\n  pstree -p 可以帮你显示进程树。\n  使用 pgrep 和 pkill 来找到或是kill 某个名字的进程。 (-f 选项很有用).\n  通过 \u0026lt;(some command) 可以把某命令当成一个文件。示例：比较一个本地文件和远程文件 /etc/hosts： diff /etc/hosts \u0026lt;(ssh somehost cat /etc/hosts)\n  在 bash中，使用重定向到标准输出和标准错误。如： some-command \u0026gt;logfile 2\u0026gt;\u0026amp;1。\n  使用 man ascii 来查看 ASCII 表。\n  系统调试\n  如果你想知道磁盘、CPU、或网络状态，你可以使用 iostat, netstat, top (或更好的 htop), 还有 dstat 命令。你可以很快地知道你的系统发生了什么事。关于这方面的命令，还有iftop, iotop等。\n  要了解内存的状态，你可以使用free和vmstat命令。具体来说，你需要注意 “cached” 的值，这个值是Linux内核占用的内存。还有free的值。\n  如果你要找到哪个socket或进程在使用网络带宽，你可以使用 iftop 或 nethogs。\n  如果你要抓网络包的话，试试 wireshark 或 tshark。\n  了解 strace 和 ltrace。这两个命令可以让你查看进程的系统调用，这有助于你分析进程的hang在哪了，怎么crash和failed的。你还可以用其来做性能profile，使用 -c 选项，你可以使用-p选项来attach上任意一个进程。\n  了解用ldd命令来检查相关的动态链接库。注意：ldd的安全问题\n  使用gdb来调试一个正在运行的进程或分析core dump文件。参看我写的《GDB中应该知道的几个调试方法》\n  学会到 /proc 目录中查看信息。这是一个Linux内核运行时记录的整个操作系统的运行统计和信息，比如： /proc/cpuinfo, /proc/xxx/cwd, /proc/xxx/exe, /proc/xxx/fd/, /proc/xxx/smaps.\n  如果你调试某个东西为什么出错时，sar命令会有用。它可以让你看看 CPU, 内存, 网络, 等的统计信息。\n  使用 dmesg 来查看一些硬件或驱动程序的信息或问题。\n  powerline-shell 不想每次都安装 zsh 与 ohmyzsh？\n$ pip install powerline-shell Add the following to your .bashrc file:\nfunction _update_ps1() { PS1=$(powerline-shell $?) } if [[ $TERM != linux \u0026amp;\u0026amp; ! $PROMPT_COMMAND =~ _update_ps1 ]]; then PROMPT_COMMAND=\u0026#34;_update_ps1; $PROMPT_COMMAND\u0026#34; fi 默认的话，路径会完整显示，会很长\ngenerate the default config at this location using:\n$ mkdir -p ~/.config/powerline-shell \u0026amp;\u0026amp; \\ powerline-shell --generate-config \u0026gt; ~/.config/powerline-shell/config.json Segment Configuration\n{ \u0026#34;segments\u0026#34;: [ \u0026#34;virtual_env\u0026#34;, \u0026#34;username\u0026#34;, \u0026#34;hostname\u0026#34;, \u0026#34;ssh\u0026#34;, \u0026#34;cwd\u0026#34;, \u0026#34;git\u0026#34;, \u0026#34;hg\u0026#34;, \u0026#34;jobs\u0026#34;, \u0026#34;root\u0026#34; ], + \u0026#34;cwd\u0026#34;: + { + \u0026#34;max_depth\u0026#34;: 1 +\t} } du (Disk Usage) 在 Linux 中使用 ls 命令 列出的目录内容中，目录的大小仅显示 4KB。这是一个默认的大小，是用来存储磁盘上存储目录的元数据的大小。\ndu 命令 表示 磁盘使用率。这是一个标准的 Unix 程序，用于估计当前工作目录中的文件空间使用情况。\n它使用递归方式总结磁盘使用情况，以获取目录及其子目录的大小。\n$ du -hs --max-depth=0 /path/dir  du – 这是一个命令 -h – 以易读的格式显示大小 (例如 1K 234M 2G) -s – 仅显示每个参数的总数 --max-depth=N – 目录的打印深度  Gnome GNOME 系统设置面板（gnome-control-center）和 GNOME 应用使用 dconf 配置系统存储设置。您可以使用 gsettings 或 dconf 命令行工具直接访问 dconf 数据库。这也可以让你修改用户界面不公开的设置。\nGNOME 桌面拥有强大的搜索功能，按 Super 键并搜索一些东西，可以进入“Settings-Search”中来设置可以搜索的内容和顺序。\nDo Not Disturb 使通知只在消息栏中，不会在桌面上弹出。\nGnome 3 自动切换的壁纸会有一个有时钟小图标。\nTweaks GNOME 桌面有称为“扩展”的小插件或附加组件，学会使用 GNOME 扩展来扩展系统的可用性。\n$ apt install gnome-tweaks 同时会安装新的 GNOME Shell extensions，可以禁用桌面图标、Ubuntu Dock。可从浏览器安装 GNOME Shell extensions。\n如 OpenWeather，需设置 Location，Units 为公制单位，Layout为Right\ntheme design: Skeuomorphism vs Flat Design vs Material Design\n 主题目录： /usr/share/themes 或 ~/.themes 图标鼠标目录： /usr/share/icons 或 ~/.icons 壁纸： /usr/share/background , /usr/share/wallpapers  Ubuntu Dock Ubuntu Dock 就是 Dash to Dock。\n安装\n$ sudo apt-get install gnome-shell-extension-dashtodock 重启，在 Extension 中设置 Dash to Dock，Dash to Dock 与 Ubuntu Dock 只能开启一个，否则有两个 Dock，但是就算关闭 Dash to Dock，Dash to Dock 设置依旧起作用到 Ubuntu Dock。\n重新登录。\n修改文件默认关联的应用程序  mime类型文件存在于以下的两个路径：  /usr/share/mime ~/.local/share/mime    /usr/share/mime/text/makrdown.xml  应用程序的desktop文件，存在于以下的两个路径：  /usr/share/applications ~/.local/share/applications    [Desktop Entry] # 应用名称，即开始菜单中的名称 Type=ApplicationName=name # 应用执行文件位置 Exec=appPath # 应用图标位置 Icon=default48.png # 是否显示终端 Terminal=false # 所属分类 StartupNotify=trueCategories=Office # MIME 类型 MimeType=text/x-markdown  应用程序默认关联文件，存在于以下的两个路径：  /usr/share/applications/mimeapps.list ~/.local/share/applications/mimeapps.list    桌面卡死 总的来说，就是杀死相关进程，或者避免使用造成卡死相关软件。\n  选择其他 tty：\n$ pkill Xorg pkill 用于杀死一个进程，与 kill 不同的是它会杀死指定名字的所有进程。kill 命令杀死指定进程 PID，需要配合 ps 使用。\n  安全重启：同时按住 Ctrl 和 Alt 键，按住不要放，按一下 SysRq 键（有的键盘是PrtSc），按一下 R 键，按一下 E 键，依次按下 I , S , U , B 键。\n  解决 Ubuntu 经常卡死：ubuntu 的卡死可能与显卡驱动不兼容有关。用 nvidia 代替 nouveau显卡驱动。其中 nvidia-driver-470-server 是 server 版，最好用 nvidia-driver-470\n  Fix Screen Tearing in Ubuntu after install nvidia driver, it works for me\n$ sudo vi /etc/modprobe.d/nvidia-drm-nomodeset.conf options nvidia-drm modeset=1 $ sudo reboot 检测硬盘坏道和坏块 硬盘坏道分为物理坏道和逻辑坏道。\n 物理坏道：就是硬盘实体有坏的地方，物理坏道推荐换硬盘，当然也有办法重新分区来隔离坏道，不过可能也用不久，所以不推荐。 逻辑坏道：是磁盘磁道上面的校验信息（ECC）跟磁道的数据对不上号所致。出现这一故障的原因，通常都是因为一些程序的错误操作或是该处扇区的磁介质开始出现不稳定的先兆。物理坏道也是逻辑坏道产生的一种原因。  发现 dmesg：当有硬盘坏道时，通常在dmesg输出的信息中会有 Buffer I/O Error，所以经常检查dmesg的输出可以及时发现是否存在硬盘问题。\n检测 通过fdisk 查看显示所有磁盘或闪存的信息\n$ sudo fdisk -l /dev/sd* 使用 badlocks检查 linux 硬盘上的坏道/坏块\n$ sudo badblocks -s -v /dev/sdb \u0026gt; badsectors.txt 修复 查看上述分区检查出来的坏道信息\n$ tail -f badsectors.txt 先备份数据再修复磁盘。硬盘在使用时不能修复，否则可能存在写并发的问题，所以修复前需要umount对应分区,或使用 Live CD\n$ sudo umount MountPoint umount 分区成功后，修复命令如下，其中-w表示写入修复的，后面是结束（END）和开始（START）块号，注意END在前，START在后。\n$ sudo badblocks -s -w /dev/sdb 205971590 205971595 修复后再次检查\n$ sudo badblocks -s -v /dev/sdb 205971590 205971595 屏蔽 执行e2fsck（针对 ext2/ext3/ext4 文件系统）或fsck命令，命令中还需要用到 badsectors.txt 文件和设备文件。\n# for ext2/ext3/ext4 $ sudo e2fsck -l badsectors.txt /dev/sdb # others $ sudo fsck -l badsectors.txt /dev/sdb 如何探索 從「指令」找到「使用說明」\n找使用說明\n$ man -f ls 閱讀使用說明\n$ man ls $ man 1 ls # 若是「bash」內建的指令，則是可以使用「help」 $ help if 上面的「man 1 ls」，「1」指的是「Manpage Sections」。\n執行下面指令可以看到各個「Section」的簡介。\n$ whatis intro 然後分別執行下面的指令，可以閱讀更詳細的說明\n$ man 1 intro $ man 2 intro $ man 3 intro $ man 4 intro $ man 5 intro $ man 6 intro $ man 7 intro $ man 8 intro 從「指令」找到「所屬套件」\n先透過「whereis」來找到「ls」所在的確切路徑。\n$ whereis ls ls: /bin/ls 然後根據這個結果，再執行下面的指令\n$ rpm -qf /bin/ls $ dpkg -S /bin/ls coreutils-8.32-1.2.x86_64 找「已安裝套件」的「檔案列表」\n$ rpm -ql coreutils $ dpkg -L coreutils 分卷压缩与解压缩 rar\n# rar a -vSIZE 压缩后的文件名 被压缩的文件或者文件夹 # 最大限制为 12M $ rar a -m5 -v12m myarchive myfiles #解压 $ rar e myarchive.part1.rar tar\n要将目录logs打包压缩并分割成多个1M的文件，可以用下面的命令：\n$ tar cjf - logs/ | split -b 1m - logs.tar.bz2. 完成后会产生下列文件：\nlogs.tar.bz2.aa, logs.tar.bz2.ab, logs.tar.bz2.ac 要解压的时候只要执行下面的命令就可以了：\n$ cat logs.tar.bz2.a* | tar xj 两个\u0026quot;-\u0026ldquo;不要漏了，那是tar的ouput和split的input的参数。\n7z\n压缩：\n$ 7z a name.7z filename -v10m 这里a是添加文件到压缩卷，name.7z是压缩后文件,然后filename可以是文件夹或文件，-v10m是限制每个包大小不超过10m.\n解压到当前目录：\n$ 7z x film.7z.001 Transfer files between Linux and Android  Connect Using USB Cable Apps  KDE Connect/GSConnect Android File Transfer AirDroid   Bluetooth  Xorg vs Wayland X即X11、X Window System，是用于在类UNIX的操作系统上的位图显示的窗口系统，提供了GUI环境的基本框架。X由X.Org Foundation维护，遵守MIT协议，当前参考实现为X.Org Server。在架构方面，X使用了C/S模型，客户端和服务器可以在同一个机器上，也可以在不同的机器上，X作为Server为应用程序这个Client提供显示和I/O服务。\nWayland是一个显示服务协议，服务端为Wayland Compositor，把X的X Server和Compositor合二为一，旨在替换X，作为类Unix操作系统上更现代、简介的窗口系统，遵守MIT协议，提供了Wayland Compositor的参考C语言实现Weston。\n时至今日，原本在X Server中做的事很多已被移到kernel或者单独的库中，因此X Server就显得比较累赘了。Wayland在架构上去掉了这个中间层，将compositor作为display server，使client与compositor直接通信，从而在灵活性和性能等方面上能够比前辈更加出色。\n查看是否使用 wayland\n$ echo $XDG_SESSION_TYPE Fedora、openSUSE 群讨论\nAppImage的制造者就是其中一个。主要反对的是Wayland声称自己取代X11，但在功能集合上二者完全不在一个层面，后者比前者强太多了。\n而他反对红帽的东西主要是因为红帽一直就是Linux桌面领域比较强权的那个企业，比如早期PulseAudio，比如SystemD，早期多灾多难制造了很多麻烦。\n推出一个新技术，在其不完善的前提下就想着取代旧技术，对于旧技术存在的但新技术不存在的功能却完全不考虑过渡方案，导致技术迭代的过程中用户就一次又一次地被抛弃。尤其和微软对比起来，微软在砍掉很重要的旧功能的时候会有完备的过渡方案，并且对于旧技术依然保持极长的支持周期。不过毕竟Windows 8那时候用户啥反应大家也不是不知道。\n能理解，并且我有时候也会有同样的抱怨，刚学会一个新软件，结果过半年这个软件就被下一次更新抛弃了。AppImage的制造者可能是希望Linux桌面能学习一下微软的一些策略。\n至于为什么反对Flatpak，因为Flatpak是红帽随同Wayland、Gnome一起强推的技术。\nX11 为什么强?\n远程应用，只把远程系统的一个应用程序在本机打开。X下面非常轻松，这就是X功能的一部分。微软的RDP也有同样的功能。并且渲染工作是在发起远程连接的那一段完成的。Wayland下面，没有，完全依赖窗口管理器自己提供的功能，而目前能做到的极限就是个VNC。\n统一的图形库，Xlib，Windows下与之对应的是Win32的UI部分。所有X11的窗口管理器都提供稳定且统一的图形库。在Wayland下面，没有，只能给你push一堆像素点，这就意味着Wayland的应用程序的向下兼容性会比原先X的程序更差。\n统一的窗口管理方式，也是X服务器的标准功能之一，在Windows下面我也不知道对标啥，但只要一个桌面环境用了X，那么应用程序就能确保自己使用一个标准的方法就能管理程序窗口，在Windows下也有同样的保障。Wayland下面，没有，完全依赖窗口管理器暴露的API或者无障碍API。\n接上述，统一的自动化工具实现方式。Windows下面的AutoHotkey不知道多少人用过，在X11下面对应的软件是xdotool。在Wayland下面，没有。ydotool先不说它已经被半弃坑了，最主要的是ydotool调用uinput，只能输入不能获得窗口状态。\n程序的可靠性。在X下面，桌面环境或者渲染器崩溃，应用程序依然健在。并且Windows也是如此的。Wayland下面就不是这么一回事了，至少对于Gnome来讲，shell崩溃就会连着所有程序全部崩溃。KDE的Kwin实现了自己的程序留活机制，但这样便从“所有X11桌面都支持”变成了“只有KDE支持”。\nWayland没有上述所有功能的原因很简单，Wayland不是软件、不是具体实现，它只是个标准，用来显示画面的标准。\n是的，没错，这些本来确实应该交给窗口管理器和渲染器完成。但是，Wayland在不支持这些功能的前提下却表示自己是X11的替代品/延续发展，这就非常地有问题，因为Wayland并没有做到功能上的延续。\n而且，Linux桌面下面的向下兼容性问题极度严重，我不想在这再重复一遍。桌面在用X11的时候，至少还能确保X的功能是一致的，无论跑在什么桌面组合上都不用担心兼容性问题，Wayland的出现，只会让原本离散的桌面更加离散。\nwlroots被称作有希望统一Wayland渲染器的实现方式，可惜在此之前Gnome和KDE已经开始做自己的Wayland实现了，这就意味着从X11转向Wayland，至少分裂成了Gnome、KDE和wlroots，其它桌面会不会突然想不开自己做Wayland实现我们也不知道。而且，三家的分裂，难道还不够折磨吗？\n看看Flameshot的Wayland支持，因为发现Gnome和KDE的运行表现不同，于是放弃了Portals API打算等待wlroots的标准，然而wlroots的标准和Gnome的不互通，于是它的支持计划被延期，无ETA。\n再看看Barrier的Wayland支持，它fork的项目是symless的synergy，这是个商业开源软件。Ubuntu 17.04的时候曾经短暂切换到Wayland，那时候symless就计划开始适配Wayland，之后Ubuntu换回X11，于是Wayland适配计划就被放弃。当一部分软件只跟着一部分发行版走、而不考虑整个Linux桌面生态的时候，Linux桌面便从事实上消失了。接下来便只剩Ubuntu桌面、openSUSE桌面、Fedora桌面了，至少对于ISV来讲是这样的，因为不然的话指数级别的适配难度会把开发者累死。\n我并不是在吹X11诋毁Wayland。只是指出现状。我知道这不是Wayland该做的事情，只是问题是：有谁能来做？\n用户关心的是能不能用上对应的功能，Wayland之后功能少了，那用户就会把锅甩给Wayland。\n这也是AppImage创造者一直反感Wayland的原因之一。\n为什么执行自己的程序要在前面加./ shell是如何运行程序的：如果不给出相对路径，或者绝对路径，那么它会经历下面的查找过程。\n alias中查找 内置命令中查找 PATH中查找  $ cd /temp $ ./ls_bak 等同于\n$ /temp/ls_bak shell通常可以执行两种程序，一种是二进制程序，一种是脚本程序。如果是文本程序，且开头没有指定解释程序，则按照shell脚本处理，如果指定了解释程序，则使用解释程序来解释运行；对于二进制程序，则直接创建新的进程即可。\nLTS LTS是Long Term Support的简称，即长期支持。The Ubuntu lifecycle and release cadence。\nUbuntu的LTS现在无论是桌面版还是服务器版，每2年出一个LTS版本，都提供5年的支持更新（现在是10年）。不太注重软件版本的追新。\n这种更新更多的是Bug和漏洞的修复，基本上不怎么升级软件的版本，更注重稳定。类似Windows 7，它一旦固定下来后，后面的补丁基本上只是修复为主，尽管用SP1，SP2，但它还是Windows 7。\n而非长期支持版本每半年就出一个新版本，更倾向于追新，内核和软件不断用最新版本，稳定性就要差一些。\n如果没有特别需要，一般用户建议安装最新版本的 LTS 版本即可。\nVim clear last search highlighting :noh 设计shell脚本选项 getopt 写shell脚本的时候，通过while、case、shift来设计脚本的命令行选项是一件比较麻烦的事，因为Unix命令行的选项和参数自由度很高，支持短选项和长选项，参数可能是可选的，选项顺序可能是无所谓的，等等。\nbash下的getopt命令可以解析命令行的选项和参数，将散乱、自由的命令行选项和参数进行改造，得到一个完整的、规范化的参数列表，这样再使用while、case和shift进行处理就简单的太多了。\ngetopt有不同的版本，本文介绍的是它的增强版(enhanced)，相比传统的getopt(也称为兼容版本的getopt)，它提供了引号保护的能力。另外，除了不同版本的getopt，bash还有一个内置命令getopts(注意，有个尾随的字符s)，也用来解析命令行选项，但只能解析短选项。\n要验证安装的getopt是增强版的还是传统版的，使用getopt -T判断即可。如果它什么都不输出，则是增强版，此时它的退出状态码为4。如果输出\u0026rdquo;\u0026ndash;\u0026quot;，则是传统版的getopt，此时它的退出状态码为0。如果想在脚本中进行版本检查，可以参考如下代码：\n$ getopt -T \u0026amp;\u0026gt;/dev/null;[ $? -ne 4 ] \u0026amp;\u0026amp; { echo \u0026#34;not enhanced version\u0026#34;;exit 1; } \u0026hellip;\n如何将Google搜索限制为特定语言的结果   Web界面语言： hl=\n例： www.google.com/search?q=vilnius\u0026amp;hl=lt\n  指定语言的页面： lr=lang_\n例： www.google.com/search?q=vilnius\u0026amp;lr=lang_lt\n  来自指定国家/地区的页面： cr=country\n示例：www.google.com/search?q=vilnius\u0026amp;cr=countryLT\n请注意，两个国家/地区代码字符必须大写！否则，Google会忽略该参数（自2017年1月3日起）（即使小写字母对于hl=和都适用lr=lang_）\n  Web Interface Language Codes hl=zh-CN Chinese (Simplified) hl=zh-TW Chinese (Traditional) hl=en English Search Language Codes lr=lang_zh-CN Chinese (Simplified) lr=lang_zh-TW Chinese (Traditional) lr=lang_en English 在中文介面下，如何只用英文目錄名稱？  先切到英文介面再重新開機，此時 Fedora 會問你要不要將子目錄換為英文名稱（選 Yes），再切回中文介面重新開機，Fedora 會再問你一次要不要更改子目錄為中文名稱（選 No），收工！ LANG=C xdg-user-dirs-gtk-update # 同意更新 xdg-user-dirs-gtk-update # 保留且不再問 手動修正配置文件~/.config/user-dirs.dirs ,然後在主目錄下創建對應目錄,重啟即可解決.  dd 制作U盘启动盘 $ dd bs=4M if=fileName.iso of=/dev/sdx status=progress \u0026amp;\u0026amp; sync Windows 下用 Rufus 且 dd 写入模式\nwine exe程序的卸载  wine 会在 /home 下的用户名目录生成三个隐藏的文件夹 .wine、.local、.config 等文件夹，快捷键 ctrl+H 可以显示出来; 进入 .wine 文件夹可以看到 drive_c 文件夹，这是wine自动生成的虚拟windows C盘，里面有类似windows系统盘的目录结构，在里面找到需要卸载的软件文件夹删除即可； 找到 /home/用户名/.local/share/applications/wine/Programs，将软件对应的文件删除； 找到 /home/用户名/.config/menus/applications-merged，将软件对应的文件删除； 这时候已经删除完毕，但是可能还会看到桌面图标或软件列表，重启系统即可。  为什么 Linux 要用 tar.gz，很少用 7Z 或 ZIP？ 因为 7z 和 zip 压缩格式都不能保留 unix 风格的文件权限，比如解压出个可执行文件要重新 chmod chown 才能恢复正常。而 tar 格式可以。而 tar 本身不提供压缩，无非就是把包括所有文件的內容和权限拼成一个文件而己，所以用另外如 gzip 格式压缩。为什么是 gzip，因为几乎所有 linux 都支持而已。\n置默认编辑器 visudo 等操作会打开默认编辑器，在linux中默认编辑器读取EDITOR环境变量，可通过一下命令设置\nexport EDITOR=nano 可将其加入~/.bashrc文件，使得每次登录都可使用\n$ nano ~/.bashrc export EDITOR=nano $ . ~/.bashrc debian系统提供了一个管理工具来设置默认编辑器\n$ sudo update-alternatives --config editor 有两个相似选项\n /usr/bin/vim.basic /usr/bin/vim.tiny  它们的区别：\nim.basic is just plain vanilla Vim (as you can check with apt-file vim.basic or dpkg -S /usr/bin/vim.basic).\nWhile vim.tiny, as the name implies, is a trimmed-down version of Vim (this question explains it further).\n$ vim.tiny --version 通过Linux系统进入 BIOS $ sudo systemctl reboot --firmware-setup 5 Ways to Check CPU Info in Linux  lscpu /proc/cpuinfo lshw hwinfo dmidecodes  exFAT 文件系统\n所谓文件系统，就是文件的储存方式。通过文件系统可以准确找到存储在硬盘中的数据。储存设备都需要指定文件系统，计算机才能读写。\nWindows 的文件系统\n FAT32：是最老的文件系统，所有操作系统都支持，兼容性最好。但是，它是为 32 位计算机设计的，文件不能超过 232 - 1 个字节，也就是不能超过 4GB，分区不能超过 8TB。 NTFS：是 Windows 的默认文件系统，用来替换 FAT32。 exFAT：是 FAT32 的 64位升级版，ex 就是 extended 的缩写（表示\u0026quot;扩展的 FAT32\u0026quot;），功能不如 NTFS，但是解决了文件和分区的大小问题，两者最大都可以到 128PB。  Linux 的 exFAT 格式化\n$ sudo mkfs.exfat /dev/sdX1 分区表\n所谓硬盘分区，就是指一块硬盘上面，同时存在多个文件系统。每个文件系统管理的区域，就称为一个分区（partition）。\n分区大小、起始位置、结束位置、文件系统等信息，都储存在分区表里面。\n分区表也分成两种格式：MBR 和 GPT。前者是传统格式，兼容性好；后者更现代，功能更强大。\nLogging in as Root in Ubuntu with Live CD $ sudo passwd root How To Download A Large File Faster From Google Drive? Step 1: Fetching Your File ID\n Open your browser and go to your google drive, open login with the account that has the file you wish to download. Locate the file that you wish to download and select it. Right click the file and click on “get shareable link” You don’t need to copy the entire link here; you only need the file ID that we will be using later.  The link will look like this: https://drive.google.com/file/d/XXXXX/view?usp=sharing\nIn this link, you only need to pay attention to the alphanumeric file ID, displayed by XXXXX here.\nStep 2: Getting an OAuth Code\n Visit OAuth 2.0 Playground by clicking here. On the developer’s webpage, in the “Select \u0026amp; authorize APIs” click on the “Drive API v3” option, and select the: https://www.googleapis.com/auth/drive.readonly option from the available options. Once selected click Authorize APIs button on the bottom right corner of the tab. After you click on the Authorize APIs button you will be transferred to the google account login screen. Select the same google account in which you have your file stored. Allow Google OAuth 2.0 to access your drive if asked. When you get redirected back to the OAuth 2.0 playground screen click on the “Exchange Authorization Code for Tokens” button as shown. Copy the newly generated Access Token and save it on your notepad. You will be needing this in the next step.  Step 3: Downloading The File Using A Command Line Script\n$ curl -H \u0026#34;Authorization: Bearer YYYYY\u0026#34; https://www.googleapis.com/drive/v3/files/XXXXX?alt=media -o ZZZZZ In your command, replace “XXXXX” with the file ID from above, “YYYYY” with the access token from above, and “ZZZZZ” with the file name that will be saved (for example, “myFile.mp4” if you’re downloading an mp4 file).\nPress Enter and let the download begin.\nvi 与 vim.tiny $ whereis vi vi: /usr/bin/vi /usr/share/man/man1/vi.1.gz $ ls -al /usr/bin/vi lrwxrwxrwx 1 root root 20 Oct 26 20:31 /usr/bin/vi -\u0026gt; /etc/alternatives/vi $ ls -al /etc/alternatives/vi lrwxrwxrwx 1 root root 17 Oct 26 20:31 /etc/alternatives/vi -\u0026gt; /usr/bin/vim.tiny 可见，在Ubuntu上，vi是vim.tiny的软连接，但是执行命令vi与vim.tiny后是不一样，比如vi是：在编辑模式下使用方向键的时候，并不会使光标移动，而是在命令行中出现[A [B [C [D之类的字母；并且编辑错误的话，退格键(Backspace键)是使用不了的。\nMethods to find out which (configuration) files are read by executable when started-\u0026gt;\u0026lsquo;strace vim/nano\u0026rsquo; (Ubuntu)：\n$ strace -o $HOME/tracefile vi $ cat tracefile | grep vimrc stat(\u0026#34;/usr/share/vim/vimrc.tiny\u0026#34;, {st_mode=S_IFREG|0644, st_size=662, ...}) = 0 openat(AT_FDCWD, \u0026#34;/usr/share/vim/vimrc.tiny\u0026#34;, O_RDONLY) = 3 stat(\u0026#34;/home/vane/.vimrc\u0026#34;, 0x7fff3e755550) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/.vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/_vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) stat(\u0026#34;/home/vane/.vim/vimrc\u0026#34;, 0x7fff3e755550) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/.vim/vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) 可以看到 vi，加载的是 /usr/share/vim/vimrc.tiny\n$ strace -o $HOME/tracefile vim.tiny $ cat tracefile | grep vimrc stat(\u0026#34;/usr/share/vim/vimrc\u0026#34;, {st_mode=S_IFREG|0644, st_size=2266, ...}) = 0 openat(AT_FDCWD, \u0026#34;/usr/share/vim/vimrc\u0026#34;, O_RDONLY) = 3 stat(\u0026#34;/home/vane/.vimrc\u0026#34;, 0x7fff7c99cc30) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/.vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/_vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) stat(\u0026#34;/home/vane/.vim/vimrc\u0026#34;, 0x7fff7c99cc30) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/.vim/vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) 可以看到 vim.tiny，加载的是 /usr/share/vim/vimrc\n$ diff -u /etc/vim/vimrc /etc/vim/vimrc.tiny --- /etc/vim/vimrc\t2020-01-30 19:11:47.000000000 +0800 +++ /etc/vim/vimrc.tiny\t2020-04-15 14:40:31.000000000 +0800 @@ -1,55 +1,13 @@ ... +\u0026#34; Vim configuration file, in effect when invoked as \u0026#34;vi\u0026#34;. The aim of this +\u0026#34; configuration file is to provide a Vim environment as compatible with the +\u0026#34; original vi as possible. Note that ~/.vimrc configuration files as other +\u0026#34; configuration files in the runtimepath are still sourced. +\u0026#34; When Vim is invoked differently (\u0026#34;vim\u0026#34;, \u0026#34;view\u0026#34;, \u0026#34;evim\u0026#34;, ...) this file is +\u0026#34; _not_ sourced; /etc/vim/vimrc and/or /etc/vim/gvimrc are. ... 可以看到，上面什么说明白了。\nUSB插槽鬆動怎麼辦  手机  充电宝  笔记本  笔记本  Differences between 7z, 7za and 7zr binaries The package includes three binaries, /usr/bin/7z, /usr/bin/7za, and /usr/bin/7zr. Their manual pages explain the differences:\n 7z(1) uses plugins to handle archives. 7za(1) is a stand-alone executable that handles fewer archive formats than 7z. 7zr(1) is a stand-alone executable. It is a \u0026ldquo;light-version\u0026rdquo; of 7za that only handles 7z archives. In contrast to 7za, it cannot handle encrypted archives.  nmcheck.gnome.org nmcheck.gnome.org is not malware. It is the gnome network manager connectivity check (for captive portals/hotspots). Click the link and you will see a single text file with a text in it. It should be \u0026ldquo;NetworkManager is online\u0026rdquo;.\nCheck /etc/NetworkManager/NetworkManager.conf. There probably is a section with this in it:\n[Connectivity] uri=http://nmcheck.gnome.org/check_network_status.txt on Ubuntu 20.04 no [Connectivity]  line like accepted answer in /etc/NetworkManager/NetworkManager.conf.\nBut you can disable the auto connectivity check by:\n Go to Settings app Go to Privacy menu On Connectivity tab, uncheck Connectivity Checking  XDG_TEMPLATES_DIR If you drop any files in \u0026ldquo;Templates\u0026rdquo; folder. Then when you right-click and create a new document, you can select any of these files as a basis for the new file.\nIf you have deleted the folder and need to restore this functionality:\n$ gedit ~/.config/user-dirs.dirs Check that there is a line containing the following - if not, add this line.\nXDG_TEMPLATES_DIR=\u0026quot;$HOME/Templates\u0026quot; 软件的稳定性 软件的稳定性其实往往来源于：足够多的使用者与足够多的反馈跟改进。\nLinux系统，在服务器端的大多数常用软件都有足够多的使用者，所以就足够稳定，由于它在服务器端市场占有率远高于微软，所以服务器端就是比微软稳定，很正常的事。\n在桌面端，市场占用率远低于微软，不稳定也是自然的。\n为什么Linux下命令行程序往往又好用又稳定？是因为用户喜欢装逼吗？不是，因为命令行程序是服务器端跟桌面端通用的，而服务器端程序经过了足够多用户的使用，经过了足够的反馈开发迭代，所以稳定。而图形界面只有桌面用户用，桌面占有率那么低，这些程序往往缺乏足够的测试人力也缺乏足够的开发维护人力，所以并不会非常稳定。\n那么，你要想体验Linux稳定，怎么办？答案就是只使用市场占有率高，用户量大，因而获得了充分测试的软件，这就稳定了。比方说只使用服务器端。或者桌面端只使用最常用的那些，例如终端仿真器，浏览器，输入法，gcc编译器之类，肯定是稳定的。\n你看我就用浏览器，输入法，xterm，screen，编程ide，vim，以及一堆命令行的东西，稳定得很啊，六个月才重启一次电脑，重启的那一次还是因为ubuntu升级。\n如何将Google搜索限制为特定语言的结果 只是想在Google搜索中添加有关语言参数的更全面的答案。\n有4种与语言相关的选项。\nWeb界面语言： hl=\n例： www.google.com/search?q=vilnius\u0026amp;hl=lt\nWeb Interface Language Codes hl=zh-CN Chinese (Simplified) hl=zh-TW Chinese (Traditional) hl=en English hl=ja Japanese 指定语言的页面： lr=lang_\n例： www.google.com/search?q=vilnius\u0026amp;lr=lang_lt\nSearch Language Codes lr=lang_zh-CN Chinese (Simplified) lr=lang_zh-TW Chinese (Traditional) lr=lang_en English lr=lang_ja Japanese 来自指定国家/地区的页面： cr=country\n示例：www.google.com/search?q=vilnius\u0026amp;cr=countryLT 请注意，两个国家/地区代码字符必须大写！否则，Google会忽略该参数（自2017年1月3日起）（即使小写字母对于hl=和都适用lr=lang_）。\n还有另一个参数\u0026ndash; gl=用于搜索结果，因为它们将显示在指定的国家/地区。我尝试对其进行测试，但对我而言，不同参数值的结果没有不同。浏览器或我的Google帐户的某些其他参数/设置可能已过时或覆盖了该设置。\n查找文件内容 从文件内容查找匹配指定字符串的行：\n$ grep \u0026#34;被查找的字符串\u0026#34; 文件名 例子：在当前目录里第一级文件夹中寻找包含指定字符串的 .in 文件\ngrep \u0026#34;thermcontact\u0026#34; /.in 从文件内容查找与正则表达式匹配的行：\n$ grep –e \u0026#34;正则表达式\u0026#34; 文件名 查找时不区分大小写：\n$ grep –i \u0026#34;被查找的字符串\u0026#34; 文件名 查找匹配的行数：\n$ grep -c \u0026#34;被查找的字符串\u0026#34; 文件名 从文件内容查找不匹配指定字符串的行：\n$ grep –v \u0026#34;被查找的字符串\u0026#34; 文件名 从根目录开始查找所有扩展名为 .log 的文本文件，并找出包含 \u0026ldquo;ERROR\u0026rdquo; 的行：\n$ find / -type f -name \u0026#34;*.log\u0026#34; | xargs grep \u0026#34;ERROR\u0026#34; 例子：从当前目录开始查找所有扩展名为 .in 的文本文件，并找出包含 \u0026ldquo;thermcontact\u0026rdquo; 的行：\n$ find . -name \u0026#34;*.in\u0026#34; | xargs grep \u0026#34;thermcontact\u0026#34; QUESTIONS Ubuntu 无法关机 $ sudo vim /etc/systemd/system.conf DefaultTimeoutStartSec=5s DefaultTimeoutStopSec=5s $ sudo systemctl reload DefaultTimeoutStartSec=, DefaultTimeoutStopSec= 设置启动/停止一个单元所允许的最大时长。若仅设置一个整数而没有单位，那么单位是秒。 也可以在整数后面加上时间单位后缀： \u0026ldquo;ms\u0026rdquo;(毫秒), \u0026ldquo;s\u0026rdquo;(秒), \u0026ldquo;min\u0026rdquo;(分钟), \u0026ldquo;h\u0026rdquo;(小时), \u0026ldquo;d\u0026rdquo;(天), \u0026ldquo;w\u0026rdquo;(周) 。 对于 Type=oneshot 类型的 service 单元， 这些选项没有意义(相当于全部被禁用)。 对于其他类型的 service 单元，可以在单元文件中设置 TimeoutStartSec=, TimeoutStopSec=, RestartSec= 以覆盖此处设置的默认值 (参见systemd.service(5))。 对于其他非 service 类型的单元， DefaultTimeoutStartSec= 是 TimeoutSec= 的默认值。\n注1：尽量不要使用上面更改。应该在完全清楚自己的更改造成的影响、产生的作用的前提下，做出更改。\n注2：作为桌面操作系统，如果有硬件驱动或其他各种莫名问题，可以尝试升级到最新版本来解决。\nACPI ERROR: AE_ALREADY_EXISTS These kinds of \u0026ldquo;errors\u0026rdquo; have been discussed ad nauseam, it\u0026rsquo;s simply the kernel telling you that the ACPI information received from the system seems to be incomplete in some way, update your BIOS/UEFI in hopes for a proper fix or ignore the error if you don\u0026rsquo;t notice anything off with your system.\n(And please don\u0026rsquo;t do something dumb like setting acpi=off just to get rid of these messages)\n解压zip乱码 $ unzip -O CP936 xxx.zip 用GBK, GB18030也可以\nCan\u0026rsquo;t run CS:GO at fullscreen  Open Steam Go to the \u0026ldquo;Library\u0026rdquo; Right-click the game which needs to be reconfigured Select \u0026ldquo;Properties\u0026rdquo; from the menu Click the \u0026ldquo;Set launch options\u0026hellip;\u0026rdquo; button type: -full and save  How To Disable Lock In Kubuntu open Workspace \u0026gt; Desktop Behavior \u0026gt; Screen Locking \u0026gt; uncheck Lock screen option\nGnome 3 displays two icons for same app No, there\u0026rsquo;s nothing wrong with your system.\nThe duplicated launcher icons explained:\nThe different icons are different commandline options. Some context applications with call the associated *.desktop icon. The exec option of the icon will depend on how the application is called.\nSome of the Icons you show in your image may be obvious because of the difference in the way they are named. You can see the difference in the way the app is called by right clicking and clicking on properties to see other differences.\nSome of the *.desktop files have a %U argument, used so the application will accept arguments.\nSome of the Launchers are different commands that are called differently and are named differently often by a symbolic link.\nSome exampes from the list in you image are:\nName: Online Accounts Command: unity-control-center credentials Name: Online Accounts Command: Online account credentials and settings Name: Personal File Sharing Command: gnome-file-share-properties Name: Rhythmbox Command: rhythmbox %U Name: Rhythmbox Command rhythmbox-client --select-source %U ","permalink":"https://example.com/posts/ubuntu/","summary":"友邦拓 乌班图 During the first ten years of this HOWTO\u0026rsquo;s life, I reported that from a new user\u0026rsquo;s point of view, all Linux distributions are almost equivalent. But in 2006-2007, an actual best choice emerged: Ubuntu. While other distros have their own areas of strength, Ubuntu is far and away the most accessible to Linux newbies. Beware, though, of the hideous and nigh-unusable \u0026ldquo;Unity\u0026rdquo; desktop interface","title":"Ubuntu"},{"content":"Hexo Hexo 是一个快速、简洁且高效的博客框架。\n安装   安装 Git：\n Windows: Download \u0026amp; install git. Mac: Install it with Homebrew, MacPorts or installer. Linux (Ubuntu, Debian): sudo apt-get install git-core Linux (Fedora, Red Hat, CentOS): sudo yum install git-core    安装 node.js：\n Windows: Install it with nvs (recommended) or nvm. Mac: Install it with Homebrew or MacPorts. Linux (DEB/RPM-based): Install it with NodeSource. Others: Install it through respective package manager. Refer to the guide provided by Node.js.    安装 Hexo：-g 表示全局安装，会将 Hexo 命令加入环境变量中。\n$ npm --registry https://registry.npm.taobao.org install -g hexo-cli # 持久使用镜像 $ npm config set registry https://registry.npm.taobao.org Where do global npm packages get installed\n$ npm root -g   建站 $ hexo init [folder] $ cd \u0026lt;folder\u0026gt; $ npm install 新建完成后，指定文件夹的目录如下：\n. ├── node_modules\t//依赖安装目录 ├── scaffolds\t//模板文件夹，Hexo的模板是指在新建的文章文件中默认填充的内容。 | ├── draft.md\t//草稿模板 | ├── page.md\t//页面模板 | └── post.md\t//文章模板 ├── source\t//资源文件夹 | └── _posts\t//文章目录 ├── themes\t//主题文件夹，Hexo 会根据主题来生成静态页面。 | └── landscape\t//默认主题 ├── .gitignore\t//指定不纳入git版本控制的文件 ├── _config.yml\t//站点配置文件 ├── db.json ├── package.json\t//应用程序的信息 └── package-lock.json source：资源文件夹是存放用户资源的地方。除 _posts 文件夹之外，开头命名为 _ (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。\n配置 您可以在 _config.yml 中修改大部分的配置。\n网站    参数 描述     title 网站标题   subtitle 网站副标题   description 网站描述   keywords 网站的关键词。支持多个关键词。   author 您的名字   language 网站使用的语言。对于简体中文用户来说，使用不同的主题可能需要设置成不同的值，请参考你的主题的文档自行设置，常见的有 zh-Hans和 zh-CN。   timezone 网站时区。Hexo 默认使用您电脑的时区。请参考 时区列表 进行设置，如 America/New_York, Japan, 和 UTC 。一般的，对于中国大陆地区可以使用 Asia/Shanghai。    其中，description主要用于SEO，告诉搜索引擎一个关于您站点的简单描述，通常建议在其中包含您网站的关键词。author参数用于主题显示文章的作者。\n网址    参数 描述 默认值     url 网址, 必须以 http:// 或 https:// 开头    root 网站根目录 url's pathname   permalink 文章的 永久链接 格式 :year/:month/:day/:title/   permalink_defaults 永久链接中各部分的默认值    pretty_urls 改写 permalink 的值来美化 URL    pretty_urls.trailing_index 是否在永久链接中保留尾部的 index.html，设置为 false 时去除 true   pretty_urls.trailing_html 是否在永久链接中保留尾部的 .html, 设置为 false 时去除 (对尾部的 index.html无效) true     网站存放在子目录\n如果您的网站存放在子目录中，例如 http://example.com/blog，则请将您的 url 设为 http://example.com/blog 并把 root 设为 /blog/。\n 例如：\n# 比如，一个页面的永久链接是 http://example.com/foo/bar/index.html pretty_urls: trailing_index: false # 此时页面的永久链接会变为 http://example.com/foo/bar/ 目录    参数 描述 默认值     source_dir 资源文件夹，这个文件夹用来存放内容。 source   public_dir 公共文件夹，这个文件夹用于存放生成的站点文件。 public   tag_dir 标签文件夹 tags   archive_dir 归档文件夹 archives   category_dir 分类文件夹 categories   code_dir Include code 文件夹，source_dir 下的子目录 downloads/code   i18n_dir 国际化（i18n）文件夹 :lang   skip_render 跳过指定文件的渲染。匹配到的文件将会被不做改动地复制到 public 目录中。您可使用 glob 表达式来匹配路径。     例如：\nskip_render: \u0026#34;mypage/**/*\u0026#34; # 将会直接将 `source/mypage/index.html` 和 `source/mypage/code.js` 不做改动地输出到 \u0026#39;public\u0026#39; 目录 # 你也可以用这种方法来跳过对指定文章文件的渲染 skip_render: \u0026#34;_posts/test-post.md\u0026#34; # 这将会忽略对 \u0026#39;test-post.md\u0026#39; 的渲染  提示\n如果您刚刚开始接触 Hexo，通常没有必要修改这一部分的值。\n 文章    参数 描述 默认值     new_post_name 新文章的文件名称 :title.md   default_layout 预设布局 post   auto_spacing 在中文和英文之间加入空格 false   titlecase 把标题转换为 title case false   external_link 在新标签中打开链接 true   external_link.enable 在新标签中打开链接 true   external_link.field 对整个网站（site）生效或仅对文章（post）生效 site   external_link.exclude 需要排除的域名。主域名和子域名如 www 需分别配置 []   filename_case 把文件名称转换为 (1) 小写或 (2) 大写 0   render_drafts 显示草稿 false   post_asset_folder 启动 Asset 文件夹 false   relative_link 把链接改为与根目录的相对位址 false   future 显示未来的文章 true   highlight 代码块的设置, 请参考 Highlight.js 进行设置    prismjs 代码块的设置, 请参考 PrismJS 进行设置      相对地址\n默认情况下，Hexo 生成的超链接都是绝对地址。例如，如果您的网站域名为 example.com,您有一篇文章名为 hello，那么绝对链接可能像这样：http://example.com/hello.html，它是绝对于域名的。相对链接像这样：/hello.html，也就是说，无论用什么域名访问该站点，都没有关系，这在进行反向代理时可能用到。通常情况下，建议使用绝对地址。\n 分类 \u0026amp; 标签    参数 描述 默认值     default_category 默认分类 uncategorized   category_map 分类别名    tag_map 标签别名     日期 / 时间格式 Hexo 使用 Moment.js 来解析和显示时间。\n   参数 描述 默认值     date_format 日期格式 YYYY-MM-DD   time_format 时间格式 HH:mm:ss   updated_option 当 Front Matter 中没有指定 updated 时 updated 的取值 mtime     updated_option\nupdated_option 控制了当 Front Matter 中没有指定 updated 时，updated 如何取值：\n mtime: 使用文件的最后修改时间。这是从 Hexo 3.0.0 开始的默认行为。 date: 使用 date 作为 updated 的值。可被用于 Git 工作流之中，因为使用 Git 管理站点时，文件的最后修改日期常常会发生改变 empty: 直接删除 updated。使用这一选项可能会导致大部分主题和插件无法正常工作。  use_date_for_updated 选项已经被废弃，将会在下个重大版本发布时去除。请改为使用 updated_option: 'date'。\n use_date_for_updated` | 启用以后，如果 Front Matter 中没有指定 `updated`， [`post.updated`](https://hexo.io/zh-cn/docs/configuration) 将会使用 `date` 的值而不是文件的创建时间。在 Git 工作流中这个选项会很有用 | `true 分页    参数 描述 默认值     per_page 每页显示的文章量 (0 = 关闭分页功能) 10   pagination_dir 分页目录 page    扩展    参数 描述     theme 当前主题名称。值为false时禁用主题   theme_config 主题的配置文件。在这里放置的配置会覆盖主题目录下的 _config.yml 中的配置   deploy 部署部分的设置   meta_generator Meta generator 标签。 值为 false 时 Hexo 不会在头部插入该标签    包括或不包括目录和文件\n在 Hexo 配置文件中，通过设置 include/exclude 可以让 Hexo 进行处理或忽略某些目录和文件夹。你可以使用 glob 表达式 对目录和文件进行匹配。\ninclude and exclude options only apply to the source/ folder, whereas ignore option applies to all folders.\n   参数 描述     include Hexo 默认会忽略隐藏文件和文件夹（包括名称以下划线和 . 开头的文件和文件夹，Hexo 的 _posts 和 _data 等目录除外）。通过设置此字段将使 Hexo 处理他们并将它们复制到 source 目录下。   exclude Hexo 会忽略这些文件和目录   ignore Ignore files/folders    举例：\n# Include/Exclude Files/Folders include: - \u0026#34;.nojekyll\u0026#34; # 包括 \u0026#39;source/css/_typing.css\u0026#39; - \u0026#34;css/_typing.css\u0026#34; # 包括 \u0026#39;source/_css/\u0026#39; 中的任何文件，但不包括子目录及其其中的文件。 - \u0026#34;_css/*\u0026#34; # 包含 \u0026#39;source/_css/\u0026#39; 中的任何文件和子目录下的任何文件 - \u0026#34;_css/**/*\u0026#34; exclude: # 不包括 \u0026#39;source/js/test.js\u0026#39; - \u0026#34;js/test.js\u0026#34; # 不包括 \u0026#39;source/js/\u0026#39; 中的文件、但包括子目录下的所有目录和文件 - \u0026#34;js/*\u0026#34; # 不包括 \u0026#39;source/js/\u0026#39; 中的文件和子目录下的任何文件 - \u0026#34;js/**/*\u0026#34; # 不包括 \u0026#39;source/js/\u0026#39; 目录下的所有文件名以 \u0026#39;test\u0026#39; 开头的文件，但包括其它文件和子目录下的单文件 - \u0026#34;js/test*\u0026#34; # 不包括 \u0026#39;source/js/\u0026#39; 及其子目录中任何以 \u0026#39;test\u0026#39; 开头的文件 - \u0026#34;js/**/test*\u0026#34; # 不要用 exclude 来忽略 \u0026#39;source/_posts/\u0026#39; 中的文件。你应该使用 \u0026#39;skip_render\u0026#39;，或者在要忽略的文件的文件名之前加一个下划线 \u0026#39;_\u0026#39; # 在这里配置一个 - \u0026#34;_posts/hello-world.md\u0026#34; 是没有用的。 ignore: # Ignore any folder named \u0026#39;foo\u0026#39;. - \u0026#34;**/foo\u0026#34; # Ignore \u0026#39;foo\u0026#39; folder in \u0026#39;themes/\u0026#39; only. - \u0026#34;**/themes/*/foo\u0026#34; # Same as above, but applies to every subfolders of \u0026#39;themes/\u0026#39;. - \u0026#34;**/themes/**/foo\u0026#34; 列表中的每一项都必须用单引号或双引号包裹起来。\ninclude 和 exclude 并不适用于 themes/ 目录下的文件。如果需要忽略 themes/ 目录下的部分文件或文件夹，可以使用 ignore 或在文件名之前添加下划线 _。\n使用代替配置文件\n可以在 hexo-cli 中使用 --config 参数来指定自定义配置文件的路径。你可以使用一个 YAML 或 JSON 文件的路径，也可以使用逗号分隔（无空格）的多个 YAML 或 JSON 文件的路径。例如：\n# use \u0026#39;custom.yml\u0026#39; in place of \u0026#39;_config.yml\u0026#39; $ hexo server --config custom.yml # use \u0026#39;custom.yml\u0026#39; \u0026amp; \u0026#39;custom2.json\u0026#39;, prioritizing \u0026#39;custom3.yml\u0026#39;, then \u0026#39;custom2.json\u0026#39; $ hexo generate --config custom.yml,custom2.json,custom3.yml 当你指定了多个配置文件以后，Hexo 会按顺序将这部分配置文件合并成一个 _multiconfig.yml。如果遇到重复的配置，排在后面的文件的配置会覆盖排在前面的文件的配置。这个原则适用于任意数量、任意深度的 YAML 和 JSON 文件。\n例如，使用 --options 指定了两个自定义配置文件：\n$ hexo generate --config custom.yml,custom2.json 如果 custom.yml 中指定了 foo: bar，在 custom2.json 中指定了 \u0026quot;foo\u0026quot;: \u0026quot;dinosaur\u0026quot;，那么在 _multiconfig.yml 中你会得到 foo: dinosaur。\n使用代替主题配置文件\n通常情况下，Hexo 主题是一个独立的项目，并拥有一个独立的 _config.yml 配置文件。\n除了自行维护独立的主题配置文件，你也可以在其它地方对主题进行配置。\n配置文件中的 theme_config\n 该特性自 Hexo 2.8.2 起提供\n # _config.yml theme: \u0026#34;my-theme\u0026#34; theme_config: bio: \u0026#34;My awesome bio\u0026#34; foo: bar: \u0026#39;a\u0026#39; # themes/my-theme/_config.yml bio: \u0026#34;Some generic bio\u0026#34; logo: \u0026#34;a-cool-image.png\u0026#34; foo: baz: \u0026#39;b\u0026#39; 最终主题配置的输出是：\n{ bio: \u0026#34;My awesome bio\u0026#34;, logo: \u0026#34;a-cool-image.png\u0026#34;, foo: { bar: \u0026#34;a\u0026#34;, baz: \u0026#34;b\u0026#34; } } 独立的 _config.[theme].yml 文件\n 该特性自 Hexo 5.0.0 起提供\n 独立的主题配置文件应放置于站点根目录下，支持 yml 或 json 格式。需要配置站点 _config.yml 文件中的 theme 以供 Hexo 寻找 _config.[theme].yml 文件。\n# _config.yml theme: \u0026#34;my-theme\u0026#34; # _config.my-theme.yml bio: \u0026#34;My awesome bio\u0026#34; foo: bar: \u0026#39;a\u0026#39; # themes/my-theme/_config.yml bio: \u0026#34;Some generic bio\u0026#34; logo: \u0026#34;a-cool-image.png\u0026#34; foo: baz: \u0026#39;b\u0026#39; 最终主题配置的输出是：\n{ bio: \u0026#34;My awesome bio\u0026#34;, logo: \u0026#34;a-cool-image.png\u0026#34;, foo: { bar: \u0026#34;a\u0026#34;, baz: \u0026#34;b\u0026#34; } }  我们强烈建议你将所有的主题配置集中在一处。如果你不得不在多处配置你的主题，那么这些信息对你将会非常有用：Hexo 在合并主题配置时，Hexo 配置文件中的 theme_config 的优先级最高，其次是 _config.[theme].yml 文件，最后是位于主题目录下的 _config.yml 文件。\n 指令   version 显示 Hexo 版本：\nhexo version   list 列出网站资料：\nhexo list   新建一篇文章：如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。\nhexo new [layout] \u0026lt;title\u0026gt; hexo n [layout] \u0026lt;title\u0026gt;   Hexo 有三种默认布局：\n   布局 路径     post source/_posts   page source   draft source/_drafts      预览草稿，publish 发表草稿：\nhexo server --draft hexo publish [layout] \u0026lt;filename\u0026gt;   clean 清除缓存文件 (db.json) 和已生成的静态文件 (public)：\nhexo clean   generate 生成静态文件：\nhexo generate hexo g   启动 hexo 的内置 Web 服务器：该命令将会调用 Markdown 引擎解析项目中的博客内容生成网页资源，资源将会存于内存中。\nhexo server hexo s --debug\t# 开启调试模式（--debug） hexo s --port 8000\t# 添加 -p / --port 参数来设置 Web 服务监听的端口号 hexo s --static\t# 加 -s / --static 参数，本地改动不触发 hexo 实时解析更新。   deploy 部署网站：\nhexo deploy hexo d   写作   Front-matter： 是文件最上方以 --- 分隔的区域，用于指定个别文件的变量\n--- layout: # 布局 title: # 标题 date: # 建立日期 updated: # 更新日期 comments: # 开启文章的评论功能 tags:\t# 标签 - 标签1 - 标签2 categories: [分类1, 分类2]\t# 分类, 不适用与分页 permalink: # 覆盖文章网址 --- 标签是一种列表结构，而分类是一种树结构。\n  文本居中标签：在引用单行文本时使用\n\u0026lt;blockquote class=\u0026quot;blockquote-center\u0026quot;\u0026gt;blah blah blah\u0026lt;/blockquote\u0026gt;\t# HTML方式 {% centerquote %}blah blah blah{% endcenterquote %}\t# 标签方式 {% cq %} blah blah blah {% endcq %}\t# 标签别名   引用块\n{% blockquote [author[, source]] [link] [source_link_title] %} content {% endblockquote %}   代码块\n``` [language] [title] [url] [link text] code snippet  - `langugae`：语言名称，引导渲染引擎正确解析并高亮显示关键字 - `title`：代码块标题，将会显示在左上角 - `url`：链接地址，如果没有指定 link text 则会在右上角显示 link - `link text`：链接名称，指定 url 后有效，将会显示在右上角 - 如果设置语言为 diff，可以在代码前添加 `+` 和 `-` 来使用如上所示的高亮增删行提示效果，在展示代码改动痕迹时比较实用。   note 标签：通过 note 标签可以为段落添加背景色\n{% note [class] %} 文本内容 (支持行内标签) {% endnote %}  支持的 class 种类包括 default、primary、success、info、warning、danger    label 标签：通过 label 标签可以为文字添加背景色\n{% label [class]@text %}  支持的 class 种类包括 default、primary、success、info、warning、danger    button 按钮：通过 button 标签可以快速添加带有主题样式的按钮\n{% button /path/to/url/, text, icon [class], title %} {% btn /path/to/url/, text, icon [class], title %}   tab 标签：tab 标签用于快速创建 tab 选项卡\n{% tabs [Unique name], [index] %} \u0026lt;!-- tab [Tab caption]@[icon] --\u0026gt; 标签页内容（支持行内标签） \u0026lt;!-- endtab --\u0026gt; {% endtabs %}  Unique name: 全局唯一的 Tab 名称，将作为各个标签页的 id 属性前缀 index: 当前激活的标签页索引，如果未定义则默认选中显示第一个标签页，如果设为 - 1 则默认隐藏所有标签页 Tab caption: 当前标签页的标题，如果不指定则会以 Unique name 加上索引作为标题 icon: 在标签页标题中添加 Font awesome 图标    引用站内链接\n{% post_path slug %} {% post_link slug [title] %}  slug 表示 _post 目录下的 Markdown 文件名。 post_path 标签将会渲染为文章的地址，即 permalink；而 post_link 标签将会渲染为链接，可以通过 title 指定链接标题。    插入 Swig 代码：通过 raw 标签来禁止 Markdown 引擎渲染标签内的内容。该标签通常用于在页面内引入三方脚本实现特殊功能。\n{% raw %} content {% endraw %}   插入 Gist\n{% gist gist_id [filename] %}  gist_id: Gist 仓库页面 url 中最后一段随机字符串 filename: Gist 中的文件名，如果 Gist 中只有一个文件，可以不用指定 filename，如果 Gist 中有多个文件，可以在标签内输入 filename 来指定只引入某个文件，如果没有指定 filename，将会引入 Gist 中的所有文件。    插入图片：\n  Markdown 并不会保存插入的图片资源本身，只是记录了获取资源的链接。\n  相对路径引用的标签插件\n{% asset_img slug [title] %}   slug 是资源文件夹下的图片名\n  Embedding an image using markdown：allows you to embed an image in markdown without using asset_img tag plugin.\npost_asset_folder: true marked: prependRoot: true postAsset: true ![](image.jpg) will be rendered as \u0026lt;img src=\u0026quot;/2020/01/02/foo/image.jpg\u0026quot;\u0026gt;.\n    用Typora编写Hexo博客时能实预览图片\n  思路是在before_post_render阶段将markdown文件中图片的路径转换为asset_img函数。\nnpm install hexo-image-link --save       文章加密\n  Install\nnpm install --save hexo-blog-encrypt   Quick start: Add the \u0026ldquo;password\u0026rdquo; value to your post\u0026rsquo;s front matter like\n--- password: mikemessi ---     Hexo 添加文章时自动打开编辑器\n  在 Hexo 目录下的 scripts 目录中创建一个 JavaScript 脚本文件。通过这个脚本，我们用其来监听 hexo new 这个动作，并在检测到 hexo new 之后，执行编辑器打开的命令。\n  将下列内容写入你的脚本\nvar spawn = require('child_process').exec; hexo.on('new', function(data){ spawn('start \u0026quot;markdown编辑器绝对路径.exe\u0026quot; ' + data.path); });     文章置顶\n--- sticky: true ---   资源文件夹 资源（Asset）代表 source 文件夹中除了文章以外的所有文件。\n文章资源文件夹\npost_asset_folder: true 当资源文件管理功能打开后，Hexo将会在你每一次通过 hexo new [layout] \u0026lt;title\u0026gt; 命令创建新文章时自动创建一个文件夹。这个资源文件夹将会有与这个文章文件一样的名字。将所有与你的文章有关的资源放在这个关联文件夹中之后，你可以通过相对路径来引用它们。\n部署 持续集成（Continuous Integration，简称 CI）\nSimply Push to Deploy：热部署，只需要将代码 push 到 Git 远程仓库即可自动构建及更新。\nNetlify\nGitHub Action：\n  Add your ssh key pair\n  Run the following terminal command, replacing the email with one connected to your GitHub account.\nssh-keygen -t rsa -C \u0026#34;username@example.com\u0026#34; Windows 下自定义 ssh key 文件需写成 GIT\\BlogSrc/.ssh/id_rsa\n  In Github Pages repo: Add the contents of the public key（id_rsa.pub） within your repositories deploy keys menu. You can find this option by going to Settings \u0026gt; Deploy Keys, you can name the public key whatever you want, but you do need to give it write access.\n  In hexo source code repo: Add the contents of the private key（id_rsa） to the Settings \u0026gt; Secrets menu as DEPLOY_KEY.\n    Configure github workflows：Create a workflow .yml file in your .github/workflows directory.\nname: Deploy on: [push] jobs: build: runs-on: ubuntu-latest name: A job to deploy blog. steps: - name: Checkout uses: actions/checkout@v1 with: submodules: true # Checkout private submodules(themes or something else). # Caching dependencies to speed up workflows. (GitHub will remove any cache entries that have not been accessed in over 7 days.) - name: Cache node modules uses: actions/cache@v1 id: cache with: path: node_modules key: ${{ runner.os }}-node-${{ hashFiles(\u0026#39;**/package-lock.json\u0026#39;) }} restore-keys: | ${{ runner.os }}-node- - name: Install Dependencies if: steps.cache.outputs.cache-hit != \u0026#39;true\u0026#39; run: npm ci # Deploy hexo blog website. - name: Deploy id: deploy uses: sma11black/hexo-action@v1.0.3 with: deploy_key: ${{ secrets.DEPLOY_KEY }} user_name: your github username  # (or delete this input setting to use bot account) user_email: your github useremail  # (or delete this input setting to use bot account) commit_msg: ${{ github.event.head_commit.message }}  # (or delete this input setting to use hexo default settings) # Use the output from the `deploy` step(use for test action) - name: Get the output run: | echo \u0026#34;${{ steps.deploy.outputs.notify }}\u0026#34;   一键部署\n  新建一个空的 repository（没有init任何内容）。你的 repository 必须直接命名为 \u0026lt;你的 GitHub 用户名.github.io\u0026gt;。从而能通过 \u0026lt;你的 GitHub 用户名.github.io\u0026gt; 域名直接访问你的blog。\n  安装 hexo-deployer-git。\nnpm install hexo-deployer-git --save   修改_config.yml配置。\ndeploy: type: git repo: git@github.com:yourname/yourname.github.io.git branch: master   生成站点文件并推送至远程库。执行 hexo clean \u0026amp; hexo deploy。\n  登入 Github，在库设置（Repository Settings）中将默认分支设置为_config.yml配置中的分支名称。稍等片刻（Blog 不会立马加载出来，需多刷新几下），您的站点就会显示在您的Github Pages中。\n  这是如何发生的：当执行 hexo deploy 时，Hexo 会将 public 目录中的文件和目录推送至 _config.yml 中指定的远端仓库和分支中，并且完全覆盖该分支下的已有内容。\n  部署分支与写作分支：hexo d 部署到 GitHub 的是 hexo 编译后的文件，不包含源文件。可以利用git的分支管理，将源文件上传到 GitHub。一个好的实践是放在两个不同的 Git 仓库中。\n  主题 创建 Hexo 主题非常容易，您只要在 themes 文件夹内，新增一个任意名称的文件夹，并修改 _config.yml 内的 theme 设定，即可切换主题。\n _config.yml：主题的配置文件。和 Hexo 配置文件不同，主题配置文件修改时会自动更新，无需重启 Hexo Server。 languages：语言文件夹。 layout：布局文件夹。 scripts：脚本文件夹。 source：资源文件夹。  在 GitHub 搜索 Hexo 即可找到流行的 Hexo 主题。各主题都有相应的使用文档。\n其他 列表之后不能立即接一个代码块，否则会解析出错。如\n- ```bash code... ``` 一行代码没有问题\n- `code` 首页展示最新博客 index_generator: path: \u0026#39;\u0026#39; per_page: 10 - order_by: -date + order_by: {updated: -1}  -updated_option: \u0026#39;mtime\u0026#39; +updated_option: \u0026#39;date\u0026#39; Are there more order options?\n  Api Document：https://hexojs.github.io/warehouse/Query.html#sort\n  sort(orderby, orderopt) → {Query}\n  Example:\nquery.sort('date', -1); query.sort({date: -1, title: 1}); query.sort('-date title');   If the order equals to -1, desc or descending, the data will be returned in reversed order.\n  Parameters:\n   Name Type Attributes     orderby String Object   order String Number        Sort is to sort the object properties (Page-Variables), refer to the above document for details。\n   Variable Description Type     page.title Article title string   page.date Article created date Moment.js object   page.updated Article last updated date Moment.js object      hexo-generator-index\nconst posts = locals.posts.sort(config.index_generator.order_by);   updated_option\nupdated_option 控制了当 Front Matter 中没有指定 updated 时，updated 如何取值：\n mtime: 使用文件的最后修改时间。这是从 Hexo 3.0.0 开始的默认行为。 date: 使用 date 作为 updated 的值。可被用于 Git 工作流之中，因为使用 Git 管理站点时，文件的最后修改日期常常会发生改变 empty: 直接删除 updated。使用这一选项可能会导致大部分主题和插件无法正常工作。    NexT Getting Started Installation\n  Installation\ncd hexo-site npm install hexo-theme-next   Usage, theme config file\ntheme: next   Update\ncd hexo-site npm update hexo-theme-next   Configuration\nInstalled through npm\ncp node_modules/hexo-theme-next/_config.yml _config.next.yml Theme Settings Choosing Scheme:\nBy using Scheme NexT gives you different views. And nearly all config can be used by those Schemes.\n# next/_config.yml scheme: Muse Configuring Favicon:\nBy default the Hexo site use NexT favicons in hexo-site/themes/next/source/images/ directory with different size for different device.\nYou can replace them with your own favicons.\nFor example, you can put your favicons in hexo-site/source/images/ directory. Then you need to rename them and change the settings in favicon section in theme config file.\nCreative Commons:\nNexT supports the display of Creative Commons 4.0 International License in sidebar and post.\n# next/_config.yml creative_commons: license: by-nc-sa sidebar: true post: false language: en 通行的版权协议是一种限制性的协议，就是说，只有它明文许可你可以做的事，你才能做，否则就是侵权行为。\n而\u0026quot;开放内容许可证\u0026quot;（open content licenses）只明文禁止使用者不能做的事，除此以外，可以随意使用这些作品。创作共用许可证（Creative Commons licenses，简称cc），就是这样一种许可证。\n使用创作共用许可证，作者可以选择保留四种权利：\n 署名（Attribution，简写为by）：必须提到原作者。 非商业用途（Noncommercial，简写为nc）：不得用于盈利性目的。 禁止演绎（No Derivative Works，简写为nd）：不得修改原作品。 相同方式共享（Share Alike，简写为sa）：如果允许修改原作品，那么必须使用相同的许可证发布。  Configuring Menu Items:\nMenu settings items have format Key: /link/ || icon which contains 3 values:\n Key → is the name of menu item (home, archives, etc.). /link/ → is the target link to relative url inside your site. icon → is the name of Font Awesome icon.  To customize menu items, edit the following content in theme config file:\nmenu: home: / || fa fa-home about: /about/ || fa fa-user tags: /tags/ || fa fa-tags archives: /archives/ || fa fa-archive Google Calendar Page\nschedule: /schedule/ || fa fa-calendar sitemap：为了让博文被google或百度检索，需要使用hexo的sitemap功能。\nsitemap: /sitemap.xml || fa fa-sitemap   Install\nnpm install hexo-generator-sitemap --save   Hexo Config\nsitemap: path: sitemap.xml   Except home and archives, all custom pages under menu section need to be created manually!\nSidebar Setting\nConfiguring Avatar：\nPut your avatar under site directory source/uploads/ (create directory if it doesn\u0026rsquo;t exists).And then change option to url: /uploads/avatar.png.\navatar: url: /uploads/avatar.png rounded: true 点击头像回到首页：\n主要是将\u0026lt;img class=\u0026quot;site-author-image\u0026quot; ... /\u0026gt;加入到\u0026lt;a href=\u0026quot;/\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;。\nSidebar Social Links：\n  Edit the social section in theme config file as following:\nsocial: GitHub: https://github.com/yourname || fab fa-github E-Mail: mailto:yourname@example.com || fa fa-envelope   取消社交图标前的小圆点：\n# create hexo-site/source/_data/styles.styl .links-of-author a, .links-of-author .exturl { \u0026amp;:before { display: none; } }   Sidebar Blogrolls (友链):\nlinks: Title1: https://example.com/ Sidebar TOC:\ntoc: number: false expand_all: true max_depth: 5 Footer\nSite Footer Icon:\nBy default NexT shows red heart icon between year and copyright information in the footer.\nfooter: icon: animated: true Site Copyright Name:\nBy default NexT shows the name of author from site config file.\nfooter: copyright: YourName Site Platform Information:\nBy default NexT shows Hexo and Theme \u0026amp; scheme information.\nfooter: powered: false Site Beian Information:\nBeian information is for Chinese users.\nfooter: beian: enable: true icp: 京ICP备 1234567890号-1 gongan_id: 1234567890 gongan_num: 京公网安备 1234567890号 gongan_icon_url: /uploads/beian.png Post Settings\nPreamble Text:\nYou can use following ways to show summary of articles and a Read More button.\nUse \u0026lt;!-- more --\u0026gt; in your article to break your article manually, which is recommended by Hexo. (recommended)\nIf you have added description and set its value to your article summary in front-matter, NexT excerpts description as preamble text in homepage by default. Without description, the full contents would be the preamble text in homepage.\nPost Wordcount:\n  Installation\ncd hexo-site npm install hexo-word-counter hexo clean   Hexo Config\nsymbols_count_time: total_symbols: false\t# By default NexT shows the number of all posts words in footer section. total_time: false\t# By default NexT shows the estimated reading time of all posts in footer section.    Donate Settings:\n  Get your WeChat / Alipay receive money QRcode image(s) and put into source/images .\n  Set needed values in theme config file:\nreward_settings: enable: true animation: false comment: Buy me a coffee reward: wechatpay: /images/wechatpay.png alipay: /images/alipay.png   Follow Me:\nfollow_me: WeChat: /images/wechat_channel.jpg || fab fa-weixin RSS: /atom.xml || fa fa-rss  安装RSS插件  npm i hexo-generator-feed  配置站点配置文件(/_config.yml)的Extensions  plugin: - hexo-generator-feed # Feed Atom feed: type: atom path: atom.xml limit: 20  编辑主题配置文件(/theme/next/_config.yml)的social links，开启RSS的页面功能  rss: /atom.xml  关注RSS：把 https://vanehsiung.github.io/atom.xml 复制到RSS阅读器上，就能关注了。  Custom Pages\nCustom Page Support:\n  Adding New Page\ncd hexo-site hexo new page tags   Setting Front-matter Values\n--- title: Tags date: title: 2020-11-14 22:50:2 type: \u0026quot;tags\u0026quot; ---   Editting Menu\nmenu: tags: /tags/ || fa fa-tags   Custom 404 Page:\n  Create a new page called 404\ncd hexo-site hexo new page 404 --- title: 404 permalink: /404.html\t# 在 Github Docs 中 Github Pages 章有写 comments: false ---   Make sure relative_link is disabled in site config file\nrelative_link: false   Whether users can be redirected to the 404 page depends on the settings of the website hosting service or web server, not Hexo.\n  为 GitHub Pages 站点创建自定义 404 页面\n  Misc Theme Settings\nMobile Devices Adaptation:\nreduce padding/margin indents on devices with narrow width\nmobile_layout_economy: true Codeblock Style:\nNexT uses the Highlight.js and Prism package to support code highlight\n  Read Hexo\u0026rsquo;s documentation on Syntax Highlighting first, and set it up in site config file（在 _config.yml 中开启 Highlight 或 Prism）\nhighlight: enable: true   Preview all available Code Highlight themes here: NexT Highlight Theme Preview\n  Change the value of theme and prism to choose the highlight style you like\ntheme: light: xcode   NexT supports the copy-and-paste functionality of codeblock\ncodeblock: copy_button: enable: true style: mac\t# Mac Panel风格代码块 Back To Top:\nback2top: scrollpercent: true Fonts Customization：\nfont: enable: true host: https://fonts.loli.net global: family: Architects Daughter, Ma Shan Zheng codes: family: Share Tech Mono   host：查看字体与使用字体的网址是不一样的；可能不能查看字体，但可以使用字体\n  查看 Google Fonts，使用 Google Fonts https://fonts.googleapis.com，以下为镜像\n  https://fonts.loli.net\n  https://fonts.googleapis.cnpmjs.org\n  https://fonts.proxy.ustclug.org\n      查看谷歌字体中文版，使用 https://fonts.font.im\n  技巧：先放 latin 文字，再放 chinese 文字，就可以分别定制英文与中文（有些中文字体包含英文字母）。手机无法显示自定义的中文字体，但可以显示自定义的英文字体。\n  SEO\nSEO Setting:\nNext provides useful options for better Search Engine Optimization (SEO).\nBy default a canonical link tag is created in Hexo after you have set up your URL url: http://example.com in site config file.\n# theme config file disable_baidu_transformation: true index_with_subtitle: true exturl: true Webmaster Tools:\n  Google Webmaster Tools\n  Login to Google Webmaster Tools and go to verification methods and choose HTML Tag, you will get some code:\n\u0026lt;meta name=\u0026quot;google-site-verification\u0026quot; content=\u0026quot;XXXXXXXXXXXXXXXXXXXXXXX\u0026quot;\u0026gt;   Copy XXXXXXXXXXXXXXXXXXXXXXX value of content key.Edit theme config file and add or change google_site_verification section:\ngoogle_site_verification: XXXXXXXXXXXXXXXXXXXXXXX   submit sitemap\n  That the new console says \u0026lsquo;couldnt fetch\u0026rsquo; is a bug in the console. Pending is the real status!\n    Bing Webmaster Tools\n  Login to Bing Webmaster Tools and go to verification methods and choose HTML Tag, you will get some code:\n\u0026lt;meta name=\u0026quot;msvalidate.01\u0026quot; content=\u0026quot;XXXXXXXXXXXXXXXXXXXXXXX\u0026quot;\u0026gt;   Copy XXXXXXXXXXXXXXXXXXXXXXX value of content key. Edit theme config file and add or change bing_site_verification section:\nbing_site_verification: XXXXXXXXXXXXXXXXXXXXXXX   submit sitemap\n  Bing 收录最快，立马就可以看到\n    Baidu Webmaster Tools\n  Login to Baidu Webmaster Tools and go to verification methods and choose HTML Tag, you will get some code:\n\u0026lt;meta name=\u0026quot;baidu-site-verification\u0026quot; content=\u0026quot;XXXXXXXXXXXXXXXXXXXXXXX\u0026quot;\u0026gt;   Copy XXXXXXXXXXXXXXXXXXXXXXX value of content key.Edit theme config file and add or change baidu_site_verification section:\nbaidu_site_verification: XXXXXXXXXXXXXXXXXXXXXXX   Push the url to baidu automatically\nbaidu_push: true   submit sitemap\n    Third-party Services Comment Systems\nLiveRe (Korea):\n  Create an account or log into LiveRe, click on the installation button and select the free city version, then click on the install now button.\n  Copy the data-uid field in the installation code to get your LiveRe UID.\n  Add the obtained LiveRe UID to the livere_uid section in the theme config file as following:\nlivere_uid:   Valine (China)：\n  Create an account or log into LeanCloud, and then click on the bottom left corner to create the application in dashboard.\n  Go to the application you just created, select Settings → App Keys in the lower left corner, and you will see your APP ID and APP Key.\n  Edit configurations in valine section in the theme config file as following:\nvaline: enable: true appId: appKey:   评论数据管理：请自行登录Leancloud应用管理。具体步骤：登录\u0026gt;选择你创建的应用\u0026gt;存储\u0026gt;选择Class Comment\n  Statistics and Analytics\nAnalytics Tools:\n  Baidu Analytics (China)\n  Login to Baidu Analytics and locate to site code getting page.\n  Copy the script ID after hm.js?.\n  Edit theme config file and change section baidu_analytics to your script ID.\nbaidu_analytics:     Google Analytics\n  Create an account and log into Google Analytics.\n  Edit theme config file and fill tracking_id under section google_analytics with your Google track ID. Google track ID always starts with UA- (最新版 Google Analytics 是 G-).\ngoogle_analytics: tracking_id: G-XXXXXXXX only_pageview: false     Counting Tools:\nBusuanzi Counting (China), Edit busuanzi_count option in theme config file.\n不蒜子是基于域名来进行统计计算的。数据比百度统计多很多。网络不好的话，数据与图标不一定显示得出来。\nbusuanzi_count: enable: true Search Services\nLocal Search:\nThis search method is recommended for most users.\n  Installation\nnpm install hexo-generator-searchdb   Hexo Config\nsearch: path: search.xml field: post content: true format: html   NexT Config\nlocal_search: enable: true   External Libraries\nPJAX：\n  You can enable it by setting value pjax to true in theme config file.\npjax: true   It listens to every click on links you want (by default all of them).When an internal link is clicked, Pjax fetches the page\u0026rsquo;s HTML via AJAX.\n  Please use the absolute path of the image or Hexo asset_img tag in your posts, otherwise the images may fail to load during Pjax refresh.\n  例子：添加音乐播放器并保持跳转时不中断播放状态；fireworks 特效更流畅，不存在点击链接时的卡顿现象（点击链接时不会触发fireworks）。\n  Fancybox:\nA jQuery lightbox script for displaying images, videos and more.\nfancybox: true Lazyload:\nIt delays loading of images in long web pages. Images outside of viewport will not be loaded before user scrolls to them.\nlazyload: true Progress Bar:\nNProgress will automatically monitor your Ajax requests, event loop lag, document ready state and elements on your page to decide on the progress.\nnprogress: enable: true spinner: false Canvas Ribbon：\ncanvas_ribbon: enable: true size: 300\t# The width of the ribbon. alpha: 0.6\t# The transparency of the ribbon. zIndex: -1\t# The display level of the ribbon. 粒子漂浮聚合：\n该功能由 theme-next-canvas-nest 插件提供：\n  Create a file named footer.njk  in hexo/source/_data directory, Edit this file and add the following content\n\u0026lt;script color=\u0026quot;0,0,255\u0026quot; opacity=\u0026quot;0.5\u0026quot; zIndex=\u0026quot;-1\u0026quot; count=\u0026quot;99\u0026quot; src=\u0026quot;https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;   In the NexT _config.yml, uncomment footer under the custom_file_path section.\ncustom_file_path: footer: source/_data/footer.njk   Tag Plugins Mermaid\n  Settings\nmermaid: enable: true   Usage\n{% mermaid type %} {% endmermaid %}   Advanced Settings Custom Files\n  uncomment under the section in theme config file.stylecustom_file_path。\ncustom_file_path: head: source/_data/head.njk header: source/_data/header.njk ...   Edit in site root directory and add files:source/_data/...。\n  Then use it。\n  Stylus 是 CSS 的预处理框架，给 CSS 添加了可编程的特性。Stylus支持三种注释，单行注释（//)，多行注释(/* */)。\n  Nunjucks 是 jinja2 的 javascript 的实现，可以使用 {# and #} 来写注释，渲染时将会去除所有的注释。\n  不要直接修改 model 文件，而要使用 custom file，方便之后升级。\n  Front Matter\n--- photos: /uploads/png.png --- Misc Settings 想要什么功能可以搜一下，看是否有现成的 model 可以使用。\n网易云音乐\n 在网页版云音乐中找到歌曲，点击生成外链播放器 根据个人喜好选择播放器尺寸和播放模式 将获取到的 iframe 代码添加到页面中  Aplayer 音频播放器\n  借助 hexo-tag-aplayer 插件，可以通过标签的形式方便快捷的插入音频组件。\n  Installation\nnpm install --save hexo-tag-aplayer   Usage\n{% aplayer \u0026quot;title\u0026quot; \u0026quot;author\u0026quot; \u0026quot;url\u0026quot; [\u0026quot;picture_url\u0026quot;, \u0026quot;narrow\u0026quot;, \u0026quot;autoplay\u0026quot;, \u0026quot;width:xxx\u0026quot;, \u0026quot;lrc:xxx\u0026quot;] %}  title: 曲目标题 author: 曲目作者 url: 音乐文件 URL 地址 picture_url: (可选) 音乐对应的图片地址 narrow: （可选）播放器袖珍风格 autoplay: (可选) 自动播放，移动端浏览器暂时不支持此功能 width:xxx: (可选) 播放器宽度 (默认: 100%) lrc:xxx: （可选）歌词文件 URL 地址    当开启 Hexo 的 文章资源文件夹功能时，可直接引用\n{% aplayer \u0026quot;Caffeine\u0026quot; \u0026quot;Jeff Williams\u0026quot; \u0026quot;caffeine.mp3\u0026quot; \u0026quot;picture.jpg\u0026quot; \u0026quot;lrc:caffeine.txt\u0026quot; %}   Dpalyer 视频播放器\n  Installation\nnpm install hexo-tag-dplayer --save   Usage\n{% dplayer \u0026quot;url=video-url\u0026quot; \u0026quot;pic=image-url\u0026quot; ... [\u0026quot;key=value\u0026quot;] %}   部分重要 key\n 播放器  autoplay：是否开启视频自动播放，默认为 fasle loop：是否开启视频循环播放，默认为 false screenshot：是否开启截图，默认为 false mutex：是否禁止多个播放器同时播放，默认为 true dmunlimited：是否开启海量弹幕模式，默认为 false preload：预加载模式，可选 note metadata auto theme：主题色 lang：语言，可选 en zh-cn zh-tw logo：左上角的 Logo volume：默认音量，默认为 0.7 width：播放器宽度 height：播放器长度   视频  url：视频链接 pic：视频封面 thumbnails：视频缩略图，可以使用 DPlayer-thumbnails 生成 vidtype：视频类型，可选 auto hls flv dash 或其他自定义类型   字幕  suburl：字幕链接 subtype：字幕类型，可选 webvtt ass，目前只支持 webvtt subbottom：字幕距离播放器底部的距离，如 10px 10% subcolor：字幕颜色   弹幕  id：弹幕 id api：弹幕 api token：弹幕后端验证 token addition：额外外挂弹幕 dmuser：弹幕用户名 maximum：弹幕最大数量      看板娘\n该功能由 hexo-helper-live2d 插件支持\n  Installation\nnpm install --save hexo-helper-live2d   Config：在站点配置文件中设置，主题配置文件中设置没用\nlive2d: enable: true scriptFrom: local pluginRootPath: live2dw/ pluginJsPath: lib/ pluginModelPath: assets/ tagMode: false log: false model: use: live2d-widget-model-shizuku display: position: right width: 150 height: 300 mobile: show: true react: opacity: 0.7   Models：可以从 hexo live2d 模型预览 里找到你喜欢的角色，然后根据 live2d-widget-models 中提供的方法来下载模型数据.\nnpm install live2d-widget-model-shizuku   Fireworks\n一个鼠标点击动画特效\nnpm install next-theme/hexo-next-fireworks activate-power-mode\n一个为博客添加酷炫打字特效的插件\n  编辑 /hexo-site/source/_data/footer.njk\n\u0026lt;script src=\u0026quot;https://cdn.jsdelivr.net/gh/suyin-long/activate-power-mode@1.0/dist/activate-power-mode.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; POWERMODE.colorful = true; // make power mode colorful POWERMODE.shake = false; // turn off shake document.body.addEventListener('input', POWERMODE); \u0026lt;/script\u0026gt;   取消footer: source/_data/footer.njk的注释\n  搞怪网页标题\n  编辑 /hexo-site/source/_data/head.njk，添加\n{# 搞怪网页标题 #} {% if theme.title_trick.enable %} \u0026lt;script\u0026gt; var OriginTitile = document.title; var titleTime; document.addEventListener(\u0026quot;visibilitychange\u0026quot;, function() { if (document.hidden) { document.title = \u0026quot;{{ theme.title_trick.leave }}\u0026quot;; clearTimeout(titleTime); } else { document.title = \u0026quot;{{ theme.title_trick.enter }}\u0026quot;; titleTime = setTimeout(function() { document.title = OriginTitile; }, 2000); } }); \u0026lt;/script\u0026gt; {% endif %}   在主题配置文件中添加\n# a trick on website title title_trick: enable: true leave: \u0026#34;(つェ⊂)我藏好了哦~\u0026#34; enter: \u0026#34;(*´∇｀*) 被你发现啦~\u0026#34;   我先是放在 sorce/_data/head.njk 中，问题是改变一次标题后就只显示网址。我认为 script 可能在 \u0026lt;title\u0026gt; 之前加载，所以就放在 source/_data/header.njk，正常运行。\n  Hexo NexT Three\n  Install\nnpm install next-theme/hexo-next-three   Configure\n# JavaScript 3D library. # Dependencies: https://github.com/next-theme/hexo-next-three three: enable: true defer: true cdn: waves: enable: false cdn: lines: enable: false cdn: sphere: enable: false cdn:   hexo-cake-moon-menu\n  How to use\nnpm install hexo-cake-moon-menu   Config: In hexo _config.yml\nmoon_menu: back2top: enable: true icon: fas fa-chevron-up func: back2top order: -1 back2bottom: enable: true icon: fas fa-chevron-down func: back2bottom order: -2   permalink\n  默认的文章 url 地址为 http://yoursite.com/:year/:month/:day/:title/，这种 url 格式层级太多，并且如果文章标题是中文的话可能会发生转义而出现一堆乱码，不利于搜索引擎的爬取分析，因此建议在站点配置中修改 permalink 的格式来简化页面 url，并尽量采用英文命名 Markdown 文件。(这个根据个人选择，我认为有更有组织的文件结构更重要)\n  这个 front matter 必须是 html 文件，文件会生成到 public 根目录。\n --- permalink: /post-name.html ---   robots.txt\nrobots.txt（统一小写）是一种存放于网站根目录下的ASCII编码的文本文件，它通常告诉网络搜索引擎的漫游器（又称网络蜘蛛），此网站中的哪些内容是不应被搜索引擎的漫游器获取的，哪些是可以被漫游器获取的。\nrobots.txt在线生成器\nCDN CDN 的全称是(Content Delivery Network)，即内容分发网络。其目的是通过在现有的 Internet 中增加一层新的CACHE(缓存)层，将网站的内容发布到最接近用户的网络“边缘”的节点，使用户可以就近取得所需的内容，提高用户访问网站的响应速度。从技术上全面解决由于网络带宽小、用户访问量大、网点分布不均等原因，提高用户访问网站的响应速度。\nCDN 工作原理 传统访问过程：\n 用户输入访问的域名，操作系统向 LocalDns 查询域名的ip地址 LocalDns 向 ROOT DNS 查询域名的授权服务器（这里假设LocalDns缓存过期） ROOT DNS 将域名授权 dns 记录回应给 LocalDns LocalDns 得到域名的授权 dns 记录后，继续向域名授权 dns 查询域名的 ip 地址 域名授权 dns 查询域名记录后，回应给 LocalDns LocalDns 将得到的域名 ip 地址，回应给用户端 用户得到域名 ip 地址后，访问站点服务器 站点服务器应答请求，将内容返回给客户端  CDN 访问过程：\n 用户输入访问的域名，操作系统向 LocalDns 查询域名的 ip 地址 LocalDns 向 ROOT DNS 查询域名的授权服务器（这里假设LocalDns缓存过期） ROOT DNS 将域名授权 dns 记录回应给 LocalDns LocalDns 得到域名的授权 dns 记录后，继续向域名授权 dns 查询域名的 ip 地址 域名授权 dns 查询域名记录后（一般是CNAME），回应给 LocalDns LocalDns 得到域名记录后，向智能调度 DNS 查询域名的 ip 地址 智能调度 DNS 根据一定的算法和策略，将最适合的 CDN 节点 ip 地址回应给 LocalDns LocalDns 将得到的域名 ip 地址，回应给用户端 用户得到域名 ip 地址后，访问站点服务器 CDN 节点服务器应答请求，将内容返回给客户端  参考 CDN加速原理\nNPM npm makes it easy for JavaScript developers to share and reuse code, and it makes it easy to update the code that you\u0026rsquo;re sharing.\n基本：\n  package.json 和 package-lock.json\n package.json 执行 npm init 命令生成，描述项目模块信息 package-lock.json 执行 npm install 命令生成，描述模块来源及依赖信息，可删除    安装模块：\n  全局安装\nnpm install -g 模块名称   本地安装：读取 package.json 并下载模块到 node_modules 的目录，模块分为两类 dependencies 和devDependencies，分别对应生产环境需要的安装包和开发环境需要的安装包\nnpm install \u0026lt;package_name\u0026gt; # 在安装模块的时候，可以通过指定参数来修改 package.json 文件 npm install \u0026lt;package_name\u0026gt; --save npm install \u0026lt;package_name\u0026gt; --save-dev     更新模块\nnpm update   卸载模块\nnpm uninstall -g \u0026lt;package_name\u0026gt; npm uninstall \u0026lt;package_name\u0026gt; # 卸载模块的同时，也从 package.json 文件中移除 npm uninstall --save \u0026lt;package_name\u0026gt; npm uninstall --save-dev \u0026lt;package_name\u0026gt;   解决问题：\n  Ubuntu 安装最新 LTS 版本：官方教程，Windows 版本更好\nsudo mkdir -p /usr/local/lib/nodejs sudo tar -xJvf node-$VERSION-$DISTRO.tar.xz -C /usr/local/lib/nodejs vi ~/.profile # Nodejs VERSION=v10.15.0 DISTRO=linux-x64 export PATH=/usr/local/lib/nodejs/node-$VERSION-$DISTRO/bin:$PATH . ~/.profile\t# Refresh profile sudo ln -s /usr/local/lib/nodejs/node-$VERSION-$DISTRO/bin/node /usr/bin/node   查看 npm 配置\nnpm config list -l npm config ls   配置镜像：淘宝镜像不好用，特对对于 update\nnpm config set registry https://registry.npmjs.org --global   配置 NPM 不做严格的 SSL 校验\nnpm config set strict-ssl false   npm ERR! Unexpected end of JSON input while parsing near \u0026hellip;\nnpm cache clean --force   npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents：不管\n  npm ERR! code EINTEGRITY\ngrep -ir \u0026quot;sha1-WYr+VHVbKGilMw0q/51Ou1Mgm2U\u0026quot; ~/.npm\t# wanted sha1 npm cache clean --force grep -ir \u0026quot;sha1-WYr+VHVbKGilMw0q/51Ou1Mgm2U\u0026quot; ~/.npm npm install   getaddrinfo EAI_AGAIN registry.npmjs.org：网络问题，重新运行 npm install\n  升级为最新稳定版本的 node.js：超慢\nsudo npm cache clean -f sudo npm install -g n\t# n 是 Node版本管理控制器 sudo n stable   NPM 中文文档\nGreat Blogs yearito ，suyin ，yleao ，dlzhang\nVersion    Name Version     npm 7.0.8   hexo 5.2.0   hexo-theme-next 8.0.2    ","permalink":"https://example.com/posts/hexo/","summary":"Hexo Hexo 是一个快速、简洁且高效的博客框架。 安装 安装 Git： Windows: Download \u0026amp; install git. Mac: Install it with Homebrew, MacPorts or installer. Linux (Ubuntu, Debian): sudo apt-get install git-core Linux (Fedora, Red Hat, CentOS): sudo yum install git-core 安装 node.js： Windows: Install it with","title":"Hexo"},{"content":"Workspace：工作区，Index / Stage：暂存区，Repository：仓库区（或本地仓库），Remote：远程仓库\n远程仓库 安装，windows需要处理换行符 sudo yum install git 设置姓名和邮箱地址 git config --global user.name \u0026#34;Vane Hsiung\u0026#34; git config --global user.email \u0026#34;1664548605@qq.com\u0026#34; 提高输出可读性 git config --global color.ui auto 设置文件   显示当前的 Git 配置\ngit config --list cat ~/.giconfig   编辑Git配置文件\ngit config -e [--global]   设置SSH，添加认证密码 ssh-keygen -t rsa -C \u0026#34;1664548605@qq.com\u0026#34; 添加公开密钥 将下面的密钥添加到 GitHub 设置中的 SSH key 中\ncat ~/.ssh/id_rsa.pub 查看是否认证和通信成功 ssh -T git@github.com 获取远程仓库 clone 后默认在 master 分支下自动将 origin 设置为远程仓库标识符\ngit clone SSH 提速：\ngit clone SSH --depth=1 加上 \u0026ndash;depth 会只下载一个 commit，所以内容少了很多，速度也就上去了。\n而且下载下来的内容是可以继续提交新的 commit、创建新的分支的。不影响后续开发，只是不能切换到历史 commit 和历史分支。\n在一些场景下还是比较有用的：当需要切换到历史分支的时候也可以计算需要几个 commit，然后再指定 depth，这样也可以提高速度。\n获取远程非master分支 -b 后是新建分支名称\ngit checkout -b branchName origin/branchName 获取指定分支 使用git拉代码时可以使用 -b 指定分支，拉取 develop 分支代码：\ngit clone -b develop http://gitslab.yiqing.com/declare/about.git 查看当前项目拉的是哪个分支的代码详情：\ngit branch -v 查看分支上的递交情况:\ngit show-branch 获取最新的远程仓库分支 远程仓库拉取代码并合并到本地，可简写为 git pull 等同于 git fetch \u0026amp;\u0026amp; git merge\ngit pull \u0026lt;远程主机名\u0026gt; \u0026lt;远程分支名\u0026gt;:\u0026lt;本地分支名\u0026gt; # 取回远程仓库的变化，并与本地分支合并 git pull origin branchName # 使用rebase的模式进行合并 git pull --rebase \u0026lt;远程主机名\u0026gt; \u0026lt;远程分支名\u0026gt;:\u0026lt;本地分支名\u0026gt; # 获取远程仓库特定分支的更新 git fetch \u0026lt;远程主机名\u0026gt; \u0026lt;分支名\u0026gt; # 获取远程仓库所有分支的更新 git fetch --all 问题：For those who found this searching for an answer to fatal: 'origin/remote-branch-name' is not a commit and a branch 'local-branch-name' cannot be created from it, you may also want to try this first:\ngit fetch --all 与 git pull 不同的是 git fetch 操作仅仅只会拉取远程的更改，不会自动进行 merge 操作。对你当前的代码没有影响。\ngit rebase 让你的提交记录更加清晰可读\nrebase 翻译为变基，他的作用和 merge 很相似，用于把一个分支的修改合并到当前分支上。\n即逐个应用了 mater 分支的更改，然后以 master 分支最后的提交作为基点，再逐个应用 feature 的每个更改。\n大部分情况下，rebase 的过程中会产生冲突的，此时，就需要手动解决冲突，然后使用依次 git add  、git rebase --continue  的方式来处理冲突，完成 rebase 的过程，如果不想要某次 rebase 的结果，那么需要使用 git rebase --skip  来跳过这次 rebase 操作。\ngit merge 和 git rebase 的区别\n不同于 git rebase 的是，git merge 在不是 fast-forward（快速合并）的情况下，会产生一条额外的合并记录，类似 Merge branch 'xxx' into 'xxx' 的一条提交信息。\n另外，在解决冲突的时候，用 merge 只需要解决一次冲突即可，简单粗暴，而用 rebase 的时候 ，需要依次解决每次的冲突，才可以提交。\n同一台电脑配置多个 GItHub 账号 在日常使用 git 作为仓库使用的时候，有时可能会遇到这样的一些情况：\n 有两个 github 账号，一台电脑怎么同时连接这两个账号进行维护呢？ 自己用一个 github 账号，平时用来更新自己的一些资料；公司使用的 gitlab（也是 git 的衍生产品）  如下是解决方案：\n  创建默认 SSH Key\nssh-keygen -t rsa -C \u0026#34;one@example.com\u0026#34;   将公钥添加到 one@example.com 的 GitHub SSH key 中。\n  测试 ssh key 是否成功\nssh -T git@github.com   如果设置过全局，则清除 git 的全局设置\n# 查看当前配置 git config --list # 取消 global user.name user.email git config --global --unset user.name git config --global --unset user.email   生成另外一个账号新的SSH keys\nssh-keygen -t rsa -C \u0026#34;two@example.com\u0026#34; 私钥需重命名，如 id_rsa_two。然后将对应的公钥添加到two@example.com的 Github SSH key 中。\n  需添加新私钥到 SSH agent 中，因为默认只读取 id_rsa\n# Windows 在管理员下运行 Get-Service ssh-agent Set-Service ssh-agent -StartupType Manual Start-Service ssh-agent # Linux eval `ssh-agent -s` # 添加私钥 ssh-add ~/.ssh/id_rsa_new unable to start ssh-agent service\nCould not open a connection to your authentication agent\n  配置 ~/.ssh/config 文件，用于配置私钥对应的服务器\n# Default github user(one@example.com) Host git@github.com HostName github.com User \u0026#34;Your GitHub Account Name\u0026#34; IdentityFile ~/.ssh/id_rsa # another user(two@example.com) # 建一个别名，新建的帐号使用这个别名做克隆和更新 # \u0026#34;Host\u0026#34; 如果带了 \u0026#34;git@\u0026#34;，如 \u0026#34;git@two.github.com\u0026#34;，就会连接到 two.github.com # \u0026#34;Host\u0026#34; 没有带 \u0026#34;git@\u0026#34;，就会正确的连接到 github.com Host two.github.com HostName github.com User \u0026#34;Your GitHub Account Name\u0026#34; IdentityFile ~/.ssh/id_rsa_two 测试\n# default ssh -T git@github.com # another ssh -T git@two.github.com   使用\n# default git remote add origin git@github.com:one/demo.git # another git remote add origin git@two.github.com:two/demo.git   设置每个项目的自己的 user.name 和 user.email\ngit config user.email \u0026#34;two@example.com\u0026#34; git config user.name \u0026#34;two\u0026#34;   Git 中 HTTPS 和 SSH 的 Clone 方式区别  HTTPS：不管是谁，拿到url随便clone，但是在push的时候需要验证用户名和密码； SSH：clone的项目你必须是拥有者或者管理员，而且需要在clone前添加SSH Key。SSH 在push的时候，是不需要输入用户名的，如果配置SSH key的时候设置了密码，则需要输入密码的。  本地仓库 初始化仓库 生成 .git 目录, 也就是当前目录的仓库，当前目录称为“附属于该仓库的工作树”\ngit init [project-name] 查看仓库的状态 git status\t# 显示有变更的文件 向暂存区添加文件   添加指定文件到暂存区\ngit add [file1] [file2] ...   添加指定目录到暂存区，包括子目录\ngit add [dir]   添加当前目录的所有文件到暂存区\ngit add .   删除工作区文件，并且将这次删除放入暂存区\ngit rm [file1] [file2] ...   改名文件，并且将这个改名放入暂存区\ngit mv [file-original] [file-renamed]   原理（git add 为如下两步简写）：\n  为 example.txt 创建一个副本。git hash-object 命令把 example.txt 的当前内容压缩成二进制文件，称为一个 Git 对象，保存在 .git/objects 目录。并计算当前内容的哈希值，前 2 个字符作为目录名，后 38 个字符作为该对象的文件名\ngit hash-object -w example.txt 二进制对象里面会保存一些元数据，如果想看该文件原始的文本内容，需用git cat-file命令\ngit cat-file -p e69de29bb2d1d6434b8b29ae775ad8c2e48c5391   所有变动的文件，Git 都记录在\u0026quot;暂存区\u0026quot;，git update-index 命令用于在暂存区记录一个发生变动的文件\ngit update-index --add --cacheinfo 100644 e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 example.txt git ls-files 命令显示暂存区当前内容\ngit ls-files --stage   查看更改前后的差别 习惯：git commit 前先 git diff HEAD\ngit diff 默认查看工作树和暂存区的差别\nHEAD查看工作树与最新提交的差别，HEAD 为指向当前分支中最新一次提交的指针，HEAD^ 指向 HEAD 的前一个提交，HEAD~6 则是 HEAD 之前的第6个提交。每一个分支都是一个文本文件，保存在 .git/refs/heads/ 目录中，文件的内容是最新提交的哈希值\ngit diff [HEAD] 将暂存区中文件保存到仓库历史记录中 -m 用于记录一行信息；不加 -m 记录详细信息，会新开编辑器进行编辑\n  相当与 git add 与 git commit\ngit commit -am \u0026#34;Message\u0026#34;\t  提交暂存区的指定文件到仓库区\ngit commit [file1] [file2] ... -m \u0026#34;Message\u0026#34;   提交工作区自上次commit之后的变化，直接到仓库区\ngit commit -a   提交时显示所有diff信息\ngit commit -v   原理（git commit -m \u0026quot;first commit\u0026quot; 为如下两步简写）：\n  git write-tree 命令保存当前的目录结构，生成一个 Git 对象\ngit write-tree   git commit-tree 命令用目录结构 Git 对象生成一个 Git 对象，需添加提交说明，-p 参数用来指定父提交\necho \u0026#34;first commit\u0026#34; | git e5a60f66d9966270c835343d4facc1c4bf44ed7a -p c9053865e9dff393fd2f7a92a18f9bd7f2caa7fa   修改提交信息 产生一个新的提交对象，替换掉上一次提交产生的提交对象\ngit commit --amend -m \u0026#34;Message\u0026#34; 重做上一次 commit，并包括指定文件的新变化\ngit commit --amend [file1] [file2] ... 压缩历史 用于拼错单词等简单的错误，选定当前分支中包含 HEAD（最新提交）在内的 number 个最新历史记录为对象并在编辑器中打开，pick 为合并对象，fixup 为被合并对象，最后 pick 提交信息会保留\ngit rebase -i HEAD~[number] 查看提交日志   --pretty=short 用于只显示第一行简述信息\n  FileName 为文件名或目录名，只显示指定文件的日志\n  -p 用于显示文件的改动\n  --stat 显示 commit 历史，以及每次 commit 发生变更的文件\ngit log [--pretty=short][FileName][-p][--stat]\t# 显示当前分支的版本历史   查看文件每次提交的diff\ngit log -p FileName   搜索提交历史，根据关键词\ngit log -S [keyword]   显示某个 commit 之后的所有变动，每个commit占据一行\ngit log [tag] HEAD --pretty=format:%s   显示某个 commit 之后的所有变动，其\u0026quot;提交说明\u0026quot;必须符合搜索条件\ngit log [tag] HEAD --grep feature   显示某个文件的版本历史，包括文件改名\ngit log --follow [file] git whatchanged [file]   git log 的运行过程\n 查找 HEAD 指针对应的分支 找到分支的最新提交 找到父节点（前一个提交） 依此类推，显示当前分支的所有提交  查看当前仓库操作日志 git reflog 怎么查看当前的git分支是基于哪个分支创建的\ngit reflog --date=local | grep \u0026lt;branchname\u0026gt;\n类似于如下\n6b3db1f HEAD@{Fri Jul 9 16:05:23 2021}: checkout: moving from development to feature/api_xiongwen_dump 可知 feature/api_xiongwen_dump 基于 development\n从暂存区撤销文件 停止追踪指定文件，但该文件会保留在工作区\ngit rm --cached [filename] 撤销提交 在当前提交后面，新增一次提交，抵消掉上一次提交导致的所有变化\ngit revert HEAD 想抵消多个提交，必须在命令行依次指定这些提交\ngit revert [倒数第一个提交] [倒数第二个提交] 回溯历史版本   重置暂存区的指定文件，与上一次 commit 保持一致，但工作区不变\ngit reset [file]   重置暂存区与工作区，与上一次 commit 保持一致\ngit reset --hard   让最新提交的指针回到以前某个时点，该时点之后的提交都从历史中消失\ngit reset 目标时间点哈希值\t# 重置当前分支的指针为指定 commit，同时重置暂存区，但工作区不变   默认情况下，git reset不改变工作区的文件（但会改变暂存区），--hard参数可以让工作区里面的文件也回到以前的状态\ngit reset --hard 目标时间点哈希值\t# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致   重置当前 HEAD 为指定 commit，但保持暂存区和工作区不变\ngit reset --keep [commit]   添加远程仓库 origin 为远程仓库的标识符\ngit remote add origin SSH\t# 增加一个新的远程仓库，并命名 git remote -v\t# 显示所有远程仓库 git remote show [remote]\t# 显示某个远程仓库的信息 推送至远程仓库  推送的是当前分支 -u 在推送的同时将远程仓库的（origin仓库）的 branch 分支设为本地仓库当前分支的 upstream（上游） 运行 git pull 从远程仓库获取内容时，就可以省略参数  git push [-u origin branchName]\t# 上传本地指定分支到远程仓库 git push --set-upstream origin [branchName]\t# To push the current branch and set the remote as upstream 如果每次 git push 都需要输入账号和密码\n  首先在 git 工作目录下：\ngit config [--global] credential.helper store   然后执行一次 git pull，这次输入账号和密码之后就不用再输入了。\n  Git push existing repo to a new and different remote repo server? 需求：从公司的账户 clone repo 到本地，添加注释，pull 到自己账户的私有 repo 中。\n Create a new repo at github. git remote rename origin upstream git remote add origin URL_TO_GITHUB_REPO git push origin master  Now you can work with it just like any other github repo. To pull in patches from upstream, simply run git pull upstream master \u0026amp;\u0026amp; git push origin master.\n分支 创建并切换分支 # 切换分支，并更新工作区 git checkout branchName\t#切换至上一分支 git checkout -\t# 新建一个分支，并切换到该分支 git checkout -b branchName\t# 新建本地分支，但不切换 git branch \u0026lt;branch-name\u0026gt; # 新建一个分支，指向指定commit git branch [branch] [commit]\t# 新建一个分支，与指定的远程分支建立追踪关系 git branch --track [branch] [remote-branch]\t以图表形式查看分支 git log --graph 显示分支 # 列出所有本地分支 git branch\t# 列出所有远程分支 git branch -r\t# 同时显示本地仓库和远程仓库的分支信息 git branch -a\t# 用于创建分支 git branch branchName\t# 本地分支对应哪个远程分支 git branch -vv 合并分支  --no-ff 用于记录本次分支合并 消除冲突：打开冲突的文件，在编辑器中改为想要的样子  git merge [--no-ff] branchName\t# 合并指定分支到当前分支 git cherry-pick [commit]\t# 选择一个 commit，合并进当前分支 删除分支   删除分支\n# 删除本地分支 git branch -d [branch-name]   删除远程分支\ngit push origin --delete [branch-name] git branch -dr [remote/branch]   撤销工作区的文件修改   先找暂存区，如果该文件有暂存的版本，则恢复该版本，否则恢复上一次提交的版本\ngit checkout -- [filename]   恢复某个 commit 的指定文件到暂存区和工作区\ngit checkout [commit] [file]   恢复暂存区的所有文件到工作区\ngit checkout .   分支重命名   重命名本地分支：\n  在当前分支时\ngit branch -m new_branch_name   当不在当前分支时\ngit branch -m old_branch_name new_branch_name     重命名远端分支：\n假设是在当前分支，并且远端分支与本地分支名是一致的重命名本地分支\ngit branch -m new_branch_name 删除远程分支\ngit push --delete origin old_branch_name 上传新命名的本地分支\ngit push origin new_branch_name 关联修改后的本地分支与远程分支\ngit branch --set-upstream-to origin/new_branch_name   标签   列出所有 tag\ngit tag   新建一个 tag 在当前commit\ngit tag [tag]   新建一个tag在指定commit\ngit tag [tag] [commit]   删除本地 tag\ngit tag -d [tag]   删除远程 tag\ngit push origin :refs/tags/[tagName]   查看 tag 信息\ngit show [tag]   提交指定 tag\ngit push [remote] [tag]   提交所有tag\ngit push [remote] --tags   新建一个分支，指向某个tag\ngit checkout -b [branch] [tag]   Git Ignore git 为我们提供了一个 .gitignore 文件，只要在这个文件中申明哪些文件你不希望添加到git中去，这样当你使用 git add . 的时候这些文件就会被自动忽略掉。\n经实验，可以为每一个平行非包含的目录设定一个 .gitignore。\nPull Request 当你想更正别人仓库里的错误时，要走一个流程：\n 先 fork 别人的仓库，相当于拷贝一份，相信我，不会有人直接让你改修原仓库的。 clone 到本地分支，做一些 bug fix。 发起 pull request 给原仓库，让他看到你修改的 bug。 原仓库 review 这个 bug，如果是正确的话，就会 merge 到他自己的项目中  至此，整个 pull request 的过程就结束了。\n拉取请求，就是请求对方拉取我本地仓库的 bug fix，合并到对方的 repo 中。以对方的视角来看，我的本地仓库就是一个远程仓库。因为我们是在请求对方做什么，所以要以对方视角来看，即 pull，因为对方可能同意，也可能不同意，所以是请求，即 pull request。\nGitHub Hosts GitHub520 本项目无需安装任何程序，通过修改本地 hosts 文件，试图解决：\n GitHub 访问速度慢的问题 GitHub 项目中的图片显示不出的问题  花 5 分钟时间，让你\u0026quot;爱\u0026quot;上 GitHub。\n# GitHub520 Host Start 140.82.112.26 alive.github.com 140.82.114.25 live.github.com 185.199.108.154 github.githubassets.com 140.82.113.22 central.github.com 185.199.108.133 desktop.githubusercontent.com 185.199.108.153 assets-cdn.github.com 185.199.108.133 camo.githubusercontent.com 185.199.108.133 github.map.fastly.net 199.232.69.194 github.global.ssl.fastly.net 140.82.113.4 gist.github.com 185.199.108.153 github.io 140.82.114.3 github.com 140.82.114.5 api.github.com 185.199.108.133 raw.githubusercontent.com 185.199.108.133 user-images.githubusercontent.com 185.199.108.133 favicons.githubusercontent.com 185.199.108.133 avatars5.githubusercontent.com 185.199.108.133 avatars4.githubusercontent.com 185.199.108.133 avatars3.githubusercontent.com 185.199.108.133 avatars2.githubusercontent.com 185.199.108.133 avatars1.githubusercontent.com 185.199.108.133 avatars0.githubusercontent.com 185.199.108.133 avatars.githubusercontent.com 140.82.112.10 codeload.github.com 52.216.170.203 github-cloud.s3.amazonaws.com 52.217.98.76 github-com.s3.amazonaws.com 52.216.164.3 github-production-release-asset-2e65be.s3.amazonaws.com 52.216.160.147 github-production-user-asset-6210df.s3.amazonaws.com 52.217.103.12 github-production-repository-file-5c1aeb.s3.amazonaws.com 185.199.108.153 githubstatus.com 64.71.168.201 github.community 185.199.108.133 media.githubusercontent.com # Update time: 2021-07-04T08:07:49+08:00 # Star me GitHub url: https://github.com/521xueweihan/GitHub520 # GitHub520 Host End GitHub Pages 使用 GitHub GitHub Pages 是一项静态站点托管服务，它直接从 GitHub 上的仓库获取 HTML、CSS 和 JavaScript 文件，（可选）通过构建过程运行文件，然后发布网站。\n有三种类型的 GitHub Pages 站点：项目、用户和组织。 项目站点连接到 GitHub 上托管的特定项目。 用户和组织站点连接到特定的 GitHub 帐户。\nTo publish a user site, you must create a repository owned by your user account that\u0026rsquo;s named \u0026lt;username.github.io\u0026gt;. Repositories using the legacy \u0026lt;username.github.com\u0026gt; naming scheme will still be published, but visitors will be redirected from http(s)://\u0026lt;username.github.com\u0026gt; to http(s)://\u0026lt;username.github.io. If both a \u0026lt;username.github.com\u0026gt; and \u0026lt;username.github.io\u0026gt; repository exist, only the \u0026lt;username.github.io\u0026gt; repository will be published.\nGitHub Pages sites are publicly available on the internet, even if the repository for the site is private or internal. 如果站点的仓库中有敏感数据，您可能想要在发布前删除它。\nGitHub Pages 站点的发布来源是存储站点源文件的分支和文件夹。用户和组织站点的默认发布源是仓库默认分支的根目录。 项目站点的默认发布来源是 gh-pages 分支的根目录。\n您可以创建自己的静态文件或使用静态站点生成器为您构建站点。默认情况下，GitHub Pages 将使用 Jekyll 来构建您的站点。\nGitHub Pages 站点受到以下使用限制的约束：\n GitHub Pages source repositories have a recommended limit of 1GB. 发布的 GitHub Pages 站点不得超过 1 GB。 GitHub Pages sites have a soft bandwidth limit of 100GB per month. GitHub Pages sites have a soft limit of 10 builds per hour.  可在 Repository 的 Settings 中配置 GitHub Pages 站点的发布源或取消发布 GitHub Pages 站点。\n使用 jekyll Github Docs 与 Jekyll 文档不一致，Windows 并未正式支持 Jekyll。\n使用 Hexo 我选择 Hexo，一个是安装简单；一个是文档好。\nGitHub Actions GitHub Actions 是什么 持续集成由很多操作组成，比如自动抓取代码、运行测试、登录远程服务器、发布到第三方服务等。GitHub 把这些操作就称为 actions。\n很多操作在不同项目里面是类似的，可以共享。GitHub 允许开发者把每个操作写成独立的脚本文件，存放到代码仓库，使得其他开发者可以引用。\n可在官方市场与 awesome actions 找 action。\nworkflow 文件 GitHub Actions 的配置文件叫做 workflow 文件，存放在代码仓库的 .github/workflows 目录。\nworkflow 文件采用 YAML 格式，一个库可以有多个 workflow 文件。GitHub 发现 .github/workflows 目录里有 .yml 文件，就会自动运行该文件。\n配置字段：\n  name：工作流程的名称。如果省略 name，GitHub 将其设置为相对于仓库根目录的工作流程文件路径\n  on：必要，触发工作流程的 GitHub 事件的名称\non: [push, pull_request]   on.\u0026lt;push|pull_request\u0026gt;.\u0026lt;branches|tags\u0026gt;：您可以将工作流配置为在特定分支或标记上运行\non: push: branches: - main - \u0026#39;mona/octocat\u0026#39; - \u0026#39;releases/**\u0026#39; tags: - v1 - v1.*    jobs：工作流程运行包括一项或多项作业。每项作业必须关联一个 ID\n  jobs.\u0026lt;job_id\u0026gt;.name：job_id 里面的 name 字段是任务的说明\njobs: my_first_job: name: My first job my_second_job: name: My second job   jobs.\u0026lt;job_id\u0026gt;.needs：作业默认是并行运行。needs字段指定当前任务的运行顺序\njobs: job1: job2: needs: job1 job3: needs: [job1, job2] 此例中作业执行顺序：job1、job2、job3\n  jobs.\u0026lt;job_id\u0026gt;.runs-on：必需，运行作业的机器类型\nruns-on: ubuntu-latest     jobs.\u0026lt;job_id\u0026gt;.steps：作业包含一系列任务，称为 steps\n  jobs.\u0026lt;job_id\u0026gt;.steps.name：步骤名称\n  jobs.\u0026lt;job_id\u0026gt;.steps.uses：引用的 Actions\nsteps: # Reference a specific commit - uses: actions/setup-node@74bc508 # Reference a minor version of a release - uses: actions/setup-node@v1.2 # Reference a branch - uses: actions/setup-node@main   jobs.\u0026lt;job_id\u0026gt;.steps.run：使用操作系统 shell 运行命令行程序\n- name: Clean install dependencies and build run: |npm ci npm run build     参考 GitHub Actions 入门教程\nGitHub Actions\n持续集成（Continuous integration，简称CI） 概念 持续集成指的是，频繁地（一天多次）将代码合并（集成）到主干源码仓库。在 CI 中可以通过自动化等手段高频率地去获取产品反馈并响应反馈的过程。\n流程  提交：开发者向代码仓库提交代码 测试（第一轮）：代码仓库对提交的代码跑自动化测试  单元测试：针对函数或模块的测试 集成测试：针对整体产品的某个功能的测试，又称功能测试 端对端测试：从用户界面直达数据库的全链路测试   构建：将源码转换为可以运行的实际代码，会安装依赖，配置各种资源等。常用的构建工具如下  Jenkins：开源 Travis Codeship Strider：开源   测试（第二轮）：第二轮是全面测试 部署：直接部署 回滚：当前版本发生问题，回滚到上一个版本的构建结果  Commit message 社区有多种 Commit Message Conventions。本文介绍 Angular 规范。\n格式化的 Commit message 好处   提供更多的历史信息，方便浏览\ngit log HEAD --pretty=format:%s   可以过滤某些 commit，便于查找信息\ngit log HEAD --grep feature   可以直接从 commit 生成 Change Log\n  Commit message 的格式 \u0026lt;type\u0026gt;(\u0026lt;scope\u0026gt;): \u0026lt;subject\u0026gt; // 空一行 \u0026lt;body\u0026gt; // 空一行 \u0026lt;footer\u0026gt;   Header 只有一行\n type 用于说明 commit 的类别  feat：新功能 fix：修补bug docs：文档 style： 格式 refactor：重构 test：增加测试 chore：构建过程或辅助工具的变动 Revert：当前 commit 用于撤销以前的 commit   scope 用于说明 commit 影响的范围 subject 是 commit 目的的简短描述  以动词开头，使用第一人称现在时 第一个字母小写 结尾不加句号      Body 部分是对本次 commit 的详细描述\n  Footer\n  不兼容变动：如果当前代码与上一个版本不兼容，则以 BREAKING CHANGE 开头，后面是对变动的描述、以及变动理由和迁移方法\n  关闭 Issue：如果当前 commit 针对某个issue，那么可以在 Footer 部分关闭这个 issue\nCloses #123, #245, #992     Commitizen Commitizen 是一个撰写 Commit message 的工具\n  Install the Commitizen cli tools\nnpm install commitizen -g   Initialize your project to use the cz-conventional-changelog adapter\ncommitizen init cz-conventional-changelog --save-dev --save-exact   以后，凡是用到 git commit 命令，一律改为使用 git cz。\n  参考 Commit message 和 Change log 编写指南\nYAML（YAML Ain\u0026rsquo;t a Markup Language） YAML 是专门用来写配置文件的语言\n简介 规则：\n 大小写敏感 使用缩进表示层级关系 缩进时不允许使用 Tab 键，只允许使用空格。 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可 # 表示注释，从这个字符一直到行尾，都会被解析器忽略 对象和数组可以结合使用，形成复合结构  对象 一组键值对\nanimal: pets 行内表示法\nhash: { name: Steve, foo: bar }  数组 一组连词线开头的行\n- Cat - Dog - Goldfish 数据结构的子成员是一个数组，则可以在该项下面缩进一个空格\n- - Cat - Dog - Goldfish 行内表示法\nanimal: [Cat, Dog] 纯量   字符串：字符串默认不使用引号表示\nstr: 这是一行字符串 包含空格或特殊字符，需要放在引号之中，单引号和双引号都可以使用，双引号不会对特殊字符转义\nstr: \u0026#39;内容： 字符串\u0026#39; 单引号之中如果还有单引号，必须连续使用两个单引号转义\nstr: \u0026#39;labor\u0026#39;\u0026#39;s day\u0026#39; 字符串可以写成多行，从第二行开始，必须有一个单空格缩进。换行符会被转为空格\nstr: 这是一段 多行 字符串 多行字符串可以使用|保留换行符，也可以使用\u0026gt;折叠换行\nthis: |Foo Bar that: \u0026gt;Foo Bar +表示保留文字块末尾的换行，-表示删除字符串末尾的换行\ns1: | Foo s2: |+ Foo s3: |- Foo 字符串之中可以插入 HTML 标记\nmessage: | \u0026lt;p style=\u0026#34;color: red\u0026#34;\u0026gt; 段落 \u0026lt;/p\u0026gt;   参考 YAML 语言教程\nThe Official YAML Web Site\n开源许可证 一般情况下，软件的源代码只由编写者拥有，而开源（即开放源代码，Open Source Code）是指一种更自由的软件发布模式。简单来说，开源软件的特点就是把软件程序和源代码文件一起打包提供给用户，让用户在不受限制地使用某个软件功能的基础上还可以对代码按需修改，让软件更贴合硬件环境，让功能更符合工作需求。用户还可以将其编制成衍生产品再发布出去。用户一般享有使用自由、复制自由、修改自由、创建衍生品自由，以及收费自由。是的，您没有看错，用户具备创建衍生品和收费的自由。这也就是说，可以对一个开源软件进行深度定制化加工。如果修改过的程序更加好用，或者颇具新的特色，只要符合原作者的许可要求，我们就完全可以合法地将软件进行商标注册，以商业版的形式再发布出去，只要有新用户使用您的软件并支付相应的费用，那就是您的收入。这也正好符合了黑客和极客对自由的追求，因此在合作与竞争中，国内外的开源社区慢慢生长出了强健的根基，人气也非常高。\n但是，如果开源软件只单纯追求“自由”而牺牲了程序员的利益，这肯定会影响程序员的创作热情。为了平衡两者的关系，截至目前，世界上已经有100多种被开源促进组织（OSI，Open Source Initiative）确认的开源许可证，用于保护开源工作者的权益。对于那些只知道一味抄袭、篡改、破解或者盗版他人作品的不法之徒，终归会在某一天收到法院的传票。\n考虑到大家没准儿以后会以开源工作者的身份编写出一款畅销软件，因此刘遄老师根据开源促进组织的推荐建议以及实际使用情况，为大家筛选出了程序员最喜欢的前6名的开源许可证，并教大家怎么从中进行选择。提前了解最热门的开源许可证，并在未来选择一个合适的可最大程度地保护自己软件权益的开源许可证，这对创业公司来讲能起到事半功倍的作用。\n开源许可证总览：https://opensource.org/licenses/alphabetical\nTips：上述提到的“开源许可证”与“开源许可协议”的含义完全相同，只不过是英文翻译后两种不同的叫法，这里不作区别。\nTips：自由软件基金会（Free Software Foundation，FSF）是一个非营利组织，其使命是在全球范围内促进计算机用户的自由，捍卫所有软件用户的权利。\n大家经常会在开源社区中看到Copyleft这个单词，这是一个由自由软件运动所发展出的概念，中文被翻译为“著佐权”或者“公共版权”。与Copyright截然相反，Copyleft不会限制使用者复制、修改或再发布软件。\n此外，大家应该经常会听到别人说开源软件是free的，没错，开源软件就是自由的。这里的free千万不要翻译成“免费”，这样就大错特错了，这与您去酒吧看到的“第一杯免费”的意思可相差甚远。\n下面我们来看一下程序员最喜欢的前6名的开源许可证，以及它们各自赋予用户的权利。\nGPL **GNU通用公共许可证（**General Public License，GPL）：目前广泛使用的开源软件许可协议之一，用户享有运行、学习、共享和修改软件的自由。GPL最初是自由软件基金会创始人Richard Stallman起草的，其版本目前已经发展到了第3版。GPL的目的是保证程序员在开源社区中所做的工作对整个世界是有益的，所开发的软件也是自由的，并极力避免开源软件被私有化以及被无良软件公司所剥削。\n现在，只要软件中包含了遵循GPL许可证的产品或代码，该软件就必须开源、免费，因此这个许可证并不适合商业收费软件。遵循该许可证的开源软件数量极其庞大，包括Linux内核在内的大多数的开源软件都是基于GPL许可证的。GPL赋予了用户著名的五大自由。\n **使用自由：**允许用户根据需要自由使用这个软件。\n**复制自由：**允许把软件复制到任何人的计算机中，并且不限制复制的数量。\n**修改自由：**允许开发人员增加或删除软件的功能，但软件修改后必须依然基于GPL许可证。\n**衍生自由：**允许用户深度定制化软件后，为软件注册自己的新商标，再发行衍生品的自由。\n**收费自由：**允许在各种媒介上出售该软件，但必须提前让买家知道这个软件是可以免费获得的。因此，一般来讲，开源软件都是通过为用户提供有偿服务的形式来营利的。\n LGPL 较宽松通用公共许可证（Lesser GPL, LGPL）：一个主要为保护类库权益而设计的GPL开源协议。与标准GPL许可证相比，LGPL允许商业软件以类库引用的方式使用开源代码，而不用将其产品整体开源，因此普遍被商业软件用来引用类库代码。简单来说，就是针对使用了基于LGPL许可证的开源代码，在涉及这部分代码，以及修改过或者衍生出来的代码时，都必须继续采用LGPL协议，除此以外的其他代码则不强制要求。\n如果您觉得LGPL许可证更多地是关注对类库文件的保护，而不是软件整体，那就对了。因为该许可证最早的名字是Library GPL，即GPL类库开源许可证，保护的对象有glibc、GTK widget toolkit等类库文件。\nBSD **伯克利软件发布版（**Berkeley Software Distribution, BSD）许可证：另一款被广泛使用的开源软件许可协议。相较于GPL许可证，BSD更加宽松，适合于商业用途。用户可以使用、修改和重新发布遵循该许可证的软件，并且可以将软件作为商业软件发布和销售，前提是需要满足下面3个条件。\n 如果再发布的软件中包含开源代码，则源代码必须继续遵循BSD许可证。\n如果再发布的软件中只有二进制程序，则需要在相关文档或版权文件中声明原始代码遵循了BSD许可证。\n不允许用原始软件的名字、作者名字或机构名称进行市场推广。\n Apache Apache许可证（Apache License）：顾名思义，是由Apache软件基金会负责发布和维护的开源许可协议。作为当今世界上最大的开源基金会，Apache不仅因此协议而出名，还因市场占有率第一的Web服务器软件而享誉行业。目前使用最广泛的Apache许可证是2004年发行的2.0版本，它在为开发人员提供版权及专利许可的同时，还允许用户拥有修改代码及再发布的自由。该许可证非常适合用于商业软件，现在热门的Hadoop、Apache HTTP Server、MongoDB等项目都是基于该许可证研发的。程序开发人员在开发遵循该许可证的软件时，要严格遵守下面4个条件。\n 该软件及其衍生品必须继续使用Apache许可证。\n如果修改了程序源代码，需要在文档中进行声明。\n若软件是基于他人的源代码编写而成的，则需要保留原始代码的许可证、商标、专利声明及原作者声明的其他内容信息。\n如果再发布的软件中有声明文件，则需在此文件中注明基于了Apache许可证及其他许可证。\n MIT MIT许可证（Massachusetts Institute of Technology License）：源于麻省理工学院，又称为X11协议。MIT许可证是目前限制最少的开源许可证之一，用户可以使用、复制、修改、再发布软件，而且只要在修改后的软件源代码中保留原作者的许可信息即可，因此普遍被商业软件（例如jQuery与Node.js）所使用。也就是说，MIT许可证宽松到一个新境界，即用户只要在代码中声明了MIT许可证和版权信息，就可以去做任何事情，而无须承担任何责任。\nMPL **Mozilla公共许可证（**Mozilla Public License，MPL）：于1998年初由Netscape公司的Mozilla小组设计，原因是它们认为GPL和BSD许可证不能很好地解决开发人员对源代码的需求和收益之间的平衡关系，因此便将这两个协议进行融合，形成了MPL。2012年年初，Mozilla基金会发布了MPL 2.0版本（目前为止也是最新的版本），后续被用在Firefox、Thunderbird等诸多产品上。最新版的MPL公共许可证有以下特点。\n 在使用基于MPL许可证的源代码时，后续只需要继续开源这部分特定代码即可，新研发的软件不用完全被该许可证控制。\n开发人员可以将基于MPL、GPL、BSD等多种许可证的代码一起混合使用。\n开发人员在发布新软件时，必须附带一个专门用于说明该程序的文件，内容要有原始代码的修改时间和修改方式。\n 总结 估计大家在看完上面琳琅满目的许可证后，会心生怨念：“这不都差不多吗？到底该选哪个呢？”写到这里时，刘遄老师也是一脸无助：“到底该怎么让大家进行选择呢？”搜肠刮肚之际突然眼前一亮，乌克兰程序员Paul Bagwell创作的一幅流程图正好对刚才讲过的这6款开源许可证进行了汇总归纳，具体如下图所示。\n开源许可证的选择流程图\n众所周知，绝大部分的开源软件在安装完毕之后即可使用，很难在软件界面中找到相关的收费信息。所以经常会有同学提问：“刘老师，开源社区的程序员总要吃饭的呀，他们是靠什么营利呢？”针对这个问题，网络上好像只有两种声音：\n **情怀——**开源社区的程序员觉悟好，本领强，写代码纯粹是为了兴趣以及造福社会；\n**服务——**先让用户把软件安装上，等用好、用习惯之后，再通过提供一些维护服务来营利。\n 这两种解释都各有道理，但是不够全面。读者也不要把开源软件和商业软件完全对立起来，因为好的项目也需要好的运营模式。就开源软件来讲，营利模式具体包括以下5种。\n 多条产品线：如MySQL数据库便有个人版和企业版两个版本，即个人版完全免费，起到了很好的推广作用；企业版则通过销售授权许可来营利。\n技术服务型：JBoss应用服务器便是典型代表，JBoss软件可自由免费使用，软件提供方通过技术文档、培训课程以及定制开发服务来盈利。\n软硬件结合：比如IBM公司在出售服务器时，一般会为用户捆绑销售AIX或Linux系统来确保硬件设施的营利。\n技术出版物：比如O\u0026rsquo;Reilly既是一家开源公司，也是一家出版商，诸多优秀图书都是由O\u0026rsquo;Reilly出版的。\n品牌和口碑：微软公司曾多次表示支持开源社区。大家对此可能会感到意外，但这是真的！Visual Studio Code、PowerShell、TypeScript等软件均已开源。大家是不是瞬间就对微软公司好感倍增了呢？买一份正版系统表示支持也就是人之常情了。\n SSH 原理与运用 数字签名与数字证书 鲍勃有两把钥匙，一把是公钥，另一把是私钥。\n鲍勃把公钥送给他的朋友们——帕蒂、道格、苏珊——每人一把。\n苏珊要给鲍勃写一封保密的信。她写完后用鲍勃的公钥加密，就可以达到保密的效果。\n鲍勃收信后，用私钥解密，就看到了信件内容。只要鲍勃的私钥不泄露，这封信就是安全的，即使落在别人手里，也无法解密。\n鲍勃给苏珊回信，决定采用\u0026quot;数字签名\u0026quot;。他写完后先用Hash函数，生成信件的摘要（digest）。\n然后，鲍勃使用私钥，对这个摘要加密，生成\u0026quot;数字签名\u0026quot;（signature）。\n鲍勃将这个签名，附在信件下面，一起发给苏珊。\n苏珊收信后，取下数字签名，用鲍勃的公钥解密，得到信件的摘要。由此证明，这封信确实是鲍勃发出的。\n苏珊再对信件本身使用Hash函数，将得到的结果，与上一步得到的摘要进行对比。如果两者一致，就证明这封信未被修改过。\n复杂的情况出现了。道格想欺骗苏珊，他偷偷使用了苏珊的电脑，用自己的公钥换走了鲍勃的公钥。此时，苏珊实际拥有的是道格的公钥，但是还以为这是鲍勃的公钥。因此，道格就可以冒充鲍勃，用自己的私钥做成\u0026quot;数字签名\u0026quot;，写信给苏珊，让苏珊用假的鲍勃公钥进行解密。\n后来，苏珊感觉不对劲，发现自己无法确定公钥是否真的属于鲍勃。她想到了一个办法，要求鲍勃去找\u0026quot;证书中心\u0026quot;（certificate authority，简称CA），为公钥做认证。证书中心用自己的私钥，对鲍勃的公钥和一些相关信息一起加密，生成\u0026quot;数字证书\u0026quot;（Digital Certificate）。\n鲍勃拿到数字证书以后，就可以放心了。以后再给苏珊写信，只要在签名的同时，再附上数字证书就行了。\n苏珊收信后，用CA的公钥解开数字证书，就可以拿到鲍勃真实的公钥了，然后就能证明\u0026quot;数字签名\u0026quot;是否真的是鲍勃签的。\n远程登录   1995年，芬兰学者 Tatu Ylonen 设计了 SSH 协议，用于计算机之间的加密登录。本文针对的实现是 OpenSSH。\n  基本用法：\n  假定你要以用户名 user，登录远程主机 host\nssh user@host   如果本地用户名与远程用户名一致，登录时可以省略用户名\nssh host   SSH 的默认端口是 22，使用 p 参数修这个端口\nssh -p 2222 user@host     中间人攻击（Man-in-the-middle attack）\n  SSH 加密登录过程\n 远程主机收到用户的登录请求，把自己的公钥发给用户。 用户使用这个公钥，将登录密码加密后，发送给远程主机。 远程主机用自己的私钥，解密登录密码，如果密码正确，就同意用户登录。      中间人攻击：攻击者插在用户与远程主机之间，用伪造的公钥，获取用户的登录密码，再用这个密码登录远程主机。\n  口令登录：第一次登录远程主机时，会询问是否接受远程主机公钥（是否继续连接），并显示公钥指纹——公钥长度较长（这里采用RSA算法，长达 1024 位），很难比对，所以对其进行MD5计算，将它变成一个 128 位的指纹。用户通过比对远程网站上贴出的公钥指纹，决定是否接受这个远程主机的公钥。当远程主机的公钥被接受以后，它就会被保存在文件 $HOME/.ssh/known_hosts 之中。\n  公钥登录：省去口令登录每次都必须输入密码的步骤。用户将自己的公钥储存在远程主机上，登录的时候，远程主机会向用户发送一段随机字符串，用户用自己的私钥加密后，再发回来，远程主机用事先储存的公钥进行解密，如果成功，就证明用户是可信的，直接允许登录shell，不再要求密码。\n  ssh-keygen\n在 $HOME/.ssh/ 目录下生成两个文件：公钥 id_rsa.pub 和私钥 id_rsa。\n    远程操作与端口转发   SSH 可以在用户和远程主机之间，建立命令和数据的传输通道\n  绑定本地端口：让那些不加密的网络连接，全部改走 SSH 连接\nssh -D 8080 user@host 建立一个 socket，去监听本地的 8080 端口。一旦有数据传向那个端口，就自动把它转移到 SSH 连接上面，发往远程主机。\n  本地端口转发：假定 host1 是本地主机，host2 是远程主机。由于种种原因，这两台主机之间无法连通。但是，另外还有一台 host3，可以同时连通前面两台主机。因此，很自然的想法就是，通过 host3，将 host1 连上 host2。\nssh -L 2121:host2:21 host3 L 参数接受三个值——\u0026ldquo;本地端口:目标主机:目标主机端口\u0026rdquo;。SSH 绑定本地端口 2121，指定 host3 将所有的数据转发到目标主机 host2 的 21 端口。本地端口转发使得 host1 和 host3 之间仿佛形成一个数据传输的秘密隧道，因此又被称为\u0026quot;SSH 隧道\u0026quot;。\n  远程端口转发：host1 与 host2 之间无法连通，必须借助 host3 转发，而 host3 是一台内网机器，它可以连接外网的 host1，但是反过来就不行。解决办法是从 host3 上建立与 host1 的 SSH 连接，然后在 host1 上使用这条连接。在 host3 执行下面的命令\nssh -R 2121:host2:21 host1 R 参数也是接受三个值——\u0026ldquo;远程主机端口:目标主机:目标主机端口\u0026rdquo;。它让 host1 监听它自己的 2121 端口，然后将所有数据经由 host3，转发到 host2 的 21 端口。\n  GitHub Packages Learn to safely publish and consume packages, store your packages alongside your code, and share your packages privately with your team or publicly with the open source community. You can also automate your packages with GitHub Actions.\nTip \u0026amp; Questions Repository size limits for GitHub.com Hard limits:\n Individual files in a repository are strictly limited to a 100 MB maximum size limit. Repositories have a hard size limit of 100GB.  ","permalink":"https://example.com/posts/git/","summary":"Workspace：工作区，Index / Stage：暂存区，Repository：仓库区（或本地仓库），Remote：远程仓库 远程仓库 安装，","title":"Git"},{"content":"Fedora [fəˈdɔrə] 费多拉\nFedora 定制版 为什么 Linus Torvalds 用 Fedora  2008：linus对发行版的要求是\u0026quot;易安装，比较贴近上游\u0026quot;即可。 2010年的时候，他指出了Fedora 14的一个bug。 2011年Fedora 15换Gnome3作为默认DE了，Linus直言\u0026quot;unholy mess\u0026quot; ，然后转投XFCE。 2011年末，Linus提出并修补了openSUSE中Xorg的一个严重bug。 2013年5月：Linus尝试将自己手头的MacBook Air装上Linux，把几个大的发行版全部都试了一遍。发现只有Fedora能正常工作。 之后的所有消息就是各种fedora了  SELinux 长久以来，每当遇到授权问题或者新安装的主机，我的第一反应是通过setenforce 0命令禁用SELinux，来减少产生的权限问题，但是这并不是一个良好的习惯。这篇文章尝试对SELinux的基本概念和用法进行简单介绍，并且提供一些更深入的资料。\nLinux下默认的接入控制是DAC，其特点是资源的拥有者可以对他进行任何操作（读、写、执行）。当一个进程准备操作资源时，Linux内核会比较进程和资源的UID和GID，如果权限允许，就可以进行相应的操作。此种方式往往会带来一些问题，如果一个进程是以root的身份运行，也就意味着他能够对系统的任何资源进行操作，而且不被限制。 假如我们的软件存在漏洞呢？这个往往是一个灾难性的问题。因此，就引出了另外的一种安全接入控制机制MAC，Linux下的一种现实是SELinux，也就是我们将要讨论的内容。\n基本概念 Mandatory Access Control (MAC) SELinux 属于MAC的具体实现，增强了Linux系统的安全性。MAC机制的特点在于，资源的拥有者，并不能决定谁可以接入到资源。具体决定是否可以接入到资源，是基于安全策略。而安全策略则是有一系列的接入规则组成，并仅有特定权限的用户有权限操作安全策略。\n一个简单的例子，则是一个程序如果要写入某个目录下的文件，在写入之前，一个特定的系统代码，将会依据进程的Context和资源的Context查询安全策略，并且根据安全策略决定是否允许写入文件。\nFlask Security Architecture SELinux的软件设计架构是参照Flask，Flask是一种灵活的操作系统安全架构，并且在Fluke research operating system中得到了实现。Flask的主要特点是把安全策略执行代码和安全策略决策代码，划分成了两个组件。安全策略决策代码在Flask架构中称作Security Server。除了这两个组件以外，另外一个组件Vector Cache(AVC), 主要提供策略决策结果的缓存，以此提高Security Server的性能。其具体执行流程为，安全策略执行代码通过AVC查询Security Server的安全策略决策结果，并将其缓存以备下次使用。\nLinux Security Module 前面两部分介绍了MAC机制和Flask架构，最终SELinux的实现是依赖于Linux提供的Linux Security Module框架简称为LSM。其实LSM的名字并不是特别准确，因为他并不是Linux模块，而是一些列的hook，同样也不提供任何的安全机制。LSM的的重要目标是提供对linux接入控制模块的支持。\nLSM 在内核数据结构中增加了安全字段，并且在重要的内核代码（系统调用）中增加了hook。可以在hook中注册回调函数对安全字段进行管理，以及执行接入控制。\nSELinux Security Enhanced Linux(SELinux) 为Linux 提供了一种增强的安全机制，其本质就是回答了一个“Subject是否可以对Object做Action?”的问题，例如 Web服务可以写入到用户目录下面的文件吗？其中Web服务就是Subject而文件就是Object，写入对应的就是Action。\n依照上面的例子，我们引入了几个概念，分别是Subject、Object、Action、以及例子没有体现出来的Context：\n Subject: 在SELinux里指的就是进程，也就是操作的主体。 Object： 操作的目标对象，例如 文件 Action： 对Object做的动作，例如 读取、写入或者执行等等 Context： Subject和Object都有属于自己的Context，也可以称作为Label。Context有几个部分组成，分别是SELinux User、SELinux Role、SELinux Type、SELinux Level。  用户程序执行的系统调用（例如读取文件），都要被SELinux依据安全策略进行检查。如果安全策略允许操作，则继续，否则将会抛出错误信息给应用程序。SELinux决策的同时还需要Subject和Object的Context信息，确定所属的User、Role和Type等信息，以此查询对应的安全策略进行决策。SELinux同样也使用了AVC机制用于缓存决策结果，以此来提高性能。\nSELinux Context 进程和文件都有属于自己的Context信息，Context分为几个部分，分别是 SELinux User、Role、Type 和一个可选的Level信息。SELinux在运行过程中将使用这些信息查询安全策略进行决策。\n SELinux User：每一个Linux用户都会映射到SELinux用户，每一个SELinux User都会对应相应的Role。 SELinux Role：每个Role也对应几种SELinux Type，并且充当了User和Type的‘中间人’ SELinux Type：安全策略使用SELinux Type制定规则，定义何种Domian（Type）的Subject，可以接入何种Type的Object。  显示进程的Context\n# ps -Z LABEL PID TTY TIME CMD unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 9509 pts/1 00:00:00 sudo unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 9515 pts/1 00:00:00 su unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 9516 pts/1 00:00:00 bash unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 9544 pts/1 00:00:00 ps 显示文件的Context信息\n# ls -Z system_u:object_r:admin_home_t:s0 anaconda-ks.cfg 临时修改文件的 SELinux Type\n# chcon -t httpd_sys_content_t file-name 恢复Context信息\n# restorecon [选项] \u0026lt;文件或目录 1\u0026gt; [\u0026lt;文件或目录 2\u0026gt;...]    选项 功能     -v 打印操作过程   -R 递归操作    添加目录的默认安全上下文\n如果提示找不到命令的话请安装 policycoreutils-python 软件包\n# semanage fcontext -a -t \u0026lt;文件安全上下文中的类型字段\u0026gt; \u0026#34;\u0026lt;目录（后面不加斜杠）\u0026gt;(/.*)?\u0026#34; 注：目录或文件的默认安全上下文可以通过 semanage fcontext -l 命令配合 grep 过滤查看。\n为 Nginx 新增一个网站目录 /usr/share/nginx/html2 之后，需要为其设置与原目录相同的默认安全上下文。\n# semanage fcontext -a -t httpd_sys_content_t \u0026#34;/usr/share/nginx/html2(/.*)?\u0026#34; 添加某类进程允许访问的端口\n# semanage port -a -t \u0026lt;服务类型\u0026gt; -p \u0026lt;协议\u0026gt; \u0026lt;端口号\u0026gt; 注：各种服务类型所允许的端口号可以通过 semanage port -l 命令配合 grep 过滤查看。\n为 Nginx 需要使用 10080 的端口用于 HTTP 服务。\nsemanage port -a -t http_port_t -p tcp 10080 SELinux 的运行状态 SELinux 有三个运行状态，分别是disabled, permissive 和 enforcing\n Disable： 禁用SELinux，不会给任何新资源打Label，如果重新启用的话，将会给资源重新打上Lable，过程会比较缓慢。 Permissive：如果违反安全策略，并不会真正的执行拒绝操作，替代的方式是记录一条log信息。 Enforcing: 默认模式，SELinux的正常状态，会实际禁用违反策略的操作  查看当前的运行状态\n# getenforceEnforcing 临时改变运行状态为Permissive\n# setenforce 0# getenforcePermissive 临时改变运行状态为 Enforcing\n# setenforce 1# getenforceEnforcing 使用sestatus可以查看完整的状态信息\n# sestatusSELinux status: enabledSELinuxfs mount: /sys/fs/selinuxSELinux root directory: /etc/selinuxLoaded policy name: targetedCurrent mode: enforcingMode from config file: enforcingPolicy MLS status: enabledPolicy deny_unknown status: allowedMax kernel policy version: 30 怎么启用SELinux 如果您的环境中禁用了 SELinux，则可以通过编辑 /etc/selinux/config 并设置 SELINUX=permissive 来启用 SElinux。由于 SELinux 当前尚未启用，因此最好不要将其设为立即强制执行，因为此时系统可能会出现误标记的事件，它会妨碍系统的正常启动。\n您可以在根目录中创建名为 .autorelabel 的空文件，然后重新启动，以此来强制系统自动为整个文件系统重新标记SELinux。如果系统中错误过多，应在允许模式下重新启动，以确保启动成功。重新标记所有内容后，利用 /etc/selinux/config 将 SELinux 设置为强制模式并重新启动，或运行 setenforce 1。\n如果系统管理员不太熟悉命令行，还可以选择用于管理 SELinux 的图形工具。\n针对 Linux 发行版中内置的系统，SELinux 提供了一道额外的防护层。保持开启 SELinux，就能在系统遭到破坏时保护您的系统。\nSELinux Log SELinux 的Log日志默认记录在/var/log/audit/audit.log\n# cat /var/log/audit/audit.logtype=AVC msg=audit(1223024155.684:49): avc: denied { getattr } for pid=2000 comm=\u0026#34;httpd\u0026#34; path=\u0026#34;/var/www/html/file1\u0026#34; dev=dm-0 ino=399185 scontext=unconfined_u:system_r:httpd_t:s0 tcontext=system_u:object_r:samba_share_t:s0 tclass=file /var/log/message 也会记录相应的信息，例如：\nMay 7 18:55:56 localhost setroubleshoot: SELinux is preventing httpd (httpd_t) \u0026#34;getattr\u0026#34; to /var/www/html/file1 (samba_share_t). For complete SELinux messages. run sealert -l de7e30d6-5488-466d-a606-92c9f40d316d SELinux 配置文件 SELinux的配置文件位于/etc/selinux/config。默认配置文件主要两部分，一个是SELinux的运行状态和SELinuxType。直接在配置文件中修改SELinux将会在下次启动时生效。\n# This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX=enforcing # SELINUXTYPE= can take one of these two values: # targeted - Targeted processes are protected, # mls - Multi Level Security protection. SELINUXTYPE=targeted SELinux Booleans Booleans允许在运行时修改SELinux安全策略。\n列出所有的Booleans选项\n# semanage boolean -l SELinux boolean State Default Description smartmon_3ware (off , off) Determine whether smartmon can... mpd_enable_homedirs (off , off) Determine whether mpd can traverse... 您可以通过运行 getsebool -a，找出系统中已设置的布尔值。\n临时修改httpd_can_network_connect_db状态为开启\n# setsebool [选项] \u0026lt;规则名称\u0026gt; \u0026lt;on|off\u0026gt; # setsebool httpd_can_network_connect_db on    选项 功能     -P 重启依然生效    Tips\u0026amp;Questions flatpak Cannot install apps. - Error: Failed to read commit it works for me:\nsudo flatpak repair Cannot open acess to console, the root account is locked\u0026hellip; 先是添加一个 LV 到 /etc/fstab，结果开机报错，原因是写错了：\nTime out ...Dependency failed for ... 结束后就 Cannot open acess to console, the root account is locked，什么也干不了，只能强制关机。\n解决方案是重启进入 Fedora Live CD，挂载 root，修改 /etc/fstab。但是无法挂载，挂载的是 Fedora Live CD 的 root，我 TM 佛了，原因应该是这两个名一模一样，Live CD 覆盖了 root。最后是用 Ubntu Live CD 解决。\n这告诉我们，不要只有一个 Live CD。这还告诉我们，先找自己的原因才能有耐心去解决问题。\ndmesg-x86/cpu: SGX disabled by BIOS SGX技术的分析和研究\nsnd_hda_codec_hdmi hdaudioC0D2: Monitor plugged-in, Failed to power up codec ret=[-13] set Kernel parameters，要使改变在重启后仍生效，您可以手动编辑 /boot/grub/grub.cfg。对于初学者，建议编辑 /etc/default/grub 并将您的内核选项添加至 GRUB_CMDLINE_LINUX_DEFAULT 行：\nGRUB_CMDLINE_LINUX_DEFAULT=\u0026quot;snd_hda_codec_hdmi.enable_silent_stream=0\u0026quot; 然后重新生成 grub.cfg 文件：\n# grub2grub-mkconfig2 -o /boot/grub2/grub.cfg Speed Up DNF 尝试更改参数\n$ sudo vi /etc/dnf/dnf.conf fastestmirror=true max_parallel_downloads=10 metadata_expire=2d  fastermirror 选择最快的镜像 max_parallel_downloads 一次下载多个包  尝试更换为清华源。\n如果在更新过程中某个小包下载不了，导致无法更新，尝试只使用 ipv4\n$ sudo dnf update -4 -v -y CentOS Red Hat Enterprise Linux Developer Subscription Need to log in to download RHEL.\n怎样使用 Red Hat Subscription Manager (RHSM) 将系统注册到红帽客户门户网站？\n# subscription-manager register --username \u0026lt;username\u0026gt; --password \u0026lt;password\u0026gt; --auto-attach 配置 Red Hat Enterprise Linux 8 中基本系统设置的指南\nFrey\u0026rsquo;s Blog\n 所有文章 分类   关于多线程 概述 每个正在系统上运行的程序都是一个进程。每个进程包含一到N个线程。进程也可能是整个程序或者是部分程序的动态执行。线程是一组指令的集合，或者是程序的特殊段，它可以在程序里独立执行。也可以把它理解为代码运行的上下文。所以线程基本上是轻量级的进程，它负责在单个程序里执行多任务。通常由操作系统负责多个线程的调度和执行。线程是程序中一个单一的顺序控制流程。在单个程序中同时运行多个线程完成不同的工作,称为多线程。\n线程和进程的区别在于,子进程和父进程有不同的代码和数据空间,而多个线程则共享数据空间,每个线程有自己的执行堆栈和程序计数器为其执行上下文.多线程主要是为了节约CPU时间,发挥利用,根据具体情况而定. 线程的运行中需要使用计算机的内存资源和CPU。\n同步多线程（SMT）是一种在一个CPU 的时钟周期内能够执行来自多个线程的指令的硬件多线程技术。本质上，同步多线程是一种将线程级并行处理（多CPU）转化为指令级并行处理（同一CPU）的方法。 同步多线程是单个物理处理器从多个硬件线程上下文同时分派指令的能力。同步多线程用于在商用环境中及为周期/指令（CPI）计数较高的工作负载创造性能优势。 处理器采用超标量结构，最适于以并行方式读取及运行指令。同步多线程使您可在同一处理器上同时调度两个应用程序，从而利用处理器的超标量结构性质。\n超线程（HT, Hyper-Threading）是英特尔研发的一种技术，于2002年发布。通过此技术，英特尔实现在一个实体CPU中，提供两个逻辑线程。\n其实可以将SMT和HT理解为一个技术。\n Hyper-threading (officially called Hyper- ThreadingTechnology or HT Technology, and abbreviated as HTT orHT) is Intel’s proprietary simultaneous multithreading (SMT) implementation used to improve parallelization ofcomputations (doing multiple tasks at once) performed onx86 microprocessors.\n来自 https://cn.bing.com/search?q=intel+ht\u0026amp;go=%E6%8F%90%E4%BA%A4\u0026amp;qs=ds\u0026amp;form=QBLHCN\n 与多进程的区别  “进程——资源分配的最小单位，线程——程序执行的最小单位”\n 实际应用中基本上都是“进程+线程”的结合方式，千万不要真的陷入一种非此即彼的误区。\n   对比维度 多进程 多线程 总结     数据共享、同步 数据共享复杂，需要用IPC；数据是分开的，同步简单 因为共享进程数据，数据共享简单，但也是因为这个原因导致同步复杂 各有优势   内存、CPU 占用内存多，切换复杂，CPU利用率低 占用内存少，切换简单，CPU利用率高 线程占优   创建销毁、切换 创建销毁、切换复杂，速度慢 创建销毁、切换简单，速度很快 线程占优   编程、调试 编程简单，调试简单 编程复杂，调试复杂 进程占优   可靠性 进程间不会互相影响 一个线程挂掉将导致整个进程挂掉 进程占优   分布式 适应于多核、多机分布式；如果一台机器不够，扩展到多台机器比较简单 适应于多核分布式 进程占优     需要注意：   1）需要频繁创建销毁的优先用线程\n2）需要进行大量计算的优先使用线程\n3）强相关的处理用线程，弱相关的处理用进程\n一般的Server需要完成如下任务：消息收发、消息处理。“消息收发”和“消息处理”就是弱相关的任务，而“消息处理”里面可能又分为“消息解码”、“业务处理”，这两个任务相对来说相关性就要强多了。因此“消息收发”和“消息处理”可以分进程设计，“消息解码”、“业务处理”可以分线程设计。当然这种划分方式不是一成不变的，也可以根据实际情况进行调整。\n4）可能要扩展到多机分布的用进程，多核分布的用线程\n5）都满足需求的情况下，用你最熟悉、最拿手的方式\n来自 https://blog.csdn.net/lishenglong666/article/details/8557215\n 如何使用？ 需要CPU、BIOS、操作系统、应用软件都支持多线程技术才可以。\n支持多线程的CPU Power CPU 支持的SMT技术：\n Simultaneous multithreading (SMT) is a processor technology that allows multiple instruction streams (threads) to run concurrently on the same physical processor, improving overall throughput. To the operating system, each hardware thread is treated as an independent logical processor. Single-threaded (ST) execution mode is also supported.\n来自 https://www.ibm.com/support/knowledgecenter/SSFHY8_6.2/reference/am5gr_f0106.html?view=embed\n Intel CPU 支持的HT技术：\n Intel® Hyper-Threading Technology (Intel® HT Technology) uses processor resources more efficiently, enabling multiple threads to run on each core. As a performance feature, it also increases processor throughput, improving overall performance on threaded software. Intel® HT Technology is available on the latest Intel® Core™ vPro™ processors, the Intel® Core™ processor family, the Intel® Core™ M processor family, and the Intel® Xeon® processor family. By combining one of these Intel® processors and chipsets with an operating system and BIOS supporting Intel® HT Technology.\n来自 https://www.intel.com/content/www/us/en/architecture-and-technology/hyper-threading/hyper-threading-technology.html\n SMT/HT支持情况  Intel CPU : 2 Thread/Core Power9 CPU： 8 Thread /Core Sparc: 8 Thread /Core  RHEL7/CentOS7 \u0026amp; Intel CPU BIOS 中修改SMT/HT 的设置，使用这种方式Enable或者Disable后，将永久生效，需要重启。\nHyper-Threading Technology BIOS Setup Options For Intel® Desktop/Server Boards setup option location is the main menu of the BIOS setup program. • Located on the same menu screen that already had Processor Type, Processor Speed, System Bus Speed, and other related processor fields. • Setup Option Text ○ The field is called Hyper-Threading Technology. • Setup Option Values ○ The setup option values are Enabled and Disabled. • Setup Option Help Text 来自 \u0026lt;https://www.intel.com/content/www/us/en/support/articles/000007645/boards-and-kits/desktop-boards.html\u0026gt; RHEL/CentOS操作系统中查看多线程情况：（更多信息：https://access.redhat.com/solutions/rhel-smt）\n# lscpu | grep -e Socket -e Core -e Thread Thread(s) per core: 2 # 线程数 Core(s) per socket: 6 # core 数量 Socket(s): 2 或者\n# grep -H . /sys/devices/system/cpu/cpu*/topology/thread_siblings_list | sort -n -t ':' -k 2 -u # 显示 /sys/devices/system/cpu/cpu0/topology/thread_siblings_list:0 # 表示HT关闭 # 显示 /sys/devices/system/cpu/cpu0/topology/thread_siblings_list:0-1 # 表示 HT 启用 操作系统层关闭多线程有几种办法：\n 方法一：使用nosmt启动参数，需要新的x86 CPU，需要重启  # grubby --args=nosmt --update-kernel=DEFAULT # grub2-mkconfig -o /boot/grub/grub.conf # 创建新的grub.conf # reboot #重启  方法二：临时关闭，重启后失效  # echo off \u0026gt; /sys/devices/system/cpu/smt/control /sys/devices/system/cpu/smt/control: This file allows to read out the SMT control state and provides the ability to disable or (re)enable SMT. The possible states are: ============== =================================================== on SMT is supported by the CPU and enabled. All logical CPUs can be onlined and offlined without restrictions. off SMT is supported by the CPU and disabled. Only the so called primary SMT threads can be onlined and offlined without restrictions. An attempt to online a non-primary sibling is rejected forceoff Same as 'off' but the state cannot be controlled. Attempts to write to the control file are rejected. notsupported The processor does not support SMT. It's therefore not affected by the SMT implications of L1TF. Attempts to write to the control file are rejected. ============== =================================================== The possible states which can be written into this file to control SMT state are: - on - off - forceoff /sys/devices/system/cpu/smt/active: This file reports whether SMT is enabled and active, i.e. if on any physical core two or more sibling threads are online. AIX \u0026amp; Power Power9 CPU默认支持8线程，使用smtctl命令可以查看和修改 smt级别。更多内容查看https://www.ibm.com/support/knowledgecenter/ssw_aix_72/com.ibm.aix.cmds5/smtctl.htm\n 查看 SMT level  smtctl  临时修改 SMT level, # 可以是 1, 2, 4 or 8，重启后将恢复原来的smt level  smtctl -t 2 -w now  修改 SMT level永久生效，# 可以是 1, 2, 4 or 8，完成后需要使用bosboot创建启动设备   smtctl -t 4 -w boot bosboot -a # Creates complete boot image and device. RHEL7 \u0026amp; Power OpenPower CPU 默认支持4线程，安装RHEL后可以使用开源的工具 ppc64_cpu进行查看和修改多线程（更多查看 https://github.com/ibm-power-utilities/powerpc-utils）。\nppc64_cpu --------- This allows users to set the smt state, smt-snooze-delay and other settings on ppc64 processors. It also allows users to control the number of processor cores which are online (not in the sleep state). 来自 \u0026lt;https://github.com/ibm-power-utilities/powerpc-utils\u0026gt; 1，查看 SMT level\nppc64_cpu --smt 2，修改 SMT 级别， # is 1, 2, 4 or on\nppc64_cpu --smt=# 3， 关闭 smt支持\nppc64_cpu --smt=off 其他 oracle数据库 Oracle Database 在12c之前windows平台下支持多线程，Unix和Linux只支持多进程模式。在Oracle Database 12c中，Oracle引入了多线程模式，允许在Windows平台之外的Unix、Linux系统使用多线程模式，结合多进程与多线程模式，Oracle可以改进进程管理与性能。\n通过设置初始化参数threaded_execution，可以启用或关闭多线程模式，该参数缺省值为False，设置为TRUE启用12c的这个新特性：\nSQL\u0026gt; show parameter threaded_exec NAME TYPE VALUE --- threaded_execution boolean FALSE SQL\u0026gt; alter system set threaded_execution=true scope=spfile; System altered. 该参数重新启动数据库后生效，但是注意，多线程模式，不支持操作系统认证，不能直接启动数据库，需要提供SYS的密码认证后方能启动数据库：\nSQL\u0026gt; shutdown immediate; SQL\u0026gt; startup ORA-01017: invalid username/password; logon denied # 需要通过用户名和密码登录数据库。 用ps -ef 检查一下进程/线程：\n[oracle@enmocoredb dbs]$ ps -ef|grep ora_ oracle 27404 1 0 17:00 ? 00:00:00 ora_pmon_core oracle 27406 1 0 17:00 ? 00:00:00 ora_psp0_core oracle 27408 1 3 17:00 ? 00:00:05 ora_vktm_core oracle 27412 1 0 17:00 ? 00:00:00 ora_u004_core oracle 27418 1 0 17:00 ? 00:00:00 ora_u005_core oracle 27424 1 0 17:00 ? 00:00:00 ora_dbw0_core 其中U\u0026lt;NNN\u0026gt;进程是共享线程的\u0026quot;容器进程\u0026quot;，每个进程可以容纳100个线程。 来自 https://www.eygle.com/archives/2013/07/oracle_database_12c_multithreaded_model.html 连接热点   打开WIFI\nifconfig interface up   查看所有可用的无线网络信号\niw wlp2s0 scan | grep SSID   连接无线网\nwpa_supplicant -B -i wlp2s0 -c \u0026lt;(wpa_passphrase \u0026#34;SSID\u0026#34; \u0026#34;passwd\u0026#34;)   分配IP地址\ndhclient interface   查看无线网卡地址信息，有ip地址表示网络连接成功\nifconfig interface   PPPOE （ADSL）拨号上网   安装拨号软件\ndnf install rp-pppoe* ppp*   设定\npppoe-setup   拨号上网\npppoe-stoppppoe-start   安装中文输入法   安装 fcitx\ndnf install fcitx-im fcitx-configtool fcitx-googlepinyin   配置\n$ nano ~/.xprofile # or ~/.bashrc export GTK_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=\u0026#34;@im=fcitx\u0026#34;   fcitx 没图标：重装fcitx，在fcitx配置里关掉Kimpanel\n  关闭触摸板 $ dnf install xorg-x11-apps synclient TouchpadOff=1\t# 关闭 synclient TouchpadOff=0\t# 开启 用 MTP 挂载手机   安装jmtpfs\ndnf install jmtpfs   查看手机 “busnum”和“devnum”\njmptfs -l   建立挂载点\nmkdir /media/dir   挂载手机\njmtpfs -device=busnum,devnum /media/dir/   查找依赖 $ yum whatprovide package $ dnf provides package 默认字体 CentOS 默认字体目录 /lib/kbd/consolefonts\n纯命令行是不能使用系统之外的字体的。\nCentOS Minimal + Xfce base 源与 epel 源，使用用阿里镜像: https://developer.aliyun.com/mirror/\n  安装Xfce4，先安装 Xfce 可以保证不安装多余的包\ndnf group listdnf groupinstall Xfce   安装 X Window system\ndnf groupinstall \u0026#34;X Window system\u0026#34;   验证\nsystemctl isolate graphical.target   设置\n# 设置成命令模式systemctl set-default multi-user.target\t# 设置成图形模式systemctl set-default graphical.target\t   安装中文字体和中文输入法楷体字体\ndnf install cjkuni-ukai-fonts   输入法需要安装如下包：\n ibus， 这个包里有ibus-daemon这个平台服务器程序和ibus这个配置助手。 ibus-libpinyin， 这个是ibus平台下具体的拼音输入法。 im-chooser,这个是输入法平台选择助手程序。 执行im-chooser，选择输入法平台和输入法。重新登录系统。    xfce 主题\n 网站：xfce-look.org 主题目录： /usr/share/themes 或 ~/.themes 图标鼠标目录： /usr/share/icons 或 ~/.icons 壁纸： /usr/share/background , /usr/share/wallpapers Plank    EPEL EPEL的全称叫 Extra Packages for Enterprise Linux 。EPEL是由 Fedora 社区打造，为 RHEL 及衍生发行版如 CentOS、Scientific Linux 等提供高质量软件包的项目。装上了 EPEL之后，就相当于添加了一个第三方源。\n如果你知道rpmfusion.org的话，拿 rpmfusion 做比较还是很恰当的，rpmfusion 主要为桌面发行版提供大量rpm包（只有开源驱动才能进官方源，想要闭源驱动装rpmfusion），而EPEL则为服务器版本提供大量的rpm包，而且大多数rpm包在官方 repository 中是找不到的。\nopenSUSE /ˌoʊpənˈsuːzə/\n为什么选择 openSUSE Free and Open Source 确定你心目中的贡献者们是什么样的，从而聚拢到这样的人。\n狭义的自由开源概念 狭义的自由开源概念是：自由地开放源代码。即：软件作者把源代码公开发布，给予你修改并二次发布的权利。就这样，没别的了。\n测试、调试、故障受理与修复、接受新功能请求、接受代码合并请求、接受别人的帮助、用户社区建立、互动、整个自由开源生态的维护，统统都是完全没有，谁愿意干谁干，跟我没有关系。或者这么说：“写完拉倒”，哪怕洪水滔天。这从 GPL 许可证的“无保声明”中可以看出端倪。\n广义的自由开源概念 实际上如果你看过操作系统革命你就会明白：开放源代码其实并不是这一运动想要实现的全部，它的最终目的是普及自由精神，建立自由社区。\n目前这一精神在自由开源软件上的表现有：\n 源代码开源。 来自软件所有者的开发门槛为零。 不重新发明轮子。如果有已有实现并可以扩展，那么扩展它。 文档开源。使用维基等。 组织并形成用户互助社区。积极帮助用户（在不影响开发的前提下）。同时在开发上尽量面向用户，把用户的反应纳入到重大修改的考量因素当中去，积极采纳合理意见。 积极回应故障汇报并提供修复。 积极回应新功能请求。能做的做，不能做的解释原因寻求理解。 形成良性的贡献者添加内容和用户反馈渠道。 重视并维护由类似软件共同组成的生态的和谐稳定。（简单说就是：我开发 KDE 是因为 GNOME 满足不了我的需求，而不是为了搞死 GNOME。）  现在您可以拿来同狭义的自由开源概念做比较，发现如果说狭义的自由开源概念只是指某种行为，那么广义的自由开源概念已经是指一种氛围了。\nopenSUSE 秉持的自由开源概念 openSUSE 项目是完全做到“广义的自由开源概念”的社区。\n同时我们一直持有的相关理念还有：\n 积极的与上游合作。不“内化”补丁或修改，除非上游出于种种原因不收。 积极的为整个生态着想。 不搞歧视或二等公民。 尊重许可证、版权甚至是专利  如果你认同这些，那么您适合这个社区。\n配置 Install 语言请选择 English，因为 Linux 需要经常使用 Terminal，中文家目录并不方便。\n分区请选择默认的 btrfs 文件系统，有需要选择 Guided setup 和 Expert Partitioner。\nUse Snapper 默认开启。\nopenSUSE 镜像 我们官方的态度是不鼓励直接使用镜像的。\n因为比起「其它」发行版，我们 openSUSE 的技术力量比较强，开发了两个东西。\n一个叫做 Metalink，意思是这个格式（BT、Megalink 磁力链一样的格式）可以自动从 BT/FTP/HTTP 同时下载。\n另一个叫做 MirrorBrain，意思是我把所有的镜像地址隐藏起来，只暴露出一个中央服务器，所有人只需使用这个中央服务器（download.opensuse.org ），它会根据你的 IP 地理位置为你分配一个离你最近的镜像，但是在你那边显示的依旧是来自 download.opensuse.org。而如何分配是根据镜像管理员和中央服务器管理员当初的协定来确定的，比如镜像每月能够承受的流量、所愿意扮演的角色（是区域中心、地标式的镜像比如北交大、中科大，还是小镜像）等。\n而根据 openSUSE 软件源的构造，所有的 RPM 包都是从镜像获得的，所有的 metadata（元数据）都是从主镜像（位于德国）获得的，所以你源刷新的慢，只能证明你被我们光荣伟大的放火长城拖住了，而不能证明 openSUSE 项目有错，也代表不了你下载 RPM 包时的速度。\n申报自己为官方镜像。\nUninstall Discover Discover is the software center that is shipped with Plasma 5. Discover is infamous for its crashes, and it’s not a very good app overall. On top of that, it also adds redundancy since we already have Yast.\nYou can safely remove Discover:\nOpen Yast → Software Management → Search for `discover` → Right-click → Delete → Toggle #1 (deinstallation of discover packages) → Accept or\nsudo zypper remove packagekit 在 System Tray Setting 里面关闭 Software Updates 的通知。\n取消推荐的软件包 \u0026amp; 删除模组 打开 YaST ，点击 软件管理 ，再点击左上角的 依赖项 ，取消勾选 安装被推荐的软件包 。这样你的电脑就不会在某次更新后出现一些不是你主动安装的软件包。\n在 软件管理 页面，点击 视图，选择 模组 ，然后你就能看到按模组分类的包。例如你可以在此页面直接用鼠标右键单击 游戏 ，选择 不安装 或 卸载，卸载全部的预装的 KDE/Gnome 游戏包。\nUpdate System openSUSE Leap 是 openSUSE 打造定期释出的 Linux 发行版本的一种全新方式。 Leap 使用 SUSE Linux Enterprise（SLE） 的源代码，使 Leap 具有其它 Linux 发行版无法比拟的稳定性，并将其与社区开发相结合，为用户、开发人员和系统管理员提供最佳的 Linux 体验。贡献者和企业为 Leap 所做的贡献使它成为了提供成熟的软件包的 SLE 和提供最新的软件包的 Tumbleweed 这两者之间的桥梁。\nLeap 用户将会定期收到安全更新和补丁修复，如果你希望应用这些更新，在终端下用 Root 运行：\nsudo zypper patch zypper patch 只会更新列在 patchinfo 上面的包。\n有时，第三方软件源会提供一些功能性的更新，如果你希望应用这些更新，在终端下用 Root 运行：\nsudo zypper update OBS Package Installer \u0026amp; Flatpak 如果你想在终端直接查找来自 OBS 的软件包，你可以先安装 opi，同理添加 fltapak 仓库。\nsudo zypper in opi sudo flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo 然后输入你想要查找的软件包的名称，例如你要安装 qbittorrent enhanced edition ，你可以：\n$ opi qbittorrent $ flathub install netease 中文社区源是 openSUSE 中文社区的开发者们为用户构建、打包和收录一些发起自中文 Linux 圈子的软件或中文 Linux 圈子常用的软件。\nAdd Community Repositories That’s where community repositories come in. The most important one is Packman. For Leap:\nsudo zypper ar -cfp 90 'https://ftp.gwdg.de/pub/linux/misc/packman/suse/openSUSE_Leap_$releasever/' packman Open RPM with Yast Select any RPM package → Right-click → Properties → File Type Options → Move Yast to the first place → Apply Install Multimedia Codecs openSUSE 默认是没有部分多媒体编解码器的，包括家喻户晓的 MP3、AVI 等。这是因为它们是受限媒体格式。具体解释见openSUSE 编解码器一键安装、常见编解码器对应软件包/源说明、及版权须知。\nsudo zypper in opi \u0026amp;\u0026amp; opi codecs or, In order to install the H264/AVC support on your system, type in:\nsudo zypper install x264 libx265-130 libx264-148 或者通过 Packman 安装解码器\nzypper ar -cfp 90 https://mirrors.ustc.edu.cn/packman/suse/openSUSE_Leap_$releasever packmansudo zypper refreshsudo zypper dist-upgrade --from packman --allow-vendor-changesudo zypper install --from packman ffmpeg gstreamer-plugins-{good,bad,ugly,libav} libavcodec-full vlc-codecs Turn on Night Color Night color reduces the amount of blue light at night.\nOpen System Settings → Display and Monitor → Night Color → Activate Night Color → Apply Theme 在系统设置 startup and shutdown 下载使用个主题，因为默认主题输入密码的时候密码总是没有居中，跑到上面去了。\n或者，使用一个全局主题，例如 Layan。\nDisable touchpad 对于 touchpad 选择 Disable touchpad when mouse is pulgged in\n用户字体 Dolphin 下单击安装字体目录为\n/home/用户名/.fonts 如果下载好的字体文件无法直接点开安装（例如 *.ttc），或者字体太多，不想一个一个地安装，可以将字体文件全部放到字体文件夹中。然后运行：\nfc-cache -fv 输入法 在Yast中安装第二语言，就会自动安装fcitx并添加中文支持。\n词库\nFcitx 的 Libpinyin 可以直接在线导入搜狗细胞词库。不需要安装sougou输入法。\n需要安装 fcitx-pinyin-tools/fcitx-table-tools 这两个包，以添加处理词库的工具。\nsudo zypper in fcitx-pinyin-tools fcitx-table-tools 词库少了的话，也不好用，但是一次只能导入一个细胞词库。网上可以找到比较全的词库包。\n通过 7zr 解压过后将所有 txt 词库拷贝到 ~/.config/fcitx/libpinyin/importdict 即可。\n7zr x txt.7z 搜狗拼音\nsudo opi sogou-pinyin cloudpinyin\n根据文档，可以使用 libpinyin + cloudpinyin，哪怕不用导入词典，依旧很好用。果然，还是云词库的力量强大。\nsudo zypper in fcitx-cloudpinyin 默认的云输入引擎是 Google ，国内直接访问很不流畅，你可以打开输入法的配置，点击 Addon Config，找到 Cloud Pinyin ，点击右侧的设置，在弹出的窗口中，将 Google 替换为 Baidu 。\nKDE Connect KDE Connect 是一款能够方便手机与电脑进行连接的应用。\n 文件互传 共享剪贴板 远程输入 响铃，即既可以用电脑来找手机，也可以用手机找电脑。 幻灯片遥控器 多媒体控制 执行命令 共享通知  默认 kdeconnect 在防火墙那边是没放开的，要操作一下\nsudo firewall-cmd --zone=public --permanent --add-service=kdeconnect-kdesudo firewall-cmd --reload 装入 NTFS 分区   安装 ntfs-3g。\nsudo zypper in ntfs-3g   创建一个要充当安装点的目录，如 ~/mounts/windows。\nmkdir ~/mounts/windows   确定所需的 Windows 分区。\nsudo fdisk -l   以读写模式装入分区。使用相应的 Windows 分区替换占位符 DEVICE：\nntfs-3g /dev/DEVICE MOUNT POINT 要在只读模式下使用 Windows 分区，请追加 -o ro\nntfs-3g /dev/DEVICE MOUNT POINT -o ro ntfs-3g 命令使用当前用户 (UID) 和组 (GID) 装入给定设备。如果要为其他用户设置写权限，请使用命令 id  USER 获取 UID 和 GID 值的输出。设置方式：\nid usernamentfs-3g /dev/DEVICE MOUNT POINT -o uid=1000,gid=100   要卸载资源，请运行 fusermount -u 安装点。\n  任务栏透明化 Go to System Settings | Window Management | Window Rules. Press New\u0026hellip; button. Give some description to the new rule, Dock Transparency, for example. Then select only Dock (panel) in \u0026ldquo;Window type\u0026rdquo; field.\n之后在 Appearance \u0026amp; Fixes 中调整 opacity。\nBtrfs 文件系统似乎是内核中比较稳定的部分，多年来，人们一直使用 ext2/3，ext 文件系统以其卓越的稳定性成为了事实上的 Linux 标准文件系统。近年来 ext2/3 暴露出了一些扩展性问题，于是便催生了 ext4 。在 2008 年发布的 Linux2.6.19 内核中集成了 ext4 的 dev 版本。 2.6.28 内核发布时，ext4 结束了开发版，开始接受用户的使用。似乎 ext 就将成为 Linux 文件系统的代名词。然而当您阅读很多有关 ext4 的文章时，会发现都不约而同地提到了 btrfs，并认为 ext4 将是一个过渡的文件系统。 ext4 的作者 Theodore Tso 也盛赞 btrfs 并认为 btrfs 将成为下一代 Linux 标准文件系统。 Oracle，IBM， Intel 等厂商也对 btrfs 表现出了极大的关注，投入了资金和人力。为什么 btrfs 如此受人瞩目呢。这便是本文首先想探讨的问题。\nKevin Bowling 有一篇介绍各种文件系统的文章，在他看来，ext2/3 等文件系统属于“古典时期”。文件系统的新时代是 2005 年由 Sun 公司的 ZFS 开创的。 ZFS 代表” last word in file system ”，意思是此后再也不需要开发其他的文件系统了。 ZFS 的确带来了很多崭新的观念，对文件系统来讲是一个划时代的作品。\n如果您比较 btrfs 的特性，将会发现 btrfs 和 ZFS 非常类似。也许我们可以认为 btrfs 就是 Linux 社区对 ZFS 所作出的回应。从此往后在 Linux 中也终于有了一个可以和 ZFS 相媲美的文件系统。\nBtrfs 的特性 您可以在 btrfs 的主页上看到 btrfs 的特性列表。我自作主张，将那张列表分成了四大部分。\n首先是扩展性 (scalability) 相关的特性，btrfs 最重要的设计目标是应对大型机器对文件系统的扩展性要求。 Extent，B-Tree 和动态 inode 创建等特性保证了 btrfs 在大型机器上仍有卓越的表现，其整体性能而不会随着系统容量的增加而降低。\n其次是数据一致性 (data integrity) 相关的特性。系统面临不可预料的硬件故障，Btrfs 采用 COW 事务技术来保证文件系统的一致性。 btrfs 还支持 checksum，避免了 silent corrupt 的出现。而传统文件系统则无法做到这一点。\n第三是和多设备管理相关的特性。 Btrfs 支持创建快照 (snapshot)，和克隆 (clone) 。 btrfs 还能够方便的管理多个物理设备，使得传统的卷管理软件变得多余。\n最后是其他难以归类的特性。这些特性都是比较先进的技术，能够显著提高文件系统的时间 / 空间性能，包括延迟分配，小文件的存储优化，目录索引等。\n扩展性相关的特性 B-Tree\nbtrfs 文件系统中所有的 metadata 都由 BTree 管理。使用 BTree 的主要好处在于查找，插入和删除操作都很高效。可以说 BTree 是 btrfs 的核心。\n一味地夸耀 BTree 很好很高效也许并不能让人信服，但假如稍微花费一点儿时间看看 ext2/3 中元数据管理的实现方式，便可以反衬出 BTree 的优点。\n妨碍 ext2/3 扩展性的一个问题来自其目录的组织方式。目录是一种特殊的文件，在 ext2/3 中其内容是一张线性表格。\n图中展示了一个 ext2 目录文件的内容，该目录中包含四个文件。分别是 \u0026ldquo;home1\u0026rdquo;，\u0026ldquo;usr\u0026rdquo;，\u0026ldquo;oldfile\u0026rdquo; 和 \u0026ldquo;sbin\u0026rdquo; 。如果需要在该目录中查找目录 sbin，ext2 将遍历前三项，直至找到 sbin 这个字符串为止。\n这种结构在文件个数有限的情况下是比较直观的设计，但随着目录下文件数的增加，查找文件的时间将线性增长。 2003 年，ext3 设计者开发了目录索引技术，解决了这个问题。目录索引使用的数据结构就是 BTree 。如果同一目录下的文件数超过 2K，inode 中的 i_data 域指向一个特殊的 block 。在该 block 中存储着目录索引 BTree 。 BTree 的查找效率高于线性表，\n但为同一个元数据设计两种数据结构总是不太优雅。在文件系统中还有很多其他的元数据，用统一的 BTree 管理是非常简单而优美的设计。\nBtrfs 内部所有的元数据都采用 BTree 管理，拥有良好的可扩展性。 btrfs 内部不同的元数据由不同的 Tree 管理。在 superblock 中，有指针指向这些 BTree 的根。如图 2 所示：\nFS Tree 管理文件相关的元数据，如 inode，dir 等； Chunk tree 管理设备，每一个磁盘设备都在 Chunk Tree 中有一个 item ； Extent Tree 管理磁盘空间分配，btrfs 每分配一段磁盘空间，便将该磁盘空间的信息插入到 Extent tree 。查询 Extent Tree 将得到空闲的磁盘空间信息； Tree of tree root 保存很多 BTree 的根节点。比如用户每建立一个快照，btrfs 便会创建一个 FS Tree 。为了管理所有的树，btrfs 采用 Tree of tree root 来保存所有树的根节点； checksum Tree 保存数据块的校验和。\n基于 Extent 的文件存储\n现代很多文件系统都采用了 extent 替代 block 来管理磁盘。 Extent 就是一些连续的 block，一个 extent 由起始的 block 加上长度进行定义。\nExtent 能有效地减少元数据开销。为了进一步理解这个问题，我们还是看看 ext2 中的反面例子。\next2/3 以 block 为基本单位，将磁盘划分为多个 block 。为了管理磁盘空间，文件系统需要知道哪些 block 是空闲的。 Ext 使用 bitmap 来达到这个目的。 Bitmap 中的每一个 bit 对应磁盘上的一个 block，当相应 block 被分配后，bitmap 中的相应 bit 被设置为 1 。这是很经典也很清晰的一个设计，但不幸的是当磁盘容量变大时，bitmap 自身所占用的空间也将变大。这就导致了扩展性问题，随着存储设备容量的增加，bitmap 这个元数据所占用的空间也随之增加。而人们希望无论磁盘容量如何增加，元数据不应该随之线形增加，这样的设计才具有可扩展性。\n下图比较了 block 和 extent 的区别：\n在 ext2/3 中，10 个 block 需要 10 个 bit 来表示；在 btrfs 中则只需要一个元数据。对于大文件，extent 表现出了更加优异的管理性能。\nExtent 是 btrfs 管理磁盘空间的最小单位，由 extent tree 管理。 Btrfs 分配 data 或 metadata 都需要查询 extent tree 以便获得空闲空间的信息。\n动态 inode 分配\n为了理解动态 inode 分配，还是需要借助 ext2/3 。下表列举了 ext2 文件系统的限制：\n限制最大文件数量文件系统空间大小 V / 8192\n比如 100G 大小的文件系统中，能创建的文件个数最大为 131072\n下图显示了 ext2 的磁盘布局：\n在 ext2 中 inode 区是被预先固定分配的，且大小固定，比如一个 100G 的分区中，inode table 区中只能存放 131072 个 inode，这就意味着不可能创建超过 131072 个文件，因为每一个文件都必须有一个唯一的 inode 。\n为了解决这个问题，必须动态分配 inode 。每一个 inode 只是 BTree 中的一个节点，用户可以无限制地任意插入新的 inode，其物理存储位置是动态分配的。所以 btrfs 没有对文件个数的限制。\n针对 SSD 的优化支持\nSSD 是固态存储 Solid State Disk 的简称。在过去的几十年中，CPU/RAM 等器件的发展始终遵循着摩尔定律，但硬盘 HDD 的读写速率却始终没有飞跃式的发展。磁盘 IO 始终是系统性能的瓶颈。\nSSD 采用 flash memory 技术，内部没有磁盘磁头等机械装置，读写速率大幅度提升。 flash memory 有一些不同于 HDD 的特性。 flash 在写数据之前必须先执行擦除操作；其次，flash 对擦除操作的次数有一定的限制，在目前的技术水平下，对同一个数据单元最多能进行约 100 万次擦除操作，因此，为了延长 flash 的寿命，应该将写操作平均到整个 flash 上。\nSSD 在硬件内部的微代码中实现了 wear leveling 等分布写操作的技术，因此系统无须再使用特殊的 MTD 驱动和 FTL 层。虽然 SSD 在硬件层面做了很多努力，但毕竟还是有限。文件系统针对 SSD 的特性做优化不仅能提高 SSD 的使用寿命，而且能提高读写性能。 Btrfs 是少数专门对 SSD 进行优化的文件系统。 btrfs 用户可以使用 mount 参数打开对 SSD 的特殊优化处理。\nBtrfs 的 COW 技术从根本上避免了对同一个物理单元的反复写操作。如果用户打开了 SSD 优化选项，btrfs 将在底层的块空间分配策略上进行优化：将多次磁盘空间分配请求聚合成一个大小为 2M 的连续的块。大块连续地址的 IO 能够让固化在 SSD 内部的微代码更好的进行读写优化，从而提高 IO 性能。\n数据一致性相关的特性 COW 事务\n理解 COW 事务，必须首先理解 COW 和事务这两个术语。\n所谓 COW，即每次写磁盘数据时，先将更新数据写入一个新的 block，当新数据写入成功之后，再更新相关的数据结构指向新 block 。\nCOW 只能保证单一数据更新的原子性。但文件系统中很多操作需要更新多个不同的元数据，比如创建文件需要修改以下这些元数据：\n 修改 extent tree，分配一段磁盘空间 创建一个新的 inode，并插入 FS Tree 中 增加一个目录项，插入到 FS Tree 中  任何一个步骤出错，文件便不能创建成功，因此可以定义为一个事务。\n下面将演示一个 COW 事务。\nA 是 FS Tree 的根节点，新的 inode 的信息将被插入节点 C 。首先，btrfs 将 inode 插入一个新分配的 block C ’中，并修改上层节点 B，使其指向新的 block C ’；修改 B 也将引发 COW，以此类推，引发一个连锁反应，直到最顶层的 Root A 。当整个过程结束后，新节点 A ’变成了 FS Tree 的根。但此时事务并未结束，superblock 依然指向 A 。\n接下来，修改目录项（E 节点），同样引发这一过程，从而生成新的根节点 A ’’。\n此时，inode 和目录项都已经写入磁盘，可以认为事务已经结束。 btrfs 修改 superblock，使其指向 A ’’，如下图所示：\nCOW 事务能够保证文件系统的一致性，并且系统 Reboot 之后不需要执行 fsck 。因为 superblock 要么指向新的 A ’’，要么指向 A，无论哪个都是一致的数据。\nChecksum\nChecksum 技术保证了数据的可靠性，避免 silent corruption 现象。由于硬件原因，从磁盘上读出的数据会出错。比如 block A 中存放的数据为 0x55，但读取出来的数据变是 0x54，因为读取操作并未报错，所以这种错误不能被上层软件所察觉。\n解决这个问题的方法是保存数据的校验和，在读取数据后检查校验和。如果不符合，便知道数据出现了错误。\next2/3 没有校验和，对磁盘完全信任。而不幸的是，磁盘的错误始终存在，不仅发生在廉价的 IDE 硬盘上，昂贵的 RAID 也存在 silent corruption 问题。而且随着存储网络的发展，即使数据从磁盘读出正确，也很难确保能够安全地穿越网络设备。\nbtrfs 在读取数据的同时会读取其相应的 checksum 。如果最终从磁盘读取出来的数据和 checksum 不相同，btrfs 会首先尝试读取数据的镜像备份，如果数据没有镜像备份，btrfs 将返回错误。写入磁盘数据之前，btrfs 计算数据的 checksum 。然后将 checksum 和数据同时写入磁盘。\nBtrfs 采用单独的 checksum Tree 来管理数据块的校验和，把 checksum 和 checksum 所保护的数据块分离开，从而提供了更严格的保护。假如在每个数据 block 的 header 中加入一个域保存 checksum，那么这个数据 block 就成为一个自己保护自己的结构。这种结构下有一种错误无法检测出来，比如本来文件系统打算从磁盘上读 block A，但返回了 block B，由于 checksum 在 block 内部，因此 checksum 依旧是正确的。 btrfs 采用 checksum tree 来保存数据块的 checksum，避免了上述问题。\nBtrfs 采用 crc32 算法计算 checksum，在将来的开发中会支持其他类型的校验算法。为了提高效率，btrfs 将写数据和 checksum 的工作分别用不同的内核线程并行执行。\n多设备管理相关的特性 每个 Unix 管理员都曾面临为用户和各种应用分配磁盘空间的任务。多数情况下，人们无法事先准确地估计一个用户或者应用在未来究竟需要多少磁盘空间。磁盘空间被用尽的情况经常发生，此时人们不得不试图增加文件系统空间。传统的 ext2/3 无法应付这种需求。\n很多卷管理软件被设计出来满足用户对多设备管理的需求，比如 LVM 。 Btrfs 集成了卷管理软件的功能，一方面简化了用户命令；另一方面提高了效率。\n多设备管理\nBtrfs 支持动态添加设备。用户在系统中增加新的磁盘之后，可以使用 btrfs 的命令将该设备添加到文件系统中。\n为了灵活利用设备空间，Btrfs 将磁盘空间划分为多个 chunk 。每个 chunk 可以使用不同的磁盘空间分配策略。比如某些 chunk 只存放 metadata，某些 chunk 只存放数据。一些 chunk 可以配置为 mirror，而另一些 chunk 则可以配置为 stripe 。这为用户提供了非常灵活的配置可能性。\nSubvolume\nSubvolume 是很优雅的一个概念。即把文件系统的一部分配置为一个完整的子文件系统，称之为 subvolume 。\n采用 subvolume，一个大的文件系统可以被划分为多个子文件系统，这些子文件系统共享底层的设备空间，在需要磁盘空间时便从底层设备中分配，类似应用程序调用 malloc() 分配内存一样。可以称之为存储池。这种模型有很多优点，比如可以充分利用 disk 的带宽，可以简化磁盘空间的管理等。\n所谓充分利用 disk 的带宽，指文件系统可以并行读写底层的多个 disk，这是因为每个文件系统都可以访问所有的 disk 。传统的文件系统不能共享底层的 disk 设备，无论是物理的还是逻辑的，因此无法做到并行读写。\n所谓简化管理，是相对于 LVM 等卷管理软件而言。采用存储池模型，每个文件系统的大小都可以自动调节。而使用 LVM，如果一个文件系统的空间不够了，该文件系统并不能自动使用其他磁盘设备上的空闲空间，而必须使用 LVM 的管理命令手动调节。\nSubvolume 可以作为根目录挂载到任意 mount 点。 subvolume 是非常有趣的一个特性，有很多应用。\n假如管理员只希望某些用户访问文件系统的一部分，比如希望用户只能访问 /var/test/ 下面的所有内容，而不能访问 /var/ 下面其他的内容。那么便可以将 /var/test 做成一个 subvolume 。 /var/test 这个 subvolume 便是一个完整的文件系统，可以用 mount 命令挂载。比如挂载到 /test 目录下，给用户访问 /test 的权限，那么用户便只能访问 /var/test 下面的内容了。\n快照和克隆\n快照是对文件系统某一时刻的完全备份。建立快照之后，对文件系统的修改不会影响快照中的内容。这是非常有用的一种技术。\n比如数据库备份。假如在时间点 T1，管理员决定对数据库进行备份，那么他必须先停止数据库。备份文件是非常耗时的操作，假如在备份过程中某个应用程序修改了数据库的内容，那么将无法得到一个一致性的备份。因此在备份过程中数据库服务必须停止，对于某些关键应用这是不能允许的。\n利用快照，管理员可以在时间点 T1 将数据库停止，对系统建立一个快照。这个过程一般只需要几秒钟，然后就可以立即重新恢复数据库服务。此后在任何时候，管理员都可以对快照的内容进行备份操作，而此时用户对数据库的修改不会影响快照中的内容。当备份完成，管理员便可以删除快照，释放磁盘空间。\n快照一般是只读的，当系统支持可写快照，那么这种可写快照便被称为克隆。克隆技术也有很多应用。比如在一个系统中安装好基本的软件，然后为不同的用户做不同的克隆，每个用户使用自己的克隆而不会影响其他用户的磁盘空间。非常类似于虚拟机。\nBtrfs 支持 snapshot 和 clone 。这个特性极大地增加了 btrfs 的使用范围，用户不需要购买和安装昂贵并且使用复杂的卷管理软件。下面简要介绍一下 btrfs 实现快照的基本原理。\n如前所述 Btrfs 采用 COW 事务技术，从图 COW transaction 3 可以看到，COW 事务结束后，如果不删除原来的节点 A,C,E，那么 A,C,E,D,F 依然完整的表示着事务开始之前的文件系统。这就是 snapshot 实现的基本原理。\nBtrfs 采用引用计数决定是否在事务 commit 之后删除原有节点。对每一个节点，btrfs 维护一个引用计数。当该节点被别的节点引用时，该计数加一，当该节点不再被别的节点引用时，该计数减一。当引用计数归零时，该节点被删除。对于普通的 Tree Root, 引用计数在创建时被加一，因为 Superblock 会引用这个 Root block 。很明显，初始情况下这棵树中的所有其他节点的引用计数都为一。当 COW 事务 commit 时，superblock 被修改指向新的 Root A ’’，原来 Root block A 的引用计数被减一，变为零，因此 A 节点被删除。 A 节点的删除会引发其子孙节点的引用计数也减一，图 COW transaction 3 中的 B，C 节点的引用计数因此也变成了 0，从而被删除。 D,E 节点在 COW 时，因为被 A ’’所引用，计数器加一，因此计数器这时并未归零，从而没有被删除。\n创建 Snapshot 时，btrfs 将的 Root A 节点复制到 sA，并将 sA 的引用计数设置为 2 。在事务 commit 的时候，sA 节点的引用计数不会归零，从而不会被删除，因此用户可以继续通过 Root sA 访问 snapshot 中的文件。\n软件 RAID\nRAID 技术有很多非常吸引人的特性，比如用户可以将多个廉价的 IDE 磁盘组合为 RAID0 阵列，从而变成了一个大容量的磁盘； RAID1 和更高级的 RAID 配置还提供了数据冗余保护，从而使得存储在磁盘中的数据更加安全。\nBtrfs 很好的支持了软件 RAID，RAID 种类包括 RAID0,RAID1 和 RAID10.\nBtrfs 缺省情况下对 metadata 进行 RAID1 保护。前面已经提及 btrfs 将设备空间划分为 chunk，一些 chunk 被配置为 metadata，即只存储 metadata 。对于这类 chunk，btrfs 将 chunk 分成两个条带，写 metadata 的时候，会同时写入两个条带内，从而实现对 metadata 的保护。\n其他特性 Btrfs 主页上罗列的其他特性不容易分类，这些特性都是现代文件系统中比较先进的技术，能够提高文件系统的时间或空间效率。\nDelay allocation\n延迟分配技术能够减少磁盘碎片。在 Linux 内核中，为了提高效率，很多操作都会延迟。\n在文件系统中，小块空间频繁的分配和释放会造成碎片。延迟分配是这样一种技术，当用户需要磁盘空间时，先将数据保存在内存中。并将磁盘分配需求发送给磁盘空间分配器，磁盘空间分配器并不立即分配真正的磁盘空间。只是记录下这个请求便返回。\n磁盘空间分配请求可能很频繁，所以在延迟分配的一段时间内，磁盘分配器可以收到很多的分配请求，一些请求也许可以合并，一些请求在这段延迟期间甚至可能被取消。通过这样的“等待”，往往能够减少不必要的分配，也有可能将多个小的分配请求合并为一个大的请求，从而提高 IO 效率。\nInline file\n系统中往往存在大量的小文件，比如几百个字节或者更小。如果为其分配单独的数据 block，便会引起内部碎片，浪费磁盘空间。 btrfs 将小文件的内容保存在元数据中，不再额外分配存放文件数据的磁盘块。改善了内部碎片问题，也增加了文件的访问效率。\n上图显示了一个 BTree 的叶子节点。叶子中有两个 extent data item 元数据，分别用来表示文件 file1 和 file2 所使用的磁盘空间。\n假设 file1 的大小仅为 15 个字节； file2 的大小为 1M 。如图所示，file2 采用普通的 extent 表示方法：extent2 元数据指向一段 extent，大小为 1M，其内容便是 file2 文件的内容。\n而对于 file1， btrfs 会把其文件内容内嵌到元数据 extent1 中。如果不采用 inline file 技术。如虚线所示，extent1 指向一个最小的 extent，即一个 block，但 file1 有 15 个字节，其余的空间便成为了碎片空间。\n采用 inline 技术，读取 file1 时只需要读取元数据 block，而无需先读取 extent1 这个元数据，再读取真正存放文件内容的 block，从而减少了磁盘 IO 。\n得益于 inline file 技术，btrfs 处理小文件的效率非常高，也避免了磁盘碎片问题。\nDirectory index\n当一个目录下的文件数目巨大时，目录索引可以显著提高文件搜索时间。 Btrfs 本身采用 BTree 存储目录项，所以在给定目录下搜索文件的效率是非常高的。\n然而，btrfs 使用 BTree 管理目录项的方式无法同时满足 readdir 的需求。 readdir 是 POSIX 标准 API，它要求返回指定目录下的所有文件，并且特别的，这些文件要按照 inode number 排序。而 btrfs 目录项插入 BTree 时的 Key 并不是 Inode number，而是根据文件名计算的一个 hash 值。这种方式在查找一个特定文件时非常高效，但却不适于 readdir 。为此，btrfs 在每次创建新的文件时，除了插入以 hash 值为 Key 的目录项外，还同时插入另外一种目录项索引，该目录项索引的 KEY 以 sequence number 作为 BTree 的键值。这个 sequence number 在每次创建新文件时线性增加。因为 Inode number 也是每次创建新文件时增加的，所以 sequence number 和 inode number 的顺序相同。以这种 sequence number 作为 KEY 在 BTree 中查找便可以方便的得到一个以 inode number 排序的文件列表。\n另外以 sequence number 排序的文件往往在磁盘上的位置也是相邻的，所以以 sequence number 为序访问大量文件会获得更好的 IO 效率。\n压缩\n大家都曾使用过 zip，winrar 等压缩软件，将一个大文件进行压缩可以有效节约磁盘空间。 Btrfs 内置了压缩功能。\n通常人们认为将数据写入磁盘之前进行压缩会占用很多的 CPU 计算时间，必然降低文件系统的读写效率。但随着硬件技术的发展，CPU 处理时间和磁盘 IO 时间的差距不断加大。在某些情况下，花费一定的 CPU 时间和一些内存，但却能大大节约磁盘 IO 的数量，这反而能够增加整体的效率。\n比如一个文件不经过压缩的情况下需要 100 次磁盘 IO 。但花费少量 CPU 时间进行压缩后，只需要 10 次磁盘 IO 就可以将压缩后的文件写入磁盘。在这种情况下，IO 效率反而提高了。当然，这取决于压缩率。目前 btrfs 采用 zlib 提供的 DEFALTE/INFLATE 算法进行压缩和解压。在将来，btrfs 应该可以支持更多的压缩算法，满足不同用户的不同需求。\n目前 btrfs 的压缩特性还存在一些不足，当压缩使能后，整个文件系统下的所有文件都将被压缩，但用户可能需要更细粒度的控制，比如针对不同的目录采用不同的压缩算法，或者禁止压缩。我相信，btrfs 开发团队将在今后的版本中解决这个问题。\n对于某些类型的文件，比如 jpeg 文件，已经无法再进行压缩。尝试对其压缩将纯粹浪费 CPU 。为此，当对某文件的若干个 block 压缩后发现压缩率不佳，btrfs 将不会再对文件的其余部分进行压缩操作。这个特性在某种程度上提高了文件系统的 IO 效率。\n预分配\n很多应用程序有预先分配磁盘空间的需要。他们可以通过 posix_fallocate 接口告诉文件系统在磁盘上预留一部分空间，但暂时并不写入数据。如果底层文件系统不支持 fallocate，那么应用程序只有使用 write 预先写一些无用信息以便为自己预留足够的磁盘空间。\n由文件系统来支持预留空间更加有效，而且能够减少磁盘碎片，因为所有的空间都是一次分配，因而更有可能使用连续的空间。 Btrfs 支持 posix_fallocate 。\n总结 至此，我们对 btrfs 的很多特性进行了较为详细的探讨，但 btrfs 能提供的特性却并不止这些。 btrfs 正处于试验开发阶段，还将有更多的特性。\nBtrfs 也有一个重要的缺点，当 BTree 中某个节点出现错误时，文件系统将失去该节点之下的所有的文件信息。而 ext2/3 却避免了这种被称为”错误扩散”的问题。\n但无论怎样，希望您和我一样，开始认同 btrfs 将是 Linux 未来最有希望的文件系统。\nBtrfs 使用 了解了 btrfs 的特性，想必您一定想亲身体验一下 btrfs 的使用。本章将简要介绍如何使用 btrfs 。\n要使用一些用户空间工具的话，需要 安装 基础操作必须的 btrfs-progs 软件包。\n创建文件系统 单一设备上的文件系统\n要在分区 /dev/partition 上创建一个 Btrfs 文件系统，执行：\n# mkfs.btrfs -L mylabel /dev/partition Btrfs 用于元数据的默认节点大小 (nodesize) 为 16KB，而用于数据的默认扇区大小 (sectorsize) 等于页面大小 (page size) 并会自动检测。 要对元数据使用较大的节点大小 (必须为扇区大小的倍数，最大允许 64KB)，请通过 -n 开关为 nodesize 指定一个值。如下例所示，使用 32KB 块大小：\n# mkfs.btrfs -L mylabel -n 32k /dev/partition 注意： 根据 mkfs.btrfs(8) § OPTIONS 手册页内容：“较小的节点大小会增加碎片，但也会让 B-trees 更高，进而使得锁定争用（locking contention）更少。较高的节点大小则能有更好的打包（packing）和更少的碎片，但代价是，更新元数据块时会使用更多的内存”。\n多设备文件系统 RAID\n多个设备可以用来创建一组 RAID。支持的 RAID 级别有 RAID 0、RAID 1、RAID 10、RAID 5 和 RAID 6。从 5.5 版本内核开始，新增对 RAID1c3 和 RAID1c4 的支持，分别是 3 份冗余和 4 份冗余的 RAID 1。可以使用 -d 和 -m 参数分别为数据和元数据配置 RAID 等级。默认情况下，数据有一份副本（single），元数据则被镜像（RAID1）。\n# mkfs.btrfs -d single -m raid1 /dev/part1 /dev/part2 ... subvolume 创建子卷\n要创建一个子卷:\n# btrfs subvolume create /path/to/subvolume 列出子卷列表\n要列出当前路径 (path) 下的子卷和它们的 ID:\n# btrfs subvolume list -p path 删除子卷\n要删除一个子卷:\n# btrfs subvolume delete /path/to/subvolume 自 Linux 4.18 起, 用户可以像移除常规目录一样删除一个子卷 (用 rm -r, rmdir 命令)。\n挂载子卷\n可以使用 subvol=*/path/to/subvolume* 或 subvolid=*objectid* 挂载标志来安装子卷，就像文件系统分区一样。\n$ sudo mount /dev/sdb1 -o subvol=projects /tmp/projects$ sudo mount /dev/sdb1 -o subvolid=261 /tmp/projects 使用 Btrfs 快照进行增量备份 *快照(snapshot)*是 Btrfs 的一个有趣的功能。快照是一个子卷的副本。生成快照是立即的。然而，生成快照与执行 rsync 或 cp 不同，快照并不是一创建就会占用空间。\n 编者注：来自 BTRFS Wiki：快照简单的来说就是一个子卷，它使用 Btrfs 的 COW 功能与其他子卷共享其数据（和元数据）。\n 占用的空间将随着原始子卷或快照本身（如果它是可写的）的数据变化而增加。子卷中已添加/修改的文件和已删除的文件仍然存在于快照中。这是一种方便的备份方式。\n使用快照进行备份\n快照驻留在子卷所在的同一磁盘上。你可以像浏览普通目录一样浏览它，并按照生成快照时的状态恢复文件的副本。顺便说一下，在快照子卷的同一磁盘上生成快照并不是一个理想的备份策略：如果硬盘坏了，快照也会丢失。快照的一个有趣的功能是可以将快照发送到另一个位置。快照可以被发送到外部硬盘或通过 SSH 发送到远程系统（目标文件系统也需要格式化为 Btrfs）。要实现这个，需要使用命令 btrfs send 和 btrfs receive。\n生成快照\n要使用 btrfs send 和 btrfs receive 命令，重要的是要将快照创建为只读，而快照默认是可写的。\n要创建一个快照:\n# btrfs subvolume snapshot source [dest/]name source为要创建快照的对象，[dest/]name为快照安放路径。\n下面的命令将对 /home 子卷进行快照。请注意 -r 标志代表只读。\nsudo btrfs subvolume snapshot -r /home /.snapshots/home-day1 快照的名称可以是当前日期，而不是 day1，比如 home-$(date +%Y%m%d)。快照看起来像普通的子目录。你可以把它们放在任何你喜欢的地方。目录 /.snapshots 可能是一个不错的选择，以保持它们的整洁和避免混淆。\n 编者注：快照不会对自己进行递归快照。如果你创建了一个子卷的快照，子卷所包含的每一个子卷或快照都会被映射到快照里面的一个同名的空目录。\n 使用 btrfs send 进行备份\n在本例中，U 盘中的目标 Btrfs 卷被挂载为 /run/media/user/mydisk/bk。发送快照到目标卷的命令是：\nsudo btrfs send /.snapshots/home-day1 | sudo btrfs receive /run/media/user/mydisk/bk 这被称为初始启动，它相当于一个完整的备份。这个任务需要一些时间，取决于 /home 目录的大小。显然，后续的增量发送只需要更短的时间。\n增量备份\n快照的另一个有用的功能是能够以增量的方式执行发送任务。让我们再来生成一个快照。\nsudo btrfs subvolume snapshot -r /home /.snapshots/home-day2 为了执行增量发送任务，需要指定上一个快照作为基础，并且这个快照必须存在于源文件和目标文件中。请注意 -p 选项。\nsudo btrfs send -p /.snapshot/home-day1 /.snapshot/home-day2 | sudo btrfs receive /run/media/user/mydisk/bk 再来一次（一天之后）：\nsudo btrfs subvolume snapshot -r /home /.snapshots/home-day3sudo btrfs send -p /.snapshot/home-day2 /.snapshot/home-day3 | sudo btrfs receive /run/media/user/mydisk/bk 清理\n操作完成后，你可以保留快照。但如果你每天都执行这些操作，你可能最终会有很多快照。这可能会导致混乱，并可能会在你的磁盘上使用大量的空间。因此，如果你认为你不再需要一些快照，删除它们是一个很好的建议。\n请记住，为了执行增量发送，你至少需要最后一个快照。这个快照必须存在于源文件和目标文件中。\nsudo btrfs subvolume delete /.snapshot/home-day1sudo btrfs subvolume delete /.snapshot/home-day2sudo btrfs subvolume delete /run/media/user/mydisk/bk/home-day1sudo btrfs subvolume delete /run/media/user/mydisk/bk/home-day2 注意：第 3 天的快照被保存在源文件和目标文件中。这样，明天（第 4 天），你就可以执行新的增量 btrfs send。\n最后的建议是，如果 U 盘的空间很大，可以考虑在目标盘中保留多个快照，而在源盘中只保留最后一个快照。\n压缩 给现存文件启用压缩，可使用 btrfs filesystem defragment -c alg 命令，alg 处可选填为 zlib，lzo 或 zstd。举例来说，要用 zstd 方式给整个文件系统重新压缩，执行下列命令：\n# btrfs filesystem defragment -r -v -c zstd / 要在新的 Btrfs 分区上安装 Arch Linux 时就启用压缩功能 (充分利用压缩特性)，请在 挂载 文件系统时使用 compress 选项：mount -o compress=zstd /dev/sd*xY* /mnt/。在配置过程中，请在 fstab 中把 compress=zstd 添加到根目录文件系统的挂载选项里。\nBtrfs 和 LVM-ext4 两者的共性 尽管两个文件系统之间存在核心差异，但 Btrfs 和 LVM-ext4 实际上有很多共同之处。两者都是成熟且经过充分测试的存储技术。从 Fedora Core 的早期开始，就一直在使用 LVM，而 ext4 在 2009 年成为 Fedora 11 的默认设置。Btrfs 在 2009 年并入 Linux 主线内核，并且 Facebook 广泛使用了该文件系统。SUSE Linux Enterprise 12 在 2014 年使其成为默认文件系统。因此，它在生产环境中也有着长久的运行时间。\n这两个系统都能很好地防止因意外停电而导致的文件系统损坏，尽管它们的实现方式不同。它们支持的配置包括使用单盘设置和跨越多个设备，并且这两种配置都能够创建近乎即时的快照。有各种工具可以帮助管理这两种系统，包括命令行和图形界面。这两种解决方案在家用台式机和高端服务器上都同样有效。\nLVM-ext4 的优势 ext4 文件系统 专注于高性能和可伸缩性，没有太多额外的花哨之处。它能有效地防止长时间后的碎片化，并当碎片化出现后提供了 很好的工具。ext4 之所以坚如磐石，是因为它构建在前代的 ext3 文件系统之上，带来了多年的系统内测试和错误修复。\nLVM-ext4 环境中的大多数高级功能都来自 LVM 本身。LVM 位于文件系统的“下方”，这意味着它支持任何文件系统。逻辑卷Logical volume（LV）是通用的块设备，因此 虚拟机可以直接使用它们。这种灵活性使得每个逻辑卷都可以使用合适的文件系统，用合适的选项应对各种情况。这种分层方法还遵循了“小工具协同工作”的 Unix 哲学。\n从硬件抽象出来的卷组volume group（VG）允许 LVM 创建灵活的逻辑卷。每个逻辑卷都提取自同一个存储池，但具有自己的设置。调整卷的大小比调整物理分区的大小容易得多，因为没有数据有序放置的限制。LVM 物理卷physical volume（PV）可以是任意数量的分区，甚至可以在系统运行时在设备之间移动。\nLVM 支持只读和读写的 快照，这使得从活动系统创建一致的备份变得很容易。每个快照都有一个定义的大小，更改源卷或快照卷将占用其中的空间。又或者，逻辑卷也可以是稀疏配置池thinly provisioned pool的一部分。这允许快照自动使用池中的数据，而不是使用在创建卷时定义的固定大小的块。\n有多个磁盘驱动器的 LVM\n当有多个设备时，LVM 才真正大放异彩。它原生支持大多数 RAID 级别，每个逻辑卷可以具有不同的 RAID 级别。LVM 将自动为 RAID 配置选择适当的物理设备，或者用户可以直接指定它。基本的 RAID 支持包括用于性能的数据条带化（RAID0）和用于冗余的镜像（RAID1）。逻辑卷也可以使用 RAID5、RAID6 和 RAID10 等高级设置。LVM RAID 支持已经成熟，因为 LVM 在底层使用的 设备映射器（dm） 和 多设备（md） 内核支持， 与 mdadm 使用的一样。\n对于具有快速和慢速驱动器的系统，逻辑卷也可以是 缓存卷。经典示例是 SSD 和传统磁盘驱动器的组合。缓存卷使用较快的驱动器来存储更频繁访问的数据（或用作写缓存），而慢速的驱动器则用于处理大量数据。\nLVM 中大量稳定的功能以及 ext4 的可靠性在既往的使用中早已被证明了。当然，功能越多就越复杂。在配置 LVM 时，要找到合适的功能选项是很有挑战性的。对于单驱动器的台式机系统，LVM 的功能（例如 RAID 和缓存卷）不适用。但是，逻辑卷比物理分区更灵活，快照也很有用。对于正常的桌面使用，LVM 的复杂性会成为典型的用户可能遇到的问题恢复的障碍。\nBtrfs 的优势 从前几代文件系统中学到的经验指导了构建到 Btrfs 的功能设计。与 ext4 不同，它可以直接跨越多个设备，因此它具有通常仅在卷管理器中才能找到的功能。它还具有 Linux 文件系统空间中独有的功能（ZFS 具有相似的功能集，但不要指望它在 Linux 内核中出现）。\nBtrfs 的主要功能\n也许最重要的功能是对所有数据进行校验和checksumming。校验和与写时复制copy-on-write（COW）一起，提供了在意外断电后确保文件系统完整性的 关键方法。更独特的是，校验和可以检测数据本身中的错误。悄然的数据损坏（有时也称为 bitrot）比大多数人意识到的更常见。如果没有主动验证，损坏最终可能会传播到所有可用的备份中。这使得用户没有有效的副本。通过透明地校验所有数据，Btrfs 能够立即检测到任何此类损坏。启用正确的 dup 或 raid 选项，文件系统也可以透明地修复损坏。\n写时复制也是 Btrfs 的基本功能，因为它在提供文件系统完整性和即时子卷快照方面至关重要。从公共子卷创建快照后，快照会自动共享底层数据。另外，事后的重复数据删除deduplication 使用相同的技术来消除相同的数据块。单个文件可以通过使用 cp 的 reflink 选项 来使用 COW 功能。reflink 副本对于复制大型文件（例如虚拟机镜像）特别有用，这些文件往往随着时间的推移具有大部分相同的数据。\nBtrfs 支持跨越多个设备，而无需卷管理器。多设备支持可提供数据镜像功能以实现冗余和条带化以提高性能。此外，还实验性地支持更高级的 RAID 级别，例如 RAID 5 和 RAID 6。与标准 RAID 设置不同，Btrfs 的 RAID1 实际上允许奇数个设备。例如，它可以使用 3 个设备，即使它们的大小不同。\n所有 RAID 和 dup 选项都是在文件系统级别指定的。因此，各个子卷不能使用不同的选项。请注意，使用多设备的 RAID1 选项意味着即使一个设备发生故障，卷中的所有数据都是可用的，并且校验功能可以保持数据本身的完整性。这超出了当前典型的 RAID 设置所能提供的范围。\n附加功能\nBtrfs 还支持快速简便的远程备份。子卷快照可以 发送到远程系统 进行存储。通过利用文件系统中固有的 COW 元数据，这些传输通过仅发送先前发送的快照中的增量更改而非常有效。诸如 snapper 之类的用户应用程序使管理这些快照变得容易。\n另外，Btrfs 卷可以具有 透明压缩 功能，并且 chattr +c 可以标记进行压缩的单个文件或目录。压缩不仅可以减少数据消耗的空间，还可以通过减少写入操作量来帮助延长 SSD 的寿命。压缩当然会带来额外的 CPU 开销，但是有很多选项就可以权衡取舍。\nBtrfs 集成了文件系统和卷管理器功能，这意味着总体维护比 LVM-ext4 更简单。当然，这种集成的灵活性较低，但是对于大多数台式机甚至服务器而言，设置已足够。\nLVM 上使用 Btrfs Btrfs 可以 就地转换 ext3/ext4 文件系统。就地转换意味着无需将数据复制出来然后再复制回去。数据块本身甚至都不需要修改。因此，对于现有的 LVM-ext4 系统，一种选择是将 LVM 保留在原处，然后简单地将 ext4 转换为 Btrfs。虽然可行且受支持，但有一些原因使它不是最佳选择。\nBtrfs 的吸引力之一是与卷管理器集成的文件系统所带来的更轻松的管理。要是在 LVM 之上运行，对于系统维护，仍然要对额外的卷管理器进行一些设置。同样，LVM 设置通常具有多个固定大小的逻辑卷，并具有独立文件系统。虽然 Btrfs 支持给定的计算机上的多个卷，但是许多不错的功能都需要单一卷具有多个子卷。如果每个 LVM 卷都有一个独立的 Btrfs 卷，则用户仍然需要手动管理固定大小的 LVM 卷。虽然能够收缩挂载的 Btrfs 文件系统的能力确实使处理固定大小的卷的工作变得更轻松。通过在线收缩功能，就无需启动 实时镜像 了。\n在使用 Btrfs 的多设备支持时，必须仔细考虑逻辑卷的物理位置。对于 Btrfs 而言，每个逻辑卷都是一个单独的物理设备，如果实际情况并非如此，则某些数据可用性功能可能会做出错误的决定。例如，如果单个驱动器发生故障，对数据使用 RAID1 通常可以提供保护。如果实际逻辑卷在同一物理设备上，则没有冗余。\n如果强烈需要某些特定的 LVM 功能，例如原始块设备或高速缓存的逻辑卷，则在 LVM 之上运行 Btrfs 是有意义的。在这种配置下，Btrfs 仍然提供其大多数优点，例如校验和和易于发送的增量快照。尽管使用 LVM 会产生一些操作开销，但 Btrfs 的这种开销并不比任何其他文件系统大。\n总结 当尝试在 Btrfs 和 LVM-ext4 之间进行选择时，没有一个正确的答案。每个用户都有独特的要求，并且同一用户可能拥有具有不同需求的不同系统。看一下每个配置的功能集，并确定是否有令人心动的功能。如果没有，坚持默认值没有错。选择这两种设置都有很好的理由。\nSnapper Snapper 是 openSUSE 下用于创建和管理文件系统快照（以下简称快照）的工具。快照保存了文件系统在某个时间点的状态，从而可以轻松实现系统回滚或数据备份。\nSnapper 可以在 Btrfs 文件系统（推荐）及采用 XFS 或 Ext4 文件系统的 LVM 精简配置卷上使用，本文主要介绍在 Btrfs 文件系统上使用 Snapper 的方法。\n快照类型 Snapper 快照可分为两大类型：\n 快照对：由一对快照组成，在进行某项操作前拍摄一个“前快照”（pre），操作后再拍摄一个“后快照”（post），从而可以比较两个快照对差异而撤销该操作。快照对是一一对应的，如果删除了某一快照，则对应的快照也会被删除。 单一快照（single）：由一个单独的快照组成，与其他快照没有特殊联系。可用于备份或回滚整个系统等操作。  快照对和单一快照既可以手动创建，也可以根据配置自动创建。自动创建的快照又可分为三种类型：\n 时间线快照：每小时自动创建的单一快照。 安装快照：在安装软件包前后自动创建的一对快照对。可用于撤销软件包更改。 管理快照：在使用 YaST 管理系统前后自动创建的一堆快照对。可用于撤销配置更改。  这三种自动创建的快照均可单独启用和配置，从而提供了极大的灵活性。\n默认配置 要在分区或 Btrfs 子卷启用快照，需要创建配置文件。Snapper 的配置文件存储在 /etc/snapper/configs 中。\n如果你的根分区大于 16 GB，并且在安装 openSUSE 时使用默认分区配置，则根分区的配置文件应已被自动创建。默认配置启用了安装快照和管理快照，并排除了部分目录，可以满足大多数需求。以下列表显示了排除的所有目录：\n  /boot/grub2/i386-pc、/boot/grub2/x86_64-efi、/boot/grub2/powerpc-ieee1275、/boot/grub2/s390x-emu\n不能回滚引导加载程序配置。上面列出的目录是架构专属目录。前两个目录位于 AMD64/Intel 64 计算机上，后两个目录分别位于 IBM POWER 和 IBM Z 上。\n  /home\n如果独立的分区中没有 /home，便会将该目录排除以免在回滚时发生数据丢失。\n  /opt、/var/opt\n第三方产品通常安装到 /opt 下。排除此目录是为了防止在回滚时卸装这些应用程序。\n  /srv\n包含 Web 和 FTP 服务器的数据。排除此目录是为了防止在回滚时发生数据丢失。\n  /tmp、/var/tmp、/var/cache、/var/crash\n包含临时文件和超速缓存的所有目录都会排除在快照范围之外。\n  /usr/local\n在手动安装软件时会用到此目录。系统会将该目录排除以免在回滚时卸载这些安装的软件。\n  /var/lib/libvirt/images\n使用 libvirt 管理的虚拟机映像的默认位置。为确保回滚期间虚拟机映像不会替换为旧版本而被排除。默认情况下，此子卷是使用写入时不复制选项创建的。\n  /var/lib/mailman、/var/spool\n包含邮件或邮件队列的目录会排除，以免在回滚后造成邮件丢失。\n  /var/lib/bind\n包含 DNS 服务器的区域数据。排除该目录是为了确保回滚后名称服务器仍能运作。\n  /var/lib/mariadb、/var/lib/mysql、/var/lib/pgqsl\n这些目录包含数据库数据。默认情况下，这些子卷是使用写入时不复制选项创建的。\n  /var/log\n日志文件所在的位置。排除该目录是为了在对受损的系统进行回滚后能够对日志文件进行分析。\n  如果你希望使用 openSUSE 的默认配置，但在安装 openSUSE 时未开启快照功能，可以使用以下命令创建根分区的默认配置文件：\n注意： 要使用该默认配置文件，请确保根分区大小至少为 16 GB，并使用 openSUSE 安装程序建议的包含子卷的 Btrfs 根文件系统（安装程序默认分区设置）\nsnapper -c root create-config / 确保 snapper-zypp-plugin 软件包已安装以启用安装快照：\nzypper install snapper-zypp-plugin 手动配置 创建和装入新子卷 系统支持在 / 层次下创建新的子卷，并永久性装入该卷。此类子卷将从快照中排除。切勿在现有快照中创建此类子卷，因为在回滚之后，您将无法再删除快照。\nSUSE Linux Enterprise Server 上配置了 /@/ 子卷，该子卷充当永久性子卷（例如 /opt、/srv、/home 等）的独立根目录。您创建和永久装入的任何新子卷都需要在这个初始根文件系统中创建。\n为此，请运行以下命令。在此示例中，从 /dev/sda2 创建了一个新子卷 /usr/important。\nsudo mount /dev/sda2 -o subvol=@ /mntsudo btrfs subvolume create /mnt/usr/importantsudo umount /mnt /etc/fstab 中的相应项需类似于：\n/dev/sda2 /usr/important btrfs subvol=@/usr/important 0 0 提示：子卷可能包含经常更改的文件，例如虚拟化的磁盘映像、数据库文件或日志文件。如果是这样，可考虑对此卷禁用写入时复制功能，以免复制磁盘块。可在 /etc/fstab 中使用 nodatacow 装入选项来实现此目的：\n/dev/sda2 /usr/important btrfs nodatacow,subvol=@/usr/important 0 0 或者，要为单个文件或目录禁用写入时复制功能，请使用命令 chattr +C 路径。\n创建配置文件 希望在特定分区或子卷启用快照，可以以下命令创建相应的配置文件：\nsnapper -c 配置文件名 create-config 分区或子卷的挂载点 这将根据 /etc/snapper/config-templates/default 提供的默认值创建配置文件。\n注意： 在创建配置文件前请确保目标分区或子卷已被创建。不能为同一分区或子卷创建多个配置文件。\n例如，为防止回滚时数据丢失，默认的根分区配置排除了 /home 目录，可以使用上述命令为 /home 创建配置文件：\nsnapper -c home create-config /home 该命令会使用 /etc/snapper/config-templates/default 提供的默认值创建 /etc/snapper/configs/home 文件。\n可以使用\nsnapper list-configs 查看现有配置文件。\n启用/禁用自动快照 你可以选择性地启用/禁用自动创建的快照类型：\n启用时间线快照\nsnapper -c 配置文件名 set-config \u0026quot;TIMELINE_CREATE=yes\u0026quot; 禁用时间线快照\nsnapper -c 配置文件名 set-config \u0026quot;TIMELINE_CREATE=no\u0026quot; 时间线快照默认会启用，但根分区除外。\n注意： 以下两种快照包含的内容由安装的软件包或修改的配置而定，与特定分区或子卷无关。默认为启用状态。\n启用安装快照\nzypper install snapper-zypp-plugin 禁用安装快照\nzypper remove snapper-zypp-plugin 使用 YaST 或 Zypper 安装包时所创建的快照会由 snapper-zypp-plugin 进行处理。何时创建快照由 XML 配置文件 /etc/snapper/zypp-plugin.conf 定义。\n启用管理快照\n在 /etc/sysconfig/yast2 中将 USE_SNAPPER 设置为 yes 禁用管理快照\n在 /etc/sysconfig/yast2 中将 USE_SNAPPER 设置为 no 配置文件参数 Snapper 的行为由配置文件参数定义，除了直接使用文本编辑器编辑配置文件外，还可以使用\nsnapper -c 配置文件名称 set-config \u0026quot;参数名称=参数\u0026quot; 修改配置文件参数。\n以下对几个常用配置案例进行说明，完整的参数说明可参阅 snapper-configs(5) ：\nman snapper-configs 允许普通用户管理快照\n默认情况下仅 root 用户可以管理快照，要允许普通用户或组管理快照，可运行：\nsnapper -c 配置文件名称 set-config \u0026quot;ALLOW_USERS=用户名\u0026quot; \u0026quot;ALLOW_GROUPS=组名\u0026quot; \u0026quot;SYNC_ACL=yes\u0026quot; 必须配置“SYNC_ACL=yes”以允许普通用户访问快照所在目录。\n自动清理旧快照\n为防止快照占据全部磁盘空间，Snapper 提供了几种自动清理旧快照的机制，可通过一系列参数配置自动清理过程：\n   清理机制 说明 启用选项 配置参数 含义 备注     编号 根据快照编号进行清理 NUMBER_CLEANUP=yes NUMBER_LIMIT=数字或范围 定义要保留的快照数量。 如果启用了定额支持，应使用范围。如果未启用定额支持，应使用单个数字。   NUMBER_LIMIT_IMPORTANT=数字或范围 定义要保留的含 important 标签的快照数量，内核更新等的安装快照自带该标签。       NUMBER_MIN_AGE=秒 定义满足上述条件的快照被清理前最少应保留的时间。0 表示无限制。       时间线 根据快照创建时间进行清理 TIMELINE_CLEANUP=yes TIMELINE_LIMIT_HOURLY=数字或范围 定义要保留的每小时首张快照的数量。 如果启用了定额支持，应使用范围。如果未启用定额支持，应使用单个数字。   TIMELINE_LIMIT_DAILY=数字或范围 定义要保留的每日首张快照的数量。       TIMELINE_LIMIT_WEEKLY=数字或范围 定义要保留的每周首张快照的数量，此处的周由星期一开始。       TIMELINE_LIMIT_MONTHLY=数字或范围 定义要保留的每月首张快照的数量。       TIMELINE_LIMIT_YEARLY=数字或范围 定义要保留的每年首张快照的数量。       TIMELINE_MIN_AGE=秒 定义满足上述条件的快照被清理前最少应保留的时间。0 表示无限制。       无差异快照对 清理没有差异的快照对。如运行 Yast2 后未作任何修改，则自动清理创建的管理快照。 EMPTY_PRE_POST_CLEANUP=yes EMPTY_PRE_POST_CLEANUP=秒 定义无差异快照对被清理前最少应保留的时间。0 表示无限制。    磁盘定额 定义快照可占用空间的百分比 运行snapper setup-quota SPACE_LIMIT=表示百分比的小数 定义快照可占用空间的百分比 仅支持 Btrfs 文件系统需至少启用编号或时间线清理算法中的一个启用定额支持后，编号和时间线清理算法的部分参数应当使用范围值。清理算法会清理快照至上限值，如果未满足定额配置则在下限值范围内尽量清理快照以满足定额。    管理配置文件 可以使用 snapper 命令快速管理配置文件：\n列出配置文件\nsnapper list-configs 显示特定的配置文件\nsnapper -c 配置文件名称 get-config 删除配置文件\nsnapper -c 配置文件名称 delete-config 快照管理 可以使用 snapper 工具或 Yast2 模块进行查看、创建、比较快照等操作。\nsnapper 工具提供了一系列子命令，可以在文本界面进行快照管理。本节介绍了一些常用命令和参数，更多信息可参阅 snapper(8)：\nman snapper 注意： 管理快照时可使用 “-c 配置文件名” 指定配置文件，如未指定则默认使用 root 配置文件，下述示例均未指定配置文件。\n查看快照\nsnapper list 将列出 root 配置的所有快照。\n可以使用 “-t” 参数列出特定类型的快照。\n例如，列出 root 配置下的所有快照对：\nsnapper list -t pre-post 列出 home 配置下的所有单一快照：\nsnapper -c home list -t single 你还可以使用\nsnapper list -a 列出所有配置下的快照。\n创建快照\nsnapper create 将使用 root 配置文件创建一个单一快照。\n可以使用“-t”参数指定快照类型（默认值为 single），使用“-d”参数添加描述。手动创建的快照默认不会自动被清理，使用“\u0026ndash;cleanup-algorithm”参数指定自动清理算法。还可以使用“\u0026ndash;userdata”参数定义自定义数据（如 important 标记）。\n例如，创建当前系统的单一快照，标记为重要，并指定时间线清理算法：\nsnapper create -t single --description \u0026quot;系统快照\u0026quot; --userdata \u0026quot;important=yes\u0026quot; --cleanup-algorithm timeline 要创建一个快照对，首先创建一个前快照，使用“\u0026ndash;print-number”选项以列出快照编号：\nsnapper create -t pre --print-number --description \u0026quot;Before\u0026quot; 假设列出的快照编号为 30，将其作为“\u0026ndash;pre-number”参数的值创建后快照：\nsnapper create -t post --pre-number 30 --description \u0026quot;After\u0026quot; 你也可以使用\nsnapper create --command \u0026quot;要运行的命令\u0026quot; 以自动创建运行命令前后的快照对。\n比较快照\n有两种比较方法：\nsnapper status \u0026lt;第一个快照编号\u0026gt;..\u0026lt;第二个快照编号\u0026gt; //第一个快照的创建时间要早于第二个 将显示您在两个快照时间内修改的全部文件的路径和文件名。\n例如，下述命令可以比较当前系统状态与 161 号快照的差异：\nsnapper status 161..0 //0 表示当前系统，它不是快照，但你可以认为是比所有快照都新的一个快照。 第二种：\nsnapper diff \u0026lt;第一个快照编号\u0026gt;..\u0026lt;第二个快照编号\u0026gt; 文件名 将以 diff 的格式显示指定文件的差异，如果未指定文件名，将显示所有文件的差异。\n撤销修改\nsnapper undochange \u0026lt;修改前的快照编号\u0026gt;..\u0026lt;修改后的快照编号\u0026gt; \u0026lt;文件名\u0026gt; 比如你误删除了某个文件，可以使用：\nsnapper undochange \u0026lt;删除文件前的快照编号\u0026gt;..0 文件名 //0 表示当前系统，它不是快照，但你可以认为是比所有快照都新的一个快照。 来撤销。\n删除快照\nsnapper delete 快照编号或范围 例如，要删除 16 号快照：\nsnapper delete 16 要删除 10 号到 15 号快照：\nsnapper delete 10-15 可以结合“-s”参数以在删除快照后立刻释放可用空间而不必等待 Btrfs 进程回收。\n回滚整个系统\nSUSE Linux Enterprise Server 上包含的 GRUB 2 版本可以从 Btrfs 快照进行引导。与 Snapper 的回滚功能相结合，就能恢复配置错误的系统。只有针对默认 Snapper 配置（根）创建的快照才可引导。\n注意： 要回滚整个系统，请确保根文件系统为 openSUSE 安装程序默认的带子卷的 Btrfs 文件系统。从 SUSE Linux Enterprise Server 15 开始，只有在根分区的默认子卷配置未更改过的情况下，才支持系统回滚。\n如果因为更新或病毒等原因导致系统出现重大错误，并保留了错误前的快照，则可以回滚整个系统到错误前的状态。\nsnapper rollback 要回滚的快照编号 该命令将创建当前系统状态的只读快照 A 及指定编号快照的可读写快照 B，并使用快照 B 替换根分区的默认子卷，重新启动系统后即可实现回滚。\n你还可以在引导系统时选择Start bootloader from a read-only snapshot，以引导想要回滚的快照，在检查无误后在引导的快照中执行：\nsnapper rollback 不指定快照编号时，将创建根分区默认子卷（即原系统）的只读快照 A 和当前系统（即目前引导的快照）的可读写快照 B，并使用快照 B 替换根分区的默认子卷，重新启动系统后选择默认引导项即可实现回滚。\nFirewall-cmd firewall-cmd(firewalld command line client) 是 firewalld 的主要命令行工具。它可以用来获取 firewalld 的状态信息，获取运行时和永久环境的防火墙配置，也可以用来修改这些配置。\n基本概念 firewalld 将所有的网络数据流量划分为多个区域，再根据数据包的源IP地址或传入网络接口等条件，将数据流量转入相应区域的防火墙规则中。\n block：拒绝所有传入的网络连接。只有从系统内部发起的网络连接才可能有效； dmz：隔离区域也称为非军事化区域，为您的局域网提供有限的访问权限，并且只允许选定的传入端口； drop：终止所有传入链接，只允许传出的链接； external：对路由器类型的连接很有用。你需要局域网和广域网的接口来进行伪装（NAT）才能正常工作。 home：适用于家庭电脑，如局域网内的笔记本电脑和台式机，您可以信任其他电脑。只允许选定的 TCP/IP 端口； internal：用于内部网络，当你几乎信任局域网内的其他服务器或计算机时； public（系统默认值）：适用于始终处于公共区域的云服务器或托管在您处的服务器。您不信任网络上的任何其他计算机和服务器。您只允许使用所需的端口和服务； trusted：允许任何的网络链接； work：适用于您信任您的同事和其他服务器的工作场所。  查看默认区域：\n$ firewall-cmd --get-default-zone 当 NetworkManager 添加新的接口连接（如 eth0 或 ens3）时，它们将被连接到默认的区域。通过运行以下命令进行验证：\n$ firewall-cmd --get-active-zones 服务（services） 服务是一个包含了本地端口、协议、源端口、目的地和防火墙帮助模块 (firewall helper modules) 的列表。\n查询服务 # 查询当前区域允许的服务 $ sudo firewall-cmd --list-services # 查询特定区域允许的服务 $ sudo firewall-cmd --list-services --zone=[区域] # 查询全部区域的服务或防火墙规则 $ sudo firewall-cmd --list-all-zones 如查询与 public 相关的防火墙规则或服务：\n$ sudo firewall-cmd --list-all --zone=public public (active) target: default icmp-block-inversion: no interfaces: wlan0 sources: services: dhcpv6-client ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: 在该查询结果中，默认区域是 public ，允许的服务是 dhcpv6-client 。\n删除服务 $ sudo firewall-cmd --remove-service=[服务] --permanent --zone=[区域] $ sudo firewall-cmd --reload \u0026ndash;permanent 指定永久规则则。运行时的 firewalld 配置更改是临时性的，当你重新启动 openSUSE 或 firewalld 时，它们就会消失。而永久规则则不受影响。\n添加服务 $ sudo firewall-cmd --add-service=[服务] --permanent --zone=[区域] $ sudo firewall-cmd --reload sudo 许多命令和系统实用程序都需要以 root 身份运行才能执行。为了确保安全和避免发生意外运行危险命令，通常建议不要直接以 root 身份登录。建议的做法是以非特权的普通用户身份工作，并使用 sudo 命令来运行需要较高特权的命令。\n在 SUSE Linux Enterprise Server 上，sudo 默认配置与 su 的工作方式类似。但是，sudo 可让用户以高度可配置的方式使用任何其他用户的特权来运行命令。这样，便可为某些用户和组指派具有特定特权的角色。举例来说，可以允许组 users 的成员使用 wilber 的特权运行命令。通过禁止指定任何命令选项，可以进一步限制对命令的权限。虽然 su 始终需要 root 口令才能使用 PAM 进行身份验证，但是您可以将 sudo 配置为使用您自己的身份凭证进行身份验证。这样就不需要共享 root 口令，从而提高了安全性。\nsudo 基本用法 虽然 sudo 简单易用，功能却十分强大。\n运行单个命令 以普通用户身份登录后，您可以在命令前加上 sudo 以 root 身份运行任何命令。按照提示输入口令后，如果身份验证成功，您便能以 root 身份运行命令：\n# id -un 命令会打印当前用户的登录名 $ id -un tux # 在输入过程中不会显示口令，无论是明文还是密文均不显示。  $ sudo id -un root\u0026#39;s password: root # 只有以 sudo 开头的命令才会使用较高的特权运行。如果是不带 sudo 前缀的相同命令，仍会使用当前用户的特权运行。  $ id -un tux # 在限定时间内，您无需再次输入 root 口令。  $ sudo id -un root I/O 重定向的工作方式与您预期的可能不同：\n$ sudo echo s \u0026gt; /proc/sysrq-trigger bash: /proc/sysrq-trigger: Permission denied $ sudo cat \u0026lt; /proc/1/maps bash: /proc/1/maps: Permission denied 只有 echo/cat 二进制会使用较高特权运行，重定向则由用户外壳使用用户特权执行。您可以按启动外壳中所述启动外壳，也可以使用 dd 实用程序来启动：\n$ echo s | sudo dd of=/proc/sysrq-trigger $ sudo dd if=/proc/1/maps | cat 启动外壳 必须在每条命令前加上 sudo 可能很繁琐。虽然可以将外壳指定为命令 sudo bash，但还是建议您使用以下其中一种内置机制来启动外壳：\n  sudo -s (\u0026lt;命令\u0026gt;)\n启动 SHELL 环境变量所指定的外壳或目标用户的默认外壳。如果给定了命令，则会将该命令传递给外壳（使用 -c 选项），否则外壳会以交互模式运行。\n$ sudo -s root's password: $ exit   sudo -i (\u0026lt;命令\u0026gt;)\n  与 -s 类似，但是会将外壳启动为登录外壳。也就是说，系统会对外壳的启动文件（.profile 等）进行处理，并会将当前的工作目录设置为目标用户的主目录。\n$ sudo -i root's password: $ exit   环境变量 默认情况下，sudo 不会传播环境变量：\n$ ENVVAR=test env | grep ENVVAR ENVVAR=test $ ENVVAR=test sudo env | grep ENVVAR root's password: $ 输出为空即表明在使用 sudo 运行的命令的环境中不存在环境变量 ENVVAR。\n此行为可通过 env_reset 选项进行更改，请参见下文有用的标志和选项。\n配置 sudo sudo 是一个非常灵活的工具，提供各种配置选项。\n注意：如果您不小心将自己锁定在 sudo 之外，则可以使用 su - 及 root 口令来获取 root 外壳。要修复该错误，请运行 visudo。\n编辑配置文件 sudo 的主要策略配置文件为 /etc/sudoers。如果此文件中存在错误，您可能便会无法进入系统，因此强烈建议您使用 visudo 来编辑配置文件。此举可防止同时更改打开的文件，并会在保存修改之前检查语法错误。\n您还可以通过设置 EDITOR 环境变量来使用除 vi 以外的编辑器（不论名字如何），例如：\n$ sudo EDITOR=/usr/bin/nano visudo 不过，/etc/sudoers 文件本身是由系统包提供的，更新时这些修改可能会取消。因此，建议您将自定义配置放到 /etc/sudoers.d/ 目录下的文件中。该目录下的任何文件都会自动纳入系统中。要在该子目录下创建或编辑文件，请运行：\nsudo visudo -f /etc/sudoers.d/NAME 或者，使用其他编辑器（例如 nano）：\nsudo EDITOR=/usr/bin/nano visudo -f /etc/sudoers.d/NAME 注意：/etc/sudoers 中的 #includedir 命令（用于 /etc/sudoers.d）会忽略以 ~（波浪号）结尾或包含 .（点）的文件。\n关于 visudo 命令的详细信息，请运行 man 8 visudo。\nsudoers 基本配置语法 在 sudoers 配置文件中，有两种类型的选项：字符串和标志。字符串可以包含任何值，而标志则只能在“ON”或“OFF”之间切换。sudoers 配置文件最重要的语法构造为：\n# Everything on a line after a # gets ignored, Defaults !insults # Disable the insults flag Defaults env_keep += \u0026quot;DISPLAY HOME\u0026quot; # Add DISPLAY and HOME to env_keep tux ALL = NOPASSWD: /usr/bin/frobnicate, PASSWD: /usr/bin/journalctl  #include 和 #includedir 这两个普通命令例外。其后跟数字，用于指定 UID。 去除 ! 可将指定的标志设置为“ON”。  有用的标志和选项\n   选项名称 说明 示例     targetpw 此标志控制调用用户是需要输入目标用户（例如 root）的口令 (ON) 还是需要输入调用用户的口令 (OFF)。 Defaults targetpw # Turn targetpw flag ON   rootpw 如果设置了该选项，sudo 会提示输入 root 口令，而非目标用户或调用者的口令。默认值为“OFF”。 Defaults !rootpw # Turn rootpw flag OFF   env_reset 如果设置了该选项，sudo 会构造一个仅包含 TERM、PATH、HOME、MAIL、SHELL、LOGNAME、USER、USERNAME 和 SUDO_* 集的最小环境。此外，会从调用环境导入 env_keep 中列出的变量。默认值为“ON”。 Defaults env_reset # Turn env_reset flag ON   env_keep env_reset 标志设为“ON”时要保留的环境变量列表。 # Set env_keep to contain EDITOR and PROMPT Defaults env_keep = \u0026quot;EDITOR PROMPT\u0026quot; Defaults env_keep += \u0026quot;JRE_HOME\u0026quot; # Add JRE_HOME Defaults env_keep -= \u0026quot;JRE_HOME\u0026quot; # Remove JRE_HOME   env_delete env_reset 标志设为“OFF”时要去除的环境变量列表。 # Set env_delete to contain EDITOR and PROMPT Defaults env_delete = \u0026quot;EDITOR PROMPT\u0026quot; Defaults env_delete += \u0026quot;JRE_HOME\u0026quot; # Add JRE_HOME Defaults env_delete -= \u0026quot;JRE_HOME\u0026quot; # Remove JRE_HOME    还可以使用 Defaults 令牌为用户、主机和命令集合创建别名。并且，可以仅将选项应用到特定用户集。\n关于 /etc/sudoers 配置文件的详细信息，请参见 man 5 sudoers。\nsudoers 中的规则 sudoers 配置中的规则可能会非常复杂，因此本节仅涉及基本内容。每个规则都遵循基本模式（[] 标记的是可选部分）：\n#Who Where As whom Tag What User_List Host_List = [(User_List)] [NOPASSWD:|PASSWD:] Cmnd_List   User_List\n一个或多个（用 , 分隔）标识符：用户名、格式为 %GROUPNAME 的组或格式为 #UID 的用户 ID。可以使用 ! 前缀来取反。\n  Host_List\n一个或多个（用 , 分隔）标识符：（完全限定的）主机名或 IP 地址。可以使用 ! 前缀来取反。Host_List 的惯常选项为 ALL。\n  NOPASSWD:|PASSWD:\n如果用户在 NOPASSWD: 后面运行的命令与 CMDSPEC 匹配，系统不会提示用户输入口令。\nPASSWD 为默认选项，仅当两个选项位于同一行时才需要指定它：\ntux ALL = PASSWD: /usr/bin/foo, NOPASSWD: /usr/bin/bar   Cmnd_List\n一个或多个（用 , 分隔）区分符：可执行文件的路径，后跟允许使用的自变量或什么也不跟。\n/usr/bin/foo # Anything allowed /usr/bin/foo bar # Only \u0026quot;/usr/bin/foo bar\u0026quot; allowed /usr/bin/foo \u0026quot;\u0026quot; # No arguments allowed   ALL 可以用作 User_List、Host_List 和 Cmnd_List。\n允许 tux 在无需输入口令的情况下以 root 身份运行所有命令的规则：\ntux ALL = NOPASSWD: ALL 允许 tux 运行 systemctl restart apache2 的规则：\ntux ALL = /usr/bin/systemctl restart apache2 允许 tux 在不带自变量的情况下以 admin 身份运行 wall 的规则：\ntux ALL = (admin) /usr/bin/wall \u0026quot;\u0026quot; 警告：以下类型的构造\nALL ALL = ALL 在没有 Defaults targetpw 的情况下切勿使用，否则任何人都能以 root 身份运行命令。\n常见使用情况 尽管默认配置对于简单的设置和桌面环境通常已经够用，但是自定义配置非常有用。\n在无需 root 口令的情况下使用 sudo 在具有特殊限制（“用户 X 只能以 root” 身份运行命令 Y）的情况下，无法实现此目的。在其他情况下，还是建议进行某种分隔。按照惯例，组 wheel 的成员能以 root 身份运行所有带有 sudo 的命令。\n  将自己添加到 wheel 组\n如果您自己的用户帐户尚不是 wheel 组的成员，请添加该帐户，具体做法是运行 sudo usermod -a -G wheel 用户名然后注销并再次登录。运行 groups 用户名以确认更改是否成功。\n  将使用调用用户的口令进行身份验证的选项设为默认设置。\n使用 visudo 创建文件 /etc/sudoers.d/userpw并添加：\nDefaults !targetpw   选择新默认规则。\n根据是否想要用户重新输入口令，取消对 /etc/sudoers 中特定行的注释，并将默认规则注释掉。\n## Uncomment to allow members of group wheel to execute any command # %wheel ALL=(ALL) ALL ## Same thing without a password # %wheel ALL=(ALL) NOPASSWD: ALL   提高默认规则的限制性\n将 /etc/sudoers 中允许一切操作的规则注释掉或去除：\nALL ALL=(ALL) ALL # WARNING! Only use this together with 'Defaults targetpw'!   警告：切勿漏掉这一步，否则任何用户都能以 root 身份执行任何命令。\n  测试配置\n尝试以 wheel 的成员和非成员身份运行 sudo。\n# user tux $ groups users wheel $ sudo id -un tux's password: root # use wilber $ groups users $ sudo id -un wilber is not in the sudoers file. This incident will be reported.   对 X.Org 应用程序使用 sudo 在使用 sudo 启动图形应用程序时，可能会出现以下错误：\n$ sudo xterm xterm: Xt error: Can't open display: %s xterm: DISPLAY is not set YaST 会选择 ncurses 界面而非图形界面。\n要在通过 sudo 启动的应用程序中使用 X.Org，需要传播环境变量 DISPLAY 和 XAUTHORITY。要进行此项配置，请创建文件 /etc/sudoers.d/xorg并添加下面一行：\nDefaults env_keep += \u0026quot;DISPLAY XAUTHORITY\u0026quot; 如尚未设置 XAUTHORITY 变量，请按如下方式设置：\nexport XAUTHORITY=~/.Xauthority 现在，X.Org 应用程序便可正常运行：\nsudo yast2 Zypper Zypper 是用于安装、更新和去除包的命令行包管理器。它还可管理储存库。这一点对于完成远程软件管理任务或从外壳脚本管理软件尤其有用。\n一般使用 Zypper 的常用语法为：\nzypper [--global-options] COMMAND [--command-options] [arguments] 有关常规选项和所有命令的列表，请参见 zypper help。要获取有关特定命令的帮助，请键入 zypper help 命令。\n  Zypper 命令\n执行 Zypper 最简单的方式是，键入其名称后跟一个命令。例如，要将所有需要的增补程序应用于系统，请使用：\n$ sudo zypper patch   全局选项\n此外，您还可以选择使用一个或多个全局选项，只需在命令前面键入它们即可：\n$ sudo zypper --non-interactive patch 在上面的示例中，选项 --non-interactive 表示在不询问任何问题的情况下运行命令（自动应用默认回答）。\n  命令特定的选项\n要使用特定于某个命令的选项，请紧接在该命令后面键入这些选项：\n$ sudo zypper patch --auto-agree-with-licenses 在上面的示例中，--auto-agree-with-licenses 用于将所有需要的增补程序应用于系统，不要求您确认任何许可条款，而是自动接受许可条款。\n  自变量\n某些命令需要一个或多个自变量。例如，使用 install 命令时，需要指定您要安装的一个或多个包：\n$ sudo zypper install mplayer 某些选项还需要单个自变量。用以下命令可列出所有已知模式：\n$ zypper search -t pattern   您可以组合上述所有模式。例如，下面的命令在冗长模式下运行时将安装 mc and vim 包（来自 factory 储存库）：\n$ sudo zypper -v install --from factory mc vim --from 选项确保了在从指定储存库请求包时保留所有储存库的启用状态（用于解析任何依赖项）。\n多数 Zypper 命令都有 dry-run 选项，它模拟给定的命令。它可用于测试。\n$ sudo zypper remove --dry-run MozillaFirefox Zypper 支持 --userdata 字符串全局选项。您可以使用此选项指定一个将会写入 Zypper 的日志文件和插件（例如 Btrfs 插件）的字符串。它可以用于标记和标识日志文件中的事务。\n$ sudo zypper --userdata STRING patch 使用 Zypper 安装和删除软件 要安装或去除包，请使用以下命令：\n$ sudo zypper install PACKAGE_NAME$ sudo zypper remove PACKAGE_NAME 警告：不要去除必需的系统包，例如 glibc 、zypper、kernel。如果去除这些包，系统可能会变得不稳定，或完全停止工作。\n选择要安装或去除的包 可以使用 zypper install 和 zypper remove 命令通过多种方法来找到包。\n  按确切的包名称\n$ sudo zypper install MozillaFirefox   按确切的包名称和版本号\n$ sudo zypper install MozillaFirefox-52.2   按储存库别名和包名称\n$ sudo zypper install mozilla:MozillaFirefox 其中 mozilla 是用于安装的储存库别名。\n  使用通配符按包名称\n您可以选择名称以特定字符串开头或结尾的所有包。使用通配符要小心，特别是去除包的时候。以下命令将安装名称以“Moz”开头的所有包：\n$ sudo zypper install 'Moz*' 提示：在调试问题时，您有时需要临时安装大量的 -debuginfo 包，以获取有关正在运行的进程的详细信息。在调试会话完成后，如果您需要清理环境，请运行以下命令：\n$ sudo zypper remove '*-debuginfo'   按功能\n例如，要安装不知道名称的包，这些功能就很有用。下面的命令将安装包 MozillaFirefox：\n$ sudo zypper install firefox   按功能、硬件体系结构或版本\n  所需硬件体系结构的名称需要追加在功能的后面，两者以句点分隔。例如，要指定 AMD64/Intel 64 体系结构（在 Zypper 中命名为 x86_64），请使用：\n$ sudo zypper install 'firefox.x86_64'   版本必须追加到字符串的末尾，并且前面必须带有一个运算符：\u0026lt;（小于）、\u0026lt;=（小于等于）、=（等于）、\u0026gt;=（大于等于）或 \u0026gt;（大于）。\n$ sudo zypper install 'firefox\u0026gt;=52.2'   还可以指定硬件体系结构与版本组合要求：\n$ sudo zypper install 'firefox.x86_64\u0026gt;=52.2'     按 RPM 文件的路径\n您还可以指定包的本地或远程路径：\n$ sudo zypper install /tmp/install/MozillaFirefox.rpm$ sudo zypper install http://download.example.com/MozillaFirefox.rpm   同时安装和去除包 要同时安装和去除包，请使用 +/- 修饰符。要安装 emacs 并同时去除 vim ，请使用：\n$ sudo zypper install emacs -vim 要去除 emacs 并同时安装 vim ，请使用：\n$ sudo zypper remove emacs +vim 为避免 - 开头的包名称被解释为命令行选项，要始终把它用作第二个自变量。如果做不到这点，在它之前加上 --：\n$ sudo zypper install -emacs +vim # Wrong$ sudo zypper install vim -emacs # Correct$ sudo zypper install -- -emacs +vim # Correct$ sudo zypper remove emacs +vim # Correct 清理已去除包的依赖项 如果您想将在指定的包去除后不再需要的所有包（随指定的包）自动去除，请使用 --clean-deps 选项：\n$ sudo zypper rm PACKAGE_NAME --clean-deps 在脚本中使用 Zypper 默认情况下，在安装或删除选定包之前发生问题时，Zypper 会要求确认。您可以使用 --non-interactive 选项覆盖此行为。必须在实际命令（install、remove 和 patch）的前面指定此选项，如下所示：\n$ sudo zypper --non-interactive install PACKAGE_NAME 该选项允许在脚本和 cron 任务中使用 Zypper。\n安装或下载源包 要安装某个包的对应源代码包，请使用：\n$ zypper source-install PACKAGE_NAME 以 root 身份执行时，源包的默认安装位置为 /usr/src/packages/；以用户身份运行时，则为 ~/rpmbuild。可以在本地 rpm 配置中更改这些值。\n使用此命令还会安装指定包的版本依赖项。如果不想执行此操作，请添加开关 -D：\n$ sudo zypper source-install -D PACKAGE_NAME 要只安装版本依赖项，请使用 -d。\n$ sudo zypper source-install -d PACKAGE_NAME 当然，只有当储存库列表中启用了含有源包的储存库时，才能这样做（默认添加但不启用它）。\n可使用以下方法来获取储存库中所有源包的列表：\n$ zypper search -t srcpackage 您也可以将所有已安装软件包的源包下载到本地目录。要下载源包，请使用：\n$ zypper source-download 默认的下载目录是 /var/cache/zypper/source-download。您可以使用 --directory 选项更改下载目录。若只想显示缺失或多余的包而不进行下载或删除任何内容，请使用 --status 选项。要删除多余的源包，请使用 --delete 选项。要禁用删除，请使用 --no-delete 选项。\n从禁用的储存库安装包 通常，您只能安装或刷新来自启用的储存库的包。--plus-content 标记选项可帮助您指定要刷新的、要在当前 Zypper 会话期间暂时启用的，以及要在会话完成后禁用的储存库。\n例如，要启用可以提供其他 -debuginfo 或 -debugsource 包的储存库，请使用 --plus-content debug。可以多次指定此选项。\n要暂时启用此类“调试”储存库以安装特定的 -debuginfo 包，请按如下所示使用该选项：\n$ sudo zypper --plus-content debug \\ install \u0026quot;debuginfo(build-id)=eb844a5c20c70a59fc693cd1061f851fb7d046f4\u0026quot; 对于缺少的 debuginfo 包，gdb 将会报告 build-id 字符串。\n实用程序 要校验所有依赖项是否仍然满足，并修复缺少的依赖项，请使用：\n$ zypper verify 除了依赖项必须满足外，某些包还“推荐”其他包。只有在实际可用并可安装时才会安装这些推荐包。如果推荐的包在推荐它们的包已安装（通过添加其他包或硬件）之后才可用，请使用以下命令：\n$ sudo zypper install-new-recommends 此命令在插入网络摄像头或 Wi-Fi 设备后非常有用。如果可用，它将安装设备驱动程序和相关软件。只有在满足特定硬件依赖项后，才可安装驱动程序和相关软件。\n使用 Zypper 更新软件 用 Zypper 更新软件有三种方式：安装包、安装包的新版本或更新整个分发包。最后一种方式可通过 zypper dist-upgrade 来实现。\n安装全部所需的增补程序 要安装所有适用于您系统的正式发布的增补程序，请运行：\n$ sudo zypper patch 系统将会检查您计算机上配置的储存库中提供的所有增补程序是否与您的安装相关。如果相关（未分为可选或功能类别），则会立即安装这些增补程序。\n如果即将安装的增补程序所包含的更改要求重引导系统，您会在重引导前收到警告。\n单纯使用 zypper patch 命令不会应用来自第三方储存库的包。要同时更新第三方储存库，请使用 with-update 命令选项，如下所示：\n$ sudo zypper patch --with update 要额外安装可选增补程序，请使用：\n$ sudo zypper patch --with-optional 要安装与特定 Bugzilla 问题相关的所有增补程序，请使用：\n$ sudo zypper patch --bugzilla=NUMBER 要安装与特定 CVE 数据库项相关的所有增补程序，请使用：\n$ sudo zypper patch --cve=NUMBER 例如，要安装 CVE 编号为 CVE-2010-2713 的安全增补程序，请执行：\n$ sudo zypper patch --cve=CVE-2010-2713 如果只想安装影响 Zypper 和包管理本身的增补程序，请使用：\n$ sudo zypper patch --updatestack-only 请记住，如果您使用了 updatestack-only 命令选项，将会丢弃原本还会更新其他储存库的其他命令选项。\n列出增补程序 为了让您确定增补程序是否可用，Zypper 允许您查看以下信息：\n  所需增补程序的数目\n要列出所需增补程序（适用于您的系统但尚未安装的增补程序）的数目，请使用 patch-check：\n$ zypper patch-checkLoading repository data...Reading installed packages...5 patches needed (1 security patch) 可以结合 --updatestack-only 选项使用此命令，以便仅列出影响 Zypper 和包管理本身的增补程序。\n  所需增补程序的列表\n要列出全部所需的增补程序（适用于您的系统但尚未安装的增补程序），请使用 list-patches：\n$ zypper list-patchesLoading repository data...Reading installed packages...Repository | Name | Version | Category | Status | Summary---------------+-------------+---------+----------+---------+---------SLES12-Updates | SUSE-2014-8 | 1 | security | needed | openssl: Update for OpenSSL   所有增补程序的列表\n要列出可用的所有增补程序，而不管它们是否已安装或适用于您的安装，请使用 zypper patches。\n还可以列出并安装与特定问题相关的增补程序。要列出特定的增补程序，请使用带以下选项的 zypper list-patches 命令：\n  按 Bugzilla 问题\n要列出与 Bugzilla 问题相关的全部所需增补程序，请使用 --bugzilla 选项。\n要列出针对特定 Bug 的增补程序，您也可以指定 Bug 编号：--bugzilla=编号。要搜索与多个 Bugzilla 问题相关的增补程序，请在 bug 编号之间添加逗号，例如：\n$ zypper list-patches --bugzilla=972197,956917   按 CVE 编号\n要列出与 CVE（公共漏洞和披露）数据库中某个项相关的全部所需增补程序，请使用 --cve 选项。\n要列出针对特定 CVE 数据库项的增补程序，您也可以指定 CVE 编号：--cve=*编号*。要搜索与多个 CVE 数据库项相关的增补程序，请在 CVE 编号之间添加逗号，例如：\n$ zypper list-patches --bugzilla=CVE-2016-2315,CVE-2016-2324     要列出所有增补程序而不管是否需要安装它们，请另外使用 --all 选项。例如，要列出指派有 CVE 编号的所有增补程序，请使用：\n$ zypper list-patches --all --cveIssue | No. | Patch | Category | Severity | Status------+---------------+-------------------+-------------+-----------+----------cve | CVE-2015-0287 | SUSE-SLE-Module.. | recommended | moderate | neededcve | CVE-2014-3566 | SUSE-SLE-SERVER.. | recommended | moderate | not needed[...] 安装新的包版本 如果某个安装源只包含新包，但未提供增补程序，则 zypper patch 不会产生任何作用。要使用可用的较新版本更新所有已安装的包（同时还要保持系统完整性），请使用︰\n$ sudo zypper update 要更新个别包，请用更新或安装命令指定包：\n$ sudo zypper update PACKAGE_NAME$ sudo zypper install PACKAGE_NAME 可使用此命令来获取所有新的可安装包的列表：\n$ zypper list-updates 请注意，此命令只会列出符合以下准则的包︰\n 与已安装的包拥有相同的供应商， 由至少与已安装包拥有相同优先级的储存库提供， 可安装（满足所有依赖项）。  所有新的可用包（无论是否可安装）的列表可通过以下方式获取：\n$ sudo zypper list-updates --all 要找出新包无法安装的原因，请使用上面所述的 zypper install 或 zypper update 命令。\n识别孤立的包 每当您从 Zypper 中去除某个储存库或者升级系统时，某些包可能会进入“孤立”状态。这些孤立的包不再属于任何活动储存库。以下命令可以列出这些包：\n$ sudo zypper packages --orphaned 借助此列表，您可以确定是否仍然需要某个包，或者是否可以安全去除某个包。\n识别使用已删除文件的进程和服务 在增补、更新或去除包时，系统上可能有一些正在运行的进程会继续使用更新或去除后已被删除的文件。运行 zypper ps 可以列出使用已删除文件的进程。如果此类进程属于某个已知的服务，则会列出服务名称，方便您重启动该服务。默认情况下，zypper ps 会显示一个表：\nPID | PPID | UID | User | Command | Service | Files------+------+-----+-------+--------------+--------------+-------------------814 | 1 | 481 | avahi | avahi-daemon | avahi-daemon | /lib64/ld-2.19.s-\u0026gt; | | | | | | /lib64/libdl-2.1-\u0026gt; | | | | | | /lib64/libpthrea-\u0026gt; | | | | | | /lib64/libc-2.19-\u0026gt;[...]  PID：进程的 ID PPID：父进程的 ID UID：运行进程的用户的 ID User：运行进程的用户的登录名 Command：用于执行进程的命令 Service：服务名称（仅当命令与系统服务关联时才显示） Files：已删除文件的列表  通过如下方式可控制 zypper ps 的输出格式：\n  zypper ps -s\n创建一份简短表格，其中不会显示已删除的文件。\nPID | PPID | UID | User | Command | Service------+------+------+---------+--------------+--------------814 | 1 | 481 | avahi | avahi-daemon | avahi-daemon817 | 1 | 0 | root | irqbalance | irqbalance1567 | 1 | 0 | root | sshd | sshd1761 | 1 | 0 | root | master | postfix1764 | 1761 | 51 | postfix | pickup | postfix1765 | 1761 | 51 | postfix | qmgr | postfix2031 | 2027 | 1000 | tux | bash |   zypper ps -ss\n仅显示与系统服务关联的进程。\nPID | PPID | UID | User | Command | Service------+------+------+---------+--------------+--------------814 | 1 | 481 | avahi | avahi-daemon | avahi-daemon817 | 1 | 0 | root | irqbalance | irqbalance1567 | 1 | 0 | root | sshd | sshd1761 | 1 | 0 | root | master | postfix1764 | 1761 | 51 | postfix | pickup | postfix1765 | 1761 | 51 | postfix | qmgr | postfix   zypper ps -sss\n仅显示使用已删除文件的系统服务。\navahi-daemonirqbalancepostfixsshd   zypper ps --print \u0026quot;systemctl status %s\u0026quot;\n显示用于检索可能需要重启动的服务状态信息的命令。\nsystemctl status avahi-daemonsystemctl status irqbalancesystemctl status postfixsystemctl status sshd   用 Zypper 管理安装源 Zypper 的所有安装或增补程序命令均基于已知安装源列表。要列出系统已知的所有储存库，请使用命令：\n$ zypper repos 结果将类似于与以下输出：\n# | Alias | Name | Enabled | Refresh--+--------------+---------------+---------+--------1 | SLEHA-12-GEO | SLEHA-12-GEO | Yes | No2 | SLEHA-12 | SLEHA-12 | Yes | No3 | SLES12 | SLES12 | Yes | No 当在各个命令中指定储存库时，可以使用别名、URI 或 zypper repos 命令输出中的储存库编号。储存库别名是用于储存库处理命令中的储存库名称的简短版本。请注意，在修改储存库列表后，储存库编号可能会更改。别名本身不会更改。\n默认情况下不显示储存库的 URI 或优先级之类的细节。用以下命令可以列出所有细节：\n$ zypper repos -d 添加安装源 要添加安装源，请运行\n$ sudo zypper addrepo URI ALIAS URI 可以是因特网储存库、网络资源、目录、CD 或 DVD。ALIAS 是储存库的唯一简写标识符。您可以随意选择别名，前提是它必须唯一。如果指定的别名已在使用，Zypper 将发出警告。\n刷新储存库 zypper 可让您从配置的储存库中提取包的更改。要提取更改，请运行：\n$ sudo zypper refresh 注意：有些命令默认会自动执行 refresh，因此您不需要明确运行该命令。\n使用 refresh 命令时搭配 --plus-content 选项还可查看已禁用储存库中的更改：\n$ sudo zypper --plus-content refresh 该选项虽然会提取储存库中的更改，但会使禁用储存库的状态保持不变，即仍为禁用。\n删除储存库 要从列表中去除某个储存库，请将命令 zypper removerepo 与要删除的储存库的别名或编号结合使用。例如\n$ sudo zypper removerepo 1$ sudo zypper removerepo \u0026quot;SLEHA-12-GEO\u0026quot; 修改储存库 用 zypper modifyrepo 启用或禁用储存库。您还可以用该命令更改储存库的属性（例如刷新行为、名称或优先级）。以下命令将会启用名为 updates 的储存库、打开自动刷新并将其优先级设置为 20：\n$ sudo zypper modifyrepo -er -p 20 'updates' 修改储存库并不局限于单个储存库 —— 您也可以对组执行该操作︰\n -a：所有储存库 -l：本地储存库 -t：远程储存库 -m 类型：特定类型的储存库（其中类型可以是以下之一：http、https、ftp、cd、dvd、dir、file、cifs、smb、nfs、hd 和 iso）  要重命名安装源别名，请使用 renamerepo 命令。以下示例将别名从 Mozilla Firefox 更改为 firefox：\n$ sudo zypper renamerepo 'Mozilla Firefox' firefox 用 Zypper 查询储存库和包 Zypper 提供各种查询储存库或包的方式。要获取所有可用的产品、模式、包或增补程序的列表，请使用以下命令：\n$ zypper products$ zypper patterns$ zypper packages$ zypper patches 要查询特定包的所有储存库，请使用 search。要获得有关特定包的信息，请使用 info 命令。\n搜索软件 zypper search 命令可对包名或（视情况）对包摘要和说明执行搜索。括在 / 中的字符串会解译为正则表达式。默认情况下搜索不区分大小写。\n  执行简单搜索来查找包含 fire 的包名称\n$ zypper search \u0026quot;fire\u0026quot;   执行简单搜索来查找确切的包 MozillaFirefox\n$ zypper search --match-exact \u0026quot;MozillaFirefox\u0026quot;   同时在包描述和摘要中搜索\n$ zypper search -d fire   仅显示尚未安装的包\n$ zypper search -u fire   显示包含字符串 fir 且该字符串后面不是 e 的包\n$ zypper se \u0026quot;/fir[^e]/\u0026quot;   搜索特定功能 要搜索提供特殊功能的包，请使用命令 what-provides。例如，如果您想知道哪个包提供 Perl 模块 SVN::Core，请使用以下命令：\n$ zypper what-provides 'perl(SVN::Core)' what-provides 包名 与 rpm -q --whatprovides 包名 类似，不过 RPM 只能查询 RPM 数据库（即所有已安装的包的数据库）。另一方面，Zypper 将告诉您任意储存库的功能的提供商，而非仅已安装的储存库功能的提供商。\n显示包信息 要查询个别包，请使用 info 命令，并用完整包名称作为自变量。这会显示有关某个包的详细信息。如果包名与储存库中的所有包名都不匹配，该命令会输出非包匹配项的详细信息。如果您请求特定类型（通过使用 -t 选项），但该类型不存在，该命令会输出其他可用的匹配项，但不提供详细信息。\n如果您指定源包，该命令会显示基于该源包构建的二进制包。如果您指定二进制包，该命令会输出用来构建该二进制包的源包。\n如果还要显示该包必需/推荐的包，则使用选项 --requires 和 --recommends：\nzypper info --requires MozillaFirefox 显示生命周期信息 要检查您的产品和所支持包的生命周期，请如下所示使用 zypper lifecycle 命令：\n$ zypper lifecycleProduct end of supportCodestream: SUSE Linux Enterprise Server 15 2028-04-23 SUSE Linux Enterprise Server 15 n/a*Module end of supportBasesystem Module 2021-07-31No packages with end of support different from product.*) See https://www.suse.com/lifecycle for latest information 配置 Zypper Zypper 现在随附配置文件，允许您永久更改 Zypper 的行为（系统范围或用户特定）。要进行系统范围更改，请编辑 /etc/zypp/zypper.conf。要进行用户特定的更改，请编辑 ~/.zypper.conf。如果 ~/.zypper.conf 尚不存在，您可以使用 /etc/zypp/zypper.conf 作为模板：将其复制到 ~/.zypper.conf 并根据您的喜好进行调整。请参见文件中的注释，获取有关可用选项的帮助。\n查错 如果您在访问配置的储存库中的包时遇到问题（例如，尽管您知道某个包在某个储存库中，但 Zypper 找不到该包），刷新储存库或许可以解决问题：\nsudo zypper refresh 如果不起作用，则尝试\nsudo zypper refresh -fdb 这会强制完全刷新和重构建数据库，包括强制下载原始元数据。\nBtrfs 文件系统上的 Zypper 回滚功能 如果根分区上使用的是 Btrfs 文件系统，且系统中安装了 snapper，当 Zypper 提交对文件系统所做的更改以创建相应的文件系统快照时，会自动调用 snapper。这些快照可用于还原 Zypper 进行的任何更改。\nRPM RPM（RPM 程序包管理器）用于管理软件包。其主要程命令为 rpm 和 rpmbuild。用户、系统管理员和包构建人员可以查询强大的 RPM 数据库以获得有关已安装软件的详细信息。\nrpm 有五种模式：安装、卸装（或更新）软件包、重构建 RPM 数据库、查询 RPM 库或独立 RPM 存档、对包执行完整性检查以及对包签名。rpmbuild 可用于从原始源构建可安装的包。\n用特殊的二进制格式对可安装 RPM 存档进行打包。这些存档由要安装的程序文件和某些元信息组成，这些元信息供 rpm 在安装过程中配置软件包使用或者储存在 RPM 数据库中进行存档。RPM 存档通常具有扩展名 .rpm。\n对于一些包，软件开发所需的组件（库、报头、包含文件等）已纳入独立的包中。只有当您要自己编译软件时才需要这些开发包（例如最新的 GNOME 包）。可以通过扩展名 -devel 确定这些开发包，例如包 alsa-devel 和 gimp-devel。\n校验包真实性 RPM 包具有 GPG 签名。要校验 RPM 包的签名，请使用 rpm --checksig PACKAGE-1.2.3.rpm 命令确定该包是来自 SUSE 还是另一个可信机构。特别建议对来自因特网的更新包使用此命令。\n修复操作系统中的问题时，您可能需要将问题临时修复 (PTF) 安装到生产系统中。SUSE 提供的包已使用特殊的 PTF 密钥签名。要手动导入该密钥，请使用以下命令：\nsudo rpm --import \\/usr/share/doc/packages/suse-build-key/suse_ptf_key.asc 导入该密钥后，您可以在系统上安装 PTF 包。\n管理包：安装、更新和卸装 安装 RPM 存档的步骤通常十分简单，执行运行：rpm -i PACKAGE.rpm。使用此命令可以安装包，但前提是满足其依赖关系并且不与其他包冲突。如果出现错误消息，rpm 将请求那些需要安装的包以满足依赖关系要求。在后台，RPM 数据库确保不出现冲突 － 一个特定文件只能属于一个包。通过选择不同的选项，您可以强制 rpm 忽略这些默认设置，但这只供专家用户使用。否则，将影响系统的完整性并可能使系统无法更新。\n选项 -U 或 --upgrade 以及 -F 或 --freshen 可用于更新包（例如，rpm -F PACKAGE.rpm）。此命令将删除旧版本的文件并立即安装新文件。两个版本之间的差别是：-U 安装系统中以前不存在的包，而 -F 只更新以前安装的包。更新时，rpm 使用以下策略小心更新配置文件：\n 如果配置文件未被系统管理员更改，则 rpm 将安装适当文件的新版本。系统管理员无需执行任何操作。 如果配置文件在更新前曾被系统管理员更改，则 rpm 会以扩展名 .rpmorig 或 .rpmsave（备份文件）保存更改的文件，并安装新包中的版本。仅当原先安装的文件和较新的版本不同时，才执行此操作。如果是这种情况，则将备份文件（.rpmorig 或 .rpmsave）与新安装的文件进行比较，并在新文件中再次进行更改。之后，请删除所有 .rpmorig 和 .rpmsave 文件，以免以后的更新出现问题。 如果配置文件已存在并且 .spec 文件中指定了 noreplace 标签，则出现 .rpmnew 文件。  更新后，在使用 .rpmsave 和 .rpmnew 文件进行比较后应将它们删除，从而防止它们阻碍以后的更新。如果 RPM 数据库以前未能识别文件，则将为其指派扩展名 .rpmorig。 否则，将使用 .rpmsave。换句话说，.rpmorig 是从异系统格式更新为 RPM 的结果。而 .rpmsave 是从较早的 RPM 更新为较新的 RPM 的结果。.rpmnew 不提供任何有关系统管理员是否对配置文件进行过任何更改的信息。/var/adm/rpmconfigcheck 中提供这些文件的列表。不覆盖某些配置文件（如 /etc/httpd/httpd.conf）以允许继续进行操作。\n-U 开关的作用并不完全等同于使用 -e 选项进行卸载以及使用 -i 选项进行安装，它还有其他作用。只要可能，就可以使用 -U。\n要去除包，请输入 rpm -e PACKAGE。仅当不存在未解决的依赖项问题时，此命令才会删除包。例如，只要有其他程序需要 Tcl/Tk，理论上就不能删除它。即使是在这种情况下，RPM 也会向数据库寻求帮助。如果出于任何原因无法进行此删除操作（即使不存在其他依赖项），则最好使用选项 --rebuilddb 重构建 RPM 数据库。\n增量 RPM 包 增量 RPM 包包含旧版本和新版本的 RPM 包之间的差别。在旧 RPM 上应用增量 RPM 将得到全新的 RPM。不需要旧 RPM 的副本，因为增量 RPM 也可以与已安装的 RPM 一起工作。增量 RPM 包的大小甚至比增补程序 RPM 小，这有利于通过因特网传送更新包。缺点是，涉及增量 RPM 的更新操作与使用纯粹 RPM 或增补程序 RPM 进行更新的情况相比，占用的 CPU 周期要长得多。\nmakedeltarpm 和 applydelta 二进制文件是增量 RPM 套件（包 deltarpm）的一部分，可帮助您创建和应用增量 RPM 包。使用以下命令可以创建名为 new.delta.rpm 的增量 RPM。以下命令假设 old.rpm 和 new.rpm 是存在的：\nsudo makedeltarpm old.rpm new.rpm new.delta.rpm 如果旧包已经安装，则使用 applydeltarpm 可以从文件系统重新构建新的 RPM：\nsudo applydeltarpm new.delta.rpm new.rpm 如果不访问文件系统而从旧 RPM 得到它，请使用 -r 选项：\nsudo applydeltarpm -r old.rpm new.delta.rpm new.rpm RPM 查询 带 -q 选项的 rpm 将启动查询，如此用户便可查看 RPM 存档（通过添加选项 -p）并查询已安装包的 RPM 数据库。可以使用多个开关指定所需信息的类型。\n   选项 含义     -i 包信息   -l 文件列表   -f FILE 查询包含文件 FILE 的包（必须使用 FILE 指定完整路径）   -s 带有状态信息的文件列表（间接指定 -l）   -d 仅列出文档文件（间接指定 -l）   -c 仅列出配置文件（间接指定 -l）   --dump 带有完整详细信息的文件列表（将用于 -l、-c 或 -d）   --provides 列出包中可被另一个包通过 --requires 请求的功能   --requires, -R 包需要的功能   --scripts 安装脚本（预安装、后安装、卸载）    例如，命令 rpm -q -i wget 显示\nName : wgetVersion : 1.14Release : 17.1Architecture: x86_64Install Date: Mon 30 Jan 2017 14:01:29 CETGroup : Productivity/Networking/Web/UtilitiesSize : 2046483License : GPL-3.0+Signature : RSA/SHA256, Thu 08 Dec 2016 07:48:44 CET, Key ID 70af9e8139db7c82Source RPM : wget-1.14-17.1.src.rpmBuild Date : Thu 08 Dec 2016 07:48:34 CETBuild Host : sheep09Relocations : (not relocatable)Packager : https://www.suse.com/Vendor : SUSE LLC \u0026lt;https://www.suse.com/\u0026gt;URL : http://www.gnu.org/software/wget/Summary : A Tool for Mirroring FTP and HTTP ServersDescription :Wget enables you to retrieve WWW documents or FTP files from a server.This can be done in script files or via the command line.Distribution: SUSE Linux Enterprise 12 只有当您指定带有完整路径的完整文件名时，选项 -f 才起作用。根据需要提供任意多个文件名。例如：\nrpm -q -f /bin/rpm /usr/bin/wgetrpm-4.11.2-15.1.x86_64wget-1.14-17.1.x86_64 如果只知道部分文件名，则可以使用外壳脚本。当运行所显示的脚本时，将部分文件名以参数的形式传递给脚本。\n#! /bin/shfor i in $(rpm -q -a -l | grep $1); do echo \u0026quot;\\\u0026quot;$i\\\u0026quot; is in package:\u0026quot; rpm -q -f $i echo \u0026quot;\u0026quot;done rpm -q --changelog PACKAGE 命令会按日期排序显示有关特定包的详细更改信息列表。\n借助已安装的 RPM 数据库，可以进行校验检查。使用 -V 或 --verify 启动这些检查。使用此选项，rpm 显示安装后已被更改的包中的所有文件。rpm 使用 8 个字符符号给出有关以下更改的一些提示：\n   符号 含义     5 MD5 校验和   S 文件大小   L 符号链接   T 修改时间   D 主要和次要设备编号   U 拥有者   G 组   M 方式（权限和文件类型）    对于配置文件，将输出字母 c。例如，对于 /etc/wgetrc（wget 包）的更改：\nrpm -V wgetS.5....T c /etc/wgetrc RPM 数据库的文件被放置在 /var/lib/rpm 中。如果分区 /usr 的大小为 1 GB，则此数据库可能会占用将近 30 MB，特别是在完全更新之后。如果数据库比预期大得多，则最好使用选项 --rebuilddb 重构建数据库。在执行此操作之前，制作旧数据库的备份。cron 脚本 cron.daily 每天制作数据库的副本（用 gzip 打包）并将这些副本储存在 /var/adm/backup/rpmdb 中。副本的数目是由 /etc/sysconfig/backup 中的变量 MAX_RPMDB_BACKUPS（默认值为 5）控制的。对于 1 GB 的 /usr，单个备份的大小大约为 1 MB。\n安装和编译源包 所有源包都带有 .src.rpm 扩展名（源 RPM）。\n源包可以从安装媒体复制到硬盘并使用 YaST 解压缩。但是，在包管理器中它们不会被标记为已安装 ([i])。这是因为源包不是在 RPM 数据库中输入的。只有已安装的操作系统软件列在 RPM 数据库中。安装源包时，只将源代码添加到系统中。\n以下目录必须可用于 /usr/src/packages 中的 rpm 和 rpmbuild（除非在诸如 /etc/rpmrc 这样的文件中指定自定义设置）：\n  SOURCES\n代表原始源（.tar.bz2 或 .tar.gz 文件等）和特定于发布版本的调整（多为 .diff 或 .patch 文件）\n  SPECS\n代表 .spec 文件，类似于元 Makefile，该文件控制构建进程\n  BUILD\n在此目录中解压缩、增补和编译所有源\n  RPMS\n储存完整的二进制包的位置\n  SRPMS\n这里是源 RPM\n  使用 YaST 安装源包时，将在 /usr/src/packages 中安装所有需要的组件：源和调整在 SOURCES 中，相关的 .spec 文件在 SPECS 中。\n警告：不要对系统组件（glibc、rpm 等）进行试验，因为这样做会影响系统的稳定性。\n下面的示例使用 wget.src.rpm 包。安装源包后，应具有类似以下列表中的文件：\n/usr/src/packages/SOURCES/wget-1.11.4.tar.bz2/usr/src/packages/SOURCES/wgetrc.patch/usr/src/packages/SPECS/wget.spec rpmbuild -bX /usr/src/packages/SPECS/wget.spec 会启动编译。X 是通配符，代表构建进程的不同阶段。以下简要描述：\n  -bp\n在 /usr/src/packages/BUILD 中准备源：解压和打增补程序。\n  -bc\n执行与 -bp 相同的操作，但还进行编译。\n  -bi\n执行与 -bp 相同的操作，但还安装生成的软件。注意：如果包不支持 BuildRoot 功能，则可能会重写配置文件。\n  -bb\n执行与 -bi 相同的操作，但还创建二进制包。如果编译成功，二进制包应该在 /usr/src/packages/RPMS 中。\n  -ba\n执行与 -bb 相同的操作，但还创建源 RPM。如果编译成功，二进制包应该在 /usr/src/packages/SRPMS 中。\n  --short-circuit\n跳过某些步骤。\n  现在可以使用 rpm -i 或最好使用 rpm -U 来安装创建的二进制 RPM。使用 rpm 进行安装使它显示在 RPM 数据库中。\n使用 build 编译 RPM 包 许多包存在的风险是构建进程中会将许多不需要的文件添加到正在运行的系统中。为防止发生这种情况，请使用 build，它将创建构建包的已定义环境。要建立这一 chroot 环境，build 脚本必须和完整的包树结构一起提供。可以通过 NFS 或从 DVD 使用硬盘上的此树。使用 build --rpms DIRECTORY 设置位置。与 rpm 不同，build 命令在源目录中查找 .spec 文件。要用系统中 /media/dvd 下装入的 DVD 构建 wget（如上例所示），请以 root 用户身份使用以下命令：\ncd /usr/src/packages/SOURCES/mv ../SPECS/wget.spec .build --rpms /media/dvd/suse/ wget.spec 随后，将在 /var/tmp/build-root 建立一个最小的环境。在此环境中构建包。完成后，生成的包位于 /var/tmp/build-root/usr/src/packages/RPMS 中。\nbuild 脚本提供多个其他选项。例如，使脚本优先选择您自己的 RPM、忽略构建环境的初始化或者将 rpm 命令限制在上述阶段之一。\n用于 RPM 存档和 RPM 数据库的工具 Midnight Commander (mc) 可以显示 RPM 存档的内容并复制部分内容。它将存档表示为虚拟文件系统，提供 Midnight Commander 所有常用的菜单选项。使用 F3 键显示 HEADER。使用光标键和 Enter 键查看存档结构。使用 F5 键复制部分存档。\n拥有全部功能的包管理器将作为 YaST 模块提供。\nPackman 什么是 Packman ？ openSUSE 的 Packman 是 Package man 的缩写。意即指一群打包狂组成的团体。他们在尊重并重视版权的基础上做一些规避专利的事。总之，他们想要自由打包从多媒体到大型软件到游戏到甚至是自己的回收站的所有内容。\nPackman 和 openSUSE 的关系 Packman 不隶属于任何 openSUSE 官方，是独立于 openSUSE 社区之外的社区，只是基于 openSUSE 打给 openSUSE 用的软件包。注意 openSUSE 社区也是官方，同样有在专利法最为严苛的美国和欧洲注册，这也是为什么 OBS 不能打包专利软件的原因，另一个原因是 OBS 的服务器坐落于德国诺伦堡。\nPackman 的资源来自于成员捐献，不能和 openSUSE 官方有任何的联系，也就是说即使是 SuSE 的捐献，也要放弃一切权利。不能像社区董事会那样，主席要由 SuSE 指定，一般是 SuSE 员工。\nPackman 欢迎大学和社区为它做镜像。\nPackman 收纳什么样的软件 ？ 由于英文的 free 很有迷惑性（大部分外国人喜欢用法语 Libre，也就是自由）：\n 这里的自由，仍然不包括商业和私有软件，版权产品应该尊重他们自有的分发渠道。也就是说，这里仍然不做盗版，也不做免费使用的商业软件。不规避版权，只规避专利。版权同样是保护 Linux 下的开源作品不被盗版的力量，而专利则是大公司用来牟利的工具。 这里只接纳由于或有专利纠纷而不能存在于官方构建服务中的软件。比如 FFMPEG，MPLAYER，MP3, AMULE。和依赖它们的软件。以及可以自由分发的软件，并且愿意允许从源代码编译。  也就是说，大部分时候这里的软件都是 FOSS/LOSS （自由和开源软件），而不是免费软件。而且是存在或有专利纠纷的软件，想想看什么软件最容易发生专利纠纷呢？ 多媒体。于是 Packman 里有那么多多媒体软件也就不奇怪了。\n另外 Packman 还允许两类软件：发行版中长期不更新的软件的最新版，和发行版中没有的软件。但这是 FTP 做源的时代延续下来的。目前这两类软件都建议走 OBS 流程来做，因为 OBS 的服务器比 Packman 的多快好省。\nTips\u0026amp;Questions 解决KDE下KDE Wallet重装系统后每次登陆需要输入密码 在每次重装或者配置桌面后kdewallet总是在登陆系统之后提示输入密码，虽然在输入密码后能够继续正常使用，但是每次登陆系统都需要输入一次密码还是很烦人的。\n出现的原因：\n在重新配置桌面或者重装系统之后KDE Wallet所需要的一些必备需要依赖组件未能找到，所以导致不能正确运行KDE Wallet，所以只要安装其所需的组件即可。而其所需的但是未能自动安装的依赖组件正是 pam_kwallet，kwallet-pam 与 GnuPG keys 不兼容，所以 KDE Wallet 必须使用 blowfish 加密方式。\n解决方案 ：\n安装缺失的组件\nsudo zypper in pam_kwallet 为了保险起见，查看个人目录下是否存在~/.kde4/share/apps/kwallet文件夹，如果存在则将其删除或者重命名以避免出现冲突，并且还需要确定使用的钱包名为kdewallet并且密码为当前用户的密码。\n如此便可完全正常使用KDE Wallet\n解决方案参考arch wiki的KDE Wallet小节中。\nCould not open a connection to your authentication agent 执行ssh-add时出现\nssh-agent bash 无法读取 exfat 、 .7z 和 .rar sudo zypper in fuse-exfat exfat-utilssudo zypper in p7zip-fullsudo zypper in unrar 不关闭单击运行 Dolphin 默认单击运行，多数人都熟悉双击运行，但是其实只要点击文件左上角的加号，就可以不运行，相当于双击下的单击选择文件。\n杀死窗口 按 CTRL + ESC ，启动系统卫士，点击 工具 ，然后点击 杀死窗口 ，然后点击你想干掉的窗口。\n主题 不是我喜欢黑暗主题，而是热门的好看的主题都是黑暗主题。所以尝试如下：\n 全局黑暗主题为 Sweet chrome 黑暗主题  系统设置 Theme 使用 GTK+，可以使标题栏，设置菜单栏为黑暗，但是网页、设置页为白色。 Chrome 黑暗模式：在网址栏输入 chrome://flags/#enable-force-dark，启用。可以使设置页面黑暗，网页黑暗，但是进入 segmentfault，你会发现 segment 不见了。 安装 dark reader 插件。可以使网页黑暗，比 chrome 自带表现要好。但是打开新页面时，还是有短暂的白色。   Firefox 黑暗主题  设置页的颜色会与系统一致，也就是与 chrome 相反。 firefox theme 会改变标题栏、设置菜单栏颜色。    实际上你会发现，无法达到一致的黑暗，反而使得眼睛不舒服，所以我放弃了黑暗主题。\n亮色混合主题：\n Global Theme 为 openSUSE Plasma 为 Edna-light Window Decorations 为 Edna-light Font 为 Source Hans Sans CN 和 Jet Brains Moon Icon 为 Papirus SSDM Theme 为 chili for plasma kconsole 主题为 sweet 开始改为 application dashboard  实际你会发现，混合主题没有一个单独主题搭配的那么协调。\n窗体内容亮色，其他部分为黑暗，即标准主题:\n 全局主题 Sweet Colors 为 Breeze，使得 window 内容为亮色 Window Decorations 为 sweet-dark-transparent，设置标题栏 Icon 为 Papirus SSDM Theme 为 sweet fcitx 为 dartmouth。  感觉可以。\nDesktop Effects：\n Magic Lamp 400ms Wobbly Windows  不如不要。\nopenSUSE 的默认 /etc/sudoers Defaults targetALL ALL=(ALL) ALLroot ALL=(ALL) ALL 并把root密码设置为安装时用户密码。\n这导致你在装完系统后，如果改了密码，依旧需要通过原来的密码获取 root 权限。\nvscode keychain issues for KDE $ sudo zypper in gnome-keyring 提示添加密码的时候为空就行了，否则每次启动 vscode 都需要输入一次密码。\nNVIDIA 有两种为英伟达（NVIDIA）显卡提供的驱动：\n 为 NVIDIA 硬件提供的自由开源的驱动名叫 nouveau。 来自 NVIDIA 厂商自己的驱动名为 nvidia，但由于许可证问题，它不能直接被集成进入 openSUSE 。  添加 Nvdia 软件源\n# zypper addrepo --refresh 'https://download.nvidia.com/opensuse/leap/$releasever' NVIDIA 确定显卡型号\n# hwinfo --gfxcard | grep Model 安装驱动\n# zypper in x11-video-nvidiaG05 重启确认是否加载\n# lsmod | grep nvidia 常用软件 Typora 字体 如果 Typora 字体如上面那样，每个字大小不一样：\n  整个应用的语言设置为英语\n  在 conf.user.json 指定字体\n{ \u0026#34;defaultFontFamily\u0026#34;: { \u0026#34;standard\u0026#34;: \u0026#34;Source Han Sans CN\u0026#34;, //String - Defaults to \u0026#34;Times New Roman\u0026#34;.  \u0026#34;serif\u0026#34;: \u0026#34;Source Han Sans CN\u0026#34;, // String - Defaults to \u0026#34;Times New Roman\u0026#34;.  \u0026#34;sansSerif\u0026#34;: \u0026#34;Source Han Sans CN\u0026#34;, // String - Defaults to \u0026#34;Arial\u0026#34;.  \u0026#34;monospace\u0026#34;: \u0026#34;JetBrains Mono\u0026#34; // String - Defaults to \u0026#34;Courier New\u0026#34;.  } }   flatpak run: Invalid MIT-MAGIC-COOKIE-1 key rm .Xauthority Linux Deploy 准备 一个 Root 了的 Android 手机\nBusy Box：Linux Deploy 支撑软件。\nLinux deploy：Linux 系统支撑软件。\n安装 Busy Box 点击安装，等待程序自行运行，在界面中输出 ## END 后退出程序。\nLinux deploy  点击左图左上角部分，选择 设置，在设置界面中找到PATH变量，赋予其值 /system/xbin。 建议开启 锁定Wifi 功能。 接着退回主界面，点击右下角部分。 发行版 看个人喜好选择，Debian 系（Debian，Kaili，Ubuntu）较热门。 架构 默认。 源 默认。如果下的慢的话，就仿照默认的源换为国内的源，如 USTC MIRRORS，但是不要特意去换源，官方的源用的了的话官方的源最好。 安装路径 ：安装在手机自带的存储空间中，则在路径开头加上${ENV_DIR}；安装在 sdcard 中，加上${EXTERNAL_STORAGE}。 文件系统 ：推荐 ext4。 用户名 和 密码 自定义。 DNS 默认。 本地化 ：简体中文可以选择 zh_CN.UTF-8，建议选择 en_US.UTF-8 。 挂载列表：添加访问手机内容的目录，手机目录：挂载点，如 /sdcard:/mnt，之后会自动挂载。 开启SSH。 图形界面功能，需要的话就选 XFce 为桌面，XFce`是轻量级桌面环境。 退出系统设置界面，点击主界面右上角，选择安装。 等待程序自行安装Linux系统，开始时会自动创造一个4G左右大小的img文件，这个是默认的大小，你可以根据你手机的容量自定义，创造文件需要一点时间，屏幕会很安静，再然后会安装各种东西，屏幕会输出很多信息，根据你的源的速度，等待时间不等，看到 \u0026lt;\u0026lt;\u0026lt;deploy 则安装完毕。如果中间没有 failed 则安装成功。安装失败的话就需要重新安装，换个快一点的网，或者好一点的源。 注意：安装完毕后要先点击停止按钮，再按启动按钮。这个很重要，不然你就得重装了。  使用   Andorid 端用 ConnectBox\n  Windows用 putty ，图形界面用 VNC Viewer。VNC Viewer 直接搜主机IP就行，VNC Server 在你选择安装图形界面功能时就自动安装了，不需要再安装 vnc4server。\n  Linux 输入ssh username@hostname就行。\n  其他   安装后如果用 vnc viewer 只有一个点的话，可以换一个发行版，我尝试的 CentOS 有这个问题。\n  Linux连的时候出现 WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!：\nssh-keygen -R + 输入服务器的IP   altarch 架构的手机 CentOS 系统换源\ncp CentOS-7-armhfp.repo CentOS-Base.repo mv CentOS-7-armhfp.repo CentOS-7-armhfp.repo.backup vi CentOS-Base.repo baseurl=https://mirrors.ustc.edu.cn/centos-altarch/7.6.1810/os/armhfp/ yum makecache yum update   如果你之前没有安装VNC的话，现在又想装：\nyum -y install tigervnc-server   ","permalink":"https://example.com/posts/distributions/","summary":"Fedora [fəˈdɔrə] 费多拉 Fedora 定制版 为什么 Linus Torvalds 用 Fedora 2008：linus对发行版的要求是\u0026quot;易安装，比较贴近上游\u0026quot;即可。 201","title":"Distributions"},{"content":" The goals of the FreeBSD Project are to provide software that may be used for any purpose and without strings attached. Many of us have a significant investment in the code (and project) and would certainly not mind a little financial compensation now and then, but we are definitely not prepared to insist on it. We believe that our first and foremost \u0026ldquo;mission\u0026rdquo; is to provide code to any and all comers, and for whatever purpose, so that the code gets the widest possible use and provides the widest possible benefit. This is, I believe, one of the most fundamental goals of Free Software and one that we enthusiastically support.\nThat code in our source tree which falls under the GNU General Public License (GPL) or Library General Public License (LGPL) comes with slightly more strings attached, though at least on the side of enforced access rather than the usual opposite. Due to the additional complexities that can evolve in the commercial use of GPL software we do, however, prefer software submitted under the more relaxed BSD license when it is a reasonable option to do so.\nJordan Hubbard - FreeBSD Handbook\n Install FreeBSD BIOS Disable unused and unwanted options.\nInstall   To put the image on the pendrive we will use the dd tool available on almost any Mac OS X (macOS) and Linux system. For Windows You will have to download it from here – dd for windows( bs=1M on Linux/Windows ).（可用 Rufus 替代）\nsudo dd if=FreeBSD-11.1-RELEASE-amd64-memstick.img of=/dev/da1 bs=1m   When we have a new machine there is always a problem with new name for it. The RFC 1178 Choosing a Name for Your Computer from 1990 year tries to address that issue\n  We will use ZFS because we want to use Boot Environments with sysutils/beadm port.\n Hit [ENTER] on the Pool Type/Disks to select target disk to install FreeBSD on. Now (in FreeBSD 12.x) it is possible to install FreeBSD on GELI encrypted root on ZFS pool without any additional partitions or filesystems. You need to select is Yes for the Encryption part . I advice using GPT (BIOS+UEFI) as it will support both system types so when you are running BIOS system now and will move the disk to other system that boots with UEFI it will also just work out of the box. We will set SWAP size to 0 (no SWAP) as it will not be needed. If we will need SWAP in the future, then we will create ZVOL on ZFS and use it as a SWAP device.     Select services as shown below.   Enable all security hardening features as shown below.  X11 Window System X 最初設計是以網路為中心，採用 “client-server” 架構。在此架構下 “X 伺服器” 在有鍵盤、螢幕、滑鼠的電腦上運作。該伺服器負責的工作包含管理顯示、處理來自鍵盤、滑鼠的輸入及來自其他設備)的輸入或輸出。\n每個 X 應用程式，如 XTerm、Firefox 都是 “客戶端”。\n視窗管理程式規定螢幕上的視窗該長什麼樣、要如何移動滑鼠指標、 要用什麼鍵來在視窗切換、每個視窗的標題列長相，及是否該有關閉按鈕，等等。視窗管理程式負責滑鼠指標的聚焦政策。 聚焦政策指的是如何決定使用中及接收鍵盤輸入的視窗。通常較為人熟悉的聚焦政策叫做 “click-to-focus”，這個模式中，滑鼠點選到的視窗便會處於作用中 (Active) 的狀態。\nKDE 與 GNOME 會被稱作桌面環境是因為包含了完整常用桌面作業的應用程式。\nBIOS or UEFI If you find a device that is not supported by any ‘accelerated’driver like intel or nvidia. You would use vesa driver (Video Electronics Standards Association) while booting in BIOS mode and You will use scfb driver (System Console Frame Buffer) while booting on UEFI mode. This can be checked by\nsudo sysctl machdep.bootmethod Packages sudo pkg install xorg Xorg Configuration   顯示卡、顯示器以及輸入裝置會自動偵測，無須任何手動設置。除非自動設置失敗，否則請勿建立 xorg.conf 或執行 -configure 步驟。\n  加入要執行 Xorg 的使用者到 video 或 wheel 群組，以便在可用時能開啟 3D 加速。要加入使用者 jru 到任一個可用的群組：\nsudo pw groupmod video -m jru || pw groupmod wheel -m jru   Login Class(可解决中文乱码，powershell 字符显示方形)\nAdd this login class to the /etc/login.conf file.\nvideo:\\  :charset=UTF-8:\\  :lang=en_US.UTF-8:\\  :tc=default: Rebuild the login class database.\nsudo cap_mkdb /etc/login.conf Lets set the login class to video for the vuk user.\nsudo pw usermod -L video -n vuk How the account looks after setting the login class.\nsudo grep vuk /etc/master.passwd vuk:{REMOVED}:1000:1000:video:0:0:vuk:/home/vuk:/bin/sh Now logout and login again to make that work. View the changes through the locale command.\n  显卡驱动：使用多檔，每一個檔案只設定一個指定項目會較傳統使用單一 /etc/X11/xorg.conf 設定來的簡單。完整路徑為 /usr/local/etc/X11/xorg.conf.d/。（安装 intel 显卡驱动与 nvidia 驱动难，scfb 与 vesa 驱动无法调整分辨率）\nsudo vi /usr/local/etc/X11/xorg.conf.d/driver-intel.conf Section \u0026#34;Device\u0026#34; Identifier \u0026#34;Card0\u0026#34; Driver \u0026#34;scfb\u0026#34; BusID \u0026#34;PCI:0:2:0\u0026#34; EndSection 若有多張顯示卡，可取消註解 BusID identifier 然後設定為想要的顯示卡，顯示卡的 Bus ID 清單可以使用 pciconf -lv | grep -B3 display 取得。\n  手動設定\n  設定檔可由 Xorg 根據偵測到的硬體產生，這個檔案對一開始自訂設定很有幫助。\nXorg -configure   設定檔會儲存至 /root/xorg.conf.new，做任何需要的更改，然後使用以下指令測試該檔案：\nXorg -config /root/xorg.conf.new 在新設定檔調整與測試過後，便可分開成較小的檔案放置到正常的位置 /usr/local/etc/X11/xorg.conf.d/。\n    Install Desktop Enviroment   FreeBSD 桌面发行版\n GhostBSD 是 FreeBSD 桌面发行版，注意使用 Official 版本，不能直接使用 FreeBSD 源升级。 nomadbsd 是个非常漂亮的 FreeBSD 桌面发行版 ，德国产。 可以在虚拟机里面安装 FreeBSD 桌面发行版，然后找到自己想用的桌面工具，再定制自己的 FreeBSD 桌面。    Install Desktop Environment\nsudo pkg install gnome3 sudo pkg install gnome3-lite sudo pkg install x11/kde5 sudo pkg install xfce sudo pkg install mate   Install/Enable Display Manager: You have to decide how You want to start your X11 Window Server, you may login in plan text console and then type xinit or startx to read your ~/.xinitrc configuration and daemons (The difference between xinit and startx is that startx command executes xinit command with arguments.) or You may want to use X11 Login manager such as xdm/sddm/slim with ~/.xsession configuration to load after successful login.\nsudo pkg install xdm sudo pkg install slim\t# xfce,mate，slim 有个 slim-themes 软件包 sudo pkg install x11/sddm\t# kde While xinit run commands based on the ~/.xinitrc file the XDM login manager looks for the ~/.xsession file. As You will be loading same stuff regardless of the startup method we will create a link of ~/.xsession pointing to the ~/.xinitrc file. This way either method You choose You will always end with started X11 session.\nln -s ~/.xinitrc ~/.xsession One more case about the ~/.xinitrc (or ~/.xsession) file. It is interpreted as a shell script (and yes you can do if/then/else/fi and case/esac or for/while POSIX shell scripting in it) but it does not need to be executable. The last command in this file MUST NOT to be put in the background (must be without the \u0026amp; char at the end) because the X11 session will end.\n  Setting\nsudo vi /etc/ttys\t# xdm ttyv8 \u0026#34;/usr/local/bin/xdm -nodaemon\u0026#34; xterm on secure sudo vi /etc/fstab\t# gnome, kde proc /proc procfs rw 0 0 sudo vi /etc/rc.conf moused_enalbe=\u0026#34;YES\u0026#34; dbus_enable=\u0026#34;YES\u0026#34;\t# gnome, kde, xfce hald_enable=\u0026#34;YES\u0026#34;\t# gnome, kde, mate gdm_enalbe=\u0026#34;YES\u0026#34;\t# gnome 启动 sddm_enable=\u0026#34;YES\u0026#34;\t# kde 启动 slim_enable=\u0026#34;YES\u0026#34;\t# xfce,mate gnome_enable=\u0026#34;YES\u0026#34;\t# gnome 服务   slim Usage(Failed to execute login command)\nsudo vi ~/.xinitrc exec mate-session\t# mate exec xfce4-session\t# xfce   Components   Window Manager: Openbox\u0026hellip;\n  Status Bar: Also known as information bar, the place on the screen that would provide You needed information such as current date and time, CPU, RAM and storage usage, current network information or battery status.\n  While Xmobar is nice solution it comes with about 2 GB of dependencies of Haskell and Haskell libraries.\n  While Polybar can look very nice on screenshots it is a lot more heavy on resources and is limited only to modules/features that were implemented in it.\n  I have used Conky for quite long time but after recent tests I made Dzen2 is a lot less on resources then Conky while doing the same thing.\n    Task Bar: A taskbar is an element of a graphical user interface which has various purposes. It typically shows which programs are currently running.\n  You can use classic taskbar like XFCE Panel used in the XFCE desktop environment.\n  You can also configure Tint2 that way. But it only shows applications that are active on the current desktop.\n  One of the greatest taskbars of all time was/is the Mac OS X Dock (now macOS Dock). It also has an indicator showing if application is launched. Currently the best and lightest solution for providing the dock-like functionality on open desktops seems to be Plank.\n    Application Launcher: While not being any crucial role of the desktop environment it have its uses and sometimes save time.\nLets start with resources, the Rofi implementation of application launcher uses almost 3 times more RAM then Dmenu solution.\n  Desktop with Dmenu launched and with alc characters inserted to ‘filter’ commands in the search of a calculator application.\n  The Rofi requires simple command.\nrofi -show run -theme solarized_alternate -font \u0026#34;Monaco 8\u0026#34;     Blue Light Spectrum Suppress: Automatically adjusts color temperature of the screen according to your current time in your location.\n  While F.lux (closed source) does not provide a native binary for FreeBSD it does offer such binary for Linux and as FreeBSD provides Linux Binary Compatibility its possible to use it on FreeBSD. To use F.lux just start it in the ~/.xinitrc or ~/.xsession file like that.\n~/path/to/bin/xflux -l 33.54321 -g 11.12345 \u0026amp; Of course 33.54321 is latitude and 11.12345 is longitude of your localization.\n  Redshift is the solution that I propose to use as open source blue light spectrum suppressor. Similarly like with the F.lux to start Redshift just put it in the ~/.xinitrc or ~/.xsession file like that.\nredshift -l 33.54321:11.12345 -g 0.9 \u0026amp;   Someone else suggested trying sctd which is sct but rewritten/modified to be a daemon that will automatically change the color temperature during the day (or night). The sctd uses smaller about of RAM memory, uses less libraries and size of these libraries is smaller then what redshfit needs.\n    Binary 套件 搜寻软件：FreeBSD Ports、FreshPorts\n因編譯選項不同，有些 Port 會有多個版本可使用。\n  USTC Mirrors：注意使用 Latest 源，有很多流行软件。创建 /usr/local/etc/pkg/repos/FreeBSD.conf 覆盖官方源 /etc/pkg/FreeBSD.conf 配置\nsudo vi /usr/local/etc/pkg/repos/FreeBSD.conf FreeBSD: { url: \u0026#34;pkg+http://mirrors.ustc.edu.cn/freebsd-pkg/${ABI}/latest\u0026#34;, } sudo pkg update -f\t# 更新索引   163 Mirrors\n url: \u0026quot;pkg+http://mirrors.163.com/freebsd-pkg/${ABI}/latest\u0026quot;,   要啟動 (Bootstrap) 系統，請執行\nsudo /usr/sbin/pkg   當升級原使用舊版 pkg_* 工具的既有系統時，必須將資料庫轉換成新的格式\nsudo pkg2ng   Update the available remote repositories as listed in pkg.conf\nsudo pkg update   Search for a package\nsudo pkg search perl   在指定要安裝的套件時，最好使用 Port 來源來指定該應用程式，Port 來源是指應用程式在 Port 樹中的路徑\nsudo pkg search -o perl   Install a package: Installing must specify a unique origin or version otherwise it will try installing all matches\nsudo pkg install perl-5.14   列出已經安裝的 Port 中有那些已過時\nsudo pkg version -l \u0026#34;\u0026lt;\u0026#34;   Upgrade from remote repository\nsudo pkg upgrade   Delete an installed package\nsudo pkg delete perl-5.14   Remove unneeded dependencies\nsudo pkg autoremove   List installed packages\nsudo pkg info   Display information about installed packages\nsudo pkg info perl-5.14   Show the pkg-message of a package\nsudo pkg info -D perl-5.14   要查詢已安在系統上的軟體是否有任何已知的漏洞\nsudo pkg audit -F   因為相依所安裝的套件稱作自動 (Automatic) 套件，而非自動套件即套件被安裝的原因不是因為其他套件所相依\nsudo pkg prime-list\t# deprecated   Clean the local cache of fetched remote packages\nsudo pkg clean   Packages\nsudo pkg install linux-sublime3 sudo pkg install mysql180-server mysql180-client   Port 套件 優點：\n 可更改編譯選項 部份軟體的授權條款中禁止以 Binary 格式發佈。 這種軟體必須以原始碼發佈並由終端使用者編譯。 原始碼可套用自訂的修補。  Port 中並不含實際的原始碼，在編譯 Port 解壓縮時會自動下載的原始碼到 /usr/ports/distfiles。\n  USTC Mirrors：在 /etc/make.conf 中添加以下内容\nMASTER_SITE_OVERRIDE?=http://mirrors.ustc.edu.cn/freebsd-ports/distfiles/${DIST_SUBDIR}/   163 Mirrors\nMASTER_SITE_OVERRIDE?=http://mirrors.163.com/freebsd-ports/distfiles/${DIST_SUBDIR}/   安裝 Port 套件集：下載壓縮後的 Port 套件集快照 (Snapshot) 到 /var/db/portsnap\nsudo portsnap fetch   第一次執行 Portsnap 時，要先解壓縮快照到 /usr/ports\nsudo portsnap extract   執行以下指令來更新 /usr/ports\nsudo portsnap fetch sudo portsnap update   要找到 Port 所在的分類\nsudo whereis lsof   使用 Port 套件集內建的搜尋機制來找軟體\nsudo cd /usr/ports sudo make search name=lsof sudo make quicksearch name=lsof\t# 不接受多資訊   若要進行更有深度的搜尋\nsudo make search key=string sudo make quicksearch key=string   一次設定所有Port 編譯選項\nsudo make config-recursive   重新進入 Port 的編譯選項清單\nsudo make config\t# or sudo make showconfig\t# or sudo make rmconfig   編譯並安裝 Port\nsudo cd /usr/ports/sysutils/lsof sudo make install   編譯在 /usr/ports Port 並安裝到 /usr/home/example/local\nsudo make WRKDIRPREFIX=../ports PREFIX=../local install   安裝過程中會建立工作用的子目錄用來儲存編譯時暫存的檔案。可移除此目錄來節省磁碟空間並漸少往後升級新版 Port 時造成問題\nsudo make clean   移除已安裝的 Port\nsudo cd /usr/ports/sysutils/lsof sudo make deinstall   Example\ncd /usr/ports/java/linux-oracle-jdk18 sudo make install   安裝後的注意事項：\n 大部份應用程式安裝會在 /usr/local/etc 安裝至少一個預設的設定檔。 應用程式提供的文件會安裝到 /usr/local/share/doc。 部份應用程式會以服務的方式執行，在啟動應用程式前前需要加入設定到 /etc/rc.conf。這些應用程式通常會安裝啟動 Script 到 /usr/local/etc/rc.d。  Linux® Binary 相容性 FreeBSD 提供 Linux® Binary 的相容性，允許使用者在 FreeBSD 系統上不需要修改就可以安裝和執行大部份的 Linux® Binary。\n最好不要直接安装 Linux 的软件，而使用 FreeBSD 源中的 Linux 软件，一般以 linux-package 命名。\n  載入 Linux® 核心模組\nsudo kldload linux   對 64-位元的相容性\nsudo kldload linux64   確認模組已載入\nsudo kldstat   安裝基本的 Linux® 程式庫和 Binary\nsudo pkg install emulators/linux_base-c7   Add the following line\nsudo vi /etc/fstab linprocfs /compat/linux/proc\tlinprocfs\trw\t0\t0 linsysfs /compat/linux/sys\tlinsysfs\trw\t0\t0 tmpfs /compat/linux/dev/shm\ttmpfs\trw,mode=1777\t0\t0   開機時開啟 Linux® 相容性\nsudo vi /etc/rc.conf linux_enable=\u0026#34;YES\u0026#34;   安裝 Linux® ELF Binary\nsudo brandelf -t Linux my-linux-elf-binary   安裝以 Linux® RPM 為基礎的應用程式,需先安裝 archivers/rpm4 套件或 Port\nsudo pkg install rpm4 sudo cd /compat/linux sudo rpm2cpio \u0026lt; /path/to/linux.archive.rpm | cpio -id   手動安裝其他程式庫   在 Linux® 系統，可使用 ldd 來找出應用程式需要哪個共用程式庫\nldd linuxdoom libXt.so.3 (DLL Jump 3.1) =\u0026gt; /usr/X11/lib/libXt.so.3.1.0   複製 Linux® 系統輸出結果中最後一欄需要的的檔案到 FreeBSD 系統的 /compat/linux。 複製完後，建立符號連結 (Symbolic link) 至輸出結果第一欄的名稱\n/compat/linux/usr/X11/lib/libXt.so.3.1.0 /compat/linux/usr/X11/lib/libXt.so.3 -\u0026gt; libXt.so.3.1.0   自訂核心 為何要編譯自訂的核心? 自訂核心有許多項優點，如：\n 加速開機，因為自訂的核心只需要偵測您系統上存在的硬體，所以讓啟動所花的過程更流暢快速。 減少記憶體使用，自訂的核心通常會比 GENERIC 核心使用更少的記憶體，這很重要，因為核心必須一直存放在實體記憶體內。 支援額外的硬體，自訂的核心可以增加一些 GENERIC 核心沒有提供的硬體支援。  偵測系統硬體   dmesg or /var/run/dmesg.boot or /var/log/messages\n  pciconf -lv\n  在 man指令加上 -k 旗標可列出有包含指定裝置品牌或名稱的手冊頁面清單：man -k Intel\n  設定檔 /usr/src/sys 下子目錄代表著支援的硬體架構 (Architecture)，每個支援的硬體架構中會有 conf 子目錄，裡面含有供該架構使用的 GENERIC 核心設定檔。\n說明在GENERIC 同目錄的 NOTES 檔案中。所有架構通用選項，參考 /usr/src/sys/conf/NOTES。\n备份与恢复 dump \u0026amp; restore FreeBSD 系统的备份就是对系统文件的打包，然后放到一个安全的地方，使用的打包工具是 dump；FreeBSD 系统的恢复就是把你保存好的系统文件从安全的地方里面拿出来放到你的硬盘上去，使用的恢复工具是 restore；\n  需要备份的目录：\n / 这个目录存放很多基本工具，包括内核，需要备份； /home 用户数据，需要备份； /usr 很多工具以及系统的源代码都放在这里面，需要备份； /usr/local 所有安装的软件基本上都在这里，需要备份； /var 系统的日志，ports系统的数据库，需要备份；    备份方法：以 / 目录为例，把移动硬盘挂载在 /mnt/fender_01 目录，/ 目录对应硬盘上面的 /dev/ad12s1a 分区，备份整个目录的命令如下：\ndump -0Lauf /mnt/fender_01/dump/ad12sa1.dump /dev/ad12s1a  -0 备份所有的文件系统中的内容，也就是不使用增量备份； -f 指定备份结果存放的文件名； -a 告诉 dump 不考虑备份的介质的大小问题，早期备份使用磁带，dump 会预先计算一下需要的空间，使用这个选项告诉 dump 忽略这个问题； -u 告诉 dump 更新一下 /etc/dumpdates，这个文件记录了你在系统上搜有的备份活动； -L 备份已经挂载的文件系统时需要，这个选项会使用 UFS2 的 snapshot 功能来保证文件系统的一致性。    恢复方法\n  恢复 / 以外的目录：以恢复 /home 目录为例，重启系统进入单用户模式，挂载 /tmp 分区，挂载移动硬盘，这时备份生成的文件保存在 /mnt/01/dump/dev/ad12s1h.dump，格式化 /dev/ad12s1h：\nnewfs -U /dev/ad12s1h\t# -U 选型来打开 softupdate 挂载这个分区，例如 /mnt/02/，恢复目录：\ncd /mnt/02 restore -rf /mnt/01/dump/ad12s1h.dump   恢复 /：因为 restore 在 / 目录中，所以不能使用上面方法恢复 / 目录。解决办法是使用 freebsd_livefs_cd 启动系统。\n    备份 MBR\n  备份\ndd if=/dev/da0 of=/path/to/mbr.img bs=512 count=1   恢复\ndd if=/path/to/mbr.img of=/dev/da0 bs=512 count=1     参考：FreeBSD dump 备份\nrsync（remote sync） 可以在本地计算机与远程计算机之间，或者两个本地目录之间同步文件，且仅传输有变动的部分。\n  将源目录同步到目标目录\nrsync -r source1 source2 destination\t# -r 表示递归，即包含子目录 rsync -a source/ destination\t# -a 除了可以递归同步以外，还可以同步元信息（比如修改时间、权限等）   排除文件：同步时排除某些文件或目录，这时可以用 --exclude 参数指定排除模式，多个排除模式，可以用多个 --exclude 参数\nrsync -av --exclude dir source/ destination\t# 排除所有 TXT 文件   增量备份：除了源目录与目标目录直接比较，rsync 还支持使用基准目录，即将源目录与基准目录之间变动的部分，同步到目标目录。--link-dest 参数用来指定同步时的基准目录。\nrsync -a --delete --link-dest /compare/path /source/path /target/path   远程同步：rsync 默认使用 SSH 进行远程登录和数据传输\nrsync -av source/ username@remote_host:destination\t# 将本地内容同步到远程服务器 rsync -av username@remote_host:source/ destination\t# 将远程内容同步到本地   使用 rsync 来备份系统\nrsync -aH --delete --exclude dir --link-dest /compare/path source destination  -H 选项用来保持硬链接 默认情况下，rsync 只确保源目录的所有内容（明确排除的文件除外）都复制到目标目录。它不会使两个目录保持相同，并且不会删除文件。如果你想让那些在源目录里被删除的文件在目标目录里也被删除，那么你可以加上 --delete 选项来删除。--delete 参数会使得 destination 成为 source 的一个镜像。    参考：rsync 用法教程，使用 rsync 来备份 Linux 系统\nZ 檔案系統 (ZFS) ZFS 的設計目標主要有三個：\n 資料完整性：所有資料都會有一個資料的校驗碼 (checksum)，資料寫入時會計算校驗碼然後一併寫入，往後讀取資料時會再計算一次校驗碼，若校驗碼與當初寫入時不相符，便可偵測到資料錯誤，此時若有可用的資料備援 (Data redundancy)，ZFS 會嘗試自動修正錯誤。 儲存池：實體的儲存裝置都會先被加入到一個儲存池 (Pool)，這個共用的儲存池可用來配置儲存空間，儲存池的空間可被所有的檔案系統使用且透過加入新的儲存裝置來增加空間。 效能：提供多個快取機制來增加效能。先進、以記憶體為基礎的讀取快取可使用 ARC。第二層以磁碟為基礎的讀取快取可使用 L2ARC，以磁碟為基礎的同步寫入快取則可使用 ZIL。  Others Screen resolution on FreeBSD on VirtualBox 问题描述：在virtualbox虚拟机下，无法改变桌面分辨率为1366x768\nVBoxManage setextradata \u0026#34;FreeBSD\u0026#34; VBoxInternal2/EfiGraphicsResolution 1366x768 Disable the Forward/Back buttons on my mouse 问题描述：浏览网页时，鼠标滑轮滚动浏览器就会前进后退。\nSalved：\n  执行下面命令后，上下滑动鼠标滑轮，看看映射到那些button，一般是buttons 8 and 9\nsudo xev | grep -A2 ButtonPress   then disable button 8 and 9（前提是有上面的问题，否则就不要禁）\nsudo vi ~/.Xmodmap pointer = 1 2 3 4 5 6 7 0 0 0 0 0   test it with the command,command automatically when you log in; if yours doesn\u0026rsquo;t, arrange for it to run when X starts.\nsudo xmodmap ~/.Xmodmap   Install chinese font sudo pkg install zh-CJKUnifonts\t# CJK（中日韩统一表意文字） 设单使用模式为不安全 sudo vi /etc/ttys console none\tunknown off insecure No space left on device 问题描述：使用 pkg update 时提示这个问题。原因是 /tmp is too small。\nSalved:\nsudo vi /etc/fstab tmpfs\t/tmp\ttmpfs\trw,size=256000000\t0\t0\t# size 以Byte为单位 VirtualBox™ guest additions sudo cd /usr/ports/emulators/virtualbox-ose-additions \u0026amp;\u0026amp; make install clean sudo vi /etc/rc.conf vboxguest_enable=\u0026#34;YES\u0026#34; vboxservice_enable=\u0026#34;YES\u0026#34; vboxservice_flags=\u0026#34;--disable-timesync\u0026#34;\t# 若有使用 ntpd或 ntpdate，便可關閉主機時間同步功能 Fish Fish 是\u0026quot;the friendly interactive shell\u0026quot;的简称，最大特点就是方便易用。\nFish 会自动在光标后面给出建议，表示可能的选项，颜色为灰色。如果采纳建议，可以按下→或Control + F。如果只采纳一部分，可以按下Alt + →。\n输入命令时，Fish 会自动显示匹配的上一条历史记录。如果没有匹配的历史记录，Fish 会猜测可能的结果，自动补全各种输入。\nHow to start things at boot time   主流的桌面环境都自带应用程序自启动设置程序。\n  These directories are defined in /etc/defaults/rc.conf（主要是运行脚本）\n  Default startup directory is /usr/local/etc/rc.d/. if you need the files to be executed in a specific order, try numbering the files. For example:\n000This.Will.Run.First.sh 020This.Will.Run.Next.sh 030And.Then.This.sh   deprecated: /etc/rc.local\n    DSBAutostart is a Qt program that allows you to add commands to be executed at session start.\n（本质就是在 .xinitrc 调用程序指令，GUI 程序开机启动都需放入 .xinitrc，在 Xorg 启动后运行）\n  Installation\ncd /usr/ports/x11/dsbautostart \u0026amp;\u0026amp; make install distclean   Usage\n  Manual\n  Setup: Add the following command to your ~/.xinitrc, or to your window manager\u0026rsquo;s startup script (e.g. ~/.config/openbox/autostart.sh)\nsh ~/.config/DSB/autostart.sh\u0026amp;   ~/.config/DSB/autostart.sh\nPlank\u0026amp;     GUI: Setting -\u0026gt; DSBAutostart -\u0026gt; Add Command, example plank, then Save and Quit\n      FreeBSD Insall Oracle JDK  安装 Linux Compact 在 /usr/ports/java/linux-oracle-jdk18 运行 sudo make install 根据提示在 Oracle Java Archive 下载需要的 JDK 版本安装包，复制到 /usr/ports/distfiles 在 /usr/ports/java/linux-oracle-jdk18 运行 sudo make install，安装成功  FreeBSD Install Python and pip sudo pkg install python python --version Python 3.7.9 sudo pkg install py37-pip 简化启动 FreeBSD 默认启动过程相当详细，包含大量调试信息以及内核消息。\n Add the boot_mute=YES option to the /boot/loader.conf file. Add autoboot_delay=2 parameter to the /boot/loader.conf file. Add rc_startmsgs=\u0026quot;NO\u0026quot; to your /etc/rc.conf file.  连接网络 If You will have attached LAN cable and your interface is em0 (check ifconfig command output) then dhclient em0 command should grant You the working connection to the Internet – assuming that You have DHCP server on that network.\nifconfig em0 up dhclient em0 To test the network connectivity use the ping command.\nping -c 3 freebsd.org If You would like to connect to the World with wireless connection then here are the needed commands. First lets check what wireless card You have.\nsysctl net.wlan.devices We will now create wlan virtual device on top of our iwn0 device and bring it up.\nifconfig wlan0 create wlandev iwn0 ifconfig wlan0 up We can scan for existing nearby WiFi access points if needed.\nifconfig wlan0 scan Now we need to add the desired WiFi network to the /etc/wpa_supplicant.conf file as shown below.\nnetwork={ ssid=\u0026quot;WIFI-NETWORK-NAME\u0026quot; psk=\u0026quot;PASSWORD\u0026quot; } Then You may connect to it using the wpa_supplicant daemon. Hit the [CTRL]+[Z] key combination to put the process into suspended state. Then we type the bg command to put it back into running state, but in the background so we can continue to type next commands.\nwpa_supplicant -i wlan0 -c /etc/wpa_supplicant.conf Now we will request for the IP address from the access point DHCP server.\ndhclient wlan0 How To Add and Remove Users on FreeBSD   Add a User: adduser\n  Grant Sudo Privileges: On FreeBSD, users that are members of the wheel group are allowed to use sudo. This is due to the following line in the default sudoers file, /usr/local/etc/sudoers\n%wheel ALL=(ALL) NOPASSWD: ALL   Remove a User: rmuser\n  Lock a User Account: pw lock username\n  Unlock a User: pw unlock username\n  其他 NetBSD: huaweicloud、aliyun、tsinghua\nOpenBSD: huaweicloud、aliyun、tsinghua\n一篇好文：FreeBSD的现状和未来\nFreeBSD Desktop\nFreeBSD 使用手冊\n","permalink":"https://example.com/posts/freebsd/","summary":"The goals of the FreeBSD Project are to provide software that may be used for any purpose and without strings attached. Many of us have a significant investment in the code (and project) and would certainly not mind a little financial compensation now and then, but we are definitely not prepared to insist on it. We believe that our first and foremost \u0026ldquo;mission\u0026rdquo; is to provide code to any and","title":"FreeBSD"},{"content":"Just a little conversation\nAbout give me your picture\nOn the cover of a magazine\nOn the cover of a magazine\nJust a little conversation\nBut how long it might take one?\nTo get along with such thing?\nTo get along with such thing?\nBut everybody knows\nIt\u0026rsquo;s easier to fall apart\nJust a little conversation\nAbout give me your picture\nOn the cover of a magazine\nOn the cover of a magazine\n  ","permalink":"https://example.com/posts/conversation/","summary":"Just a little conversation\nAbout give me your picture\nOn the cover of a magazine\nOn the cover of a magazine\nJust a little conversation\nBut how long it might take one?\nTo get along with such thing?\nTo get along with such thing?\nBut everybody knows\nIt\u0026rsquo;s easier to fall apart\nJust a little conversation\nAbout give me your picture\nOn the cover of a magazine\nOn the cover of a magazine","title":"Conversation"}]