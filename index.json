[{"content":"Portal 信息生产者主要是企业。\n OSCHINA：开源资讯 少数派：软硬件使用技巧 Linux 中国：Linux 相关 Distrowatch：Linxu 发行版排行 FreeBSDNews LWN.net: News and Information source for the free software community 36氪 虎嗅 利器 湾区日报：每天推送3到5篇优质英文文章 It\u0026rsquo;s FOSS: Focuses on Open Source in general and Linux in particular 开源工厂 \u0026lt;奇客\u0026gt; solidot：中文科技信息交流平台和开源新闻平台 LinuxToday: Linux News On Internet Time linuxinsider desktoplinux THE LINUX FOUNDATION ChinaUnix：Linux/Unix技术社区网站 Fedora Magazine Planet Gentoo 新运维 FreeBuf 51CTO  Forum\u0026amp;community 信息生产者主要是各个用户。\n 思否：技术文章 掘金：很多优质前端文章 v2ex：程序员之间的交流 博客园：blog，新闻 豆瓣：读书、电影 知乎：提问 StackOverflow：提问 牛客网：求职 The FreeBSD Forums openSUSE 中文论坛：很活跃的 Linux 论坛 Ubuntu 中文论坛 LUG@USTC：中国科学技术大学 Linux 用户协会 LinuxQuestions: Linux Community LINUX.ORG：Linux 主站 火狐社区 Ask Ubuntu freeCodeCamp 中文社区 Hacker News Daily 4chan ubuntu forums ASK FEDORA 灰狐和他的朋友们 Ubuntu 正体中文站 China FreeBSD Tuxmachines.org Linux Journal HowtoForge phoronix 先知社区 LUPA 开源社区 AOSC 社区：AOSC OS 是独立于 Debian 构建和维护的发行版。 北京 GNU/Linux 用户组  Blog\u0026amp;log 信息生产者是个人。\n 月光博客：IT咨询 包昊军的博客 delphij\u0026rsquo;s Chaos：FreeBSD 学习日志：Web系统架构 Lamp Nginx Golang MySQL 𝚟𝚎𝚛𝚖𝚊𝚍𝚎𝚗: FreeBSD D0n9X1n\u0026rsquo;s Blog: Hexo, WorldPress Java技术驿站 芋道源码: Java 酷壳 – CoolShell.cn LinuxTOY：Linux 相关资讯 Zoom.Quiet：Python 与 开源 plaintxt.org：Minimalism in blog design, an experiment Sickly Life：日文 Blog，Ubuntu 相关 阿星Plus Js中文网周刊 当然我在扯淡 wlop：微博2020十大影响力画手 知名动漫博主 蘑菇天文馆：opensuser Jerry Qu：专注 WEB 端开发 Flavio Copes：I\u0026rsquo;m a computer engineer and I write free books to help you become a Web Developer 黑果小兵的部落阁 张鑫旭的个人主页 阮一峰的网络日志 廖雪峰的官方网站 囧克斯 W3cplus Houge\u0026rsquo;s Madness Blog marguerite：opensuser Slbtty\u0026rsquo;s Notepad：opensuser 鹤仙人：em\u0026hellip; 依云\u0026rsquo;s Blog：仙子 Eric S. Raymond\u0026rsquo;s Home Page Dark Side Make Linux 星黎殿 Mark Shuttleworth：Ubuntu创始人的blog V2方圆 omg! ubuntu! Yafa-Xena: Gentoo bitbili: Gentoo farseerfc 的小窝 YangMame ManateeLazyCat codeplayer 菜菜博士 阿虚同学的储物间 Vamei Felix\u0026rsquo;s Blog：肥猫、猫菊苣 iovxw 土木坛子 约伊兹的萌狼乡手札 喵\u0026rsquo;s StackHarbor 512 Pixels: 512 Pixels is a blog covering Apple, computer history, space, design and lots of other fine nerdery. CS Slayer：囧脸，Fcitx 作者 李皓奇 Phoenix\u0026rsquo;s island：凤凰酱 ICEHONEY：秋水学姐 Plum\u0026rsquo;s Blog: Ubuntu 初等記憶體 Beyond the void Henry\u0026rsquo;s Blog: FreeBSD! Planet Ubuntu：Ubuntu 开发者博客汇集 钛山：开源软件吉祥物 编程随想 FiveYellowMice 荒原之梦  Entertainment\u0026amp;games  Unsplash：图片 Pexels：图片 Pxhere：图片 Pixabay：图片 Canva：图片 Kisscc0：图片 10wallpaper.com：壁纸 wallpaperhub：电子产品的默认壁纸 wall.alphacoders.com：动漫风壁纸 极简壁纸 Rijksmuseum：the museum of the Netherlands wallhaven Lorem Picsum：The Lorem Ipsum for photos. RedMonk：编程语言排行榜 IPAddress：查 ip StatCounter：OS、浏览器使用数据 APKCombo：Google Play 镜像 Internet Speed Test - Measure Latency \u0026amp; Jitter | Cloudflare MSDN, 我告诉你 Alternativeto：寻找 Linux 下替代软件 Windows绝赞应用 Softnic：软件下载，针对没有 Google Play 小众软件：windows 软件 酷安：安装 Microsoft 应用 W3Techs：World Wide Web Technology Surveys BuiltWith：Web Technology Usage Trends \u0026ldquo;LinuxQuestions.org Members Choice Results\u0026rdquo; EASYCOUNTER：couont wep pages hints using only html Steam Hardware \u0026amp; Software Survey YGOPRO：游戏王 萌卡社区：游戏王社区 YGOPRODECK：游戏王卡组 故宫博物院藏品总目 墨刀：原型设计工具 CanIUse：浏览器兼容性查询 ProcessOn：在线制作流程图 幕布：一键生成思维导图 Get Emoji ilovepdf：各种免费的 PDF 在线工具 找字网 有字库 Iconfont Color Hunt OSCI：Open Source Contributor Index Gitstar Ranking：GitHub 全球排名 Codrops：网页设计开发博客 Neumorphism：新拟态效果 uiGradients：渐变配色方案 kunstderfuge：该网站可以按照古典音乐家的人名查询，免费下载他们作品的 MIDI 文件 lofi.cafe：这个网站是一个制作精良的在线电台，播放工作学习时放松精神的背景音乐，可以根据音乐风格切换房间。 Slant：use Slant to find the best products and share their knowledge SHOUTcast：radio stations for Rhythmbox（how to） 中华人民共和国国家卫生健康委员会：可以查看医院等级信息 UNPKG：unpkg is a fast, global content delivery network for everything on npm. Skyline Webcams：该网站提供世界五大洲的直播摄像头，可以看到世界各个地点的实况。 figma：Figma是一个向量图形编辑器和原型设计工具，主要基于网页，透过macOS和Windows的桌面应用程序可启用额外的离线功能。 Manage your team’s work, projects, \u0026amp; tasks online • Asana JetBrains Mono Github Ranking freemdict The top 500 sites on the web DistroTest.net：Test a new operating system GAMUX：Linux Game Top500 Stack Overflow Developer Survey pixiv Server World 网址导航 Jamendo Music Magnatune: Music Magisk drivedroid: Boot a PC using ISO files stored on your Android phone TWRP pixelexperience Notion Avatar Maker 老生常谈 Distro Chooser 中华古籍资源库 My beautiful Linux development environment 中国哲学书电子化计划 Nyaa：It is one of the largest public anime-dedicated torrent indexes. 游戏机模拟器  PPSSPP：A PSP emulator. Citra：Nintendo 3DS Emulator，3DS中文游戏全集 RPCS3：The Open-source PlayStation 3 Emulator，PS3中文游戏合集下载 PCSX2：The Playstation 2 emulator 老男人游戏网：主机资源站 ROMSFUN   绅士天堂 Immortal Proxy 吾爱破解 萌娘百科 Wikipedia Greasy Fork：用户脚本 Mox.moe：Kindle漫畫 Lutris：Play all your games on Linux protondb：With Proton and Steam Play, many Windows games now work on Linux! Play On Linux：PlayOnLinux simplifies much of this and makes installing and using Windows programs in Ubuntu easier. Paint of Persia：这个工具让你可以在屏幕任何一个窗口，框选一部分内容，将其变成像素画。 NomnomNami YuriNovel ponpomuYuri 轻小说文库 宝书网 饭饭文学 La Memoria Vegetale 千秋书在 搬书匠 书栈网 BT之家 BD影视分享 在线之家 IGGGAMES PCGamesTorrents APKMODY: An Android App Store where you can download your favorite Premium / MOD / APK apps. Antivirus software：AV-Comparatives、AVTEST（杀毒软件评比） Yurifans Intel Product Specifications Google Public DNS：Configure your network settings to use the IP addresses 8.8.8.8 and 8.8.4.4 as your DNS servers. Norton DNS  Security (virus, phishing sites, and scam sites): 199.85.126.10 Security + Pornography: 199.85.126.20 Security + Pornography + Other: 199.85.126.30   OpenDNS  OpenDNS Family Shield: Preconfigured to block adult content — set it \u0026amp; forget it  208.67.222.123 208.67.220.123   OpenDNS Home: Our classic, free service with customizable filtering and basic protection   114DNS  纯净无劫持：114.114.114.114 和 114.114.115.115 拦截钓鱼病毒木马网站：114.114.114.119 和 114.114.115.119 拦截色情网站：114.114.114.110 和 114.114.115.110   LowEndBox: low end dedicated servers and cheap virtual private servers DOSBox: classic PC games emojimix: Combine two emojis into one and share them with your friends. Thousands of combinations are available. FODI: yuri lover Ubuntu certified hardware: Machines you can trust with Ubuntu Linux on Laptops: Reports on running Linux on notebook or laptop computers Library Genesis  Tutorial\u0026amp;materials  极客学院：在线教程 W3school：在线教程 菜鸟教程：在线教程 Arch Wiki FreeBSD Handbook Goodreads：找原文小说 图灵社区：电子书 Microsoft Docs 鸟哥 Linux 私房菜 中文马克思主义文库 Unix Toolbox Learn X in Y minutes openSUSE Wiki openSUSE Documentation Unofficial Guide to openSUSE Leap SUSE product documentation Ubuntu 中文 Wiki Ubuntu Manpage Ubuntu 正體中文 Wiki Full Circle：Ubuntu社区的独立杂志 Linux C编程一站式学习 亚嵌教育：Linux Books Linuxtopia：online resource for anyone learning or deploying enterprise level open source technology. Ultimate Guide: Getting Started With Ubuntu DB-Engines： Knowledge Base of Relational and NoSQL Database Management Systems Zoo Weekly MDN Web Docs YouZack：英语听力精听、背单词 现代 JavaScript 教程 CodinGame：编程学习平台，练习编程 FreeCodeCamp：编程学习平台，适合初学者 Codecademy：编程学习平台，适合初学者 JavaScript Weekly CodePen.io CSS Battle：一共有12个级别，需要你用 HTML和 CSS 100%还原它给出的页面，然后再尽量减少代码 Learn CSS Layout：学习 CSS 布局 CSS-Tricks：一些关于 CSS 的技巧优秀的教程和技巧 English++ Project 网道 Docs4dev 古登堡计划（Project Gutenberg）：专门提供公共领域的电子书下载 Project Bartleby：哥伦比亚大学的免费电子图书馆项目 The Labyrinth：中世纪研究 Spark Notes：学习笔记 Voice of the Shuttle：学术资源 Linux 101 掘金翻译计划 前端精读周刊 Linux就该这么学 金步国作品集：Linux KDE 25 年历史年表 KDE UserBase SEL 管理指南 鵝從未在裡面：ubuntu Official Ubuntu Documentation 开源世界旅行手册 书格 Eric S. Raymond 五部曲 开源软件指南 Fedora Project Wiki 如何成为黑客[English]-[Chinese] LibreOffice 中文社区 LibreOffice 简体中文用户文档 Linux Documentation Project Debian 参考手册 Linux工具快速教程 Complete Handbook: Gentoo Arch Linux 安装使用教程 Explanations Linux Wiki 极客手册：Fedora FreeBSD 从入门到跑路 KanCloud Free On-line Linux Technical Books and Tutorials working-on-gnu-linux  Open source project  Gitee：代码托管 Coding：代码托管 Apple Open Source USTC Open Source Software Mirror SourceForge：开源软件下载 OpenDesktop.org  pling xfce-look gnome-look KDE Store   FreshPorts: FreeBSD Ports FOSSHUB：Software Download Hub Welcome to Linux From Scratch!: Build your own custom Linux 超赞的 Linux 软件 GitHub：一个 GitHub 镜像，用于下载大文件 HelloGithub：分享 GitHub 上有趣、入门级的开源项目 snapcraft：The app store for Linux GNU mozilla Gnome Debian Ubuntu The Linux Kernel Archives AppImage: Linux apps that run anywhere FLATHUB: the home of hundreds of apps which can be easily installed on any Linux distribution. F-Droid：专门收录各类自由软件的 Android 应用商店。 Storybook：Storybook is an open source tool for building UI components and pages in isolation. gitmoji：An emoji guide for your commit messages Track Awesome List Compute Freely openSUSE Build Service：find rpm package for openSUSE and fedora \u0026hellip; StackEdit：科技爱好者周刊所用 \u0026gt;_ .bashrc PS1 generator musicForProgramming fedora SPINS: Alternative desktops for Fedora JSDELIVR：A free CDN for Open Source gentoo portage overlays KDE Applications Internet Archive Online UUID Generator Tool Launchpad：Launchpad is a software collaboration platform Pkgs.org：Packages for Linux and Unix Getdeb  ","permalink":"https://sakamotokurome.github.io/posts/links/","summary":"Portal 信息生产者主要是企业。 OSCHINA：开源资讯 少数派：软硬件使用技巧 Linux 中国：Linux 相关 Distrowatch：Linxu 发行版排行 FreeBSDNews LWN.net:","title":"Links"},{"content":"友邦拓 乌班图\n During the first ten years of this HOWTO\u0026rsquo;s life, I reported that from a new user\u0026rsquo;s point of view, all Linux distributions are almost equivalent. But in 2006-2007, an actual best choice emerged: Ubuntu. While other distros have their own areas of strength, Ubuntu is far and away the most accessible to Linux newbies. Beware, though, of the hideous and nigh-unusable \u0026ldquo;Unity\u0026rdquo; desktop interface that Ubuntu introduced as a default a few years later; the Xubuntu or Kubuntu variants are better.\nEric Steven Raymond - How To Become A Hacker\n 学习 Linux 几点忠告 不要當“傳教士”\n(這點有一個重大弊端：開放軟體沒有商業軟件那樣的宣傳，如果使用者都如此低調，用戶群不會大幅擴展。)\n很多人在討論區不斷的引起的Linux對比Windows之類的討論，甚至爭的面紅耳赤，這是沒有必要的\n這種爭論是浪費時間而沒有任何用處的。對，你花了一下午，用許多事實“捍衛”了Linux比Windows好這個說法。但是Windows的支持者並不會喜歡上Linux的，他們只是稍微退縮一下，然後找一些新的證據來跟你辯論。\n世界上的人們都在利用Linux的研究最前沿的科學，我們還在這裡討論“要不要用Linux的這種無聊的問題，什麼時候才能趕上時代前進的步伐？\n什麼叫做Window支持者，什麼叫做Linux的支持者？我們為什麼要支持某一個而反對另外一個？你不需要為 Linux的護法，不需要成為 Linux的支持者“或者”GNU的傳教士“ GNU / Linux的已經用事實向世界證明了它們的威力，已經被大多數人接受。你只需要安安靜靜享受的GNU / Linux的給你的樂趣和自由。\n你需要關心的不是你的工具是什麼，而是你用它做了什麼。精通的Linux並不說明任何問題，因為它只是一個工具而已。如果你用的Windows能很好的完成你的任務，那你就沒有必要費時間去熟悉Linux操作系統。直到有一天你發現一項任務只有Linux操作系統才能完成的時候再換也不遲，因為你身邊的的Linux的愛好者一定會很樂意的幫助你。\n如果你在使用Linux操作系統的過程中對它產生了感情，那麼你應該明白那些習慣於使用Windows的人也會對Windows產生依賴。類似的爭論還有很多：微軟 Office Word和TeX，Emacs和Vim，Wolfram Mathematica和Maple，侏儒，fvwm的和KDE的時候，狗派\u0026hellip; \u0026hellip;和冷靜地對自己說：“我不站在它們任何一邊。”儘管這有些不容易辦到。\n各人的需要不同，生活的環境不同。對你來說好的東西，對別人來說不一定好，我們需要尊重別人的選擇。如果你當面說別人正在用的程序不好，沒有必要。\n不要強迫自己”\n喜歡電腦的人總是有某些心理強迫傾向。有的人說：“鍵盤比滑鼠快。我不要用滑鼠。這樣才有高效率。”所以他在編輯器裡無論什麼時候總是用20W的，大於 10J這樣的命令到達目的點。他甚至覺得圖形界面是多餘的，乾脆都不裝 Xwindow。\n全部用鍵盤看起來的確比讓手離開鍵盤去拿鼠標，再回來“快”多了，但是快的擊鍵頻率不等於工作的高效率，對你的健康更沒有什麼好處。這只能把你變成打鍵盤的機器。\n當你正在檢查你的文章或者程序，思維正在隨著字符的含義流動，突然為 20W，大於 10J這樣的東西出現在你的腦子裡，是不是會打斷思路？不？那說明你當時思考的問題比較簡單，這些干擾還不會起到副作用。\n其實很多人用電腦的時候，思想都受到某種教學的束縛，上面這個只是教多數種類中的一種。某些人創造了很多這種數學，用他的工作方式來要求別人，嘲笑方式跟他不一樣的人。比如有的人嘲笑其它人寫程序不按ç 8字符縮進，嘲笑別人在六裡用方向鍵，嘲笑別人不知道是什麼增值稅，嘲笑其它人用在Java，C＃這種由地方選區回收內存語言 \u0026hellip; \u0026hellip;\n你不用管各種各樣的教學，電腦只是你的工具，你想怎麼用就怎麼用。沒有人能夠約束你，沒有人可以嘲笑你的工作方式。電腦明天就不再是這個樣子，所以今天你不用完全了解它。你沒有必要知道別人創造的一切，因為你需要留點時間自己創造些東西。只要有樂趣！\n當你下次修改文章的時候，不妨試試悠閒的用滑鼠在你眼睛看到的地方輕輕點一下。\n 如果你發現自己有類似的強迫症，建議去諮詢一下心理醫生。\n 不要“玩”Linux\nLinux的很多人用的時候會感覺很迷茫，該用哪個發行版本呢？是不是我少裝了什麼？怎麼升級這麼快啊！怎麼這麼不穩定！每當遇到新的軟件他就想試用，每當新的版本出現，他就更新，然後用鼠標在新的菜單裡選擇從來沒見過的程序來用用。\n其實你是為了玩Linux而使用Linux操作系統的，而沒有找到正確的理由來利用Linux操作系統。你首先要明確用電腦的目的，你用它是為了解決你的實際問題，而不是為了學習安裝操作系統，不是為了測試哪個版本好用，不是為了“趕上潮流，更不是因為你硬盤太大了，你想多佔點空間。\n如果你啟動了電腦之後不知道應該幹什麼，那麼最好先不要用電腦，因為你可能有更重要的事情需要做。這沒什麼說的。\n不用挑剔發行版本\n很多人剛開始用linux的時候，總是在懷疑別的發行版本是否比自己正在用的這個好，總是懷疑自己以後什麼時候會失去支持，不得不換用別的發行。所以很多人今天是紅帽，明天又換成了Debian的，一會兒又是巴布亞\u0026hellip; \u0026hellip;甚至有的人在一台機器上裝了兩個版本的Linux操作系統，然後比較哪一個好。\n其實你完全沒有必要這樣做，任何發行，只要你熟悉了，你在上面的工作方式幾乎不會受到任何影響。我以前一直用的紅帽，當我有一天在我的一台新機器上安裝Debian時，我發現使用紅帽的經驗完全沒有浪費。我用了一個下午就配置好了Debian，使它服服貼貼的聽我的話，就跟沒有換發行版本一樣。\nDebian，拓林思，SuSE，紅帽，Gentoo\u0026hellip; \u0026hellip;任何一個版本都是不錯的。很多人認為自己攢一個 LFS的是高水平黑客的象徵，但是不是每個人都有精力去了解所有細節。\n不要盲目升級\n不知道這是心理作用還是什麼，有的人看到比較大的版本號，就會很想換成那個。很多人的Redhat的本來配置的很舒服了，可是一旦Redhat的發行新的版本，他們就會盡快下載過來，然後選擇升級安裝。結果很多時候把自己原來修改得很好的配置文件給沖掉了。新的軟件又帶來了新的問題，比如有一次我的rxvt的就升級到2.7.8跟miniChinput衝突了，升級到Redhat的8.0，xmms的發現居然缺省不能放了MP3播放，XFree86的是i810的模塊在啟動上有新的漏洞，Mozilla中，會導致突然退出。\n如果你已經配置好了一切，千萬別再整體升級了，這會浪費你很多很多時間的，不值得。有句話說得好：“如果沒有打破，不解決它。”如果你的程序能夠完成你需要做的事情，你何必升級呢？？？？\n 是的，不論是從論壇還是其他的地方反映出來的大部分都是這個問題，要么比较SUSE和Ubuntu的好，要么比Ubuntu或者Mandriva的好等等的言論。很多人還是把Linux操作系統看成了一個表面的東西。並沒有塌下心來學習 Linux系統。\n 不要配置你不需要的東西\n如果你只想做一個像我這樣的普通用戶，主要目的是用的Linux來完成自己的科研任務和日常工作，那就可以不用系統管理員或者網絡管理員的標準來要求自己，因為當一個系統和網絡管理員確實很辛苦。普通用戶學習那些不經常用到的複雜的維護系統的工具，其實是浪費時間，學了不用是會很快忘記的！\n我不是一個合格的網絡管理員，我的服務器都只設置了我自己需要的功能，設置好ssh連接的ftp已經足夠了，那樣可以省去我很多麻煩。我從來不過度考慮“安全，因為 Linux操作系統缺省已經很安全了。我沒有磁帶機，就不用管tar的那些稀奇古怪的參數了，czf，xzf，ztf已經可以滿足我所有的需要。桑達，awk的，\u0026hellip;我也只會幾種常用的命令行。\n不要習慣的使用根帳號。在需要的時候才用！\n這是很多剛接觸的UNIX類操作系統的人常見的現象，他們不喜歡在管理系統的時候才用，而是一直用根帳號幹所有事情，配置系統，安裝程序，瀏覽網頁，玩遊戲，編程 \u0026hellip; \u0026hellip;\n結果有一天，他不小心在某個系統目錄使用了del * \u0026hellip;後果不堪設想 \u0026hellip; \u0026hellip;\n不要用商業的眼光來看待Linux\nLinux不是商業軟件，所以不要用要求Solaris操作系統，視窗那樣的眼光來看 Linux操作系統。自由軟件的作者們從來不拉攏用戶，他們對用戶不負有任何責任。實際上在自由軟件的世界裡，開發者“和”用戶“並沒有明確的界限，大家是朋友。\n自由軟件很可能只是滿足作者和他的朋友的需要，甚至是為了好玩而創造的。自由軟件不是完美的，自由軟件承認自己有缺點，它不會自吹自擂，蒙蔽“用戶”的耳目。這種對作者責任的解脫激發了作者的創造力，他們不用過分考慮“向上兼容，他們往往比背上重重包袱的商業軟件結構更合理，技術更先進。\n所以當你用某個自由軟件遇到困難的時候，不應該埋怨軟件的作者，因為他們對你並沒有義務。你不應該把自己當成一個挑剔的顧客，而要把自己作為這個軟件的顧問和一個和藹的建議者，這樣你才能理解作者寫這個程序時的快樂，在遇到問題時向作者反映，幫助他完善這個軟件，成為一個快樂的參與者。就像你的哥哥送你一個他用舊了的自行車，你應該珍惜這份友情，而不要在車壞了，或者騎車摔了一跤的時候大罵你的哥哥。如果你真的不能使用這種合作的心態，那麼最好不要使用這個軟件。\n這是一種先進的文化，它包含了互相合作，科學創新的精神。理解這一點不是很容易，很多人往往是因為不能理解這種文化而離開自由軟件。這對於作者來說並沒有什麼損失。\n幹你的正事去\n很多人跟我說，你的網頁浪費我好多時間來配置這配置那，一會兒是fvwm的，一會兒是Mutt中\u0026hellip; \u0026hellip;\n嗯\u0026hellip; \u0026hellip;那些東西都是我有空的時候一點一點積累的，如果你想一次性搞定所有那些東西，恐怕得花你幾個星期甚至幾個月的時間！並不是一定要搞定所有這些東西你才能正常工作的。除非你真的非得利用某個程序，或者你閒著沒事，否則你可以不管這些東西。\n上面幾條僅供參考\n以上只是個人意見，不一定適合所有人。取捨由你了！\nSettings DNS GUI\n 打开设置窗口 如果你连接到了 WiFi 网络，点击“Wi-FI”标签栏。否则，如果你有一个有线连接，点击『Network』标签栏。 选择你要设置 DNS 的网络连接，并且点击齿轮状的按钮，打开网络管理器。 选择 IPv4 设置标签栏。 禁用自动开关，并且输入 DNS 的 IP 地址，用逗号隔开。我们使用 Google DNS 域名解析服务器。 点击“Apply”按钮，保存修改。  这个修改应该会立即有效，除非那些已经缓存了的 DNS 条目。如果你想切换回旧的设置，打开网络管理器，IPv4 设置，并且启用自动开关。\nCLI\n# 显示当前网络连接 $ nmcli connection show # 修改当前网络连接对应的DNS服务器，这里的网络连接可以用名称或者UUID来标识 $ nmcli con mod ens160 ipv4.dns \u0026#34;114.114.114.114 8.8.4.4\u0026#34; # 配置生效 $ nmcli con up ens160 或者\n# Config File $ vi /etc/netplan/01-network-manager-all.yaml network: version: 2 renderer: NetworkManager ethernets: ens3: dhcp4: no addresses: - 192.168.100.199/24 gateway4: 192.168.100.1 nameservers: address: [114.114.114.114, 8.8.4.4] wifis: ... # Apply the changes you made in the config file $ sudo netplan apply # To check if the system successfully applied the changes $ systemd-resolve --status | grep \u0026#39;DNS Servers\u0026#39; -A2 DNS Servers: 114.114.114.114 8.8.8.8 8.8.4.4 注意：您系统上的文件可能缺少整个以太网或 wifi 部分。 在这种情况下，添加缺少的行，确保遵守示例中提供的缩进。\nTesting the Domain Name Resolution Speed\n$ time dig @114.114.114.114 Others  Bluetooth: OFF Formats: United States Blank screen: 10 Night Light: On Touchpad: OFF Fractional Scaling  SoftWare\u0026amp;Updates   Ubuntu Software 栏 Download from 选择 USTC MIRRORS。\n  Other Software 栏下开启 Canonical Partner Repositories (The partner repositories offer access to proprietary and closed-source software)。\n  Ubuntu 自动下载并安装对你的系统至关重要的安全更新。而这个自动更新经常导致你“无法锁定管理目录”错误。在 Updates 栏下选择\n For other packages, subscribe to: All updates Automatically check for updates: Every two weeks When there are security updates: Download and Install automatically When there are other updates: Display immediately Notify me of a new Ubuntu version: For long-term support versions    更新系统:\n$ sudo apt update $ sudo apt upgrade $ sudo apt autoremove   Livepatch: 更新内核不需要 Reboot required 了\n$ sudo ua attach \u0026lt;subscription\u0026gt;   Ubuntu Software \u0026amp; Update 卡在 cache refresh\n通过 apt update 可以看见是 Connecting to security.ubuntu.com Failed，解决办法是更改 /etc/hosts 文件添加其 IP，可通过 EASYCOUNTER 查找：\n## security.ubuntu.com 91.189.88.142 security.ubuntu.com 91.189.88.152 security.ubuntu.com 91.189.91.38 security.ubuntu.com 91.189.91.39 security.ubuntu.com ## archive.canonical.com 91.189.92.150 archive.canonical.com 91.189.92.191 archive.canonical.com 91.189.91.15 archive.canonical.com ## downloads.sourceforge.net 216.105.38.13 downloads.sourceforge.net ubuntu下如何获取源码包和源码\n  在 Software \u0026amp; Updates 中选中 Source code，不要 Reload，因为很慢，在命令行中 update。或者在软件源配置文件 /etc/apt/sources.list 中添加 deb-src 项。\n  获取 xxx 源码包的详细信息\n$ sudo apt-cache showsrc xxx   获取源码包，并将源码包解压到同名目录\n$ sudo apt-get source xxx   Upgrade Ubuntu version\n 打开 Software Updater 更新软件 打开 Software \u0026amp; Updates 选择 Updates 栏，在 Notify me of a new Ubuntu Version 中选择 For any new version 。 打开 Software Updater 更新到新 Ubuntu 版本。 使用 lsb_release -a 确认 Ubuntu 版本。  Input Method Editor 首先在 Language Support 中下载语言包\nIBus ubuntu libpinyin 输入法支持云拼音，只需要开启就可以了。\n搜狗细胞词库\n到hslinuxextra下载sougou-phrases-full.7z。\n经过与ibus开发者协商，ibus-pinyin的词库查找规则做了一些更改，只要在词库目录（就是有一个.db文件的那个目录，一般是/usr/share/ibus-libpinyin/db/目录）把新词库复制过来并改名为local.db就可以使用了，如果感觉词库不好，直接删除掉local.db，就可以让ibus使用原来的词库。\n覆盖以后，你把ibus重启一下ibus-daemon -d -x -r，如果你能打出下面的这个词组，说明生效了：\n弗雷德霍姆行列式 这个词库，基于ibus原有的android词库文件，另外增加了搜狗的细胞词库。\nFcitx 4 在Ubuntu Wayland 桌面中使用fictx管理中文输入法\n$ sudo apt install fcitx -y 设置 fcitx：\n  在 Language Support 中选择 fcitx，全局应用，并恢复 ibus 自定义切换语言快捷键设置。\n  (可选）wayland桌面默认不读取/etc/profile中的环境变量，而是从/etc/environment文件中读取，这是导致fcitx不能正常工作的原因。\n$ sudo vim /etc/environment INPUT_METHOD=fcitx GTK_IM_MODULE=fcitx QT_IM_MODULE=fcitx XMODIFIERS=@im=fcitx   输入法框架：\n 搜狗输入法 for Linux 百度输入法Linux版 Google拼音  其他：\n 百度输入法不能安装用于更换皮肤的 fcitx-ui-qimpanel，否则乱码。需要手动安装 fcitx-libs，否则开机不自动启动。 在 fcitx 与 sogoupinyin 安装完之后，需要重启才能使用。  皮肤：\n fcitx 皮肤：/usr/share/fcitx/skin sogoupinyin 皮肤：/usr/share/sogou-qimpanel/skin。  旧：可以改名为 zip 解压 新：受版权保护    Fcitx 5 安装\n配置工具 KDE 下使用 kde-config-fcitx5， Gnome 下使用 fcitx5-config-qt。\n20.04 (20220122) 官方仓库里没有 Gnome 的配置工具 kcm-fcitx5（内含 fcitx5-config-qt），因此通过 ppa:zhsj/fcitx5 来安装\n$ sudo add-apt-repository ppa:zhsj/fcitx5 $ sudo apt-get update $ sudo apt install fcitx5 fcitx5-chinese-addons 或者也可以通过**通过 flatpak 安装**。\n安装后在 Ubuntu 在 Language Support 里修改输入法系统为 fcitx5，记得点击 Apply System-Wide。\n肥猫百万大词库\nDownload latest version of \u0026ldquo;zhwiki.dict\u0026rdquo; from https://github.com/felixonmars/fcitx5-pinyin-zhwiki/releases\nCopy into ~/.local/share/fcitx5/pinyin/dictionaries/ (create the folder if it does not exist)\n可以在设置中看到是否启用，或者输入 “jinjinjin” 会出现 “鑫”。\nAutomatically switch wallpapers Apps  Shotwell：在侧边栏 Photos 中 Ctrl + A，在菜单栏 File 中选择 Set as Desktop SlideShow\u0026hellip;；这会把图片复制到 .local/share/shotwell/wallpaper，并在该目录生成 wallpaper.xml，wallpaper.xml 定义自动切换壁纸动画。 替代软件： Variety、BingWall 等。 脚本分享：styli.sh、lswc、 动态壁纸：komorebi、LiveWallpaper  unsplash   gsettings set org.gnome.desktop.background picture-uri file://$HOME/Wallpaper\n  添加脚本\n$ vi $HOME/.unsplash.sh #!/bin/bash SAVE_DIR=$HOME/DataOne/Unsplash FILE_NAME=daily$(date \u0026#39;+%Y%m%d\u0026#39;).jpeg wget -O $SAVE_DIR/$FILE_NAME https://source.unsplash.com/1920x1080/daily cp $SAVE_DIR/$FILE_NAME $HOME/Wallpaper 在 Unsplash Source 查看更多 API。\n  crontab -e\n0 12 * * * /home/vane/.unsplash.sh   除了使用 crontab 外，还可以使用 Startup Applications Preferences 添加一个启动项。\n  wallhaven   gsettings set org.gnome.desktop.background picture-uri $HOME/Wallpaper\n一般文件内容开头都会有一个文件类型的标记，根据文件名后缀只是一个快捷的方法，不用读取文件内容就判断文件类型，但不是唯一的方法。\n  vi $HOME/.wallhaven/wallhaven.sh\n#!/bin/bash  WORK_DIR=$HOME/.wallhaven SAVE_DIR=$HOME/Pictures/wallhaven IMG_URL=https://w.wallhaven.cc/full function GetListing() { echo \u0026#39;get listing\u0026#39; listing=$(curl https://wallhaven.cc/api/v1/search?apikey=\u0026lt;API KEY\u0026gt;\u0026amp;categories=010\u0026amp;purity=111\u0026amp;atleast=1920x1080\u0026amp;ratios=16x9\u0026amp;sorting=random\u0026amp;order=desc\u0026amp;page=1) echo \u0026#39;save listing\u0026#39; echo $listing | jq -r \u0026#39;.data[].path\u0026#39; | awk -F \u0026#39;/\u0026#39; \u0026#39;{print $NF}\u0026#39; \u0026gt; $WORK_DIR/listing echo \u0026#39;save res\u0026#39; cat $WORK_DIR/listing | wc -l \u0026gt; $WORK_DIR/res SetWallpaper } function SetWallpaper() { if [ -a $WORK_DIR/res ]; then echo \u0026#39;read res\u0026#39; read res \u0026lt; $WORK_DIR/res if [ $res -ne 0 ]; then echo \u0026#39;get img\u0026#39; img=$(cat $WORK_DIR/listing | tail -${res} | head -1) echo \u0026#34;down $imgfrom $IMG_URL/${img:10:2}/$img\u0026#34; curl -o $SAVE_DIR/$img $IMG_URL/${img:10:2}/$img if [ $? -eq 0 ]; then echo \u0026#39;set wallpaper\u0026#39; cp $SAVE_DIR/$img $HOME/Wallpaper echo \u0026#39;res-1\u0026#39; echo $(($res - 1)) \u0026gt; $WORK_DIR/res echo \u0026#39;exit\u0026#39; exit 0 else echo \u0026#39;download error\u0026#39; SetWallpaper fi else echo \u0026#39;res=0\u0026#39; GetListing fi else echo \u0026#39;no res\u0026#39; GetListing fi } SetWallpaper 使用 Shell 脚本来处理 JSON，jq Manual，wallhaven API v1 Documentation\n  crontab -e\n0 12 * * * /home/vane/.wallhaven/wallhaven.sh Gsettings 无法在 Cron 中使用：出现此问题是因为 cron 仅使用一组非常有限的环境变量。 唯一一个负责在将其设置为 cron 作业时以正确方式运行问题脚本的环境变量是 DBUS_SESSION_BUS_ADDRESS。\n  Astronomy #!/bin/bash API_KEY=zTL5rJmctXwHcsjfCSalfDRNFTeaVYa9FxgINVVU HTTP_REQUEST=https://api.nasa.gov/planetary/apod?api_key=$API_KEY HTTP_RESPONSE=$(curl $HTTP_REQUEST) IMG_HDURL=$(echo $HTTP_RESPONSE | jq -r \u0026#39;.hdurl\u0026#39;) IMG_FILENAME=$(echo ${IMG_HDURL##*/}) curl -o $HOME/DataOne/Images/Astronomy/$IMG_FILENAME $IMG_HDURL cp -av $HOME/DataOne/Images/Astronomy/$IMG_FILENAME $HOME/Wallpaper Social Telegram 先通过手机登录，再在电脑端登录。电脑先登录，手机老是收不到验证码。\n简介   Telegram —— 中文名又称\u0026quot;电报\u0026quot;，或简称\u0026quot;TG\u0026quot;。\n  Telegram 是跨平台的即时通信软件，其客户端是自由及开放源代码软件，但服务器是专有软件。\n  Telegram 在中国大陆境内无法直接连接，注册和使用都需要科学上网，请自备节点和工具。\n  下载：Telegram 有官方版和第三方版本，但出于安全和隐私的考虑，推荐大家使用 Telegram 官方版客户端\n  推荐设置  Privacy and Security  Phone Number  谁能看见我的手机号码：Nobody 谁能通过手机号码找到我：My Contacts   Forwarded Messages：Nobody Calls：Nobody Groups：My Contacts   Local Passcode：本地密码只是本设备打开 Telegram 的应用密码 Two-Step Verification：为了账号安全，强烈推荐您设置两步验证密码。 Delete my account：推荐您设置为一年  隐私保护注意事项  资料设置  昵称及用户名：避免使用与其他社交平台相同或相似的昵称及用户名 手机号码：在\u0026quot;设置——隐私——电话号码\u0026quot;中设置\u0026quot;不允许任何人查看我的手机号码\u0026quot;和\u0026quot;仅允许联系人通过手机号码找到我\u0026quot;。   群组聊天：Telegram 的群聊是\u0026quot;不安全\u0026quot;的。 公开群组的所有聊天内容都可被其他人查看，即使他人并未注册 Telegram； 对于群组内的机器人，它们可以收集群组内的绝大部分消息。 媒体文件：在分享照片时，请注意使用专业修图软件打码处理关键信息，并清除照片包含的地理位置信息 分享链接：从其他平台分享内容至 Telegram 时，请注意清除分享链接中的用户 UserID 识别信息，他人完全有可能从您的分享链接中获取您的用户信息。 第三方客户端：如无特殊需要，请使用官方 Telegram 客户端。第三方客户端有能力获取和控制您的账户，读取您全部的聊天记录，收集您设备的可识别信息，包括但不限于：手机号、设备型号、IMEI码、MAC码等。  常见问题及解答  无法给他人发送私聊：“Sorry, you can only send messages to mutual contacts at the momet.”  @SpamBot But I can\u0026rsquo;t message non-contacts！ No，I\u0026rsquo;ll never do any of this   群组和频道有什么类型？有什么特点？  群组(Group)或者频道(Channel)有两种类型。  一种是公开群组(Public Group/Channel) 一种是私有群组(Private Group/Channel)   公开群组(Public Group/Channel) 有自定义设置的ID，所有人可以通过搜索功能，输入id查询到相应的群组。公开群组的历史消息对所有人可见，即使没加入公开群组，也可以查看群组历史消息。 私有群组(Private Group/Channel) 没有自定义的ID，要加入只能通过点击邀请链接或者被邀请入群， 在私有群组，群主可以设定历史消息的可见性。而对于没有加入群组的人，则不可以查看群组的消息。   Telegram 用户名是什么？  其他用户可以通过用户名找到您，您将出现在“全局结果”下的联系人搜索中。这样人们就可以在不知道您的电话号码的情况下通过 Telegram 与您联系。 由于用户名的唯一性，可以防止他人盗用你的头像和昵称冒充你。   如何添加联系人？：添加和删除联系人都是单向操作，对方设备并不会同步。 添加非手机号码联系人后，对方能知道自己的手机号码吗？：如果想取消分享你的手机号，请到隐私设置(Privacy and Security)中找到手机号码(Phone Number)的设置，在里面移除对方即可。 不登陆 Telegram 如何查看频道消息？：Telegram 公开频道可以直接通过浏览器输入 https://t.me/s/频道id 访问，不需要拥有TG账号。  进阶知识 什么是 MTProxy 代理？\n MTProxy 是 Telegram 的官方项目，仅能用于代理 Telegram 软件 MTP 代理是在 Telegram 中内置的代理程序，可以直接在软件内配置，而不需要下载任何其他 App 来配置代理  主题与美化 美化主题频道\n 官方 Desktop 桌面版主题频道 @themes 官方 Android 安卓主题频道 @Androidthemes  Mutt Mutt 是一个基于文本的邮件客户端，因其强大的功能而闻名。 Mutt虽然已诞生二十多年了，但仍然是大量用户的首选邮件客户端。\nMutt主要侧重于作为邮件用户代理（MUA），最初是为了查看邮件而编写的。 与其他邮件应用程序相比，稍后实现的功能（检索，发送和过滤邮件）比较简单，因此用户可能希望使用外部应用程序来扩展Mutt的功能。\n模块搭配方案 就像穿衣搭配一样，收件发件过滤邮件转发邮件各种功能都有很多种程序可以用，mutt怎么搭配呢？\n常用选项有这些(User/Transport/Delivery)：\n MUA 收件：fetchmail或getmail或OfflineIMAP MTA 发件：sendmail或msmtp或postfix。其中msmtp兼容强，postfix对国内不友好 MDA 分类: procmail或maildrop 邮件编辑：VIM。  一般搭配是：\n 老式搭配：mutt + getmail + sendmail + procmail 新式搭配：mutt + fetchmail + msmtp + maildrop  这里我们用：mutt + fetchmail + msmtp + procmail\n安装：\n$ sudo apt install mutt fetchmail msmtp procmail -y Mutt或各个写协作程序在配置前都是不能使用的，学习曲线还是比较陡峭的，所以要做好准备去花好一段去了解和学习各个部件。\n大概的配置流程是：\n 配置收件：~/.fetchmailrc 配置过滤：~/.procmailrc 配置发件：~/.msmtprc 配置mutt框架本身：~/.muttrc  注意：初学过程中，不要一上来就配置mutt。最好是先从各个部件开始：收件-\u0026gt;过滤邮件-\u0026gt;阅读邮件-\u0026gt;发件-\u0026gt;mutt界面，按照这种顺序。\n收件：配置Fetchmail  Fetchmail是由著名的《大教堂与集市》作者 Eric Steven Raymond 编写的。\n Fetchmail是一个非常简单的收件程序，而且是前台运行、一次性运行的，意思是：你每次手动执行fetchmail命令，都是在前台一次收取完，程序就自动退出了，不是像一般邮件客户端一直在后台运行。\n注意：fetchmail只负责收件，而不负责存储！所以它是要调用另一个程序如procmail来进行存储的。\nfetchmail的配置文件为~/.fetchmailrc。然后文件权限最少要设置chmod 600 ~/.fetchmailrc\n比如我们要设置多个邮箱账户同时收取，那么配置如下：\npoll pop.AAA.com protocol POP3 user \u0026#34;me@AAA.com\u0026#34; password \u0026#34;123\u0026#34; poll pop.BBB.com protocol POP3 user \u0026#34;me\u0026#34; there with password \u0026#34;123\u0026#34; is falko here fetchall poll pop.CCC.com protocol POP3 user \u0026#34;me\u0026#34; there with password \u0026#34;123\u0026#34; is till here keep poll pop.DDD.com protocol POP3 user \u0026#34;me\u0026#34; password \u0026#34;123\u0026#34; ## QQ 邮箱 poll pop.qq.com port 995 protocol POP3 user \u0026#34;1664548605@qq.com\u0026#34; password [授权码] ssl keep # 全局选项 mimedecode # 不加 -d %T 就会报 ~/Mail/inbox is not a mailbox. 错误 mda \u0026#34;/usr/bin/procmail -d %T\u0026#34; 其中：\n 各种参数可以不按顺序，也可以不在一行。 空格隔开每个参数，poll隔开每个账户。 here, there, with, is等等，都不是关键词，随便写不影响参数。 以下是必填  poll后面是邮件服务器的地址，一般是pop.xxx.com protocol后面是收件协议，一般是pop或pop3 user后面是用户名，可以是username，也可以是邮箱地址 password后面是密码   sslproto：可能会报错 fetchmail: pop.qq.com: upgrade to TLS failed.，故可以禁掉SSL，同 man 手册查到  加上option --nosslcertck，虽然有报错，但至少可以收邮件了。 加--sslprotocl '', 注意要用空字符串   四选一：  nofetchall ：仅检索新消息（默认）。 fetchall ：获取所有消息，无论是否看到。 keep ：不要从服务器上删除看到的消息。 nokeep ：从服务器中删除看到的消息。   mimedecode用来自动解码MIME mda后面指定本机安装的邮件过滤分类程序。如果不填，则收取的邮件在本地不会保存。注意用which procmail查一下路径。 QQ 邮箱客户端设置 Outlook 设置：失败了  配置完成后，可以运行fetcmail -v来看看是否有错误信息，如果能够正常显示很多行的收取信息，那么就能正确登录邮箱收取了。\n一般收取的命令如下：\n# 只收取未读邮件 $ fetchmai # 收取所有邮件 $ fetchmail -a # （重要）收取新邮件，但不在服务器端删除已经收取的邮件 $ fetchmail -k 但是fetchmail只负责收取，不负责“下载”部分，你找不到邮件存在哪了。 所以还需要配置MDA分类器，如procmail，才能看到下载后的邮件。\n注意：Fetch其实不是在Mutt“里”使用的，而是脱离mutt之外的！也就是说，Mutt只负责读取本地存储邮件的文件夹更新，而不会自动帮你去执行fetchmail命令。\n你必须自己手动执行，或者用Crontab定期收取，或者设为Daemon守护进程，还可以在Mutt中设置快捷键执行Shell命令：\n  要使fetchmail作为守护进程运行，我们必须编辑/etc/default/fetchmail并将START_DAEMON设置为yes\n$ vi /etc/default/fetchmail START_DAEMON=yes 接下来，必须创建配置文件/etc/fetchmailrc并设置 set daemon 300 （这意味着fetchmail应该每300秒检索一次电子邮件）。\n  设置Mutt快捷键收取邮件的方法是在~/.muttrc中加入macro：\nmacro index,pager I \u0026#39;\u0026lt;shell-escape\u0026gt; fetchmail -vk\u0026lt;enter\u0026gt;\u0026#39; 这样的话，你就可以在index邮件列表中按I执行外部shell命令收取邮件了。\n  邮件过滤：配置Procmail Procmail是单纯负责邮件的存储、过滤和分类的，一般配合fetchmail收件使用。\n在Pipline中，fetchmail把收到的邮件全部传送到Procmail进行过滤筛选处理，然后Procmail就会把邮件存到本地形成文件，然后给邮件分类为工作、生活、重要、垃圾等。\n当然，分类规则是自己可以指定的。可以根据发信人、主题、长度以及关键字 等对邮件进行排序、分类、整理。\nProcmail 的配置文件是 ~/.procmailrc ，记得改权限：chmod 600 ~/.procmailrc。\n内容也非常简单，前面是邮件位置、日志等默认选项，后面则是一块一块的过滤规则。\n基本配置：\n# 邮件存储地址 MAILDIR=$HOME/Mail # 默认：收件箱 DEFAULT=$MAILDIR/inbox VERBOSE=off LOGFILE=/tmp/procmaillog # 某个垃圾邮件规则 :0 * ^From: webmaster@st\\.zju\\.edu\\.cn # 垃圾文件的存储位置 /dev/null # 其它所有都存到收件箱中 :0: inbox/ 其中，$HOME/Mail是设定的邮件存储位置。\n我们需要手动创建mkdir ~/Mail，否则程序会报错。\n配置好后，我们再测试一下就会看到：\n$ fetchmail -a 78 messages for 1664548605@qq.com at pop.qq.com (2843793 octets). reading message 1664548605@qq.com@pop.qq.com:1 of 78 (36692 octets) not flushed ... $ tree ~/Mail /home/vane/Mail └── inbox 0 directories, 1 file $ du -h Mail/inbox 2.1M\tMail/inbox 可以看到，所有邮件都保存在了inbox这个单一文件中。这个文件可以打开看到MIME格式(协议)的邮件源码。就像HTML一样，展示给我们的和背后的源码不一样。\n那么怎么把这个类似HTML的MIME格式邮件解析为我们人能读懂的内容呢？——这个我们就要靠mutt自己了，mutt自身具备基本的MIME邮件解析功能（不包括HTML格式邮件读取）。\n发件：配置msmtp msmtp是作为sendmail发邮件程序更好的替代品。\nmsmtp的配置文件为~/.msmtprc，记得改权限：chmod 600 ~/.msmtprc\n配置内容比收件还简单，因为发件永远比收件简单。\n基本配置：\naccount default auth login host smtp.XXX.com port 587 from ME@XXX.com user ME password passwd # 关于tls，如果是阿里云则不用写，如果是Outlook的话，必须写 tls on tls_starttls off tls_certcheck off # QQ 邮箱例子 account default # QQ邮箱这里必须是 on，否则会 535 Login Fail auth on host smtp.qq.com port 587 from 1664548605@qq.com # user 必须是 @ 之前的部分，不能自定义，否则会 535 Login Fail user 1664548605 password [授权码] tls on tls_starttls off tls_certcheck off logfile /tmp/msmtp.log QQ 邮箱例子：使用mutt+msmtp在Linux命令行界面下发邮件。\n总之，哪怕QQ 邮箱设置对了，也要多试几次才能发送成功。\n主界面：配置Mutt Mutt的配置文件为~/.muttrc，记得改权限：chmod 600 ~/.muttrc\n另外：mutt的配置文件还可以放在~/.mutt/muttrc。这种方法有一个好处，即~/.mutt/目录下可以放很多主题、插件等文件。\n基本配置：\n# 通用设定 set use_from=yes set envelope_from=yes #移动已读邮件 set move=yes #回复的时候调用原文 set include set charset=\u0026#34;utf-8\u0026#34; #自动显示HTML auto_view text/html # 发送者账号 set realname=\u0026#34;Vane Hsiung\u0026#34; set from=\u0026#34;1664548605@qq.com\u0026#34; # 分类邮箱 #Mail box type set mbox_type = Maildir set folder = \u0026#34;$HOME/Mail\u0026#34; #INBOX set spoolfile = \u0026#34;$HOME/Mail/inbox\u0026#34; #Seen box set mbox=\u0026#34;$HOME/Mail/seen\u0026#34; #Sent box set record=\u0026#34;$HOME/Mail/sent\u0026#34; #Draft box set postponed=\u0026#34;$HOME/Mail/draft\u0026#34; # 关联程序（需要自己用which命令确定一下） # 默认使用 nano set editor=\u0026#34;vim\u0026#34; set sendmail=\u0026#34;/usr/bin/msmtp\u0026#34; 以上如果有什么问题，可参考etchmail + proc + msmtp + mutt configuration samples。\n确认邮箱服务器 即使上面配置一切OK，也不一定能正常收发邮件。因为你用的Gmail、QQ、网易、阿里云等等，后台都有一系列的第三方收取设置。这是各不相同的。\n除了第三方客户端的允许，我们还要设置POP。最好放开全部邮件或者最近30天，然后禁止客户端删信。这是什么意思呢？POP默认客户端在收件后，服务器上的邮件就自动删除了！这个不太合适，所以必须要禁止。\n基本操作 邮件列表操作：\n 基本：q:Quit, d:删除当前邮件, s:将邮件移动至指定文件夹, m:创建新邮件, r:回复当前邮件, ?:帮助 移动：j/k 上下移动邮件, z/Z上下翻页, \u0026lt;Number\u0026gt; 跳至序号处（不进入邮件） \u0026lt;Enter\u0026gt; 打开选中的邮件 /在当前文件夹搜索 d 将选中邮件标记为删除, N 将选中邮件标记为未读, $ 让标记的东西生效，如删除、未读等。 f 转发选中邮件, e 编辑选中邮件 c切换文件夹(inbox/seen/draft等), 需要输入文件夹名称，或按?在列表里选择，j/k上下移动。  在邮件中的操作：\n j/k 上一封／下一封邮件, \u0026lt;Space\u0026gt;: 向下翻页, \u0026lt;Enter\u0026gt;: 向下滚动 e 编辑当前邮件, t编辑TO，c编辑CC，b编辑BCC，y发送邮件，a添加附件，Return查看附件，E编辑附件，D删除附件  使用命令操作：\nMutt如同Vim一样，不光可以把命令绑定为快捷键，还能直接输入:直接输入命令。 但是稍有不同的是，Mutt称之为Action，而且需要用:exec \u0026lt;命令\u0026gt;这样格式执行。\n比如sidebar侧边栏的移动，命令是：sidebar-next, sidebar-prev。 那么我们可以直接输入:exec sidebar-next，按下回车执行。\nIRC 简介 芬兰人雅尔可·欧伊卡利宁（Jarkko Oikarinen）于1988年8月创造了IRC来取代一个叫做MUT的程序。\n IRC（Internet Relay Chat的缩写，“因特网中继聊天”）是一个位于应用层的协议。 其主要用于群体聊天，但同样也可以用于个人对个人的聊天。 一个IRC服务器可以连接其他的IRC服务器以扩展为一个IRC网络。 IRC 不强制注册；但如果你注册了，就可以强制把占用自己唯一 ID 的人踢下线。 IRC 协议简单，开源实现多，其第三方机器人程序非常众多，几乎每种语言都有一个实现。 IRC 是开源社区会议标准；因此，许多开源世界的技术大牛混在那里。  irchelp：一个致力于帮助用户了解IRC的网站。\nIRC：Linux文档项目的IRC HOWTO\n服务器 首先要区分一些概念：\n Networks：是指的互相隔离的网络，如Freenode和DALnet这些是世界知名的网络，但互相隔离，频道不共享。 Servers：Network网络中的某一台电脑服务器，你加入世界上任何一个server都能加入这个Network。IRC是一个分布式的客户端/服务器结构。通过连接到一个IRC服务器，我们可以访问这个服务器以及它所连接的其他服务器上的频道（即这个 Network 中所有频道）。  频道存在于一个IRC服务器上。一个频道类似于一个聊天室，频道名称必须以#符号开始，例如#irchelp。\n要使用IRC，必须先登录到一个IRC服务器上，最常见的为irc.freenode.net——最大的IRC网络，为免费和开源软件社区，非营利组织和相关社区提供讨论设施。\nFreenode 用户模式。\nIRC使用的服务器端口有:\n 6667（明文传输，如irc://irc.freenode.net） 6697（SSL加密传输，如ircs://irc.freenode.net:6697）。  IRCD: 简称互联网中继聊天守护，是服务器软件实现了IRC 协议，使人们通过上网彼此交谈（交换文本即时消息）。\n客户端 IRC用户透过客户端软件和服务器相连。\nInternet Relay Chat客户端的比较：\n   Client Homepage Description     Irssi https://irssi.org/ 支持IPv6的模块化文本UI IRC客户端。轻量级流行客户端。   WeeChat https://weechat.org/ 便携式和多接口（文本，Web和GUI）IRC客户端。    Irssi 安装\n$ apt install irssi 命令行输入irssi即进入了聊天室。\n和一般Linux程序的一般命令、格式都不同，IRC客户端一般有自己的命令。窗口右下方[(status)]是输入命令的地方。\n一般命令(不区分大小写)：\n /quit，退出程序。一般的ctrl-c, ctrl-d, esc, q之类的都不管用 /help，帮助 /network list 查看已保存的服务器列表 /connect xxx.xxx.xxx 连接某服务器。连接 freenode，需要到 https://irc.com/login/sso 注册，然后按照 https://freenode.net/kb/answer/sasl 进行设置。 /join xxx 加入某channel /leave或/part 离开当前channel /normal或/n 查看当前channel的人数 /list -YES 查看当前服务器的所有chennels (慎用) /nick NewNickName 更改当前昵称 /msg NickName Content 给某人发送消息，一般都是给/msg nickserv管理人NPC发送消息  常用快捷键：\n Alt + 1/2/3/4...，切换window窗口，一般一个channel一个窗口 Alt + n/p，上下滚动屏幕  IRC 常用缩写词\n配置\n如果想长期保存、备份一个固定的程序配置，那么就需要修改配置文件。\nirssi默认的配置文件为~/.irssi/config。\n配置中，会在第一次运行时就自动设置了一些，包括根据当前电脑账户的用户名设置nickname等。整个配置，是一直“类似”JSON的格式。\nsettings ：记录自己的名字：nick, real_name, user_name\nservers ：这是指的Network而不是具体某台server，如Freenode、Dal、ESPer、EFnet等大型网络。服务器配置案例：\nservers = ( { address = \u0026#34;irc.dal.net\u0026#34;; chatnet = \u0026#34;DALnet\u0026#34;; port = \u0026#34;6667\u0026#34;; }, { address = \u0026#34;路径\u0026#34;; chatnet = \u0026#34;下面chatnet对应的名称\u0026#34;; port = \u0026#34;端口\u0026#34;; autoconnect = true; use_ssl = \u0026#34;yes\u0026#34;; password = \u0026#34;用户名:密码\u0026#34;; } ); chatnets：记录各个网络的登录信息，也可以作为“别名”，这样每次/connect不用输入全路径了。配置完每个服务器后，还要配置相应的chatnets，每一条的名称都要与servers中的对应。\nchatnets = { DALnet = { type = \u0026#34;IRC\u0026#34;; max_kicks = \u0026#34;4\u0026#34;; max_msgs = \u0026#34;20\u0026#34;;max_whois = \u0026#34;30\u0026#34;; }; Freenode = { type = \u0026#34;IRC\u0026#34;; max_kicks = \u0026#34;4\u0026#34;; max_msgs = \u0026#34;20\u0026#34;;max_whois = \u0026#34;30\u0026#34;; autosendcmd = \u0026#34;/msg nickserv identify MyName MyPassword\u0026#34;; }; }; channels ：记录自己收藏的频道名。RC的频道不是用URL之类很复杂的东西，全都是用#tag这种简单一个标签来区分的，非常好记。\nchannels = ( { name = \u0026#34;#lobby\u0026#34;; chatnet = \u0026#34;EsperNet\u0026#34;; autojoin = \u0026#34;No\u0026#34;; }, { name = \u0026#34;#freenode\u0026#34;; chatnet = \u0026#34;Freenode\u0026#34;; autojoin = \u0026#34;No\u0026#34;; }, ); statusbar：界面美化的设置。目前IRSSI的世界里，唯一知名的主题只有weed。\nAudio Pipewire 从 Pulseaudio 切换到 Pipewire 的理由是对于蓝牙的“LDAC”“APTX”之类编码格式的支持\nRhythmbox Music\n搜 \u0026ldquo;无损音乐\u0026rdquo; \u0026ldquo;车载音乐\u0026rdquo; 打包下载。\n电台\n很多电台是基于mms协议的，如果rhythmbox无法播放mms协议的电台，则需要安装支持mms协议的gstreamer插件——因为rhymbox使用gstreamer做后台解码。支持mms协议的插件为gstreamer bad插件，所以执行命令：\n$ sudo apt-get install gstreamer0.10-plugins-bad 同样的，如果需要播放mp3文件则安装ugly插件，需要播放wma文件则安装ffmpeg插件。\n电视台和电台MMS地址\n分享Rhythmbox电台列表\n最终还是没什么无法播放mms，因为 Rhythmbox 报错了。\nSpotify 作为世界上最大的音乐流媒体服务商，Spotify 因优秀的设计和精准的音乐推荐算法让不少人为之倾心。\n在正式注册 Spotify 之前，我们先来看一看曲库的问题。由于不同地区的歌曲版权差异，Spotify 在不同地区提供服务时，其相应的曲库也有所不同。例如港区的曲库中，粤语歌就要比美区多，相反美区的英文歌就要比港区多。同理，若你喜欢听其他语种的歌，注册当地的 Spotify 则是最好的选择。\n注册后要是发现当前的地区选择并不是很理想，想要换区也是可行的。首先要挂上自己想要换到地区的代理，然后进入自己的「Profile/资料」界面，点击「Edit Profile/修改资料」，「Country/国家」这个选项就会出现你当前所挂代理地区，保存更改即可换区成功。\n登录的话，需要先在登录界面设置Proxy重启。登录后在设置里改回来，不再需要Proxy了。\nSpotifyd An open source Spotify client running as a UNIX daemon.\nNeteaseMusic Linux 下官方只发布了 deb 包，flatpak 直接安装\nNetEase-MusicBox 网易云音乐命令行版\nQQMusic 官网下载的要比 UWP 强太多\nlx-music-desktop 一个基于 electron 的音乐软件\nPulseAudio PulseAudio 是在GNOME 或 KDE等桌面环境中广泛使用的音频服务。它在内核音频组件（比如ALSA 和 OSS）和应用程序之间充当代理的角色。\n配置 Pulseaudio 支持通过多种模块扩展其功能。在这里可以找到PulseAudio可用的模块的详细信息： Pulseaudio Loadable Modules。增加 load-module \u0026lt;module-name-from-list\u0026gt; 到文件 /etc/pulse/default.pa就可以启用对应的模块。\n启动 警告： 如果你给每个用户拷贝了配置文件（例如client.conf, daemon.conf 或者 default.pa）到~/.config/pulse/ 或者 ~/.pulse/目录下，确定这些文件的修改与/etc/pulse/下的文件修改同步，否则PulseAudio可能由于配置文件错误而拒绝启动。\n注意： 大多数X11环境会在启动X11会话时自动启动PulseAudio。\n少数情况下PulseAudio在启动X11时没有自动启动，可运行下面的命令启动：\n$ pulseaudio --start 运行下面的命令可以终止PulseAudio：\n$ pulseaudio --kill 在不支持的桌面环境中自动启动 注意： 正如之前所说, 如果用户安装了桌面环境，PulseAudio很可能通过 /etc/X11/xinit/xinitrc.d/pulseaudio文件或者 /etc/xdg/autostart/目录下的文件自动启动\n查看PulseAudio是否正在运行：\n$ pgrep -af pulseaudio 369 /usr/bin/pulseaudio 如果PulseAudio未运行而且用户正在使用X11，运行下面的命令可以在启动PulseAudio的同时加载需要的X11插件：\n$ start-pulseaudio-x11 如果你没有运行GNOME, KDE或者Xfce，并且你的~/.xinitrc文件并未引用/etc/X11/xinit/xinitrc.d目录下的文件内容，为了让PulseAudio自动启动，你可以这样做：\n~/.xinitrc /usr/bin/start-pulseaudio-x11 后端设置 ALSA 配置ALSA与PulseAudio共同工作必须的文件/etc/asound.conf。\n为了防止应用程序使用ALSA的OSS模拟功能而忽略PulseAudio（从而导致其他应用程序无法播放声音），确定snd_pcm_oss模块没有在系统启动时自动加载。如果该模块已经被加载(lsmod | grep oss)，运行下面命令以卸载该模块：\n# rmmod snd_pcm_oss 均衡器 PulseAudio内置了10段均衡器系统，按下列步骤操作以启用均衡器：\n加载均衡器通道和dbus协议模块 $ pactl load-module module-equalizer-sink $ pactl load-module module-dbus-protocol 安装并运行图形前端 $ sudo apt install pulseaudio-equalizer $ qpaeq 每次启动时加载均衡器和dbus模块 编辑 /etc/pulse/default.pa 并加入下面几行：\n### Load the integrated PulseAudio equalizer and D-Bus module load-module module-equalizer-sink load-module module-dbus-protocol Video FFmpeg  powershell 执行与在 cmd 执行不一样，poweshell 某些 -c:v 会报错 ffmpeg 输出参数含义  frame: 编码的帧数量 fps：每秒编码的帧数 q：质量因子 size/ Lsize：视频和音频编码后的大小，即基本等于视频和音频 之和 time：输出帧的显示时间 bitrate：输出视频的比特率 dup：输入帧重复（duplicate）的数量 drop：输入帧丢弃（drop）的个数 speed：编码速度    视频文件本身其实是一个容器（container），里面包括了视频和音频，也可能有字幕等其他内容。\n视频和音频都需要经过编码，才能保存成文件。不同的编码格式（CODEC），有不同的压缩率，会导致文件大小和清晰度的差异。\n编码器（encoders）是实现某种编码格式的库文件。只有安装了某种格式的编码器，才能实现该格式视频/音频的编码和解码。\nFFmpeg 的命令行参数非常多，可以分成五个部分：\n$ ffmpeg [全局参数] [输入文件参数] -i 输入文件 [输出文件参数] [输出文件] 常用参数  -c：指定编码器 -c copy：直接复制，不经过重新编码（这样比较快） -c:v：指定视频编码器 -c:a：指定音频编码器 -i：指定输入文件 -an：去除音频流 -vn： 去除视频流 -preset：指定输出的视频质量，会影响文件的生成速度，有以下几个可用的值 ultrafast, superfast, veryfast, faster, fast, medium, slow, slower, veryslow。 -y：不经过确认，输出时直接覆盖同名文件。  查看视频文件的元信息 $ ffmpeg -i input.mp4 -hide_banner 转换编码格式 $ ffmpeg -i [input.file] -c:v libx264 output.mp4 转成 H.264 编码，一般使用编码器 libx264\n转换容器格式 $ ffmpeg -i input.mp4 -c copy output.mkv 改变分辨率 $ ffmpeg -i input.mp4 -vf scale=720:-1 output.mp4 提取视频 $ ffmpeg -i input.mp4 -an -c:v copy ouput.mp4 -vcodec codec 强制使用codec编解码方式。如果用copy表示原始编解码数据必须被拷贝。\n提取音频 $ ffmpeg -i input.mp4 -vn -c:a copy output.aac -c:a copy表示不改变音频编码，直接拷贝。\n添加音轨 $ ffmpeg -i input.aac -i input.mp4 output.mp4 音视频合成 $ ffmpeg -i video.mp4 -i audio.aac -c:v copy -c:a copy output.mp4 截图 从指定时间开始，连续对1秒钟的视频进行截图\n$ ffmpeg -y -i input.mp4 -ss 00:01:24 -t 00:00:01 output_%3d.jpg 指定只截取一帧\n$ ffmpeg -ss 01:23:45 -i input.mp4 -vframes 1 -q:v 2 output.jpg -vframes 1指定只截取一帧，-q:v 2表示输出的图片质量，一般是1到5之间（1 为质量最高）。\n裁剪 $ ffmpeg -ss [start] -i [input] -t [duration] -c copy [output] $ ffmpeg -ss [start] -i [input] -to [end] -c copy [output] 裁剪（cutting）指的是，截取原始视频里面的一个片段，输出为一个新视频。可以指定开始时间（start）和持续时间（duration），也可以指定结束时间（end）。\n添加字幕  外挂字幕：一个单独的外部字幕文件，格式类型一般有srt、vtt、ass等等。播放视频时，需要把外挂字幕和视频放在同一目录下，并在播放器中选择字幕文件才可以在视频中看到字幕。 软字幕：也叫内挂字幕、封装字幕、内封字幕，字幕流等，就是把前面的外挂字幕的字幕文件嵌入到视频中作为流的一部分，如果一个视频有多个字幕流那么播放视频是还得选择对应的字幕流 硬字幕：是嵌入到视频帧里面的字幕，它就像视频水印一样作为视频帧的一分部分了，不管再任何平台字幕看起来都是一样的，而且也不再要求播放器单独对字母进行渲染  常见的字幕格式有：\n SRT（标准外挂字幕格式）：只包含文字和时间码，没有样式，显示效果由播放器决定，不同的播放器显示出的效果可能差别很大。 ASS（高级外挂字幕格式）：支持样式、字体、字幕定位、淡入淡出、简单的特效。如果不缺字体，不同的播放器显示效果基本一致。  ffmpeg字幕处理流程(容器是否支持字幕流指的是输出容器)\n添加软字幕：\n$ ffmpeg -i video.mp4 -i subtitle.srt -c copy output.mkv 软字幕只有部分容器格式比如(mkv)才支持，MP4/MOV等不支持，而且也只有部分播放器支持软字幕或者外挂字幕(如VLC播放器)。\n添加多个字幕：\nffmpeg -i input.mp4 -i zh_CN.srt -i en_US.srt -map 0:v -map 0:a -map 1 -map 2 -c:v copy -c:a copy -metadata:s:s:0 language=chn -metadata:s:s:1 language=eng \u0026#34;output.mp4\u0026#34;  -map 是轨道参数，如果只有一个字幕，就不需要这个参数。-map 0:v 表示第一个文件输入视频轨道，-map 0:a 表示第二个轨道是第一个文件输入的音频轨道，-map 1 建立第三个轨道，-map 2 建立第四个轨道。如果没添加 map 参数，默认就只有一个字幕轨道，第二个英文字幕会覆盖第一个中文字幕轨道。 -metadata:s:s:0 language=chn 第一条字幕的语言设置为中文，-metadata:s:s:1 language=eng 第二条字幕的语言设置为英文。 language 不能自定义，只能设置成固定的缩写。  添加硬字幕：\n$ ffmpeg -i video.mkv -vf subtitles=subtitle.srt out.mp4 下载 m3u8 现在比较常见的视频流媒体，大部分都是 m3u8 格式的，而对于 m3u8 格式的视频而言，如果你下载过，你会发现它就是一个文本文件，大概也就只有几十 kb，从磁盘大小来看，应该也知道它并不是一个直接的视频文件。\n什么是 m3u8\n说到 m3u8 就要先说说 HLS（HTTP Live Streaming）。HLS 是 Apple 公司针对 iPhone、iPod、iTouch 等移动设备，而研发的基于 HTTP 协议的流媒体解决方案。在 HLS 技术中，Web 服务器可以向客户端提供接近实时的音视频流，但是它又是使用的标准的 HTTP 协议。所以基本上，比较大型的点播直播类服务，都是基于 HLS 的。\n而该技术的原理，就是将视频文件或者视频流，进行切片（ts文件），并建立索引文件（m3u8），它支持的视频流编码为 H.264，音频流编码为 AAC。\n简单来说，基于 HLS 的视频流，会将完整的视频，切割成一个个比较小的视频片段（ts 文件），然后根据协议组合成一个 m3u8 文件。这些比较小的 ts 文件，是可以单独播放的。而视频播放器，拿到 m3u8 文件之后，根据对其内 ts 片段的索引，连续播放不同的视频片段，来达到流畅的播放效果。\n下载的 m3u8 文件\n说这些概念都没用，我们来看两个真实的被下载的 m3u8 文件。\n这种 m3u8 文件就还是比较清晰的，能看到它一个个的片段。但是需要注意的是，这里的片段，全部是基于域名的相对地址，也就是说，这样一个 m3u8 文件，你丢到播放器里，是无法播放的，但是如果你记录了原始下载这个 m3u8 的链接，它在播放器里是可以正常播放的。\n当然，如果你修改这个 m3u8 文件，将它相对路径拼接上域名地址，也是可以达到播放的效果的。\n再来看看另外一种 m3u8 文件，它其内的 ts 片段，都是完整地址。\n像这种具有完整地址的 ts 片段，哪怕你将它保存成一个本地的文件，播放器依然是可以直接播放的，不过这里本质上依然是在在线播放。\n这两中 m3u8 文件，虽然有细微的差别，但是它们都是基于标准的协议。\n简单总结一下：\n m3u8 不是视频内容的文件，它占用的磁盘空间非常的小。 m3u8 文件，如果其内的 ts 片段，是完整地址，则可以保存后播放，否者只能在线播放。 播放器播放 m3u8 文件的时候，实际上，还是在线从线上获取的视频流进行播放，所以是存在失效的情况的。  暂时知道这三点就可以了，接下来我们再看如何将一个 m3u8 文件，下载成一个 mp4 视频文件。\n使用 fmpeg 下载 m3u8\nffmpeg 是一套可以用来记录、转换音视频，并将其转化为流的开源程序，采用 LGPL 或 GPL 协议许可证书，很多大型的音视频软件，内部都是基于 ffmpeg 的。\n$ ffmpeg -i \u0026#34;m3u8_file_uri\u0026#34; \u0026#34;save_video.mp4\u0026#34; 到此，如果 m3u8 的链接正确可播放，就会开始下载，等待下载完成就可以了，最终会在指定目录下，保存 save_video.mp4 文件，它就是最终我们下载的离线视频文件。\nMPV MPV 是一个基于 MPlayer 和 mplayer2 的开源极简全能播放器。支持各种视频格式、音频解码、支持特效字幕（电影动漫的ass特效字幕都没啥问题），不仅支持本地播放，同样支持网络播放（mpv 集成了 youtube-dl）。重点是 MPV 具有多系统平台支持、命令行、自定义、GPU 解码、脚本支持等特点……\nOSC 界面 由于默认情况下，MPV 播放器简约到连 GUI 界面都没有提供，因此需要通过命令行或配置文件设置。\n虽然 MPV 并没有提供官方的 GUI 界面，没有菜单，但它提供 OSC 操作界面和快捷键用于操作，只要关联好文件格式，使用 mpv 打开视频后，使用上其实也非常的简单方便。\n快捷键 操作主要通过键盘快捷键（区分大小写）调整。下面介绍一些常用的 mpv 快捷键（更多的快捷键请阅读官方参考手册）。\n鼠标操作\n   快捷键 作用说明     鼠标左键双击 进入/退出全屏   鼠标右键单击 暂停/继续播放   鼠标滚轮 快进/快退    播放控制\n   快捷键  作用说明     p Space 暂停、继续播放   / * 减少/增加音量   9 0 减少/增加音量（数字键盘区的9、0不可用）   m  静音   ← → 快退/快进5秒   ↑ ↓ 快进/快退1分钟   \u0026lt; \u0026gt; 上一个/下一个（播放列表中）   Enter  下一个（播放列表中）   l  设定/清除 A-B循环点   L  循环播放   s  截屏   q  停止播放并退出   Q  保存当前播放进度并退出，播放同样文件从上次保存进度继续播放。    视频控制\n   快捷键 作用说明     _(下划线) 循环切换可用视频轨   A 循环切换视频画面比例   Alt+0 0.5倍源视频画面大小   Alt+1 1倍源视频画面大小   Alt+2 2倍源视频画面大小    音频控制\n   快捷键  作用说明     #  循环切换可用音频轨   Ctrl + Ctrl - 音轨延迟+/- 0.1秒    字幕控制\n   快捷键  作用说明     V  关闭/开启字幕   j J 循环切换可用字幕轨   x z 字幕延迟 +/- 0.1秒   r t 上移/下移字幕位置    窗口控制\n   快捷键 作用说明     T 窗口始终置顶   f 进入/退出全屏   ESC 退出全屏    配置 因为mpv本身不具有图形化前端，绝大多数的设置选项都是靠在主设置文件 ~/.config/mpv/mpv.conf 中输入参数实现的。\n## 部分选项之间有关联作用，MPV读取参数时由上往下读，所以注意书写通用参数的顺序，可查看手册[02]的顺序逻辑部分的错误示范 ## 基础 ## # 视频硬件解码API选择 # 因系统环境、显卡、驱动等差异硬件解码API方式（阅读官方参考手册查询）各有不同，建议实际测试验证后再填入可用API。 # 默认值为 no（使用软件解码），auto 为自动。 hwdec=auto # 尽可能所有格式先尝试上面指定视频硬件解码API #hwdec-codecs=all  # 输出log， # ~~/ 意思是 mpv config dir(for example ~/.config/mpv/) log-file=\u0026#34;~~/mpv.log\u0026#34; ## 功能 ## # --fs 等效 --fullscreen。运行MPV自动进入全屏 #fs=yes  # 默认为系统原生窗口界面，启用此项使用无边框界面 #border=no # 窗口置顶 #ontop=yes  # 窗口模式下最大占屏幕的百分比 # 例如在FHD屏上打开4k视频初始窗口过大 #autofit-larger=80%x80%  # 窗口模式下最小占屏幕的百分比 # 例如在4k屏上打开720p视频初始窗口过小 #autofit-smaller=50%x50%  # 默认yes，默认情况下MPV的窗口比例锁定为视频比例。启用此项以实现窗口自由拉伸行为 # 当 keepaspect=yes 时四周填充黑边 # keepaspect-window=no  # 以暂停状态启动播放器 #pause=yes  # 始终循环播放当前文件\u0026lt;N|inf|no\u0026gt; #loop=inf  # 播放列表循环\u0026lt;N|inf|force|no\u0026gt; #loop-playlist=no  # 默认情况下播完列表所有文件MPV自动关闭，设置为 yes 所有播放完毕不退出，设置为 always 可以实现类似“每个文件播完都暂停”的效果\u0026lt;yes|默认no|always\u0026gt;  keep-open=yes # 退出时记住播放状态。缓存目录默认在设置文件夹中的 \u0026#34;watch_later\u0026#34; save-position-on-quit=yes # 播放网络视频时的向后缓存大小（KiB或MiB） demuxer-max-bytes=20MiB ## OSD ## ## OSD 即 On-Screen-Display ，通常为屏幕上弹出显示的信息。  ## OSC 即 on-screen-controller ，MPV中指的是简易操控界面 # \u0026lt;no,bar,msg,msg-bar\u0026gt; 在跳转时间轴时显示的信息类型 osd-on-seek=msg-bar # 更改OSD字体大小（全局，影响多个功能显示的文本）（默认值：55） #osd-font-size=40  # 以秒为单位显示OSD时间（毫秒精度），有助于查看视频帧的确切时间戳 osd-fractions=yes # 开始播放时短暂显示的信息：文件名 osd-playing-msg=\u0026#34;${filename}\u0026#34; # 设置OSD文本信息的持续时间（毫秒）（默认值：1000） osd-duration=2000 ## 音频 ## # 最大音量。默认值130（130的响度约为100的两倍）\u0026lt;100.0-1000.0\u0026gt; volume-max=120 # 播放器启动音量。0为静音，默认100 #volume=100  # 自动加载同名外挂音轨（fuzzy为模糊名，exact为精确名）\u0026lt;默认no|exact|fuzzy|all\u0026gt;  audio-file-auto=fuzzy ## 视频 ## # 如果做过专业校色应开启（系统目录存在对应的icm校色文档）。未做校色的广色域屏应手动指定 --target-prim=\u0026lt;value\u0026gt; #icc-profile-auto=yes  ## 脚本 滤镜 着色器 ## ## 内置脚本开关（如果没有必要的目的，那就不要屏蔽mpv内建的功能 # 控制台 #load-osd-console=no # 统计信息 #load-stats-overlay=no  ## 字幕 ## # 自动加载当前播放文件的同名外挂字幕 sub-auto=fuzzy # 在指定的额外目录中寻找匹配的字幕，支持相对和绝对路径。 # 示例即自动搜索当前文件路径下名为\u0026#34;sub\u0026#34;,\u0026#34;subtitles\u0026#34;,\u0026#34;字幕\u0026#34;和C盘的\u0026#34;字幕库\u0026#34;文件夹内 #sub-file-paths=sub;subtitles;字幕;C:/字幕库 # 字幕首选语言为中文，但MPV优先加载外挂轨道，此项参数可能实际用处不大 slang=chs,sc,zh,chi,zho # 在插值和颜色管理之前，将字幕混合到视频帧上\u0026lt;yes|video|默认no\u0026gt;。值video类似于yes，但是以视频的原始分辨率绘制字幕，并与视频一起缩放 # 启用此功能会将字幕限制在视频的可见部分（不能出现在视频下方的黑色空白处） # 还会让字幕受 --icc-profile --target-prim --target-trc --interpolation --gamma-factor --glsl-shaders 的影响 # 与 --interpolation 一起使用时，可提高字幕渲染性能  #blend-subtitles=video  # [当 --blend-subtitles=yes/video 时无效] 使ASS字幕尽可能输出在黑边上 sub-ass-force-margins=yes ## 截图 ## ## 以下预设参数只是为了截取最高质量的图片（高质量截图处理效率较低） # \u0026lt;默认 jpg|png|webp\u0026gt; screenshot-format=png # JPEG的最高质量，默认为90\u0026lt;0-100\u0026gt;  #screenshot-jpeg-quality=100  # 用与源视频相同的色度半采样写入JPEG，默认yes #screenshot-jpeg-source-chroma=yes  # PNG压缩等级，过高的等级影响性能，默认为7\u0026lt;0-9\u0026gt;  #screenshot-png-compression=5  # PNG的压缩过滤器。默认5即可实现最佳压缩率\u0026lt;0-5\u0026gt;  #screenshot-png-filter=5  # 使用适当的色彩空间标记屏幕截图（并非所有格式受支持）默认no #screenshot-tag-colorspace=yes  # 主要影响PNG，尽可能使用和视频输出时相同的位深，默认yes #screenshot-high-bit-depth=yes # 若直接在模板中设置路径，此时无需 --screenshot-directory screenshot-template=\u0026#34;MPV-%P-N%n\u0026#34; # 截屏文件保存路径 # ~/ 意思是 user home directory root (similar to shell, $HOME) screenshot-directory=\u0026#34;~/Pictures\u0026#34; Shotcut Shotcut is a free, open source, cross-platform video editor.\nDaVinci Resolve 专业的剪辑、调色、特效和音频后期制作！\nMKVToolNix MKVToolNix is a set of tools to create, alter and inspect Matroska(mkv) files under Linux, other Unices and Windows.\nVLC VLC is a free and open source cross-platform multimedia player and framework that plays most multimedia files, and various streaming protocols.\nDownload Aria2 Aria2是一款开源下载工具，可帮助简化不同设备和服务器之间的下载过程。它支持磁力链接、BT种子、http等类型的文件下载，与迅雷相比，Aria2有着优秀的性能及较低的资源占用，架构本身非常轻巧，通常只需要4兆字节（HTTP下载）到9兆字节（用于BitTorrent交互）之间。最重要的一点是Aria2完全免费！\n$ sudo apt-get install aria2 下载安装完成之后，可以通过输入 aria2c -v 来验证是否安装成功。\nUsage 命令行使用\n使用Aria2下载文件，只需在命令后附加地址即可：\n$ aria2c URL 下载后以其他名称保存文件\n$ aria2c -o fileName URL 下载多个文件\n$ aria2c -Z URL URL 从列表下载文件：\n$ aria2c -i URLs.txt 限制下载速度：\n# 单个文件 aria2c –max-download-limit=500k URL # 全局 aria2c –max-overall-download-limit=500k URL 断点续传：\n$ aria2c -c URL 下载磁力链接文件：要下载磁力链接文件，如果下载没有速度，可以添加--bt-tracker=选项，tracker 中用 , 隔开：\n$ aria2c --bt-tracker=tracker,tracker torrent tracker 服务器：\n  trackerslist：trackers_best (20 trackers) =\u0026gt; link / mirror / mirror 2\n  TrackersListCollection：BEST Tracker list (78 trackers)=\u0026gt; link / mirror\n  中国可用的 BT Tracker 服务器列表\n  将多行文本转换成一行并用逗号隔开\n$ cat tracker | xargs | tr \u0026#39; \u0026#39; \u0026#39;,\u0026#39;   分段下载：可以加快文件的下载速度，对于下载大文件时特别有用，-s 后面的参数值介于1~5之间，你可以根据实际情况选择。下面命令将使用2连接来下载该文件：\n$ aria2c -s 2 URL 后台下载：\n$ aria2c -D url $ aria2c –deamon=true url 验证文件：\n$ aria2c –checksum=md5=提供的md5 设置dht端口：\n$ aria2c –dht-listen-port=1234 torrent 下载需要引用页的文件：\n$ aria2c –referer=referurl URL 下载需要Cookie验证的文件：\n$ aria2c –essay-header=’Cookie:key=value’ URL $ aria2c –load-cookies=cookie文件 URL 从密码保护的网站下载一个文件：\n$ aria2c --http-user=xxx --http-password=xxx URL $ aria2c --ftp-user=xxx --ftp-password=xxx URL 注意：当源地址存在诸如\u0026amp;,*等shell的特殊字符，请使用单引号或双引号把URI包含起来。\nRPC Server 模式\n该模式可以配合 Web UI 进行图形管理。默认启动是 6800 端口，怕别人盗用，可以设置用户名和密码(1.18.4以上版本支持密钥)。\n$ aria2c --enable-rpc --rpc-listen-all --rpc-allow-origin-all -c --dir ~/Download Configuration 默认情况下，aria2 检查旧路径 $HOME/.aria2/aria2.conf 是否存在，否则它会将 $XDG_CONFIG_HOME/aria2/aria2.conf 解析为它的配置文件。 您可以使用 --conf-path 选项指定配置文件的路径。 如果您不想使用配置文件，请使用 --no-conf 选项。\n配置详解：\n## \u0026#39;#\u0026#39;开头为注释内容, 选项都有相应的注释说明, 根据需要修改 ## ## 被注释的选项填写的是默认值, 如为空则无默认设置，请自行选取需要更改的添加到你的配置文件中 ## ## 文件保存设置 ## # 下载路径(可使用绝对路径或相对路径), 默认: 当前启动位置 #dir= dir=/home/kurome/Downloads # 磁盘缓存 # 启用磁盘缓存. 如果设置为 0, 将禁用磁盘缓存. 此功能将下载的数据缓存在内存中, 最多占用此选项设置的字节数. 缓存存储由 aria2 实例创建并对所有下载共享. 由于数据以较大的单位写入并按文件的偏移重新排序, 所以磁盘缓存的一个优点是减少磁盘的 I/O. 如果调用哈希检查时并且数据缓存在内存中时, 将不需要从磁盘中读取. 大小可以包含 K 或 M (1K = 1024, 1M = 1024K). disk-cache=64M # 文件预分配方式, 可选：none, prealloc, trunc, falloc, 默认:prealloc # 预分配对于机械硬盘可有效降低磁盘碎片、提升磁盘读写性能、延长磁盘寿命。 # 机械硬盘使用 ext4（具有扩展支持），btrfs，xfs 或 NTFS（仅 MinGW 编译版本）等文件系统建议设置为 falloc # 若无法下载，提示 fallocate failed.cause：Operation not supported 则说明不支持，请设置为 none # prealloc 分配速度慢, trunc 无实际作用，不推荐使用。 # 固态硬盘不需要预分配，只建议设置为 none ，否则可能会导致双倍文件大小的数据写入，从而影响寿命。 file-allocation=none # 文件分配限制 # 不对比此参数设置大小小的分配文件. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). no-file-allocation-limit=64M # 断点续传 # 继续下载部分完成的文件. 启用此选项可以继续下载从浏览器或其他程序按顺序下载的文件. 此选项目前只支持 HTTP(S)/FTP 下载的文件. continue=true # 始终断点续传 # 始终断点续传. 如果设置为\u0026#34;是\u0026#34;, aria2 始终尝试断点续传, 如果无法恢复, 则中止下载. 如果设置为\u0026#34;否\u0026#34;, 对于不支持断点续传的 URI 或 aria2 遇到 N 个不支持断点续传的 URI (N 为 --max-resume-failure-tries 选项设置的值), aria2 会从头下载文件. 参见 --max-resume-failure-tries 参数. always-resume=true # 最大断点续传尝试次数 # 当 --always-resume 选项设置为\u0026#34;否\u0026#34;时, 如果 aria2 检测到有 N 个 URI 不支持断点续传时, 将从头开始下载文件. 如果 N 设置为 0, 当所有 URI 都不支持断点续传时才会从头下载文件. 参见 --always-resume 选项. max-resume-failure-tries=0 # 获取服务器文件时间 # 从 HTTP/FTP 服务获取远程文件的时间戳, 如果可用将设置到本地文件 remote-time=true ## 进度保存设置 ## # 从会话文件中读取下载任务 input-file=/home/kurome/.aria2/aria2.session # 会话文件保存路径 # 当退出时保存错误及未完成的任务到指定的文件中. 必须用绝对路径 # 您可以在重启 aria2 时使用 --input-file 选项重新加载. 如果您希望输出的内容使用 GZip 压缩, 您可以在文件名后增加 .gz 扩展名. 请注意, 通过 aria2.addTorrent() 和 aria2.addMetalink() RPC 方法添加的下载, 其元数据没有保存到文件的将不会保存. 通过 aria2.remove() 和 aria2.forceRemove() 删除的下载将不会保存. #save-session= save-session=/home/kurome/.aria2/aria2.session # 任务状态改变后保存会话的间隔时间（秒）, 0 为仅在进程正常退出时保存, 默认:0 # 为了及时保存任务状态、防止任务丢失，此项值只建议设置为 1 save-session-interval=1 # 自动保存任务进度到控制文件(*.aria2)的间隔时间（秒），0 为仅在进程正常退出时保存，默认：60 # 不论设置的值为多少, aria2 会在任务结束时保存控制文件. 可以设置的值为 0 到 600. # 此项值也会间接影响从内存中把缓存的数据写入磁盘的频率 # 想降低磁盘 IOPS (每秒读写次数)则提高间隔时间 # 想在意外非正常退出时尽量保存更多的下载进度则降低间隔时间 # 非正常退出：进程崩溃、系统崩溃、SIGKILL 信号、设备断电等 auto-save-interval=20 # 强制保存，即使任务已完成也保存信息到会话文件, 默认:false # 即使任务完成或删除时使用 --save-session 选项时也保存该任务. 此选项在这种情况下还会保存控制文件. 此选项可以保存被认为已经完成但正在做种的 BT 任务. # 开启后会在任务完成后保留 .aria2 文件，文件被移除且任务存在的情况下重启后会重新下载。 # 关闭后已完成的任务列表会在重启后清空。 force-save=false ## 下载连接设置 ## # 文件未找到重试次数 # 如果 aria2 从远程 HTTP/FTP 服务器收到 \u0026#34;文件未找到\u0026#34; 的状态超过此选项设置的次数后下载将会失败. 设置为 0 将会禁用此选项. 此选项仅影响 HTTP/FTP 服务器. 重试时同时会记录重试次数, 所以也需要设置 --max-tries 这个选项. max-file-not-found=10 # 最大尝试次数 # 设置最大尝试次数. 0 表示不限制，默认:5 max-tries=0 # 重试等待时间, 默认:0 (禁用) # 设置重试间隔时间(秒). 当此选项的值大于 0 时, aria2 在 HTTP 服务器返回 503 响应时将会重试. retry-wait=10 # 连接超时时间 # 设置建立 HTTP/FTP/代理服务器 连接的超时时间(秒). 当连接建立后, 此选项不再生效, 请使用 --timeout 选项. connect-timeout=10 # 超时时间。默认：60 timeout=10 # 最大同时下载任务数, 运行时可修改, 默认:5 max-concurrent-downloads=5 # 单服务器最大连接线程数, 任务添加时可指定, 默认:1 # 最大值为 16 (增强版无限制), 且受限于单任务最大连接线程数(split)所设定的值。 max-connection-per-server=16 # 单任务最大连接线程数, 任务添加时可指定, 默认:5 # 下载时使用 N 个连接. 如果提供超过 N 个 URI 地址, 则使用前 N 个地址, 剩余的地址将作为备用. 如果提供的 URI 地址不足 N 个, 这些地址多次使用以保证同时建立 N 个连接. 同一服务器的连接数会被 --max-connection-per-server 选项限制. split=64 # 文件最小分段大小, 添加时可指定, 默认:20M # aria2 不会分割小于 2*SIZE 字节的文件. 例如, 文件大小为 20MB, 如果 SIZE 为 10M, aria2 会把文件分成 2 段 [0-10MB) 和 [10MB-20MB), 并且使用 2 个源进行下载 (如果 --split \u0026gt;= 2). 如果 SIZE 为 15M, 由于 2*15M \u0026gt; 20MB, 因此 aria2 不会分割文件并使用 1 个源进行下载. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). 可以设置的值为: 1M-1024M. # 理论上值越小使用下载分段就越多，所能获得的实际线程数就越大，下载速度就越快，但受限于所下载文件服务器的策略。 min-split-size=4M # 文件分片大小，最小值为 1M，默认：1M # 设置 HTTP/FTP 下载的分配大小. aria2 根据这个边界分割文件. 所有的分割都是这个长度的倍数. 此选项不适用于 BitTorrent 下载. 如果 Metalink 文件中包含分片哈希的结果此选项也不适用. piece-length=1M # 允许分片大小变化。默认：false # 如果设置为\u0026#34;否\u0026#34;, 当分片长度与控制文件中的不同时, aria2 将会中止下载. 如果设置为\u0026#34;是\u0026#34;, 您可以继续, 但部分下载进度将会丢失. allow-piece-length-change=true # 分片选择算法 # 指定 HTTP/FTP 下载使用的分片选择算法. 分片表示的是并行下载时固定长度的分隔段. 如果设置为\u0026#34;默认\u0026#34;, aria2 将会按减少建立连接数选择分片. 由于建立连接操作的成本较高, 因此这是合理的默认行为. 如果设置为\u0026#34;顺序\u0026#34;, aria2 将选择索引最小的分片. 索引为 0 时表示为文件的第一个分片. 这将有助于视频的边下边播. --enable-http-pipelining 选项有助于减少重连接的开销. 请注意, aria2 依赖于 --min-split-size 选项, 所以有必要对 --min-split-size 选项设置一个合理的值. 如果设置为\u0026#34;随机\u0026#34;, aria2 将随机选择一个分片. 就像\u0026#34;顺序\u0026#34;一样, 依赖于 --min-split-size 选项. 如果设置为\u0026#34;几何\u0026#34;, aria2 会先选择索引最小的分片, 然后会为之前选择的分片保留指数增长的空间. 这将减少建立连接的次数, 同时文件开始部分将会先行下载. 这也有助于视频的边下边播. #stream-piece-selector=default # 最小速度限制 # 当下载速度低于此选项设置的值(B/s) 时将会关闭连接. 0 表示不设置最小速度限制. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). 此选项不会影响 BT 下载. lowest-speed-limit=0 # 全局最大下载速度 # 设置全局最大下载速度 (字节/秒). 0 表示不限制. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). max-overall-download-limit=0 # 最大下载速度 # 设置每个任务的最大下载速度 (字节/秒). 0 表示不限制. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). max-download-limit=0 # 禁用 IPv6, 默认:false disable-ipv6=true # 支持 GZip # 如果远程服务器的响应头中包含 Content-Encoding: gzip 或 Content-Encoding: deflate , 将发送包含 Accept: deflate, gzip 的请求头并解压缩响应. http-accept-gzip=true # URI 复用 # 当所有给定的 URI 地址都已使用, 继续使用已经使用过的 URI 地址. reuse-uri=false # URI 选择算法 # 指定 URI 选择的算法. 可选的值包括 \u0026#34;按顺序\u0026#34;, \u0026#34;反馈\u0026#34; 和 \u0026#34;自适应\u0026#34;. 如果设置为\u0026#34;按顺序\u0026#34;, URI 将按列表中出现的顺序使用. 如果设置为\u0026#34;反馈\u0026#34;, aria2 将根据之前的下载速度选择 URI 列表中下载速度最快的服务器. 同时也将有效跳过无效镜像. 之前统计的下载速度将作为服务器状态文件的一部分, 参见 --server-stat-of 和 --server-stat-if 选项. 如果设置为\u0026#34;自适应\u0026#34;, 将从最好的镜像和保留的连接里选择一项. 补充说明, 其返回的镜像没有被测试过, 同时如果每个镜像都已经被测试过时, 返回的镜像还会被重新测试. 否则, 其将不会选择其他镜像. 例如\u0026#34;反馈\u0026#34;, 其使用服务器状态文件. #uri-selector=feedback # 禁用 netrc，默认:false no-netrc=true # .netrc 文件路径 #netrc-path=$(HOME)/.netrc # 允许覆盖 # 如果相应的控制文件不存在时从头重新下载文件. 参见 --auto-file-renaming 选项. allow-overwrite=false # 文件自动重命名。默认:true # 重新命名已经存在的文件. 此选项仅对 HTTP(S)/FTP 下载有效. 新的文件名后会在文件名后、扩展名 (如果有) 前追加句点和数字(1..9999). auto-file-renaming=true # 使用 UTF-8 处理 Content-Disposition，默认:false # 处理 \u0026#34;Content-Disposition\u0026#34; 头中的字符串时使用 UTF-8 字符集来代替 ISO-8859-1, 例如, 文件名参数, 但不是扩展版本的文件名. content-disposition-default-utf8=true # 最低 TLS 版本，可选：TLSv1.1、TLSv1.2、TLSv1.3 默认:TLSv1.2 #min-tls-version=TLSv1.2 ## BT/PT 下载设置 ## # BT 监听端口(TCP), 默认:6881-6999 # 设置 BT 下载的 TCP 端口. 多个端口可以使用逗号 \u0026#34;,\u0026#34; 分隔, 例如: 6881,6885. 您还可以使用短横线 \u0026#34;-\u0026#34; 表示范围: 6881-6999, 或可以一起使用: 6881-6889, 6999. # 直通外网的设备，比如 VPS ，务必配置防火墙和安全组策略允许此端口入站 # 内网环境的设备，比如 NAS ，除了防火墙设置，还需在路由器设置外网端口转发到此端口 listen-port=51413 # DHT 网络与 UDP tracker 监听端口(UDP), 默认:6881-6999 # 设置 DHT (IPv4, IPv6) 和 UDP 服务器使用的 UCP 端口. 多个端口可以使用逗号 \u0026#34;,\u0026#34; 分隔, 例如: 6881,6885. 您还可以使用短横线 \u0026#34;-\u0026#34; 表示范围: 6881-6999, 或可以一起使用: 6881-6889, 6999. # 因协议不同，可以与 BT 监听端口使用相同的端口，方便配置防火墙和端口转发策略。 dht-listen-port=51413 # 启用 DHT (IPv4), 默认:true # 启用 IPv4 DHT 功能. 此选项同时会启用 UDP 服务器支持. PT 下载(私有种子)会自动禁用 enable-dht=true # 启用 DHT (IPv6)，默认:false # 启用 IPv6 DHT 功能. 如果种子设置为私有, 即使此选项设置为\u0026#34;是\u0026#34;, aria2 也不会启用 DHT. 使用 --dht-listen-port 选项设置监听的端口. # 在没有 IPv6 支持的环境开启可能会导致 DHT 功能异常 enable-dht6=false # 外部 IP 地址 # 指定用在 BitTorrent 下载和 DHT 中的外部 IP 地址. 它可能被发送到 BitTorrent 服务器. 对于 DHT, 此选项将会报告本地节点正在下载特定的种子. 这对于在私有网络中使用 DHT 非常关键. 虽然这个方法叫外部, 但其可以接受各种类型的 IP 地址. # 使用场景：在家庭宽带没有公网 IP 的情况下可以把 BT 和 DHT 监听端口转发至具有公网 IP 的服务器，在此填写服务器的 IP ，可以提升 BT 下载速率。 #bt-external-ip= # DHT (IPv4) 文件，默认：$HOME/.aria2/dht.dat # 修改 IPv4 DHT 路由表文件路径. dht-file-path=/home/kurome/.aria2/dht.dat # DHT (IPv6) 文件，默认：$HOME/.aria2/dht6.dat # 修改 IPv6 DHT 路由表文件路径. dht-file-path6=/home/kurome/.aria2/dht6.dat # IPv4 DHT 网络引导节点 dht-entry-point=dht.transmissionbt.com:6881 # IPv6 DHT 网络引导节点 dht-entry-point6=dht.transmissionbt.com:6881 # 启用本地节点发现(LPD),PT 下载(私有种子)会自动禁用,默认:false bt-enable-lpd=true # 指定用于本地节点发现的接口，可能的值：接口，IP地址 # 如果未指定此选项，则选择默认接口。 #bt-lpd-interface= # 启用节点交换, 默认:true # 启用节点交换扩展. 如果种子设置为私有, 即使此选项设置为\u0026#34;是\u0026#34;, aria2 也不会启用此功能. enable-peer-exchange=true # BT 下载最大连接数（单任务），运行时可修改。0 为不限制，默认:55 # 理想情况下连接数越多下载越快，但在实际情况是只有少部分连接到的做种者上传速度快，其余的上传慢或者不上传。 # 如果不限制，当下载非常热门的种子或任务数非常多时可能会因连接数过多导致进程崩溃或网络阻塞。 # 进程崩溃：如果设备 CPU 性能一般，连接数过多导致 CPU 占用过高，因资源不足 Aria2 进程会强制被终结。 # 网络阻塞：在内网环境下，即使下载没有占满带宽也会导致其它设备无法正常上网。因远古低性能路由器的转发性能瓶颈导致。 bt-max-peers=128 # BT 下载期望速度值（单任务），运行时可修改。单位 K 或 M 。默认:50K # BT 下载速度低于此选项值时会临时提高连接数来获得更快的下载速度，不过前提是有更多的做种者可供连接。 # 实测临时提高连接数没有上限，但不会像不做限制一样无限增加，会根据算法进行合理的动态调节。 bt-request-peer-speed-limit=10M # 全局最大上传速度, 运行时可修改, 默认:0 (无限制) # 设置全局最大上传速度 (字节/秒). 0 表示不限制. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). # 设置过低可能影响 BT 下载速度 max-overall-upload-limit=2M # 单任务上传速度限制, 默认:0 (无限制) # 设置每个任务的最大上传速度 (字节/秒). 0 表示不限制. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). max-upload-limit=0 # 最小分享率, 0 为一直做种, 默认:1.0 # 指定分享率. 当分享率达到此选项设置的值时会完成做种. 强烈建议您将此选项设置为大于等于 1.0. 如果您想不限制分享比率, 可以设置为 0.0. 如果同时设置了 --seed-time 选项, 当任意一个条件满足时将停止做种. seed-ratio=1.0 # 最小做种时间（分钟） # 此选项设置为 0 时, 将在 BT 任务下载完成后不进行做种. seed-time=0 # 做种前检查文件哈希, 默认:true # 如果设置为\u0026#34;是\u0026#34;, 当使用 --check-integrity 选项完成哈希检查及文件完成后才继续做种. 如果您希望仅当文件损坏或未完成时检查文件, 请设置为\u0026#34;否\u0026#34;. 此选项仅对 BT 下载有效 bt-hash-check-seed=true # 继续之前的BT任务时, 无需再次校验, 默认:false # 不检查之前下载文件中每个分片的哈希值. bt-seed-unverified=false # BT tracker 服务器连接超时时间（秒）。默认：60 # 建立连接后，此选项无效，将使用 bt-tracker-timeout 选项的值 bt-tracker-connect-timeout=10 # BT tracker 服务器超时时间（秒）。默认：60 bt-tracker-timeout=10 # BT 服务器连接间隔时间。默认：0 (自动) # 设置请求 BT 服务器的间隔时间 (秒). 此选项将完全覆盖服务器返回的最小间隔时间和间隔时间, aria2 仅使用此选项的值.如果设置为 0, aria2 将根据服务器的响应情况和下载进程决定时间间隔. #bt-tracker-interval=0 # BT 下载优先下载文件开头或结尾 # 尝试先下载每个文件开头或结尾的分片. 此选项有助于预览文件. 参数可以包括两个关键词: head 和 tail. 如果包含两个关键词, 需要使用逗号分隔. 每个关键词可以包含一个参数, SIZE. 例如, 如果指定 head=SIZE, 每个文件的最前 SIZE 数据将会获得更高的优先级. tail=SIZE 表示每个文件的最后 SIZE 数据. SIZE 可以包含 K 或 M (1K = 1024, 1M = 1024K). bt-prioritize-piece=head=32M,tail=32M # 保存通过 WebUI(RPC) 上传的种子文件(.torrent)，默认:true # 在 dir 选项设置的目录中保存上传的种子文件或 Metalink 文件. 文件名包括 SHA-1 哈希后的元数据和扩展名两部分. 对于种子文件, 扩展名为 \u0026#39;.torrent\u0026#39;. 对于 Metalink 为 \u0026#39;.meta4\u0026#39;. 如果此选项设置为\u0026#34;否\u0026#34;, 通过 aria2.addTorrent() 或 aria2.addMetalink() 方法添加的下载将无法通过 --save-session 选项保存. # 所有涉及种子文件保存的选项都建议开启，不保存种子文件有任务丢失的风险。 # 通过 RPC 自定义临时下载目录可能不会保存种子文件。 rpc-save-upload-metadata=true # 下载种子文件(.torrent)自动开始下载, 默认:true，可选：false|mem # true：保存种子文件 # false：仅下载种子文件 # mem：将种子保存在内存中 # 如果设置为\u0026#34;是\u0026#34;或\u0026#34;仅内存\u0026#34;, 当后缀为 .torrent 或内容类型为 application/x-bittorrent 的文件下载完成时, aria2 将按种子文件读取并下载该文件中提到的文件. 如果设置为\u0026#34;仅内存\u0026#34;, 该种子文件将不会写入到磁盘中, 而仅会存储在内存中. 如果设置为\u0026#34;否\u0026#34;, 则 .torrent 文件会下载到磁盘中, 但不会按种子文件读取并且其中的文件不会进行下载. follow-torrent=true # 种子文件下载完后暂停任务，默认：false # 在开启 follow-torrent 选项后下载种子文件或磁力会自动开始下载任务进行下载，而同时开启当此选项后会建立相关任务并暂停。 pause-metadata=false # 保存磁力链接元数据为种子文件(.torrent), 默认:false # 保存种子文件为 \u0026#34;.torrent\u0026#34; 文件. 此选项仅对磁链生效. 文件名为十六进制编码后的哈希值及 \u0026#34;.torrent\u0026#34;后缀. 保存的目录与下载文件的目录相同. 如果相同的文件已存在, 种子文件将不会保存. bt-save-metadata=true # 加载已保存的元数据文件(.torrent)，默认:false # 当使用磁链下载时, 在从 DHT 获取种子元数据之前, 首先尝试加载使用 --bt-save-metadata 选项保存的文件. 如果文件加载成功, 则不会从 DHT 下载元数据. bt-load-saved-metadata=true # 删除 BT 下载任务中未选择文件，默认:false # 当 BT 任务完成后删除未选择的文件. 要选择需要下载的文件, 请使用 --select-file 选项. 如果没有选择, 则所有文件都默认为需要下载. 此选项会从磁盘上直接删除文件, 请谨慎使用此选项. bt-remove-unselected-file=true # BT强制加密, 默认: false # 启用后将拒绝旧的 BT 握手协议并仅使用混淆握手及加密。可以解决部分运营商对 BT 下载的封锁，且有一定的防版权投诉与迅雷吸血效果。 # 此选项相当于后面两个选项(bt-require-crypto=true, bt-min-crypto-level=arc4)的快捷开启方式，但不会修改这两个选项的值。 bt-force-encryption=true # BT加密需求，默认：false # 启用后拒绝与旧的 BitTorrent 握手协议(\\19BitTorrent protocol)建立连接，始终使用混淆处理握手。 #bt-require-crypto=true # BT最低加密等级，可选：plain（明文），arc4（加密），默认：plain # 设置加密方法的最小级别. 如果节点提供多种加密方法, aria2 将选择满足给定级别的最低级别. #bt-min-crypto-level=arc4 # 分离仅做种任务，默认：false # 从正在下载的任务中排除已经下载完成且正在做种的任务，并开始等待列表中的下一个任务。 # 统计当前活动下载任务(参见 -j 选项) 时排除仅做种的任务. 这意味着, 如果参数设置为 -j3, 此选项打开并且当前有 3 个正在活动的任务, 并且其中有 1 个进入做种模式, 那么其会从正在下载的数量中排除(即数量会变为 2), 在队列中等待的下一个任务将会开始执行. 但要知道, 在 RPC 方法中, 做种的任务仍然被认为是活动的下载任务. bt-detach-seed-only=true ## 客户端伪装 ## # 自定义 User Agent user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36 Edg/93.0.961.47 # BT 客户端伪装 # PT 下载需要保持 user-agent 和 peer-agent 两个参数一致 # 部分 PT 站对 Aria2 有特殊封禁机制，客户端伪装不一定有效，且有封禁账号的风险。 # 自定义 User Agent，默认：aria2/$VERSION #user-agent=Deluge 1.3.15 # Peer Agent # 指定 BT 扩展握手期间用于节点客户端版本的字符串. peer-agent=Deluge 1.3.15 # 节点 ID 前缀 # 指定节点 ID 的前缀. BT 中节点 ID 长度为 20 字节. 如果超过 20 字节, 将仅使用前 20 字节. 如果少于 20 字节, 将在其后不足随机的数据保证为 20 字节. peer-id-prefix=-DE13F0- ## 执行额外命令 ## # 下载停止后执行的命令 # 从 正在下载 到 删除、错误、完成 时触发。暂停被标记为未开始下载，故与此项无关。 #on-download-stop=/home/kurome/.aria2/delete.sh # 下载完成后执行的命令 # 此项未定义则执行 下载停止后执行的命令 (on-download-stop) #on-download-complete=/home/kurome/.aria2/clean.sh # 下载错误后执行的命令 # 此项未定义则执行 下载停止后执行的命令 (on-download-stop) #on-download-error= # 下载暂停后执行的命令 #on-download-pause= # 下载开始后执行的命令 #on-download-start= # BT 下载完成后执行的命令 #on-bt-download-complete= ## RPC 设置 ## # 启用 JSON-RPC/XML-RPC 服务器, 默认:false enable-rpc=true # 接受所有远程请求, 默认:false # 在 RPC 响应头增加 Access-Control-Allow-Origin 字段, 值为 * .web界面跨域权限需要 rpc-allow-origin-all=true # 允许外部访问, 默认:false rpc-listen-all=true # RPC 监听端口, 默认:6800 rpc-listen-port=6800 # RPC 密钥, v1.18.4新增功能, 取代 --rpc-user 和 --rpc-passwd 选项 rpc-secret=P3TERX # RPC 最大请求大小 # 设置 JSON-RPC/XML-RPC 最大的请求大小. 如果 aria2 检测到请求超过设定的字节数, 会直接取消连接. rpc-max-request-size=10M # RPC 服务 SSL/TLS 加密, 默认：false # RPC 将通过 SSL/TLS 加密传输. RPC 客户端需要使用 https 协议连接服务器. 对于 WebSocket 客户端, 使用 wss 协议. 使用 --rpc-certificate 和 --rpc-private-key 选项设置服务器的证书和私钥. # 不推荐开启，建议使用 web server 反向代理，比如 Nginx、Caddy ，灵活性更强。 #rpc-secure= # 在 RPC 服务中启用 SSL/TLS 加密时的证书文件, # 使用 PEM 格式时，您必须通过 --rpc-private-key 指定私钥 #rpc-certificate=/path/to/certificate.pem # 在 RPC 服务中启用 SSL/TLS 加密时的私钥文件 #rpc-private-key=/path/to/certificate.key # 事件轮询方式, 可选：epoll, kqueue, port, poll, select, 不同系统默认值不同 # 设置事件轮训的方法. 对于 epoll, kqueue, port 和 poll, 只有系统支持时才可用. 最新的 Linux 支持 epoll. 各种 *BSD 系统包括 Mac OS X 支持 kqueue. Open Solaris 支持 port. 默认值根据您使用的操作系统不同而不同. #event-poll=select ## 高级选项 ## # 启用异步 DNS 功能。默认：true #async-dns=true # 指定异步 DNS 服务器列表，未指定则从 /etc/resolv.conf 中读取。 #async-dns-server=119.29.29.29,223.5.5.5,8.8.8.8,1.1.1.1 # 指定单个网络接口，可能的值：接口，IP地址，主机名 # 如果接口具有多个 IP 地址，则建议指定 IP 地址。 # 已知指定网络接口会影响依赖本地 RPC 的连接的功能场景，即通过 localhost 和 127.0.0.1 无法与 Aria2 服务端进行讯通。 #interface= # 指定多个网络接口，多个值之间使用逗号(,)分隔。 # 使用 interface 选项时会忽略此项。 #multiple-interface= ## 日志设置 ## # 日志文件保存路径，默认：不保存 # 如果设置为 \u0026#34;-\u0026#34;, 日志则写入到 stdout. 如果忽略或设置为空字符串(\u0026#34;\u0026#34;), 日志将不会记录到磁盘上. #log= # 日志级别，可选 debug, info, notice, warn, error 。默认：debug #log-level=warn # 控制台日志级别，可选 debug, info, notice, warn, error ，默认：notice console-log-level=notice # 安静模式，禁止在控制台输出日志，默认：false quiet=false # 下载进度摘要输出间隔时间（秒），0 为禁止输出。默认：60 summary-interval=0 ## BitTorrent trackers ## # BT 服务器地址 # 逗号分隔的 BT 服务器地址. 如果服务器地址在 --bt-exclude-tracker 选项中, 其将不会生效. bt-tracker=udp://open.tracker.cl:1337/announce,udp://tracker.opentrackr.org:1337/announce,udp://9.rarbg.com:2810/announce,udp://tracker.openbittorrent.com:6969/announce,udp://exodus.desync.com:6969/announce,http://tracker.openbittorrent.com:80/announce,http://openbittorrent.com:80/announce,udp://www.torrent.eu.org:451/announce,udp://tracker.torrent.eu.org:451/announce,udp://tracker.tiny-vps.com:6969/announce,udp://tracker.moeking.me:6969/announce,udp://tracker.dler.org:6969/announce,udp://tracker.bitsearch.to:1337/announce,udp://tracker.altrosky.nl:6969/announce,udp://tracker-udp.gbitt.info:80/announce,udp://opentor.org:2710/announce,udp://open.stealth.si:80/announce,udp://explodie.org:6969/announce,udp://discord.heihachi.pw:6969/announce,udp://bt2.archive.org:6969/announce 更多：Aria2 完美配置\nAria2 Web 控制台\nAira2 没有软件界面，程序员可以用代码执行任务，但普通用户怎样添加下载任务呢？——打开浏览器，输入网址aria2c.com（YAAW 的中文版）就可以打开 Aria2 Web 控制台。\nJSON-RPC Path 默认为: http://localhost:6800/jsonrpc，如果提示 “Aria2 RPC 服务器错误”，按照以下方法修改：\n 普通情况设置为: http://host:port/jsonrpc  host: 指运行 Aria2 所在机器的 IP 或者名字 port: 使用 --rpc-listen-port 选项设置的端口, 未设置则是 6800；可通过 lsof -i:6800 查看端口是否被占用   使用 --rpc-secret=xxxxxx 选项设置为: http://token:xxxxxx@host:port/jsonrpc 使用 --rpc-user=user --rpc-passwd=pwd 选项设置为: http://user:pwd@host:port/jsonrpc 以上JSON-RPC Path 中的 http 可以用 ws 替代, 代表使用 WebSocket 协议。换用 ws 也可能解决 “Aria2 RPC 服务器错误”。 当使用 https://aria2c.com 访问时, 可能需要使用 https 或 wss 协议。  在 Web UI 中对 Aria2 的设置会在 Aria2 重启后丢失,，必要的设置请写入配置文件。\n已经下载完成的任务会在 Aria2 重启后消失, 除非启用了 --force-save 选项。\nProtocol **HTTP / HTTPS / FTP / SFTP **\n超文本传输协议（HTTP / HTTPS）和 文件传输协议（FTP / SFTP）将文件放到服务器上，然后由服务器传送到不同的用户机器上，称为Client-Server Model简称C/S模式，或者叫一对多模式。\n缺点是：当非常多的用户同时访问和下载服务器上的文件时，由于服务器处理能力和带宽的限制，下载速度会急剧下降，有的用户可能访问不了服务器。\nBitTorrent 协议\nBitTorrent(简称BT)是一个文件分发协议，每个下载者在下载的同时不断向其他下载者上传已下载的数据。BT协议与FTP协议不同，特点是下载的人越多，下载速度越快，原因在于每个下载者将已下载的数据提供给其他下载者下载，充分利用了用户的上载带宽。通过一定的策略保证上传速度越快，下载速度也越快。在很短时间内，BitTorrent协议成为一种新的变革技术。\nBitTorrent 的发展依赖于对等网络 (Peer - to - Peer 简称 P2P)。P2P技术体现了互联网最根本的内涵——自由和免费，它的主要优点如下：\n 对等性高：非中心化，互联网回归本色——联系和传输； 扩展性强：用户扩展与资源、服务、系统同步扩展； 健壮性高：服务分散和自适应，耐攻击、高容错性； 性价比高：P2P成本低、存储和技术能力强； 负载均衡：分布存储和技术，整个网络负载得以均衡。  在P2P网络中，每个参与的节点既是服务器又是客户端，既是信息的提供者又是信息的消费者。P2P信息检索的目的就是网络中的任意节点都可以提交检索的请求，然后这些检索通过相关信息的节点将会回应请求，按照某种路由机制路由到本地相关的内容，以对等的形式直接传送到请求节点上。\n检索过程分为以下几个阶段：每个节点在加入网络的时候，会对存储在本节点上的内容进行索引，以满足本地内容检索的目的。然后按某种预定的规则选择一些节点作为自己的邻居，加入到P2P网络当中。发起者P提出检索请求q，并将q发送给自己的邻居，P的邻居收到q后，再按照某种策略转发给它在网络中的其它邻居节点。这样，q就在整个网络中传播开来。收到请求q的节点如果存储有相应内容信息 , 则将对应的内容返回。\n普通的HTTP/FTP下载使用TCP/IP协议，BitTorrent协议是架构于TCP/IP协议之上的一个P2P文件传输协议，处于TCP/IP结构的应用层。 BitTorrent协议本身也包含了很多具体的内容协议和扩展协议，并在不断扩充中。\n根据BitTorrent协议，文件发布者会根据要发布的文件生成提供一个.torrent文件，即种子文件，也简称为“种子”。\n种子还有如下相关概念：\n 发布BT种子的人，做种多少天指的就是持续多少天不撤种。这期间如果有别人下完了，就叫出种。下完的人可以继续做种。这时发布种子的人就可以不做种了，叫撤种。 一个资源只要有一个人在做种，那就其他人就可以继续下。如果没人做种了，叫断种，这是资源就死了，下不了了。某人长时间一直做种，叫保种。  .torrent文件本质上是文本文件，包含Tracker信息和文件信息两部分。Tracker信息主要是BT下载中需要用到的Tracker服务器的地址和针对Tracker服务器的设置，文件信息是根据对目标文件的计算生成的，计算结果根据BitTorrent协议内的B编码规则进行编码。它的主要原理是需要把提供下载的文件虚拟分成大小相等的块，块大小必须为2k的整数次方（由于是虚拟分块，硬盘上并不产生各个块文件），并把每个块的索引信息和Hash验证码写入种子文件（.torrent）中。所以，种子文件（.torrent）就是被下载文件的“索引”。\n下载者要下载文件内容，需要先得到相应的.torrent文件，然后使用BT客户端软件进行下载。\n下载时，BT客户端首先解析.torrent文件得到Tracker地址，然后连接Tracker服务器。Tracker服务器回应下载者的请求，提供下载者其他下载者（包括发布者）的IP。下载者再连接其他下载者，根据.torrent文件，两者分别对方告知自己已经有的块，然后交换对方没有的数据。此时不需要其他服务器参与，分散了单个线路上的数据流量，因此减轻了服务器负担。\n下载者每得到一个块，需要算出下载块的Hash验证码与.torrent文件中的对比，如果一样则说明块正确，不一样则需要重新下载这个块。这种规定是为了解决下载内容准确性的问题。\n从 BT 客户端角度考虑，下载原理分为以下几步：\n 根据 BitTorrent 协议，文件发布者会根据要发布的文件生成提供一个 .torrent 文件。客户端可从 Web 服务器上下载种子文件，并从中得到 Tracker 服务器 URL。 根据 Tracker URL 与 Tracker 服务器建立连接，并从服务器上得到 Peers 信息。 根据 Peers 信息与一个 Peer 建立连接，依据 Peer wire 协议完成握手，并从 Peer 端下载数据文件。同时监听 Peer 的连接，并给 Peer 上传数据文件。  迅雷，俗称吸血雷：\n 吸血就是指一些客户端在进行P2P下载时，从其它客户端下载的数据量非常多，但是分享给其它客户端的数据非常少，下载完成后立即关机走人的行为 而迅雷就是这样的一个下载器，迅雷的服务器疯狂索取资源，但自己又不上传资源给别人），当收集了大量资源后，进而下载限速，开启付费会员制度  BT下载讲究共享精神，这跟互联网的共享精神一脉相承，所以请不要在BT下载器设置里面限制上传速度。\n鉴于这类自私行为对其它合理使用P2P网络的用户的伤害，现在的很多P2P软件都加入反吸血功能。就是说检测到特定用户的吸血行为或者吸血软件时自动对这些用户降权处理，简单来说就是你的上传速度低的话，你的下载速度也不会特别快。\n这里又要多嘴一句\n 迅雷靠着自身在国内多年的发展，服务器里囤积了大量资源，所以很多其他BT下载器下载不动的资源，可能只有迅雷下载的动（因为它原来从别人那里下载了后存在了它的服务器上） 同理，很多文件可能只有115才能能离线下载，也是因为当年的115就存储了大量的资源在它服务器上 这里顺便可以说一下，所谓的百度云秒离线功能，不过是在你离线下载之前，已经有人把这个文件离线下载到百度云服务器中了  BT下载带来的好处\n 快。减少了网路传输节点。 减轻服务器压力。如果某公司有新版本软件推出（如LOL游戏更新时），服务器必定会人山人海，而使用BT能大大减轻服务器的负担，节约服务器的购置成本。 保护隐私。与有http那种中央服务器的网络系统不同，BT下载节点能遍布整个互联网（每个人都是分享者与下载者），给包括开发者在内的任何人、组织、或政府带来监控难题。  坏处当然也有，从上面第3点不难得出，BT下载很容易导致一个问题：盗版泛滥——海盗湾。\n上面说过了，想加入BT下载的无中心网络，首先需要找Tracker服务器问路，于是Tracker服务器成为了版权组织打击的重点，他们的想法很明确，只要除掉了Tracker，BT下载就完了。\n然而魔高一尺道高一丈，需求带动发展，这反而促使了BT技术的一次大升级，这带来了磁力链接。\nMagNet 协议\nMagNet协议，也就是磁力链接，简称磁链。 Magnet不需要Tracker服务器，也不需要.torrent文件，仅需要一串字符就可以进行文件下载。\n磁力链接基于的是DHT网络技术，因此可以在无固定Tracker服务器的情况下下载，实际过程是把所有下载者都变成一个小型Tracker服务。\nDHT技术：2002年，纽约大学的两个教授Petar Maymounkov和David Mazières发表了一篇论文，提出了一种真正去中心化的“点对点”下载模型，他们将其称为Kademlia方法。2005年，BT软件开始引入这种技术，在BT中被称为DHT协议（Distributed Hash Table，分布式哈希表）。\nDHT是一种分布式存储方法。DHT的作用是找到那些与本机正在下载（上传）相同文件的对端主机（Peer），当然，实现这一过程并不依赖Tracker服务器。在DHT网络中的每个客户端负责一个小范围的路由，并负责存储一小部分数据，从而实现整个DHT网络的寻址和存储。这种信息获取方式保证了整个网络没有单个的中心，即使一个节点下线，依然可以通过其他节点来获取文件，因此也就不需要Tracker服务器来告诉你，其他节点在什么地方。\nPEX：是Peer Exchange的简写，我们可以将其理解为“节点信息交换”。虽然DHT解决了去中心化的问题，但要在没有“中心协调员”（Tracker）的情况下实现高效寻址，就要借助PEX。PEX所提供的功能有点类似于以前的Tracker服务器，但工作方式却非常不同，我们可以打个比方来说明：\n 当你得到一个磁力链接并进行下载时，使用比如迅雷，迅雷就会实例化出一个DHT节点，加入DHT网络 把DHT网络比作一个朋友圈子，当你被A带进这个朋友圈，此刻你就只认识A而已 但是你的目的是想找唐纳德·特朗普（川普）总统，所以你就问A要川普的联系方式，但是A也没有川普的联系方式， 他介绍了一个美国朋友B给你认识 于是你去问B要川普的联系方式，B其实也没有川普的联系方式，但是B认识一个美国州长C 于是你又得到了C的联系方式，C把川普的联系方式告诉你之后，你就可以写信或者致电给川普了  这里相关的有个有趣的理论「六度分隔理论」（也叫六度空间理论）：简单来说，就是最多通过6个中间人你就能够认识世界上任何一个陌生人。\nMagnet links（磁力链接）示例：\nmagnet:?xt=urn:btih:36684b463ca2aa2f9347b18e9f6b1a9090bdb073\u0026amp;dn=Microsoft+iSCSI+Initiator  magnet：协议名。 xt：exact topic的缩写，表示资源定位点。BTIH（BitTorrent Info Hash）表示哈希方法名，这里还可以使用SHA1和MD5。这个值是文件的标识符，是不可缺少的。 dn：display name的缩写，表示向用户显示的文件名。这是一个可选项。 tr：tracker的缩写，表示tracker服务器的地址。这是一个可选项，本例中并未出现。  可能看出了DHT+PEX+Magnet Link模式中的一个问题——BT客户端的“第一步是如何迈出的”，套用在介绍PEX时使用的例子，那就是你怎怎么进入A的这个朋友圈的（即DHT节点如何进入DHT网络）？这确实是个问题。解决这个问题依然需要一台服务器（bootstrap node），不过这台服务器所起的作用与Tracker不同，它仅负责接纳DHT节点如何进入DHT网络，当DHT节点与其它DHT节点“搭上了话”，之后这台服务器就没有什么用处了。bootstrap node可以是不同BT客户端厂商独立运营的，也可以是几家联合共用，总之，它是分散的，只要在客户端软件中内置一张表单，那客户端就将有非常多的入口可供选择。\neD2k 协议\nBT / 磁力 / eD2k都是P2P技术 。eD2k链接对应的客户端，如eMule电骡是共享软件，而Magnet磁链对应的BT软件则是下载软件。这让它们在使用上，有着很多根本性的区别：\n BT使用的时候，只要你不下载东西你就不会上传 eMule电骡不同，比如，开启eMule电骡后，第一件事做的并不是什么下载，而是设置共享目录，该目录中的所有文件，都会实时共享到eD2k网络和KAD网络中。 目录中共享了的文件都会生成eD2k链接，所有人通过相应的eD2k链接，都能够拿到你共享的文件，一旦有人下载相应文件，那么你的eMule客户端就会上传数据，换言之，你想下载别人的文件，需要别人开着eMule客户端 我们平时使用eD2k链接下载，资源也是来自他人eMule所共享的文件的。当然，共享目录中也可以啥都不放，但很多eMule客户端都拥有队列优先级机制，上传得少，下载速度也会被限制。  电驴可以说是进化版的BT，用户不需要下载什么种子文件了，直接在“电驴”软件上输入eD2k开头的一长串代码一样的链接，就能下载。\n电驴以及后来的电骡、VERYCD电驴还有各种类似的软件，采用的eD2k网络仍是基于服务器的，你需要连接到服务器并从服务器索引 / 查找用户或者文件\n重要的是电驴提供的其中一种模式——KAD网络（类似磁力下载中的DHT网络），能够脱离中央服务器，直接实现网络来用户之间的点对点传输\n历史证明，这个脱离中央服务器的革新，真的十分十分的重要——这是电驴软件在面对盗版问题时，能够生存下来的主要原因，因为他们可以说，那是用户之间的自发传输行为，没有经过服务器\n但是，尽管电驴做了如此多的革新，但还是逃不过被时代淘汰的命运，客户端对于大部分人来说配置起来十分复杂，愿意一直开着服务器上传资源的人越来越少，更多人只想单纯的索取（类似上文提到的迅雷吸血行为），如今使用eD2k分享资源的人实在算少数，远不如磁力下载。\nOthers AriaNg\nAriaNg 是一个让 aria2 更容易使用的现代 Web 前端\n 使用很简单，将文件下载解压即可，可以本地打开 index.html 文件，也可上传到服务器。 如果您懒得部署 AriaNg ，可以直接访问现成的 http://a2.ssss.fun 。 打开后需要配置 AriaNg，打开 AriaNg 设置 - RPC，修改 Aria2 RPC 地址 和 Aria2 RPC 密钥 ，点击 重新加载 AriaNg 即可。  WebUI-Aria2\n这个项目的目标是创建世界上最好和最热门的界面来与 aria2 交互。\n使用非常简单，只需在任何网络浏览器中下载并打开 index.html。\nAria2 for \u0026hellip;.\n比如 YAAW for Chrome、Aria2 for Chrome 、Aria2 for Edge 之类的。\n在浏览器中直接内置一个 AriaNg，用于直接管理 Aria2。\nUsing Aria2 as a Daemon\n运行 gnome-session-properties打开应用程序首选项管理，添加：\n Name: Aria2 Daemon Command: /usr/bin/aria2c --conf-path=/home/kurome/.aria2/aria2.conf -D  会建立 .config/autostart/aria2c.desktop\n[Desktop Entry] Type=Application Exec=/usr/bin/aria2c --conf-path=/home/vane/.aria2/aria2.conf -D Hidden=false NoDisplay=false X-GNOME-Autostart-enabled=true Name[en_US]=Aria2 Daemon Name=Aria2 Daemon Comment[en_US]= Comment= BT 下载预热\n是这样滴，和很多BT客户端一样，Aria2有个dht.dat文件(开启ipv6还有个dht6.dat)，这玩意用于存储一种叫做DHT Routing Table的东西，DHT网络由无数节点组成，你接触到一个后能通过它接触到更多的节点，Aria2我记得是有内置的节点，但是！如果你在Aria2第一次运行的时候直接下载磁力链接或者冷门种子，你很可能遇到连MetaData都无法获取的情况，这就是因为第一次只是初始化dht.dat文件，你本地不存在DHT Routing Table的缓存，所以你无法从DHT网络中获取足够的数据。\n那么怎么办？我的建议是，找个热门种子(千万建议是种子，而不是磁力链接)，然后下一波，挂着做种，过几个小时后退出Aria2，或者等Aria2会话自动保存，你会发现dht.dat从空文件变成有数据了，这时候你下载就会正常很多。\n什么是PT，PT和BT有什么不同？\n答：PT（Private Tracker）下载其实也是Bt下载的一种，但有两个明显的改进：一是私密的小范围下载，二是进行流量统计，根据上载量决定你的权限。\nBT下载时，软件会分析.torrent种子文件得到Tracker地址，然后连接Tracker服务器，服务器返回其他下载者的IP，下载者再与这些IP联系进行下载，从而减轻了服务器的负担，BT下载的Tracker是公开的，而Private Tracker 下载(PT下载)的Tracker则是私有的，每个人的Tracker是不同的，即passkey不同，passkey对PT下载者很重要，所以不要轻易泄露出去。\n其实和通常BT相比，PT就是多了一个passkey验证，这样就能保证未注册的用户不能下载。所以passkey很重要，一旦发现有问题，就要到站点上去重置passkey。Tracker Server根据passkey把BT客户端上传量和下载量进行计算，从而算出分享率(上传量/下载量)。如果分享率太小，将会被删除帐号，从而不能下载。\n这样Private Tracker 下载(PT下载)是一种小范围的BT下载，通过禁用DHT有要求地选择并控制用户数量，这样，在有限的范围内，下载的用户基本上都可以达到自己的宽带上限，Private Tracker 下载(PT下载)下载还通过论坛等方式的约束机制将BT下载的理念现实化，真正让用户做到下载的过程中努力上传。因此，Private Tracker 下载(PT下载)的速度很快，能够让用户款待得到最大程度的使用。\nPT通过对做种时间和流量的要求在一定程度上避免了BT中存在的下完不做种的现象，因此在网络上，尤其是需要大文件（如高清）资源交换的时候广受欢迎，在PT站里，“水管”代表上传带宽的大小，大水管可以通过快速的上传获得积分，PT站点也会采取措施（比如做种时间，优惠等）使上传较慢的小水管能够参与贡献和共享资源。\nRPC\n首先了解什么叫RPC，为什么要RPC，RPC是指远程过程调用，也就是说两台服务器A，B，一个应用部署在A服务器上，想要调用B服务器上应用提供的函数/方法，由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义和传达调用的数据。\n比如说，一个方法可能是这样定义的：\nEmployee getEmployeeByName(String fullName) 那么：\n 首先，要解决通讯的问题，主要是通过在客户端和服务器之间建立TCP连接，远程过程调用的所有交换的数据都在这个连接里传输。连接可以是按需连接，调用结束后就断掉，也可以是长连接，多个远程过程调用共享同一个连接。 第二，要解决寻址的问题，也就是说，A服务器上的应用怎么告诉底层的RPC框架，如何连接到B服务器（如主机或IP地址）以及特定的端口，方法的名称名称是什么，这样才能完成调用。比如基于Web服务协议栈的RPC，就要提供一个endpoint URI，或者是从UDDI服务上查找。如果是RMI调用的话，还需要一个RMI Registry来注册服务的地址。 第三，当A服务器上的应用发起远程过程调用时，方法的参数需要通过底层的网络协议如TCP传递到B服务器，由于网络协议是基于二进制的，内存中的参数的值要序列化成二进制的形式，也就是序列化（Serialize）或编组（marshal），通过寻址和传输将序列化的二进制发送给B服务器。 第四，B服务器收到请求后，需要对参数进行反序列化（序列化的逆操作），恢复为内存中的表达方式，然后找到对应的方法（寻址的一部分）进行本地调用，然后得到返回值。 第五，返回值还要发送回服务器A上的应用，也要经过序列化的方式发送，服务器A接到后，再反序列化，恢复为内存中的表达方式，交给A服务器上的应用  为什么RPC呢？就是无法在一个进程内，甚至一个计算机内通过本地调用的方式完成的需求，比如比如不同的系统间的通讯，甚至不同的组织间的通讯。由于计算能力需要横向扩展，需要在多台机器组成的集群上部署应用，\nRPC的协议有很多，比如最早的CORBA，Java RMI，Web Service的RPC风格，Hessian，Thrift，甚至Rest API。\n其他下载工具\n qBittorrent Transmission rTorrent Deluge  有支持ed2k的计划吗？\n真是笑死我了，你们难道真的认为那所谓迅雷等国产BT下载软件会使用真正的eDonkey网络？\n非也！它们只不过通过ed2k链接所列出的哈希值 直接链接到它们服务器自身（如迅雷、百度）所存储的文件 或链接到BitTorrent协议的种子和磁力链接上。你们用的软件不是P2P（Peer to Peer），而是P2SP（Peer to Server and to Peer）！\n如果你们用过真正的ed2k下载器（如eMule、aMule）的话，你们会发现，真正的eDonkey网络早已消亡，截至目前全球用户也就50-60万的样子。\n最后，作为曾经的eMule老用户，我可以说明真正的eDonkey网络不仅有繁琐的排队机制，还有文件优先级网络优先级等复杂的设定，远比你们想像中难用的多。\nyoutube-dl youtube-dl 是一个命令行程序，用于从 YouTube.com 和更多其他网站下载视频。 基于 Python 实现，不限于特定平台。\n# 安装 $ pip install -i https://pypi.tuna.tsinghua.edu.cn/simple youtube-dl # 使用 $ youtube-dl [OPTIONS] URL [URL...] 当前版本（2021.06.06）不能下载哔哩哔哩播放列表，可以用类似软件如 you-get， annie 代替。\nUsage 下载视频或整个视频播放列表\n 要从 Youtube 下载视频或整个视频播放列表，只需直接使用 URL 即可：youtube-dl [url]。程序自动选择一个最清晰的格式下载。 如果要指定视频下载之后的名称，可以使用如下方式：youtube-dl -o '名称' [url]。 还可以在下载视频时附加更多详细信息，可用的参数有标题、上传者名称（频道名称）和视频上传日期等：youtube-dl -o '%(title)s by %(uploader)s on %(upload_date)s in %(playlist)s.%(ext)s' [ul]。  查看视频的所有类型，只看不下载\n命令：youtube-dl -F [url]或者youtube-dl --list-formats [url]。 这是一个列清单参数，执行后并不会下载视频，但能知道这个目标视频都有哪些格式存在，以便有选择的下载。\n下载指定质量的视频和音频并自动合并\n下载最佳/最差质量的音/视频文件：\n默认情况下，youtube-dl将自主选择最佳质量的视频下载。 但是，也可以以特定的质量或格式来下载视频或播放列表\nYoutube-dl 支持以下品质：\n best选择最佳质量的音/视频文件 worst选择质量最差的格式（视频和音频） bestvideo选择最佳质量的仅视频格式（例如DASH视频），可能无法使用。 worstvideo选择质量最差的纯视频格式，可能无法使用。 bestaudio选择最优质的音频格式，可能无法使用。 worstaudio选择质量最差的音频格式，可能无法使用。  例如，如果要自动选择并下载最佳质量格式（音频和视频），只需使用以下命令：youtube-dl -f best [url]。\n您还可以组合使用以下不同的格式选项：youtube-dl -f bestvideo+bestaudio [ul]。该命令将分别下载最高质量的仅视频和最高质量的纯音频格式，再用ffmpeg或avconv合并成一个最佳质量的mkv文件；如果您不想合并，请将+（加号）替换为,（逗号）即可分别得到最高质量的音频和视频（两个文件）：youtube-dl -f 'bestvideo,bestaudio' [url]。\n 下载指定质量的音/视频文件：\n-F 获取的所有视频格式的清单，最左边一列就是编号对应着不同的格式。由于YouTube的1080p及以上的分辨率都是音视频分离的，所以我们需要分别下载视频和音频，可以使用137+140这样的组合。如果系统中安装了ffmpeg的话，youtube-dl 会自动合并下好的视频和音频，然后自动删除单独的音视频文件：youtube-dl -f [format code] [url]。\n从播放列表下载视频时，某些视频可能没有相同的格式。 在这种情况下，可以按首选顺序指定多个格式代码，例如：命令youtube-dl -f 22/17/18 \u0026lt;playlist_url\u0026gt;将以格式 22 下载视频（如果可用）；如果格式 22不可用，则它将下载格式 17（如果可用）；如果格式 22 和 17 都不可用，最后尝试下载格式 18。如果所有格式代码都不匹配，Youtube-dl 会报出提示。还需要注意的是，斜杠是左关联的，即最左侧的格式代码是首选。\n下载字幕\n youtube-dl --write-sub [url]这样会下载一个vtt格式的英文字幕和mkv格式的1080p视频下来 youtube-dl --write-sub --skip-download [url]下载单独的vtt字幕文件,而不会下载视频 youtube-dl --write-sub --all-subs [url]下载所有语言的字幕(如果有的话) youtube-dl --write-auto-sub [url]下载自动生成的字幕(YouTube only)  下载多个视频\n youtube-dl \u0026lt;url1\u0026gt; \u0026lt;url2\u0026gt;有时我们需要一次下载多个不同的视频，此时我们只需用空格将多个URL分隔开即可。 youtube-dl -a url.txt也可以将要下载视频的URL全部放在文本文件中，并将其作为参数传递给youtube-dl。此命令将下载url.txt文件中所有URL指向的视频。  只下载（视频中的）音频\n youtube-dl -x [url]仅从视频网站下载其音频。 youtube-dl -x --audio-format mp3 [ul]默认情况下，youtube-dl 将以Ogg （opus）格式保存音频。此命令将从给定的视频/播放列表下载音频，将其转换为 MP3 并将其保存在当前目录中。应注意：您应该安装 ffmpeg 或 avconv 将文件转换为 mp3 格式。  下载带有描述、元数据、注释、字幕和缩略图的视频\n要下载视频及其他详细信息，如：说明、元数据、注释、字幕和缩略图等，请使用以下命令： youtube-dl --write-description --write-info-json --write-annotations --write-sub --write-thumbnail [url]\n通过文件扩展名下载音/视频\n 以您的首选格式下载视频，例如 MP4，只需执行：youtube-dl --format mp4 [url]或者youtube-dl -f mp4 [url]。 某些视频可能无法以您的首选格式提供。 在这种情况下，youtube-dl 将下载其他最佳可用格式。例如： youtube-dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best' [ul] 此命令将下载最佳质量的MP4格式文件。如果 MP4 格式不可用，则它将下载其他最佳可用格式。  限制下载视频的大小\n从YouTube播放列表下载多个视频时，您可能只想下载特定大小的视频。例如：\n 此命令不会下载任何小于指定大小（例如100MB）的视频：youtube-dl --min-filesize 100M \u0026lt;playlist_url\u0026gt;。 如果您不想下载大于给定大小的视频，可以这样：youtube-dl --max-filesize 100M \u0026lt;playlist_url\u0026gt;。  我们还可以用组合格式，选择运算符来下载特定大小的视频。例如：\n 以下命令将下载最佳视频格式但不大于 100MB 的视频：youtube-dl -f 'best[filesize\u0026lt;100M]' [url]。  按日期下载视频\nYoutube-dl 允许我们按照上传日期来筛选和下载视频或播放列表，例如：\n 要下载 2019 年 8 月 1 日上传的视频，可以使用：youtube-dl --date 20190801 [URL]； 下载在特定日期或之前上传的视频：youtube-dl --datebefore 20190801 [URL]； 下载在特定日期或之后上传的视频：youtube-dl --dateafter 20190101 [URL]； 仅下载过去 6 个月内上传的视频：youtube-dl --dateafter now-6months [URL]； 下载特定时间段内（例如 2018 年 1 月 1 日至 2019 年 1 月 1 日）上传的视频：youtube-dl --dateafter 20180101 --datebefore 20190101 [URL]。  从播放列表下载特定的视频\n从播放列表下载特定的视频，是youtube-dl 的另一个非常有用的功能。例如：\n 要从播放列表下载第 10 个文件，可使用：youtube-dl --playlist-items 10 [playlist_url]； 要下载多个指定的文件，只需用逗号分隔：youtube-dl --playlist-items 2,3,7,10 [playlist_url]；  也可以按序号来指定要下载范围，例如：\n 从第 10 个开始，直接下载完整个列表：youtube-dl --playlist-start 10 [playlist_url]； 在播放列表中仅下载从第 2 到第 5 的文件：youtube-dl --playlist-start 2 --playlist-end 5 [playlist_url]。  Configuration 在 Linux 和 macOS 上，系统配置文件位于 /etc/youtube-dl.conf，用户配置文件位于 ~/.config/youtube-dl/config。\n# Continue on download errors, for example to skip unavailable videos in a playlist --ignore-errors # Time to wait before giving up, in seconds --socket-timeout 10 # Download only videos not listed in the archive file. Record the IDs of all downloaded videos in it. #--download-archive /path/archive.txt # Number of retries (default is 10), or \u0026#34;infinite\u0026#34;. --retries infinite # Give these arguments to the external downloader --external-downloader aria2c --external-downloader-args \u0026#34;--no-conf -c\u0026#34; # Output filename template, see the \u0026#34;OUTPUT TEMPLATE\u0026#34; for all the info -o \u0026#39;~/Videos/%(id)s.%(ext)s\u0026#39; # Write thumbnail image to disk #--write-thumbnail # download best 30hz mp4 file , h264+aac ,use http or https protocol,because we can use aria2c downloader to have a faster speed --format \u0026#39;(bestvideo[ext=mp4][fps\u0026lt;31]+bestaudio[ext=m4a]/best[ext=mp4]/bestvideo+bestaudio/best)[protocol^=http]\u0026#39; # Embed thumbnail in the audio as cover art #--embed-thumbnail # Write metadata to the video file --add-metadata curl 简介 curl 是常用的命令行工具，用来请求 Web 服务器。它的名字就是客户端（client）的 URL 工具的意思。\n它的功能非常强大，命令行参数多达几十种。如果熟练的话，完全可以取代 Postman 这一类的图形界面工具。\n本文介绍它的主要命令行参数，作为日常的参考，方便查阅。\n不带有任何参数时，curl 就是发出 GET 请求。\n$ curl https://www.example.com 上面命令向www.example.com发出 GET 请求，服务器返回的内容会在命令行输出。\n主要命令行参数 -A\n-A参数指定客户端的用户代理标头，即User-Agent。curl 的默认用户代理字符串是curl/[version]。\n$ curl -A \u0026#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36\u0026#39; https://google.com 上面命令将User-Agent改成 Chrome 浏览器。\n$ curl -A \u0026#39;\u0026#39; https://google.com 上面命令会移除User-Agent标头。\n也可以通过-H参数直接指定标头，更改User-Agent。\n$ curl -H \u0026#39;User-Agent: php/1.0\u0026#39; https://google.com -b\n-b参数用来向服务器发送 Cookie。\n$ curl -b \u0026#39;foo=bar\u0026#39; https://google.com 上面命令会生成一个标头Cookie: foo=bar，向服务器发送一个名为foo、值为bar的 Cookie。\n$ curl -b \u0026#39;foo1=bar;foo2=bar2\u0026#39; https://google.com 上面命令发送两个 Cookie。\n$ curl -b cookies.txt https://www.google.com 上面命令读取本地文件cookies.txt，里面是服务器设置的 Cookie（参见-c参数），将其发送到服务器。\n-c\n-c参数将服务器设置的 Cookie 写入一个文件。\n$ curl -c cookies.txt https://www.google.com 上面命令将服务器的 HTTP 回应所设置 Cookie 写入文本文件cookies.txt。\n-d\n-d参数用于发送 POST 请求的数据体。\n$ curl -d \u0026#39;login=emma＆password=123\u0026#39;-X POST https://google.com/login # 或者 $ curl -d \u0026#39;login=emma\u0026#39; -d \u0026#39;password=123\u0026#39; -X POST https://google.com/login 使用-d参数以后，HTTP 请求会自动加上标头Content-Type : application/x-www-form-urlencoded。并且会自动将请求转为 POST 方法，因此可以省略-X POST。\n-d参数可以读取本地文本文件的数据，向服务器发送。\n$ curl -d \u0026#39;@data.txt\u0026#39; https://google.com/login 上面命令读取data.txt文件的内容，作为数据体向服务器发送。\n\u0026ndash;data-urlencode\n--data-urlencode参数等同于-d，发送 POST 请求的数据体，区别在于会自动将发送的数据进行 URL 编码。\n$ curl --data-urlencode \u0026#39;comment=hello world\u0026#39; https://google.com/login 上面代码中，发送的数据hello world之间有一个空格，需要进行 URL 编码。\n-e\n-e参数用来设置 HTTP 的标头Referer，表示请求的来源。\ncurl -e \u0026#39;https://google.com?q=example\u0026#39; https://www.example.com 上面命令将Referer标头设为https://google.com?q=example。\n-H参数可以通过直接添加标头Referer，达到同样效果。\ncurl -H \u0026#39;Referer: https://google.com?q=example\u0026#39; https://www.example.com -F\n-F参数用来向服务器上传二进制文件。\n$ curl -F \u0026#39;file=@photo.png\u0026#39; https://google.com/profile 上面命令会给 HTTP 请求加上标头Content-Type: multipart/form-data，然后将文件photo.png作为file字段上传。\n-F参数可以指定 MIME 类型。\n$ curl -F \u0026#39;file=@photo.png;type=image/png\u0026#39; https://google.com/profile 上面命令指定 MIME 类型为image/png，否则 curl 会把 MIME 类型设为application/octet-stream。\n-F参数也可以指定文件名。\n$ curl -F \u0026#39;file=@photo.png;filename=me.png\u0026#39; https://google.com/profile 上面命令中，原始文件名为photo.png，但是服务器接收到的文件名为me.png。\n-G\n-G参数用来构造 URL 的查询字符串。\n$ curl -G -d \u0026#39;q=kitties\u0026#39; -d \u0026#39;count=20\u0026#39; https://google.com/search 上面命令会发出一个 GET 请求，实际请求的 URL 为https://google.com/search?q=kitties\u0026amp;count=20。如果省略--G，会发出一个 POST 请求。\n如果数据需要 URL 编码，可以结合--data--urlencode参数。\n$ curl -G --data-urlencode \u0026#39;comment=hello world\u0026#39; https://www.example.com -H\n-H参数添加 HTTP 请求的标头。\n$ curl -H \u0026#39;Accept-Language: en-US\u0026#39; https://google.com 上面命令添加 HTTP 标头Accept-Language: en-US。\n$ curl -H \u0026#39;Accept-Language: en-US\u0026#39; -H \u0026#39;Secret-Message: xyzzy\u0026#39; https://google.com 上面命令添加两个 HTTP 标头。\n$ curl -d \u0026#39;{\u0026#34;login\u0026#34;: \u0026#34;emma\u0026#34;, \u0026#34;pass\u0026#34;: \u0026#34;123\u0026#34;}\u0026#39; -H \u0026#39;Content-Type: application/json\u0026#39; https://google.com/login 上面命令添加 HTTP 请求的标头是Content-Type: application/json，然后用-d参数发送 JSON 数据。\n-i\n-i参数打印出服务器回应的 HTTP 标头。\n$ curl -i https://www.example.com 上面命令收到服务器回应后，先输出服务器回应的标头，然后空一行，再输出网页的源码。\n-I\n-I参数向服务器发出 HEAD 请求，然会将服务器返回的 HTTP 标头打印出来。\n$ curl -I https://www.example.com 上面命令输出服务器对 HEAD 请求的回应。\n--head参数等同于-I。\n$ curl --head https://www.example.com -k\n-k参数指定跳过 SSL 检测。\n$ curl -k https://www.example.com 上面命令不会检查服务器的 SSL 证书是否正确。\n-L\n-L参数会让 HTTP 请求跟随服务器的重定向。curl 默认不跟随重定向。\n$ curl -L -d \u0026#39;tweet=hi\u0026#39; https://api.twitter.com/tweet \u0026ndash;limit-rate4\n--limit-rate用来限制 HTTP 请求和回应的带宽，模拟慢网速的环境。\n$ curl --limit-rate 200k https://google.com 上面命令将带宽限制在每秒 200K 字节。\n-o\n-o参数将服务器的回应保存成文件，等同于wget命令。\n$ curl -o example.html https://www.example.com 上面命令将www.example.com保存成example.html。\n-O\n-O参数将服务器回应保存成文件，并将 URL 的最后部分当作文件名。\n$ curl -O https://www.example.com/foo/bar.html 上面命令将服务器回应保存成文件，文件名为bar.html。\n-s\n-s参数将不输出错误和进度信息。\n$ curl -s https://www.example.com 上面命令一旦发生错误，不会显示错误信息。不发生错误的话，会正常显示运行结果。\n如果想让 curl 不产生任何输出，可以使用下面的命令。\n$ curl -s -o /dev/null https://google.com -S\n-S参数指定只输出错误信息，通常与-s一起使用。\n$ curl -s -o /dev/null https://google.com 上面命令没有任何输出，除非发生错误。\n-u\n-u参数用来设置服务器认证的用户名和密码。\n$ curl -u \u0026#39;bob:12345\u0026#39; https://google.com/login 上面命令设置用户名为bob，密码为12345，然后将其转为 HTTP 标头Authorization: Basic Ym9iOjEyMzQ1。\ncurl 能够识别 URL 里面的用户名和密码。\n$ curl https://bob:12345@google.com/login 上面命令能够识别 URL 里面的用户名和密码，将其转为上个例子里面的 HTTP 标头。\n$ curl -u \u0026#39;bob\u0026#39; https://google.com/login 上面命令只设置了用户名，执行后，curl 会提示用户输入密码。\n-v\n-v参数输出通信的整个过程，用于调试。\n$ curl -v https://www.example.com --trace参数也可以用于调试，还会输出原始的二进制数据。\n$ curl --trace - https://www.example.com -x\n-x参数指定 HTTP 请求的代理。\n$ curl -x socks5://james:cats@myproxy.com:8080 https://www.example.com 上面命令指定 HTTP 请求通过myproxy.com:8080的 socks5 代理发出。\n如果没有指定代理协议，默认为 HTTP。\n$ curl -x james:cats@myproxy.com:8080 https://www.example.com 上面命令中，请求的代理使用 HTTP 协议。\n-X\n-X参数指定 HTTP 请求的方法。\n$ curl -X POST https://www.example.com 上面命令对https://www.example.com发出 POST 请求。\nHTTPie HTTPie（http）以一种更人性化的方式做同样的工作。你会看到彩色的、格式化的输出，这使得它更容易理解和调试。\nUSENET 起源 简单地说，USENET是一个巨大无比的网上讨论组，一般也称为\u0026quot;新闻组\u0026quot;（newsgroups）。你可以将它想象成一个包罗万象、无所不有的网上论坛，但是它又不同于我们通常看到的普通论坛。这要从它的起源说起。\n上个世纪70年代末，当时还没有互联网和浏览器，它们都要在十多年后才会出现。那时所谓\u0026quot;上网\u0026quot;，就是用modem（调制解调器），拨一个电话号码，将自己的电脑连到另一台电脑（也称\u0026quot;主机\u0026quot;），收收邮件，看看上面系统管理员发的通告。如果想换一台主机看看，那就必须先挂断，再拨另外一个电话号码。\n这样的上网方式，很不利于开展多人的讨论。由于是拨号上网，只有地理位置相近的用户，才会登录同一台主机。很难想象，同一台机器的登录用户，既有东岸的纽约人，也有西岸的洛杉矶人。即使长途电话费不是问题，当时的主机也没有能力同时负担太多的远程终端。因此，迫切需要一种大规模的、分布式的、多中心的远程信息交换手段。\n1979年，Duke大学的两个研究生Tom Truscott和Jim Ellis，提出一种分布式的网上讨论组的构想。这种讨论组创建之初，主要是供UNIX爱好者协会（USENIX）的成员使用，因此就被定名为USENET。当然，后来全世界的用户都在使用它。\n运行机制 USENET的运行机制其实非常简单。对于用户来说，只有三步。\n1）网络服务提供商（ISP）在一个网络中，设定一台服务器作为USENET专用服务器，再将它的网址告诉用户。\n2）用户想要发言的时候，就向这个网址发送帖子（post），这与发送Email很相似，但是两者格式不一样，在USENET上发言必须使用专用的客户端。不过，现在大多数的Email客户端都带有新闻组功能，最常见的Outlook Express的设置可以参考网上的说明。\n3）查看其他人的发言时，就必须从服务器上下载其他人的帖子。下载完成后，如果想回复某人的帖子，就再重复第二步。\n可以看到，这个过程同邮件列表的运行几乎一模一样，不同之处在于，USENET服务器每天会同其他USENET服务器交换帖子。这就是说，全世界所有的USENET服务器最终都可以互相交换帖子，保持内容的同步。所以理论上，不管你的帖子是发到哪一台服务器上，最终全世界的人们都会看到，并且会从世界各地给你回复。\n因此，USENET就有一个其他交流机制所没有的优点，即这是一个真正的全世界参与的讨论组。\n内容结构 由于USENET中的讨论内容无所不包，所以必须根据主题分类。每一个主题就是一个\u0026quot;频道\u0026quot;，对这个主题感兴趣的用户就订阅这个频道。\nUSENET中的主题分类采用等级制（hierarchies），在形式上同域名很相似，即\u0026quot;一级主题.二级主题.三级主题\u0026hellip;.\u0026quot;，中间以小数点分隔。\n一级主题有9个。\n * comp.*: 与计算机相关的讨论。（computer-related discussions，比如comp.software, comp.sys.amiga）\n* misc.*: 各种不属于其他分类的主题。（Miscellaneous topics，比如misc.education, misc.forsale, misc.kids）\n* news.*: 对USENET本身的讨论（比如news.groups, news.admin）\n* rec.*: 休闲和娱乐（Recreation and entertainment，比如rec.music, rec.arts.movies）\n* sci.*: 与科学相关的讨论。（Science related discussions，比如sci.psychology, sci.research）\n* soc.*: 与社会相关的讨论。（Social discussions，比如soc.college.org, soc.culture.african）\n* talk.*: 各种争议性话题的讨论。（Talk about various controversial topics，比如talk.religion, talk.politics, talk.origins）\n* humanities.*: 艺术、文学、哲学方面的讨论。（Fine arts, literature, and philosophy，比如humanities.classics, humanities.design.misc）\n* alt.*: 自由讨论区。（alternative）\n 这9个一级主题中，除了alt.*以外，都不能自行设立讨论区。只有在alt主题区中，可以自己发起主题\u0026quot;频道\u0026quot;。\n二进制内容 USENET最初设计的时候，只打算用来传递文本信息，没有考虑传递二进制数据（也就是\u0026quot;文件\u0026quot;）。但是，随着互联网的发展，不传递二进制数据看上去是不可能的。\n于是，专门的编码方式被设计了出来，使得二进制文件可以转换成文本文件，在USENET上传递，用户下载以后再传换成原来的格式。这时，USENET就不仅是一个讨论组了，而成了传递文件的一种手段，图片、音频和视频都可以通过USENET传播。\n事实上，如今USENET上的流量，99%都已经是二进制文件了。它们大部分都在alt.binaries这个主题中传播。由于不受监管，所以各种各样的文件都有。\n收费服务 根据一项统计，2007年4月USENET上一天的流量为3.12TB，且还在快速增加中。这么大的流量，使得世界上提供USENET的服务商肯定不会很多。大家可以查看这个网页，上面有USENET提供商的不完全列表。\n这些服务商，又分为免费和收费两种。免费的USENET绝大多数都不提供二进制文件下载，查看alt.free.newsservers主题可以获得最新的免费USENET服务器的信息。\n在收费服务商中，名气比较大的是GIGANEWS，它提供多种收费账户供用户选择。其中白金用户每月费用为19.99美元，可以无限量下载，14天内不满意可以退款。如果你是一个狂热的下载爱好者，我强烈推荐去购买一个账户。\nGoogle Groups Google Groups也提供免费USENET服务。（当然，没有二进制文件下载。）我会另写文章专门介绍，这里就省略了。\nEditor VSCode 中国国内下载 VSCode 速度慢问题解决：使用 azure 中国 cdn 镜像地址加速下载 VSCode\n将默认下载地址\nhttps://az764295.vo.msecnd.net/stable/ 替换为 vscode.cdn.azure.cn\nhttps://vscode.cdn.azure.cn/stable/ 自动换行\n将word wrap的off改成on\n最适合程序员的笔记软件\nhttps://github.dev/[用户名]/[仓库名] Google Keep Now I am using Google Keep.\nGoogle Keep键盘快捷键\n   hortcut Action     J/K Next/previous note   Shift + J/K Move note to next/previous position   N/P Next/previous list item   Shift + N/P Move list item to next/previous position   C New note   L New list   / Search   Ctrl + A Select all   E Archive   # Delete   F Pin/unpin   X Select   Ctrl + G Toggle list and grid view   Esc Close editor   Ctrl + Shift + 8 Toggle checkboxes   Ctrl + ] / [ Indent/dedent list item   ? Open shortcut list   @ Send feedback    Joplin+Typora+OneDrive Joplin $ wget -O - https://raw.githubusercontent.com/laurent22/joplin/dev/Joplin_install_and_update.sh | bash Typora 安装：\n# sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys BA300B7755AFCFAE $ wget -qO - https://typora.io/linux/public-key.asc | $ sudo apt-key add - # add Typora\u0026#39;s repository $ sudo add-apt-repository \u0026#39;deb https://typora.io/linux ./\u0026#39; $ sudo apt-get update # install typora $ sudo apt-get install typora 如果安装的时二进制包，则建立 typora.desktop\n$ gedit ~/.local/share/applications/typora.desktop [Desktop Entry] Name=Typora Comment=a minimal Markdown reading \u0026amp; writing app. Change Log: (https://typora.io/windows/dev_release.html) GenericName=Markdown Editor Exec=/home/kurome/.typora/Typora %U Icon=/home/kurome/.typora/resources/assets/icon/icon_256x256.png Type=Application StartupNotify=true Categories=Office;WordProcessor; MimeType=text/markdown;text/x-markdown; typora 有时会出现丢数据的现象，很困扰；特别是围栏代码块，失去了缩进，成了一行，完全不可阅读了。但是其他的 Markdown Editor 用的不习惯，例如 VSCode、Sublime、ghostwriter、marktext。因此最好通过 ppa 安装，获取 Typora 最新的版本。\n在Joplin下，菜单Tools-\u0026gt;Options-\u0026gt;General\u0026gt;Text editor command可以设置第三方编辑软件。\n配置 File \u0026gt; Preferences：\n General \u0026gt; Auto Save: on Editor \u0026gt; Spell Check: Disable Image \u0026gt; Use relative path if possible: on Markdown \u0026gt; Syntax Support \u0026gt; Inline Math: on  Crack Typora 1.0.4\n  需要python、nodejs 环境，没有的话自行安装一下\n$ sudo apt install pip nodejs   克隆脚本文件 https://github.com/Mas0nShi/typoraCracker.git\n  安装依赖:\n$ pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r ~/Downloads/typoraCracker-master/requirements.tx Missing dependencies for SOCKS support：\n关闭代理，安装 pysocks\n# Unset socks proxy $ unset all_proxy $ unset ALL_PROXY # Install missing dependencies: $ pip install pysocks # Reset proxy $ source ~/.bashrc   执行解包命名：\n$ cd ~/Downloads/Typora-linux-x64/bin/Typora-linux-x64/resources/ $ python3 ~/Downloads/typoraCracker-master/typora.py app.asar workstation/outfile   替换掉License.js文件\n$ cp ~/Downloads/typoraCracker-master/example/patch/License.js workstation/outfile/dec_app/   打包app.asar文件\n$ python3 ~/Downloads/typoraCracker-master/typora.py -u workstation/outfile/dec_app workstation/outappasar   将打包回来的app.asar文件重新丢到Typora的resources目录下\n$ cp workstation/outappasar/app.asar .   授权码生成\n$ node ~/Downloads/typoraCracker-master/example/keygen.js CAJ8Q4-ETFCZ4-RH3X85-GMKD68   激活：授权码输入生成的码，邮箱输入crack@example.com，完事。\n  Recover Unsaved Drafts Preferences =\u0026gt; General =\u0026gt; Save \u0026amp; Recover =\u0026gt; Recover Unsaved Drafts =\u0026gt; 选择要恢复的文档，打开后另存为到之前保存的地址覆盖它即可\nMarkText Foxit PDF Reader Industry’s most powerful PDF reader.\nWPS WPS Office is a lightweight, feature-rich comprehensive office suite with high compatibility.\nSublime Text Atom PDFCrack OCRmyPDF OCRmyPDF adds an OCR text layer to scanned PDF files, allowing them to be searched\nVim vi 与 vim.tiny $ whereis vi vi: /usr/bin/vi /usr/share/man/man1/vi.1.gz $ ls -al /usr/bin/vi lrwxrwxrwx 1 root root 20 Oct 26 20:31 /usr/bin/vi -\u0026gt; /etc/alternatives/vi $ ls -al /etc/alternatives/vi lrwxrwxrwx 1 root root 17 Oct 26 20:31 /etc/alternatives/vi -\u0026gt; /usr/bin/vim.tiny 可见，在Ubuntu上，vi是vim.tiny的软连接，但是执行命令vi与vim.tiny后是不一样，比如vi是：在编辑模式下使用方向键的时候，并不会使光标移动，而是在命令行中出现[A [B [C [D之类的字母；并且编辑错误的话，退格键(Backspace键)是使用不了的。\nMethods to find out which (configuration) files are read by executable when started-\u0026gt;\u0026lsquo;strace vim/nano\u0026rsquo; (Ubuntu)：\n$ strace -o $HOME/tracefile vi $ cat tracefile | grep vimrc stat(\u0026#34;/usr/share/vim/vimrc.tiny\u0026#34;, {st_mode=S_IFREG|0644, st_size=662, ...}) = 0 openat(AT_FDCWD, \u0026#34;/usr/share/vim/vimrc.tiny\u0026#34;, O_RDONLY) = 3 stat(\u0026#34;/home/vane/.vimrc\u0026#34;, 0x7fff3e755550) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/.vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/_vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) stat(\u0026#34;/home/vane/.vim/vimrc\u0026#34;, 0x7fff3e755550) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/.vim/vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) 可以看到 vi，加载的是 /usr/share/vim/vimrc.tiny\n$ strace -o $HOME/tracefile vim.tiny $ cat tracefile | grep vimrc stat(\u0026#34;/usr/share/vim/vimrc\u0026#34;, {st_mode=S_IFREG|0644, st_size=2266, ...}) = 0 openat(AT_FDCWD, \u0026#34;/usr/share/vim/vimrc\u0026#34;, O_RDONLY) = 3 stat(\u0026#34;/home/vane/.vimrc\u0026#34;, 0x7fff7c99cc30) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/.vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/_vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) stat(\u0026#34;/home/vane/.vim/vimrc\u0026#34;, 0x7fff7c99cc30) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/.vim/vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) 可以看到 vim.tiny，加载的是 /usr/share/vim/vimrc\n$ diff -u /etc/vim/vimrc /etc/vim/vimrc.tiny --- /etc/vim/vimrc\t2020-01-30 19:11:47.000000000 +0800 +++ /etc/vim/vimrc.tiny\t2020-04-15 14:40:31.000000000 +0800 @@ -1,55 +1,13 @@ ... +\u0026#34; Vim configuration file, in effect when invoked as \u0026#34;vi\u0026#34;. The aim of this +\u0026#34; configuration file is to provide a Vim environment as compatible with the +\u0026#34; original vi as possible. Note that ~/.vimrc configuration files as other +\u0026#34; configuration files in the runtimepath are still sourced. +\u0026#34; When Vim is invoked differently (\u0026#34;vim\u0026#34;, \u0026#34;view\u0026#34;, \u0026#34;evim\u0026#34;, ...) this file is +\u0026#34; _not_ sourced; /etc/vim/vimrc and/or /etc/vim/gvimrc are. ... 可以看到，上面什么说明白了。\nVim clear last search highlighting :noh VIMRC The ultimate Vim configuration (vimrc)\ncopilot.vim Neovim plugin for GitHub Copilot\nNeovim Neovim 提出了将 Vim 扩展为一个 IDE 的想法。\n它增加了现代终端的功能，如光标样式、焦点事件、括号内粘贴等，并内置了一个终端模拟器。最重要的是，你不需要忘却 Vim 的习惯就可以开始使用 Neovim。\n最适合程序员的笔记软件 程序员的笔记软件，应该满足下面几个条件。\n 跨平台，同时支持桌面电脑（Windows，Mac，Linux）和手机（Android，iOS）。 随时同步，打开任何一台机器，都能接着上一次的工作继续写。 实时存储，如果软件突然关闭，也不会丢失内容。 支持 Markdown 格式，便于后期直接发布。 支持推送到远程 Git 仓库，产生历史版本，同时作为远程备份。  Stackedit.io 和 HackMD.io，都不是很理想。\nGitHub 官方推出的 github.dev。只要访问 https://github.dev/[用户名]/[仓库名]，你就能在浏览器里面，使用 VS Code 编辑指定仓库。它实际上就是 VS Code 编辑器的 Web 版，并且与 Git 高度集成。GitHub 提供了一个快捷入口。 打开 GitHub 仓库主页，按一下小数点（.）这个键， 页面就会自动跳转到 VS Code 编辑环境。\n如果你更希望使用手机原生 App，我推荐 Obsidian。它有全平台的客户端，并且可以参考这篇文章设置 Git 集成。\n评论里还有很多推荐，选择一个合适的就行。\nShell Tmux Tmux 是一个终端复用器（terminal multiplexer），非常有用，属于常用的开发工具。\n简介 会话与进程\n命令行的典型使用方式是，打开一个终端窗口（terminal window，以下简称\u0026quot;窗口\u0026quot;），在里面输入命令。用户与计算机的这种临时的交互，称为一次\u0026quot;会话\u0026quot;（session） 。\n会话的一个重要特点是，窗口与其中启动的进程是连在一起的。打开窗口，会话开始；关闭窗口，会话结束，会话内部的进程也会随之终止，不管有没有运行完。\n一个典型的例子就是，SSH 登录远程计算机，打开一个远程窗口执行命令。这时，网络突然断线，再次登录的时候，是找不回上一次执行的命令的。因为上一次 SSH 会话已经终止了，里面的进程也随之消失了。\n为了解决这个问题，会话与窗口可以\u0026quot;解绑\u0026quot;：窗口关闭时，会话并不终止，而是继续运行，等到以后需要的时候，再让会话\u0026quot;绑定\u0026quot;其他窗口。\nTmux 的作用\nTmux 就是会话与窗口的\u0026quot;解绑\u0026quot;工具，将它们彻底分离。\n 它允许在单个窗口中，同时访问多个会话。这对于同时运行多个命令行程序很有用。 它可以让新窗口\u0026quot;接入\u0026quot;已经存在的会话。 它允许每个会话有多个连接窗口，因此可以多人实时共享会话。 它还支持窗口任意的垂直和水平拆分。  类似的终端复用器还有 GNU Screen。Tmux 与它功能相似，但是更易用，也更强大。\n基本用法 安装\nTmux 一般需要自己安装。\n$ sudo apt-get install tmux 启动与退出\n安装完成后，键入tmux命令，就进入了 Tmux 窗口。\n$ tmux Tmux 窗口，底部有一个状态栏。状态栏的左侧是窗口信息（编号和名称），右侧是系统信息。\n按下Ctrl+d或者显式输入exit命令，就可以退出 Tmux 窗口。\n$ exit 前缀键\nTmux 窗口有大量的快捷键。所有快捷键都要通过前缀键唤起。默认的前缀键是Ctrl+b，即先按下Ctrl+b，快捷键才会生效。\n举例来说，帮助命令的快捷键是Ctrl+b ?。它的用法是，在 Tmux 窗口中，先按下Ctrl+b，再按下?，就会显示帮助信息。\n然后，按下 ESC 键或q键，就可以退出帮助。\n会话管理 新建会话\n第一个启动的 Tmux 窗口，编号是0，第二个窗口的编号是1，以此类推。这些窗口对应的会话，就是 0 号会话、1 号会话。\n使用编号区分会话，不太直观，更好的方法是为会话起名。\n$ tmux new -s \u0026lt;session-name\u0026gt; 上面命令新建一个指定名称的会话。\n分离会话\n在 Tmux 窗口中，按下Ctrl+b d或者输入tmux detach命令，就会将当前会话与窗口分离。\n$ tmux detach 上面命令执行后，就会退出当前 Tmux 窗口，但是会话和里面的进程仍然在后台运行。\ntmux ls命令或Ctrl+b s可以查看当前所有的 Tmux 会话。\n$ tmux ls # or $ tmux list-session 接入会话\ntmux attach命令用于重新接入某个已存在的会话。\n# 使用会话编号 $ tmux attach -t 0 # 使用会话名称 $ tmux attach -t \u0026lt;session-name\u0026gt; 杀死会话\ntmux kill-session命令用于杀死某个会话。\n# 使用会话编号 $ tmux kill-session -t 0 # 使用会话名称 $ tmux kill-session -t \u0026lt;session-name\u0026gt; 切换会话\ntmux switch命令用于切换会话。\n# 使用会话编号 $ tmux switch -t 0 # 使用会话名称 $ tmux switch -t \u0026lt;session-name\u0026gt; 重命名会话\ntmux rename-session命令或Ctrl+b $用于重命名会话。\n$ tmux rename-session -t 0 \u0026lt;new-name\u0026gt; 上面命令将0号会话重命名。\n最简操作流程 综上所述，以下是 Tmux 的最简操作流程。\n 在服务器端新建会话tmux new -s my_session。 在 Tmux 窗口运行所需的程序。 按下快捷键Ctrl+b d将会话分离。 下次使用时，重新连接到会话tmux attach-session -t my_session。  窗格操作 Tmux 可以将窗口分成多个窗格（pane），每个窗格运行不同的命令。以下命令都是在 Tmux 窗口中执行。\n划分窗格\ntmux split-window命令用来划分窗格。\n# 划分上下两个窗格，或 Ctrl+b \u0026#34; $ tmux split-window # 划分左右两个窗格，或 Ctrl+b % $ tmux split-window -h 移动光标\ntmux select-pane命令或Ctrl+b \u0026lt;arrow key\u0026gt;用来移动光标位置。\n# 光标切换到上方窗格，或 Ctrl+b ; $ tmux select-pane -U # 光标切换到下方窗格，或 Ctrl+b o $ tmux select-pane -D # 光标切换到左边窗格 $ tmux select-pane -L # 光标切换到右边窗格 $ tmux select-pane -R  Ctrl+b x：关闭当前窗格。 Ctrl+b !：将当前窗格拆分为一个独立窗口。 Ctrl+b z：当前窗格全屏显示，再使用一次会变回原来大小。 Ctrl+b Ctrl+\u0026lt;arrow key\u0026gt;：按箭头方向调整窗格大小。 Ctrl+b q：显示窗格编号。  交换窗格位置\ntmux swap-pane命令用来交换窗格位置。\n# 当前窗格上移，或 Ctrl+b { $ tmux swap-pane -U # 当前窗格下移，或 Ctrl+b } $ tmux swap-pane -D  Ctrl+b Ctrl+o：所有窗格向前移动一个位置，第一个窗格变成最后一个窗格。 Ctrl+b Alt+o：所有窗格向后移动一个位置，最后一个窗格变成第一个窗格。  窗口管理 除了将一个窗口划分成多个窗格，Tmux 也允许新建多个窗口。\n新建窗口\ntmux new-window命令用来创建新窗口。\n$ tmux new-window # 新建一个指定名称的窗口 $ tmux new-window -n \u0026lt;window-name\u0026gt; Ctrl+b c：创建一个新窗口，状态栏会显示多个窗口的信息。\n切换窗口\ntmux select-window命令用来切换窗口。\n# 切换到指定编号的窗口 $ tmux select-window -t \u0026lt;window-number\u0026gt; # 切换到指定名称的窗口 $ tmux select-window -t \u0026lt;window-name\u0026gt;  Ctrl+b p：切换到上一个窗口（按照状态栏上的顺序）。 Ctrl+b n：切换到下一个窗口。 Ctrl+b \u0026lt;number\u0026gt;：切换到指定编号的窗口，其中的\u0026lt;number\u0026gt;是状态栏上的窗口编号。 Ctrl+b w：从列表中选择窗口。  重命名窗口\ntmux rename-window命令或Ctrl+b ,用于为当前窗口起名（或重命名）。\n$ tmux rename-window \u0026lt;new-name\u0026gt; 其他命令 下面是一些其他命令。\n# 列出所有快捷键，及其对应的 Tmux 命令 $ tmux list-keys # 列出所有 Tmux 命令及其参数 $ tmux list-commands # 列出当前所有 Tmux 会话的信息 $ tmux info # 重新加载当前的 Tmux 配置 $ tmux source-file ~/.tmux.conf Fish 命令行是程序员的必备技能。图形界面虽然好看，解决问题还是要靠命令行。\n命令行由 Shell 提供。各种命令通过 Shell，传递给操作系统的内核。学习命令行就是在学习 Shell。\nShell 有好几种，目前最常用是 Bash 和 zsh。但是，在我看来，它们都不如 Fish Shell 好用。\n五年前，我第一次尝试 Fish，感到很惊艳，一直用到现在。本文介绍 Fish 的主要特点，希望你也来尝试它。\n简介 Fish 是\u0026quot;the friendly interactive shell\u0026quot;的简称，最大特点就是方便易用。很多其他 Shell 需要配置才有的功能，Fish 默认提供，不需要任何配置。\n如果你想拥有一个方便好用的 Shell，又不想学习一大堆语法，或者花费很多时间配置，那么你一定要尝试一下 Fish。\n安装 Ubuntu 的安装方法。\n$ sudo apt install fish 其他系统的安装请参考官方网站。\n启动与帮助 安装完成后，就可以启动 Fish。\n$ fish 由于 Fish 的语法与 Bash 有很大差异，Bash 脚本一般不兼容。因此，我建议不要将 Fish 设为默认 Shell，而是每次手动启动它。\n使用过程中，如果需要帮助，可以输入help命令。浏览器就会自动打开，显示在线文档。\n$ help 彩色显示 进入 Fish 以后，你注意到的第一件事，可能就是它默认彩色显示。\n# 无效命令为红色 $ mkd # 有效命令为蓝色 $ mkdir 有效路径会有下划线。\n$ cat ~/somefi 上面代码表示，存在以~/somefi开头的路径。如果没有下划线，你就知道这个路径不存在。\n自动建议 Fish 会自动在光标后面给出建议，表示可能的选项，颜色为灰色。\n# 命令建议 $ /bin/hostname # 参数建议 $ grep --ignore-case # 路径建议 $ ls node_modules 如果采纳建议，可以按下→或Control + F。如果只采纳一部分，可以按下Alt + →。\n自动补全 输入命令时，Fish 会自动显示匹配的上一条历史记录。\n$ git commit -m \u0026#34;feat: first commit\u0026#34; 如果没有匹配的历史记录，Fish 会猜测可能的结果，自动补全各种输入。比如，输入pyt再按下Tab，就会自动补全为python命令。\n如果有多个可能的结果，Fish 会把它们都列出，还带有简要介绍。\n$ vi[按下 Tab 键] vi (Executable link, 2.7MB) view (Vi IMproved, 一个程序员的文本编辑器) viewer.py (Executable, 967B) viewres (Graphical class browser for Xt) ...and 12 more rows 这时，再按一次tab，就可以在这些命令之中选择。\n除了补全命令，Fish 还可以补全参数。比如，ls命令的-l参数后面按下Tab键，就会显示可以连用的其他参数。\n$ ls -l[按下 Tab 键] -l1 (List one file per line) -lA (Show hidden except . and ..) -la (Show hidden) -lB (Ignore files ending with ~) ...and 16 more rows``` Fish 还可以自动补全 Git 分支。\n$ git checkout master 易懂的语法 Fish 的语法非常自然，一眼就能看懂。\nif语句：\nif grep fish /etc/shells echo Found fish else if grep bash /etc/shells echo Found bash else echo Got nothing end switch语句：\nswitch (uname) case Linux echo Hi Tux! case Darwin echo Hi Hexley! case FreeBSD NetBSD DragonFly echo Hi Beastie! case \u0026#39;*\u0026#39; echo Hi, stranger! end while循环：\nwhile true echo \u0026#34;Loop forever\u0026#34; end for循环：\nfor file in *.txt cp $file $file.bak end 函数 Fish 的函数用来封装命令，或者为现有的命令起别名。\nfunction ll ls -lhG $argv end 上面代码定义了一个ll函数。命令行执行这个函数以后，就可以用ll命令替代ls -lhG。其中，变量$argv表示函数的参数。\n下面是另一个例子。\nfunction ls command ls -hG $argv end 上面的代码重新定义ls命令。注意，函数体内的ls之前，要加上command，否则会因为无限循环而报错。\n提示符 fish_prompt函数用于定义命令行提示符（prompt）。\nfunction fish_prompt set_color purple date \u0026#34;+%m/%d/%y\u0026#34; set_color FF0 echo (pwd) \u0026#39;\u0026gt;\u0026#39; set_color normal end 执行上面的函数以后，你的命令行提示符就会变成下面这样。\n02/06/13 /home/tutorial \u0026gt; 配置 Fish 的配置文件是~/.config/fish/config.fish，每次 Fish 启动，就会自动加载这个文件。\n我们可以在这个文件里面写入各种自定义函数，它们会被自动加载。比如，上面的fish_prompt函数就可以写在这个文件里面，这样每次启动 Fish，就会出现自定义的提示符。\nFish 还提供 Web 界面配置该文件。\n$ fish_config 输入上面的命令以后，浏览器就会自动打开本机的 8000 端口，用户可以在网页上对 Fish 进行配置，比如选择提示符和配色主题。\nZsh Oh My Zsh $ sh -c \u0026#34;$(wget https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)\u0026#34; oh-my-zsh应该对通配符作了限制，需要用跳脱字符\nsudo apt remove fcitx\\* Zsh theme：Powerlevel10kUSER\n尽量用开源代替闭源（CopyLeft alternative to CopyRight）。\n这部分程序都是需要手动安装的——即不是系统自带的。\nProxy Clash for linux 下载 clash\n$ gzip -d clash-linux-amd64-v1.6.5.gz $ mkdir ~/.clash \u0026amp;\u0026amp; mv clash-linux-amd64-v1.6.5 ~/.clash/clash 下载配置\n$ wget -O config.yaml [订阅链接] 运行 clash\n$ chmod 770 clash./clash -d . 使用 clash dashboard 选择节点\n设置系统代理：\n  GUI：打开系统设置，点击网络代理右边的 ⚙ 按钮，选择手动\n HTTP 和 HTTPS 代理为 127.0.0.1:7890 Socks 主机为 127.0.0.1:7891    CLI：change system proxy settings from the command line\n# To modify a DConf setting: $ gsettings set \u0026lt;schema\u0026gt; \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; # To read a DConf setting: $ gsettings get \u0026lt;schema\u0026gt; \u0026lt;key\u0026gt;   相关软件：\n Qv2ray：很好的工具，但已停止维护。 v2ray-core：可以直接用命令行 v2rayA glider proxychains-ng proxychains Lantern Privoxy openvpn Shadowsocks Tor  实例一 $ vi ~/.clash/run-clash.sh #!/bin/bash CLASH_HOME=/home/vane/.clash subscription=\u0026#34;订阅连接\u0026#34; # 设置系统代理 function setting { gsettings set org.gnome.system.proxy.http host \u0026#39;127.0.0.1\u0026#39; gsettings set org.gnome.system.proxy.http port \u0026#39;7890\u0026#39; gsettings set org.gnome.system.proxy.https host \u0026#39;127.0.0.1\u0026#39; gsettings set org.gnome.system.proxy.https port \u0026#39;7890\u0026#39; gsettings set org.gnome.system.proxy.socks host \u0026#39;127.0.0.1\u0026#39; gsettings set org.gnome.system.proxy.socks port \u0026#39;7891\u0026#39; } # 更新订阅 function update { wget -O $CLASH_HOME/config.yaml $subscription } # 运行 clash function run { # 打开系统代理（之前已经设置了） gsettings set org.gnome.system.proxy mode \u0026#39;manual\u0026#39; $CLASH_HOME/clash-linux-amd64 -d $CLASH_HOME/ } # 停止运行 clash function stop { # 关闭系统代理  gsettings set org.gnome.system.proxy mode \u0026#39;none\u0026#39; } if [ \u0026#34;$1\u0026#34; = \u0026#34;-u\u0026#34; ]; then update elif [ \u0026#34;$1\u0026#34; = \u0026#34;-r\u0026#34; ]; then run elif [ \u0026#34;$1\u0026#34; = \u0026#34;-s\u0026#34; ]; then setting else if [ \u0026#34;$1\u0026#34; ]; then $CLASH_HOME/clash $1 else echo Plese run clash -r fi fi trap stop EXIT How to change system proxy settings from the command line on Ubuntu desktop\n$ chmod 700 run-clash.sh 实例二 $ vi ~/.clash/rc.sh #!/bin/bash /usr/bin/wget -O home/kurome/.clash/config.yaml \u0026#34;订阅连接\u0026#34; /home/kurome/.clash/clash-linux-amd64 -d /home/kurome/.clash/ clash as a daemon：\n$ sudo vi /usr/lib/systemd/system/clash.service [Unit] Description=Clash daemon, A rule-based proxy in Go. After=network.target [Service] Type=simple Restart=always RestartSec=10 ExecStart=/bin/bash /home/kurome/.clash/rc.sh [Install] WantedBy=multi-user.target 运行\n$ systemctl enable clash.service $ systemctl start clash.service $ systemctl status clash.service 如果不想代理了，可以直接在 clash dashboard 的 Proxy （如果有的话）或者 Settting 里选择 DIRECT，而不是关闭 clash.service。根据设置的规则，有的流量会走代理，有的流量直接走。\nTUN “系统代理”一般只是桌面环境下的约定，需要 app 遵循约定才行。\n因此某些软件\u0026amp;命令行软件不支持系统代理，需要手动指定环境变量，或者用透明代理。\nclash for Windows 的 Linux 版更省事啦，用 tun 模式还是对全部 app 生效——对于不遵循系统代理的软件，TUN 模式可以接管其流量并交由 CFW 处理。启动 TUN 模式需要进行如下操作：\n  安装 nftables 和 iproute2 并重启\n$ sudo apt install nftables iproute2 $ sudo reboot   点击General中Service Mode右边Manage，在打开窗口中安装服务模式，安装完成应用会自动重启（某些系统需要手动重启 APP），Service Mode 右边地球图标变为绿色即安装成功\n  点击General中TUN Mode右边开关启动 TUN 模式\n  无法安装参考：\n$ curl https://gist.githubusercontent.com/Fndroid/2119fcb5ccb5a543a8f6a609418ae43f/raw/592eba4f480c7ccb4f29c9b8e80d24bfd5dda8cf/linux.sh \u0026gt; cfw-tun.sh \u0026amp;\u0026amp; chmod +x cfw-tun.sh \u0026amp;\u0026amp; sudo ./cfw-tun.sh install \u0026lt;cfw安装目录\u0026gt; 如要卸载则将 install 改为 uninstall，最后一部分位 CFW 安装目录\n  WireGuard 官方文档：https://github.com/pirate/wireguard-docs\nWireGuard 是由 Jason Donenfeld 等人用 C 语言编写的一个开源 VPN 协议，被视为下一代 VPN 协议，旨在解决许多困扰 IPSec/IKEv2、OpenVPN 或 L2TP 等其他 VPN 协议的问题。它与 Tinc 和 MeshBird 等现代 VPN 产品有一些相似之处，即加密技术先进、配置简单。从 2020 年 1 月开始，它已经并入了 Linux 内核的 5.6 版本，这意味着大多数 Linux 发行版的用户将拥有一个开箱即用的 WireGuard。\n术语 Peer/Node/Device\n连接到 VPN 并为自己注册一个 VPN 子网地址（如 192.0.2.3）的主机。还可以通过使用逗号分隔的 CIDR 指定子网范围，为其自身地址以外的 IP 地址选择路由。\n中继服务器（Bounce Server）\n一个公网可达的对等节点，可以将流量中继到 NAT 后面的其他对等节点。Bounce Server 并不是特殊的节点，它和其他对等节点一样，唯一的区别是它有公网 IP，并且开启了内核级别的 IP 转发，可以将 VPN 的流量转发到其他客户端。\n子网（Subnet）\n一组私有 IP，例如 192.0.2.1-255 或 192.168.1.1/24，一般在 NAT 后面，例如办公室局域网或家庭网络。\nCIDR 表示法\nCIDR中文全称是无分类域间路由选择，英文全称是Classless Inter-Domain Routing，在平常，大家多称之为无分类编址，它也是构成超网的一种技术实现。CIDR在一定程度上解决了路由表项目过多过大的问题。CIDR之所以称为无分类编址，就是因为CIDR完全放弃了之前的分类IP地址表示法，它真正消除了传统的A类、B类、C类地址以及划分子网的概念，它使用如下的IP地址表示法：\nIP地址 ::= {\u0026lt;网络前缀\u0026gt;， \u0026lt;主机号\u0026gt;} / 网络前缀所占位数 CIDR仅将IP地址划分为网络前缀和主机号两个部分，可以说又回到了二级IP地址的表示，不过大家要注意，最后面用“/”斜线分隔，在其后写上了网络前缀所占的位数，这样就不需要告知路由器地址掩码，仅需要通过网络前缀所占的位数就可以得到地址掩码，为了统一，CIDR中的地址掩码依然称为子网掩码。\nNAT\n子网的私有 IP 地址由路由器提供，通过公网无法直接访问私有子网设备，需要通过 NAT 做网络地址转换。路由器会跟踪发出的连接，并将响应转发到正确的内部 IP。\n公开端点（Public Endpoint）\n节点的公网 IP 地址:端口，例如 123.124.125.126:1234，或者直接使用域名 some.domain.tld:1234。如果对等节点不在同一子网中，那么节点的公开端点必须使用公网 IP 地址。\n私钥（Private key）\n单个节点的 WireGuard 私钥，生成方法是：wg genkey \u0026gt; example.key。\n公钥（Public key）\n单个节点的 WireGuard 公钥，生成方式为：wg pubkey \u0026lt; example.key \u0026gt; example.key.pub。\nDNS\n域名服务器，用于将域名解析为 VPN 客户端的 IP，不让 DNS请求泄漏到 VPN 之外。\n工作原理 中继服务器工作原理\n中继服务器（Bounce Server）和普通的对等节点一样，它能够在 NAT 后面的 VPN 客户端之间充当中继服务器，可以将收到的任何 VPN 子网流量转发到正确的对等节点。事实上 WireGuard 并不关心流量是如何转发的，这个由系统内核和 iptables 规则处理。\n如果所有的对等节点都是公网可达的，则不需要考虑中继服务器，只有当有对等节点位于 NAT 后面时才需要考虑。\n*在 WireGuard 里，客户端和服务端基本是平等的，差别只是谁主动连接谁而已。*双方都会监听一个 UDP 端口，谁主动连接，谁就是客户端。主动连接的客户端需要指定对端的公网地址和端口，被动连接的服务端不需要指定其他对等节点的地址和端口。如果客户端和服务端都位于 NAT 后面，需要加一个中继服务器，客户端和服务端都指定中继服务器作为对等节点，它们的通信流量会先进入中继服务器，然后再转发到对端。\nWireGuard 是支持漫游的，也就是说，双方不管谁的地址变动了，WireGuard 在看到对方从新地址说话的时候，就会记住它的新地址（跟 mosh 一样，不过是双向的）。所以双方要是一直保持在线，并且通信足够频繁的话（比如配置 persistent-keepalive），两边的 IP 都不固定也不影响的。\n流量路由\n利用 WireGuard 可以组建非常复杂的网络拓扑，这里主要介绍几个典型的拓扑：\n 端到端直接连接  这是最简单的拓扑，所有的节点要么在同一个局域网，要么直接通过公网访问，这样 WireGuard 可以直接连接到对端，不需要中继跳转。\n一端位于 NAT 后面，另一端直接通过公网暴露  这种情况下，最简单的方案是：通过公网暴露的一端作为服务端，另一端指定服务端的公网地址和端口，然后通过 persistent-keepalive 选项维持长连接，让 NAT 记得对应的映射关系。\n两端都位于 NAT 后面，通过中继服务器连接  大多数情况下，当通信双方都在 NAT 后面的时候，NAT 会做源端口随机化处理，直接连接可能比较困难。可以加一个中继服务器，通信双方都将中继服务器作为对端，然后维持长连接，流量就会通过中继服务器进行转发。\n两端都位于 NAT 后面，通过 UDP NAT 打洞  上面也提到了，当通信双方都在 NAT 后面的时候，直接连接不太现实，因为大多数 NAT 路由器对源端口的随机化相当严格，不可能提前为双方协调一个固定开放的端口。必须使用一个信令服务器（STUN），它会在中间沟通分配给对方哪些随机源端口。通信双方都会和公共信令服务器进行初始连接，然后它记录下随机的源端口，并将其返回给客户端。这其实就是现代 P2P 网络中 WebRTC 的工作原理。有时候，即使有了信令服务器和两端已知的源端口，也无法直接连接，因为 NAT 路由器严格规定只接受来自原始目的地址（信令服务器）的流量，会要求新开一个随机源端口来接受来自其他 IP 的流量（比如其他客户端试图使用原来的通信源端口）。运营商级别的 NAT 就是这么干的，比如蜂窝网络和一些企业网络，它们专门用这种方法来防止打洞连接。更多细节请参考下一部分的 NAT 到 NAT 连接实践的章节。\n如果某一端同时连接了多个对端，当它想访问某个 IP 时，如果有具体的路由可用，则优先使用具体的路由，否则就会将流量转发到中继服务器，然后中继服务器再根据系统路由表进行转发。你可以通过测量 ping 的时间来计算每一跳的长度，并通过检查对端的输出（wg show wg0）来找到 WireGuard 对一个给定地址的路由方式。\n报文格式\nWireGuard 使用加密的 UDP 报文来封装所有的数据，UDP 不保证数据包一定能送达，也不保证按顺序到达，但隧道内的 TCP 连接可以保证数据有效交付。WireGuard 的报文格式如下图所示：\n性能\nWireGuard 声称其性能比大多数 VPN 协议更好，但这个事情有很多争议，比如某些加密方式支持硬件层面的加速。\nWireGuard 直接在内核层面处理路由，直接使用系统内核的加密模块来加密数据，和 Linux 原本内置的密码子系统共存，原有的子系统能通过 API 使用 WireGuard 的 Zinc 密码库。WireGuard 使用 UDP 协议传输数据，在不使用的情况下默认不会传输任何 UDP 数据包，所以比常规 VPN 省电很多，可以像 55 一样一直挂着使用，速度相比其他 VPN 也是压倒性优势。\n安全模型\nWireGuard 使用以下加密技术来保障数据的安全：\n 使用 ChaCha20 进行对称加密，使用 Poly1305 进行数据验证。 利用 Curve25519 进行密钥交换。 使用 BLAKE2 作为哈希函数。 使用 HKDF 进行解密。  WireGuard 的加密技术本质上是 Trevor Perrin 的 Noise 框架的实例化，它简单高效，其他的 VPN 都是通过一系列协商、握手和复杂的状态机来保障安全性。WireGuard 就相当于 VPN 协议中的 qmail，代码量比其他 VPN 协议少了好几个数量级。\n密钥管理\nWireGuard 通过为每个对等节点提供简单的公钥和私钥来实现双向认证，每个对等节点在设置阶段生成密钥，且只在对等节点之间共享密钥。每个节点除了公钥和私钥，不再需要其他证书或预共享密钥。\n在更大规模的部署中，可以使用 Ansible 或 Kubernetes Secrets 等单独的服务来处理密钥的生成、分发和销毁。\n如果你不想在 wg0.conf 配置文件中直接硬编码，可以从文件或命令中读取密钥，这使得通过第三方服务管理密钥变得更加容易：\n[Interface] ... PostUp = wg set %i private-key /etc/wireguard/wg0.key \u0026lt;(cat /some/path/%i/privkey) 从技术上讲，多个服务端之间可以共享相同的私钥，只要客户端不使用相同的密钥同时连接到两个服务器。但有时客户端会需要同时连接多台服务器，例如，你可以使用 DNS 轮询来均衡两台服务器之间的连接，这两台服务器配置相同。大多数情况下，每个对等节点都应该使用独立的的公钥和私钥，这样每个对等节点都不能读取到对方的流量，保障了安全性。\n搭建使用与配置详解 快速开始 安装\n# Ubuntu ≥ 18.04 $ apt install wireguard 在中继服务器上开启 IP 地址转发：\n$ echo \u0026#34;net.ipv4.ip_forward = 1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf $ echo \u0026#34;net.ipv4.conf.all.proxy_arp = 1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf $ sysctl -p /etc/sysctl.conf 添加 iptables 规则，允许本机的 NAT 转换：\n$ iptables -A INPUT -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT $ iptables -A FORWARD -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT $ iptables -A FORWARD -i wg0 -o wg0 -m conntrack --ctstate NEW -j ACCEPT $ iptables -t nat -A POSTROUTING -s 192.0.2.0/24 -o eth0 -j MASQUERADE 需要把 eth0 改成你实际使用的网卡接口名称。\n配置文件\n配置文件可以放在任何路径下，但必须通过绝对路径引用。默认路径是 /etc/wireguard/wg0.conf。\n生成密钥\n#生成私钥 $ wg genkey \u0026gt; example.key # 生成公钥 $ wg pubkey \u0026lt; example.key \u0026gt; example.key.pub 启动与停止\n$ wg-quick up /full/path/to/wg0.conf $ wg-quick down /full/path/to/wg0.conf # 启动/停止 VPN 网络接口 $ ip link set wg0 up $ ip link set wg0 down # 注册/注销 VPN 网络接口 $ ip link add dev wg0 type wireguard $ ip link delete dev wg0 # 注册/注销 本地 VPN 地址 $ ip address add dev wg0 192.0.2.3/32 $ ip address delete dev wg0 192.0.2.3/32 # 添加/删除 VPN 路由 $ ip route add 192.0.2.3/32 dev wg0 $ ip route delete 192.0.2.3/32 dev wg0 查看信息\n# 查看系统 VPN 接口信息 $ ip link show wg0 # 查看 VPN 接口详细信息 $ wg show all $ wg show wg0 # 查看 VPN 接口地址 $ ip address show wg0 路由\n# 查看系统路由表 $ ip route show table main $ ip route show table local # 获取到特定 IP 的路由 $ ip route get 192.0.2.3 一键安装\n一键安装请参考这个项目：WireGuard installer\n配置详解 WireGuard 使用 INI 语法作为其配置文件格式。配置文件可以放在任何路径下，但必须通过绝对路径引用。默认路径是 /etc/wireguard/wg0.conf。\n配置文件的命名形式必须为 ${WireGuard 接口的名称}.conf。通常情况下 WireGuard 接口名称以 wg 为前缀，并从 0 开始编号，但你也可以使用其他名称，只要符合正则表达式 ^[a-zA-Z0-9_=+.-]{1,15}$ 就行。\n你可以选择使用 wg 命令来手动配置 VPN，但一般建议使用 wg-quick，它提供了更强大和用户友好的配置体验，可以通过配置文件来管理配置。\n下面是一个配置文件示例：\n[Interface] # Name = node1.example.tld Address = 192.0.2.3/32 ListenPort = 51820 PrivateKey = localPrivateKeyAbcAbcAbc= DNS = 1.1.1.1,8.8.8.8 Table = 12345 MTU = 1500 PreUp = /bin/example arg1 arg2 %i PostUp = /bin/example arg1 arg2 %i PreDown = /bin/example arg1 arg2 %i PostDown = /bin/example arg1 arg2 %i [Peer] # Name = node2-node.example.tld AllowedIPs = 192.0.2.1/24 Endpoint = node1.example.tld:51820 PublicKey = remotePublicKeyAbcAbcAbc= PersistentKeepalive = 25 [Interface]\n这一节定义本地 VPN 配置。例如：\n本地节点是客户端，只路由自身的流量，只暴露一个 IP。\n[Interface] # Name = phone.example-vpn.dev Address = 192.0.2.5/32 PrivateKey = \u0026lt;private key for phone.example-vpn.dev\u0026gt; 本地节点是中继服务器，它可以将流量转发到其他对等节点（peer），并公开整个 VPN 子网的路由。\n[Interface] # Name = public-server1.example-vpn.tld Address = 192.0.2.1/24 ListenPort = 51820 PrivateKey = \u0026lt;private key for public-server1.example-vpn.tld\u0026gt; DNS = 1.1.1.1  Name  这是 INI 语法中的标准注释，用于展示该配置部分属于哪个节点。这部分配置会被 WireGuard 完全忽略，对 VPN 的行为没有任何影响。\nAddress  定义本地节点应该对哪个地址范围进行路由。如果是常规的客户端，则将其设置为节点本身的单个 IP（使用 CIDR 指定，例如 192.0.2.3/32）；如果是中继服务器，则将其设置为可路由的子网范围。\n例如：\n 常规客户端，只路由自身的流量：Address = 192.0.2.3/32 中继服务器，可以将流量转发到其他对等节点（peer）：Address = 192.0.2.1/24 也可以指定多个子网或 IPv6 子网：Address = 192.0.2.1/24,2001:DB8::/64  ListenPort  当本地节点是中继服务器时，需要通过该参数指定端口来监听传入 VPN 连接，默认端口号是 51820。常规客户端不需要此选项。\nPrivateKey  本地节点的私钥，所有节点（包括中继服务器）都必须设置。不可与其他服务器共用。\n私钥可通过命令 wg genkey \u0026gt; example.key 来生成。\nDNS  通过 DHCP 向客户端宣告 DNS 服务器。客户端将会使用这里指定的 DNS 服务器来处理 VPN 子网中的 DNS 请求，但也可以在系统中覆盖此选项。例如：\n 如果不配置则使用系统默认 DNS 可以指定单个 DNS：DNS = 1.1.1.1 也可以指定多个 DNS：DNS = 1.1.1.1,8.8.8.8  Table  定义 VPN 子网使用的路由表，默认不需要设置。该参数有两个特殊的值需要注意：\n Table = off : 禁止创建路由 Table = auto（默认值） : 将路由添加到系统默认的 table 中，并启用对默认路由的特殊处理。  例如：Table = 1234\nMTU  定义连接到对等节点（peer）的 MTU（Maximum Transmission Unit，最大传输单元），默认不需要设置，一般由系统自动确定。\nPreUp  启动 VPN 接口之前运行的命令。这个选项可以指定多次，按顺序执行。\n例如添加路由：PreUp = ip rule add ipproto tcp dport 22 table 1234\nPostUp  启动 VPN 接口之后运行的命令。这个选项可以指定多次，按顺序执行。\n例如：\n  从文件或某个命令的输出中读取配置值：\nPostUp = wg set %i private-key /etc/wireguard/wg0.key \u0026lt;(some command here)   添加一行日志到文件中：\nPostUp = echo \u0026#34;$(date +%s) WireGuard Started\u0026#34; \u0026gt;\u0026gt; /var/log/wireguard.log   调用 WebHook：\nPostUp = curl https://events.example.dev/wireguard/started/?key=abcdefg   添加路由：\nPostUp = ip rule add ipproto tcp dport 22 table 1234   添加 iptables 规则，启用数据包转发：\nPostUp = iptables -A FORWARD -i %i -j ACCEPT; iptables -A FORWARD -o %i -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE   强制 WireGuard 重新解析对端域名的 IP 地址：\nPostUp = resolvectl domain %i \u0026#34;~.\u0026#34;; resolvectl dns %i 192.0.2.1; resolvectl dnssec %i yes   PreDown  停止 VPN 接口之前运行的命令。这个选项可以指定多次，按顺序执行。\n例如：\n  添加一行日志到文件中：\nPreDown = echo \u0026#34;$(date +%s) WireGuard Going Down\u0026#34; \u0026gt;\u0026gt; /var/log/wireguard.log   调用 WebHook：\nPreDown = curl https://events.example.dev/wireguard/stopping/?key=abcdefg   PostDown  停止 VPN 接口之后运行的命令。这个选项可以指定多次，按顺序执行。\n例如：\n  添加一行日志到文件中：\nPostDown = echo \u0026#34;$(date +%s) WireGuard Going Down\u0026#34; \u0026gt;\u0026gt; /var/log/wireguard.log   调用 WebHook：\nPostDown = curl https://events.example.dev/wireguard/stopping/?key=abcdefg   删除 iptables 规则，关闭数据包转发：\nPostDown = iptables -D FORWARD -i %i -j ACCEPT; iptables -D FORWARD -o %i -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE   [Peer]\n定义能够为一个或多个地址路由流量的对等节点（peer）的 VPN 设置。对等节点（peer）可以是将流量转发到其他对等节点（peer）的中继服务器，也可以是通过公网或内网直连的客户端。\n中继服务器必须将所有的客户端定义为对等节点（peer），除了中继服务器之外，其他客户端都不能将位于 NAT 后面的节点定义为对等节点（peer），因为路由不可达。对于那些只为自己路由流量的客户端，只需将中继服务器作为对等节点（peer），以及其他需要直接访问的节点。\n举个例子，在下面的配置中，public-server1 作为中继服务器，其他的客户端有的是直连，有的位于 NAT 后面：\n  public-server1（中继服务器）\n[peer] : public-server2, home-server, laptop, phone\n  public-server2（直连客户端）\n[peer] : public-server1\n  home-server（客户端位于 NAT 后面）\n[peer] : public-server1, public-server2\n  laptop（客户端位于 NAT 后面）\n[peer] : public-server1, public-server2\n  phone（客户端位于 NAT 后面）\n[peer] : public-server1, public-server2\n  配置示例：\n  对等节点（peer）是路由可达的客户端，只为自己路由流量\n[Peer] # Name = public-server2.example-vpn.dev Endpoint = public-server2.example-vpn.dev:51820 PublicKey = \u0026lt;public key for public-server2.example-vpn.dev\u0026gt; AllowedIPs = 192.0.2.2/32   对等节点（peer）是位于 NAT 后面的客户端，只为自己路由流量\n[Peer] # Name = home-server.example-vpn.dev Endpoint = home-server.example-vpn.dev:51820 PublicKey = \u0026lt;public key for home-server.example-vpn.dev\u0026gt; AllowedIPs = 192.0.2.3/32   对等节点（peer）是中继服务器，用来将流量转发到其他对等节点（peer）\n[Peer] # Name = public-server1.example-vpn.tld Endpoint = public-server1.example-vpn.tld:51820 PublicKey = \u0026lt;public key for public-server1.example-vpn.tld\u0026gt; # 路由整个 VPN 子网的流量 AllowedIPs = 192.0.2.1/24 PersistentKeepalive = 25    Endpoint  指定远端对等节点（peer）的公网地址。如果对等节点（peer）位于 NAT 后面或者没有稳定的公网访问地址，就忽略这个字段。通常只需要指定中继服务器的 Endpoint，当然有稳定公网 IP 的节点也可以指定。例如：\n  通过 IP 指定：\nEndpoint = 123.124.125.126:51820   通过域名指定：\nEndpoint = public-server1.example-vpn.tld:51820   AllowedIPs  允许该对等节点（peer）发送过来的 VPN 流量中的源地址范围。同时这个字段也会作为本机路由表中 wg0 绑定的 IP 地址范围。如果对等节点（peer）是常规的客户端，则将其设置为节点本身的单个 IP；如果对等节点（peer）是中继服务器，则将其设置为可路由的子网范围。可以使用 , 来指定多个 IP 或子网范围。该字段也可以指定多次。\n当决定如何对一个数据包进行路由时，系统首先会选择最具体的路由，如果不匹配再选择更宽泛的路由。例如，对于一个发往 192.0.2.3 的数据包，系统首先会寻找地址为 192.0.2.3/32 的对等节点（peer），如果没有再寻找地址为 192.0.2.1/24 的对等节点（peer），以此类推。\n例如：\n  对等节点（peer）是常规客户端，只路由自身的流量：\nAllowedIPs = 192.0.2.3/32   对等节点（peer）是中继服务器，可以将流量转发到其他对等节点（peer）：\nAllowedIPs = 192.0.2.1/24   对等节点（peer）是中继服务器，可以转发所有的流量，包括外网流量和 VPN 流量，可以用来干嘛你懂得：\nAllowedIPs = 0.0.0.0/0,::/0   对等节点（peer）是中继服务器，可以路由其自身和其他对等节点（peer）的流量：\nAllowedIPs = 192.0.2.3/32,192.0.2.4/32   对等节点（peer）是中继服务器，可以路由其自身的流量和它所在的内网的流量：\nAllowedIPs = 192.0.2.3/32,192.168.1.1/24   PublicKey  对等节点（peer）的公钥，所有节点（包括中继服务器）都必须设置。可与其他对等节点（peer）共用同一个公钥。\n公钥可通过命令 wg pubkey \u0026lt; example.key \u0026gt; example.key.pub 来生成，其中 example.key 是上面生成的私钥。\n例如：PublicKey = somePublicKeyAbcdAbcdAbcdAbcd=\nPersistentKeepalive  如果连接是从一个位于 NAT 后面的对等节点（peer）到一个公网可达的对等节点（peer），那么 NAT 后面的对等节点（peer）必须定期发送一个出站 ping 包来检查连通性，如果 IP 有变化，就会自动更新Endpoint。\n例如：\n 本地节点与对等节点（peer）可直连：该字段不需要指定，因为不需要连接检查。 对等节点（peer）位于 NAT 后面：该字段不需要指定，因为维持连接是客户端（连接的发起方）的责任。 本地节点位于 NAT 后面，对等节点（peer）公网可达：需要指定该字段 PersistentKeepalive = 25，表示每隔 25 秒发送一次 ping 来检查连接。  GUI Utilities Gnome GNOME 系统设置面板（gnome-control-center）和 GNOME 应用使用 dconf 配置系统存储设置。您可以使用 gsettings 或 dconf 命令行工具直接访问 dconf 数据库。这也可以让你修改用户界面不公开的设置。\nGNOME 桌面拥有强大的搜索功能，按 Super 键并搜索一些东西，可以进入“Settings-Search”中来设置可以搜索的内容和顺序。\nDo Not Disturb 使通知只在消息栏中，不会在桌面上弹出。\nGnome 3 自动切换的壁纸会有一个有时钟小图标。\n浏览 GNOME Shell cheat sheet 中解释了如何高效地使用 GNOME shell，它展示了 GNOME shell 的特色和快捷键，包括切换任务，使用键盘，窗口控制，面板，概览模式等等。以下是部分常用的快捷键：\n Super + m：显示消息托盘 Super + a：显示应用程序菜单 Alt- + Tab：切换当前使用的应用 Alt- + ` (美式键盘 Tab 上面的按键)：切换前台应用程序的窗口 Alt + F2，然后输入 r 或 restart：在图形界面出问题时重启界面（仅用于 X/传统 模式，不适用于 Wayland 模式）。也可通过此运行后台应用，如 cfw。  遗留名称 注意： 一些 GNOME 程序在文档和对话框中的名称已经更改，但执行文件名称却没有。下面表格列出了一些这样的应用程序。\n提示： 在搜索栏中搜索应用的遗留名称将成功找到对应的应用，例如搜索 nautilus 将返还 文件。\n   当前 遗留     文件 Nautilus   Web Epiphany   视频 Totem   主菜单 Alacarte   文档查看器 Evince   磁盘使用情况分析器 Baobab   图像查看器 EoG (Eye of GNOME)   密码和密钥 Seahorse    修改文件默认关联的应用程序  mime类型文件存在于以下的两个路径：  /usr/share/mime ~/.local/share/mime    /usr/share/mime/text/makrdown.xml  应用程序的desktop文件，存在于以下的两个路径：  /usr/share/applications ~/.local/share/applications    [Desktop Entry] # 应用名称，即开始菜单中的名称 Type=ApplicationName=name # 应用执行文件位置 Exec=appPath # 应用图标位置 Icon=default48.png # 是否显示终端 Terminal=false # 所属分类 StartupNotify=trueCategories=Office # MIME 类型 MimeType=text/x-markdown  应用程序默认关联文件，存在于以下的两个路径：  /usr/share/applications/mimeapps.list ~/.local/share/applications/mimeapps.list    Gedit 编码 直接打开gedit（非通过文件打开），点击左上角 Open，点击左下角 Automatically Detected，下拉选择 Add or Remove\u0026hellip;，将简体中文编码都选上。\n或者：\n$ gsettings list-keys org.gnome.gedit.preferences.encodings candidate-encodings $ gsettings set org.gnome.gedit.preferences.encodings candidate-encodings \u0026#34;[\u0026#39;UTF-8\u0026#39;, \u0026#39;ISO-8859-15\u0026#39;, \u0026#39;UTF-16\u0026#39;, \u0026#39;GBK\u0026#39;, \u0026#39;GB18030\u0026#39;, \u0026#39;GB2312\u0026#39;]\u0026#34; NVIDIA Optimus NVIDIA Optimus 是一项允许英特尔（Intel）集成图形处理器（GPU）和英伟达（NVIDIA）独立图形处理器置入并通过一台笔记本电脑访问的技术。\n桌面卡死 总的来说，就是杀死相关进程，或者避免使用造成卡死相关软件。\n  选择其他 tty：\n$ pkill Xorg pkill 用于杀死一个进程，与 kill 不同的是它会杀死指定名字的所有进程。kill 命令杀死指定进程 PID，需要配合 ps 使用。\n  安全重启：同时按住 Ctrl 和 Alt 键，按住不要放，按一下 SysRq 键（有的键盘是PrtSc），按一下 R 键，按一下 E 键，依次按下 I , S , U , B 键。\n  解决 Ubuntu 经常卡死：ubuntu 的卡死可能与显卡驱动不兼容有关。用 nvidia 代替 nouveau显卡驱动。其中 nvidia-driver-470-server 是 server 版，最好用 nvidia-driver-470\n  Ubuntu 20.04 Screen Tearing after install nvidia driver, it works for me\n$ sudo gedit /etc/modprobe.d/nvidia-drm-nomodeset.conf options nvidia-drm modeset=1 $ sudo update-initramfs -u $ sudo reboot 要检查重新启动后以前的更改是否有效，请运行命令：\n$ sudo cat /sys/module/nvidia_drm/parameters/modeset Y Permanently Set NVIDIA PowerMizer Settings $ nvidia-settings -q GpuPowerMizerMode Attribute \u0026#39;GPUPowerMizerMode\u0026#39; (rastating-PC:1[gpu:0]): 0. Valid values for \u0026#39;GPUPowerMizerMode\u0026#39; are: 0, 1 and 2. \u0026#39;GPUPowerMizerMode\u0026#39; can use the following target types: GPU. $ nvidia-settings -a \u0026#34;[gpu:0]/GpuPowerMizerMode=1\u0026#34; Attribute \u0026#39;GPUPowerMizerMode\u0026#39; (rastating-PC:1[gpu:0]) assigned value 1. $ nvidia-settings -q GpuPowerMizerMode Attribute \u0026#39;GPUPowerMizerMode\u0026#39; (rastating-PC:1[gpu:0]): 1. Valid values for \u0026#39;GPUPowerMizerMode\u0026#39; are: 0, 1 and 2. \u0026#39;GPUPowerMizerMode\u0026#39; can use the following target types: GPU. 添加到开机启动\n Name：NVIDIA X Server Performance Settings Command：/usr/bin/nvidia-settings -a \u0026quot;[gpu:0]/GpuPowerMizerMode=1\u0026quot;  密钥环 如果你用过 Ubuntu 或者其他的 Linux 发行版里的自动登录功能, 你可能遇到过这种弹出消息：\n 请输入密码以解锁你的登录密钥环\n登录密钥环在你登录系统时未解锁。\n 如果你一直点击取消，它会不断弹出几次才会消失。你可能想知道，为什么你会一直看到这个密钥环信息呢？\n让我来告诉你吧。它其实不是错误，而是一个安全特性。\n奇怪吗？下面就让我来解释下 Linux 里的密钥环概念。\n密钥环是什么，为什么需要它？ 在现实生活中你为什么要用钥匙环（也叫钥匙链）？你用它把一把或多把钥匙串到一起, 以便于携带和查找。\nLinux 里也是类似的。密钥环特性使你的系统可以将各种密码放在一起，并将其保存在一个地方。\n大多数 Linux 桌面环境，如 GNOME、KDE、Xfce 等采用 GNOME 密钥环来提供这个功能。\n该密钥环保存了 ssh 密钥、GPG 密钥以及使用此功能的应用程序（例如 Chromium 浏览器）的密钥。默认情况下，“密钥环”通过主密码来保护，该密码通常是帐户的登录密码。\n系统上的每个用户都有自己的密钥环，（通常）密码与用户帐户本身的密码相同。当你使用密码登录系统时，你的密匙环将使用你帐户的密码自动解锁。\n当你启用 Ubuntu 中的自动登录功能时时，就有问题了。这意味着你无需输入密码即可登录系统。在这种情况下，你的密钥环不会自动解锁。\n密钥环是一个安全特性\n记得我说过密钥环是一个安全特性吗？现在想象一下你在 Linux 电脑上开启了自动登录功能。有权访问你电脑的任何人无需密码就能进入你的系统。但是你可能不会在意，因为你只是用它来访问互联网。\n但是，如果你在 Ubuntu 中使用 Chromium 或 Google Chrome 之类的浏览器，并使用它来保存各种网站的登录密码，那么你将遇到麻烦。任何人都可以使用浏览器并利用你在浏览器中保存的密码登录网站。这不很危险吗？\n这就是为什么当你使用 Chrome 时，它将反复地提示你先解锁密钥环。这确保了只有知道密钥环密码（即账户密码）的人才能使用在浏览器中保存的密码来登录它们相关的网站。\n如果你反复取消解锁密钥环的提示，它最终将消失，并允许你使用浏览器。但是，保存的密码将不会被解锁，你在 Chromium/Chome 浏览器上将会看到“同步暂停”的提示。\n如果密钥环一直存在，为什么你从来没有见过它呢?\n如果你在你的 Linux 系统上从没见过它的话，这个问题就很有道理。\n如果你从没有用过自动登录功能（或者修改你的账户密码），你可能都没有意识到这个特性的存在。\n这是因为当你通过你的密码登录系统时，你的密钥环被你的账户密码自动解锁了。\nUbuntu（和其他发行版）在执行普通的管理任务如修改用户、安装新软件等需要输入密码，无论你是否是自动登录的。但是对于日常任务像使用浏览器，它不需要输入密码因为密钥环已经被解锁了。\n当你切换到自动登录时，你不再需要输入登录密码。这意味着密钥环没有被自动解锁，因此当你使用利用了密钥环特性的浏览器时，它将提示你来解锁密钥环。\n你可以轻松地管理密钥环和密码\n这个密钥环放在哪里？它的核心是一个守护任务（一个后台自动运行的程序）。\n别担心。你不必通过终端来操作守护任务。大多数桌面环境都自带一个可以和这个守护进程进行交互的图形化应用程序。KDE 上有 KDE 钱包，GNOME 和其他桌面上叫做“密码和密钥”（Password And Keys）。\n你可以用这个 GUI 程序来查看哪些应用程序在用密钥环来管理/保护密码。\n你可以看到，我的系统有自动创建的登录密钥环。也有一个存储 GPG 和 SSH 密钥的密钥环。那个证书用来保存证书机构颁发的证书（如 HTTPS 证书）。\n你也可以使用这个应用程序来手动保存网站的密码。\n这里有一个潜在的问题，如果你格式化你的系统，手动保存的密码必然会丢失。通常，你会备份你的个人文件，但并不是所有的用户特定数据，如密钥环文件。\n有一种办法能解决它。密钥环数据通常保存在 ~/.local/share/keyrings 目录。在这里你可以看到所有的密钥环，但是你不能直接看到它们的内容。如果你移除密钥环的密码（我会在这篇文章的后面描述操作步骤），你可以像一个普通的文本文件一样读取密钥环的内容。你可以将这个解锁后的密钥环文件完整地复制下来，并在其他的 Linux 机器上运行“密码和密钥”应用程序导入到其中。\n总结一下目前为止所学的内容：\n 大多数 Linux 系统缺省已经安装并激活了密钥环特性 系统上的每个用户都拥有他自己的密钥环 密钥环通常是用账户密码锁定的（保护） 当你通过密码登录时密钥环会被自动解锁 对于自动登录，密钥环不会自动解锁，因此当你试图使用依赖密钥环的应用程序时会被提示先解锁它 并不是所有的浏览器或应用程序利用了密钥环特性 （Linux 上）安装一个 GUI 程序可以和密钥环交互 你可以用密钥环来手动存储加密格式的密码 你可以自己修改密钥环密码 你可以通过导出（需要先解锁密钥环）并导入到其他计算机上的方式来获取手工保存的密码。  修改密钥环密码 假设你修改了你的账户密码。当你登录时，你的系统试图通过新的登录密码来自动解锁密钥环。但是密钥环还在使用老的登录密码。\n这种情况下，你可以修改密钥环密码为新的登录密码，这样密码环才能在你登录系统时自动解锁。\n 从菜单中打开“密码和密钥”应用程序 在“Login”密钥环上右击并点击“修改密码”：  如果你不记得老的登录密码怎么办？\n你可能知道在 Ubuntu 上重置忘记的密码很容易。但是密钥环在这种场景下还是有问题。你修改了账户密码，但是你不记得仍然被密钥环使用的老的账户密码。\n你不能修改它因为你不知道老的密码。怎么办？\n这种情况下，你将不得不移除整个密钥环。你可以通过“密码和密钥”应用程序来操作。\n另外，你也可以手动删除 ~/.local/share/keyrings 目录下的密钥环文件。\n老的密钥环文件被移除后，你再打开 Chrome/Chromium 时，它会提示你创建一个新的密钥环。\n你可以用新的登录密码，密钥环就会被自动解锁了。\n禁用密钥环密码 在你想用自动登录但又不想手动解锁密钥环时，你可以把禁用密钥环密码作为一个规避方法。记住你正在禁用一个安全特性，因此请三思。\n操作步骤和修改密钥环相似。打开“密码和密钥”应用程序，然后修改密钥环密码。\n技巧在于当它提示修改密码时，不要输入新密码，而是点击“继续”按钮。这将移除密钥环的密码。\n这种方法，密钥环没有密码保护，并将一直处于解锁状态。\nGnome Tweaks GNOME 桌面有称为“扩展”的小插件或附加组件，学会使用 GNOME 扩展来扩展系统的可用性。\n$ apt install gnome-tweaks 同时会安装新的 GNOME Shell extensions，可以禁用桌面图标、Ubuntu Dock。可从浏览器安装 GNOME Shell extensions。\n如 OpenWeather，需设置 Location，Units 为公制单位，Layout为Right\ntheme design: Skeuomorphism vs Flat Design vs Material Design\n 主题目录： /usr/share/themes 或 ~/.themes 图标鼠标目录： /usr/share/icons 或 ~/.icons 壁纸： /usr/share/background , /usr/share/wallpapers  Ubuntu Dock Ubuntu Dock 就是 Dash to Dock。安装：\n$ sudo apt-get install gnome-shell-extension-dashtodock 重启，在 Extension 中设置 Dash to Dock，Dash to Dock 与 Ubuntu Dock 只能开启一个，否则有两个 Dock，但是就算关闭 Dash to Dock，Dash to Dock 设置依旧起作用到 Ubuntu Dock。\n重新登录。\nKDE Connect/GSConnect Files and links. Shared between devices.\nNetSpeed Displays Internet Speed\nClipboard Indicator Clipboard Manager extension for Gnome-Shell - Adds a clipboard indicator to the top panel, and caches clipboard history.\nCoverflow Alt-Tab Replacement of Alt-Tab, iterates through windows in a cover-flow manner.\nBluetooth Quick Connect Allow to connect to paired devices from gnome control panel.\nDesktop Icons NG (DING) with these advantages:\n Drag\u0026rsquo;n\u0026rsquo;Drop, both inside the desktop, between desktop and applications, and nautilus windows Allows to use \u0026ldquo;Open with\u0026hellip;\u0026rdquo; option with several files When hovering or clicking on an icon with a name too large to fit, it shows the full name Doesn\u0026rsquo;t hang the compositor when there is too much activity in the desktop folder  Frippery Move Clock Move clock to left of status menu button\nInput Method Panel Input Method Panel using KDE\u0026rsquo;s kimpanel protocol for Gnome-Shell\nLock Keys Numlock \u0026amp; Capslock status on the panel\nOpenWeather Weather extension to display weather information from https://openweathermap.org/ or https://darksky.net for almost all locations in the world.\nPanel Date Format Allows to customize the date format on the panel.\nRefresh Wifi Connections This extension adds a refresh button to the Wi-Fi connection selection dialog to manually request for a network scan.\nScreenshot Tool Conveniently create, copy, store and upload screenshots. Please log out and log in again after updating.\nSound Input \u0026amp; Output Device ChooserLivepatch Shows a list of sound output and input devices (similar to gnome sound settings) in the status menu below the volume slider.\nStatus Area Horizontal Spacing Reduce the horizontal spacing between icons in the top-right status area\nUnite Unite is a GNOME Shell extension which makes a few layout tweaks to the top panel and removes window decorations to make it look like Ubuntu Unity Shell.\nUser Themes Load shell themes from user directory.\nVitals A glimpse into your computer\u0026rsquo;s temperature, voltage, fan speed, memory usage, processor load, system resources, network speed and storage stats. This is a one stop shop to monitor all of your vital sensors. Uses asynchronous polling to provide a smooth user experience.\nPapirus Icon Theme $ sudo add-apt-repository ppa:papirus/papirus $ sudo apt-get update $ sudo apt-get install papirus-icon-theme Materia Theme $ sudo apt install materia-gtk-theme Chrome Import Passwords\n Launch Chrome on your computer. Type the following in the address bar and pressEnter: chrome://flags On the flags screen, put your cursor in the search box and type Password import. You should see the Password import flag in the search results. To enable this flag, click the dropdown menu next to the flag and select Enabled. Click Relaunch at the bottom to relaunch Chrome. This will restore all of your open tabs. When Chrome opens, click the three dots in the top-right corner, and select Settings \u0026gt; Passwords on the following screen. Click the three dots next to Saved Passwords and select Import. Navigate to your CSV passwords file and select it to import it into Chrome.  Tampermonkey 提供用户脚本\n FastGithub 镜像加速访问、克隆和下载 文本选中复制：解除网站不允许复制的限制，文本选中后点击复制按钮即可复制，主要用于 百度文库 道客巴巴 无忧考网 学习啦 蓬勃范文 思否社区 力扣 知乎 语雀 等 秒传链接提取：用于提取和生成百度网盘秒传链接 知乎增强：移除登录弹窗  Download All Images 下载网页所有图片\nuBlock Origin 禁广告\n沙拉查词 聚合词典专业划词翻译\nInfinity New Tab Chrome Extension，解决 Chrome new tab 加载后会清空搜索栏问题\nQuestions The repository \u0026lsquo;http://dl.google.com/linux/chrome/deb stable Release\u0026rsquo; does not have a Release file\nThe \u0026ldquo;key\u0026rdquo; is \u0026ldquo;repository can\u0026rsquo;t be authenticated\u0026rdquo;\nIMHO\u0026hellip; you don\u0026rsquo;t have the key of the repo\nTo solve that just use this command:\n$ wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add - Chromium Chromium 是一款来自 \u0026ldquo;The Chromium Project\u0026rdquo; 的开源图形网络浏览器，基于 Blink 渲染引擎。它也是商业软件 Google Chrome 浏览器得以组成的基础。\n在这里你可以看到 Google Chrome 与 Chromium 浏览器的区别。此外，还有一点重要的不同：2021年3月2日发布的 Chromium 89 及其以后版本不再支持 Google 账户同步功能。\n注意： 目前，可以通过 使用 Chrome 的OAuth2 凭证或者 申请一个属于自己的凭证来恢复同步功能, 但是请注意，这不一定是一个长期的解决方案。长期来讲，最好考虑使用 xbrowsersync 来同步书签数据。\nFirefox Codec 主要用于 Firefox，安装媒体解码器来播放 MP3、MPEG4 和其他格式媒体文件。由于各个国家的版权问题， Ubuntu 在默认情况下不会安装它。\n$ sudo apt-get install ubuntu-restricted-extras 这种方式会安装 .exe 程序，不如直接安装\n$ sudo apt-get install h264enc Flameshot Powerful, yet simple to use open-source screenshot software.\n   Keys Description     ←, ↓, ↑, → Move selection 1px   Shift + ←, ↓, ↑, → Resize selection 1px   Esc Quit capture   Ctrl + C Copy to clipboard   Ctrl + S Save selection as a file   Ctrl + Z Undo the last modification   Right Click Show color picker   Mouse Wheel Change the tool\u0026rsquo;s thickness    Add a new Shortcuts\n On \u0026lsquo;Name\u0026rsquo;, name it \u0026lsquo;Flameshot\u0026rsquo; Define the command as \u0026lsquo;flameshot gui\u0026rsquo;. Select \u0026lsquo;Define shortcut\u0026hellip;\u0026lsquo;and click your keyboard win + shift + Prt Sc key.  PPSSPP Settings A PSP emulator.\n$ sudo add-apt-repository ppa:ppsspp/stable $ sudo apt-get update $ sudo apt install ppsspp Graphics:\n Rendering Mode  set the Backend from OpenGL to Vulkan.   Framework Control  Frameskipping is Off Auto-Frameskip is Off set the Alternative Speed to Unlimited   Postprocessing effects  Postprocessing shader should be off.   Performance  If your Device is Powerful, high rendering resolution will work. Its recommended to first try with 2x Rendering resolution as It brings impressive graphics and supports stable gameplay too Hardware transform, Software skinning, Vertex cache and Lazy texture caching should be checked. Retain changed textures should be unchecked while keeping Disable slower effects and Hardware Installation checked.   Overlay Information  Select FPS in Show FPS counter.    System:\n Make sure Fast memory is checked Set I/O timing method, to Simulate UMD delays or Fast  uTools uTools 是一个极简、插件化的现代桌面软件，通过自由选配丰富的插件，打造得心应手的工具集合。\n通过快捷键（默认 alt + space ）就可以快速呼出这个搜索框。你可以往输入框内粘贴文本、图片、截图、文件、文件夹等等，能够处理此内容的插件也早已准备就绪，统一的设计风格和操作方式，助你高效的得到结果。\n一旦你熟悉它后，能够为你节约大量时间，即用即走、不中断、无干扰，让你可以更加专注地改变世界。\nLiferea Liferea is a web feed reader/news aggregator that brings together all of the content from your favorite subscriptions into a simple interface that makes it easy to organize and browse feeds. Its GUI is similar to a desktop mail/news client, with an embedded web browser.\nCalibre calibre is a powerful and easy to use e-book manager. Users say it’s outstanding and a must-have. It’ll allow you to do nearly everything and it takes things a step beyond normal e-book software. It’s also completely free and open source and great for both casual users and computer experts.\nVentoy 简单来说，Ventoy是一个制作可启动U盘的开源工具。\n有了Ventoy你就无需反复地格式化U盘，你只需要把 ISO/WIM/IMG/VHD(x)/EFI 等类型的文件直接拷贝到U盘里面就可以启动了，无需其他操作。\netcher Supported Operating Systems\n Linux (most distros) macOS 10.10 (Yosemite) and later Microsoft Windows 7 and later  UNetbootin UNetbootin installs Linux/BSD distributions to a partition or USB drive\nWoeUSB-ng WoeUSB-ng is a simple tool that enable you to create your own usb stick windows installer from an iso image or a real DVD. This is a rewrite of original WoeUSB.\nGoldenDict Timeshift System restore tool for Linux.\nTodoist Plank Plank is meant to be the simplest dock on the planet.\nMotrix A full-featured download manager.\nSTEAM YACReader work_crawler Download comics novels\ndingtalk 钉钉桌面版，基于electron和钉钉网页版开发\nhowdy Windows Hello™ style facial authentication for Linux\n向日葵 向日葵远程控制软件是一款免费的集远程控制电脑手机、远程桌面连接、远程开机、远程管理、支持内网穿透的一体化远程控制管理工具软件。\nCLI Utilities fdupes You can call it like fdupes -r /dir/ect/ory and it will print out a list of dupes. fdupes has also a simple Homepage and a Wikipedia article, which lists some more programs.\ndigiKam 可用于查找重复相片，然后根据需要删除重复内容。\nbypy bypy info 认证特别慢，而授权码又只有10分钟，导致后面授权码过期 Heroku server 认证失败失败。\n如此，可以通过手动认证。\n  通过 bypy -dv 查看详细输出，得到 Full URL，如 https://bypyoauth.herokuapp.com/auth?code=...\u0026amp;bypy_version=1.7.2\u0026amp;redirect_uri=oob，在浏览器中打开，获得token。\n  将其放在 ~/.bypy/bypy.json 中。\n  源码仓库也有示例。\n我下载一个大文件，总共12G左右，已用了两个晚上，中途没关（由于不是立马就要的东西，就用时间换金钱了），一次看进度时，Terminal 就卡退了，重新运行后，bypy会继续上次下载，而不是重新开始（这样话太可怕了）。\nFRP frp 是一个专注于内网穿透的高性能的反向代理应用，支持 TCP、UDP、HTTP、HTTPS 等多种协议。可以将内网服务以安全、便捷的方式通过具有公网 IP 节点的中转暴露到公网。\n其他内网穿透工具\n ngrok ZeroTier N2N Dog Tunnel Tinc  Git $ vi .gitignore_default $ vi .auto-git.sh #!/bin/bash BLOG_DIR=$HOME/Documents/BlogSrc NOTE_DIR=$HOME/Documents/vNotebook TIME=\u0026#34;$(date \u0026#39;+%Y%m%d%H%M%S\u0026#39;)\u0026#34; echo \u0026#39;##BlogSrc##\u0026#39; cd $BLOG_DIR git pull git add . git commit -m \u0026#34;Update-${TIME}\u0026#34; git push echo \u0026#39;##vNotebook##\u0026#39; cd $NOTE_DIR git pull echo \u0026#39;#Tree DataOne\u0026#39; tree $HOME/DataOne \u0026gt; $NOTE_DIR/DataOne.tree echo \u0026#39;#Ignore files larger than 100MB\u0026#39; cat .gitignore_default \u0026gt; .gitignore # We need to remove the \u0026#34;./\u0026#34; then, .gitignore works, this command does that. find . -size +100M | sed \u0026#39;s|^./||g\u0026#39; | cat \u0026gt;\u0026gt; .gitignore git add . git commit -m \u0026#34;Update-${TIME}\u0026#34; git push exit 0 $ crontab -e 0 12 * * * /home/vane/.auto-git.sh  A collection of useful .gitignore templates Ignore files \u0026gt;100MB in your Git repos About large files on GitHub  GitHub Desktop Focus on what matters instead of fighting with Git. Whether you\u0026rsquo;re new to Git or a seasoned user, GitHub Desktop simplifies your development workflow.\nlibguestfs libguestfs 支持几乎所有类型的磁盘镜像。\n在基于 Debian 的系统上：\n$ apt-get install libguestfs-tools 我们可以像下面这样挂载一个 qcow2 格式的磁盘镜像：\n$ guestmount -a /path/to/qcow2/image -m \u0026lt;device\u0026gt; /path/to/mount/point 要卸载它，则执行：\n$ guestunmount qcow2_mount_poin Oracle JDK   解压缩到目录\n$ tar -zxv -f jdk-7u60-linux-x64.gz -C dir   修改环境变量\n$ vi ~/.bashrc export JAVA_HOME=/usr/lib/jvm/jdk1.7.0_60 # 这里换成自己解压的jdk 目录 export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib export PATH=${JAVA_HOME}/bin:$PATH   使环境变量生效\n$ source ~/.bashrc   Snapper Snapper 是一个由 openSUSE 的 Arvin Schnell 开发的工具，用于管理 Btrfs 子卷和 LVM 精简配置(thin-provisioned)卷。它可以创建和比较快照，在快照间回滚，并支持自动按时间序列创建快照。\n列出子卷列表\n$ sudo btrfs subvolume list -p / ID 256 gen 7746 parent 5 top level 5 path @ ID 258 gen 7746 parmount -n -o remount,rw /ent 5 top level 5 path @home 安装 snapper\n$ sudo apt install snapper snapper-gui 创建配置文件，启用自动快照\n$ sudo snapper -c root create-config / $ sudo snapper -c home create-config /home Snapshots on boot\n$ sudo systemctl status snapper-boot.timer 管理 snapshot\n$ sudo snapper-gui Fail2Ban Fail2Ban 是一款入侵防御软件，可以保护服务器免受暴力攻击。 它是用 Python 编程语言编写的。 Fail2Ban 基于auth 日志文件工作，默认情况下它会扫描所有 auth 日志文件，如 /var/log/auth.log、/var/log/apache/access.log 等，并禁止带有恶意标志的IP，比如密码失败太多，寻找漏洞等等标志。\n通常，Fail2Ban 用于更新防火墙规则，用于在指定的时间内拒绝 IP 地址。 它也会发送邮件通知。 Fail2Ban 为各种服务提供了许多过滤器，如 ssh、apache、nginx、squid、named、mysql、nagios 等。\nFail2Ban 能够降低错误认证尝试的速度，但是它不能消除弱认证带来的风险。 这只是服务器防止暴力攻击的安全手段之一。\nSyncthing Syncthing是一款开源免费跨平台的文件同步工具，是基于P2P技术实现设备间的文件同步，所以它的同步是去中心化的，即你并不需要一个服务器，故不需要担心这个中心的服务器给你带来的种种限制，而且类似于torrent协议，参与同步的设备越多，同步的速度越快。针对隐私问题，Syncthing软件只会将数据存储于个人信任的设备上，不会存储到服务器上。设备之间的通信均通过TLS进行，Syncthing还使用了完全正向保密技术来进一步保障你的数据安全。对于处于不同局域网之中的设备之间的文件同步，Syncthing也提供了支持。\nmasscan Masscan号称是最快的互联网端口扫描器，最快可以在六分钟内扫遍互联网。\nImageMagick Use ImageMagick to create, edit, compose, or convert digital images. It can read and write images in a variety of formats (over 200) including PNG, JPEG, GIF, WebP, HEIC, SVG, PDF, DPX, EXR and TIFF. ImageMagick can resize, flip, mirror, rotate, distort, shear and transform images, adjust image colors, apply various special effects, or draw text, lines, polygons, ellipses and Bézier curves.\np7zip 7-Zip is a file archiver with a high compression ratio.\np7zip 是 7-Zip 的 POSIX 系统移植，支持 Linux。\n警告： 不要将7z格式用于备份目的，因为它不会保存文件的所有者/组。有关更多详细信息，请参见7z(1)。\n添加文件或目录至已有的存档（或创建一个新的存档）：\n$ 7z a \u0026lt;archive name\u0026gt; \u0026lt;file name\u0026gt; 也可以通过参数-p设置密码，并通过标志-mhe = on隐藏存档的结构：\n$ 7z a \u0026lt;archive name\u0026gt; \u0026lt;file name\u0026gt; -p -mhe=on 更新存档内已有的文件或添加新文件：\n$ 7z u \u0026lt;archive name\u0026gt; \u0026lt;file name\u0026gt; 列出存档内容：\n$ 7z l \u0026lt;archive name\u0026gt; 从存档中解压文件至当前文件夹，不使用存档内的目录结构：\n$ 7z e \u0026lt;archive name\u0026gt; 如果需要恢复存档内的目录结构，使用：\n$ 7z x \u0026lt;archive name\u0026gt; 解压至新的目录：\n$ 7z x -o\u0026lt;folder name\u0026gt; \u0026lt;archive name\u0026gt; 校验存档完整性：\n$ 7z t \u0026lt;archive name\u0026gt; Differences between 7z, 7za and 7zr binaries The package includes three binaries, /usr/bin/7z, /usr/bin/7za, and /usr/bin/7zr. Their manual pages explain the differences:\n 7z(1) uses plugins to handle archives. 7za(1) is a stand-alone executable that handles fewer archive formats than 7z. 7zr(1) is a stand-alone executable. It is a \u0026ldquo;light-version\u0026rdquo; of 7za that only handles 7z archives. In contrast to 7za, it cannot handle encrypted archives.  分卷压缩与解压缩 rar\n# rar a -vSIZE 压缩后的文件名 被压缩的文件或者文件夹 # 最大限制为 12M $ rar a -m5 -v12m myarchive myfiles #解压 $ rar e myarchive.part1.rar tar\n要将目录logs打包压缩并分割成多个1M的文件，可以用下面的命令：\n$ tar cjf - logs/ | split -b 1m - logs.tar.bz2. 完成后会产生下列文件：\nlogs.tar.bz2.aa, logs.tar.bz2.ab, logs.tar.bz2.ac 要解压的时候只要执行下面的命令就可以了：\n$ cat logs.tar.bz2.a* | tar xj 两个\u0026quot;-\u0026ldquo;不要漏了，那是tar的ouput和split的input的参数。\n7z\n压缩：\n$ 7z a name.7z filename -v10m 这里a是添加文件到压缩卷，name.7z是压缩后文件,然后filename可以是文件夹或文件，-v10m是限制每个包大小不超过10m.\n解压到当前目录：\n$ 7z x film.7z.001 Wudao-dict 有道词典的命令行版本，支持英汉互查和在线查询。\nascii-image-converter ttyd Share your terminal over the web\nprogress Linux tool to show progress for cp, mv, dd, \u0026hellip; (formerly known as cv)\nvosk-api Offline speech recognition API for Android, iOS, Raspberry Pi and servers with Python, Java, C# and Node\nconvert MP3 to text The software you can use is Vosk-api, a modern speech recognition toolkit based on neural networks. It supports 7+ languages and works on variety of platforms including RPi and mobile.\nFirst you convert the file to the required format and then you recognize it:\n$ ffmpeg -i file.mp3 -ar 16000 -ac 1 file.wav Then install vosk-api with pip:\n$ pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple vosk Then use these steps:\n$ git clone https://github.com/alphacep/vosk-api $ cd vosk-api/python/example $ curl -O http://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip $ unzip vosk-model-small-en-us-0.15.zip $ mv vosk-model-small-en-us-0.15 model $ python3 ./test_simple.py test.wav \u0026gt; result.json The result will be stored in json format.\nThe same directory also contains an srt subtitle output example, which is easier to evaluate and can be directly useful to some users:\n$ python3 -m pip install srt $ python3 ./test_srt.py test.wav The example given in the repository says in perfect American English accent and perfect sound quality three sentences which I transcribe as:\none zero zero zero one nine oh two one oh zero one eight zero three The \u0026ldquo;nine oh two one oh\u0026rdquo; is said very fast, but still clear. The \u0026ldquo;z\u0026rdquo; of the before last \u0026ldquo;zero\u0026rdquo; sounds a bit like an \u0026ldquo;s\u0026rdquo;.\nThe SRT generated above reads:\n1 00:00:00,870 --\u0026gt; 00:00:02,610 what zero zero zero one 2 00:00:03,930 --\u0026gt; 00:00:04,950 no no to uno 3 00:00:06,240 --\u0026gt; 00:00:08,010 cyril one eight zero three so we can see that several mistakes were made, presumably in part because we have the understanding that all words are numbers to help us.\nNext I also tried with the vosk-model-en-us-0.22.zip which was a 1.8G download compared to 40M of vosk-model-small-en-us-0.15 and is listed at https://alphacephei.com/vosk/models:\n$ mv model vosk-model-small-en-us-0.15 $ curl -O http://alphacephei.com/vosk/models/vosk-model-en-us-0.22.zip $ unzip vosk-model-en-us-0.22.zip $ mv vosk-model-en-us-0.22 model and the result was:\n1 00:00:00,840 --\u0026gt; 00:00:02,610 one zero zero zero one 2 00:00:04,026 --\u0026gt; 00:00:04,980 i know what you window 3 00:00:06,270 --\u0026gt; 00:00:07,980 serial one eight zero three which got one more word correct.\ninxi inix 是一个用于获取 Linux 系统信息的终端命令。能够获取软件和硬件的详细信息，比如计算机型号、内核版本、发行版号以及桌面环境等信息，甚至可以读取主存模块占用主板的哪块 RAM 卡槽等详细信息。\ninxi 还可以用于监控系统中正在消耗 CPU 或者内存资源的进程。\n在 Ubuntu/Debian 发行版系统中，安装命令：\nsudo apt install inxi 用 -F 参数可以获取详细的系统信息。几乎囊括了所有层次的系统信息。\ninxi -F BusyBox BusyBox 是一个开源（GPL）项目，提供了近 400 个常用命令的简单实现，包括 ls、mv、ln、mkdir、more、ps、gzip、bzip2、tar 和 grep。它还包含了编程语言 awk、流编辑器 sed、文件系统检查工具 fsck、软件包管理器rpm 和 dpkg ，当然还有一个可以方便的访问所有这些命令的 shell（sh）。简而言之，它包含了所有 POSIX 系统需要的基本命令，以执行常见的系统维护任务以及许多用户和管理任务。\n事实上，它甚至包含一个 init 命令，可以作为 PID 1 启动，以作为所有其它系统服务的父进程。换句话说，BusyBox 可以作为 systemd、OpenRC、sinit、init 和其他初始化系统的替代品。\nBusyBox 非常小。作为一个可执行文件，它不到 1MB，所以它在嵌入式、边缘计算 和物联网领域很受欢迎，因为这些场景的存储空间是很宝贵的。在容器和云计算的世界里，它作为精简的 Linux 容器镜像的基础镜像也很受欢迎。\n极简主义 BusyBox 的部分魅力在于它的极简主义。它的所有命令都被编译到一个二进制文件里（busybox），它的手册只有 81 页（根据我对 man 送到 pr 管道的计算），但它涵盖了近 400 条命令。\n作为一个例子的比较，这是 “原版” 的 useradd —help 的输出：\n-b, --base-dir BASE_DIR base directory for home -c, --comment COMMENT GECOS field of the new account -d, --home-dir HOME_DIR home directory of the new account -D, --defaults print or change the default config -e, --expiredate EXPIRE_DATE expiration date of the new account -f, --inactive INACTIVE password inactivity -g, --gid GROUP name or ID of the primary group -G, --groups GROUPS list of supplementary groups -h, --help display this help message and exit -k, --skel SKEL_DIR alternative skeleton dir -K, --key KEY=VALUE override /etc/login.defs -l, --no-log-init do not add the user to the lastlog -m, --create-home create the user's home directory -M, --no-create-home do not create the user's home directory -N, --no-user-group do not create a group with the user's name -o, --non-unique allow users with non-unique UIDs -p, --password PASSWORD encrypted password of the new account -r, --system create a system account -R, --root CHROOT_DIR directory to chroot into -s, --shell SHELL login shell of the new account -u, --uid UID user ID of the new account -U, --user-group create a group with the same name as a user 而这是是同一命令的 BusyBox 版本：\n-h DIR Home directory -g GECOS GECOS field -s SHELL Login shell -G GRP Group -S Create a system user -D Don't assign a password -H Don't create home directory -u UID User id -k SKEL Skeleton directory (/etc/skel) 这种差异是一种特性还是一种限制，取决于你是喜欢你的命令拥有 20 个选项还是 10 个选项。对于一些用户和某些用例来说，BusyBox 的极简主义刚刚满足所需。对于其他人来说，它是一个很好的最小化环境，可以作为一个后备工具，或者作为安装更强大的工具的基础，比如 Bash、Zsh、GNU Awk 等等。\nLynis  使用这个全面的开源安全审计工具检查你的 Linux 机器的安全性。\n 你有没有想过你的 Linux 机器到底安全不安全？Linux 发行版众多，每个发行版都有自己的默认设置，你在上面运行着几十个版本各异的软件包，还有众多的服务在后台运行，而我们几乎不知道或不关心这些。\n要想确定安全态势（指你的 Linux 机器上运行的软件、网络和服务的整体安全状态），你可以运行几个命令，得到一些零碎的相关信息，但你需要解析的数据量是巨大的。\n如果能运行一个工具，生成一份关于机器安全状况的报告，那就好得多了。而幸运的是，有一个这样的软件：Lynis。它是一个非常流行的开源安全审计工具，可以帮助强化基于 Linux 和 Unix 的系统。根据该项目的介绍：\n “它运行在系统本身，可以进行深入的安全扫描。主要目标是测试安全防御措施，并提供进一步强化系统的提示。它还将扫描一般系统信息、易受攻击的软件包和可能的配置问题。Lynis 常被系统管理员和审计人员用来评估其系统的安全防御。”\n 安装 Lynis 你的 Linux 软件仓库中可能有 Lynis。如果有的话，你可以用以下方法安装它：\n$ sudo apt install lynis 然而，如果你的仓库中的版本不是最新的，你最好从 GitHub 上安装它。事实上，Lynis 主要是用 shell 脚本来实现的。\n运行 Lynis 通过给 Lynis 一个 -h 选项来查看帮助部分，以便有个大概了解：\n$ sudo lynis -h 你会看到一个简短的信息屏幕，然后是 Lynis 支持的所有子命令。\n接下来，尝试一些测试命令以大致熟悉一下。要查看你正在使用的 Lynis 版本，请运行：\n$ sudo lynis show version 3.0.0 要查看 Lynis 中所有可用的命令：\n$ sudo lynis show commands Commands: lynis audit lynis configure lynis generate lynis show lynis update lynis upload-only 审计 Linux 系统 要审计你的系统的安全态势，运行以下命令：\n$ sudo lynis audit system 这个命令运行得很快，并会返回一份详细的报告，输出结果可能一开始看起来很吓人，但我将在下面引导你来阅读它。这个命令的输出也会被保存到一个日志文件中，所以你可以随时回过头来检查任何可能感兴趣的东西。\nLynis 将日志保存在这里：\nFiles: - Test and debug information : /var/log/lynis.log - Report data : /var/log/lynis-report.dat 你可以验证是否创建了日志文件。它确实创建了：\n$ ls -l /var/log/lynis.log -rw-r-----. 1 root root 341489 Apr 30 05:52 /var/log/lynis.log $ ls -l /var/log/lynis-report.dat -rw-r-----. 1 root root 638 Apr 30 05:55 /var/log/lynis-report.dat 探索报告 Lynis 提供了相当全面的报告，所以我将介绍一些重要的部分。作为初始化的一部分，Lynis 做的第一件事就是找出机器上运行的操作系统的完整信息。之后是检查是否安装了什么系统工具和插件：\n[+] Initializing program ------------------------------------ - Detecting OS... [ DONE ] - Checking profiles... [ DONE ] --------------------------------------------------- Program version: 3.0.0 Operating system: Linux Operating system name: Red Hat Enterprise Linux Server 7.8 (Maipo) Operating system version: 7.8 Kernel version: 3.10.0 Hardware platform: x86_64 Hostname: example --------------------------------------------------- \u0026lt;\u0026lt;截断\u0026gt;\u0026gt; [+] System Tools ------------------------------------ - Scanning available tools... - Checking system binaries... [+] Plugins (phase 1) ------------------------------------ Note: plugins have more extensive tests and may take several minutes to complete - Plugin: pam [..] - Plugin: systemd [................] 接下来，该报告被分为不同的部分，每个部分都以 [+] 符号开头。下面可以看到部分章节。（哇，要审核的地方有这么多，Lynis 是最合适的工具！）\n[+] Boot and services [+] Kernel [+] Memory and Processes [+] Users, Groups and Authentication [+] Shells [+] File systems [+] USB Devices [+] Storage [+] NFS [+] Name services [+] Ports and packages [+] Networking [+] Printers and Spools [+] Software: e-mail and messaging [+] Software: firewalls [+] Software: webserver [+] SSH Support [+] SNMP Support [+] Databases [+] LDAP Services [+] PHP [+] Squid Support [+] Logging and files [+] Insecure services [+] Banners and identification [+] Scheduled tasks [+] Accounting [+] Time and Synchronization [+] Cryptography [+] Virtualization [+] Containers [+] Security frameworks [+] Software: file integrity [+] Software: System tooling [+] Software: Malware [+] File Permissions [+] Home directories [+] Kernel Hardening [+] Hardening [+] Custom tests Lynis 使用颜色编码使报告更容易解读。\n 绿色。一切正常 黄色。跳过、未找到，可能有个建议 红色。你可能需要仔细看看这个  在我的案例中，大部分的红色标记都是在 “Kernel Hardening” 部分找到的。内核有各种可调整的设置，它们定义了内核的功能，其中一些可调整的设置可能有其安全场景。发行版可能因为各种原因没有默认设置这些，但是你应该检查每一项，看看你是否需要根据你的安全态势来改变它的值：\n[+] Kernel Hardening ------------------------------------ - Comparing sysctl key pairs with scan profile - fs.protected_hardlinks (exp: 1) [ OK ] - fs.protected_symlinks (exp: 1) [ OK ] - fs.suid_dumpable (exp: 0) [ OK ] - kernel.core_uses_pid (exp: 1) [ OK ] - kernel.ctrl-alt-del (exp: 0) [ OK ] - kernel.dmesg_restrict (exp: 1) [ DIFFERENT ] - kernel.kptr_restrict (exp: 2) [ DIFFERENT ] - kernel.randomize_va_space (exp: 2) [ OK ] - kernel.sysrq (exp: 0) [ DIFFERENT ] - kernel.yama.ptrace_scope (exp: 1 2 3) [ DIFFERENT ] - net.ipv4.conf.all.accept_redirects (exp: 0) [ DIFFERENT ] - net.ipv4.conf.all.accept_source_route (exp: 0) [ OK ] - net.ipv4.conf.all.bootp_relay (exp: 0) [ OK ] - net.ipv4.conf.all.forwarding (exp: 0) [ OK ] - net.ipv4.conf.all.log_martians (exp: 1) [ DIFFERENT ] - net.ipv4.conf.all.mc_forwarding (exp: 0) [ OK ] - net.ipv4.conf.all.proxy_arp (exp: 0) [ OK ] - net.ipv4.conf.all.rp_filter (exp: 1) [ OK ] - net.ipv4.conf.all.send_redirects (exp: 0) [ DIFFERENT ] - net.ipv4.conf.default.accept_redirects (exp: 0) [ DIFFERENT ] - net.ipv4.conf.default.accept_source_route (exp: 0) [ OK ] - net.ipv4.conf.default.log_martians (exp: 1) [ DIFFERENT ] - net.ipv4.icmp_echo_ignore_broadcasts (exp: 1) [ OK ] - net.ipv4.icmp_ignore_bogus_error_responses (exp: 1) [ OK ] - net.ipv4.tcp_syncookies (exp: 1) [ OK ] - net.ipv4.tcp_timestamps (exp: 0 1) [ OK ] - net.ipv6.conf.all.accept_redirects (exp: 0) [ DIFFERENT ] - net.ipv6.conf.all.accept_source_route (exp: 0) [ OK ] - net.ipv6.conf.default.accept_redirects (exp: 0) [ DIFFERENT ] - net.ipv6.conf.default.accept_source_route (exp: 0) [ OK ] 看看 SSH 这个例子，因为它是一个需要保证安全的关键领域。这里没有什么红色的东西，但是 Lynis 对我的环境给出了很多强化 SSH 服务的建议：\n[+] SSH Support ------------------------------------ - Checking running SSH daemon [ FOUND ] - Searching SSH configuration [ FOUND ] - OpenSSH option: AllowTcpForwarding [ SUGGESTION ] - OpenSSH option: ClientAliveCountMax [ SUGGESTION ] - OpenSSH option: ClientAliveInterval [ OK ] - OpenSSH option: Compression [ SUGGESTION ] - OpenSSH option: FingerprintHash [ OK ] - OpenSSH option: GatewayPorts [ OK ] - OpenSSH option: IgnoreRhosts [ OK ] - OpenSSH option: LoginGraceTime [ OK ] - OpenSSH option: LogLevel [ SUGGESTION ] - OpenSSH option: MaxAuthTries [ SUGGESTION ] - OpenSSH option: MaxSessions [ SUGGESTION ] - OpenSSH option: PermitRootLogin [ SUGGESTION ] - OpenSSH option: PermitUserEnvironment [ OK ] - OpenSSH option: PermitTunnel [ OK ] - OpenSSH option: Port [ SUGGESTION ] - OpenSSH option: PrintLastLog [ OK ] - OpenSSH option: StrictModes [ OK ] - OpenSSH option: TCPKeepAlive [ SUGGESTION ] - OpenSSH option: UseDNS [ SUGGESTION ] - OpenSSH option: X11Forwarding [ SUGGESTION ] - OpenSSH option: AllowAgentForwarding [ SUGGESTION ] - OpenSSH option: UsePrivilegeSeparation [ OK ] - OpenSSH option: AllowUsers [ NOT FOUND ] - OpenSSH option: AllowGroups [ NOT FOUND ] 我的系统上没有运行虚拟机或容器，所以这些显示的结果是空的：\n[+] Virtualization ------------------------------------ [+] Containers ------------------------------------ Lynis 会检查一些从安全角度看很重要的文件的文件权限：\n[+] File Permissions ------------------------------------ - Starting file permissions check File: /boot/grub2/grub.cfg [ SUGGESTION ] File: /etc/cron.deny [ OK ] File: /etc/crontab [ SUGGESTION ] File: /etc/group [ OK ] File: /etc/group- [ OK ] File: /etc/hosts.allow [ OK ] File: /etc/hosts.deny [ OK ] File: /etc/issue [ OK ] File: /etc/issue.net [ OK ] File: /etc/motd [ OK ] File: /etc/passwd [ OK ] File: /etc/passwd- [ OK ] File: /etc/ssh/sshd_config [ OK ] Directory: /root/.ssh [ SUGGESTION ] Directory: /etc/cron.d [ SUGGESTION ] Directory: /etc/cron.daily [ SUGGESTION ] Directory: /etc/cron.hourly [ SUGGESTION ] Directory: /etc/cron.weekly [ SUGGESTION ] Directory: /etc/cron.monthly [ SUGGESTION ] 在报告的底部，Lynis 根据报告的发现提出了建议。每项建议后面都有一个 “TEST-ID”（为了下一部分方便，请将其保存起来）。\nSuggestions (47): ---------------------------- * If not required, consider explicit disabling of core dump in /etc/security/limits.conf file [KRNL-5820] https://cisofy.com/lynis/controls/KRNL-5820/ * Check PAM configuration, add rounds if applicable and expire passwords to encrypt with new values [AUTH-9229] https://cisofy.com/lynis/controls/AUTH-9229/ Lynis 提供了一个选项来查找关于每个建议的更多信息，你可以使用 show details 命令和 TEST-ID 号来访问：\n$ sudo lynis show details TEST-ID 这将显示该测试的其他信息。例如，我检查了 SSH-7408 的详细信息：\n$ sudo lynis show details SSH-7408 2020-04-30 05:52:23 Performing test ID SSH-7408 (Check SSH specific defined options) 2020-04-30 05:52:23 Test: Checking specific defined options in /tmp/lynis.k8JwazmKc6 2020-04-30 05:52:23 Result: added additional options for OpenSSH \u0026amp;lt; 7.5 2020-04-30 05:52:23 Test: Checking AllowTcpForwarding in /tmp/lynis.k8JwazmKc6 2020-04-30 05:52:23 Result: Option AllowTcpForwarding found 2020-04-30 05:52:23 Result: Option AllowTcpForwarding value is YES 2020-04-30 05:52:23 Result: OpenSSH option AllowTcpForwarding is in a weak configuration state and should be fixed 2020-04-30 05:52:23 Suggestion: Consider hardening SSH configuration [test:SSH-7408] [details:AllowTcpForwarding (set YES to NO)] [solution:-] 试试吧 如果你想更多地了解你的 Linux 机器的安全性，请试试 Lynis。如果你想了解 Lynis 是如何工作的，可以研究一下它的 shell 脚本，看看它是如何收集这些信息的。\nHow can I protect against single user mode Potential Attacks\nSingle User Mode\nThis is the easiest way to gain unauthorised access to a Linux system is to boot the server into Single User Mode because it does not, by default, require a root password to gain root level access. Single User Mood can be accessed by power cycling the machine and interrupting the boot process. To boot into single user mode where the GRUB bootloader is used perform the following; interrupt the boot process, press e to edit the boot configuration file, append to the line starting Linux one of either s, S, 1 or systemd. unit=[rescue.target, emergency.target, rescue] to change the argument being passed to the kernel during boot to boot into Single User Mode, then press ctrl+x.\nProtecting Against Single User Mode\nFor a traditional init based system\nAs root edit the file /etc/sysconfig/init then on the line SINGLE=/sbin/sushell change sushell TO sulogin.\nFor a systemd based system\nThe target configuration need to be altered for the root password to be prompted for. The targets are located in /lib/systemd/system the files which need alteration are emergency.service and rescue.service. Alter the line starting ExecStart=-/bin/sh –c “/usr/sbin/sushell; ……” and change the /usr/sbin/sushell to/usr/sbin/sulogin in both emergency.service and rescue.service.\nTo check this has taken affect\nThen save changes and reboot to confirm the alteration has taken affect, if the alteration was success when booting into single user mode it shall ask for the root password.\nRoot Password\nBy default, some Linux distributions do not have root password sets, this can be checked by running the command head -1 /etc/shadow and if the second column, using a colon as a delimiter, is an exclamation mark then no password has been set. If no root password is set, then regardless of if the system is set to prompt for a password for Single User Mode or not it will just load root access.\nSecuring Bootloader\nInsecure bootloaders can result in the bootloader being bypassed completely and a shell being used to gain direct root level access to the system. This is done by interrupting the GRUB boot process and appending init=/bin/bas to the line beginning linux16. This will tell the kernel to use bash instead of init.\nProtecting against bootloader side loading\nThe GRUB bootloader can be password protected by placing the configuration in /etc/grub.d/40_custom file because this file will remain un touched by updates and upgrades to the boot loader. In /etc/grub.d/40_custom add set superusers=”admin” then password admin after that save and exit the file and run the following command grub2-mkpasswd-… (allow tab completion to finish this command so that the system compatible script is run) the output of this command from grub2. Onwards need to be added to the end of the line password admin in /etc/grub.d/40_custom. After that the grub file need to be recompiled by running the command grub2-mkconfig –o /boot/grub2/grub.cfg for centos or update-grub¬ on debian.\nTo check this has taken affect\nThen save changes and reboot to confirm the alteration has taken affect, if the alteration was success when booting and wanting to change the grub setting you will need to supply the username admin and the encrypted password.\nProtecting Against Recovery Attack\nThese measures can aid in protection however, if a disk is used the recover Linux feature on the disk can be used to mount the file system and alter the GRUB setting from the disk. To protect against make any removable media have a lower boot priority than the boot drive and password protect the BIOS and boot option menu to stop someone who hasn’t got access altering the boot order and booting into a disk to make changes to the system.\nSystem man 手册页（man pages），即参考手册页（reference manual pages）的简称，是你进入 Linux 的钥匙。你想知道的一切都在那里，包罗万象。这套文档永远不会赢得普利策奖，但这套文档是相当准确和完整的。手册页是主要信源，其权威性是众所周知的。\n虽然它们是源头，但阅读起来并不是最令人愉快的。有一次，在很久以前的哲学课上，有人告诉我，阅读 亚里士多德 是最无聊的阅读。我不同意：说到枯燥的阅读，亚里士多德远远地排在第二位，仅次于手册页。\n乍一看，这些页面可能看起来并不完整，但是，不管你信不信，手册页并不是为了隐藏信息 —— 只是因为信息量太大，这些页面必须要有结构，而且信息是以尽可能简短的形式给出的。这些解释相当简略，需要一些时间来适应，但一旦你掌握了使用它们的技巧，你就会发现它们实际上是多么有用。\n入门 这些页面是通过一个叫做 man 的工具查看的，使用它的命令相当简单。在最简单的情况下，要使用 man，你要在命令行上输入 man，后面加一个空格和你想查询的命令，比如 ls 或 cp，像这样：\nman ls man 会打开 ls 命令的手册页。\n你可以用方向键上下移动，按 q 退出查看手册页。通常情况下，手册页是用 less 打开的，所以 less 命令的键盘快捷键在 man 中也可以使用。\n例如，你可以用 /search_term 来搜索一个特定的文本，等等。\n有一个关于手册页的介绍，这是一篇值得阅读介绍。它非常详细地说明了手册页是如何布局和组织的。\n要看这个页面，请打开一个终端，然后输入：\nman man 节 在你开始更深入地研究手册页之前，知道手册页有一个固定的页面布局和一个归档方案会有帮助。这可能会让新手感到困惑，因为我可以说：“看手册页中关于 ls 的 NAME 节（section）”，我也可以说：“看第 5 节（section）中的 passwd 的手册页。”\n这个词，“节（section）” 被用于两种不同的方式，但并不总是向新人解释其中的区别。\n我不确定为什么会出现这种混淆，但我在培训新用户和初级系统管理员时看到过几次这种混淆。我认为这可能是隧道视野，专注于一件事会使一个人忘记另一件事。一叶障目，不见泰山。\n对于那些已经知道其中的区别的人，你可以跳过这一小节。这一部分是针对那些刚接触到手册页的人。\n这就是区别：\n对于手册页\n单独的手册页是用来显示信息块的。例如，每个手册页都有一个“NAME”节，显示命令的名称和简短的描述。还会有另一个信息块，称为“SYNOPSIS”，显示该命令是如何使用的，以此类推。\n每个手册页都会有这些，以及其他的标题。这些在各个手册页上的节，或者说标题，有助于保持事情的一致性和信息的分工。\n对于手册\n使用“节”，如 “查看第 5 节中的 passwd 的手册页”，是指整个手册的内容。当我们只看一页时，很容易忽略这一点，但是 passwd 手册页是同一本手册的一部分，该手册还有 ls、rm、date、cal 等的手册页。\n整个 Linux 手册是巨大的；它有成千上万的手册页。其中一些手册页有专门的信息。有些手册页有程序员需要的信息，有些手册页有网络方面的独特信息，还有一些是系统管理员会感兴趣的。\n这些手册页根据其独特的目的被分组。想想看，把整个手册分成几个章节 —— 每章有一个特定的主题。有 9 个左右的章节（非常大的章节）。碰巧的是，这些章节被称为“节”。\n总结一下：\n 手册中单页（我们称之为“手册页”）的节是由标题定义的信息块。 这个大的手册（所有页面的集合）中的章节，刚好被称为“节”。  现在你知道区别了，希望本文的其余部分会更容易理解。\n手册页的节 你将会看到不同的手册页，所以让我们先研究一下各个页面的布局。\n手册页被分成几个标题，它们可能因提供者不同而不同，但会有相似之处。一般的分类如下：\n NAME（名称） SYNOPSIS（概要） DESCRIPTION（描述） EXAMPLES（例子） DIAGNOSTICS（诊断） FILES（文件） LIMITS（限制） PORTABILITY（可移植性） SEE ALSO（另见） HISTORY（历史） WARNING（警告）或BUGS（错误） NOTES（注意事项）  NAME - 在这个标题下是命令的名称和命令的简要描述。\nSYNOPSIS - 显示该命令的使用方法。例如，这里是 cal 命令的概要：\ncal [Month] [Year] 概要以命令的名称开始，后面是选项列表。概要采用命令行的一般形式；它显示了你可以输入的内容和参数的顺序。方括号中的参数（[]）是可选的；你可以不输入这些参数，命令仍然可以正常工作。不在括号内的项目必须使用。\n请注意，方括号只是为了便于阅读。当你输入命令时，不应该输入它们。\nDESCRIPTION - 描述该命令或工具的作用以及如何使用它。这一节通常以对概要的解释开始，并说明如果你省略任何一个可选参数会发生什么。对于长的或复杂的命令，这一节可能会被细分。\nEXAMPLES - 一些手册页提供了如何使用命令或工具的例子。如果有这一节，手册页会尝试给出一些简单的使用例子，以及更复杂的例子来说明如何完成复杂的任务。\nDIAGNOSTICS - 本节列出了由命令或工具返回的状态或错误信息。通常不显示不言自明的错误和状态信息。通常会列出可能难以理解的信息。\nFILES - 本节包含了 UNIX 用来运行这个特定命令的补充文件的列表。这里，“补充文件”是指没有在命令行中指定的文件。例如，如果你在看 passwd 命令的手册，你可能会发现 /etc/passwd 列在这一节中，因为 UNIX 是在这里存储密码信息。\nLIMITS - 本节描述了一个工具的限制。操作系统和硬件的限制通常不会被列出，因为它们不在工具的控制范围内。\nPORTABILITY - 列出其他可以使用该工具的系统，以及该工具的其他版本可能有什么不同。\nSEE ALSO - 列出包含相关信息的相关手册页。\nHISTORY - 提供命令的简要历史，如它第一次出现的时间。\nWARNING - 如果有这个部分，它包含了对用户的重要建议。\nNOTES - 不像警告那样严重，但也是重要的信息。\n同样，并不是所有的手册都使用上面列出的确切标题，但它们足够接近，可以遵循。\n手册的节 整个 Linux 手册集合的手册页传统上被划分为有编号的节：\n第 1 节：Shell 命令和应用程序\n第 2 节：基本内核服务 - 系统调用和错误代码\n第 3 节：为程序员提供的库信息\n第 4 节：网络服务 - 如果安装了 TCP/IP 或 NFS 设备驱动和网络协议\n第 5 节：文件格式 - 例如：显示 tar 存档的样子\n第 6 节：游戏\n第 7 节：杂项文件和文档\n第 8 节：系统管理和维护命令\n第 9 节：不知名的内核规格和接口\n将手册页分成这些组，可以使搜索更有效率。在我工作的地方，我有时会做一些编程工作，所以我花了一点时间看第 3 节的手册页。我也做一些网络方面的工作，所以我也知道要涉足网络部分。作为几个实验性机器的系统管理员，我在第 8 节花了很多时间。\n将手册网归入特定的节（章节），使搜索信息更加容易 —— 无论是对需要搜索的人，还是对进行搜索的机器。\n你可以通过名称旁边的数字来判断哪个手册页属于哪个部分。例如，如果你正在看 ls 的手册页，而页面的最上面写着。 LS(1)，那么你正在浏览第 1 节中的 ls 页面，该节包含关于 shell 命令和应用程序的页面。\n下面是另一个例子。如果你在看 passwd 的手册页，页面的顶部显示: PASSWD(1)，说明你正在阅读第 1 节中描述 passwd 命令如何更改用户账户密码的手册页。如果你看到 PASSWD(5)，那么你正在阅读关于密码文件和它是如何组成的的手册页。\npasswd 恰好是两个不同的东西：一个是命令的名称，一个是文件的名称。同样，第 1 节描述了命令，而第 5 节涉及文件格式。\n括号中的数字是重要的线索 —— 这个数字告诉你正在阅读的页面来自哪一节。\n搜索一个特定的节 基本命令：\nman -a name 将在每一节中搜索由 name 标识的手册页，按数字顺序逐一显示。要把搜索限制在一个特定的部分，请在 man 命令中使用一个参数，像这样：\nman 1 name 这个命令将只在手册页的第 1 节中搜索 name。使用我们前面的 passwd 例子，这意味着我们可以保持搜索的针对性。如果我想阅读 passwd 命令的手册页，我可以在终端输入以下内容：\nman 1 passwd man 工具将只在第 1 节中搜索 passwd 并显示它。它不会在任何其他节中寻找 passwd。\n这个命令的另一种方法是输入: man passwd.1。\n搜索包含某个关键词的所有手册页 如果你想获得包含某个关键词的手册页的列表，man 命令中的 -k 选项（通常称为标志或开关）可以派上用场。例如，如果你想看一个关于 ftp 的手册列表，你可以通过输入以下内容得到这个列表：\nman -k ftp 在接下来的列表中，你可以选择一个特定的手册页来阅读。\n在某些系统上，在 man -k 工作之前，系统管理员需要运行一个叫做 catman 的工具。\n了解手册的各个节 有两个有趣的工具可以帮助你搜索信息：whatis和 whereis。\nwhatis\n有的时候，我们完全可以得到我们需要的信息。我们需要的信息有很大的机会是可以找到的 —— 找到它可能是一个小问题。\n例如，如果我想看关于 passwd 文件的手册页，我在终端上输入：\nman passwd 我就会看到关于 passwd 命令所有信息的手册页，但没有关于 passwd 文件的内容。我知道 passwd 是一个命令，也有一个 passwd 文件，但有时，我可能会忘记这一点。这时我才意识到，文件结构在手册页中的不同节，所以我输入了：\nman 4 passwd 我得到这样的答复：\nNo manual entry for passwd in section 4 See 'man 7 undocumented' for help when manual pages are not available. 又是一次健忘的失误。文件结构在 System V UNIX 页面的第 4 节中。几年前，当我建立文件时，我经常使用 man 4 ...；这仍然是我的一个习惯。那么它在 Linux 手册中的什么地方呢？\n现在是时候调用 whatis 来纠正我了。为了做到这一点，我在我的终端中输入以下内容：\nwhatis passwd 然后我看到以下内容：\npasswd (1) - change user password passwd (1ssl) - compute password hashes passwd (5) - the password file 啊！passwd 文件的页面在第 5 节。现在没问题了，可以访问我想要的信息了：\nman 5 passwd 然后我被带到了有我需要的信息的手册页。\nwhatis 是一个方便的工具，可以用简短的一句话告诉你一个命令的作用。想象一下，你想知道 cal 是做什么的，而不想查看手册页。只要在命令提示符下键入以下内容。\nwhatis cal 你会看到这样的回应：\ncal (1) - displays a calendar and the date of Easter 现在你知道了 whatis 命令，我可以告诉你一个秘密 —— 有一个 man 命令的等价物。为了得到这个，我们使用 -f 开关：man -f ...。\n试试吧。在终端提示下输入 whatis cal。执行后就输入：man -f cal。两个命令的输出将是相同的。\nwhereis\nwhereis 命令的名字就说明了这一点 —— 它告诉你一个程序在文件系统中的位置。它也会告诉你手册页的存放位置。再以 cal 为例，我在提示符下输入以下内容：\nwhereis cal 我将看到这个：\ncal: /usr/bin/cal /usr/share/man/man1/cal.1.gz 仔细看一下这个回答。答案只在一行里，但它告诉我两件事：\n /usr/bin/cal 是 cal 程序所在的地方，以及 /usr/share/man/man1/cal.1.gz 是手册页所在的地方（我也知道手册页是被压缩的，但不用担心 —— man 命令知道如何即时解压）。  whereis 依赖于 PATH 环境变量；它只能告诉你文件在哪里，如果它们在你的 PATH 环境变量中。\n你可能想知道是否有一个与 whereis 相当的 man 命令。没有一个命令可以告诉你可执行文件的位置，但有一个开关可以告诉你手册页的位置。在这个例子中使用 date 命令，如果我们输入：\nwhereis date 在终端提示符下，我们会看到：\ndate: /usr/bin/date /usr/share/man/man1/date.1.gz 我们看到 date 程序在 /usr/bin/ 目录下，其手册页的名称和位置是：/usr/share/man/man1/date.1.gz。\n我们可以让 man 像 whereis 一样行事，最接近的方法是使用 -w 开关。我们不会得到程序的位置，但我们至少可以得到手册页的位置，像这样：\nman -w date 我们将看到这样的返回：\n/usr/share/man/man1/date.1.gz 你知道了 whatis 和 whereis，以及让 man 命令做同样（或接近）事情的方法。我展示了这两种方法，有几个不同的原因。\n多年来，我使用 whatis 和 whereis，因为它们在我的培训手册中。直到最近我才了解到 man -f ... 和 man -w ...。我确信我看了几百次 man 的手册页，但我从未注意到 -f 和 -w 开关。我总是在看手册页的其他东西（例如：man -k ...）。我只专注于我需要找到的东西，而忽略了其他的东西。一旦我找到了我需要的信息，我就会离开这个页面，去完成工作，而不去注意这个命令所提供的其他一些宝贝。\n这没关系，因为这部分就是手册页的作用：帮助你完成工作。\n直到最近我向别人展示如何使用手册页时，我才花时间去阅读 —— “看看还有什么可能” —— 我们才真正注意到关于 man 命令的 -f 和 -w 标记可以做什么的信息。\n不管你使用 Linux 多久了，或者多么有经验，总有一些新东西需要学习。\n手册页会告诉你在完成某项任务时可能需要知道的东西 —— 但它们也有很多内容 —— 足以让你看起来像个魔术师，但前提是你要花时间去读。\n结论 如果你花一些时间和精力在手册页上，你将会取得胜利。你对手册页的熟练程度，将在你掌握 Linux 的过程中发挥巨大作用。\ntldr Collaborative cheatsheets for console commands\n“TLDR” 是流行的互联网行话，意思是“太长不读（to long didn\u0026rsquo;t read）”。这就是他们创建 tldr 的想法。如果你觉得手册页太长而不想阅读，tldr 通过提供命令的实际例子而将其简化了。\nls ls 命令可以列出一个 POSIX 系统上的文件。这是一个简单的命令，但它经常被低估，不是它能做什么（因为它确实只做了一件事），而是你该如何优化对它的使用。\nGNU 还是 BSD？ 在了解 ls 的隐藏能力之前，你必须确定你正在运行哪个 ls 命令。有两个最流行的版本：包含在 GNU coreutils 包中的 GNU 版本，以及 BSD 版本。如果你正在运行 Linux，那么你很可能已经安装了 GNU 版本的 ls。如果你正在运行 BSD 或 MacOS，那么你有的是 BSD 版本。本文会介绍它们的不同之处。\n你可以使用 --version 选项找出你计算机上的版本：\n$ ls --version 如果它返回有关 GNU coreutils 的信息，那么你拥有的是 GNU 版本。如果它返回一个错误，你可能正在运行的是 BSD 版本（运行 man ls | head 以确定）。\n你还应该调查你的发行版可能具有哪些预设选项。终端命令的自定义通常放在 $HOME/.bashrc 或 $HOME/.bash_aliases 或 $HOME/.profile 中，它们是通过将 ls 别名化为更复杂的 ls 命令来完成的。例如：\nalias ls=\u0026#39;ls --color\u0026#39; 发行版提供的预设非常有用，但它们确实很难分辨出哪些是 ls 本身的特性，哪些是它的附加选项提供的。你要是想要运行 ls 命令本身而不是它的别名，你可以用反斜杠“转义”命令：\n$ \\ls 分类 单独运行 ls 会以适合你终端的列数列出文件：\n$ ls ~/example bunko jdk-10.0.2 chapterize otf2ttf.ff despacer overtar.sh estimate.sh pandoc-2.7.1 fop-2.3 safe_yaml games tt 这是有用的信息，但所有这些文件看起来基本相同，没有方便的图标来快速表示出哪个是目录、文本文件或图像等等。\n使用 -F（或 GNU 上的长选项 --classify）以在每个条目之后显示标识文件类型的指示符：\n$ ls ~/example bunko jdk-10.0.2/ chapterize* otf2ttf.ff* despacer* overtar.sh* estimate.sh pandoc@ fop-2.3/ pandoc-2.7.1/ games/ tt* 使用此选项，终端中列出的项目使用简写符号来按文件类型分类：\n 斜杠（/）表示目录（或“文件夹”）。 星号（*）表示可执行文件。这包括二进制文件（编译代码）以及脚本（具有可执行权限的文本文件）。 符号（@）表示符号链接（或“别名”）。 等号（=）表示套接字。 在 BSD 上，百分号（%）表示涂改whiteout（某些文件系统上的文件删除方法）。 在 GNU 上，尖括号（\u0026gt;）表示门door（Illumos 和 Solaris上的进程间通信）。 竖线（|）表示 FIFO 管道。 这个选项的一个更简单的版本是 -p，它只区分文件和目录。  （LCTT 译注：在支持彩色的终端上，使用 --color 选项可以以不同的颜色来区分文件类型，但要注意如果将输出导入到管道中，则颜色消失。）\n长列表 从 ls 获取“长列表”的做法是如此常见，以至于许多发行版将 ll 别名为 ls -l。长列表提供了许多重要的文件属性，例如权限、拥有每个文件的用户、文件所属的组、文件大小（以字节为单位）以及文件上次更改的日期：\n$ ls -l -rwxrwx---. 1 seth users 455 Mar 2 2017 estimate.sh -rwxrwxr-x. 1 seth users 662 Apr 29 22:27 factorial -rwxrwx---. 1 seth users 20697793 Jun 29 2018 fop-2.3-bin.tar.gz -rwxrwxr-x. 1 seth users 6210 May 22 10:22 geteltorito -rwxrwx---. 1 seth users 177 Nov 12 2018 html4mutt.sh [...] 如果你不想以字节为单位，请添加 -h 标志（或 GNU 中的 --human）以将文件大小转换为更加人性化的表示方法：\n$ ls --human -rwxrwx---. 1 seth users 455 Mar 2 2017 estimate.sh -rwxrwxr-x. 1 seth seth 662 Apr 29 22:27 factorial -rwxrwx---. 1 seth users 20M Jun 29 2018 fop-2.3-bin.tar.gz -rwxrwxr-x. 1 seth seth 6.1K May 22 10:22 geteltorito -rwxrwx---. 1 seth users 177 Nov 12 2018 html4mutt.sh 要看到更少的信息，你可以带有 -o 选项只显示所有者的列，或带有 -g 选项只显示所属组的列：\n$ ls -o -rwxrwx---. 1 seth 455 Mar 2 2017 estimate.sh -rwxrwxr-x. 1 seth 662 Apr 29 22:27 factorial -rwxrwx---. 1 seth 20M Jun 29 2018 fop-2.3-bin.tar.gz -rwxrwxr-x. 1 seth 6.1K May 22 10:22 geteltorito -rwxrwx---. 1 seth 177 Nov 12 2018 html4mutt.sh 也可以将两个选项组合使用以显示两者。\n时间和日期格式 ls 的长列表格式通常如下所示：\n-rwxrwx---. 1 seth users 455 Mar 2 2017 estimate.sh -rwxrwxr-x. 1 seth users 662 Apr 29 22:27 factorial -rwxrwx---. 1 seth users 20697793 Jun 29 2018 fop-2.3-bin.tar.gz -rwxrwxr-x. 1 seth users 6210 May 22 10:22 geteltorito -rwxrwx---. 1 seth users 177 Nov 12 2018 html4mutt.sh 月份的名字不便于排序，无论是通过计算还是识别（取决于你的大脑是否倾向于喜欢字符串或整数）。你可以使用 --time-style 选项和格式名称更改时间戳的格式。可用格式为：\n full-iso：ISO 完整格式（1970-01-01 21:12:00） long-iso：ISO 长格式（1970-01-01 21:12） iso：iso 格式（01-01 21:12） locale：本地化格式（使用你的区域设置） posix-STYLE：POSIX 风格（用区域设置定义替换 STYLE）  你还可以使用 date 命令的正式表示法创建自定义样式。\n按时间排序 通常，ls 命令按字母顺序排序。你可以使用 -t 选项根据文件的最近更改的时间（最新的文件最先列出）进行排序。\n例如：\n$ touch foo bar baz $ ls bar baz foo $ touch foo $ ls -t foo bar baz 列出方式 ls 的标准输出平衡了可读性和空间效率，但有时你需要按照特定方式排列的文件列表。\n要以逗号分隔文件列表，请使用 -m：\nls -m ~/example bar, baz, foo 要强制每行一个文件，请使用 -1 选项（这是数字 1，而不是小写的 L）：\n$ ls -1 ~/bin/ bar baz foo 要按文件扩展名而不是文件名对条目进行排序，请使用 -X（这是大写 X）：\n$ ls bar.xfc baz.txt foo.asc $ ls -X foo.asc baz.txt bar.xfc 隐藏杂项 在某些 ls 列表中有一些你可能不关心的条目。例如，元字符 . 和 .. 分别代表“本目录”和“父目录”。如果你熟悉在终端中如何切换目录，你可能已经知道每个目录都将自己称为 .，并将其父目录称为 ..，因此当你使用 -a 选项显示隐藏文件时并不需要它经常提醒你。\n要显示几乎所有隐藏文件（. 和 .. 除外），请使用 -A 选项：\n$ ls -a . .. .android .atom .bash_aliases [...] $ ls -A .android .atom .bash_aliases [...] 有许多优秀的 Unix 工具有保存备份文件的传统，它们会在保存文件的名称后附加一些特殊字符作为备份文件。例如，在 Vim 中，备份会以在文件名后附加 ~ 字符的文件名保存。\n这些类型的备份文件已经多次使我免于愚蠢的错误，但是经过多年享受它们提供的安全感后，我觉得不需要用视觉证据来证明它们存在。我相信 Linux 应用程序可以生成备份文件（如果它们声称这样做的话），我很乐意相信它们存在 —— 而不用必须看到它们。\n要隐藏备份文件，请使用 -B 或 --ignore-backups 隐藏常用备份格式（此选项在 BSD 的 ls 中不可用）：\n$ ls bar.xfc baz.txt foo.asc~ foo.asc $ ls -B bar.xfc baz.txt foo.asc 当然，备份文件仍然存在；它只是过滤掉了，你不必看到它。\n除非另有配置，GNU Emacs 在文件名的开头和结尾添加哈希字符（＃）来保存备份文件（#file＃）。其他应用程序可能使用不同的样式。使用什么模式并不重要，因为你可以使用 --hide 选项创建自己的排除项：\n$ ls bar.xfc baz.txt #foo.asc# foo.asc $ ls --hide=\u0026#34;#*#\u0026#34; bar.xfc baz.txt foo.asc 递归地列出目录 除非你在指定目录上运行 ls，否则子目录的内容不会与 ls 命令一起列出：\n$ ls -F example/ quux* xyz.txt $ ls -R quux xyz.txt ./example: bar.xfc baz.txt #foo.asc# foo.asc 使用别名使其永久化 ls 命令可能是 shell 会话期间最常使用的命令。这是你的眼睛和耳朵，为你提供上下文信息和确认命令的结果。虽然有很多选项很有用，但 ls 之美的一部分就是简洁：两个字符和回车键，你就知道你到底在哪里以及附近有什么。如果你不得不停下思考（更不用说输入）几个不同的选项，它会变得不那么方便，所以通常情况下，即使最有用的选项也不会用了。\n解决方案是为你的 ls 命令添加别名，以便在使用它时，你可以获得最关心的信息。\n要在 Bash shell 中为命令创建别名，请在主目录中创建名为 .bash_aliases 的文件（必须在开头包含 .）。 在此文件中，列出要创建的别名，然后是要为其创建别名的命令。例如：\nalias ls=\u0026#39;ls -A -F -B --human --color\u0026#39; 这一行导致你的 Bash shell 将 ls 命令解释为 ls -A -F -B --human --color。\n你不必仅限于重新定义现有命令，还可以创建自己的别名：\nalias ll=\u0026#39;ls -l\u0026#39; alias la=\u0026#39;ls -A\u0026#39; alias lh=\u0026#39;ls -h\u0026#39; 要使别名起作用，shell 必须知道 .bash_aliases 配置文件存在。在编辑器中打开 .bashrc 文件（如果它不存在则创建它），并包含以下代码块：\nif [ -e $HOME/.bash_aliases ]; then source $HOME/.bash_aliases fi 每次加载 .bashrc（这是一个新的 Bash shell 启动的时候），Bash 会将 .bash_aliases 加载到你的环境中。你可以关闭并重新启动 Bash 会话，或者直接强制它执行此操作：\n$ source ~/.bashrc 如果你忘了你是否有别名命令，which 命令可以告诉你：\n$ which ls alias ls=\u0026#39;ls -A -F -B --human --color\u0026#39; /usr/bin/ls 如果你将 ls 命令别名为带有选项的 ls 命令，则可以通过将反斜杠前缀到 ls 前来覆盖你的别名。例如，在示例别名中，使用 -B 选项隐藏备份文件，这意味着无法使用 ls 命令显示备份文件。 可以覆盖该别名以查看备份文件：\n$ ls bar baz foo $ \\ls bar baz baz~ foo 做一件事，把它做好 ls 命令有很多选项，其中许多是特定用途的或高度依赖于你所使用的终端。在 GNU 系统上查看 info ls，或在 GNU 或 BSD 系统上查看 man ls 以了解更多选项。\n你可能会觉得奇怪的是，一个以每个工具“做一件事，把它做好”的前提而闻名的系统会让其最常见的命令背负 50 个选项。但是 ls 只做一件事：它列出文件，而这 50 个选项允许你控制接收列表的方式，ls 的这项工作做得非常、非常好。\nexa A modern replacement for ‘ls’.\ndu (Disk Usage) 在 Linux 中使用 ls 命令 列出的目录内容中，目录的大小仅显示 4KB。这是一个默认的大小，是用来存储磁盘上存储目录的元数据的大小。\ndu 命令 表示 磁盘使用率。这是一个标准的 Unix 程序，用于估计当前工作目录中的文件空间使用情况。\n它使用递归方式总结磁盘使用情况，以获取目录及其子目录的大小。\n$ du -hs --max-depth=0 /path/dir  du – 这是一个命令 -h – 以易读的格式显示大小 (例如 1K 234M 2G) -s – 仅显示每个参数的总数 --max-depth=N – 目录的打印深度  NCurses Disk Usage Ncdu is a disk usage analyzer with an ncurses interface.\nncdu 命令旨在提供一份关于你在硬盘上使用的空间的交互式报告。\ngdu Fast disk usage analyzer with console interface written in Go\nDiff diff是Unix系统的一个很重要的工具程序。\n它用来比较两个文本文件的差异，是代码版本管理的基石之一。你在命令行下，输入：\n$ diff \u0026lt;变动前的文件\u0026gt; \u0026lt;变动后的文件\u0026gt; diff就会告诉你，这两个文件有何差异。它的显示结果不太好懂，下面我就来说明，如何读懂diff。\n三种格式 由于历史原因，diff有三种格式：\n 正常格式（normal diff） 上下文格式（context diff） 合并格式（unified diff）  我们依次来看。\n示例文件 为了便于讲解，先新建两个示例文件。\n第一个文件叫做f1，内容是每行一个a，一共7行。\na a a a a a a 第二个文件叫做f2，修改f1而成，第4行变成b，其他不变。\na a a b a a a 正常格式 现在对f1和f2进行比较：\n$ diff f1 f2 这时，diff就会显示正常格式的结果：\n4c4 \u0026lt; a --- \u0026gt; b 第一行是一个提示，用来说明变动位置。\n4c4 它分成三个部分：前面的\u0026quot;4\u0026rdquo;，表示f1的第4行有变化；中间的\u0026quot;c\u0026quot;表示变动的模式是内容改变（change），其他模式还有\u0026quot;增加\u0026quot;（a，代表addition）和\u0026quot;删除\u0026quot;（d，代表deletion）；后面的\u0026quot;4\u0026quot;，表示变动后变成f2的第4行。\n第二行分成两个部分。\n\u0026lt; a 前面的小于号，表示要从f1当中去除该行（也就是第4行），后面的\u0026quot;a\u0026quot;表示该行的内容。\n第三行用来分割f1和f2。\n--- 第四行，类似于第二行。\n\u0026gt; b 前面的大于号表示f2增加了该行，后面的\u0026quot;b\u0026quot;表示该行的内容。\n最早的Unix（即AT\u0026amp;T版本的Unix），使用的就是这种格式的diff。\n上下文格式 上个世纪80年代初，加州大学伯克利分校推出BSD版本的Unix时，觉得diff的显示结果太简单，最好加入上下文，便于了解发生的变动。因此，推出了上下文格式的diff。\n它的使用方法是加入c参数（代表context）。\n$ diff -c f1 f2 显示结果如下：\n*** f1 2012-08-29 16:45:41.000000000 +0800 --- f2 2012-08-29 16:45:51.000000000 +0800 *************** *** 1,7 **** a a a !a a a a --- 1,7 ---- a a a !b a a a 这个结果分成四个部分。\n第一部分的两行，显示两个文件的基本情况：文件名和时间信息。\n*** f1 2012-08-29 16:45:41.000000000 +0800 --- f2 2012-08-29 16:45:51.000000000 +0800 ***表示变动前的文件，---表示变动后的文件。\n第二部分是15个星号，将文件的基本情况与变动内容分割开。\n*************** 第三部分显示变动前的文件，即f1。\n*** 1,7 **** a a a !a a a a 这时不仅显示发生变化的第4行，还显示第4行的前面三行和后面三行，因此一共显示7行。所以，前面的*** 1,7 ****就表示，从第1行开始连续7行。\n另外，文件内容的每一行最前面，还有一个标记位。如果为空，表示该行无变化；如果是感叹号（!），表示该行有改动；如果是减号（-），表示该行被删除；如果是加号（+），表示该行为新增。\n第四部分显示变动后的文件，即f2。\n--- 1,7 ---- a a a !b a a a 除了变动行（第4行）以外，也是上下文各显示三行，总共显示7行。\n合并格式 如果两个文件相似度很高，那么上下文格式的diff，将显示大量重复的内容，很浪费空间。1990年，GNU diff率先推出了\u0026quot;合并格式\u0026quot;的diff，将f1和f2的上下文合并在一起显示。\n它的使用方法是加入u参数（代表unified）。\n$ diff -u f1 f2 显示结果如下：\n--- f1 2012-08-29 16:45:41.000000000 +0800 +++ f2 2012-08-29 16:45:51.000000000 +0800 @@ -1,7 +1,7 @@ a a a -a +b a a a 它的第一部分，也是文件的基本信息。\n--- f1 2012-08-29 16:45:41.000000000 +0800 +++ f2 2012-08-29 16:45:51.000000000 +0800 ---表示变动前的文件，+++表示变动后的文件。\n第二部分，变动的位置用两个@作为起首和结束。\n@@ -1,7 +1,7 @@ 前面的\u0026quot;-1,7\u0026quot;分成三个部分：减号表示第一个文件（即f1），\u0026ldquo;1\u0026quot;表示第1行，\u0026ldquo;7\u0026quot;表示连续7行。合在一起，就表示下面是第一个文件从第1行开始的连续7行。同样的，\u0026quot;+1,7\u0026quot;表示变动后，成为第二个文件从第1行开始的连续7行。\n第三部分是变动的具体内容。\na a a -a +b a a a 除了有变动的那些行以外，也是上下文各显示3行。它将两个文件的上下文，合并显示在一起，所以叫做\u0026quot;合并格式\u0026rdquo;。每一行最前面的标志位，空表示无变动，减号表示第一个文件删除的行，加号表示第二个文件新增的行。\ngit格式 版本管理系统git，使用的是合并格式diff的变体。\n$ git diff 显示结果如下：\ndiff --git a/f1 b/f1 index 6f8a38c..449b072 100644 --- a/f1 +++ b/f1 @@ -1,7 +1,7 @@ a a a -a +b a a a 第一行表示结果为git格式的diff。\ndiff --git a/f1 b/f1 进行比较的是，a版本的f1（即变动前）和b版本的f1（即变动后）。\n第二行表示两个版本的git哈希值（index区域的6f8a38c对象，与工作目录区域的449b072对象进行比较），最后的六位数字是对象的模式（普通文件，644权限）。　index 6f8a38c..449b072 100644 第三行表示进行比较的两个文件。\n--- a/f1 +++ b/f1 ---表示变动前的版本，+++表示变动后的版本。\n后面的行都与官方的合并格式diff相同。\n@@ -1,7 +1,7 @@ a a a -a +b a a a Crontab 使用 crontab 命令来执行定时任务。所谓定时任务，就是未来的某个或多个时点，预定要执行的任务，比如每五分钟收一次邮件、每天半夜两点分析一下日志等等。\nInstalling Cron $ sudo apt install cronie Running the Crond Service $ systemctl enable crond.service $ systemctl start crond.service crontab 命令详解 crontab 命令通过 /etc/cron.allow 和 /etc/cron.deny 文件来限制某些用户是否可以使用 crontab 命令：\n 当系统中有 /etc/cron.allow 文件时，只有写入此文件的用户可以使用 crontab 命令，没有写入的用户不能使用 crontab 命令。 当系统中只有 /etc/cron.deny 文件时，写入此文件的用户不能使用 crontab 命令，没有写入文件的用户可以使用 crontab 命令。 /etc/cron.allow 文件比 /etc/cron.deny 文件的优先级高，Linux 系统中默认只有 /etc/cron.deny 文件。  crontab 命令的基本格式如下：\ncrontab [选项] [file] 注意，这里的 file 指的是命令文件的名字，表示将 file 作为 crontab 的任务列表文件并载入 crontab，若在命令行中未指定文件名，则此命令将接受标准输入（键盘）上键入的命令，并将它们键入 crontab。\n常用选项    选项 功能     -u user 用来设定某个用户的 crontab 服务，例如 \u0026ldquo;-u demo\u0026rdquo; 表示设备 demo 用户的 crontab 服务，此选项一般有 root 用户来运行。   -e 编辑某个用户的 crontab 文件内容。如果不指定用户，则表示编辑当前用户的 crontab 文件。   -l 显示某用户的 crontab 文件内容，如果不指定用户，则表示显示当前用户的 crontab 文件内容。   -r 从 /var/spool/cron 删除某用户的 crontab 文件，如果不指定用户，则默认删除当前用户的 crontab 文件。   -i 在删除用户的 crontab 文件时，给确认提示。    crontab 文件格式 * * * * * 执行的任务 执行的任务字段既可以定时执行系统命令，也可以定时执行某个 Shell 脚本。\n执行时间\n   项目 含义 范围     第一个\u0026rdquo;*\u0026quot; 一小时当中的第几分钟（minute） 0~59   第二个\u0026quot;*\u0026quot; 一天当中的第几小时（hour） 0~23   第三个\u0026quot;*\u0026quot; 一个月当中的第几天（day） 1~31   第四个\u0026quot;*\u0026quot; 一年当中的第几个月（month） 1~12   第五个\u0026quot;*\u0026quot; 一周当中的星期几（week） 0~7（0和7都代表星期日）    时间特殊符号\n   特殊符号 含义     *（星号） 代表任何时间。比如第一个\u0026quot;*\u0026ldquo;就代表一小时种每分钟都执行一次的意思。   ,（逗号） 代表不连续的时间。比如\u0026quot;0 8，12，16***命令\u0026quot;就代表在每天的 8 点 0 分、12 点 0 分、16 点 0 分都执行一次命令。   -（中杠） 代表连续的时间范围。比如\u0026quot;0 5 ** 1-6命令\u0026rdquo;，代表在周一到周六的凌晨 5 点 0 分执行命令。   /（正斜线） 代表每隔多久执行一次。比如\u0026quot;*/10****命令\u0026quot;，代表每隔 10 分钟就执行一次命令。    当“crontab -e”编辑完成之后，一旦保存退出，那么这个定时任务实际就会写入 /var/spool/cron/ 目录中，每个用户的定时任务用自己的用户名进行区分。而且 crontab 命令只要保存就会生效，只要 crond 服务是启动的。\ncrontab举例\n   时间 含义     45 22 ***命令 在每天 22 点 45 分执行命令   0 17 ** 1命令 在每周一的 17 点 0 分执行命令   0 5 1，15**命令 在每月 1 日和 15 日的凌晨 5 点 0 分执行命令   40 4 ** 1-5命令 在每周一到周五的凌晨 4 点 40 分执行命令   */10 4 ***命令 在每天的凌晨 4 点，每隔 10 分钟执行一次命令   0 0 1，15 * 1命令 在每月 1 日和 15 日，每周一 0 点 0 分都会执行命令    注意事项\n 6 个选项都不能为空，必须填写。如果不确定，则使用“*”代表任意时间。 crontab 定时任务的最小有效时间是分钟，最大有效时间是月。像 2018 年某时执行、3 点 30 分 30 秒这样的时间都不能被识别。 在定义时间时，日期和星期最好不要在一条定时任务中出现，因为它们都以天为单位，非常容易让管理员混淆。 在定时任务中，不管是直接写命令，还是在脚本中写命令，最好都使用绝对路径。有时使用相对路径的命令会报错。  ps 简介 要对进程进行监测和控制，首先必须要了解当前进程的情况，也就是需要查看当前进程，而 ps 命令（Process Status）就是最基本同时也是非常强大的进程查看命令。使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等等。总之大部分信息都是可以通过执行该命令得到的。ps命令列出的是当前那些进程的快照，就是执行ps命令的那个时刻的那些进程，如果想要动态的显示进程信息，就可以使用top命令。\nlinux上进程有5种状态：\n  就绪状态和运行状态\n就绪状态的状态标志state的值为TASK_RUNNING。此时，程序已被挂入运行队列，处于准备运行状态。一旦获得处理器使用权，即可进入运行状态。\n当进程获得处理器而运行时 ，state的值仍然为TASK_RUNNING，并不发生改变；但Linux会把一个专门用来指向当前运行任务的指针current指向它，以表示它是一个正在运行的进程。\n  可中断等待状态\n状态标志state的值为TASK_INTERRUPTIBL。此时，由于进程未获得它所申请的资源而处在等待状态。一旦资源有效或者有唤醒信号，进程会立即结束等待而进入就绪状态。\n  不可中断等待状态\n状态标志state的值为TASK_UNINTERRUPTIBL。此时，进程也处于等待资源状态。一旦资源有效，进程会立即进入就绪状态。这个等待状态与可中断等待状态的区别在于：处于TASK_UNINTERRUPTIBL状态的进程不能被信号量或者中断所唤醒，只有当它申请的资源有效时才能被唤醒。\n这个状态被应用在内核中某些场景中，比如当进程需要对磁盘进行读写，而此刻正在DMA中进行着数据到内存的拷贝，如果这时进程休眠被打断（比如强制退出信号）那么很可能会出现问题，所以这时进程就会处于不可被打断的状态下。\n  停止状态\n状态标志state的值为TASK_STOPPED。当进程收到一个SIGSTOP信号后，就由运行状态进入停止状态，当受到一个SIGCONT信号时，又会恢复运行状态。这种状态主要用于程序的调试，又被叫做“暂停状态”、“挂起状态”。\n  中止状态\n状态标志state的值为TASK_DEAD。进程因某种原因而中止运行，进程占有的所有资源将被回收，除了task_struct结构（以及少数资源）以外，并且系统对它不再予以理睬，所以这种状态也叫做“僵死状态”，进程成为僵尸进程。\n  ps 标识进程状态对应的 5 种状态码：\n R：就绪状态和运行状态 runnable (on run queue) S：可中断等待状态 sleeping D：不可中断等待状态 uninterruptible sleep (usually IO) T：停止状态 traced or stopped Z：中止状态 a defunct (”zombie”) process  ps 标识进程的其他状态码：\n X：死掉的进程 Dead （应该不会出现） W：内存交互状态Paging （从 2.6 内核开始无效） N：高优先级 \u0026lt;：低优先级 s：包含子进程 L：被锁入内存 l：多线程状态 +：前台进程  命令参数 在不同的 Linux 发行版上，ps 命令的语法各不相同，为此，Linux 采取了一个折中的方法，即融合各种不同的风格，兼顾那些已经习惯了其它系统上使用 ps 命令的用户。ps命令支持三种使用的语法格式：\n UNIX 风格，选项可以组合在一起，并且选项前必须有“-”连字符； BSD 风格，选项可以组合在一起，但是选项前不能有“-”连字符； GNU 风格的选项，选项前有两个“-”连字符；  ps 命令常用的参数：\nps -a 显示所有终端下执行的进程，包含其他用户的进程 ps -A 显示所有进程 ps -e 和-A功能一样 ps -H 显示树状结构，表示程序间的相互关系 ps -f 全格式显示进程 ps a 显示当前终端下执行的进程 ps c 显示进程的真实名称 ps e 列出程序所使用的环境变量 ps f 用ASCII字符显示树状结构，表达程序间的相互关系 ps x 显示所有进程，无论是否运行在终端上 ps u 显示用户相关的进程或者与用户相关的属性 ps r 只显示正在运行的进程 使用实例 大家如果执行 man ps 命令，则会发现 ps 命令的帮助为了适应不同的类 UNIX 系统，可用格式非常多，不方便记忆。所以，我建议大家记忆几个固定选项即可。\nps aux 查看系统中所有的进程\n# ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.2 2872 1416 ? Ss Jun04 0:02 /sbin/init root 2 0.0 0.0 0 0 ? S Jun04 0:00 [kthreadd] root 3 0.0 0.0 0 0 ? S Jun04 0:00 [migration/0] root 4 0.0 0.0 0 0 ? S Jun04 0:00 [ksoftirqd/0] …省略部分输出… 输出信息中各列的具体含义：\n   表头 含义     USER 该进程是由哪个用户产生的。   PID 进程的 ID。   %CPU 该进程占用 CPU 资源的百分比，占用的百分比越高，进程越耗费资源。   %MEM 该进程占用物理内存的百分比，占用的百分比越高，进程越耗费资源。   VSZ 该进程占用虚拟内存的大小，单位为 KB。   RSS 该进程占用实际物理内存的大小，单位为 KB。   TTY 该进程是在哪个终端运行的。其中，tty1 ~ tty7 代表本地控制台终端（可以通过 Alt+F1 ~ F7 快捷键切换不同的终端），tty1~tty6 是本地的字符界面终端，tty7 是图形终端。pts/0 ~ 255 代表虚拟终端，一般是远程连接的终端，第一个远程连接占用 pts/0，第二个远程连接占用 pts/1，依次増长。   STAT 进程状态。   START 该进程的启动时间。   TIME 该进程占用 CPU 的运算时间，注意不是系统时间。   COMMAND 产生此进程的命令名。    ps -le 查看系统中所有的进程\nps aux 命令可以看到系统中所有的进程，ps -le 命令也能看到系统中所有的进程。由于 -l 选项的作用，所以 ps -le 命令能够看到更加详细的信息，比如父进程的 PID、优先级等。但是这两个命令的基本作用是一致的，掌握其中一个就足够了。\n# ps -le F S UID PID PPID C PRI Nl ADDR SZ WCHAN TTY TIME CMD 4 S 0 1 0 0 80 0 - 718 - ? 00:00:02 init 1 S 0 2 0 0 80 0 - 0 - ? 00:00:00 kthreadd 1 S 0 3 2 0 -40 - - 0 - ? 00:00:00 migration/0 1 S 0 4 2 0 80 0 - 0 - ? 00:00:00 ksoflirqd/0 1 S 0 5 2 0 -40 - - 0 - ? 00:00:00 migration/0 …省略部分输出… 输出信息中各列的含义：\n   表头 含义     F 进程标志，说明进程的权限，常见的标志有两个: 1：进程可以被复制，但是不能被执行；4：进程使用超级用户权限；   S 进程状态。具体的状态和\u0026quot;psaux\u0026quot;命令中的 STAT 状态一致；   UID 运行此进程的用户的 ID；   PID 进程的 ID；   PPID 父进程的 ID；   C 该进程的 CPU 使用率，单位是百分比；   PRI 进程的优先级，数值越小，该进程的优先级越高，越早被 CPU 执行；   NI 进程的优先级，数值越小，该进程越早被执行；   ADDR 该进程在内存的哪个位置；   SZ 该进程占用多大内存；   WCHAN 该进程是否运行。\u0026quot;-\u0026ldquo;代表正在运行；   TTY 该进程由哪个终端产生；   TIME 该进程占用 CPU 的运算时间，注意不是系统时间；   CMD 产生此进程的命令名；    ps -l 查看当前 Shell 产生的进程\n# ps -l F S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD 4 S 0 18618 18614 0 80 0 - 1681 - pts/1 00:00:00 bash 4 R 0 18683 18618 4 80 0 - 1619 - pts/1 00:00:00 ps top 简介 top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。\ntop显示系统当前的进程和其他状况，是一个动态显示过程，即可以通过用户按键来不断刷新当前状态。如果在前台执行该命令，它将独占前台，直到用户终止该程序为止。\n比较准确的说，top命令提供了实时的对系统处理器的状态监视。它将显示系统中CPU最“敏感”的任务列表。该命令可以按CPU使用、内存使用和执行时间对任务进行排序；而且该命令的很多特性都可以通过交互式命令或者在个人定制文件中进行设定。\n命令参数 top 命令的基本格式如下：\n#top [选项] 选项：\n -d 秒数：指定 top 命令每隔几秒更新。默认是 3 秒； -b：使用批处理模式输出。一般和\u0026rdquo;-n\u0026quot;选项合用，用于把 top 命令重定向到文件中； -n 次数：指定 top 命令执行的次数。一般和\u0026quot;-b\u0026quot;选项合用； -p 进程PID：仅查看指定 ID 的进程； -s：使 top 命令在安全模式中运行，避免在交互模式中出现错误； -u 用户名：只监听某个用户的进程；  交互操作指令 在 top 命令的显示窗口中，还可以使用如下按键，进行一下交互操作：\n ? 或 h：显示交互模式的帮助 P：按照 CPU 的使用率排序，默认就是此选项 M：按照内存的使用率排序 N：按照 PID 排序 T：按照 CPU 的累积运算时间排序，也就是按照 TIME+ 项排序 k：按照 PID 给予某个进程一个信号。一般用于中止某个进程，信号 9 是强制中止的信号 r：按照 PID 给某个进程重设优先级（Nice）值 \u0026lt;Space\u0026gt;：立即刷新 s：设置刷新时间间隔 c：显示命令完全模式 t:：显示或隐藏进程和CPU状态信息 m：显示或隐藏内存状态信息 l：显示或隐藏uptime信息 f：增加或减少进程显示标志 S：累计模式，会把已完成或退出的子进程占用的CPU时间累计到父进程的TIME+ u：指定显示用户进程 i：只显示正在运行的进程 W：保存对top的设置到文件 ~/.toprc，下次启动将自动调用toprc文件的设置。 q：退出  使用实例 # top top - 12:26:46 up 1 day, 13:32, 2 users, load average: 0.00, 0.00, 0.00 Tasks: 95 total, 1 running, 94 sleeping, 0 stopped, 0 zombie Cpu(s): 0.1%us, 0.1%sy, 0.0%ni, 99.7%id, 0.1%wa, 0.0%hi, 0.1%si, 0.0%st Mem: 625344k total, 571504k used, 53840k free, 65800k buffers Swap: 524280k total, 0k used, 524280k free, 409280k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 19002 root 20 0 2656 1068 856 R 0.3 0.2 0:01.87 top 1 root 20 0 2872 1416 1200 S 0.0 0.2 0:02.55 init 2 root 20 0 0 0 0 S 0.0 0.0 0:00.03 kthreadd 第一行为任务队列信息\n   内 容 说 明     12:26:46 系统当前时间   up 1 day, 13:32 系统的运行时间.本机己经运行 1 天 13 小时 32 分钟   2 users 当前登录了两个用户   load average: 0.00,0.00，0.00 系统在之前 1 分钟、5 分钟、15 分钟的平均负载。如果 CPU 是单核的，则这个数值超过 1 就是高负载：如果 CPU 是四核的，则这个数值超过 4 就是高负载 （这个平均负载完全是依据个人经验来进行判断的，一般认为不应该超过服务器 CPU 的核数）    第二行为进程信息\n   内 容 说 明     Tasks: 95 total 系统中的进程总数   1 running 正在运行的进程数   94 sleeping 睡眠的进程数   0 stopped 正在停止的进程数   0 zombie 僵尸进程数。如果不是 0，则需要手工检查僵尸进程    第三行为 CPU 信息\n   内 容 说 明     Cpu(s): 0.1 %us 用户模式占用的 CPU 百分比   0.1%sy 系统模式占用的 CPU 百分比   0.0%ni 改变过优先级的用户进程占用的 CPU 百分比   99.7%id 空闲 CPU 占用的 CPU 百分比   0.1%wa 等待输入/输出的进程占用的 CPU 百分比   0.0%hi 硬中断请求服务占用的 CPU 百分比   0.1%si 软中断请求服务占用的 CPU 百分比   0.0%st st（steal time）意为虚拟时间百分比，就是当有虚拟机时，虚拟 CPU 等待实际 CPU 的时间百分比    第四行为物理内存信息\n   内 容 说 明     Mem: 625344k total 物理内存的总量，单位为KB   571504k used 己经使用的物理内存数量   53840k free 空闲的物理内存数量。我们使用的是虚拟机，共分配了 628MB内存，所以只有53MB的空闲内存   65800k buffers/cache 作为缓冲的内存数量    缓冲（buffer）和缓存（cache）的区别：\n 缓存（cache）是在读取硬盘中的数据时，把最常用的数据保存在内存的缓存区中，再次读取该数据时，就不去硬盘中读取了，而在缓存中读取。 缓冲（buffer）是在向硬盘写入数据时，先把数据放入缓冲区,然后再一起向硬盘写入，把分散的写操作集中进行，减少磁盘碎片和硬盘的反复寻道，从而提高系统性能。  简单来说，缓存（cache）是用来加速数据从硬盘中\u0026quot;读取\u0026quot;的，而缓冲（buffer）是用来加速数据\u0026quot;写入\u0026quot;硬盘的。\n第五行为交换分区（swap）信息\n   内 容 说 明     Swap: 524280k total 交换分区（虚拟内存）的总大小   Ok used 已经使用的交换分区的大小   524280k free 空闲交换分区的大小   409280k cached 作为缓存的交换分区的大小    第六行为系统进程信息\n再来看 top 命令的第二部分输出，主要是系统进程信息，各个字段的含义如下：\n PID：进程的 ID。 USER：该进程所属的用户。 PR：优先级，数值越小优先级越高。 NI：优先级，数值越小、优先级越高。 VIRT：该进程使用的虚拟内存的大小，单位为 KB。 RES：该进程使用的物理内存的大小，单位为 KB。 SHR：共享内存大小，单位为 KB。 S：进程状态。 %CPU：该进程占用 CPU 的百分比。 %MEM：该进程占用内存的百分比。 TIME+：该进程共占用的 CPU 时间。 COMMAND：进程的命令名。  htop htop 是一个 Linux 下的交互式的进程浏览器，可以用来替换Linux下的top命令。\n与Linux传统的top相比，htop更加人性化。它可让用户交互式操作，支持颜色主题，可横向或纵向滚动浏览进程列表，并支持鼠标操作。\nbpytop Linux/OSX/FreeBSD resource monitor\nlsof 简介 lsof 命令，“list opened files”的缩写，直译过来，就是列举系统中已经被打开的文件。通过 lsof 命令，我们就可以根据文件找到对应的进程信息，也可以根据进程信息找到进程打开的文件。\n在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。\n在终端下输入lsof即可显示系统打开的文件，因为 lsof 需要访问核心内存和各种文件，所以必须以 root 用户的身份运行它才能够充分地发挥其功能。\n$ sudo lsof | less COMMAND PID TID TASKCMD USER FD TYPE DEVICE SIZE/OFF NODE NAME systemd 1 root cwd DIR 8,2 4096 2 / systemd 1 root rtd DIR 8,2 4096 2 / systemd 1 root txt REG 8,2 1620224 2491035 /usr/lib/systemd/systemd systemd 1 root mem REG 8,2 1369352 2498532 /usr/lib/x86_64-linux-gnu/libm-2.31.so systemd 1 root mem REG 8,2 178528 2490726 /usr/lib/x86_64-linux-gnu/libudev.so.1.6.17 输出各列信息的意义如下：\n  COMMAND：进程的名称\n  PID：进程标识符\n  PPID：父进程标识符（需要指定-R参数）\n  USER：进程所有者\n  PGID：进程所属组\n  FD：文件描述符（filedescriptor，简称 fd），应用程序通过文件描述符识别该文件类型。\n例如 cwd 表示current work dirctory，即应用程序的当前工作目录，这是该应用程序启动的目录，除非它本身对这个目录进行更改。txt 表示该类型的文件是程序代码，如应用程序二进制文件本身或共享库，如上列表中显示的 /usr/lib/systemd/systemd 程序。\n  TYPE：文件类型，如DIR、REG等，常见的文件类型:\n DIR：目录 REG：普通文件 CHR：字符 BLK：块设备类型 UNIX： UNIX 域套接字 FIFO：先进先出 (FIFO) 队列 IPv4：网际协议 (IP) 套接字    DEVICE：指定磁盘的名称\n  SIZE：文件的大小\n  NODE：索引节点（文件在磁盘上的标识）\n  NAME：打开文件的确切名称\n  命令参数    参数 含义     -a 列出打开文件存在的进程   -c \u0026lt;进程名\u0026gt; 列出指定进程名所打开的文件   -g 列出GID号进程详情   -d \u0026lt;文件号\u0026gt; 列出占用该文件号的进程   +d \u0026lt;目录\u0026gt; 列出目录下被打开的文件   +D \u0026lt;目录\u0026gt; 递归列出目录下被打开的文件   -n \u0026lt;目录\u0026gt; 列出使用NFS的文件   -i \u0026lt;条件\u0026gt; 列出符合条件的进程   -p \u0026lt;进程号\u0026gt; 列出指定进程号所打开的文件   -u 列出UID号进程详情   -h 显示帮助信息   -v 显示版本信息    使用实例 查询某个文件被哪个进程调用\n$ lsof /bin/bash 查询某个目录下所有的文件是被哪些进程调用的\n$ lsof +d /usr/lib 查看以httpd开头的进程调用了哪些文件\n$ lsof -c httpd 查询PID是1的进程调用的文件\n$ lsof -p 1 按照用户名查询某个用户的进程调用的文件\n$ lsof -u username 列出某个用户以及某个进程所打开的文件信息\n$ lsof -u test -c mysql 列出所有的网络连接\n$ lsof -i 列出所有tcp 网络连接信息\n$ lsof -i tcp 列出谁在使用某个端口\n$ lsof -i :3306 列出某个用户的所有活跃的网络端口\n$ lsof -a -u test -i 根据文件描述列出对应的文件信息\n$ lsof -d txt 列出被进程号为1234的进程所打开的所有 IPV4 network files\n$ lsof -i 4 -a -p 1234 列出目前连接主机nf5260i5-td上端口为：20，21，80相关的所有文件信息，且每隔3秒重复执行\n$ lsof -i @nf5260i5-td:20,21,80 -r 3 write 在服务器上，有时会有多个用户同时登录，一些必要的沟通就显得尤为重要。比如,我必须关闭某个服务，或者需要重启服务器，当然需要通知同时登录服务器的用户，这时就可以使用 write 命令。\nwrite 命令的信息如下：\n 命令名称：write。 英文原意：send a message to another user。 所在路径：/usr/bin/write。 执行权限：所有用户。 功能描述：向其他用户发送信息。  write 命令的基本格式如下:\n$ write 用户名 [终端号] write 命令没有多余的选项，我们要向在某个终端登录的用户发送信息，就可以这样来执行命令：\n# 向在pts/1 (远程终端1)登录的user1用户发送信息，使用\u0026#34;Ctrl+D\u0026#34;快捷键保存发送的数据 $ write user1 pts/1 hello I will be in 5 minutes to restart, please save your data 这时，user1 用户就可以收到你要在 5 分钟之后重启系统的信息了。\nxargs 标准输入与管道命令 Unix 命令都带有参数，有些命令可以接受\u0026quot;标准输入\u0026quot;（stdin）作为参数。\n$ cat /etc/passwd | grep root 上面的代码使用了管道命令（|）。管道命令的作用，是将左侧命令（cat /etc/passwd）的标准输出转换为标准输入，提供给右侧命令（grep root）作为参数。\n因为grep命令可以接受标准输入作为参数，所以上面的代码等同于下面的代码。\n$ grep root /etc/passwd 但是，大多数命令都不接受标准输入作为参数，只能直接在命令行输入参数，这导致无法用管道命令传递参数。举例来说，echo命令就不接受管道传参。\n$ echo \u0026#34;hello world\u0026#34; | echo 上面的代码不会有输出。因为管道右侧的echo不接受管道传来的标准输入作为参数。\nxargs 命令的作用 xargs命令的作用，是将标准输入转为命令行参数。\n$ echo \u0026#34;hello world\u0026#34; | xargs echo hello world 上面的代码将管道左侧的标准输入，转为命令行参数hello world，传给第二个echo命令。\nxargs命令的格式如下。\n$ xargs [-options] [command] 真正执行的命令，紧跟在xargs后面，接受xargs传来的参数。\nxargs的作用在于，大多数命令（比如rm、mkdir、ls）与管道一起使用时，都需要xargs将标准输入转为命令行参数。\n$ echo \u0026#34;one two three\u0026#34; | xargs mkdir 上面的代码等同于mkdir one two three。如果不加xargs就会报错，提示mkdir缺少操作参数。\nxargs 的单独使用 xargs后面的命令默认是echo。\n$ xargs # 等同于 $ xargs echo 大多数时候，xargs命令都是跟管道一起使用的。但是，它也可以单独使用。\n输入xargs按下回车以后，命令行就会等待用户输入，作为标准输入。你可以输入任意内容，然后按下Ctrl d，表示输入结束，这时echo命令就会把前面的输入打印出来。\n$ xargs hello (Ctrl + d) hello 再看一个例子。\n$ xargs find -name \u0026#34;*.txt\u0026#34; ./foo.txt ./hello.txt 上面的例子输入xargs find -name以后，命令行会等待用户输入所要搜索的文件。用户输入\u0026quot;*.txt\u0026quot;，表示搜索当前目录下的所有 TXT 文件，然后按下Ctrl d，表示输入结束。这时就相当执行find -name *.txt。\n-d 参数与分隔符 默认情况下，xargs将换行符和空格作为分隔符，把标准输入分解成一个个命令行参数。\n$ echo \u0026#34;one two three\u0026#34; | xargs mkdir 上面代码中，mkdir会新建三个子目录，因为xargs将one two three分解成三个命令行参数，执行mkdir one two three。\n-d参数可以更改分隔符。\n$ echo -e \u0026#34;a\\tb\\tc\u0026#34; | xargs -d \u0026#34;\\t\u0026#34; echo a b c 上面的命令指定制表符\\t作为分隔符，所以a\\tb\\tc就转换成了三个命令行参数。echo命令的-e参数表示解释转义字符。\n-p 参数，-t 参数 使用xargs命令以后，由于存在转换参数过程，有时需要确认一下到底执行的是什么命令。\n-p参数打印出要执行的命令，询问用户是否要执行。\n$ echo \u0026#39;one two three\u0026#39; | xargs -p touch touch one two three ?... 上面的命令执行以后，会打印出最终要执行的命令，让用户确认。用户输入y以后（大小写皆可），才会真正执行。\n-t参数则是打印出最终要执行的命令，然后直接执行，不需要用户确认。\n$ echo \u0026#39;one two three\u0026#39; | xargs -t rm rm one two three -0 参数与 find 命令 由于xargs默认将空格作为分隔符，所以不太适合处理文件名，因为文件名可能包含空格。\nfind命令有一个特别的参数-print0，指定输出的文件列表以null分隔。然后，xargs命令的-0参数表示用null当作分隔符。\n$ find /path -type f -print0 | xargs -0 rm 上面命令删除/path路径下的所有文件。由于分隔符是null，所以处理包含空格的文件名，也不会报错。\n还有一个原因，使得xargs特别适合find命令。有些命令（比如rm）一旦参数过多会报错\u0026quot;参数列表过长\u0026quot;，而无法执行，改用xargs就没有这个问题，因为它对每个参数执行一次命令。\n$ find . -name \u0026#34;*.txt\u0026#34; | xargs grep \u0026#34;abc\u0026#34; 上面命令找出所有 TXT 文件以后，对每个文件搜索一次是否包含字符串abc。\n-L 参数 如果标准输入包含多行，-L参数指定多少行作为一个命令行参数。\n$ xargs find -name \u0026#34;*.txt\u0026#34; \u0026#34;*.md\u0026#34; find: paths must precede expression: `*.md\u0026#39; 上面命令同时将\u0026quot;*.txt\u0026quot;和*.md两行作为命令行参数，传给find命令导致报错。\n使用-L参数，指定每行作为一个命令行参数，就不会报错。\n$ xargs -L 1 find -name \u0026#34;*.txt\u0026#34; ./foo.txt ./hello.txt \u0026#34;*.md\u0026#34; ./README.md 上面命令指定了每一行（-L 1）作为命令行参数，分别运行一次命令（find -name）。\n下面是另一个例子。\n$ echo -e \u0026#34;a\\nb\\nc\u0026#34; | xargs -L 1 echo a b c 上面代码指定每行运行一次echo命令，所以echo命令执行了三次，输出了三行。\n-n 参数 -L参数虽然解决了多行的问题，但是有时用户会在同一行输入多项。\n$ xargs find -name \u0026#34;*.txt\u0026#34; \u0026#34;*.md\u0026#34; find: paths must precede expression: `*.md\u0026#39; 上面的命令将同一行的两项作为命令行参数，导致报错。\n-n参数指定每次将多少项，作为命令行参数。\n$ xargs -n 1 find -name 上面命令指定将每一项（-n 1）标准输入作为命令行参数，分别执行一次命令（find -name）。\n下面是另一个例子。\n$ echo {0..9} | xargs -n 2 echo 0 12 34 56 78 9 上面命令指定，每两个参数运行一次echo命令。所以，10个阿拉伯数字运行了五次echo命令，输出了五行。\n-I 参数 如果xargs要将命令行参数传给多个命令，可以使用-I参数。\n-I指定每一项命令行参数的替代字符串。\n$ cat foo.txt one two three $ cat foo.txt | xargs -I file sh -c \u0026#39;echo file; mkdir file\u0026#39; one two three $ ls one two three 上面代码中，foo.txt是一个三行的文本文件。我们希望对每一项命令行参数，执行两个命令（echo和mkdir），使用-I file表示file是命令行参数的替代字符串。执行命令时，具体的参数会替代掉echo file; mkdir file里面的两个file。\n\u0026ndash;max-procs 参数 xargs默认只用一个进程执行命令。如果命令要执行多次，必须等上一次执行完，才能执行下一次。\n--max-procs参数指定同时用多少个进程并行执行命令。--max-procs 2表示同时最多使用两个进程，--max-procs 0表示不限制进程数。\n$ docker ps -q | xargs -n 1 --max-procs 0 docker kill 上面命令表示，同时关闭尽可能多的 Docker 容器，这样运行速度会快很多。\nawk awk是处理文本文件的一个应用程序，几乎所有 Linux 系统都自带这个程序。\n它依次处理文件的每一行，并读取里面的每一个字段。对于日志、CSV 那样的每行格式相同的文本文件，awk可能是最方便的工具。\nawk其实不仅仅是工具软件，还是一种编程语言。不过，本文只介绍它的命令行用法，对于大多数场合，应该足够用了。\n基本用法 awk的基本用法就是下面的形式。\n# 格式 $ awk 动作 文件名 # 示例 $ awk \u0026#39;{print $0}\u0026#39; demo.txt 上面示例中，demo.txt是awk所要处理的文本文件。前面单引号内部有一个大括号，里面就是每一行的处理动作print $0。其中，print是打印命令，$0代表当前行，因此上面命令的执行结果，就是把每一行原样打印出来。\n下面，我们先用标准输入（stdin）演示上面这个例子。\n$ echo \u0026#39;this is a test\u0026#39; | awk \u0026#39;{print $0}\u0026#39; this is a test 上面代码中，print $0就是把标准输入this is a test，重新打印了一遍。\nawk会根据空格和制表符，将每一行分成若干字段，依次用$1、$2、$3代表第一个字段、第二个字段、第三个字段等等。\n$ echo \u0026#39;this is a test\u0026#39; | awk \u0026#39;{print $3}\u0026#39; a 上面代码中，$3代表this is a test的第三个字段a。\n下面，为了便于举例，我们把/etc/passwd文件保存成demo.txt。\nroot❌0:0:root:/root:/usr/bin/zsh daemon❌1:1:daemon:/usr/sbin:/usr/sbin/nologin bin❌2:2:bin:/bin:/usr/sbin/nologin sys❌3:3:sys:/dev:/usr/sbin/nologin sync❌4:65534:sync:/bin:/bin/sync 这个文件的字段分隔符是冒号（:），所以要用-F参数指定分隔符为冒号。然后，才能提取到它的第一个字段。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{ print $1 }\u0026#39; demo.txt root daemon bin sys sync 变量 除了$ + 数字表示某个字段，awk还提供其他一些变量。\n变量NF表示当前行有多少个字段，因此$NF就代表最后一个字段。\n$ echo \u0026#39;this is a test\u0026#39; | awk \u0026#39;{print $NF}\u0026#39; test $(NF-1)代表倒数第二个字段。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{print $1, $(NF-1)}\u0026#39; demo.txt root /root daemon /usr/sbin bin /bin sys /dev sync /bin 上面代码中，print命令里面的逗号，表示输出的时候，两个部分之间使用空格分隔。\n变量NR表示当前处理的是第几行。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{print NR \u0026#34;) \u0026#34; $1}\u0026#39; demo.txt 1) root 2) daemon 3) bin 4) sys 5) sync 上面代码中，print命令里面，如果原样输出字符，要放在双引号里面。\nawk的其他内置变量如下。\n FILENAME：当前文件名 FS：字段分隔符，默认是空格和制表符。 RS：行分隔符，用于分割每一行，默认是换行符。 OFS：输出字段的分隔符，用于打印时分隔字段，默认为空格。 ORS：输出记录的分隔符，用于打印时分隔记录，默认为换行符。 OFMT：数字输出的格式，默认为％.6g。  函数 awk还提供了一些内置函数，方便对原始数据的处理。\n函数toupper()用于将字符转为大写。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{ print toupper($1) }\u0026#39; demo.txt ROOT DAEMON BIN SYS SYNC 上面代码中，第一个字段输出时都变成了大写。\n其他常用函数如下。\n tolower()：字符转为小写。 length()：返回字符串长度。 substr()：返回子字符串。 sin()：正弦。 cos()：余弦。 sqrt()：平方根。 rand()：随机数。  awk内置函数的完整列表，可以查看手册。\n条件 awk允许指定输出条件，只输出符合条件的行。\n输出条件要写在动作的前面。\n$ awk \u0026#39;条件 动作\u0026#39; 文件名 请看下面的例子。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;/usr/ {print $1}\u0026#39; demo.txt root daemon bin sys 上面代码中，print命令前面是一个正则表达式，只输出包含usr的行。\n下面的例子只输出奇数行，以及输出第三行以后的行。\n# 输出奇数行 $ awk -F \u0026#39;:\u0026#39; \u0026#39;NR % 2 == 1 {print $1}\u0026#39; demo.txt root bin sync # 输出第三行以后的行 $ awk -F \u0026#39;:\u0026#39; \u0026#39;NR \u0026gt;3 {print $1}\u0026#39; demo.txt sys sync 下面的例子输出第一个字段等于指定值的行。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;$1 == \u0026#34;root\u0026#34; {print $1}\u0026#39; demo.txt root $ awk -F \u0026#39;:\u0026#39; \u0026#39;$1 == \u0026#34;root\u0026#34; || $1 == \u0026#34;bin\u0026#34; {print $1}\u0026#39; demo.txt root bin if 语句 awk提供了if结构，用于编写复杂的条件。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{if ($1 \u0026gt; \u0026#34;m\u0026#34;) print $1}\u0026#39; demo.txt root sys sync 上面代码输出第一个字段的第一个字符大于m的行。\nif结构还可以指定else部分。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{if ($1 \u0026gt; \u0026#34;m\u0026#34;) print $1; else print \u0026#34;---\u0026#34;}\u0026#39; demo.txt root --- --- sys sync find find 命令由 POSIX 规范 定义，它创建了一个用于衡量 POSIX 系统的开放标准，这包括 Linux、BSD 和 macOS。简而言之，只要你运行的是 Linux、BSD 或 macOS，那么 find 已经安装了。\n但是，并非所有的 find 命令都完全相同。例如，GNU 的 find 命令有一些 BSD、Busybox 或 Solaris 上 find 命令可能没有或有但实现方式不同的功能。本文使用 findutils 包中的 GNU find，因为它很容易获得且非常流行。本文演示的大多数命令都适用于 find 的其他实现，但是如果你在 Linux 以外的平台上尝试命令并得到非预期结果，尝试下载并安装 GNU 版本。\nman文档中给出的find命令的一般形式为：\nfind [-H] [-L] [-P] [-D debugopts] [-Olevel] [path...] [expression] 其实[-H] [-L] [-P] [-D debugopts] [-Olevel]这几个选项并不常用（至少在我的日常工作中，没有用到过），上面的find命令的常用形式可以简化为：\nfind [path...] [expression]   path：find命令所查找的目录路径。例如用.来表示当前目录，用/来表示系统根目录\n  expression：expression可以分为——“-options [-print -exec -ok \u0026hellip;]”\n   -options，指定find命令的常用选项 -print，find命令将匹配的文件输出到标准输出 -exec，find命令对匹配的文件执行该参数所给出的shell命令。相应命令的形式为'command' { } \\;，注意{ }和\\；之间的空格 find ./ -size 0 -exec rm {} \\; 删除文件大小为零的文件 （还可以以这样做：rm -i find ./ -size 0 或 find ./ -size 0 | xargs rm -f \u0026amp;）  为了用ls -l命令列出所匹配到的文件，可以把ls -l命令放在find命令的-exec选项中：find . -type f -exec ls -l { } \\; 在/logs目录中查找更改时间在5日以前的文件并删除它们：find /logs -type f -mtime +5 -exec rm { } \\; -ok，和-exec的作用相同，只不过以一种更为安全的模式来执行该参数所给出的shell命令，在执行每一个命令之前，都会给出提示，让用户来确定是否执行。 find . -name \u0026quot;*.conf\u0026quot; -mtime +5 -ok rm { } \\; 在当前目录中查找所有文件名以.LOG结尾、更改时间在5日以上的文件，并删除它们，只不过在删除之前先给出提示    也有人这样总结find命令的结构：\nfind start_directory options criteria_to_match action_to_perform_on_results 常用选项  -name  按照文件名查找文件。 find /dir -name filename  在/dir目录及其子目录下面查找名字为filename的文件 find . -name \u0026quot;*.c\u0026quot; 在当前目录及其子目录（用“.”表示）中查找任何扩展名为“c”的文件 -perm 按照文件权限来查找文件。 find . -perm 755 –print 在当前目录下查找文件权限位为755的文件，即文件属主可以读、写、执行，其它用户可以读、执行的文件 -prune  使用这一选项可以使find命令不在当前指定的目录中查找，如果同时使用-depth选项，那么-prune将被find命令忽略。 find /apps -path \u0026quot;/apps/bin\u0026quot; -prune -o –print 在/apps目录下查找文件，但不希望在/apps/bin目录下查找 find /usr/sam -path \u0026quot;/usr/sam/dir1\u0026quot; -prune -o –print 在/usr/sam目录下查找不在dir1子目录之内的所有文件 -user  按照文件属主来查找文件。 find ~ -user sam –print 在$HOME目录中查找文件属主为sam的文件 -group  按照文件所属的组来查找文件。 find /apps -group gem –print 在/apps目录下查找属于gem用户组的文件 -mtime -n +n  按照文件的更改时间来查找文件， - n表示文件更改时间距现在n天以内，+ n表示文件更改时间距现在n天以前。 find / -mtime -5 –print 在系统根目录下查找更改时间在5日以内的文件 find /var/adm -mtime +3 –print 在/var/adm目录下查找更改时间在3日以前的文件 -nogroup  查找无有效所属组的文件，即该文件所属的组在/etc/groups中不存在。 find / –nogroup -print -nouser  查找无有效属主的文件，即该文件的属主在/etc/passwd中不存在。 find /home -nouser –print -newer file1 ! file2  查找更改时间比文件file1新但比文件file2旧的文件。 -type  查找某一类型的文件，诸如： b - 块设备文件。 d - 目录。 c - 字符设备文件。 p - 管道文件。 l - 符号链接文件。 f - 普通文件。 find /etc -type d –print 在/etc目录下查找所有的目录 find . ! -type d –print 在当前目录下查找除目录以外的所有类型的文件 find /etc -type l –print 在/etc目录下查找所有的符号链接文件 -size n：[c] 查找文件长度为n块的文件，带有c时表示文件长度以字节计。 find . -size +1000000c –print 在当前目录下查找文件长度大于1 M字节的文件 find /home/apache -size 100c –print 在/home/apache目录下查找文件长度恰好为100字节的文件 find . -size +10 –print 在当前目录下查找长度超过10块的文件（一块等于512字节） -depth：在查找文件时，首先查找当前目录中的文件，然后再在其子目录中查找。 find / -name \u0026quot;CON.FILE\u0026quot; -depth –print 它将首先匹配所有的文件然后再进入子目录中查找 -mount：在查找文件时不跨越文件系统mount点。 find . -name \u0026quot;*.XC\u0026quot; -mount –print 从当前目录开始查找位于本文件系统中文件名以XC结尾的文件（不进入其它文件系统） -follow：如果find命令遇到符号链接文件，就跟踪至链接所指向的文件。  按名称查找文件 你可以借助正则表达式使用完整或部分的文件名来定位文件。find 命令需要你给出想搜索的目录；指定搜索属性选项，例如，-name 用于指定区分大小写的文件名；然后是搜索字符串。默认情况下，搜索字符串按字面意思处理：除非你使用正则表达式语法，否则 find 命令搜索的文件名正是你在引号之间输入的字符串。\n假设你的 Documents 目录包含四个文件：Foo、foo、foobar.txt 和 foo.xml。以下是对 foo 的字面搜索：\n$ find ~ -name \u0026#34;foo\u0026#34; /home/tux/Documents/examples/foo 你可以使用 -iname 选项使其不区分大小写来扩大搜索范围：\n$ find ~ -iname \u0026#34;foo\u0026#34; /home/tux/Documents/examples/foo /home/tux/Documents/examples/Foo 通配符 你可以使用基本的 shell 通配符来扩展搜索。例如，* 表示任意数量的字符：\n$ find ~ -iname \u0026#34;foo*\u0026#34; /home/tux/Documents/examples/foo /home/tux/Documents/examples/Foo /home/tux/Documents/examples/foo.xml /home/tux/Documents/examples/foobar.txt ? 表示单个字符：\n$ find ~ -iname \u0026#34;foo*.???\u0026#34; /home/tux/Documents/examples/foo.xml /home/tux/Documents/examples/foobar.txt 这不是正则表达式语法，因此 . 在示例中只表示字母“点”。\n正则表达式 你还可以使用正则表达式。与 -iname 和 -name 一样，也有区分大小写和不区分大小写的选项。但不一样的是，-regex 和 -iregex 搜索应用于整个路径，而不仅仅是文件名。这意味着，如果你搜索 foo，你不会得到任何结果，因为 foo 与 /home/tux/Documents/foo 不匹配。相反，你必须要么搜索整个路径，要么在字符串的开头使用通配符：\n$ find ~ -iregex \u0026#34;.*foo\u0026#34; /home/tux/Documents/examples/foo /home/tux/Documents/examples/Foo 查找近一周修改过的文件 要查找近一周修改的文件，使用 -mtime 选项以及过去的天数（负数）：\n$ find ~ -mtime -7 /home/tux/Documents/examples/foo /home/tux/Documents/examples/Foo /home/tux/Documents/examples/foo.xml /home/tux/Documents/examples/foobar.txt 查找近几天修改的文件 你可以结合使用 -mtime 选项来查找近几天范围内修改的文件。对于第一个 -mtime 参数，表示上一次修改文件的最近天数。第二个参数表示最大天数。例如，搜索修改时间超过 1 天但不超过 7 天的文件：\n$ find ~ -mtime +1 -mtime -7 按文件类型限制搜索 指定查找文件的类型来优化 find 的结果是很常见的。如果你不确定要查找的内容，则不应该使用此选项。但如果你知道要查找的是文件而不是目录，或者是目录而不是文件，那么这可能是一个很好的过滤器。选项是 -type，它的参数是代表不同类型数据的字母代码。最常见的是：\n d - 目录 f - 文件 l - 链接文件 s - 套接字 p - 命名管道（用于 FIFO） b - 块设备（通常是硬盘）  下面是一些例子：\n$ find ~ -type d -name \u0026#34;Doc*\u0026#34; /home/tux/Documents $ find ~ -type f -name \u0026#34;Doc*\u0026#34; /home/tux/Downloads/10th-Doctor.gif $ find /dev -type b -name \u0026#34;sda*\u0026#34; /dev/sda/dev/sda1 调整范围 find 命令默认是递归的，这意味着它会在指定的目录中层层搜索结果。这在大型文件系统中可能会变得不堪重负，但你可以使用 -maxdepth 选项来控制搜索深度：\n$ find /usr -iname \u0026#34;*xml\u0026#34; | wc -l 15588 $ find /usr -maxdepth 2 -iname \u0026#34;*xml\u0026#34; | wc -l 15 也可以使用 -mindepth 设置最小递归深度：\n$ find /usr -mindepth 8 -iname \u0026#34;*xml\u0026#34; | wc -l 9255 与 xargs 在使用find命令的-exec选项处理匹配到的文件时， find命令将所有匹配到的文件一起传递给exec执行。但有些系统对能够传递给exec的命令长度有限制，这样在find命令运行几分钟之后，就会出现溢出错误。错误信息通常是“参数列太长”或“参数列溢出”。这就是xargs命令的用处所在，特别是与find命令一起使用。\nfind命令把匹配到的文件传递给xargs命令，而xargs命令每次只获取一部分文件而不是全部，不像-exec选项那样。这样它可以先处理最先获取的一部分文件，然后是下一批，并如此继续下去。\n在有些系统中，使用-exec选项会为处理每一个匹配到的文件而发起一个相应的进程，并非将匹配到的文件全部作为参数一次执行；这样在有些情况下就会出现进程过多，系统性能下降的问题，因而效率不高；\n而使用xargs命令则只有一个进程。另外，在使用xargs命令时，究竟是一次获取所有的参数，还是分批取得参数，以及每一次获取参数的数目都会根据该命令的选项及系统内核中相应的可调参数来确定。\n来看看xargs命令是如何同find命令一起使用的，并给出一些例子。\nfind . -type f -print | xargs file 查找系统中的每一个普通文件，然后使用xargs命令来测试它们分别属于哪类文件\nfind / -name \u0026quot;core\u0026quot; -print | xargs echo \u0026quot;\u0026quot; \u0026gt;/tmp/core.log 在整个系统中查找内存信息转储文件(core dump) ，然后把结果保存到/tmp/core.log 文件中：\nfind . -type f -print | xargs grep \u0026quot;hostname\u0026quot; 用grep命令在所有的普通文件中搜索hostname这个词\nfind ./ -mtime +3 -print|xargs rm -f –r 删除3天以前的所有东西 （find . -ctime +3 -exec rm -rf {} \\;）\nfind ./ -size 0 | xargs rm -f \u0026amp; 删除文件大小为零的文件\nfind命令配合使用exec和xargs可以使用户对所匹配到的文件执行几乎所有的命令。\nfd fd 命令是一个流行的、用户友好的 find 命令的替代品。\ngrep grep (global search regular expression(RE) and print out the line，全面搜索正则表达式并把行打印出来)是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。\ngrep 这个名字，来源于一个 Unix/Linux 中的古老的行编辑器 ed 中执行相似操作的命令：\ng/re/p 语法如下所示:\ngrep [OPTIONS] PATTERN [FILE...] grep [OPTIONS] [-e PATTERN | -f FILE] [FILE...] grep命令用于搜索由Pattern参数指定的模式，并将每个匹配的行写入标准输出中。这些模式是具有限定的正则表达式，它们使用ed或egrep命令样式。\n如果在File参数中指定了多个名称，grep命令将显示包含匹配行的文件的名称。\n对 shell 有特殊含义的字符 ($, *, [, |, ^, (, ), \\ ) 出现在 Pattern参数中时必须带双引号。如果 Pattern参数不是简单字符串，通常必须用单引号将整个模式括起来。在诸如 [a-z], 之类的表达式中，-（减号）cml 可根据当前正在整理的序列来指定一个范围。整理序列可以定义等价的类以供在字符范围中使用。\n如果未指定任何文件，grep会假定为标准输入。\n基本集 grep正则表达式元字符集：\n ^ 锚定行的开始 如：'^grep'匹配所有以grep开头的行。 $ 锚定行的结束 如：'grep$'匹配所有以grep结尾的行。 . 匹配一个非换行符的字符 如：'gr.p'匹配gr后接一个任意字符，然后是p。 * 匹配零个或多个先前字符 如：' *grep'匹配所有一个或多个空格后紧跟grep的行。 .*一起用代表任意字符。 [] 匹配一个指定范围内的字符，如'[Gg]rep'匹配Grep和grep。 [^]  匹配一个不在指定范围内的字符，如：'[^A-FH-Z]rep'匹配不包含A-F和H-Z的一个字母开头，紧跟rep的行。 \\(..\\) 标记匹配字符，如：'\\(love\\)'，love被标记为1。 \\\u0026lt; 锚定单词的开始，如：`'`` ``\u0026gt; 锚定单词的结束，如\u0026lsquo;grep\u0026gt;'`匹配包含以grep结尾的单词的行。 x\\{m\\} 连续重复字符x，m次，如：'o\\{5\\}'匹配包含连续5个o的行。 x\\{m,\\} 连续重复字符x,至少m次，如：'o\\{5,\\}'匹配至少连续有5个o的行。 x\\{m,n\\} 连续重复字符x，至少m次，不多于n次，如：'o\\{5,10\\}'匹配连续5\u0026ndash;10个o的行。 \\w 匹配一个文字和数字字符，也就是[A-Za-z0-9]，如：'G\\w*p'匹配以G后跟零个或多个文字或数字字符，然后是p。 \\W  w的反置形式，匹配一个非单词字符，如点号句号等。\\W*则可匹配多个。 \\b 单词锁定符，如: '\\bgrep\\b'只匹配grep，即只能是grep这个单词，两边均为空格。  常用选项 -? 同时显示匹配行上下的？行，如：grep -2 pattern filename同时显示匹配行的上下2行。\n-b，--byte-offset 打印匹配行前面打印该行所在的块号码。\n-c,--count 只打印匹配的行数，不显示匹配的内容。\n-f File，--file=File 从文件中提取模板。空文件中包含0个模板，所以什么都不匹配。\n-h，--no-filename 当搜索多个文件时，不显示匹配文件名前缀。\n-i，--ignore-case 忽略大小写差别。\n-q，--quiet 取消显示，只返回退出状态。0则表示找到了匹配的行。\n-l，--files-with-matches 打印匹配模板的文件清单。\n-L，--files-without-match 打印不匹配模板的文件清单。\n-n，--line-number 在匹配的行前面打印行号。\n-s，--silent 不显示关于不存在或者无法读取文件的错误信息。\n-v，--revert-match 反检索，只显示不匹配的行。\n-w，--word-regexp 如果被\\引用，就把表达式做为一个单词搜索。\n-V，--version 显示软件版本信息。\n怎么样使用 grep 来搜索一个文件 搜索 /etc/passwd 文件下的 boo 用户,输入:\n$ grep boo /etc/passwd 输出内容:\nfoo❌1000:1000:foo,,,:/home/foo:/bin/ksh 可以使用 grep 去强制忽略大小写。例如，使用 -i 选项可以匹配 boo, Boo, BOO 和其他组合：\n$ grep -i \u0026quot;boo\u0026quot; /etc/passwd 递归使用 grep 你可以递归地使用 grep 进行搜索。例如，在文件目录下面搜索所有包含字符串“192.168.1.5”的文件\n$ grep -r \u0026quot;192.168.1.5\u0026quot; /etc/ 或者是：\n$ grep -R \u0026quot;192.168.1.5\u0026quot; /etc/ 示例输出:\n/etc/ppp/options:# ms-wins 192.168.1.50/etc/ppp/options:# ms-wins 192.168.1.51/etc/NetworkManager/system-connections/Wired connection 1:addresses1=192.168.1.5;24;192.168.1.2; 你会看到搜索到 192.168.1.5 的结果每一行都前缀以找到匹配的文件名（例如：/etc/ppp/options）。输出之中包含的文件名可以加 -h 选项来禁止输出：\n$ grep -h -R \u0026quot;192.168.1.5\u0026quot; /etc/ 或者\n$ grep -hR \u0026quot;192.168.1.5\u0026quot; /etc/ 示例输出:\n# ms-wins 192.168.1.50# ms-wins 192.168.1.51addresses1=192.168.1.5;24;192.168.1.2; 使用 grep 去搜索文本 当你搜索 boo 时，grep 命令将会匹配 fooboo，boo123, barfoo35 和其他所有包含 boo 的字符串，你可以使用 -w 选项去强制只输出那些仅仅包含那个整个单词的行（LCTT译注：即该字符串两侧是英文单词分隔符，如空格，标点符号，和末端等，因此对中文这种没有断字符号的语言并不适用。）。\n$ grep -w \u0026quot;boo\u0026quot; file 使用 grep 命令去搜索两个不同的单词 使用 egrep 命令如下:\n$ egrep -w 'word1|word2' /path/to/file （LCTT 译注：这里使用到了正则表达式，因此使用的是 egrep 命令，即扩展的 grep 命令。）\n统计文本匹配到的行数 grep 命令可以通过加 -c 参数显示每个文件中匹配到的次数：\n$ grep -c 'word' /path/to/file 传递 -n 选项可以输出的行前加入匹配到的行的行号：\n$ grep -n 'root' /etc/passwd 示例输出:\n1:root:x:0:0:root:/root:/bin/bash1042:rootdoor:x:0:0:rootdoor:/home/rootdoor:/bin/csh3319:initrootapp:x:0:0:initrootapp:/home/initroot:/bin/ksh 反转匹配（不匹配） 可以使用 -v 选项来输出不包含匹配项的内容，输出内容仅仅包含那些不含给定单词的行，例如输出所有不包含 bar 单词的行：\n$ grep -v bar /path/to/file UNIX/Linux 管道与 grep 命令 grep 常常与管道一起使用，在这个例子中，显示硬盘设备的名字：\n# dmesg | egrep '(s|h)d[a-z]' 显示 CPU 型号：\n# cat /proc/cpuinfo | grep -i 'Model' 然而，以上命令也可以按照以下方法使用，不使用管道:\n# grep -i 'Model' /proc/cpuinfo 示例输出:\nmodel : 30model name : Intel(R) Core(TM) i7 CPU Q 820 @ 1.73GHzmodel : 30model name : Intel(R) Core(TM) i7 CPU Q 820 @ 1.73GHz 如何仅仅显示匹配到内容的文件名字? 使用 -l 选项去显示那些文件内容中包含 main() 的文件名：\n$ grep -l 'main' *.c 最后，你可以强制 grep 以彩色输出：\n$ grep --color vivek /etc/passwd 查找文件内容 从根目录开始查找所有扩展名为 .log 的文本文件，并找出包含 \u0026ldquo;ERROR\u0026rdquo; 的行：\n$ find / -type f -name \u0026#34;*.log\u0026#34; | xargs grep \u0026#34;ERROR\u0026#34; 例子：从当前目录开始查找所有扩展名为 .in 的文本文件，并找出包含 \u0026ldquo;thermcontact\u0026rdquo; 的行：\n$ find . -name \u0026#34;*.in\u0026#34; | xargs grep \u0026#34;thermcontact\u0026#34; cat bat A cat(1) clone with wings.\n添加了语法高亮和 Git 集成等功能，并且还提供了分页选项。\nip linux的ip命令和ifconfig类似，但前者功能更强大，并旨在取代后者。使用ip命令，只需一个命令，你就能很轻松地执行一些网络管理任务。ifconfig是net-tools中已被废弃使用的一个命令，许多年前就已经没有维护了。iproute2套件里提供了许多增强功能的命令，ip命令即是其中之一。\n设置和删除Ip地址 要给你的机器设置一个IP地址，可以使用下列ip命令：\n$ sudo ip addr add 192.168.0.193/24 dev wlan0 请注意IP地址要有一个后缀，比如/24。这种用法用于在无类域内路由选择（CIDR）中来显示所用的子网掩码。在这个例子中，子网掩码是255.255.255.0。\n在你按照上述方式设置好IP地址后，需要查看是否已经生效。\n$ ip addr show wlan0 你也可以使用相同的方式来删除IP地址，只需用del代替add。\n$ sudo ip addr del 192.168.0.193/24 dev wlan0 列出路由表条目 ip命令的路由对象的参数还可以帮助你查看网络中的路由数据，并设置你的路由表。第一个条目是默认的路由条目，你可以随意改动它。\n在这个例子中，有几个路由条目。这个结果显示有几个设备通过不同的网络接口连接起来。它们包括WIFI、以太网和一个点对点连接。\n$ ip route show 假设现在你有一个IP地址，你需要知道路由包从哪里来。可以使用下面的路由选项（译注：列出了路由所使用的接口等）：\n$ ip route get 10.42.0.47 更改默认路由 要更改默认路由，使用下面ip命令：\n$ sudo ip route add default via 192.168.0.196 显示网络统计数据 使用ip命令还可以显示不同网络接口的统计数据。\n当你需要获取一个特定网络接口的信息时，在网络接口名字后面添加选项ls即可。使用多个选项**-s**会给你这个特定接口更详细的信息。特别是在排除网络连接故障时，这会非常有用。\n$ ip -s -s link ls p2p1 ARP条目 地址解析协议（ARP）用于将一个IP地址转换成它对应的物理地址，也就是通常所说的MAC地址。使用ip命令的neigh或者neighbour选项，你可以查看接入你所在的局域网的设备的MAC地址。\n$ ip neighbour 监控netlink消息 也可以使用ip命令查看netlink消息。monitor选项允许你查看网络设备的状态。比如，所在局域网的一台电脑根据它的状态可以被分类成REACHABLE或者STALE。使用下面的命令：\n$ ip monitor all 激活和停止网络接口 你可以使用ip命令的up和down选项来激某个特定的接口，就像ifconfig的用法一样。\n在这个例子中，当ppp0接口被激活和在它被停止和再次激活之后，你可以看到相应的路由表条目。这个接口可能是wlan0或者eth0。将ppp0更改为你可用的任意接口即可。\n$ sudo ip link set ppp0 down $ sudo ip link set ppp0 up 获取帮助 当你陷入困境，不知道某一个特定的选项怎么用的时候，你可以使用help选项。man页面并不会提供许多关于如何使用ip选项的信息，因此这里就是获取帮助的地方。\n比如，想知道关于route选项更多的信息：\n$ ip route help 小结 对于网络管理员们和所有的Linux使用者们，ip命令是必备工具。是时候抛弃ifconfig命令了，特别是当你写脚本时。\ndig 使用 dig 来进行 DNS 查询。\n参数类型：查询和格式化 有两种主要的参数可以传递给 dig：\n 告诉 dig 要进行什么 DNS 查询的参数。 告诉 dig 如何 格式化响应的参数。  首先，让我们看一下查询选项。\n主要的查询选项 你通常想控制 DNS 查询的 3 件事是：\n 名称（如 jvns.ca）。默认情况下，查询的是空名称（.）。 DNS 查询类型（如 A 或 CNAME）。默认是 A。 发送查询的 服务器（如 8.8.8.8）。默认是 /etc/resolv.conf 中的内容。  其格式是：\ndig @server name type 这里有几个例子：\n dig @8.8.8.8 jvns.ca 向谷歌的公共 DNS 服务器（8.8.8.8）查询 jvns.ca。 dig ns jvns.ca 对 jvns.ca 进行类型为 NS 的查询。  -x：进行反向 DNS 查询\n我偶尔使用的另一个查询选项是 -x，用于进行反向 DNS 查询。下面是输出结果的样子。\n$ dig -x 172.217.13.174 174.13.217.172.in-addr.arpa. 72888 IN PTR yul03s04-in-f14.1e100.net。 -x 不是魔术。dig -x 172.217.13.174 只是对 174.13.217.172.in-addr.arpa. 做了一个 PTR 查询。下面是如何在不使用 `-x’ 的情况下进行完全相同的反向 DNS 查询。\n$ dig ptr 174.13.217.172.in-addr.arpa. 174.13.217.172.in-addr.arpa. 72888 IN PTR yul03s04-in-f14.1e100.net。 我总是使用 -x，因为它可以减少输入。\nDNS反向查询大概的一个定义就是：\n从 IP 地址获取 PTR 记录。也就是说，通过使用一些网络工具可以将 IP 地址转换为主机名。 实际上，PRT 代表 POINTER，在 DNS 系统有唯一性，将 IP 地址与规范化的主机名联系起来。PTR 记录其实是 NDS 系统的一部分，但是由专门的区域文件组成的，使用的是传统的 in-addr.arpa 格式。\n格式化响应的选项 现在，让我们讨论一下你可以用来格式化响应的参数。\n我发现 dig 默认格式化 DNS 响应的方式对初学者来说是很难接受的。下面是输出结果的样子：\n; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.16.20 \u0026lt;\u0026lt;\u0026gt;\u0026gt; -r jvns.ca ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 28629 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096 ; COOKIE: d87fc3022c0604d60100000061ab74857110b908b274494d (good) ;; QUESTION SECTION: ;jvns.ca. IN A ;; ANSWER SECTION: jvns.ca. 276 IN A 172.64.80.1 ;; Query time: 9 msec ;; SERVER: 192.168.1.1#53(192.168.1.1) ;; WHEN: Sat Dec 04 09:00:37 EST 2021 ;; MSG SIZE rcvd: 80 如果你不习惯看这个，你可能需要花点时间来筛选，找到你要找的 IP 地址。而且大多数时候，你只对这个响应中的一行感兴趣（jvns.ca. 180 IN A 172.64.80.1）。\n下面是我最喜欢的两种方法，可以使 dig 的输出更容易管理：\n方式 1 : +noall +answer\n这告诉 dig 只打印 DNS 响应中的“答案”部分的内容。下面是一个查询 google.com 的 NS 记录的例子：\n$ dig +noall +answer ns google.com google.com. 158564 IN NS ns4.google.com. google.com. 158564 IN NS ns1.google.com. google.com. 158564 IN NS ns2.google.com. google.com. 158564 IN NS ns3.google.com. 这里的格式是：\nNAME TTL TYPE CONTENT google.com 158564 IN NS ns3.google.com. 顺便说一下：如果你曾经想知道 IN 是什么意思，它是指“查询类”，代表“互联网internet”。它基本上只是上世纪 80、90 年代的遗物，当时还有其他网络与互联网竞争，如“混沌网络chaosnet”。\n方式 2：+short\n这就像 dig +noall +answer，但更短：它只显示每条记录的内容。比如说：\n$ dig +short ns google.com ns2.google.com. ns1.google.com. ns4.google.com. ns3.google.com. digrc 如果你不喜欢 dig 的默认格式（我就不喜欢！），你可以在你的主目录下创建一个 .digrc 文件，告诉它默认使用不同的格式。\n我非常喜欢 +noall +answer 格式，所以我把 +noall +answer 放在我的 ~/.digrc 中。下面是我使用该配置文件运行 dig jvns.ca 时的情况。\n$ dig jvns.ca jvns.ca. 255在172.64.80.1中 这样读起来就容易多了！\n如果我想回到所有输出的长格式（我有时会这样做，通常是因为我想看响应的权威部分的记录），我可以通过运行再次得到一个长答案。\n$ dig +all jvns.ca dig +trace 我使用的最后一个 dig 选项是 +trace。dig +trace 模仿 DNS 解析器在查找域名时的做法 —— 它从根域名服务器开始，然后查询下一级域名服务器（如 .com），以此类推，直到到达该域名的权威域名服务器。因此，它将进行大约 30 次 DNS 查询。（我用 tcpdump 检查了一下，对于每个根域名服务器的 A / AAAA 记录它似乎要进行 2 次查询，所以这已经是 26 次查询了。我不太清楚它为什么这样做，因为它应该已经有了这些 IP 的硬编码，但它确实如此。）\n我发现这对了解 DNS 的工作原理很有用，但我不认为我用它解决过问题。\n为什么要用 dig 尽管有一些更简单的工具来进行 DNS 查询（如 dog 和 host），我发现自己还是坚持使用 dig。\n我喜欢 dig 的地方实际上也是我 不喜欢 dig 的地方 —— 它显示了大量的细节！\n我知道，如果我运行 dig +all，它将显示 DNS 响应的所有部分。例如，让我们查询 jvns.ca 的一个根名称服务器。响应有 3 个部分，我可能会关心：回答部分、权威部分和附加部分。\n$ dig @h.root-servers.net. jvns.ca +all ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 18229 ;; flags: qr rd; QUERY: 1, ANSWER: 0, AUTHORITY: 4, ADDITIONAL: 9 ;; WARNING: recursion requested but not available ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 1232 ;; QUESTION SECTION: ;jvns.ca. IN A ;; AUTHORITY SECTION: ca. 172800 IN NS c.ca-servers.ca. ca. 172800 IN NS j.ca-servers.ca. ca. 172800 IN NS x.ca-servers.ca. ca. 172800 IN NS any.ca-servers.ca. ;; ADDITIONAL SECTION: c.ca-servers.ca. 172800 IN A 185.159.196.2 j.ca-servers.ca. 172800 IN A 198.182.167.1 x.ca-servers.ca. 172800 IN A 199.253.250.68 any.ca-servers.ca. 172800 IN A 199.4.144.2 c.ca-servers.ca. 172800 IN AAAA 2620:10a:8053::2 j.ca-servers.ca. 172800 IN AAAA 2001:500:83::1 x.ca-servers.ca. 172800 IN AAAA 2620:10a:80ba::68 any.ca-servers.ca. 172800 IN AAAA 2001:500:a7::2 ;; Query time: 103 msec ;; SERVER: 198.97.190.53#53(198.97.190.53) ;; WHEN: Sat Dec 04 11:23:32 EST 2021 ;; MSG SIZE rcvd: 289 dog 也显示了 “附加” 部分的记录，但它没有明确指出哪个是哪个（我猜 + 意味着它在附加部分？） ，但它似乎没有显示“权威”部分的记录。\n$ dog @h.root-servers.net. jvns.ca NS ca. 2d0h00m00s A \u0026#34;c.ca-servers.ca.\u0026#34; NS ca. 2d0h00m00s A \u0026#34;j.ca-servers.ca.\u0026#34; NS ca. 2d0h00m00s A \u0026#34;x.ca-servers.ca.\u0026#34; NS ca. 2d0h00m00s A \u0026#34;any.ca-servers.ca.\u0026#34; A c.ca-servers.ca. 2d0h00m00s + 185.159.196.2 A j.ca-servers.ca. 2d0h00m00s + 198.182.167.1 A x.ca-servers.ca. 2d0h00m00s + 199.253.250.68 A any.ca-servers.ca. 2d0h00m00s + 199.4.144.2 AAAA c.ca-servers.ca. 2d0h00m00s + 2620:10a:8053::2 AAAA j.ca-servers.ca. 2d0h00m00s + 2001:500:83::1 AAAA x.ca-servers.ca. 2d0h00m00s + 2620:10a:80ba::68 AAAA any.ca-servers.ca. 2d0h00m00s + 2001:500:a7::2 而 host 似乎只显示“答案”部分的记录（在这种情况下没有得到记录）：\n$ host jvns.ca h.root-servers.net Using domain server: Name: h.root-servers.net Address: 198.97.190.53#53 Aliases: 总之，我认为这些更简单的 DNS 工具很好（我甚至自己做了一个 简单的网络 DNS 工具），如果你觉得它们更容易，你绝对应该使用它们，但这就是为什么我坚持使用 dig 的原因。drill 的输出格式似乎与 dig 的非常相似，也许 drill 更好！但我还没有真正试过它。\nOthers Ubuntu Packages Search List of applications—Arch 常用软件—openSUSE 应用程序—Ubuntu 生态适配清单—UOS QEMU KVM QEMU 的图形前端 与其他的虚拟化程序如 VirtualBox 和 VMware 不同, QEMU不提供管理虚拟机的GUI（运行虚拟机时出现的窗口除外），也不提供创建具有已保存设置的持久虚拟机的方法。除非您已创建自定义脚本以启动虚拟机，否则必须在每次启动时在命令行上指定运行虚拟机的所有参数。\nLibvirt提供了一种管理 QEMU 虚拟机的便捷方式。有关可用的前端，请参阅 libvirt 客户端列表。\n创建新虚拟系统 创建硬盘镜像 除非直接从 CD-ROM 或网络引导（并且不安装系统到本地），运行 QEMU 时都需要硬盘镜像。硬盘镜像是一个文件，存储虚拟机硬盘上的内容。\n一个硬盘镜像可能是 raw镜像, 和客户机器上看到的内容一模一样，并且将始终使用主机上的来宾硬盘驱动器的全部容量。此方法提供的I / O开销最小，但可能会浪费大量空间，因为guest虚拟机上未使用的空间无法在主机上使用。\n另外一种方式是qcow2 格式，仅当客户系统实际写入内容的时候，才会分配镜像空间。对客户机器来说，硬盘大小表现为完整大小，即使它可能仅占用主机系统上的非常小的空间。此映像格式还支持QEMU快照功能。但是，使用此格式而不是 raw 可能会影响性能。\nQEMU 提供 qemu-img命令创建硬盘镜像.例如创建一个 4 GB raw 格式的镜像:\n$ qemu-img create -f raw image_file 4G 您也可以用 -f qcow2 创建一个 qcow2 镜像。\n用 dd 或 fallocate 也可以创建一个 raw 镜像。\n警告： 如果硬盘镜像存储在 Btrfs 系统上，则应在创建任何映像之前考虑禁用该目录的 写时复制。\n调整镜像大小\n警告： 调整包含NTFS引导文件系统的镜像将无法启动已安装的操作系统，推荐在操作之前进行备份\n执行 qemu-img 带 resize 选项调整硬盘驱动镜像的大小.它适用于 raw 和 qcow2. 例如, 增加镜像 10 GB 大小, 运行:\n$ qemu-img resize disk_image +10G 在磁盘映像扩容后，必须使用虚拟机内部系统的分区工具对该镜像进行分区并格式化后才能真正开始使用新空间。 在收缩磁盘映像时，必须首先使用虚拟机内部系统的分区工具减少分该分区的大小，然后相应地收缩磁盘映像，否则收缩磁盘映像将导致数据丢失！\n安装操作系统 这是你第一次需要去启动模拟器的步骤，为了在磁盘镜像上安装操作系统，你必须同时将磁盘镜像与安装介质装载到虚拟机上，从安装介质中启动操作系统。\n以i386的客户机为例，为了从CD-ROM内的把可用于启动的ISO文件安装到磁盘镜像上，你需要：\n$ qemu-system-x86_64 -cdrom iso_image -boot order=d -drive file=disk_image,format=raw 在安装完操作系统后，就可以直接从QEMU镜像内启动了。\n注意： 默认情况下仅分配给虚拟机128MB的内存， 分配的内存大小可以通过 -m 调整， 比如 -m 512M 或 -m 2G。\n提示：\n 相较于指定 -boot order=x ，一部分用户感觉使用 -boot menu=on 启用boot菜单的体验更舒服些，至少在配置和实验时是这样的。 当使用无界面（headless）模式时， 将会默认在本地5900端口启动一个VNC服务器， 可以用 TigerVNC 连接到客户机的系统上: vncviewer :5900 若你在安装过程中需要替换软盘或CD，可以使用QEMU机器监视器（在虚拟机窗口中按Ctrl + Alt + 2）来删除存储设备并将其连接到虚拟机。使用info block查看块设备，然后使用change命令换出设备。按下Ctrl + Alt + 1返回虚拟机。  运行虚拟化的系统 qemu-system-* 程序 (例如 qemu-system-i386 或 qemu-system-x86_64, 取决于客户机架构)用来运行虚拟化的客户机. 用法是:\n$ qemu-system-i386 options disk_image 所有 qemu-system-*的选项是相同的。\n默认 QEMU会在窗口中显示虚拟机的视频输出.有一点要记住:当您单击QEMU窗口,鼠标指针被捕获。要放开，按 Ctrl+Alt+g.\n警告： QEMU 不应以 root 身份运行. 如果必须以root身份在某个脚本中运行QEMU，那么你需要使用 -runas 选项让QEMU放弃root权限\n启用 KVM KVM 必须要您处理器和内核支持, 和必要的 kernel modules加载。更多信息参见 KVM。\n要在KVM模式中启动QEMU, 追加 -enable-kvm到启动选项. 要检查是否为正在运行的 VM 启用了 KVM，请使用 Ctrl+Alt+Shift+2 进入 QEMU Monitor，然后键入 info kvm。\n注意：\n -machine 选项中的 accel=kvm 参数与-enable-kvm 或 -accel kvm 选项是等价的。 CPU模型 host 需要 KVM。 如果你使用GUI工具去启动QEMU，但是性能体验极差，那么最好检查一下是否真的开启了KVM支持，因为QEMU可能选择了备用的模拟模式，即软件级模拟。 需要启用KVM才能正常启动windows7和windows8，否则会出现“蓝屏”.  启用 IOMMU (Intel VT-d/AMD-Vi) 的支持 首先启用IOMMU。\n确保您的 CPU 支持 AMD-Vi/Intel Vt-d 并且已经在 BIOS 中打开。通常这个选项会在类似“其他 CPU 特性”的菜单里，也有可能隐藏在超频选项之中。选项可能就叫做 “VT-d” 或者 “AMD-Vi” ，也有可能是更通用的名称，比如“虚拟化技术”之类。有可能您主板的手册并不会解释这些。\n设置内核参数以启用 IOMMU，注意不同品牌的 CPU 所需的内核参数并不同。\n 对于 Intel CPU(VT-d)，使用 intel_iommu=on。 对于 AMD CPU(AMD-Vi)，使用 amd_iommu=on。  您同时需要设置iommu=pt，这将防止Linux试图接触(touching)无法直通的设备。\n在重启之后，检查 dmesg 以确认 IOMMU 已经被正确启用：\n$ dmesg | grep -e DMAR -e IOMMU ... [ 0.000000] Intel-IOMMU: enabled ... 添加 -device intel-iommu 选项创建IOMMU设备:\n$ qemu-system-x86_64 -enable-kvm -machine q35 -device intel-iommu -cpu host .. 注意： 在基于Intel CPU的系统上用 -device intel-iommu 创建QEMU内的IOMMU设备将会禁用PCI直通， 如果需要PCI直通，则不应设置-device intel-iommu。\n宿主机和虚拟机数据交互 网络 我们可以利用任何支持文件传输的网络协议实现客户机和宿主机之间的数据交互, 例如 NFS, SMB, NBD, HTTP, FTP, 或 SSH, 当然这么做的前提是你已经配置好二者之间的网络，且在系统上启动了相应的服务程序。\n在默认情况下，用户模式的客户机能够通过10.0.2.2这个IP访问到宿主机。任何运行于宿主机上的服务端程序都可以通过这个地址被访问到，比如说我们可以通过这个IP访问到宿主机上的SSH服务器或SMB服务器。因此在这种情况下，客户机能够挂载宿主机通过SMB or NFS暴露出来的目录，也可以访问宿主机上的HTTP服务器等。 通常情况下宿主机无法访问客户机上的服务，不过你也可以通过一些特殊的网络配置达到这个目的 (参阅#Tap 网络)\nQEMU 端口转发 QEMU能够将宿主机的端口转发到客户机上以实现一些功能，例如从宿主机上访问客户机的SSH端口。\n举个例子，将宿主机上的10022端口与客户机上的22 (SSH) 端口进行绑定， 对应的QEMU命令如下：\n$ qemu-system-x86_64 disk_image -nic user,hostfwd=tcp::10022-:22 确认你客户机上的sshd程序正在运行，然后可以通过如下命令连接到客户机的SSH端口\n$ ssh guest-user@localhost -p 10022 你可以用 SSHFS 把客户机的整个文件系统都挂到宿主机上，这样就可以在宿主机上对客户机的文件系统进行读写了。\n想进行多端口转发的话, 只需要在-nic参数中指定多个hostfwd, 以VNC端口为例:\n$ qemu-system-x86_64 disk_image -nic user,hostfwd=tcp::10022-:22,hostfwd=tcp::5900-:5900 QEMU 的内置SMB服务器 QEMU的文档中指出它有一个内置的SMB服务器，但实际上，它只是在宿主机上加载一个自动生成的smb.conf配置文件 (位于/tmp/qemu-smb.random_string)，然后启动宿主机上的Samba，使得客户机能够通过一个IP地址进行访问 (默认的IP地址是10.0.2.4)。这个方法只适用于用户网络，在你不想在宿主机开启通常的Samba服务 (客户机同样能访问这类Samba服务) 时这个方法还挺好用的。\n宿主机上必须安装 Samba。通过如下QEMU命令启用这项特性:\n$ sudo apt install samba $ qemu-system-x86_64 disk_image -net nic -net user,smb=shared_dir_path shared_dir_path 就是你想要在宿主机和客户机之间共享的目录。\n接着，在客户机内，你应该能够通过10.0.2.4访问到名为qemu的共享文件夹。例如在Windows Explorer中前往 \\\\10.0.2.4\\qemu 这个地址。\n注意：\n 如果你像这样多次指定共享选项 -net user,smb=shared_dir_path1 -net user,smb=shared_dir_path2 or -net user,smb=shared_dir_path1,smb=shared_dir_path2 qemu只会共享参数中最后的一个目录。 如果你不能访问共享文件夹且客户机系统为 Windows, 请检查 NetBIOS 协议是否被启用 并确认防火墙没有屏蔽NetBIOS协议的 端口 如果你不能访问共享文件夹且客户机系统为 Windows 10 Enterprise 或 Education 或 Windows Server 2016, 请启用游客访问.  共享多个文件夹并在运行时增删文件夹的一个方法是：共享一个空目录，然后在其中创建指向其余共享目录的符号链接。可以用下面的脚本修改SMB服务器的配置，这个脚本还能使宿主机上不允许执行的文件在客户机内拥有执行权限。\n#!/bin/bash eval $(ps h -C smbd -o pid,args | grep /tmp/qemu-smb | gawk \u0026#39;{print \u0026#34;pid=\u0026#34;$1\u0026#34;;conf=\u0026#34;$6}\u0026#39;) echo \u0026#34;[global] allow insecure wide links = yes [qemu] follow symlinks = yes wide links = yes acl allow execute always = yes\u0026#34; \u0026gt;\u0026gt; $conf # in case the change is not detected automatically: smbcontrol --configfile=$conf $pid reload-config 仅当客户机第一次访问到网络驱动后，才能将该脚本启用，并作用于qemu启动的SMB服务器。共享多文件的另一个方法是在配置文件里加入额外的共享路径，就像下面这样\n$ echo \u0026#34;[myshare] path=another_path read only=no guest ok=yes force user=username\u0026#34; \u0026gt;\u0026gt; $conf 这个共享文件夹可以在客户机内通过\\\\10.0.2.4\\*myshare*访问。\n网络 采用TAP设备（tun 与 tap 设备，都是虚拟网络设备，tun 设备用来实现三层隧道（三层 ip 数据报），tap 设备用来实现二层隧道（二层以太网数据帧）。）和网桥（使用网桥可以将多个接口连接到同一网段内，这一功能等同于交换式集线器。）的虚拟网络的性能应该会比使用用户模式网络或VDE要好，原因在于TAP设备和网桥是在内核中实现的。\n此外，虚拟网络的性能可以通过将网络设备直接注册到虚拟机中改善，这比默认情况下模拟e1000 NIC的性能表现要更好，参阅 #安装 virtio 驱动 获得更多相关信息。\n关于链路层地址的限制 若在QEMU启动中指定了 -net nic 参数，QEMU将会为虚拟机注册一块虚拟网卡，其链路层地址为 52:54:00:12:34:56 。然而，当在多台虚拟机之间搭建桥接网络时，每台虚拟机在tap设备的虚拟机端都需要拥有一个独一无二的链路层地址 (MAC)，否则网桥会因为收到多个不同源却拥有相同MAC地址的数据包而无法正常工作。即使你为多个tap设备配置了不同的MAC地址也依旧会出现这个问题，因为当数据包通过tap设备时，tap设备并不会改写包内的链路层地址。\n因此请确保每个虚拟机拥有自己独一无二的网卡地址, 并且它们都以 52:54: 开头。 可以通过如下命令手动设置虚拟机的MAC地址, 下面的\u0026rsquo;X\u0026rsquo;可以替换成任何16进制字符:\n$ qemu-system-x86_64 -net nic,macaddr=52:54:XX:XX:XX:XX -net vde disk_image 用户模式 默认情况下，没有任何-netdev参数，QEMU将使用带有内置DHCP服务器的用户模式网络。当您的虚拟机运行其DHCP客户端时，将为其分配IP地址，它们将能够通过QEMU伪装的IP来访问物理主机的网络。\n警告： 仅适用于TCP和UDP协议，因此ICMP协议（包括ping）将不起作用。 请勿使用ping测试网络连接。\n如果主机已连接Internet，则此默认配置可以使您的虚拟机轻松访问Internet。但是如果您同时启动多个虚拟机，则虚拟机将无法在外部网络上直接看到，虚拟机也将无法相互通信。\nQEMU的用户模式网络可以提供更多功能，例如内置TFTP或SMB服务器，将主机端口重定向到虚拟机（例如，允许SSH连接到虚拟机）或将虚拟机连接到VLAN（vlan 全程 virtual lan，能够用来虚拟分配以太网。归属于不同的 VLAN ID 的设备之间需要一个路由才能够通信，这意味这不同的 VLAN ID 将以太网划分成了不同的分组。），以便它们可以彼此通信。 有关更多详细信息，请参见-net user标志上的QEMU文档。\n但是，用户模式网络在效用和性能上都有局限性。更高级的网络配置需要使用TAP设备或其他方法。\nTap 网络 Tap devices是一个Linux内核特性，允许您创建作为真实网络接口的虚拟网络接口。发送到tap接口的包将被传递到一个用户空间程序(如QEMU)，该程序将自己绑定到该接口。\nQEMU可以为虚拟机使用tap网络，因此发送到tap接口的包将被发送到虚拟机，并显示为来自虚拟机中的网络接口(通常是以太网接口)。相反，虚拟机通过其网络接口发送的所有内容都将出现在tap接口上。\nLinux桥接驱动程 序支持Tap设备，因此可以将Tap设备彼此桥接在一起，也可以连接其他主机接口，如eth0。如果您希望您的虚拟机能够相互通信，或者希望LAN上的其他机器能够与虚拟机通信，那么这是非常理想的方案。\n警告： 如果您将tap设备和一些主机接口桥接在一起，例如eth0，您的虚拟机将直接出现在外部网络上，这将使它们遭受攻击的可能。根据您的虚拟机可以访问的资源，您可能需要采取所有precautions来保护您的虚拟机。如果风险太大,虚拟机没有资源或您设置多个虚拟机,一个更好的解决方案可能是使用host-only networking建立NAT。在这种情况下，您只需要在主机上安装一个防火墙，而不是为每个虚拟机安装多个防火墙。\n正如在用户模式网络部分中指出的，tap设备提供比用户模式具有更高的网络性能。如果虚拟机中的操作系统支持virtio网络驱动程序，那么网络性能也会显著提高。假设使用tap0设备，virtio驱动程序在客户端上使用，并且没有使用脚本来帮助启动/停止网络，使用下面的qemu命令：\n-net nic,model=virtio -net tap,ifname=tap0,script=no,downscript=no 但是，如果已经使用带有virtio网络驱动程序的Tap设备，则甚至可以通过启用vhost来提高网络性能，例如：\n-net nic,model=virtio -net tap,ifname=tap0,script=no,downscript=no,vhost=on 仅主机网络\n如果为网桥提供了IP地址，并且使能发往该网桥的流量允许，但没有实际接口（例如eth0）连接到网桥，则虚拟机与虚拟机间，虚拟机与主机间能够相互通信。但是，如果您没有在物理主机上设置IP掩蔽，则他们将无法与外部网络进行通信。 此配置被其他虚拟化软件（例如VirtualBox）称为“仅主机网络模式”。\n提示：\n  如果你想设置IP掩蔽，例如虚拟机的NAT，请查看Internet sharing#Enable NAT页面。\n  您也许想在网桥接口上运行一个DHCP服务器来服务虚拟网络。例如，使用172.20.0.1/16子网，dnsmasq作为DHCP服务器:\n# ip addr add 172.20.0.1/16 dev br0 # ip link set br0 up # dnsmasq --interface=br0 --bind-interfaces --dhcp-range=172.20.0.2,172.20.255.254   内部网络\n如果您不为网桥提供IP地址并在iptables添加INPUT规则链，将所有流向网桥中的数据丢弃，则虚拟机将能够彼此通信，但无法与物理主机或外部网络通信。此配置被其他虚拟化软件（例如VirtualBox）称为“内部网络”。您将需要为虚拟机分配静态IP地址，或在其中一个虚拟机上运行DHCP服务器。\n在默认情况下，iptables将丢弃桥接网络中的数据包。您可能需要使用这样的iptables规则来允许桥接网络中的数据包:\n# iptables -I FORWARD -m physdev --physdev-is-bridged -j ACCEPT 使用 qemu-bridge-helper 桥接网络\n这种方法不需要启动脚本，并且很容易适应多个tap和多个桥。它使用/usr/lib/qemu/qemu-bridge-helper，允许在现有桥上创建tap设备。\n提示： 参见 Network bridge 获取创建网桥的信息.\n首先，创建一个配置文件，包含QEMU使用的所有网桥的名称:\n/etc/qemu/bridge.conf allow bridge0 allow bridge1 ... 现在启动虚拟机：\n$ qemu-system-i386 -net nic -net bridge,br=bridge0 [...] 在多个TAP设备的情况下，最基本的用法是要为所有NIC指定VLAN：\n$ qemu-system-i386 -net nic -net bridge,br=bridge0 -net nic,vlan=1 -net bridge,vlan=1,br=bridge1 [...] 手工创建网桥\n将虚拟机连接到主机接口，如eth0，这可能是最常见的配置。这种配置使虚拟机看起来直接位于外部网络，与物理主机位于同一以太网段。\n物理设备和Tap设备之间通过iptables进行网络共享\n桥接网络能在有线接口(例如eth0)之间工作，并且很容易设置。但是，如果主机通过无线设备连接到网络，则无法进行桥接。\n解决这个问题的一种方法是，给tap设备设置一个静态IP，使linux自动处理它的路由，然后通过iptables规则转发tap接口和连接到网络的设备之间的通信。\n通过 VDE2 配置网络 VDE全称为Virtual Distributed Ethernet，作为uml_switch的一个扩展，是一个用于管理虚拟网络的工具包\n其基本的思想是创建一个虚拟的开关，就如插座那样，允许虚拟机和物理机通过\u0026quot;插入\u0026quot;连接彼此。下面的配置非常简单，然而，VDE的功能远比展示的更强大，其能够接入虚拟开关，在不同的主机上运行它们并监听开关上的通信。\n本方法的优点在于无需sudo特权，普通用户一般没有运行modprobe的权限。\nVDE2 网桥 任何连接到vde上的虚拟机都会暴露给外部。举个例子，每台虚拟机都能直接从ADSL路由器那收到DHCP的配置信息。\n简化配置参数 如果你经常需要以不同的网络配置选项运行QEMU，就会发现时常得输入大量的-netdev和-device选项组合，这些是大量重复性的劳动。可以用-nic选项将二者结合，就如下面这样，底下这些参数：\n-netdev tap,id=network0,ifname=tap0,script=no,downscript=no,vhost=on -device virtio-net-pci,netdev=network0 可简化为:\n-nic tap,script=no,downscript=no,vhost=on,model=virtio-net-pci 要注意的是缺失了网络ID，因此将会以model=创建这些设备。{ic|-nic}}命令的前半部分参数正是-netdev的参数，而后半部分参数（model=之后的部分）则与设备有关，原本设备所提供的参数同样可以在此使用（例如，可以指定smb=）。若要完全禁用网络，可以用-nic none。\n图形 QEMU 可以使用一下几个图形输出：std, cirrus, vmware, qxl, xenfs 和 vnc。\n使用 vnc 选项，你可以单独运行客户机，并且通过 VNC 连接。\nstd 使用 -vga std 你可以得到最高 2560 x 1600 像素的分辨率。从 QEMU 2.2 开始是默认选项。\nqxl QXL是一个支持2D的并行虚拟化图形驱动。需要在客户机中安装驱动并在启动QEMU时设置-vga qxl选项。你可能也会想使用#SPICE优化QXL的图形表现。\n在Linux客户机中，需要加载qxl和bochs_drm这两个内核模块，以获得一个比较好的效果。\nQXL设备的默认VGA内存大小为16M，这样的内存大小最高支持QHD (2560x1440)的分辨率，如果想要一个更高的分辨率，请增加vga_memmb。\nvmware 尽管Bug有点多，但相比于std和cirrus它的表现会更好。对于Arch Linux客户机来说可以安装xf86-video-vmware和xf86-input-vmmouse获取VMware驱动。\nvirtio virtio-vga / virtio-gpu 是一个基于virgl的3D并行虚拟化图形驱动。目前依旧处于开发中，仅支持最近的（\u0026gt;= 4.4）的Linux客户机，且需要以gallium-drivers=virgl选项编译mesa (\u0026gt;=11.2)。\n若要在客户机上启用3D加速，那么需要用-vga virtio选项选择此vga，并用-display sdl,gl=on或-display gtk,gl=on在显示设备上启用opengl上下文，这两个选项分别适用于sdl输出和gtk输出。如果配置成功了，那么在客户机的kernel log里可以看到：\n# dmesg | grep drm [drm] pci: virtio-vga detected [drm] virgl 3d acceleration enabled cirrus cirrus是2.2之前默认的图形选项，不应当在现代操作系统中使用它。\nnone 这就像一台完全没有VGA卡的PC，无法通过-vnc访问它。另外，这种情况与使用-nographic选项不同，-nographic会让QEMU模拟VGA卡，只是关闭了SDL输出。\nSPICE SPICE project旨在为用户提供一种完全开源的方式，无缝地对虚拟机进行远程访问。\nVNC 可以用-vnc :*X*选项将QEMU的VGA输出重定向至VNC会话中。将*X*替换为输出目标的编号（0代表之后监听在5900，1代表监听在5901\u0026hellip;）。\n$ qemu-system-x86_64 -vnc :0 警告： 默认的VNC服务器没有使用任何验证手段，用户可以从任何主机上连接到VNC。\n基本的口令验证\n可以通过使用password选项很容易地设置访问口令。必须在QEMU Monitor中指定口令，仅当用户提供口令时才有可能连接到VNC。\n$ qemu-system-x86_64 -vnc :0,password -monitor stdio 在QEMU Monitor中设置口令需使用change vnc password命令，然后指定一个口令。\n底下的命令将在启动VNC时直接为其设置口令：\n$ printf \u0026quot;change vnc password\\n%s\\n\u0026quot; MYPASSWORD | qemu-system-x86_64 -vnc :0,password -monitor stdio 注意： 口令被限制在8个字符内，可以用暴力破解的方式猜到口令。因此在公网上推荐使用更细致的保护措施。\n音频 -audiodev标识用于设定后端音频驱动及其相关选项。最简单的情况下，你需要选择一个驱动并设置一个id。\n-audiodev pa,id=snd0 使用音频设备 Intel HD Audio\n模拟Intel HD Audio需要添加控制器和编解码器设备。可以用如下命令列出可用的Intel HDA Audio设备：\n$ qemu-system-x86_64 -device help | grep hda 添加音频控制器：\n-device ich9-intel-hda 添加音频编解码器并将其映射到宿主机的音频后端id上。\n-device hda-output,audiodev=snd0 Intel 82801AA AC97\n模拟AC97需要添加声卡设备并将其映射到宿主机的一个音频后端id上。\n-device AC97,audiodev=snd0 无音频设备 通过如下命令获取支持模拟的音频驱动列表：\n$ qemu-system-x86_64 -soundhw help 比如，要在客户机上模拟hda驱动，需要使用-device intel-hda -device hda-duplex选项启动QEMU。\n注意： 客户机的显卡模拟驱动可能也会导致客户机中的音频质量出现问题，需要一个个进行排查。使用qemu-system-x86_64 -h | grep vga列出可用的选项\n安装 virtio 驱动 QEMU为用户提供并行虚拟化块设备和网络设备的能力，其是借助virtio驱动实现的，拥有更好的性能表现以及更低的开销。\nvirtio块设备需要使用-drive指定一个disk image的参数，且需要带上if=virtio参数：\n$ qemu-system-x86_64 -boot order=c -drive file=disk_image,if=virtio 网络配置也是类似的：\n$ qemu-system-x86_64 -nic user,model=virtio-net-pci 注意： 仅有当客户机有virtio设备对应的驱动时该方法才能起效，Linux是有这方面支持的，不过无法保证这些驱动能够兼容其他操作系统。\n以下以windows为例。\n块设备驱动 Windows没有自带virtio驱动，因此需要在安装时加载该驱动。镜像文件可以从Fedora 仓库下载。\n通过ISO加载只对Windows Vista和Windows Server 2008及其之后的版本有效。这个方法的具体操作是在主磁盘设备和Windows安装盘外挂载一个额外的cdrom设备，将系统镜像与virtio驱动一同加载：\n$ qemu-system-x86_64 ... \\ -drive file=windows_disk_image,index=0,media=disk,if=virtio \\ -drive file=windows.iso,index=2,media=cdrom \\ -drive file=virtio.iso,index=3,media=cdrom \\ ... 在安装过程中，Windows Installer会询问你“Where do you want to install Windows?”，其会返回一个警告表示没有找到任何磁盘设备。接下来跟着如下示例中的步骤进行操作（基于Windows Server 2012 R2 with Update）：\n Select the option Load Drivers. Uncheck the box for Hide drivers that are not compatible with this computer\u0026rsquo;s hardware. Click the browse button and open the CDROM for the virtio iso, usually named \u0026ldquo;virtio-win-XX\u0026rdquo;. Now browse to E:\\viostor\\[your-os]\\amd64, select it, and confirm.  现在应该能看到virtio磁盘出现在列表中了，等待着被选中、格式化并安装。\n网络驱动 安装virtio网络驱动程序要容易一些，只需如上所述添加-net参数即可。\n$ qemu-system-i386 -m 4G -vga std -drive file=windows_disk_image,if=virtio -net nic,model=virtio-net-pci -cdrom virtio-win-0.1-185.iso Windows将检测网络适配器并尝试为其找到驱动程序。如果失败，请转到“设备管理器”，找到带有感叹号图标的网络适配器（双击打开），切换到驱动程序并单击“更新驱动程序”，然后选择虚拟CD-ROM。别忘了选中显示要递归搜索目录的复选框。\nBalloon 驱动 如果想要追踪客户机内存状态（比如通过virsh的dommemstat命令）或者在运行时改变客户机内存大小（尽管依然无法改变实际的内存大小，不过可以通过inflating balloon驱动限制内存的使用），那么请在客户机上安装balloon驱动吧。\nQEMU 监视器 QEMU运行时会提供一个监视器console界面以方便用户同虚拟机进行交互。QEMU监视器提供了许多有趣的功能，例如获取当前虚拟机的信息，热插拔设备，创建快照等。在QEMU监视器console中运行help或?命令获得完整的命令列表。\n访问QEMU监视器Console 图形化界面\n当使用默认的std图形选项时，可以通过按下Ctrl+Alt+2组合键或从QEMU窗口上的View \u0026gt; compatmonitor0访问到QEMU监视器。若要返回到虚拟机的图形界面，那么按下Ctrl+Alt+1或者View \u0026gt; VGA就行。\n然而，这种标准的访问方式不够方便，而且并不是在QEMU的所有图形化输出方式中都适用。\nTelnet\n启动QEMU时带上-monitor telnet:127.0.0.1:*port*,server,nowait参数可以启用telnet。虚拟机启动后可以通过telnet访问到监视器：\n$ telnet 127.0.0.1 port 注意： 如果指定 127.0.0.1 作为监听地址，那么只能在运行QEMU的宿主机上连接到该监视器。如果想要远程访问，QEMU需要在0.0.0.0上进行监听：-monitor telnet:0.0.0.0:*port*,server,nowait。还要记住的是，最好对firewall进行配置，该连接是完全不进行认证和加密的，因此需要通过防火墙确保本地网络环境是可信的。\nUNIX socket\n通过-monitor unix:*socketfile*,server,nowait参数运行QEMU，之后就可以通过socat或openbsd-netcat连接到监视器上。\n例如，如果QEMU是通过如下命令启动：\n$ qemu-system-x86_64 [...] -monitor unix:/tmp/monitor.sock,server,nowait [...] 就可以像这样连接到监视器上：\n$ socat - UNIX-CONNECT:/tmp/monitor.sock 或者通过这种方式:\n$ nc -U /tmp/monitor.sock TCP\n可以使用-monitor tcp:127.0.0.1:*port*,server,nowait参数将监视器暴露于TCP端口上，然后用netcat（openbsd-netcat或gnu-netcat都可）进行连接：\n$ nc 127.0.0.1 port 注意： 为了能够从其它设备上通过TCP socket访问到监视器，而不仅仅从运行QEMU的主机上连接，需要像前面Telnet中描述的那样，在0.0.0.0地址上进行监听。\n标准 I/O\n如果以-monitor stdio参数运行QEMU，那么其实是可以在运行QEMU的终端下访问到监视器的。\n在Monitor conosle下向虚拟机发送按键行为 由于在某些配置下，宿主机可能会拦截一些按键组合另作他用，这导致要在虚拟机中触发一些特定按键组合变得有些困难（一个显然的例子就是Ctrl+Alt+F*组合，该组合用于改变当前的tty）。我们采用在monitor console下发送按键组合的方式解决该问题。只需切换到monitor console下，然后使用sendkey命令，即可将按键转发至虚拟机中，例如：\n(qemu) sendkey ctrl-alt-f2 通过 monitor console 创建快照和管理快照 注意： 该特性\u0026quot;只\u0026quot;支持qcow2格式的虚拟机磁盘镜像，对于raw是无效的。\n有时候我们很需要将虚拟机的当前状态进行保存，或是将虚拟机重置到之前的快照状态，而且最好是随时能进行这些操作。QEMU monitor console为用户提供了必要的功能，进行快照创建，快照管理，以及快照恢复。\n Use savevm name 用于创建一个名为name的快照。 Use loadvm name 用于将虚拟机状态恢复至快照name。 Use delvm name 用于删除快照name。 Use info snapshots 用于查看保存的快照列表，这些快照由一个自增长的ID和标签名（用户创建快照时赋予）进行标识。  以冻结模式运行虚拟机 QEMU支持以冻结态运行虚拟机（需使用-snapshot参数），换句话说，虚拟机关闭时，对于虚拟机的一切修改都会丢弃。当用户对磁盘镜像写入时，这些变动最终写入的位置是/tmp目录下的一个临时文件，QEMU关机时将会把他们丢弃。\n不过，即使虚拟机运行于冻结状态下，依旧可以通过monitor console将这些变化写入磁盘镜像（如果你想的话）。使用下面的命令：\n(qemu) commit all 另外如果在冻结状态下创建快照，这些快照在QEMU退出时都会被丢弃，除非你显式地commit了他们。\nmonitor console中的开机和暂停命令 在QEMU monitor console下也可以模拟对物理机的一些操作：\n system_powerdown 会向虚拟机发送ACPI关机信号，效果就类似物理机上按下电源按钮。 system_reset 会重置虚拟机，类似物理机上的重置按钮。该操作可能导致数据丢失或文件系统的损坏，这是因为虚拟机并不是\u0026quot;干净地\u0026quot;重启的。 stop 会暂停虚拟机。 cont 使暂停的虚拟机恢复运行。  虚拟机截屏 可以在monitor console下运行该命令，获取PPM格式的截屏图片：\n(qemu) screendump file.ppm QEMU 机器协议 QEMU机器协议（QMP）是一个基于JSON格式的协议，使得其他应用程序可以通过该协议控制QEMU实例。类似#QEMU 监视器，其提供了与运行中的虚拟机进行交互的能力，且能够编程进行控制。关于QMP各命令的描述可以在这个qmp-commands链接中找到。\n技巧 改善虚拟机的性能表现 底下是一些可以改善虚拟机性能表现的技术，例如：\n  启用#启用 KVM：QEMU的启动命令加上-enable-kvm选项。\n  通过-cpu host选项让QEMU模拟宿主机上的特定CPU，如果没有该选项QEMU尝试模拟的是一个更为通用的CPU。\n  特别的，如果客户机是Windows，启用Hyper-V enlightenments可以改善性能：-cpu host,hv_relaxed,hv_spinlocks=0x1fff,hv_vapic,hv_time.\n  如果宿主机有多个核心，可以用-smp选项为客户机分配更多核心。\n  检查是否为虚拟机分配的足够的内存。默认情况下，QEMU仅仅为每台虚拟机分配128MiB的内存，可以使用-m选项分配更多的内存。例如，-m 1024代表启动一台内存为1024MiB的虚拟机。\n  如果客户机操作系统支持相关的驱动，可以使用virtio创建网络设备或块设备。\n  使用TAP设备代替user-mode网络，参阅#Tap 网络。\n  如果客户机需要进行大量的磁盘写工作，在宿主机文件系统上设置合适的挂载选项可以优化该工作。例如，可以用barrier=0选项挂载一个ext4 file system。在使用这些性能强化选项之前最好阅读相关文档，因为性能上的提升通常伴随着数据完整性下降的代价。\n  如果有一块原始磁盘镜像，你可能会想要禁用cache：\n$ qemu-system-x86_64 -drive file=disk_image,if=virtio,cache=none   使用原生的Linux AIO：\n$ qemu-system-x86_64 -drive file=disk_image,if=virtio,aio=native,cache.direct=on   如果正同时运行多台虚拟机，而它们拥有同样的操作系统，可以通过启用内核页归并节省内存。参阅#开启KSM。\n  在一些情况下，可以在运行时从安装了balloon驱动的客户机上回收内存，这需要QEMU启动该客户机时使用-device virtio-balloon选项。\n  允许使用一个ICH-9 AHCI控制器的仿真层，尽管它并不稳定。AHCI的仿真模拟支持NCQ，因此可以同时处理多个读写请求：\n$ qemu-system-x86_64 -drive id=disk,file=disk_image,if=none -device ich9-ahci,id=ahci -device ide-drive,drive=disk,bus=ahci.0   参阅 https://www.linux-kvm.org/page/Tuning_KVM 获取更多信息\n开机时启动QEMU虚拟机 通过libvirt实现\n如果虚拟机是通过libvirt设置的，可以用virsh autostart将其配置为开机自启，或者通过virt-managerGUI中虚拟机的Boot Options，选择\u0026quot;Start virtual machine on host boot up\u0026quot;实现开机自启。\n通过systemd service实现\n可以用如下的systemd unit和config配置开机时启动QEMU VM。\n/etc/systemd/system/qemu@.service [Unit] Description=QEMU virtual machine [Service] Environment=\u0026quot;haltcmd=kill -INT $MAINPID\u0026quot; EnvironmentFile=/etc/conf.d/qemu.d/%i ExecStart=/usr/bin/qemu-system-x86_64 -name %i -enable-kvm -m 512 -nographic $args ExecStop=/bin/bash -c ${haltcmd} ExecStop=/bin/bash -c 'while nc localhost 7100; do sleep 1; done' [Install] WantedBy=multi-user.target 注意： 为了方便地结束任务，该service会等待至console端口被释放（这意味着VM已被关闭）。\n接着创建per-VM配置文件，命名为/etc/conf.d/qemu.d/*vm_name*，在其中设置好args和haltcmd变量，配置示例：\n/etc/conf.d/qemu.d/one args=\u0026quot;-hda /dev/vg0/vm1 -serial telnet:localhost:7000,server,nowait,nodelay \\ -monitor telnet:localhost:7100,server,nowait,nodelay -vnc :0\u0026quot; haltcmd=\u0026quot;echo 'system_powerdown' | nc localhost 7100\u0026quot; # or netcat/ncat /etc/conf.d/qemu.d/two args=\u0026quot;-hda /srv/kvm/vm2 -serial telnet:localhost:7001,server,nowait,nodelay -vnc :1\u0026quot; haltcmd=\u0026quot;ssh powermanager@vm2 sudo poweroff\u0026quot; 对该变量的描述如下：\n args - 使用的QEMU命令行参数。 haltcmd - 安全关闭虚拟机的命令，在第一个例子中，QEMU monitor是通过-monitor telnet:..选项暴露至telnet，因而关闭虚拟机是通过nc命令在monitor console中发送system_powerdown，完成ACPI关机的工作。在另一个例子里，使用的则是SSH。  若要设置启动时运行哪个虚拟机，enable qemu@*vm_name*.service这个systemd单元\n鼠标整合 添加-usb -device usb-tablet选项以避免点击客户机系统的窗口时鼠标被捕获。该选项代表QEMU能够在不捕获鼠标的情况下，向系统报告鼠标的位置，该选项启用时还会覆盖PS/2鼠标模拟功能。 命令示例：\n$ qemu-system-x86_64 -hda disk_image -m 512 -usb -device usb-tablet 宿主机的USB设备传递至虚拟机 从客户机访问连接到宿主机USB口的设备是可能的，首先需要识别设备连接的位置，可以用lsusb命令找到设备连接位置，例如：\n$ lsusb ... Bus 003 Device 007: ID 0781:5406 SanDisk Corp. Cruzer Micro U3 上面以显示的数字分别用于标识\n 003 host_bus 007 host_addr 0781 vendor_id 5406 product_id  基本的思想是在QEMU中-device usb-ehci,id=ehci或-device qemu-xhci,id=xhci分别对EHCI (USB 2)或XHCI (USB 3)（在win7无法自动安装 USB3 驱动，因此应用 USB2）控制器进行模拟，然后将物理设备通过-device usb-host,..选项进行添加。\n识别出该设备，并将其连接至任一总线以及宿主机上的地址，通用的语法如下：\n-device usb-host,bus=controller_id.0,vendorid=0xvendor_id,productid=0xproduct_id 应用于上面例子中使用的设备，它变成：\n-device usb-ehci,id=ehci -device usb-host,bus=ehci.0,vendorid=0x0781,productid=0x5406 运行QEMU时会遇到 libusb couldn't open USB device Permission denied 权限错误，可以通过 udev 为设备设定合适的权限。\n$ vi /etc/udev/rules.d/50-usbtinyisp.rules SUBSYSTEMS==\u0026#34;usb\u0026#34;, ATTRS{idVendor}==\u0026#34;0781\u0026#34;, ATTRS{idProduct}==\u0026#34;5406\u0026#34;, GROUP=\u0026#34;vane\u0026#34;, MODE=\u0026#34;0660\u0026#34; $ ls -al /dve/bus/usb/003/007 crw-rw---- 1 root vane 189, 11 Nov 7 12:37 /dev/bus/usb/003/007 使用SPICE进行USB重定向 使用#SPICE时可以将USB设备从客户端重定向至虚拟机中，无需使用QEMU命令。还支持为配置USB重定向插槽数（插槽数将决定可同时重定向的最大设备数）。相比于前面那种使用-usbdevice进行重定向的方法，SPICE方法的优势在于可以在虚拟机启动后USB设备热插拔，移除或添加USB设备时无需停机。这个方法还允许通过网络将客户端的USB设备重定向至服务端。总之，其是在QEMU虚拟机中使用USB设备最灵活的方法。\n开启KSM Kernel Samepage Merging (KSM) 是Linux内核的一个特性，允许应用程序向内核申请同其他申请页归并的进程进行页归并，KSM机制允许客户虚拟机之间进行页共享。当许多客户机运行相似的操作系统时，这个机制可以节省客观的内存。\n多屏支持 Linux的QXL驱动支持默认支持四头（虚拟屏幕），可以通过qxl.heads=N这一内核参数进行变更。\n复制和粘贴 在宿主机和客户机之间共享剪贴板的方法之一是使用SPICE远程桌面协议，通过SPICE客户端访问客户机，你需要遵照#SPICE节中描述的步骤，通过该方式运行的客户机将支持与宿主机进行复制粘贴的操作。\nQEMU-KVM Win7 环境准备   安装QEMU：sudo apt install qemu-kvm\n  下载 Windows virtio driver iso：https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/archive-virtio/virtio-win-0.1.102/，因为要将磁盘挂接为 virtio 磁盘。\n需使用 virtio-win-0.1.102，我使用最新的 virtio-win-0.1.208.iso，Windows安装程序会提示驱动没有包含签名错误No signed device drivers were found. Make sure that the installation media contains the correct drivers, and then click OK\n  创建系统盘 qemu-img create -f qcow2 Windows7-VM.img 30G，这将作为Win7的操作系统盘。\n  创建启动脚本\n$ vi start_Windows7_VM.sh #!/bin/bash DISKIMG=$HOME/.vm/Windows7-VM.img exec qemu-system-x86_64 --enable-kvm \\ \t-cpu host,hv_relaxed,hv_spinlocks=0x1fff,hv_vapic,hv_time \\ \t-drive file=${DISKIMG},if=virtio \\ \t-net nic,model=virtio-net-pci -net user,smb=$HOME/Downloads \\ \t-m 4096 \\ \t-smp cores=2,threads=4 \\ \t-monitor stdio \\ \t-vga std \\ \t-audiodev pa,id=snd0 -device ich9-intel-hda -device hda-output,audiodev=snd0 \\ \t-usb -device usb-tablet \\ \t-rtc base=localtime,clock=host \\ \t-name \u0026#39;Windows7 VM\u0026#39; \\ \t$@ $ chmod u+x start_Windows7_VM.sh   ./start_Windows7_VM.sh -boot d -cdrom $HOME/Downloads/cn_windows_7_ultimate_x64_dvd_x15-66043.iso -drive file=$HOME/Downloads/virtio-win-0.1.102.iso,index=3,media=cdrom\n  安装 Win 7  选择 Custom（advanced）  选择 virtio 磁盘  选择 virtio disk driver  安装 Win7 Virtio SCSI Driver  安装好以后，就可以看到安装的目标磁盘了  进入常规的 Win7 安装流程  安装 Virtio 网络驱动 但是安装失败：\n尝试 device manager：\n[QEMU 的内置SMB服务器](#QEMU 的内置SMB服务器) 宿主机的USB设备传递至虚拟机 QEMU-KVM WinXP SP3 windows_xp.sh #!/bin/bash DISKIMG=$HOME/.vm/WindowsXP-VM.img exec qemu-system-x86_64 --enable-kvm \\ \t-cpu host,hv_relaxed,hv_spinlocks=0x1fff,hv_vapic,hv_time \\ \t-drive file=${DISKIMG} \\ \t-net nic,model=rtl8139 -net user,smb=$HOME/Downloads \\ \t-m 4096 \\ \t-cpu Nehalem \\ \t-rtc base=localtime,clock=host \\ \t-usb -device usb-tablet \\ \t-monitor stdio \\ \t-vga std \\ \t$@ Windows XP cannot connect to samba share You have \u0026lsquo;client min protocol = NT1\u0026rsquo; set, there is another similar setting \u0026lsquo;server min protocol\u0026rsquo; which from Samba 4.11.0 is set to SMBv2. Your XP is probably only using SMBv1, so it will not be able to see or connect to your Samba server.\nSo you have to edit the [global] section in the /etc/samba/smb.conf and add the server min protocol = NT1 option here. Then restart the Samba service.\n例如：\n$ ps h -C smbd -o pid,args 1707 /usr/sbin/smbd --foreground --no-process-group $ vim /tmp/qemu-smb.SL95F1/smb.conf [global] server min protocol = NT1 $ sudo smbcontrol 1707 reload-config 或者编写如下脚本\n#!/bin/bash echo \u0026#34;[global] server min protocol = NT1\u0026#34; \u0026gt;\u0026gt; /tmp/**/smb.conf sudo smbcontrol $(ps h -C smbd -o pid) reload-config Windows XP 上网提示：您的时钟快了/慢了 此时，无论你怎么调整日期和时间，都不能解决上网问题。即使把日期从2020年调整到2015年，此时虽然不在提示 “您的时钟快了”，也有证书期限等异常。\n出现这种问题的原因，是因为 Windows XP 确实太老了，Google Chrome、Mozilla Firefox 及其内核的浏览器已经不支持了。\nVirtual Machine Manager 键盘不能输入的问题 在 Display 中，设定 keymap，比如 en-us\n无网络 在 NIC 中，将 Device model 设置为 rtl8139\nQEMU-KVM Gentoo Configuration Host To create a disk image for the virtual machine, run:\n$ qemu-img create -f qcow2 Gentoo-VM.img 30G Download a minimal Gentoo LiveCD from here.\nSince QEMU requires a lot of options, it would be a good idea to put them into a shell script, e.g.:\n$ vim start_Gentoo_VM.sh #!/bin/bash DISKIMG=$HOME/VirtualMachine/Gentoo-VM.img exec qemu-system-x86_64 -enable-kvm \\  -bios /usr/share/edk2-ovmf/OVMF_CODE.fd \\  -cpu host \\  -drive file=${DISKIMG},if=virtio \\  -netdev user,id=vmnic,hostname=Gentoo-VM,hostfwd=tcp::10022-:22 \\  -device virtio-net,netdev=vmnic \\  -device virtio-rng-pci \\  -m 4G \\  -smp 2 \\  -monitor stdio \\  -vga std \\  -audiodev pa,id=snd0 -device ich9-intel-hda -device hda-output,audiodev=snd0 \\  -name \u0026#34;Gentoo VM\u0026#34; \\  $@ $ chmod u+x start_Gentoo_VM.sh Change the path to your disk image Gentoo-VM.img in the script. You can add more options when calling the script. To boot the disk image, run:\n$ ./start_Gentoo_VM.sh -boot d -cdrom $HOME/Downloads/install-amd64-minimal-20211107T170547Z.iso Install the guest per the Gentoo Handbook. See the guest section for optimum support. After the installation start the script without the additional options.\nUsing UEFI with QEMU UEFI for x86 QEMU/KVM VMs is called OVMF (Open Virtual Machine Firmware). It comes from EDK2 (EFI Development Kit), which is the UEFI reference implementation.\n$ sudo apt-get install ovmf 检查是否安装，命令为：\n$ dpkg -L ovmf | grep OVMF.fd /usr/share/ovmf/ OVMF.fd /usr/share/qemu/ OVMF.fd 要在虚拟机中运行操作系统的映像文件，添加 -bios /usr/share/ovmf/OVMF.fd。该代码调用名为 OVMF.fd 的文件，该文件是 Qemu 的 UEFI 固件。\n$ qemu-system-x86_64 -bios /usr/share/ovmf/OVMF.fd -cdrom ubuntu-21.04-desktop-amd64.iso 这个名为ovmf的包其实就是名为TianoCore的程序。该名称本身代表开放虚拟机固件)。\n\u0026ldquo;BdsDxe: failed to load Boot0001\u0026rdquo; solution: Try hitting F2 to enter the OVMF settings during guest boot and manually pick a new boot drive option.\nTips 通过 Qemu 安装 Windows 到硬盘 双系统新思路。今天装windows, 在linux上先用虚拟机，把硬盘直通进去，在raw盘上装好，然后更新grub, 再重启就可以直接接进去了。\n这样可以避免装机还要做启动盘，装机过程中的重启也可以避免了。\nwin的安装过程中驱动都是按照虚拟机的配置安装的，但是win10是自动装驱动的，重启进去后过了一会显卡驱动自动都装好了。\nLooking Glass Looking Glass 讓 Linux 可完美玩 Windows 遊戲 超低延遲不掉格\n當用戶安裝了虛擬電腦（VM）實行 Windows，並執行遊戲時，它採用的 KVM frame relay 技術可將 Windows 顯示記憶體，透過 PCI pass-through 直接由 Windows VM 被配置的顯示卡，複製到 Linux 被配置的顯示卡，這樣 Linux 便可在極為低延遲的情況下，接近完美顯示 Windows 遊戲的內容。\n簡單來說，就是一部 Linux 電腦裡面裝有虛擬電腦運行的 Windows，Windows 遊戲實行時，在被配置的顯示卡記憶體資料，在主機板 PCI 通道直接複製到 Linux 被配置的顯示卡。即是說 Windows 遊戲原本畫面，可高速反映到 Liunx 的虛擬電腦軟件上。這樣 Linux 用戶就算不 Dual boot 或使用兩個熒幕，在 Linux 上都可得到接近相同的打機體驗。\nxrdp xrdp 使用 RDP（Microsoft 远程桌面协议）为远程计算机提供图形登录。xrdp 接受来自各种 RDP 客户端的连接：FreeRDP、rdesktop、NeutrinoRDP 和 Microsoft 远程桌面客户端（适用于 Windows、macOS、iOS 和 Android）。\n正如 Windows 到 Windows 远程桌面一样，xrdp 不仅支持图形远程处理，还支持\n 双向剪贴板传输（文本、位图、文件） 音频重定向 驱动器重定向（在远程机器上安装本地客户端驱动器）  RDP 传输默认使用 TLS 加密。\nQEMU/KVM VS Virtualbox Linux 系统上的虚拟化解决方案 – KVM 和 VirtualBox\nKVM 提供了一些 VirtualBox 没有的功能，反之亦然。IT 世界中没有通用工具，因此使用适合您需求的工具非常重要。基本思想是：如果你想安装二进制 Linux 发行版作为来宾，使用 KVM。它速度更快，并且它的驱动程序包含在官方内核树中。如果您的客户涉及大量编译并且需要一些更高级的功能，并且/或者不是 Linux 系统，那么最好使用 VirtualBox。\n技术原因很简单：KVM 更好地与 Linux 集成，它更小更快，虽然你可以在 Linux 以外的其他客户机上使用它，但我们发现体验相当麻烦：BSD 的 I/O 和 Solaris 往往很慢（确切地说，是 OpenIndiana）在引导安装 ISO 后会立即出现恐慌。由于我们使用当前版本的 BSD（并且经常从源代码编译/更新系统）并且还需要 Solaris，我们发现 VirtualBox 是一个更好的选择。Oracle VirtualBox 的另一个优点是它支持挂起，即您可以将机器状态保存在主机的硬盘上并关闭 VirtualBox，当（重新)启动时，系统将从它离开的地方恢复。这就是为什么我们提到源代码编译：如果你有一台嘈杂的机器，你不想一夜之间离开，但你的 Gentoo 虚拟机只是编译一个新的 gcc 版本，暂停机器状态，关闭主机，明天继续。\n桌面虚拟化、KVM 还是 Virtualbox？\n这两者中的哪一个更适合在 Linux 台式机/笔记本电脑上运行 Windows 10 虚拟机？\n  带有virt-manager 的QEMU/KVM应该可以与 Virtualbox 媲美。\nVirtualbox 没问题，特别是如果跨主机操作系统使用相同的虚拟化很重要，但 QEMU/KVM 是更好的投资。QEMU/HAXM 也应该可以在 Mac 和 Windows 上运行，尽管它目前还不够成熟。\n  KVM, obviously. You\u0026rsquo;re probably going to need to learn how to manage it, but it is a much better system and allows abstraction on completely unexposed CPU hardware so you can easily take your image and put it onto another KVM. Windows doesn\u0026rsquo;t like to have it\u0026rsquo;s CPUs exchange on it very often.\n  KVM 与 VirtualBox\n  表现\n这是要考虑的最重要的领域之一，即管理程序的性能将如何影响您的基础架构。KVM 是 1 类管理程序（这些虚拟机管理程序直接运行在宿主机的硬件上来控制硬件和管理客操作系统），而 VirtualBox 是 2 类管理程序（这些虚拟机管理程序运行在传统的操作系统上，就像其他计算机程序那样运行），这意味着 KVM 应该优于 VirtualBox。\n根据SPECvirt_sc2013 基准测试，VirtualBox 通常比 KVM 需要更多时间来创建和启动服务器，而 KVM 以接近本机的速度运行应用程序，比其他行业管理程序更快。尽管对于典型负载，差异可能微不足道。\n  管理程序管理\n这两个给定的应用程序都可以通过 GUI 进行管理。Virtualbox 相对来说有更好的 GUI，但 KVM 的当前 GUI 使其管理比以往任何时候都更容易。”\n如果您更喜欢命令行，那么 KVM 中有各种命令行选项。Virtualbox 也提供了一个命令行界面，但它不如 KVM virsh 全面。您不能直接从 bash 启动 Virtualbox VM。\n  可扩展性\nKVM 继承了 Linux 的性能，如果来宾机器和请求的数量增加，可以扩展以匹配需求负载。KVM 允许对要求最苛刻的应用程序工作负载进行虚拟化，并且是许多企业虚拟化设置的基础，例如数据中心和私有云。\nVirtualBox 可以为每个 VM 提供多达 32 个虚拟 CPU，而不管主机上物理存在多少 CPU 内核。还可以为具有多达 1024 个 CPU 的主机提供支持。\n  安全\nKVM 提供增强的安全性，因为它结合使用 SELinux 和安全虚拟化 (sVirt)。VirtualBox 可以执行虚拟机的安全实时迁移和磁盘映像加密。它还包括远程桌面协议 (RDP) 身份验证和用于创建进一步身份验证要求以帮助提高安全性的 SDK。您可以在此页面上看到 Virtualbox 的安全功能列表。\n  成本和定价\nKVM 是一个开源的免费平台，由 Red Hat 等供应商提供有偿支持。虽然 Virtualbox 在限制范围内是免费的。一旦您超过一定的使用水平，您必须获得产品许可。\n  支持\n对于 KVM，您需要依赖开源社区和您自己的 IT 组织或受支持的供应商（如红帽）的支持。Oracle 正在积极开发 Virtualbox，您可以从他们那里获得任何支持。\n  libvirt Libvirt 是一组软件的汇集，提供了管理虚拟机和其它虚拟化功能（如：存储和网络接口等）的便利途径。这些软件包括：一个长期稳定的 C 语言 API、一个守护进程（libvirtd）和一个命令行工具（virsh）。Libvirt 的主要目标是提供一个单一途径以管理多种不同虚拟化方案以及虚拟化主机，包括：KVM/QEMU，Xen，LXC，OpenVZ 或 VirtualBox hypervisors。\nLibvirt 的一些主要功能如下：\n VM management（虚拟机管理）：各种虚拟机生命周期的操作，如：启动、停止、暂停、保存、恢复和迁移等；多种不同类型设备的热插拔操作，包括磁盘、网络接口、内存、CPU等。 Remote machine support（支持远程连接）：Libvirt 的所有功能都可以在运行着 libvirt 守护进程的机器上执行，包括远程机器。通过最简便且无需额外配置的 SSH 协议，远程连接可支持多种网络连接方式。 Storage management（存储管理）：任何运行 libvirt 守护进程的主机都可以用于管理多种类型的存储：创建多种类型的文件镜像（qcow2，vmdk，raw，\u0026hellip;），挂载 NFS 共享，枚举现有 LVM 卷组，创建新的 LVM 卷组和逻辑卷，对裸磁盘设备分区，挂载 iSCSI 共享，以及更多\u0026hellip;\u0026hellip; Network interface management（网络接口管理）：任何运行 libvirt 守护进程的主机都可以用于管理物理的和逻辑的网络接口，枚举现有接口，配置（和创建）接口、桥接、VLAN、端口绑定。 Virtual NAT and Route based networking（虚拟 NAT 和基于路由的网络）：任何运行 libvirt 守护进程的主机都可以管理和创建虚拟网络。Libvirt 虚拟网络使用防火墙规则实现一个路由器，为虚拟机提供到主机网络的透明访问。  安装 基于守护进程/客户端的架构的 libvirt 只需要安装在需要要实现虚拟化的机器上。注意，服务器和客户端可以是相同的物理机器。\n服务端\n安装 libvirt 以及至少一个虚拟运行环境（hypervisor）：libvirt 的 KVM/QEMU 驱动 是 libvirt 的首选驱动，如果 KVM 功能已启用，则支持全虚拟化和硬件加速的客户机。\n$ sudo apt update $ sudo apt install qemu-kvm libvirt-daemon-system 安装 libvirt-daemon-system 后，需要将用于管理虚拟机的用户添加到libvirt组中。这对于 sudo 组的成员是自动完成的，但对于应该访问系统范围的 libvirt 资源的其他任何人，都需要另外完成。这样做将授予用户访问高级网络选项的权限。\n在终端中输入：\n$ sudo adduser $USER libvirt 如果选择的用户是当前用户，您需要注销并重新登录才能使新的组成员身份生效。\n客户端\n客户端是用于管理和访问虚拟机的用户界面。\n virsh — virsh 是用于管理和配置域（虚拟机）的命令行程序。 Virtual Machine Manager — 使用libvirt对KVM，Xen，LXC进行管理的图形化工具。  配置 对于系统 级别的管理任务（如：全局配置和镜像卷 位置），libvirt 要求至少要设置授权和启动守护进程。\n注意： 对于用户会话 级别的管理任务，守护进程的安装和设置不是 必须的。授权总是仅限本地，前台程序将启动一个 libvirtd 守护进程的本地实例。\n设置授权 自 libvirt：连接授权：Libvirt 守护进程允许管理员分别为客户端连接的每个网络 socket 选择不同授权机制。这主要是通过 libvirt 守护进程的主配置文件 /etc/libvirt/libvirtd.conf 来实现的。每个 libvirt socket 可以有独立的授权机制配置。目前的可选项有 none、polkit 和 sasl。\n由于 libvirt 在安装时将把 polkit 作为依赖一并安装，所以 polkit 通常是 unix_sock_auth 参数的默认值。但基于文件的权限仍然可用。\n使用 polkit\n注意： 为使 polkit 认证工作正常，应该重启一次系统。\nlibvirt 守护进程在 polkit 策略配置文件（/usr/share/polkit-1/actions/org.libvirt.unix.policy）中提供了两种策略：\n org.libvirt.unix.manage 面向完全的管理访问（读写模式后台 socket），以及 org.libvirt.unix.monitor 面向仅监视察看访问（只读 socket）。  默认的面向读写模式后台 socket 的策略将请求认证为管理员。这点类似于 sudo 认证，但它并不要求客户应用最终以 root 身份运行。默认策略下也仍然允许任何应用连接到只读 socket。\n基于文件的权限授权\n为了给 libvirt 组用户定义基于文件的权限以管理虚拟机，取消下列行的注释：\n$ vim /etc/libvirt/libvirtd.conf #unix_sock_group = \u0026#34;libvirt\u0026#34; #unix_sock_ro_perms = \u0026#34;0777\u0026#34; # set to 0770 to deny non-group libvirt users #unix_sock_rw_perms = \u0026#34;0770\u0026#34; #auth_unix_ro = \u0026#34;none\u0026#34; #auth_unix_rw = \u0026#34;none\u0026#34; 有些资料提到可以通过改变某些特定 libvirt 目录的权限以简化管理。需要记住的是：包更新时，这些变更会丢失。如要修改这些系统目录的权限，需要 root 用户权限。\n守护进程 libvirtd.service 和 virtlogd.service这两个服务单元都要启动。可以把 libvirtd.service 设置为启用，这时系统将同时启用 virtlogd.service 和 virtlockd.socket 两个服务单元，因此后二者不必再设置为启用。\n测试 测试 libvirt 在系统级工作是否正常：\n$ virsh -c qemu:///system 测试 libvirt 在用户会话级工作是否正常：\n$ virsh -c qemu:///session 管理 绝大部分的 libvirt 管理可以通过三个工具实现：virt-manager（图形界面）、virsh 和 guestfish（它是 libguestfs 的一部分）。\nvirsh Visrsh 用于管理客户域（虚拟机），在脚本式虚拟化管理环境中工作良好。由于需要通过通讯管道与虚拟运行环境通讯，绝大部分 virsh 命令需要管理员权限。尽管如此，一些典型的管理操作如域的创建、运行等也可以像VirtualBox 那样以普通用户身份执行。\nVirsh 允许带命令行选项执行。如果不带则进入其内置的交互式终端：virsh。交互式终端支持 tab 键命令补全。\n从命令行执行：\n$ virsh [可选项] \u0026lt;命令\u0026gt; [参数]... 在交互式终端里运行：\nvirsh # \u0026lt;命令\u0026gt; [参数]... 帮助也是可用的：\n$ virsh help [option*] or [group-keyword*] 存储池 存储池是指保存卷的位置。Libvirt 中卷的定义相当于其他系统中虚拟磁盘或虚拟机镜像的概念。存储池应该是一个目录、一个网络文件系统或一个分区（此处包括 LVM）。存储池可以在活动与不活动之间切换，可以为其分配存储空间。\n以下示例为添加存储池、目录和 LVM 卷的方法：\n$ virsh pool-define-as name type [source-host] [source-path] [source-dev] [source-name] [\u0026lt;target\u0026gt;] [--source-format format] $ virsh pool-define-as poolname dir - - - - /home/username/.local/libvirt/images $ virsh pool-define-as poolname fs - - /dev/vg0/images - mntpoint 上述示例仅仅定义了存储池的信息，下面创建它：\n$ virsh pool-build poolname $ virsh pool-start poolname $ virsh pool-autostart poolname 删除它的命令：\n$ virsh pool-undefine poolname 提示： 对于 LVM 存储池而言：\n 最佳实践是仅把一个卷组分配给一个存储池。 请为存储池选择一个与 LVM 卷组不同的名字。否则当存储池被删除时，该卷组也将被删除。  用 virt-manager 新建存储池\n首先，连接到虚拟运行环境（例如QEMU/KVM的系统/用户会话）。然后，右键点击一个连接（例如QEMU/KVM）选择详情，切换到存储选项卡，点击左下角的**+**，按照向导操作。\n存储卷 存储池被创建之后，就可以在存储池中创建存储卷。如果你想新建一个域（虚拟机），那么这一步可以跳过，因为这一步可以在创建域的过程中完成。\n用 virsh 新建卷\n新建卷，列出卷，变更卷大小，删除卷：\n$ virsh vol-create-as poolname volumename 10GiB --format aw|bochs|raw|qcow|qcow2|vmdk $ virsh vol-upload --pool poolname volumename volumepath $ virsh vol-list poolname $ virsh vol-resize --pool poolname volumename 12GiB $ virsh vol-delete --pool poolname volumename $ virsh vol-dumpxml --pool poolname volumename # for details. 域 虚拟机被称作**“域”**。如果你想在命令行下操作，使用virsh列出，创建，暂停，关闭……域。virt-viewer可以用来查看使用virsh启动的域。域的创建通常以图形化的virt-manager或者命令行下的virt-install完成。 创建新域通常需要安装媒介，例如存储池中的iso文件或是直接从光驱安装。\n列出活动的和不活动的域：\n# virsh list --all 用 virt-install 新建域\n对于很详细的域（虚拟机）配置，可以用 virt-manager 新建域更简单地完成。但是，基础配置同样可以用virt-install完成并且同样运行顺利。至少要配置--name, --memory, 存储(--disk, --filesystem,或--nodisks),和安装方法（通常来说是.iso文件或CD）。查看virt-install(1)得到未列出的选项和更多的详情。\nWindows:\n$ virt-install \\  --name=windows7 \\  --memory 2048 \\  --cdrom /dev/sr0 \\  --os-variant=win7 \\  --disk /mnt/storage/domains/windows7.qcow2,size=20GiB \\  --network network=vm-net \\  --graphics spice 导入现有的卷：\n$ virt-install \\  --name demo \\  --memory 512 \\  --disk /home/user/VMs/mydisk.img \\  --import 用 virt-manager 新建域\n首先，连接到虚拟运行环境（例如 QEMU/KVM system 或用户 session，在连接上右击并选择 新建，然后跟随向导完成。\n 在第四步中取消选中立即分配全部虚拟磁盘空间会加快创建过程并节省实际虚拟磁盘空间占用；然而，这将导致将来花费额外的磁盘整理时间。 在第五步中打开高级选项并确认虚拟化类型设为 kvm（这通常是首选模式）。如果要求附加的硬件配置，选中安装前定制选项。  管理域\n启动域：\n$ virsh start domain $ virt-viewer --connect qemu:///session domain 正常关闭域；强制关闭域:\n$ virsh shutdown domain $ virsh destroy domain 在libvirtd启动时自动启动域:\n$ virsh autostart domain $ virsh autostart domain --disable 在宿主机关闭时自动关闭域:\n使用libvirt-guests.serviceSystemd服务，运行中的域可以在宿主机关闭时自动挂起/关闭。同时这个服务还可以让挂起/休眠的域在宿主机启动的时候自动恢复。查看/etc/conf.d/libvirt-guests并设置相关选项。\n编辑一个域的XML配置：\n$ virsh edit domain 注意： 直接被QEMU启动的虚拟机不被libvirt管理。\n网络 这里是有关 libvirt 网络的一个正宗的概述。\n默认情况下，当 libvirtd 服务启动后，即创建了一个名为 default 的 NAT 网桥与外部网络联通（仅 IPv4）。对于其他的网络连接需求，可创建下列四种类型的网络以连接到虚拟机：\n bridge — 这是一个虚拟设备，它通过一个物理接口直接共享数据。使用场景为：宿主机有 静态 网络、不需与其它域连接、要占用全部进出流量，并且域运行于 系统 层级。有关如何在现有默认网桥时增加另一个网桥的方法，请参阅 网桥。网桥创建后，需要将它指定到相应客户机的 .xml 配置文件中。 network — 这是一个虚拟网络，它可以与其它虚拟机共用。使用场景为：宿主机有 动态 网络（例如：NetworkManager）或使用无线网络。 macvtap — 直接连接到宿主机的一个物理网络接口。 user — 本地网络，仅用于用户 会话。  绝大多数用户都可以通过 virsh 的各种可选项创建具有各种功能的网络，一般来说比通过 GUI 程序（像 virt-manager 之类）更容易做到。也可以按用 virt-install 新建域 所述实现。\n注意： libvirt 通过 dnsmasq 处理 DHCP 和 DNS 请求，以启动每个虚拟网络的不同实例。也会为特定的路由添加 iptables 规则并启用 ip_forward 内核参数。这也意味着宿主机上已运行的dnsmasq并不是libvirt所必须的（并可能干扰到libvirt的dnsmasq实例）。\nUEFI 支持 Libvirt 可以通过 qemu 和 OVMF 来支持 UEFI 虚拟机。 安装 ovmf 。 添加下面的内容到 /etc/libvirt/qemu.conf 。\n$ vim /etc/libvirt/qemu.conf nvram = [ \u0026#34;/usr/share/ovmf/x64/OVMF_CODE.fd:/usr/share/ovmf/x64/OVMF_VARS.fd\u0026#34; ] 重启 libvirtd\n现在你可以创建一个 UEFI 虚拟机了。 你可以通过 virt-manager 来创建。当你进行到向导的最后一步时：\n 勾选在安装前自定义配置，之后点击完成。 在概况屏幕, 将固件改为\u0026rsquo;UEFI x86_64\u0026rsquo;。 点击开始安装 在启动屏幕，你需要使用linuxefi命令来启动安装程序，并且你需要在系统中运行efibootmgr验证确实运行在UEFI模式下。  VirtualBox 执行 .vbs 文件\n$ cscript test.vbs 删除备份\n删除虚拟机备份，当前状态前一个备份删除得快，两个备份之间的备份删除得慢。\n共享文件夹\n固定分配的共享文件夹对于定义共享文件夹的虚拟机是永久存在的；\n临时分配的共享文件夹在虚拟机运行时添加/删除，虚拟机关闭后消失。\n把img系统镜像转为VDI或VMDK格式文件\n$ VBoxManage convertdd *.img *.vdi 在 virtualbox 新建虚拟机时指定 vdi 硬盘文件，就可以安装系统\n增加现有虚拟机的磁盘大小 下面是你迟早会遇到的情况。\n你在 VirtualBox 中安装了一个或多个操作系统。在创建这些虚拟操作系统的同时，你还在 VirtualBox 中为它们创建了虚拟硬盘。\n你指定了虚拟磁盘的最大大小，比如说 15 或 20GB，但现在使用了一段时间后，你发现你的虚拟机已经没有空间了。\n虽然在 Ubuntu 和其他操作系统上有释放磁盘空间的方法，但更稳健的处理方式是增加 VirtualBox 中创建的虚拟机的磁盘大小。\n是的，你可以在 VirtualBox 中扩大虚拟硬盘，即使在创建之后也可以。虽然这是一个安全且经过测试的过程，但我们强烈建议你在执行这样的操作之前，先创建一个虚拟机的备份。\n我将向你展示如何在 VirtualBox 中以图形和命令行（对于 Linux 极客）方式调整磁盘大小。这两种方法都很简单直接。\n方法 1：在 VirtualBox 中使用虚拟媒体管理器\nVirtualBox 6 增加了一个调整虚拟磁盘大小的图形化选项。你可以在 VirtualBox 主页的文件选项卡中找到它。\n进入 “File -\u0026gt; Virtual Media Manager”：\n在列表中选择一个虚拟机，然后使用 “Size” 滑块或输入你需要的大小值。完成后点击 “Apply”。\n请记住，虽然你增加了虚拟磁盘的大小，但如果你的空间是动态分配的，那么实际的分区大小仍然不变。\n方法 2：使用 Linux 命令行增加 VirtualBox 磁盘空间\n如果你使用 Linux 操作系统作为宿主机，在宿主机中打开终端并输入以下命令来调整 VDI 的大小：\nVBoxManage modifymedium \u0026quot;/path_to_vdi_file\u0026quot; --resize \u0026lt;megabytes\u0026gt; 在你按下回车执行命令后，调整大小的过程应该马上结束。\n 注意事项\nVirtualBox 早期版本命令中的 *modifyvdi 和 modifyhd 命令也支持，并在内部映射到 modifymedium 命令。\n 如果你不确定虚拟机的保存位置，可以在 VirtualBox 主页面点击 “Files -\u0026gt; Preferences” 或使用键盘快捷键 Ctrl+G 找到默认位置。\nSeamless Mode 虚拟机通常在一个窗口中运行来宾操作系统及其程序。但是，VirtualBox和VMware都有一些功能，允许您在主机桌面上运行虚拟化程序，从而将它们从监狱中释放出来。\u0026hellip;\n这意味着您可以在不使用虚拟机窗口和来宾操作系统桌面的情况下使用程序。如果使用多个监视器，甚至可以将虚拟机中的不同窗口放置在不同的监视器上。\n工作原理\n所有这些特性都同样工作。启动虚拟机，启动您想要使用的程序，然后启用“无缝模式”或“统一模式”。来宾操作系统的桌面和虚拟机窗口将消失，将来宾操作系统的窗口留在桌面上。它们看起来正在运行，好像它们在您的主机操作系统上运行，但虚拟机仍在后台运行。程序仍然是沙盒，因此它们无法访问主机操作系统的文件——它们似乎正在主机操作系统上运行。\n无论您使用的是Windows、Linux还是Mac，这些技巧都有效。您可以在Linux桌面上无缝运行Windows程序，也可以在Windows桌面上运行Linux软件。\n使用virtualbox的无缝模式\n请注意，VirtualBox只允许您在Windows、Linux和Solaris客户机上使用此功能。如果你设法让MacOSX在VirtualBox虚拟机上运行，或者你正在使用像俳句这样的小众操作系统，你将无法使用这个功能。\n在使用此功能之前，必须在要使用的来宾虚拟机内安装VirtualBox来宾添加软件包。如果您还没有这样做，请启动虚拟机，单击“设备”菜单，然后选择“安装来宾添加”。系统将提示您安装软件。\n要使用此功能，请同时按“主机键”（通常是右Ctrl键，但它显示在虚拟机窗口的右下角）和“L”。也可以单击“视图”菜单，然后选择“切换到无缝模式”。\nVirtualBox将隐藏来宾操作系统的桌面背景，使其看起来好像来宾操作系统的程序正在主机操作系统的桌面上运行。但是，正在运行的应用程序不会出现在操作系统的标准任务栏上。\n要退出无缝模式，只需按主机键，然后再次按L。您还可以在任务栏上方找到VirtualBox菜单，您可以将鼠标悬停在上面查看。单击查看并再次选择切换到无缝模式以禁用无缝模式。\n使用vmware的unity模式\nVMware有一个类似的功能，名为Unity mode。它可以在免费的VMware Player、VMware Workstation和VMware的其他付费应用程序上使用。与VirtualBox一样，VMware的Unity模式适用于Windows和Linux客户机。\nVBox+WinXP SP3 Windows XP; Guest Additions installation stuck; Virtualbox 6.1.18\nDisconnect network. It helps me.\npodman Podman: A tool for managing OCI containers and pods.\nAndroid-x86 android x86 是一个自由而开源的项目，将谷歌制作的安卓系统从 ARM 架构移植到了 x86 架构，可以让用户在他们的桌面电脑上运行安卓系统来享受所有的安卓功能和应用程序及游戏。\n首次启动运行该安卓系统，运行：\n$ qemu-img create -f qcow2 android.img 15G $ qemu-system-x86_64 -m 2048 -boot d -enable-kvm -smp 3 -net nic -net user -hda android.img -cdrom /home/mhsabbagh/android-x86_64-8.1-r1.iso 在，安卓系统已经完全安装在你的 android.img 文件中，你应该使用下面的 QEMU 命令来启动它，而不是前面的命令：\n$ qemu-system-x86_64 -m 2048 -boot d -enable-kvm -smp 3 -net nic -net user -hda android.img 轻松地运行\n$ gedit ~/.local/share/applications/android.desktop [Desktop Entry] Name=Android 8.1 Comment=Run Android 8.1 Oreo on Linux using QEMU Icon=phone Exec=bash -c \u0026#39;pkexec env DISPLAY=$DISPLAY XAUTHORITY=$XAUTHORITY qemu-system-x86_64 -m 2048 -boot d -enable-kvm -smp 3 -net nic -net user -hda /home/mhsabbagh/android.img\u0026#39; Terminal=false Type=Application StartupNotify=true Categories=GTK; Anbox Anbox 简介 Anbox 是 “Android in a box” 的缩写。Anbox 是一个基于容器的方法，可以在普通的 GNU/Linux 系统上启动完整的 Android 系统。\nAnbox 可以让你在 Linux 系统上运行 Android，而没有虚拟化的迟钝，因为核心的 Android 操作系统已经使用 Linux 命名空间（LXE）放置到容器中了。\nAndroid 容器不能直接访问到任何硬件，所有硬件的访问都是通过在主机上的守护进程进行的。\n每个应用程序将在一个单独窗口打开，就像其它本地系统应用程序一样，并且它可以显示在启动器中。\n安装使用 Anbox 也可作为 snap 软件包安装，请确保你已经在你的系统上启用了 snap 支持。\n为使 Anbox 工作，确保需要的内核模块已经安装在你的系统中。对于基于 Ubuntu 的用户，使用下面的 PPA 来安装它。\n$ sudo add-apt-repository ppa:morphis/anbox-support $ sudo apt update $ sudo apt install linux-headers-generic anbox-modules-dkms 在你安装 anbox-modules-dkms 软件包后，你必须手动重新加载内核模块，或需要系统重新启动。\n$ sudo modprobe ashmem_linux $ sudo modprobe binder_linux 安装 anbox。\n$ sudo apt install anbox 如果你已经在你的系统上安装 snap，其它的步骤可以忽略。\n$ sudo snap install --devmode --beta anbox 默认情况下，Anbox 并没有带有 Google Play Store。因此，我们需要手动下载每个应用程序（APK），并使用 Android 调试桥（ADB）安装它。\n$ sudo apt install android-tools-adb 既然我们不能使用 Play Store ，你就得从信得过的网站来下载 APK 软件包，像 APKMirror ，然后手动安装它。\n首先，你需要启动 ADB 服务。为做到这样，运行下面的命令。\n$ adb devices 安装语法格式：\n$ adb install Name-Of-Your-Application.apk Wine Wine （“Wine Is Not an Emulator” 的首字母缩写）是一个能够在多种 POSIX-compliant 操作系统（诸如Linux，Mac，FreeBSD和Solaris等）上运行 Windows 应用的兼容层。Wine 不是像虚拟机或者模拟器一样模仿内部的 Windows 逻辑，而是将 Windows API 调用翻译成为动态的 POSIX 调用，免除了性能和其他一些行为的内存占用，让你能够干净地集合 Windows 应用到你的桌面。Wine是不断发展的免费软件。其他平台也可能受益。\n注：以下如果使用zsh，~ 应替换为 $HOME才能正常使用\n安装 使用 Ubuntu 仓库版本\n$ sudo apt install wine 使用 wine 仓库安装最新版本\n如果您之前安装过来自其他仓库的 Wine 安装包，请在尝试安装 WineHQ 安装包之前删除它及依赖它的所有安装包（如：wine-mono、wine-gecko、winetricks），否则可能导致依赖冲突。\n如果您使用的是 64 位系统，请开启 32 bit 架构支持（如果您之前没有开启的话）：\n# Verifying you have 64-bit kernel architecture. $ dpkg --print-architecture # Verifying you have multi-arch support enabled.  $ dpkg --print-foreign-architectures # Enabling multi-arch support. $ sudo dpkg --add-architecture i386 $ sudo apt update 下载添加仓库密钥：\n$ wget -nc https://dl.winehq.org/wine-builds/winehq.key $ sudo apt-key add winehq.key 并添加 Ubuntu 20.04 仓库：\n$ sudo add-apt-repository \u0026#39;deb https://dl.winehq.org/wine-builds/ubuntu/ focal main\u0026#39; 安装：\n$ sudo apt update $ sudo apt install --install-recommends winehq-stable 配置 配置Wine的方式通常有：\n winecfg是Wine的图形界面配置程序。控制台下调用$ winecfg（或指定系统目录：$ WINEPREFIX=~/.系统目录 winecfg）即可启动 control.exe是Windows控制面板的Wine实现，通过$ wine control命令启动 regedit是Wine的注册表编辑器，比较前两者，该工具能配置更多东西。部分常用键值参见：WineHQ\u0026rsquo;s article on Useful Registry Keys  初始设置 通过全局菜单，应用程序 - \u0026gt;附件 - \u0026gt;终端 ，输入命令： winecfg 这将在你的家目录中创建一个隐藏文件夹（.wine），其中包含类似于在Windows中的虚拟C：驱动器以及注册表文件。一旦该目录中创建完，wine配置窗口将出现。该窗口将允许您定制wine的各种设置，其中包括Windows版本，DLL替换，显示设置，驱动器映射，以及应用程序的特定设置。单击OK按钮关闭该窗口。\nWINEPREFIX Wine默认将配置文件和安装的Windows程序保存在~/.wine。这样的目录称为一个\u0026quot;Wine prefix\u0026quot;或\u0026quot;Wine bottle\u0026quot;（下文称“系统目录”）。每次运行Windows程序（包括内置程序，如winecfg）时，系统目录会自动创建（如果缺失）或更新。系统目录中存放有文件夹 ~/.wine/drive_c 相当于Windows下C:\\C盘（更确切的说应是系统盘）。\n通过设置WINEPREFIX环境变量，可以更改Wine系统目录的位置。如果希望让不同的Windows程序使用不同的系统环境或配置，这一变量会非常有用。建议把你安装的不同的Windows程序分给不同的WINEPREFIX，便于打包和隔离。当你要启动这个Windows程序前也记得要设置WINEPREFIX。\n例如，如果您使用 $ env WINEPREFIX=~/.win-a wine-A程序.exe参数来运行一个程序。另一个使用 $ env WINEPREFIX=~/.win-b wine-B程序.exe参数，这两个程序将使用独立的C盘和注册表配置。\n以下命令会建立一个默认的系统目录，且不启动任何Windows程序：\n$ env WINEPREFIX=~/.customprefix wineboot -u WINEARCH 这个WINEARCH 决定了你模拟的Windows是32位或是64位的x86。对应的值为win32及win64，如果你的Unix系统是64位的它就默认是win64。\n发行版所提供的wine一般都有32位及64位两个包，直接对应所模拟的Windows位数，包里面的Unix二进制及运行库也都是对应位数。\n对于64位用户，默认创建的系统目录是64位环境的。若想使用纯32位环境，修改WINEARCH 变量win32为即可： $ WINEARCH=win32 winecfg这样就会生成32位Wine环境。若不设置WINEARCH得到的就是64位环境。\n通过WINEPREFIX变量，在不同的系统目录分别创建32位和64位环境：\n$ WINEARCH=win32 WINEPREFIX=~/win32 winecfg $ WINEPREFIX=~/win64 winecfg 注意： 系统目录创建过程中，64位版本的wine将视全部目录如同64位系统目录，也将不会在已存在的目录中创建任何32位的。创建32位系统目录，您必须让Wine创建指定的WINEPREFIX目录。\nwinetricks也接受WINEPREFIX变量，以安装Steam为例：\n$ WINEARCH=win32 WINEPREFIX=~/.local/share/wineprefixes/steam winetricks steam 编辑 ~/.bashrc，使得 WINEPREFIX 和 WINEARCH 永久生效\nexport WINEPREFIX=$HOME/.config/wine/ export WINEARCH=win32 图形驱动 你需要安装32位的显卡驱动。缺少或未能正确配置驱动的一个标志是 Wine 在终端窗口里报告如下内容：\nDirect rendering is disabled, most likely your OpenGL drivers have not been installed correctly 注意： 在安装对应的库以后，你可能需要重启 X\n声音 Wine程序有可能遇到某些声音问题。首先，确保winecfg中只启用了一种声卡驱动。目前，Wine对Alsa的支持最好。\nMIDI 支持\nMIDI 是九十年代非常流行的游戏声音系统。如果你尝试运行老一点的游戏，音乐无法开箱即用的情况并不罕见。 Wine 拥有非常优秀的 MIDI 支持。但是首先你需要确保 Wine 会使用正确的 MIDI 输出。详细设置参考 Wine Wiki\n字体 中文乱码\n将中文字体copy到对应wine的目录（本地安装的wine是~/.wine，playonlinux是.PlayOnLinux/wineprefix/对应目录）下的drive_c/windows/Fonts/。\n在wine目录下任意位置添加modify_font.reg文件：\nREGEDIT4 [HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows NT\\CurrentVersion\\FontLink\\SystemLink] \u0026#34;Lucida Sans Unicode\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;Microsoft Sans Serif\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;MS Sans Serif\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;Tahoma\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;Tahoma Bold\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;msyh\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;Arial\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;Arial Black\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; 将SourceHanSans.ttc改成自己想改的中文字体。\n在wine命令提示符运行：\n$ regedit modify_font.reg 语言区域\n如果安装的系统LANG不为zh-CN，那么wine运行程序的默认语种也不会是中文，这可能导致一部分乱码。解决这个问题，用\n$ env LANG=zh_CN.UTF-8 wine example.exe 运行程序\n启动器和菜单 Wine不会为内置程序（如winecfg、winebrowser）创建桌面启动器和菜单项。但手动安装的Windows程序通常会自动创建启动器和菜单项。在Windows下，安装程序（如setup.exe）通常会在桌面和开始菜单建立快捷方式，而Wine下会创建遵循freedesktop.org规范的.desktop文件（即启动器，相当于快捷方式）。\n提示： 如果启动器没有自动创建，或者这些文件丢失了，可以尝试使用winemenubuilder修复。\nGnome3 中清理 Wine 菜单启动项\n系统全局的菜单启动器安装在 /usr/share/applications/，清除相应程序的“.desktop”文件即可从整个系统删除该启动器。\n如果这样还是无法解决问题，那么很可能 Wine 的启动器存放在用户级别的 ~/.local/share/applications/wine/Programs/ 目录中。删除相应的“.desktop”文件即可清理对应启动项。删除整个 Programs 文件夹将清理所有 Wine 程序的启动项。\n安装/运行/卸载 Windows 程序 警告： 千万不要以root身份运行Wine！详情参见本文。\n使用wine安装应用程序，可以按照以下步骤：\n 从某个地址下载Windows应用程序.exe（可执行文件）. 把它放在一个方便的目录（例如，桌面或个人文件夹） 打开终端，并且切换到.exe文件所在的目录。 输入命令 wine application-name.exe 。  这将使用Wine启动.EXE。如果它是一个安装程序，它应该像在windows一样的运行。如果应用程序要求目录来安装应用程序，选择把它放在 C:\\Program Files 。\n运行Windows程序格式为 WINEPREFIX=\u0026quot;wine配置文件存放地\u0026quot; wine [路径]程序.exe 参数 ，如：\n$ wine notepad.exe c:/abc.txt $ wine notepad.exe ~/.wine/drive_c/abc.txt 路径可以是Unix路径，也可以是（在有WINEPREFIX情况下的）Windows路径，wine会自动判断。\n对wine来说，你Unix系统里的其他文件（即模拟的C盘之外的文件）的Windows路径都以Z盘开头：\n$ wine notepad.exe z:/home/username/.wine/drive_c/abc.txt 内置的msiexec程序可以运行MSI安装包：\n$ [wine] msiexec /i path_to_msi 还可以通过在终端运行 winefile 使用 Wine 文件浏览器。\n在某些情况下，应用程序需要被从一个特定位置上运行。在这种情况下创建命令启动\n$ sh -c \u0026#34;cd /home/USER/.wine/drive_c/Program Files/APPDIR; wine game.exe\u0026#34; wine uninstaller 这将打开一个类似于Windows的程序“添加/删除程序”控制面板，让您卸载wine安装的应用程序。通过 wine 直接运行卸载程序也应该正常工作。或者，您也可以简单地删除应用程序的文件夹。\n技巧 提示： 此外您可能会感兴趣以下文章的开始所提供的链接\n Wine程序数据库 (Wine Application Database, AppDB) —— 特定Windows程序的Wine兼容情况（运行时的已知问题、用户评分、指南等等），Rating一列由运行结果好到坏为Platinum、Gold、Silver、Bronze、Garbage，无近期结果或近期仍然Silver以下的就放弃吧。 WineHQ论坛 —— 要是看完上述网页还有问题，可以到这里咨询  OpenGL 模式 很多游戏（比如魔兽争霸啦）都支持OpenGL模式，在Wine下可能比默认DirectX模式性能更好。一般添加-opengl启动程序即可，但不同程序可能有所不同：\n$ wine /path/to/3d_game.exe -opengl 请参考AppDB，了解特定程序的相关信息。\nWine 控制台 有些时候，可能需要运行.exe给游戏打补丁，比如给古董游戏添加宽屏支持。这时直接通过Wine运行可能没有用。那么，打开终端，运行一下命令：\n$ wineconsole cmd 将进入一个和Windows下cmd一样的命令行环境。在该环境下试试也许就可以了。\nwinetricks 使用Winetricks快速脚本，能够方便地安装许多Windows组件，包括DirectX、msxml（被Office 2007、IE浏览器依赖）visual运行库还有其他更多的。\n使用 Ubuntu 仓库版本\n$ sudo apt install winetricks 使用 Github 安装最新版本\n$ cd \u0026#34;${HOME}/Downloads\u0026#34; $ wget https://raw.githubusercontent.com/Winetricks/winetricks/master/src/winetricks $ chmod u+x winetricks $ mv winetricks ~/.local/bin/ 可以用winetricks list-all来看看它支持什么。\nUsing winetricks\n获得 winetricks 后，您只需在控制台输入sh winetricks即可运行它。如果你先chmod +x winetricks ，你也可以使用./winetricks。如果不带参数运行，winetricks 会显示一个带有可用包列表的 GUI。如果您知道要安装的软件包的名称，可以将它们附加到 winetricks 命令，它将立即开始安装过程。例如，\n$ sh winetricks corefonts vcrun6 将安装 corefonts 和 vcrun6 软件包。\n所有 Wine 命令一样，winetricks 知道 WINEPREFIX 环境变量。\n$ env WINEPREFIX=~/.winetest sh winetricks mfc40 拥有多个 Wine 版本的用户可以指定 winetricks 应该使用哪个版本\n$ env WINE=~/wine-git/wine sh winetricks mfc40 使用 ~/wine-git 目录中的 Wine 安装 mfc40 包。\nMono \u0026amp; Gecko Mono 是 .NET Framework 的开源和跨平台实现。Wine 可以使用 Windows 构建的 Mono 来运行 .NET 应用程序。\nWine 实现了自己的 Internet Explorer 版本。该实现基于Mozilla 的 Gecko Layout Engine的自定义版本。\n在 USTC MIRROR 分别下载对应的版本，放入~/.cache/wine就可以了。\n第三方工具 这些程序有其自己的主页和支持论坛。\nCrossOver CrossOver是Wine的付费、商业化版本，提供更全面的终端用户支持。它包括脚本、补丁、GUI和可能永远不会被Wine项目接受的第三方软件。这种组合使得那些不太懂技术的人运行Windows程序变得相当容易。\n首先在 CrossOver 21 下载专区 下载 .bin 安装包，然后要把 .bin 文件设置成可执行的：chmod u+x crossover.bin，接下来运行该文件：./crossover.bin。\n无限试用\ncrossover 有15天的试用期，crossover的时间验证信息写在每一个winebottle容器中，相互是完全隔离（不是写在全局配置中）。即使一个容器过期了，依然可以创建新的容器，并重新计算试用期，所以不需要重装软件本身。\n即使重装程序，已经过期的容器依旧不能用，不过可以删除该容器，或者删除容器下的.eval文件。\n$ rm ~/.cxoffice/**/.eval PlayOnLinux/PlayOnMac PlayOnLinux是一个图形界面的Windows/DOS程序管理器。它提供了一些帮助配置/运行程序的脚本，能够管理多个不同版本的Wine，甚至能对不同程序使用不同Wine版本。参考AppDB，看看哪个Wine版本对你要运行的程序兼容最好。\nPyWinery PyWinery是一个简单的、图形界面的Wine系统目录管理器，用它可以方便地管理不同系统目录，并从不同系统目录运行程序。同时可以开启winetricks在同一系统目录，打开系统目录所在文件夹, winecfg, 软件卸载程序和wineDOS。当你使用很多系统目录（一个打游戏用、一个编程用……）时，这个程序会非常有用。\n它在默认情况下使用winetricks打开.exe文件，所以你可以选择你有的任何Wine的配置。\nQ4wine Q4Wine 是一个图形界面的系统目录（wine-prefix）管理器。它的特色是可以把 QT 主题导入 Wine 配置，使两者完美整合。\n实例 Office 2013 Pro 注：在安装前先在 AppDB 中查找要安装的应用，在 Test Results 部分有相关教程，如 Microsoft Office 2013 Test Results\n注：要提高安装成功率，第一，不同 wine 版本安装结果是不同的，AppDB 有相应的信息；第二，winetricks 如果提供安装镜像的话，一定要用该镜像，winetrics 是一个很大的脚本，打开脚本搜索 office2013pro 即可找到官方镜像下载链接；第三，如果第一次安装失败，可以再尝试安装一次。\nI installed office 2013 and I used to get a black window after starting it up. I fixed the black screen by following the solution posted in the [WineHQ-Forum](https://forum.winehq.org/viewtopic.php?f=8\u0026amp;t=28446\u0026amp;p=109296\u0026amp;hilit=office 2013#p109284).\nHere\u0026rsquo;s what I did:\nInstall Components\n$ sudo apt install winbind cabextract Create Clean 32bit Prefix for Win7\nCrete a clean 32 bit prefix and start up winecfg:\n$ env WINEPREFIX=~/.wine-office2013pro WINEARCH=win32 winecfg In the winecfg applications tab select \u0026ldquo;Windows version: Windows 7\u0026rdquo; Close wine config and install winetricks\nInstall Libraries\nThen start winetricks for your prefix\n$ env WINEPREFIX=~/.wine-office2013pro WINEARCH=win32 winetricks accept \u0026ldquo;select the default wineprefix\u0026rdquo; with OK. Now, select \u0026ldquo;Install Windows DLL components\u0026rdquo; and go and install msxml6（这个时候会下载 msxml6，可以手动下载后移动到~/.cache/winetricks中）\nTo fix the problem in PowerPoint (not enough memory), I added two overrides with winecfg in Library section: \u0026ldquo;riched20\u0026rdquo; and \u0026ldquo;usp10\u0026rdquo;.\n如果是中文软件需安装中文字体。\n在这里我直接使用 winetrics 成功安装 office2013pro（wine 6）：\n$ env WINEPREFIX=~/.wine-office2013pro WINEARCH=win32 winetricks office2013pro 这样下面步骤不需要了。\nFix Black Window\nIn order to fix the black window that impedes Office 13 to be used, add the HKCU\\Software\\Wine\\Direct3D\\MaxVersionGL new DWORD value 30002 (hexa) to the registry.\nHere\u0026rsquo;s how to do this: In Winetricks select Run regedit and wait for the Registry Editor window to open. In the folder tree expand HKEY_CURRENT_USER - Software - Wine and create a new key in the Wine folder. To do so, right click, select new\u0026ndash;\u0026gt;key and name it Direct3D. Now create new\u0026ndash;\u0026gt;DWORD Value, rename the file to MaxVersionGL and set the value data to 30002 (hexadecimal). Close the Registry Editor window.\nClose the winetricks window and run installer:\nInstall Office 2013\n$ env LANG=zh_CN.UTF-8 WINEPREFIX=~/.wine-office2013pro WINEARCH=win32 wine ~/PathTo/Office2013Setup.x86.exe From here, the install runs and completes 100%.\n安装后可以在 ~/.local/share/applications/wine 下找到 微信、QQ 的 .desktop 文件，右键编辑，将 Exec=env 行改为 Exec=env LANG=zh_CN.utf8\nWeChat Linux 安装微信的可选方案总结\n 腾讯官方 Web 版微信 Franz + 微信（基于 Web 版） Electronic-Wechat（基于 Web 版） 虚拟机 + 微信原生 PC 客户端 CrossOver + 微信原生 PC 客户端 Winetricks（基于 Wine） + 微信原生 PC 客户端 Winetricks-ZH（基于 Wine） + 微信原生 PC 客户端 AppImage + AppImage 打包构建的（Wine + 微信原生 PC 客户端） Flatpak + Flatpak 打包构建的（Deepin-Wine + 微信原生 PC 客户端） Wine + PlayonLinux + 微信原生 PC 客户端  fstab /etc/fstab是用来存放文件系统的静态信息的文件。当系统启动的时候，系统会自动地从这个文件读取信息，并且会自动将此文件中指定的文件系统挂载到指定的目录。\n查看/etc/fstab\n# cat /etc/fstab \u0026lt;file system\u0026gt; \u0026lt;dir\u0026gt; \u0026lt;type\u0026gt; \u0026lt;options\u0026gt; \u0026lt;dump\u0026gt; \u0026lt;pass\u0026gt; tmpfs /tmp tmpfs nodev,nosuid 0 0 /dev/sda1 / ext4 defaults,noatime 0 1 /dev/sda2 none swap defaults,nodelalloc 0 0 /dev/sda3 /home ext4 defaults,noatime 0 2 分别解释一下各字段的用处：\n \u0026lt;file system\u0026gt; 要挂载的分区或存储设备 \u0026lt;dir\u0026gt; 挂载的目录位置 \u0026lt;type\u0026gt; 挂载分区的文件系统类型，比如：ext3、ext4、xfs、swap \u0026lt;options\u0026gt; 挂载使用的参数有哪些。举例如下：  auto - 在启动时或键入了 mount -a 命令时自动挂载。 noauto - 只在你的命令下被挂载。 exec - 允许执行此分区的二进制文件。 noexec - 不允许执行此文件系统上的二进制文件。 ro - 以只读模式挂载文件系统。 rw - 以读写模式挂载文件系统。 user - 允许任意用户挂载此文件系统，若无显示定义，隐含启用 noexec, nosuid, nodev 参数。 users - 允许所有 users 组中的用户挂载文件系统. nouser - 只能被 root 挂载。 owner - 允许设备所有者挂载。 sync - I/O 同步进行。 async - I/O 异步进行。 dev - 解析文件系统上的块特殊设备。 nodev - 不解析文件系统上的块特殊设备。 suid - 允许 suid 操作和设定 sgid 位。这一参数通常用于一些特殊任务，使一般用户运行程序时临时提升权限。 nosuid - 禁止 suid 操作和设定 sgid 位。 noatime - 不更新文件系统上 inode 访问记录，可以提升性能。 nodiratime - 不更新文件系统上的目录 inode 访问记录，可以提升性能(参见 atime 参数)。 relatime - 实时更新 inode access 记录。只有在记录中的访问时间早于当前访问才会被更新。（与 noatime 相似，但不会打断如 mutt 或其它程序探测文件在上次访问后是否被修改的进程。），可以提升性能。 flush - vfat 的选项，更频繁的刷新数据，复制对话框或进度条在全部数据都写入后才消失。 defaults - 使用文件系统的默认挂载参数，例如 ext4 的默认参数为:rw, suid, dev, exec, auto, nouser, async.   \u0026lt;dump\u0026gt; dump 工具通过它决定何时作备份。dump 会检查其内容，并用数字来决定是否对这个文件系统进行备份。 允许的数字是 0 和 1 。0 表示忽略， 1 则进行备份。大部分的用户是没有安装 dump 的 ，对他们而言 \u0026lt;dump\u0026gt; 应设为 0。 \u0026lt;pass\u0026gt; fsck 读取 \u0026lt;pass\u0026gt; 的数值来决定需要检查的文件系统的检查顺序。允许的数字是0, 1, 和2。 根目录应当获得最高的优先权 1, 其它所有需要被检查的设备设置为 2。 0 表示设备不会被 fsck 所检查。  示例：\n/dev/sda1 /mnt/LinuxOSBuckup ext4 defaults 0 2 UUID of Storage Devices Finding UUID with blkid\n$ sudo blkid Finding UUID with ls\n$ ls -l /dev/disk/by-uuid Finding UUID with lsblk\n$ sudo lsblk -f Package Management dpkg 管理软件包 dpkg 意即 Debian 包管理器（Debian PacKaGe manager）。dpkg 是一个可以安装、构建、删除及管理 Debian 软件包的命令行工具。\n其它的一些工具如 dpkg-deb 和 dpkg-query 等使用 dpkg 作为执行某些操作的前端。\n现在大多数系统管理员使用 Apt、Apt-Get 及 Aptitude 等工具，不用费心就可以轻松地管理软件。\n尽管如此，必要的时候还是需要用 dpkg 来安装某些软件。\n常见命令及文件位置 dpkg 命令的语法:\n$ dpkg [\u0026lt;option\u0026gt; ...] \u0026lt;command\u0026gt; dpkg 相关文件的位置在 /var/lib/dpkg\n/var/lib/dpkg/status 包含了被 dpkg 命令（install、remove 等）所修改的包的信息\n/var/lib/dpkg/status 包含了可用包的列表\n安装/升级软件 在基于 Debian 的系统里，用以下命令来安装 .deb 软件包。要是已经安装了软件包，就会升级它。\n$ sudo dpkg -i package.deb 从文件夹里安装软件 在基于 Debian 的系统里，用下列命令从目录中逐个安装软件。这会安装 /opt/software 目录下的所有以 .deb 为后缀的软件。\n$ sudo dpkg -iR /opt/software 显示已安装软件列表 以下命令可以列出 Debian 系的系统中所有已安装的软件，同时会显示软件版本和描述信息。\n$ dpkg -l 查看指定的已安装软件 用以下命令列出指定的一个已安装软件，同时会显示软件版本和描述信息。\n$ dpkg -l package 查看软件安装目录 以下命令可以在基于 Debian 的系统上查看软件的安装路径。\n$ dpkg -L package 查看 deb 包内容 下列命令可以查看 deb 包内容。它会显示 .deb 包中的一系列文件。\n$ dpkg -c package.deb 显示软件的详细信息 以下命令可以显示软件的详细信息，如软件名、软件类别、版本、维护者、软件架构、依赖的软件、软件描述等等。\n$ dpkg -s package 查看文件属于哪个软件 用以下命令来查看文件属于哪个软件。\n$ dpkg -S /path/file 移除/删除软件 以下命令可以用来移除/删除一个已经安装的软件，但不删除配置文件。\n$ sudo dpkg -r package 清除软件 以下命令可以用来移除/删除包括配置文件在内的所有文件。\n$ sudo dpkg -P package Debian 打包入门 deb包本身有三部分组成：\n注：原文写的不是很好，具体学习还是看官方的 Debian 新维护者手册\nCardbook 是用于管理基于 CardDav 和 vCard 标准的联系人的Thunderbird扩展。\n使用 dh_make 在当前目录下创建一个 debian 目录。\n$ dh_make\\ \t--native \\ \t--single \\ \t--packagename cardbook_1.0.0 \\ \t--email minkush@example.com 一些重要的文件，比如 control、rules、changelog、copyright 等文件被初始化其中。所创建的文件的完整列表如下：\n$ find debian debian debian/manpage.sgml.ex debian/cardbook.doc-base.EX debian/changelog debian/control debian/postrm.ex debian/postinst.ex debian/source debian/source/format debian/README.Debian debian/manpage.1.ex debian/salsa-ci.yml.ex debian/rules debian/cardbook.cron.d.ex debian/README.source debian/preinst.ex debian/prerm.ex debian/copyright debian/cardbook-docs.docs debian/README debian/manpage.xml.ex 在当前目录执行 dpkg-buildpackage -us -uc -ui 将会在上层目录创建一个空的包文件以及四个名为 .changes、.deb、 .dsc、 .tar.gz 的文件。\n .dsc 文件包含了所发生的修改和签名 .deb 文件是用于安装的主要包文件。 .tar.gz （tarball）包含了源代码。  这个过程也在 debian/cardbook/usr/share/doc/cardbook 目录下创建了 README 和 changelog 文件。它们包含了关于这个包的基本信息比如描述、作者、版本。\n检查这个包安装的内容：\n$ dpkg -c cardbook_1.0.0_amd64.deb /usr /usr/share /usr/share/doc /usr/share/doc/cardbook /usr/share/doc/cardbook/README.Debian /usr/share/doc/cardbook/changelog.gz /usr/share/doc/cardbook/copyright build-essential 在 Ubuntu 中安装构建基础包（build-essential），只需要在终端中简单输入这个命令：\n$ sudo apt update \u0026amp;\u0026amp; sudo apt install build-essential 构建基础包（build-essential）实际上是属于 Debian 的。在它里面其实并不是一个软件。它包含了创建一个 Debian 包（.deb）所需的软件包列表。这些软件包包括 libc、gcc、g++、make、dpkg-dev 等。构建基础包包含这些所需的软件包作为依赖，所以当你安装它时，你只需一个命令就能安装所有这些软件包。\n请不要认为构建基础包是一个可以在一个命令中神奇地安装从 Ruby 到 Go 的所有开发工具的超级软件包。它包含一些开发工具，但不是全部。\nPackage converter  alien：Alien is really designed to be used to convert from alien file formats to the packaging format used by the distribution you run it on. gentoo-zh：gentoo 本质是通过 bash 安装软件，因此，可以参考此仓库尝试手动安装软件。  Is linux binary universal to all kinds of distributions?\nThis is two questions:\nIs a Linux binary universal to all distributions?\nIt depends:\n If the program is using nothing outside the Linux kernel, it will be universal except for the 32- or 64-bit question. A Linux \u0026ldquo;hello world\u0026rdquo; (a minimalistic program that just prints \u0026ldquo;hello world\u0026rdquo; to a terminal window) could probably be independent of the distribution. If the program is using any non-kernel library or service (which is most of Linux, the kernel is fairly small), there are differences in which libraries are included, which versions these libraries are and where they are located. So in this (most common) case distributions are not equal.  Why do many commercial programs say that they only work on one or a few distributions?\nBecause there is a very large number of Linux distributions, and nobody wants to test their program on all of them.\nA commercial vendor will normally say that they support only the distributions they have tested their software on. It may or may not work on other distributions, from the vendor\u0026rsquo;s perspective the point is just that you can\u0026rsquo;t complain if it does not work on a distribution they don\u0026rsquo;t support.\nWhich distributions are selected for testing depends on what the vendor expects their customers to be using. Commercial/professional programs commonly pick enterprise distributions, possibly through a reasoning similar to \u0026ldquo;people who paid for their OS are more likely to pay for our software\u0026rdquo;, possibly simply by counting the distributions used by their existing customers.\nSee also Mark Shuttleworth (the guy that is the reason we have an Ubuntu in the first place) on [binary compatibility between Ubuntu and Debian](https://wiki.ubuntu.com/MarkShuttleworth#What about binary compatibility) - Debian is the closest distribution relative of Ubuntu.\nAPT Debian 使用一套名为 Advanced Packaging Tool（APT）的工具来管理包系统。在基于 Debian 的 Linux 发行版中，有各种工具可以与 APT 进行交互，以方便用户安装、删除和管理的软件包。apt-get 便是其中一款广受欢迎的命令行工具，但是最常用的命令都被分散在了 apt-get、apt-cache 和 apt-config 这三条命令当中，apt 命令的引入就是为了解决命令过于分散的问题。（简单来说就是：apt = apt-get、apt-cache 和 apt-config 中最常用命令选项的集合）\n   apt 命令 取代的命令 命令的功能     apt install apt-get install 安装软件包   apt remove apt-get remove 移除软件包   apt purge apt-get purge 移除软件包及配置文件   apt update apt-get update 刷新存储库索引   apt upgrade apt-get upgrade 升级所有可升级的软件包   apt autoremove apt-get autoremove 自动删除不需要的包   apt full-upgrade apt-get dist-upgrade 在升级软件包时自动处理依赖关系   apt search apt-cache search 搜索应用程序   apt show apt-cache show 显示装细节   apt list  列出包含条件的包（已安装，可升级等）   apt edit-sources  编辑源列表    列出所有手动安装软件 $ apt-mark showmanual 查看软件包依赖 当你在 Linux 中安装一个软件包，有时这个软件包还需要其他的软件包来使它工作正常。这些额外的软件包就叫作这个包的依赖。假如这些软件包之前没有在系统中被安装，那么这些依赖在安装这个软件包的同时会被自动安装上。\n使用 apt show 来查看依赖\n你可以使用 apt show 命令 来展示一个包的详细信息。其中依赖信息就是其中一部分，你可以在以 “Depends” 打头的那些行中看到它们。\n例如，下面展示的是使用 apt show 展示 ubuntu-restricted-extras 这个包的详细信息：\n$ apt show ubuntu-restricted-extras Package: ubuntu-restricted-extras Version: 67 ... Depends: ubuntu-restricted-addons Recommends: libavcodec-extra, ttf-mscorefonts-installer, unrar ... 如你所见，ubuntu-restricted-extras 包依赖于 ubuntu-restricted-addons 这个软件包。\n但你得小心的是依赖包还可能依赖于其他包，这样一直循环往复直到尽头。但幸好 APT 包管理器可以为你处理这些复杂的依赖关系，自动地安装所有的依赖（大多数情况下）。\n什么是推荐包？\n你注意到了上面结果输出中以 “Recommends” 开头的那些行了吗？\n推荐包不是软件包的直接依赖，但它们可以开启软件包的一些额外功能。\n正如你上面看到的那样， ubuntu-restricted-extras 包有 ttf-mscorefonts-installer 这个推荐包，用来在 Ubuntu 上安装 Microsoft 的字体。\n这些推荐包也会默认被一同安装上，假如你想显式地禁止这些推荐包的安装，你可以像下面这样使用 –-no-install-recommends 选项。\n$ sudo apt install --no-install-recommends package_name 使用 apt-cache 来直接获取依赖信息\n上面通过 apt show 的方式会获取到大量信息，假如你想在脚本中获取到依赖信息，那么 apt-cache 命令将会给你一个更好且更简洁的输出结果。\n$ apt-cache depends package_name 使用 dpkg 来查看一个 DEB 文件的依赖\napt 和 apt-cache 都作用于软件仓库中的软件包，但假如你下载了一个 DEB 文件，那么这两个命令就不起作用了。\n在这种情形下，你可以使用 dpkg 命令的 -I 或 --info 选项。\n$ dpkg -I path_to_deb_file 依赖信息就可以在以 “Depends” 开头的那些行中找到。\n使用 apt-rdepends 来查看依赖及依赖的依赖\n假如你想查看更多关于依赖的信息，那么你可以使用 apt-rdepends 工具。这个工具可以创建完整的依赖树。这样你就可以得到一个软件包的依赖以及这些依赖的依赖。\n它不是一个常规的 apt 命令，所以你需要从 universe 软件仓库中安装上它：\n$ sudo apt install apt-rdepends 这个命令的输出通常很多，取决于依赖树的大小。\neading package lists... Done Building dependency tree Reading state information... Done shutter Depends: procps Depends: xdg-utils imagemagick Depends: imagemagick-6.q16 (\u0026gt;= 8:6.9.2.10+dfsg-2~) imagemagick-6.q16 Depends: hicolor-icon-theme Depends: libc6 (\u0026gt;= 2.4) Depends: libmagickcore-6.q16-6 (\u0026gt;= 8:6.9.10.2) Depends: libmagickwand-6.q16-6 (\u0026gt;= 8:6.9.10.2) hicolor-icon-theme libc6 Depends: libcrypt1 (\u0026gt;= 1:4.4.10-10ubuntu4) Depends: libgcc-s1 libcrypt1 Depends: libc6 (\u0026gt;= 2.25) apt-rdepends 工具的功能非常多样，它还可以用来计算反向依赖。这意味着你可以查看某个特定的包被哪些软件包依赖。\n$ apt-rdepends -r package_name 输出可能会非常多，因为它将打印出反向依赖树。\n$ apt-rdepends -r ffmpeg Reading package lists... Done Building dependency tree Reading state information... Done ffmpeg Reverse Depends: ardour-video-timeline (\u0026gt;= 1:5.12.0-3ubuntu4) Reverse Depends: deepin-screen-recorder (5.0.0-1build2) Reverse Depends: devede (4.15.0-2) Reverse Depends: dvd-slideshow (0.8.6.1-1) Reverse Depends: green-recorder (\u0026gt;= 3.2.3) PPA 软件仓库是一组文件，其中包含各种软件及其版本的信息，以及校验和等其他一些详细信息。每个版本的 Ubuntu 都有自己的四个官方软件仓库：\n Main - Canonical 支持的自由开源软件。 Universe - 社区维护的自由开源软件。 Restricted - 设备的专有驱动程序。 Multiverse - 受版权或法律问题限制的软件。  你可以在 这里 看到所有版本的 Ubuntu 的软件仓库。你可以浏览并转到各个仓库。\n这些信息存储在系统的 /etc/apt/sources.list 文件中。如果查看此文件的内容，你就会看到里面有软件仓库的网址。# 开头的行将被忽略。\nUbuntu 不会在官方仓库中立即提供新版本的软件。他们需要一个步骤来检查此新版本的软件是否与系统兼容，从而可以确保系统的稳定性。这意味着它需要经过几周才能在 Ubuntu 上可用，在某些情况下，这可能需要几个月的时间。\n为获取最新版本的软件，需要使用 PPA，PPA (Personal Package Archives) 允许开发者上传要构建的 Ubuntu 源包，并通过 Launchpad 作为 apt 的软件仓库发布。\n通过如下命令添加 PPA 软件仓库并获取最新版本软件：\n$ sudo add-apt-repository \u0026lt;PPA_info\u0026gt; $ sudo apt-get update $ sudo apt-get install \u0026lt;package_in_PPA\u0026gt; 当你使用 PPA 时，它不会更改原始的 sources.list 文件。相反，它在 /etc/apt/sources.d 目录中创建了两个文件，一个 .list 文件和一个带有 .save 后缀的备份文件。这是一种安全措施，可以确保添加的 PPA 不会和原始的 sources.list 文件弄混，它还有助于移除 PPA。\n开发人员为他们的软件创建的 PPA 称为官方 PPA。但有时，个人会创建由其他开发人员所创建的项目的 PPA。为什么会有人这样做？ 因为许多开发人员只提供软件的源代码。\n如果 PPA 不适用于你的系统版本，你可以点击应用程序 PPA 页面的 View package details，在这里，你可以单击软件包以显示更多详细信息，还可以在此处找到包的源代码和 DEB 文件。建议 使用 Gdebi 安装这些 DEB 文件 而不是通过软件中心，因为 Gdebi 在处理依赖项方面要好得多。\n就安全性而言，很少见到因为使用 PPA 之后你的 Linux 系统被黑客攻击或注入恶意软件。到目前为止，我不记得发生过这样的事件。官方 PPA 可以不加考虑的使用，使用非官方 PPA 完全是你自己的决定。根据经验，如果程序需要 sudo 权限，则应避免通过第三方 PPA 进行安装。\nSnap \u0026amp; Flatpak A fundamental difference between Snap and Flatpak\nFlatpak is designed to install and update “apps”; user-facing software such as video editors, chat programs and more.\nsnaps can install anything which contains a kernel, printer drivers, audio subsystems and more.\nSnap and Flatpak are the software behind two universal Linux app stores: the Snap Store and Flathub.\nopenSUSE 群讨论\nFlatpak使用bubblewrap来隔离应用程序，bwrap是非常轻量化的沙箱程序，因此攻击面极小。但bwrap需要用户对Linux程序工作方式有准确的了解（使用哪些syscall），Flatpak相当于充当了一个bwrap的前端帮助控制bwrap权限。\n目前Flatpak的问题在于seccomp权限太过广泛，但目前Flatpak维护者已经意识到了这个问题（注释：在他们踩了一次坑之后），已经计划打算解决了。\n另一个问题是程序请求的权限过于广泛，但这更多是一个决策问题而不是技术问题，而且你可以用Flatseal手动调整权限。\nFlatpak你不能用常规程序方式来理解，每个程序都是一个完全独立的空间，只有给予了权限才有对应访问权，也可以用Portals调用文件选择器来获得单独一个文件的完全访问权，Flatpak版的Steam是把所有程序配置文件放在~/.var/app里面了，类似安卓下面的分区存储做法。\nAppImage就只是个自挂载程序，自带的文件透明挂载到它自己的根文件系统下面，所以依然依赖主机的一部分库。所以是的，跟打包者用的系统有关系。\nFlatpak不是这种机制，每个Flatpak空间是完全空白的，需要打包者自己选择加入哪些东西，所以Flatpak跨发行版的兼容性也更好。\n良好打包的AppImage可以有很好的跨发行版兼容性，但是代价就是需要手工测试每个发行版下面的效果。在跨发行版兼容性这点上我更看好Flatpak。\n最后，不要跟我提Snap，我不想碰那个东西，也对它没有研究的兴趣。\nFlatpak确实有很多可取之处，或者不能说是Flatpak可取，而是Linux桌面软件生态现状决定了，只有更激进的手段才能改变现状。\nAppImage那种策略还是过于不痛不痒了，结果就是程序仅仅是被打包成一个个单文件，但背后的库依赖地狱、权限隔离问题一个都没解决。\n但AppImage作者的想法本来也不是靠AppImage颠覆，他是希望Linux能够重新恢复LSB，确保发行版之间的兼容性本身可靠而不是依赖Flatpak这些技术，就类似于Windows上的软件不需要什么沙箱模拟器，你几乎可以保证旧版本的软件能在新版本运行。\n其实也可以说明，微软那种在桌面上采取的策略，很可能难以在Linux社区里推广开来，微软那种做法，确保绝对的向下兼容性，不是谁都有精力来做的。\n比如说如果让微软来做Wayland，那微软根本就不会把Wayland做出来，而是把X11一直迭代、削减臃肿功能直到性能和现代化图形技术栈的性能相匹敌，同时确保向下兼容性。而最新一代的X11很可能和最早的X11已经彻底不一样了，甚至会有“检测程序版本然后自动匹配对应的X11功能”这些奇怪的兼容性策略出来。或许有一天微软会把新项目叫做Wayland，但这个改名也仅仅是营销目的而不是技术目的。\n毕竟LSB已经没了，Ubuntu甚至砍掉32位兼容性，也可以说明其实Linux这边并没有太多人在乎这问题。\n毕竟“反正源代码都在那，重新编译一遍不就好了吗”\nsnap \u0026ldquo;canonical-livepatch\u0026rdquo; has \u0026ldquo;install-snap\u0026rdquo; change in progress\nSnap 包是 Ubuntu 16.04 LTS 发布时引入的新应用格式包。目前已流行在很多 Linux 发行版上。并且可以很方便地安装常用软件，如 VLC、Sublime Text、VSCode、Node、WPS等\n当你在安装完 Snap 后，你会发现在在根目录下会出现如 /dev/loop0 的挂载点，这些挂载点正是 Snap 软件包的目录。\n  原因是软件之前安装了一次，只是安装失败。\n$ snap changessnap abort 5\t## 5 为安装失败软件的 ID   现在重新安装\n  一些软件最好在官网下载或在 Snap 中下载，官方 Repository 可能并不新，比如 VLC。\n在 Ubuntu 上使用 Flatpak The official Flatpak PPA is the recommended way to install Flatpak. To install it, run the following in a terminal:\n$ sudo add-apt-repository ppa:flatpak/stable $ sudo apt update $ sudo apt install flatpak Flathub is the best place to get Flatpak apps. To enable it, run:\n$ flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo To complete setup, restart your system. Now all you have to do is install some apps!\ntasksel: Install Group Software 安装\n$ sudo apt install tasksel list tasks\n$ tasksel --list-tasks displays description\n$ tasksel --task-desc dns-server install\n$ sudo apt install dns-server pacstall An AUR-inspired package manager for Ubuntu\nAppImage Linux apps that run anywhere\n包管理器的进化 今天，每个可计算设备都会使用某种软件来完成预定的任务。在软件开发的上古时期，为了找出软件中的 bug 和其它缺陷，软件会被严格的测试。在近十年间，软件被通过互联网来频繁分发，以试图通过持续不断的安装新版本的软件来解决软件的缺陷问题。在很多情况下，每个独立的应用软件都有其自带的更新器。而其它一些软件则让用户自己去搞明白如何获取和升级软件。\nLinux 较早采用了维护一个中心化的软件仓库来发布软件更新这种做法，用户可以在这个软件仓库里查找并安装软件。在这篇文章里， 笔者将回顾在 Linux 上的如何进行软件安装的历史，以及现代操作系统如何保持更新以应对软件安全漏洞（CVE）不断的曝光。\n手动安装软件 曾几何时，软件都是通过 FTP 或邮件列表（LCTT 译注：即通过邮件列表发布源代码的补丁包）来分发的（最终这些发布方式在互联网的迅猛发展下都演化成为一个个现今常见的软件发布网站）。（一般在一个 tar 文件中）只有一个非常小的文件包含了创建二进制的说明。你需要做的是先解压这个包，然后仔细阅读当中的 README 文件， 如果你的系统上恰好有 GCC（LCTT 译注：GNU C Compiler）或者其它厂商的 C 编译器的话，你得首先运行 ./configure 脚本，并在脚本后添加相应的参数，如库函数的路径、创建可执行文件的路径等等。除此之外，这个配置过程也会检查你操作系统上的软件依赖是否满足安装要求。如果缺失了任何主要的依赖，该配置脚本会退出不再继续安装，直到你满足了该依赖。如果该配置脚本正常执行完毕，将会创建一个 Makefile 文件。\n当有了一个 Makefile 文件时， 你就可以接下去执行 make 命令（该命令由你所使用的编译器提供）。make 命令也有很多参数，被称为 make 标识flag，这些标识能为你的系统优化最终生成出来的二进制可执行文件。在计算机世界的早期，这些优化是非常重要的，因为彼时的计算机硬件正在为了跟上软件迅速的发展而疲于奔命。今日今时，编译标识变得更加通用而不是为了优化哪些具体的硬件型号，这得益于现代硬件和现代软件相比已经变得成本低廉，唾手可得。\n最后，在 make 完成之后， 你需要运行 make install （或 sudo make install）（LCTT 译注：依赖于你的用户权限） 来“真正”将这个软件安装到你的系统上。可以想象，为你系统上的每一个软件都执行上述的流程将是多么无聊费时，更不用说如果更新一个已经安装的软件将会多复杂，多么需要精力投入。（LCTT 译注：上述流程也称 CMMI 安装， 即Configure、Make、Make Install）\n软件包 package（LCTT 译注：下文简称“包”）这个概念是用来解决在软件安装、升级过程中的复杂性的。包将软件安装升级中需要的多个数据文件合并成一个单独的文件，这将便于传输和（通过压缩文件来）减小存储空间（LCTT 译注：减少存储空间这一点在现在已经不再重要），包中的二进制可执行文件已根据开发者所选择的编译标识预编译。包本身包括了所有需要的元数据，如软件的名字、软件的说明、版本号，以及要运行这个软件所需要的依赖包等等。\n不同流派的 Linux 发行版都创造了它们自己的包格式，其中最常用的包格式有：\n .deb：这种包格式由 Debian、Ubuntu、Linux Mint 以及其它的变种使用。这是最早被发明的包类型。 .rpm：这种包格式最初被称作红帽包管理器Red Hat Package Manager（LCTT 译注： 取自英文的首字母）。使用这种包的 Linux 发行版有 Red Hat、Fedora、SUSE 以及其它一些较小的发行版。 .tar.xz：这种包格式只是一个软件压缩包而已，这是 Arch Linux 所使用的格式。  尽管上述的包格式自身并不能直接管理软件的依赖问题，但是它们的出现将 Linux 软件包管理向前推进了一大步。\n软件仓库 多年以前（当智能电话还没有像现在这样流行时），非 Linux 世界的用户是很难理解软件仓库的概念的。甚至今时今日，大多数完全工作在 Windows 下的用户还是习惯于打开浏览器，搜索要安装的软件（或升级包），下载然后安装。但是，智能电话传播了软件“商店”（LCTT 译注： 对应 Linux 里的软件仓库）这样一个概念。智能电话用户获取软件的方式和包管理器的工作方式已经非常相近了。些许不同的是，尽管大多数软件商店还在费力美化它的图形界面来吸引用户，大多数 Linux 用户还是愿意使用命令行来安装软件。总而言之，软件仓库是一个中心化的可安装软件列表，上面列举了在当前系统中预先配置好的软件仓库里所有可以安装的软件。\n包管理器 包管理器用来和相应的软件仓库交互，获取软件的相应信息。下面对流行做一个简短介绍。\n基于 PRM 包格式的包管理器 更新基于 RPM 的系统，特别是那些基于 Red Hat 技术的系统，有着非常有趣而又详实的历史。实际上，现在的 YUM 版本（用于 企业级发行版）和 DNF（用于社区版）就融合了好几个开源项目来提供它们现在的功能。\nRed Hat 最初使用的包管理器，被称为 RPM（红帽包管理器Red Hat Package Manager），时至今日还在使用着。不过，它的主要作用是安装本地的 RPM 包，而不是去在软件仓库搜索软件。后来开发了一个叫 up2date 的包管理器，它被用来通知用户包的最新更新，还能让用户在远程仓库里搜索软件并便捷的安装软件的依赖。尽管这个包管理器尽职尽责，但一些社区成员还是感觉 up2date 有着明显的不足。\n现在的 YUM 来自于好几个不同社区的努力。1999-2001 年一群在 Terra Soft Solution 的伙计们开发了Yellowdog Updater（YUP），将其作为 Yellow Dog Linux 图形安装器的后端。杜克大学Duke University喜欢这个主意就决定去增强它的功能，它们开发了Yellowdog Updater, Modified（YUM），这最终被用来帮助管理杜克大学的 Red Hat 系统。Yum 壮大的很快，到 2005 年，它已经被超过一半的 Linux 市场所采用。今日，几乎所有的使用 RPM 的的 Linux 都会使用 YUM 来进行包管理（当然也有一些例外）。\nDandified Yum（DNF）是 YUM 的下一代接班人。从 Fedora 18 开始被作为包管理器引入系统，不过它并没有被企业版所采用，所以它只在 Fedora（以及变种）上占据了主导地位。DNF 的用法和 YUM 几乎一模一样，它主要是用来解决性能问题、晦涩无说明的API、缓慢/不可靠的依赖解析，以及偶尔的高内存占用。DNF 是作为 YUM 的直接替代品来开发的，因此这里笔者就不重复它的用法了，你只用简单的将 yum 替换为 dnf 就行了。\nZypper 是用来管理 RPM 包的另外一个包管理器。这个包管理器主要用于 SUSE（和 openSUSE），在MeeGo、Sailfish OS、Tizen 上也有使用。它最初开发于 2006 年，已经经过了多次迭代。除了作为系统管理工具 YaST 的后端和有些用户认为它比 YUM 要快之外也没有什么好多说的。\n基于 Debian 的包管理器 作为一个现今仍在被积极维护的最古老的 Linux 发行版之一，Debian 的包管理系统和基于 RPM 的系统的包管理系统非常类似。它使用扩展名为 “.deb” 的包，这种文件能被一个叫做 dpkg 的工具所管理。dpgk 同 rpm 非常相似，它被设计成用来管理在存在于本地（硬盘）的包。它不会去做包依赖关系解析（它会做依赖关系检查，不过仅此而已），而且在同远程软件仓库交互上也并无可靠的途径。为了提高用户体验并便于使用，Debian 项目开始了一个软件项目：Deity，最终这个代号被丢弃并改成了现在的 Advanced Pack Tool（APT）。\n在 1998 年，APT 测试版本发布（甚至早于 1999 年的 Debian 2.1 发布），许多用户认为 APT 是基于 Debian 系统标配功能之一。APT 使用了和 RPM 一样的风格来管理仓库，不过和 YUM 使用单独的 .repo 文件不同，APT 曾经使用 /etc/apt/sources.list 文件来管理软件仓库，后来的变成也可以使用 /etc/apt/sources.d 目录来管理。如同基于 RPM 的系统一样，你也有很多很多选项配置来完成同样的事情。你可以编辑和创建前述的文件，或者使用图形界面来完成上述工作（如 Ubuntu 的“Software \u0026amp; Updates”）。\n现今大多数的 Ubuntu 教程里都径直使用了 apt。 单独一个 apt 设计用来实现那些最常用的 APT 命令的。apt 命令看上去是用来整合那些被分散在 apt-get、apt-cache 以及其它一些命令的的功能的。它还加上了一些额外的改进，如色彩、进度条以及其它一些小功能。\n基于 Arch 的包管理器 Arch Linux 使用称为 packman 的包管理器。和 .deb 以及 .rpm 不同，它使用更为传统的 LZMA2 压缩包形式 .tar.xz 。这可以使 Arch Linux 包能够比其它形式的压缩包（如 gzip）有更小的尺寸。自从 2002 年首次发布以来， pacman 一直在稳定发布和改善。使用它最大的好处之一是它支持 Arch Build System，这是一个从源代码级别构建包的构建系统。该构建系统借助一个叫 PKGBUILD 的文件，这个文件包含了如版本号、发布号、依赖等等的元数据，以及一个为编译遵守 Arch Linux 需求的包所需要的带有必要的编译选项的脚本。而编译的结果就是前文所提的被 pacman 所使用的 .tar.xz 的文件。\n上述的这套系统技术上导致了 Arch User Respository（AUR）的产生，这是一个社区驱动的软件仓库，仓库里包括有 PKGBUILD 文件以及支持补丁或脚本。这给 Arch Linux 带了无穷无尽的软件资源。最为明显的好处是如果一个用户（或开发者）希望他开发的软件能被广大公众所使用，他不必通过官方途径去在主流软件仓库获得许可。而不利之处则是它必须将依赖社区的流程，类似于 Docker Hub、 Canonical 的 Snap Packages（LCTT 译注： Canonical 是 Ubuntu 的发行公司），或者其它类似的机制。\n有很多特定于 AUR 的包管理器能被用来从 AUR 里的 PGKBUILD 文件下载、编译、安装。其中 yaourt 和 pacaur 颇为流行。不过，这两个项目已经被 Arch Wiki 列为“不继续开发以及有已知的问题未解决”。因为这个原因，这里直接讨论 aurman，除了会搜索 AUR 以及包含几个有帮助的（其实很危险）的选项之外，它的工作机制和 pacman 极其类似。\nLVM 在对磁盘分区的大小进行规划时，往往不能确定这个分区要使用的空间的大小。而使用 fdisk、gdisk 等工具对磁盘分区后，每个分区的大小就固定了。如果分区设置的过大，就白白浪费了磁盘空间；如果分区设置的过小，就会导致空间不够用的情况出现。对于分区过小的问题，可以从新划分磁盘的分区，或者通过软连接的方式将此分区的目录链接到另外一个分区。这样虽然能够临时解决问题，但是给管理带来了麻烦。类似的问题可以通过 LVM 来解决。\nLVM 是什么 LVM 是 Logical Volume Manager 的缩写，中文一般翻译为 \u0026ldquo;逻辑卷管理\u0026rdquo;，它是 Linux 下对磁盘分区进行管理的一种机制。LVM 是建立在磁盘分区和文件系统之间的一个逻辑层，系统管理员可以利用 LVM 在不重新对磁盘分区的情况下动态的调整分区的大小。如果系统新增了一块硬盘，通过 LVM 就可以将新增的硬盘空间直接扩展到原来的磁盘分区上。\nLVM 的优点如下：\n 文件系统可以跨多个磁盘，因此大小不再受物理磁盘的限制。 可以在系统运行状态下动态地扩展文件系统大小。 可以以镜像的方式冗余重要数据到多个物理磁盘上。 可以很方便地导出整个卷组，并导入到另外一台机器上。  LVM 也有一些缺点：\n 在从卷组中移除一个磁盘的时候必须使用 reducevg 命令(这个命令要求root权限，并且不允许在快照卷组中使用)。 当卷组中的一个磁盘损坏时，整个卷组都会受影响。 因为增加了一个逻辑层，存储的性能会受影响。  LVM 的优点对服务器的管理非常有用，但对于桌面系统的帮助则没有那么显著，所以需要我们根据使用的场景来决定是否应用 LVM。\nLVM 中的基本概念 通过 LVM 技术，可以屏蔽掉磁盘分区的底层差异，在逻辑上给文件系统提供了一个卷的概念，然后在这些卷上建立相应的文件系统。下面是 LVM 中主要涉及的一些概念。\n **物理存储设备(Physical Media)：**指系统的存储设备文件，比如 /dev/sda、/dev/sdb 等。 **PV(物理卷 Physical Volume)：**指硬盘分区或者从逻辑上看起来和硬盘分区类似的设备(比如 RAID 设备)。 **VG(卷组 Volume Group)：**类似于非 LVM 系统中的物理硬盘，一个 LVM 卷组由一个或者多个 PV(物理卷)组成。 **LV(逻辑卷 Logical Volume)：**类似于非 LVM 系统上的磁盘分区，LV 建立在 VG 上，可以在 LV 上建立文件系统。 **PE(Physical Extent)：**PV(物理卷)中可以分配的最小存储单元称为 PE，PE 的大小是可以指定的。 **LE(Logical Extent)：**LV(逻辑卷)中可以分配的最小存储单元称为 LE，在同一个卷组中，LE 的大小和 PE 的大小是一样的，并且一一对应。  可以这么理解，LVM 是把硬盘的分区分成了更小的单位(PE)，再用这些单元拼成更大的看上去像分区的东西(PV)，进而用 PV 拼成看上去像硬盘的东西(VG)，最后在这个新的硬盘上创建分区(LV)。文件系统则建立在 LV 之上，这样就在物理硬盘和文件系统中间添加了一层抽象(LVM)。下图大致描述了这些概念之间的关系：\n对上图中的结构做个简单的介绍：\n两块物理硬盘 A 和 B 组成了 LVM 的底层结构，这两块硬盘的大小、型号可以不同。PV 可以看做是硬盘上的分区，因此可以说物理硬盘 A 划分了两个分区，物理硬盘 B 划分了三个分区。然后将前三个 PV 组成一个卷组 VG1，后两个 PV 组成一个卷组 VG2。接着在卷组 VG1 上划分了两个逻辑卷 LV1 和 LV2，在卷组 VG2 上划分了一个逻辑卷 LV3。最后，在逻辑卷 LV1、LV2 和 LV3 上创建文件系统，分别挂载在 /usr、/home 和 /var 目录。\nLVM 工具 在安装 Linux 时，如果选择使用 LVM 创建分区，就会安装 LVM 相关的工具。当前这个软件包的名称为 lvm2，其中包含了大量 LVM 工具。比如单是查看 LVM 相关实体状态的命令就有如下一些：\n$ sudo pvscan $ sudo pvs $ sudo pvdisplay $ sudo vgscan $ sudo vgs $ sudo vgdisplay $ sudo lvscan $ sudo lvs $ sudo lvdisplay 如果安装系统时没有默认安装 LVM 工具包，可以通过下面的命令安装它们：\n$ sudo apt update $ sudo apt install lvm2 接下来我们通过例子来演示如何使用 LVM 来一步步的创建出逻辑卷(LV)，然后在 LV 上创建文件系统并挂载到 Linux 系统中。\n使用 gdisk 对物理磁盘进行分区 目前常见的磁盘分区格式有两种，MBR 分区和 GPT 分区。\nMBR 分区，MBR 的意思是 \u0026ldquo;主引导记录\u0026rdquo;。MBR 最大支持 2TB 容量，在容量方面存在着极大的瓶颈。\nGPT 分区，GPT 意为 GUID 分区表，它支持的磁盘容量比 MBR 大得多。这是一个正逐渐取代 MBR 的新标准，它是由 UEFI 辅住而形成的，将来 UEFI 用于取代老旧的 BIOS，而 GPT 则取代老旧的 MBR。\n使用 fdisk 工具创建 MBR 磁盘分区，而 gdisk 是 Linux 系统中 GPT 格式的磁盘分区管理工具。\n假设我们的 Linux 系统中增加了一块新的磁盘，系统对应的设备名为 /dev/sdb，下面我们通过 gdisk 命令对这个磁盘进行分区。\n在用 gdisk 命令对磁盘分区前，我们先用 parted 命令查看 /dev/sdb 当前的分区情况：\n$ sudo parted /dev/sdb print 下面通过 gdisk 命令创建分区：\n$ sudo gdisk /dev/sdb 通过 p 命令可以查看磁盘当前的状态：输出中的前几行是磁盘的基本信息，比如总大小，一共有多少个扇区(sector)，每个扇区的大小，当前剩余的空间等等。\n然后是已经存在的分区信息：\n 第一列 Number 显示了分区的编号，比如 1 号指 /dev/sdb1。 第二列 Start 表示磁盘分区的起始位置。 第三列 End 表示磁盘分区的结束位置。 第四列 Size 显示分区的容量。 第五列 Code 和第六列 Name 显示分区类型的 ID和名称，比如 Linux filesystem 为 8300，Linux swap 为 8200，Linux LVM 为 8e00。  通过 n 命令来创建新分区：\n分区编号和开始/结束的扇区都直接通过回车选择默认值，这样所有的磁盘空间都划分到了一个分区中，然后输入 8e00 说明我们要创建的分区类型为 Linux LVM。最后输入 w 命令并确认执行分区操作。分区成功后可通过 p 命令查看我们创建的分区的信息。\n创建物理卷 PV # pvcreate DEVICE 现在我们可以基于磁盘分区 /dev/sdb1 来创建 LVM 物理卷(LV)，可以通过 pvcreate 命令来完成：\n$ sudo pvcreate /dev/sdb1 此时 /dev/sdb1 已经完成了从磁盘分区到 PV 的华丽转身！注意上面的命令，磁盘分区被直接转换成了 PV，连名称都没有变化！我们可以通过 pvs 命令查看 /dev/sdb1，目前它还没有被加入到 VG 中。\n创建卷组 VG # vgcreate \u0026lt;volume_group\u0026gt; \u0026lt;physical_volume1\u0026gt; \u0026lt;physical_volume2\u0026gt; ... 基于一个或多个 PV，可以创建 VG。我们使用刚才创建的 PV /dev/sdb1 来创建一个名称为 nickvg 的 VG：\n$ sudo vgcreate -s 32G nickvg /dev/sdb1 注意 vgcreate 命令中的 -s 选项，它指定了 PE(Physical Extent) 的大小。可以通 vgs 命令观察 VG 的信息：\n$ sudo vgs nickvg 如果目标 VG 已经存在，则使用 vgextend 把 PV 加入到 VG 中即可。\n# vgextend \u0026lt;卷组名\u0026gt; \u0026lt;物理卷\u0026gt; 创建逻辑卷 LV # lvcreate -L \u0026lt;卷大小\u0026gt; \u0026lt;卷组名\u0026gt; -n \u0026lt;卷名\u0026gt; 有了 VG 就可以创建逻辑卷 LV 了，lvcreate 命令用来创建 LV，让我们在前面创建的 nickvg 上创建名称为 nicklv00 的 LV：\n$ sudo lvcreate -L 15G -n nicklv00 nickvg 选项 -L 指定新建 LV 的容量，这里是 15G；选项 -n 则指定新建 LV 的名称，这里为 nicklv00。可以通过 lvs 命令观察 LV 的信息，注意需要同时指出 LV 所在的 VG：\n$ sudo lvs nickvg/nicklv00 如果你想让要创建的逻辑卷拥有卷组（VG）的所有未使用空间，请使用以下命令：\n# lvcreate -l +100%FREE \u0026lt;volume_group\u0026gt; -n \u0026lt;logical_volume\u0026gt; 格式化逻辑卷(创建文件系统) # mkfs.\u0026lt;类型\u0026gt; /dev/mapper/\u0026lt;卷组名\u0026gt;-\u0026lt;卷名\u0026gt; # mount /dev/mapper/\u0026lt;卷组名\u0026gt;-\u0026lt;卷名\u0026gt; \u0026lt;挂载点\u0026gt; 当我们创建 LV nickvg/nicklv00 时，其实是创建了名称为 /dev/nickvg/nicklv00 的设备文件。\n现在你的逻辑卷应该已经在/dev/mapper/和/dev/YourVolumeGroupName中了。\n现在我们来格式化这个逻辑卷(在该 LV 上创建文件系统)，目标为比较常见的 ext4 格式：\n$ sudo mkfs.ext4 /dev/nickvg/nicklv00 然后创建个目录，比如 /home/doc，并把新建的文件系统挂载到这个目录上：\n$ sudo mkdir /home/doc $ sudo mount /dev/nickvg/nicklv00 /home/doc 最后可以通过 df 命令查看这个文件系统的使用情况。\n开机自动挂载 编辑 /etc/fstab 文件：\n$ sudo vim /etc/fstab 把下面的行添加的文件末尾并保存文件：\n/dev/mapper/nickvg-nicklv00 /home/doc ext4 defaults 0 2 调整逻辑卷 同时缩小逻辑卷和其文件系统\n 注意： 只有ext2，ext3，ext4，ReiserFS和 XFS 文件系统支持以下操作。\n 将MyVolGroup组中的逻辑卷mediavol扩大10GiB，并同时扩大其文件系统：\n# lvresize -L +10G --resizefs MyVolGroup/mediavol 将MyVolGroup组中的逻辑卷mediavol大小调整为15GiB，并同时调整其文件系统：\n# lvresize -L 15G --resizefs MyVolGroup/mediavol 将卷组中的所有剩余空间分配给mediavol：\n# lvresize -l +100%FREE --resizefs MyVolGroup/mediavol 重命名卷 重命名卷组\n要重命名一个卷组，请使用vgrename(8)命令。\n可使用下面的任意一条命令将卷组vg02重命名为my_volume_group\n# vgrename /dev/vg02 /dev/my_volume_group # vgrename vg02 my_volume_group 重命名逻辑卷\n要重命名一个逻辑卷，请使用lvrename(8)命令。\n可使用下面的任意一条命令将vg02组中的逻辑卷lvold重命名为lvnew.\n# lvrename /dev/vg02/lvold /dev/vg02/lvnew # lvrename vg02 lvold lvnew 移除逻辑卷 警告： 在移除逻辑卷之前，请先备份好数据以免丢失！\n首先，找到你所要移除的逻辑卷的名称。你可以使用以下命令来查看系统的所有逻辑卷：\n# lvs 接下来，找到你所要移除的逻辑卷的挂载点\n$ lsblk 并卸载它：\n# umount /\u0026lt;mountpoint\u0026gt; 最后，使用以下命令来移除逻辑卷：\n# lvremove \u0026lt;volume_group\u0026gt;/\u0026lt;logical_volume\u0026gt; 例如：\n# lvremove VolGroup00/lvolhome 请输入y来确定你要执行移除逻辑卷操作。\n此外，请不要忘了更新/etc/fstab。\n你可以再次使用lvs命令来确认你的逻辑卷已被移除。\nLVM 快照 LVM 机制还提供了对 LV 做快照的功能，也就是说可以给文件系统做一个备份，这也是设计 LVM 快照的主要目的。LVM 的快照功能采用写时复制技术(Copy-On-Write，COW)，这比传统的备份技术的效率要高很多。创建快照时不用停止服务，就可以对数据进行备份。说明：LVM 还支持 thin 类型的快照，但是本文中的快照都是指 COW 类型的快照。\nLVM 采用的写时复制，是指当 LVM 快照创建的时候，仅创建到实际数据的 inode 的硬链接(hark-link)而已。只要实际的数据没有改变，快照就只包含指向数据的 inode 的指针，而非数据本身。快照会跟踪原始卷中块的改变，一旦你更改了快照对应的文件或目录，这个时候原始卷上将要改变的数据会在改变之前拷贝到快照预留的空间。\nLVM 快照的原理\n创建快照实际上也是创建了一个逻辑卷，只不过该卷的属性与普通逻辑卷的属性有些不一样。我们可以通过下图来理解快照数据卷(图中的实线框表示快照区域，虚线框表示文件系统)：\n左图为最初创建的快照数据卷状况，LVM 会预留一个区域 (比如左图的左侧三个 PE 区块) 作为数据存放处。 此时快照数据卷内并没有任何数据，而快照数据卷与源数据卷共享所有的 PE 数据， 因此你会看到快照数据卷的内容与源数据卷中的内容是一模一样的。 等到系统运行一阵子后，假设 A 区域的数据被更新了(上面右图所示)，则更新前系统会将该区域的数据移动到快照数据卷中， 所以在右图的快照数据卷中被占用了一块 PE 成为 A，而其他 B 到 I 的区块则还是与源数据卷共享！\n由於快照区与原本的 LV 共享很多 PE 区块，因此快照区与被快照的 LV 必须要在同一个 VG 上头，下面两点非常重要：\n VG中需要预留存放快照本身的空间，不能全部被占满。 快照所在的 VG 必须与被备份的 LV 的 VG 相同，否则创建快照会失败。  创建 LVM 快照\n其实快照就是一个特殊类型的数据卷，所以创建快照的命令和创建数据卷的命令相同，也是 lvcreate：\n# lvcreate --size 100M --snapshot --name snap01 /dev/vg0/lv 此时如果把 LV snap01 挂载到系统中，里面的内容和 LV /dev/vg0/lv 中的内容是一样的。\n创建的快照的大小可以比源数据卷小，但是当源数据卷中的数据更新过多时会导致快照容量不足而引起的错误并丢失数据。如上你可以修改少于100M的数据，直到该快照逻辑卷空间不足为止。\n创建快照后，如果源数据卷中的文件被更新了，快照系统中则保存着其创建快照时的版本。\n还原部分数据\n如果我们明确的知道需要还原某个文件，可以挂载快照数据卷，直接拷贝其中旧版本的文件即可。\n合并快照(merge snapshot)\n要将逻辑卷卷\u0026rsquo;lv\u0026rsquo; 恢复到创建快照\u0026rsquo;snap01\u0026rsquo;时的状态，即还原整个数据卷上的数据，请使用：\n# lvconvert --merge /dev/vg0/snap01 如果逻辑卷处于活动状态，则在下次重新启动时将进行合并（merging）(合并（merging）甚至可在LiveCD中进行)。\n注意： 合并后快照将被删除。\n可以拍摄多个快照，每个快照都可以任意与对应的逻辑卷合并。\n快照可以被挂载，并可用dd或者tar备份。使用dd备份的快照的大小为拍摄快照后对应逻辑卷中变更过文件的大小。 要使用备份，只需创建并挂载一个快照，并将备份写入或解压到其中。再将快照合并到对应逻辑卷即可。\n快照主要用于提供一个文件系统的拷贝，以用来备份; 比起直接备份分区，使用快照备份可以提供一个更符合原文件系统的镜像。\nZFS 历史 ZFS 是由 Matthew Ahrens 和 Jeff Bonwick 在 2001 年开发的。ZFS 是作为 Sun MicroSystem 公司的 OpenSolaris 的下一代文件系统而设计的。在 2008 年，ZFS 被移植到了 FreeBSD 。同一年，一个移植 ZFS on Linux 的项目也启动了。然而，由于 ZFS 是CDDL 许可的，它和 GPL 不兼容，因此不能将它迁移到 Linux 内核中。为了解决这个问题，绝大多数 Linux 发行版提供了一些方法来安装 ZFS　。\n在甲骨文公司收购太阳微系统公司之后不久，OpenSolaris 就闭源了，这使得 ZFS 的之后的开发也变成闭源的了。许多 ZFS 开发者对这件事情非常不满。三分之二的 ZFS 核心开发者，包括 Ahrens 和 Bonwick，因为这个决定而离开了甲骨文公司。他们加入了其它公司，并于 2013 年 9 月创立了 OpenZFS 这一项目。该项目引领着 ZFS 的开源开发。\n让我们回到上面提到的许可证问题上。既然 OpenZFS 项目已经和 Oracle 公司分离开了，有人可能好奇他们为什么不使用和 GPL 兼容的许可证，这样就可以把它加入到 Linux 内核中了。根据 OpenZFS 官网 的介绍，更改许可证需要联系所有为当前 OpenZFS 实现贡献过代码的人（包括初始的公共 ZFS 代码以及 OpenSolaris 代码），并得到他们的许可才行。这几乎是不可能的（因为一些贡献者可能已经去世了或者很难找到），因此他们决定保留原来的许可证。\n特性 正如前面所说过的，ZFS 是一个先进的文件系统。因此，它有一些有趣的特性。\n存储池 与大多数文件系统不同，ZFS 结合了文件系统和卷管理器的特性。这意味着，它与其他文件系统不同，ZFS 可以创建跨越一系列硬盘或池的文件系统。不仅如此，你还可以通过添加硬盘来增大池的存储容量。ZFS 可以进行分区和格式化。\n写时拷贝 Copy-on-write 是另一个有趣并且很酷的特性。在大多数文件系统上，当数据被重写时，它将永久丢失。而在 ZFS 中，新数据会写到不同的块。写完成之后，更新文件系统元数据信息，使之指向新的数据块（LCTT 译注：更新之后，原数据块成为磁盘上的垃圾，需要有对应的垃圾回收机制）。这确保了如果在写新数据的时候系统崩溃（或者发生其它事，比如突然断电），那么原数据将会保存下来。这也意味着，在系统发生崩溃之后，不需要运行 fsck 来检查和修复文件系统。\n快照 写时拷贝使得 ZFS 有了另一个特性：snapshots。ZFS 使用快照来跟踪文件系统中的更改。快照包含文件系统的原始版本（文件系统的一个只读版本），实时文件系统则包含了自从快照创建之后的任何更改。没有使用额外的空间。因为新数据将会写到实时文件系统新分配的块上。如果一个文件被删除了，那么它在快照中的索引也会被删除。所以，快照主要是用来跟踪文件的更改，而不是文件的增加和创建。\n快照可以挂载成只读的，以用来恢复一个文件的过去版本。实时文件系统也可以回滚到之前的快照。回滚之后，自从快照创建之后的所有更改将会丢失。\n数据完整性验证和自动修复 当向 ZFS 写入新数据时，会创建该数据的校验和。在读取数据的时候，使用校验和进行验证。如果前后校验和不匹配，那么就说明检测到了错误，然后，ZFS 会尝试自动修正错误。\nRAID-Z ZFS 不需要任何额外软件或硬件就可以处理 RAID（磁盘阵列）。毫不奇怪，因为 ZFS 有自己的 RAID 实现：RAID-Z 。RAID-Z 是 RAID-5 的一个变种，不过它克服了 RAID-5 的写漏洞：意外重启之后，数据和校验信息会变得不同步（LCTT 译注：RAID-5 的条带在正写入数据时，如果这时候电源中断，那么奇偶校验数据将跟该部分数据不同步，因此前边的写无效；RAID-Z 用了 “可变宽的 RAID 条带” 技术，因此所有的写都是全条带写入）。为了使用基本级别的 RAID-Z（RAID-Z1），你需要至少三块磁盘，其中两块用来存储数据，另外一块用来存储奇偶校验信息。而 RAID-Z2 需要至少两块磁盘存储数据以及两块磁盘存储校验信息。RAID-Z3 需要至少两块磁盘存储数据以及三块磁盘存储校验信息。另外，只能向 RAID-Z 池中加入偶数倍的磁盘，而不能是奇数倍的。\n巨大的存储潜力 创建 ZFS 的时候，它是作为最后一个文件系统而设计的 。那时候，大多数文件系统都是 64 位的，ZFS 的创建者决定直接跳到 128 位，等到将来再来证明这是对的。这意味着 ZFS 的容量大小是 32 位或 64 位文件系统的 1600 亿亿倍。事实上，Jeff Bonwick（其中一个创建者）说：“完全填满一个 128 位的存储池所需要的能量，从字面上讲，比煮沸海洋需要的还多。”\n如何安装 ZFS？ 如果你想立刻使用 ZFS（开箱即用），那么你需要安装 FreeBSD 或一个使用 illumos 内核的操作系统。illumos 是 OpenSolaris 内核的一个克隆版本。\n事实上，支持 ZFS 是一些有经验的 Linux 用户选择 BSD 的主要原因。\n如果你想在 Linux 上尝试 ZFS，那么只能在存储文件系统上使用。据我所知，没有任何 Linux 发行版可以在根目录上安装 ZFS，实现开箱即用。如果你对在 Linux 上尝试 ZFS 感兴趣，那么 ZFS on Linux 项目 上有大量的教程可以指导你怎么做。\n在 Ubuntu 上使用 ZFS 如果您正在考虑将 ZFS 用于您的超高速 NVMe SSD，这可能不是一个最佳选择。 它比别的文件系统要慢，不过，这完全没有问题， 它旨在存储大量的数据并保持安全。\n$ sudo apt install zfs 创建池 在 ZFS 中，池大致相当于 RAID 。 它们很灵活且易于操作。\nRAID0 RAID0 只是把你的硬盘集中到一个池子里面，就像一个巨大的驱动器一样。 它可以提高你的驱动器速度，（LCTT 译注：数据条带化后，并行访问，可以提高文件读取速度）但是如果你的驱动器有损坏，你可能会失丢失数据。\n在计算机数据存储中，数据条带化是一种对逻辑顺序数据（例如文件）进行分段的技术，以便将连续的段存储在不同的物理存储设备上。\n要使用 ZFS 实现 RAID0，只需创建一个普通的池。\n$ sudo zpool create your-pool /dev/sdc /dev/sdd RAID1（镜像） 您可以在 ZFS 中使用 mirror 关键字来实现 RAID1 功能。 RAID1 会创建一个一对一的驱动器副本。 这意味着您的数据一直在备份。 它也提高了性能。 当然，你将一半的存储空间用于了复制。\n$ sudo zpool create your-pool mirror /dev/sdc /dev/sdd RAID5/RAIDZ1 ZFS 将 RAID5 功能实现为 RAIDZ1。 RAID5 要求驱动器至少是 3 个。并允许您通过将备份奇偶校验数据写入驱动器空间的 1/n（n 是驱动器数），留下的是可用的存储空间。 如果一个驱动器发生故障，阵列仍将保持联机状态，但应尽快更换发生故障的驱动器（LCTT 译注：与原文翻译略有不同，原文是驱动器的数目是三的倍数，根据 wiki， RAID5 至少需要 3 块驱动器，也可以从下面的命令中猜测)。\n$ sudo zpool create your-pool raidz1 /dev/sdc /dev/sdd /dev/sde RAID6/RAIDZ2 RAID6 与 RAID5 几乎完全相同，但它至少需要四个驱动器。 它将奇偶校验数据加倍，最多允许两个驱动器损坏，而不会导致阵列关闭（LCTT 译注：这里也与原文略有出入，原文是驱动器的数目是四的倍数，根据 wiki ，RAID6 至少需要四个驱动器)。\n$ sudo zpool create your-pool raidz2 /dev/sdc /dev/sdd /dev/sde /dev/sdf RAID10（条带化镜像） RAID10 旨在通过数据条带化提高存取速度和数据冗余来成为一个两全其美的解决方案。 你至少需要四个驱动器，但只能使用一半的空间。 您可以通过在同一个池中创建两个镜像来创建 RAID10 中的池（LCTT 译注：这里也与原文略有出入，原文是驱动器的数目是四的倍数，根据 wiki， RAID10 至少需要四个驱动器）。\n$ sudo zpool create your-pool mirror /dev/sdc /dev/sdd mirror /dev/sde /dev/sdf 池的操作 还有一些管理工具，一旦你创建了你的池，你就必须使用它们来操作。 首先，检查你的池的状态。\n$ sudo zpool status 更新 当你更新 ZFS 时，你也需要更新你的池。 当您检查它们的状态时，您的池会通知您任何更新。 要更新池，请运行以下命令。\n$ sudo zpool upgrade your-pool 你也可以更新全部池。\n$ sudo zpool upgrade -a 添加驱动器 您也可以随时将驱动器添加到池中。 告诉 zpool 池的名称和驱动器的位置，它会处理好一切。\n$ sudo zpool add your-pool /dev/sdx Systemd LINUX PID 1 和 SYSTEMD 要说清 Systemd，得先从Linux操作系统的启动说起。Linux 操作系统的启动首先从 BIOS 开始，然后由 Boot Loader 载入内核，并初始化内核。内核初始化的最后一步就是启动 init 进程。这个进程是系统的第一个进程，PID 为 1，又叫超级进程，也叫根进程。它负责产生其他所有用户进程。所有的进程都会被挂在这个进程下，如果这个进程退出了，那么所有的进程都被 kill 。如果一个子进程的父进程退了，那么这个子进程会被挂到 PID 1 下面。（注：PID 0 是内核的一部分，主要用于内进换页，参看：Process identifier）\nSysV Init PID 1 这个进程非常特殊，其主要就任务是把整个操作系统带入可操作的状态。比如：启动 UI – Shell 以便进行人机交互，或者进入 X 图形窗口。传统上，PID 1 和传统的 Unix System V 相兼容的，所以也叫 sysvinit，这是使用得最悠久的 init 实现。Unix System V 于1983年 release。\n在 sysvint 下，有好几个运行模式，又叫 runlevel。比如：常见的 3 级别指定启动到多用户的字符命令行界面，5 级别指定启起到图形界面，0 表示关机，6 表示重启。其配置在 /etc/inittab 文件中。\n与此配套的还有 /etc/init.d/ 和 /etc/rc[X].d，前者存放各种进程的启停脚本（需要按照规范支持 start，stop子命令），后者的 X 表示不同的 runlevel 下相应的后台进程服务，如：/etc/rc3.d 是 runlevel=3 的。 里面的文件主要是 link 到 /etc/init.d/ 里的启停脚本。其中也有一定的命名规范：S 或 K 打头的，后面跟一个数字，然后再跟一个自定义的名字，如：S01rsyslog，S02ssh。S 表示启动，K表示停止，数字表示执行的顺序。\nUpStart Unix 和 Linux 在 sysvint 运作多年后，大约到了2006年的时候，Linux内核进入2.6时代，Linux有了很多更新。并且，Linux开始进入桌面系统，而桌面系统和服务器系统不一样的是，桌面系统面临频繁重启，而且，用户会非常频繁的使用硬件的热插拔技术。于是，这些新的场景，让 sysvint 受到了很多挑战。\n比如，打印机需要CUPS等服务进程，但是如果用户没有打机印，启动这个服务完全是一种浪费，而如果不启动，如果要用打印机了，就无法使用，因为sysvint 没有自动检测的机制，它只能一次性启动所有的服务。另外，还有网络盘挂载的问题。在 /etc/fstab 中，负责硬盘挂载，有时候还有网络硬盘（NFS 或 iSCSI）在其中，但是在桌面机上，有很可能开机的时候是没有网络的， 于是网络硬盘都不可以访问，也无法挂载，这会极大的影响启动速度。sysvinit 采用 netdev 的方式来解决这个问题，也就是说，需要用户自己在 /etc/fstab 中给相应的硬盘配置上 netdev 属性，于是 sysvint 启动时不会挂载它，只有在网络可用后，由专门的 netfs 服务进程来挂载。这种管理方式比较难以管理，也很容易让人掉坑。\n所以，Ubuntu 开发人员在评估了当时几个可选的 init 系统后，决定重新设计这个系统，于是，这就是我们后面看到的 upstart 。 upstart 基于事件驱动的机制，把之前的完全串行的同步启动服务的方式改成了由事件驱动的异步的方式。比如：如果有U盘插入，udev 得到通知，upstart 感知到这个事件后触发相应的服务程序，比如挂载文件系统等等。因为使用一个事件驱动的玩法，所以，启动操作系统时，很多不必要的服务可以不用启动，而是等待通知，lazy 启动。而且事件驱动的好处是，可以并行启动服务，他们之间的依赖关系，由相应的事件通知完成。\nupstart 有着很不错的设计，其中最重要的两个概念是 Job 和 Event。\nJob 有一般的Job，也有service的Job，并且，upstart 管理了整个 Job 的生命周期，比如：Waiting, Starting, pre-Start, Spawned, post-Start, Running, pre-Stop, Stopping, Killed, post-Stop等等，并维护着这个生命周期的状态机。\nEvent 分成三类，signal, method 和 hooks。signal 就是异步消息，method 是同步阻塞的。hooks 也是同步的，但介于前面两者之间，发出hook事件的进程必须等到事件完成，但不检查是否成功。\n但是，upstart 的事件非常复杂，也非常纷乱，各种各样的事件（事件没有归好类）导致有点凌乱。不过因为整个事件驱动的设计比之前的 sysvinit 来说好太多，所以，也深得欢迎。\nSystemd 直到2010的有一天，一个在 RedHat工作的工程师 Lennart Poettering 和 Kay Sievers ，开始引入了一个新的 init 系统—— systemd。这是一个非常非常有野心的项目，这个项目几乎改变了所有的东西，systemd 不但想取代已有的 init 系统，而且还想干更多的东西。\nLennart 同意 upstart 干的不错，代码质量很好，基于事件的设计也很好。但是他觉得 upstart 也有问题，其中最大的问题还是不够快，虽然 upstart 用事件可以达到一定的启动并行度，但是，本质上来说，这些事件还是会让启动过程串行在一起。 如：NetworkManager 在等 D-Bus 的启动事件，而 D-Bus 在等 syslog 的启动事件。\nLennart 认为，实现上来说，upstart 其实是在管理一个逻辑上的服务依赖树，但是这个服务依赖树在表现形式上比较简单，你只需要配置——“启动 B好了就启动A”或是“停止了A后就停止B”这样的规则。但是，Lennart 说，这种简单其实是有害的（this simplification is actually detrimental）。他认为，\n  从一个系统管理的角度出来，他一开始会设定好整个系统启动的服务依赖树，但是这个系统管理员要人肉的把这个本来就非常干净的服务依整树给翻译成计算机看的懂的 Event/Action 形式，而且 Event/Action 这种配置方式是运行时的，所以，你需要运行起来才知道是什么样的。\n  Event逻辑从头到脚到处都是，这个事件扩大了运维的复杂度，还不如之前的 sysvint。 也就是说，当用户配置了 “启动 D-Bus 后请启动 NetworkManager”， 这个 upstart 可以干，但是反过来，如果，用户启动 NetworkManager，我们应该先去启动他的前置依赖 D-Bus，然而你还要配置相应的反向 Event。本来，我只需要配置一条依赖的，结果现在我要配置很多很多情况下的Event。\n  最后，upstart 里的 Event 的并不标准，很混乱，没有良好的定义。比如：既有，进程启动，运行，停止的事件，也有USB设备插入、可用、拔出的事件，还有文件系统设备being mounted、 mounted 和 umounted 的事件，还有AC电源线连接和断开的事件。你会发现，这进程启停的、USB的、文件系统的、电源线的事件，看上去长得很像， 但是没有被标准化抽像出来掉，因为绝大多数的事件都是三元组：start, condition, stop 。这种概念设计模型并没有在 upstart 中出现。因为 upstart 被设计为单一的事件，而忽略了逻辑依赖。\n  当然，如果 systemd 只是解决 upstart 的问题，他就改造 upstart 就好了，但是 Lennart 的野心不只是想干个这样的事，他想干的更多。\n首先，systemd 清醒的认识到了 init 进程的首要目标是要让用户快速的进入可以操作OS的环境，所以，这个速度一定要快，越快越好，所以，systemd 的设计理念就是两条：\n To start less. And to start more in parallel.  也就是说，按需启动，能不启动就不启动，如果要启动，能并行启动就并行启动，包括你们之间有依赖，我也并行启动。按需启动还好理解，那么，有依赖关系的并行启动，它是怎么做到的？这里，systemd 借鉴了 MacOS 的 Launchd 的玩法（在Youtube上有一个分享——Launchd: One Program to Rule them All，在苹果的开源网站上也有相关的设计文档——About Daemons and Services）\n要解决这些依赖性，systemd 需要解决好三种底层依赖—— Socket， D-Bus ，文件系统。\n  Socket依赖。如果服务C依赖于服务S的socket，那么就要先启动S，然后再启动C，因为如果C启动时找不到S的Socket，那么C就会失败。systemd 可以帮你在S还没有启动好的时候，建立一个socket，用来接收所有的C的请求和数据，并缓存之，一旦S全部启动完成，把systemd替换好的这个缓存的数据和Socket描述符替换过去。\n  D-Bus依赖。D-Bus 全称 Desktop Bus，是一个用来在进程间通信的服务。除了用于用户态进程和内核态进程通信，也用于用户态的进程之前。现在，很多的现在的服务进程都用 D-Bus 而不是Socket来通信。比如：NetworkManager 就是通过 D-Bus 和其它服务进程通讯的，也就是说，如果一个进程需要知道网络的状态，那么就必需要通过 D-Bus 通信。D-Bus 支持 “Bus Activation”的特性。也就是说，A要通过 D-Bus 服务和B通讯，但是B没有启动，那么 D-Bus 可以把B起来，在B启动的过程中，D-Bus 帮你缓存数据。systemd 可以帮你利用好这个特性来并行启动 A 和 B。\n  文件系统依赖。系统启动过程中，文件系统相关的活动是最耗时的，比如挂载文件系统，对文件系统进行磁盘检查（fsck），磁盘配额检查等都是非常耗时的操作。在等待这些工作完成的同时，系统处于空闲状态。那些想使用文件系统的服务似乎必须等待文件系统初始化完成才可以启动。systemd 参考了 autofs 的设计思路，使得依赖文件系统的服务和文件系统本身初始化两者可以并发工作。autofs 可以监测到某个文件系统挂载点真正被访问到的时候才触发挂载操作，这是通过内核 automounter 模块的支持而实现的。比如一个 open() 系统调用作用在某个文件系统上的时候，而这个文件系统尚未执行挂载，此时 open() 调用被内核挂起等待，等到挂载完成后，控制权返回给 open() 系统调用，并正常打开文件。这个过程和 autofs 是相似的。\n  下图来自 Lennart 的演讲里的一页PPT，展示了不同 init 系统的启动。\n除此之外，systemd 还在启动时管理好了一些下面的事。\n用C语言取代传统的脚本式的启动。前面说过，sysvint 用 /etc/rcX.d 下的各种脚本启动。然而这些脚本中需要使用 awk, sed, grep, find, xargs 等等这些操作系统的命令，这些命令需要生成进程，生成进程的开销很大，关键是生成完这些进程后，这个进程就干了点屁大的事就退了。换句话说就是，我操作系统干了那么多事为你拉个进程起来，结果你就把个字串转成小写就退了，把我操作系统当什么了？\n在正常的一个 sysvinit 的脚本里，可能会有成百上千个这样的命令。所以，慢死。因此，systemd 全面用 C 语言全部取代了。一般来说，sysvinit 下，操作系统启动完成后，用 echo $$ 可以看到，pid 被分配到了上千的样子，而 systemd 的系统只是上百。\n另外，systemd 是真正一个可以管住服务进程的——可以跟踪上服务进程所fork/exec出来的所有进程。\n  我们知道， 传统 Unix/Linux 的 Daemon 服务进程的最佳实践基本上是这个样子的（具体过程可参看这篇文章“[SysV Daemon](http://0pointer.de/public/systemd-man/daemon.html#SysV Daemons)”）\n 进程启动时，关闭所有的打开的文件描述符（除了标准描述符0,1,2），然后重置所有的信号处理。 调用 fork() 创建子进程，在子进程中 setsid()，然后父进程退出（为了后台执行） 在子进程中，再调用一次 fork()，创建孙子进程，确定没有交互终端。然后子进程退出。 在孙子进程中，把标准输入标准输出标准错误都连到 /dev/null 上，还要创建 pid 文件，日志文件，处理相关信号 …… 最后才是真正开始提供服务。    在上面的这个过程中，服务进程除了两次 fork 外还会 fork 出很多很多的子进程（比如说一些Web服务进程，会根据用户的请求链接来 fork 子进程），这个进程树是相当难以管理的，因为，一旦父进程退出来了，子进程就会被挂到 PID 1下，所以，基本上来说，你无法通过服务进程自已给定的一个pid文件来找到所有的相关进程（这个对开发者的要求太高了），所以，在传统的方式下用脚本启停服务是相当相当的 Buggy 的，因为无法做对所有的服务生出来的子子孙孙做到监控。\n  为了解决这个问题，upstart 通过变态的 strace 来跟踪进程中的 fork() 和 exec() 或 exit() 等相关的系统调用。这种方法相当笨拙。 systemd 使用了一个非常有意思的玩法来 tracking 服务进程生出来的所有进程，那就是用 cgroup （我在 Docker 的基础技术“cgroup篇”中讲过这个东西）。cgroup主要是用来管理进程组资源配额的事，所以，无论服务如何启动新的子进程，所有的这些相关进程都会同属于一个 cgroup，所以，systemd 只需要简单的去遍历一下相应的 cgroup 的那个虚文件系统目录下的文件，就可以正确的找到所有的相关进程，并将他们一一停止。\n  另外，systemd 简化了整个 daemon 开发的过程：\n 不需要两次 fork()，只需要实现服务本身的主逻辑就可以了。 不需要 setsid()，systemd 会帮你干 不需要维护 pid文件，systemd 会帮处理。 不需要管理日志文件或是使用syslog，或是处理HUP的日志reload信号。把日志打到 stderr 上，systemd 帮你管理。 处理 SIGTERM 信号，这个信号就是正确退出当前服务，不要做其他的事。 ……  除此之外，systemd 还能——\n 自动检测启动的服务间有没有环形依赖。 内建 autofs 自动挂载管理功能。 日志服务。systemd 改造了传统的 syslog 的问题，采用二进制格式保存日志，日志索引更快。 快照和恢复。对当前的系统运行的服务集合做快照，并可以恢复。 ……  还有好多好多，他接管很多很多东西，于是就让很多人不爽了，因为他在干了很多本不属于 PID 1 的事。\nSystemd 争论和八卦 于是 systemd 这个东西成了可能是有史以来口水战最多的一个开源软件了。systemd 饱受各种争议，最大的争议就是他破坏了 Unix 的设计哲学（相关的哲学可以读一下《Unix编程艺术》），干了一个大而全而且相当复杂的东西。当然，Lennart 并不同意这样的说法，他后来又写一篇blog “The Biggest Myths”来解释 systemd 并不是这样的，大家可以前往一读。\n这个争议大到什么样子呢？2014 年，Debian Linux 因为想准备使用 systemd 来作为标准的 init 守护进程来替换 sysvinit 。而围绕这个事的争论达到了空前的热度，争论中充满着仇恨，systemd 的支持者和反对者都在互相辱骂，导致当时 Debian 阵营开始分裂。还有人给 Lennart 发了死亡威胁的邮件，用比特币雇凶买杀手，扬言要取他的性命，在Youbute上传了侮辱他的歌曲，在IRC和各种社交渠道上给他发下流和侮辱性的消息。这已经不是争议了，而是一种不折不扣的仇恨！\n于是，Lennart 在 Google Plus 上发了贴子，批评整个 Linux 开源社区和 Linus 本人。他大意说，\n 这个社区太病态了，全是 ass holes，你们不停用各种手段在各种地方用不同的语言和方式来侮辱和漫骂我。我还是一个年轻人，我从来没有经历过这样的场面，但是今天我已经对这种场面很熟悉了。我有时候说话可能不准确，但是我不会像他样那样说出那样的话，我也没有被这些事影响，因为我脸皮够厚，所以，为什么我可以在如何大的反对声面前让 systemd 成功，但是，你们 Linux 社区太可怕了。你们里面的有精神病的人太多了。另外，对于Linus Torvalds，你是这个社区的 Role Model，但可惜你是一个 Bad Role Model，你在社区里的刻薄和侮辱性的言行，基本从一定程度上鼓励了其它人跟你一样，当然，并不只是你一个人的问题，而是在你周围聚集了一群和你一样的这样干的人。送你一句话—— A fish rots from the head down ！一条鱼是从头往下腐烂的……\n 这篇契文很长，喜欢八卦的同学可以前往一读。感受一下 Lennart 当时的心态（我觉得能算上是非常平稳了）。\nLinus也在被一媒体问起 systemd 这个事来（参看“Torvalds says he has no strong opinions on systemd”），Linus在采访里说，\n 我对 systemd 和 Lennart 的贴子没有什么强烈的想法。虽然，传统的 Unix 设计哲学—— “Do one thing and Do it well”，很不错，而且我们大多数人也实践了这么多年，但是这并不代表所有的真实世界。在历史上，也不只有systemd 这么干过。但是，我个人还是 old-fashioned 的人，至少我喜欢文本式的日志，而不是二进制的日志。但是 systemd 没有必要一定要有这样的品味。哦，我说细节了……\n 今天，systemd 占据了几乎所有的主流的 Linux 发行版的默认配置，包括：Arch Linux、CentOS、CoreOS、Debian、Fedora、Megeia、OpenSUSE、RHEL、SUSE企业版和 Ubuntu。而且，对于 CentOS, CoreOS, Fedora, RHEL, SUSE这些发行版来说，不能没有 systemd。（Ubuntu 还有一个不错的wiki – Systemd for Upstart Users 阐述了如何在两者间切换）\n其它 还记得在《缓存更新的套路》一文中，我说过，如果你要做好架构，首先你得把计算机体系结构以及很多老古董的基础技术吃透了。因为里面会有很多可以借鉴和相通的东西。那么，你是否从这篇文章里看到了一些有分布式架构相似的东西？\n比如：从 sysvinit 到 upstart 再到 systemd，像不像是服务治理？Linux系统下的这些服务进程，是不是很像分布式架构中的微服务？还有那个D-Bus，是不是很像SOA里的ESB？而 init 系统是不是很像一个控制系统？甚至像一个服务编排（Service Orchestration）系统？\n分布式系统中的服务之间也有很多依赖，所以，在启动一个架构的时候，如果我们可以做到像 systemd 那样并行启动的话，那么是不是就像是一个微服务的玩法了？\n嗯，你会发现，技术上的很多东西是相通的，也是互相有对方的影子，所以，其实技术并不多。关键是我们学在了表面还是看到了本质。\n命令 Systemd 是 Linux 系统工具，用来启动守护进程，已成为大多数发行版的标准配置。\n系统管理 Systemd 并不是一个命令，而是一组命令，涉及到系统管理的方方面面。\nsystemctl\nsystemctl是 Systemd 的主命令，用于管理系统。\n# 重启系统 $ sudo systemctl reboot # 关闭系统，切断电源 $ sudo systemctl poweroff # CPU停止工作 $ sudo systemctl halt # 暂停系统 $ sudo systemctl suspend # 让系统进入冬眠状态 $ sudo systemctl hibernate # 让系统进入交互式休眠状态 $ sudo systemctl hybrid-sleep # 启动进入救援状态（单用户状态） $ sudo systemctl rescue systemd-analyze\nsystemd-analyze命令用于查看启动耗时。\n# 查看启动耗时 $ systemd-analyze # 查看每个服务的启动耗时 $ systemd-analyze blame # 显示瀑布状的启动过程流$ $ systemd-analyze critical-chain # 显示指定服务的启动流 $ systemd-analyze critical-chain atd.service hostnamectl\nhostnamectl命令用于查看当前主机的信息。\n# 显示当前主机的信息 $ hostnamectl # 设置主机名。 $ sudo hostnamectl set-hostname rhel7 localectl\nlocalectl命令用于查看本地化设置。\n# 查看本地化设置 $ localectl # 设置本地化参数。 $ sudo localectl set-locale LANG=en_GB.utf8 $ sudo localectl set-keymap en_GB timedatectl\ntimedatectl命令用于查看当前时区设置。\n# 查看当前时区设置 $ timedatectl # 显示所有可用的时区 $ timedatectl list-timezones # 设置当前时区 $ sudo timedatectl set-timezone America/New_York $ sudo timedatectl set-time YYYY-MM-DD $ sudo timedatectl set-time HH:MM:SS loginctl\nloginctl命令用于查看当前登录的用户。\n# 列出当前session $ loginctl list-sessions # 列出当前登录用户 $ loginctl list-users # 列出显示指定用户的信息 $ loginctl show-user ruanyf Unit 含义\nSystemd 可以管理所有系统资源。不同的资源统称为 Unit（单元）。简单说，单元就是 Systemd 的最小功能单位，是单个进程的描述。一个个小的单元互相调用和依赖，组成一个庞大的任务管理系统，这就是 Systemd 的基本思想。\n由于 Systemd 要做的事情太多，导致单元有很多不同的种类，大概一共有12种。\n Service unit：系统服务 Target unit：多个 Unit 构成的一个组 Device Unit：硬件设备 Mount Unit：文件系统的挂载点 Automount Unit：自动挂载点 Path Unit：文件或路径 Scope Unit：不是由 Systemd 启动的外部进程 Slice Unit：进程组，资源分配 Snapshot Unit：Systemd 快照，可以切回某个快照 Socket Unit：进程间通信的 socket Swap Unit：swap 文件 Timer Unit：定时器  systemctl list-units命令可以查看当前系统的所有 Unit 。\n# 列出正在运行的 Unit $ systemctl list-units # 列出所有Unit，包括没有找到配置文件的或者启动失败的 $ systemctl list-units --all # 列出所有没有运行的 Unit $ systemctl list-units --all --state=inactive # 列出所有加载失败的 Unit $ systemctl list-units --failed # 列出所有正在运行的、类型为 service 的 Unit $ systemctl list-units --type=service Unit 的状态\nsystemctl status命令用于查看系统状态和单个 Unit 的状态。\n# 显示系统状态 $ systemctl status # 显示单个 Unit 的状态 $ sysystemctl status bluetooth.service # 显示远程主机的某个 Unit 的状态 $ systemctl -H root@rhel7.example.com status httpd.service 例如查看 httpd 状态\n$ sudo systemctl status httpd httpd.service - The Apache HTTP Server Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled) Active: active (running) since 金 2014-12-05 12:18:22 JST; 7min ago Main PID: 4349 (httpd) Status: \u0026#34;Total requests: 1; Current requests/sec: 0; Current traffic: 0 B/sec\u0026#34; CGroup: /system.slice/httpd.service ├─4349 /usr/sbin/httpd -DFOREGROUND ├─4350 /usr/sbin/httpd -DFOREGROUND ├─4351 /usr/sbin/httpd -DFOREGROUND ├─4352 /usr/sbin/httpd -DFOREGROUND ├─4353 /usr/sbin/httpd -DFOREGROUND └─4354 /usr/sbin/httpd -DFOREGROUND 12月 05 12:18:22 localhost.localdomain systemd[1]: Starting The Apache HTTP Server... 12月 05 12:18:22 localhost.localdomain systemd[1]: Started The Apache HTTP Server. 12月 05 12:22:40 localhost.localdomain systemd[1]: Started The Apache HTTP Server. 上面的输出结果含义如下。\n Loaded行：配置文件的位置，是否设为开机启动 Active行：表示正在运行 Main PID行：主进程ID Status行：由应用本身（这里是 httpd ）提供的软件当前状态 CGroup块：应用的所有子进程 日志块：应用的日志  除了status命令，systemctl还提供了三个查询状态的简单方法，主要供脚本内部的判断语句使用。\n# 显示某个 Unit 是否正在运行 $ systemctl is-active application.service # 显示某个 Unit 是否处于启动失败状态 $ systemctl is-failed application.service # 显示某个 Unit 服务是否建立了启动链接 $ systemctl is-enabled application.service Unit 管理\n对于用户来说，最常用的是下面这些命令，用于启动和停止 Unit（主要是 service）。\n# 立即启动一个服务 $ sudo systemctl start apache.service # 立即停止一个服务 $ sudo systemctl stop apache.service # 重启一个服务 $ sudo systemctl restart apache.service # 杀死一个服务的所有子进程 $ sudo systemctl kill apache.service # 重新加载一个服务的配置文件 $ sudo systemctl reload apache.service # 重载所有修改过的配置文件 $ sudo systemctl daemon-reload # 显示某个 Unit 的所有底层参数 $ systemctl show httpd.service # 显示某个 Unit 的指定属性的值 $ systemctl show -p CPUShares httpd.service # 设置某个 Unit 的指定属性 $ sudo systemctl set-property httpd.service CPUShares=500 有时候，该命令可能没有响应，执行systemctl stop服务停不下来。这时候就不得不\u0026quot;杀进程\u0026quot;了，向正在运行的进程发出kill信号，执行systemctl kill。\n依赖关系\nUnit 之间存在依赖关系：A 依赖于 B，就意味着 Systemd 在启动 A 的时候，同时会去启动 B。\nsystemctl list-dependencies命令列出一个 Unit 的所有依赖。\n$ systemctl list-dependencies nginx.service 上面命令的输出结果之中，有些依赖是 Target 类型（详见下文），默认不会展开显示。如果要展开 Target，就需要使用--all参数。\n$ systemctl list-dependencies --all nginx.service Unit 的配置文件 概述\n每一个 Unit 都有一个配置文件，告诉 Systemd 怎么启动这个 Unit 。\n除了系统默认的单元文件/lib/systemd/system，Systemd 默认从目录/etc/systemd/system/读取配置文件。但是，里面存放的大部分文件都是符号链接，指向目录/usr/lib/systemd/system/。那些支持 Systemd 的软件，安装的时候，也会自动在/usr/lib/systemd/system目录添加一个配置文件。\nsystemctl enable命令用于在/etc/systemd/system/和/usr/lib/systemd/system之间，建立符号链接关系。\n$ sudo systemctl enable clamd@scan.service # 等同于 $ sudo ln -s \u0026#39;/usr/lib/systemd/system/clamd@scan.service\u0026#39; \u0026#39;/etc/systemd/system/multi-user.target.wants/clamd@scan.service\u0026#39; 如果配置文件里面设置了开机启动，systemctl enable命令相当于激活开机启动。\n与之对应的，systemctl disable命令用于在两个目录之间，撤销符号链接关系，相当于撤销开机启动。\n$ sudo systemctl disable clamd@scan.service 配置文件的后缀名，就是该 Unit 的种类，比如sshd.socket。如果省略，Systemd 默认后缀名为.service，所以sshd会被理解成sshd.service。\n设置开机启动以后，软件并不会立即启动，必须等到下一次开机。如果想现在就运行该软件，那么要执行systemctl start命令。\n配置文件的状态\nsystemctl list-unit-files命令用于列出所有配置文件。\n# 列出所有配置文件 $ systemctl list-unit-files # 列出指定类型的配置文件 $ systemctl list-unit-files --type=service 这个命令会输出一个列表。\n$ systemctl list-unit-filesUNIT FILE STATEchronyd.service enabledclamd@.service staticclamd@scan.service disabled 这个列表显示每个配置文件的状态，一共有四种。\n enabled：已建立启动链接 disabled：没建立启动链接 static：该配置文件没有[Install]部分（无法执行），只能作为其他配置文件的依赖 masked：该配置文件被禁止建立启动链接  注意，从配置文件的状态无法看出，该 Unit 是否正在运行。这必须执行前面提到的systemctl status命令。\n$ systemctl status bluetooth.service 一旦修改配置文件，就要让 Systemd 重新加载配置文件，然后重新启动，否则修改不会生效。\n$ sudo systemctl daemon-reload $ sudo systemctl restart httpd.service 配置文件的格式\n配置文件就是普通的文本文件，可以用文本编辑器打开。\nsystemctl cat命令可以查看配置文件的内容。\n$ systemctl cat sshd.service [Unit] Description=OpenSSH server daemon Documentation=man:sshd(8) man:sshd_config(5) After=network.target sshd-keygen.service Wants=sshd-keygen.service [Service] EnvironmentFile=/etc/sysconfig/sshd ExecStart=/usr/sbin/sshd -D $OPTIONS ExecReload=/bin/kill -HUP $MAINPID Type=simpleKill Mode=process Restart=on-failure RestartSec=42s [Install] WantedBy=multi-user.target 从上面的输出可以看到，配置文件分成几个区块。每个区块的第一行，是用方括号表示的区别名，比如[Unit]。注意，配置文件的区块名和字段名，都是大小写敏感的。\n每个区块内部是一些等号连接的键值对。\n[Section] Directive1=value Directive2=value . . . 注意，键值对的等号两侧不能有空格。\n配置文件的区块\n[Unit]区块通常是配置文件的第一个区块，用来定义 Unit 的元数据，以及配置与其他 Unit 的关系。它的主要字段如下。\n  Description：当前服务的简单描述\n  Documentation：文档地址\n  启动顺序\n Before：如果该字段指定的 Unit 也要启动，那么必须在当前 Unit 之后启动 After：如果该字段指定的 Unit 也要启动，那么必须在当前 Unit 之前启动。如network.target或sshd-keygen.service需要启动，那么sshd.service应该在它们之后启动。    依赖关系：\n举例来说，某 Web 应用需要 postgresql 数据库储存数据。在配置文件中，Before、After 只定义要在 postgresql 之后启动，而没有定义依赖 postgresql 。上线后，由于某种原因，postgresql 需要重新启动，在停止服务期间，该 Web 应用就会无法建立数据库连接。\n注意，Wants字段与Requires字段只涉及依赖关系，与启动顺序无关，默认情况下是同时启动的。\n Wants：与当前 Unit 配合的其他 Unit，如果它们没有运行，当前 Unit 不会启动失败。如sshd.service与sshd-keygen.service之间存在\u0026quot;弱依赖\u0026quot;关系，即如果\u0026quot;sshd-keygen.service\u0026quot;启动失败或停止运行，不影响sshd.service继续执行。 Requires：当前 Unit 依赖的其他 Unit，如果它们没有运行，当前 Unit 会启动失败。Requires字段则表示\u0026quot;强依赖\u0026quot;关系，即如果该服务启动失败或异常退出，那么sshd.service也必须退出。    BindsTo：与Requires类似，它指定的 Unit 如果退出，会导致当前 Unit 停止运行\n  Conflicts：这里指定的 Unit 不能与当前 Unit 同时运行\n  Condition...：当前 Unit 运行必须满足的条件，否则不会运行\n  Assert...：当前 Unit 运行必须满足的条件，否则会报启动失败\n  StartLimitIntervalSec=interval, StartLimitBurst=burst：设置单元的启动频率限制。 也就是该单元在 interval 时间内最多允许启动 burst 次。\n   [Service]区块用来定义如何启动当前服务，只有 Service 类型的 Unit 才有这个区块。它的主要字段如下。\n EnvironmentFile字段：指定当前服务的环境参数文件。该文件内部的key=value键值对，可以用$key的形式，在当前配置文件中获取。sshd 的环境参数文件是/etc/sysconfig/sshd。 ExecStart字段：定义启动进程时执行的命令。是配置文件里面最重要的字段。上面的例子中，启动sshd，执行的命令是/usr/sbin/sshd -D $OPTIONS，其中的变量$OPTIONS就来自EnvironmentFile字段指定的环境参数文件。与之作用相似的，还有如下这些字段。  ExecReload字段：重启服务时执行的命令 ExecStop字段：停止服务时执行的命令 ExecStartPre字段：启动服务之前执行的命令 ExecStartPost字段：启动服务之后执行的命令 ExecStopPost字段：停止服务之后执行的命令   Type：字段定义启动类型。它可以设置的值如下。  simple（默认值）：ExecStart字段启动的进程为主进程 forking：ExecStart字段将以fork()方式启动，此时父进程将会退出，子进程将成为主进程 oneshot：类似于simple，但只执行一次，Systemd 会等它执行完，才启动其他服务 dbus：类似于simple，但会等待 D-Bus 信号后启动 notify：类似于simple，启动结束后会发出通知信号，然后 Systemd 再启动其他服务 idle：类似于simple，但是要等到其他任务都执行完，才会启动该服务。一种使用场合是为让该服务的输出，不与其他服务的输出相混合   KillMode字段：定义 Systemd 如何停止服务。  control-group（默认值）：当前控制组里面的所有子进程，都会被杀掉 process：只杀主进程。比如sshd的KillMode设为process，子进程打开的 SSH session 仍然保持连接。 mixed：主进程将收到 SIGTERM 信号，子进程收到 SIGKILL 信号 none：没有进程会被杀掉，只是执行服务的 stop 命令。   Restart：Restart字段：定义了服务退出后，Systemd 重启该服务的方式。  no（默认值）：退出后不会重启 on-success：只有正常退出时（退出状态码为0），才会重启 on-failure：非正常退出时（退出状态码非0），包括被信号终止和超时，才会重启。比如sshd任何意外的失败，都将重启sshd；如果 sshd 正常停止（比如执行systemctl stop命令），它就不会重启。对于守护进程，推荐设为on-failure。 on-abnormal：只有被信号终止和超时，才会重启。对于那些允许发生错误退出的服务，可以设为on-abnormal。 on-abort：只有在收到没有捕捉到的信号终止时，才会重启 on-watchdog：超时退出，才会重启 always：不管是什么退出原因，总是重启   RestartSec字段：表示 Systemd 重启服务之前，需要等待的秒数。 TimeoutSec：定义 Systemd 停止当前服务之前等待的秒数  所有的启动设置之前，都可以加上一个连词号（-），表示\u0026quot;抑制错误\u0026quot;，即发生错误的时候，不影响其他命令的执行。比如，EnvironmentFile=-/etc/sysconfig/sshd（注意等号后面的那个连词号），就表示即使/etc/sysconfig/sshd文件不存在，也不会抛出错误。\n [Install]通常是配置文件的最后一个区块，定义如何安装这个配置文件，即怎样做到开机启动。它的主要字段如下。\n WantedBy字段：表示该服务所在的 Target，它的值是一个或多个 Target。Target的含义是服务组，表示一组服务。WantedBy=multi-user.target指的是，sshd 所在的 Target 是multi-user.target。当前 Unit 激活时（enable）符号链接会放入/etc/systemd/system目录下面 [Target 名].wants子目录中，如multi-user.target.wants子目录。 RequiredBy：它的值是一个或多个 Target，当前 Unit 激活时，符号链接会放入/etc/systemd/system目录下面以 Target 名 + .required后缀构成的子目录中 Alias：当前 Unit 可用于启动的别名 Also：当前 Unit 激活（enable）时，会被同时激活的其他 Unit  Unit 配置文件的完整字段清单，请参考官方文档。\nTarget 启动计算机的时候，需要启动大量的 Unit。如果每一次启动，都要一一写明本次启动需要哪些 Unit，显然非常不方便。Systemd 的解决方案就是 Target。\n简单说，Target 就是一个 Unit 组，包含许多相关的 Unit 。启动某个 Target 的时候，Systemd 就会启动里面所有的 Unit。从这个意义上说，Target 这个概念类似于\u0026quot;状态点\u0026quot;，启动某个 Target 就好比启动到某种状态。\n传统的init启动模式里面，有 RunLevel 的概念，跟 Target 的作用很类似。不同的是，RunLevel 是互斥的，不可能多个 RunLevel 同时启动，但是多个 Target 可以同时启动。\n# 查看当前系统的所有 Target $ systemctl list-unit-files --type=target # 查看一个 Target 包含的所有 Unit $ systemctl list-dependencies multi-user.target # 查看启动时的默认 Target，在这个组里的所有服务，都将开机启动。 $ systemctl get-default # 设置启动时的默认 Target $ sudo systemctl set-default multi-user.target # 切换 Target 时，默认不关闭前一个 Target 启动的进程， # systemctl isolate 命令改变这种行为， # 关闭前一个 Target 里面所有不属于后一个 Target 的进程 $ sudo systemctl isolate multi-user.target Target 与 传统 RunLevel 的对应关系如下。\nTraditional runlevel New target name Symbolically linked to... Runlevel 0 | runlevel0.target -\u0026gt; poweroff.target Runlevel 1 | runlevel1.target -\u0026gt; rescue.target Runlevel 2 | runlevel2.target -\u0026gt; multi-user.target Runlevel 3 | runlevel3.target -\u0026gt; multi-user.target Runlevel 4 | runlevel4.target -\u0026gt; multi-user.target Runlevel 5 | runlevel5.target -\u0026gt; graphical.target Runlevel 6 | runlevel6.target -\u0026gt; reboot.target 它与init进程的主要差别如下。\n（1）默认的 RunLevel（在/etc/inittab文件设置）现在被默认的 Target 取代，位置是/etc/systemd/system/default.target，通常符号链接到graphical.target（图形界面）或者multi-user.target（多用户命令行）。\n（2）启动脚本的位置，以前是/etc/init.d目录，符号链接到不同的 RunLevel 目录 （比如/etc/rc3.d、/etc/rc5.d等），现在则存放在/lib/systemd/system和/etc/systemd/system目录。\n（3）配置文件的位置，以前init进程的配置文件是/etc/inittab，各种服务的配置文件存放在/etc/sysconfig目录。现在的配置文件主要存放在/lib/systemd目录，在/etc/systemd目录里面的修改可以覆盖原始设置。\n日志管理 Systemd 统一管理所有 Unit 的启动日志。带来的好处就是，可以只用journalctl一个命令，查看所有日志（内核日志和应用日志）。日志的配置文件是/etc/systemd/journald.conf。\njournalctl功能强大，用法非常多。\n# 查看所有日志（默认情况下 ，只保存本次启动的日志） $ sudo journalctl # 查看内核日志（不显示应用日志） $ sudo journalctl -k # 查看系统本次启动的日志 $ sudo journalctl -b $ sudo journalctl -b -0 # 查看上一次启动的日志（需更改设置） $ sudo journalctl -b -1 # 查看指定时间的日志 $ sudo journalctl --since=\u0026#34;2012-10-30 18:17:16\u0026#34; $ sudo journalctl --since \u0026#34;20 min ago\u0026#34; $ sudo journalctl --since yesterday $ sudo journalctl --since \u0026#34;2015-01-10\u0026#34; --until \u0026#34;2015-01-11 03:00\u0026#34; $ sudo journalctl --since 09:00 --until \u0026#34;1 hour ago\u0026#34; # 显示尾部的最新10行日志 $ sudo journalctl -n # 显示尾部指定行数的日志 $ sudo journalctl -n 20 # 实时滚动显示最新日志 $ sudo journalctl -f # 查看指定服务的日志 $ sudo journalctl /usr/lib/systemd/systemd # 查看指定进程的日志 $ sudo journalctl _PID=1 # 查看某个路径的脚本的日志 $ sudo journalctl /bin/bash # 查看指定用户的日志 $ sudo journalctl _UID=33 --since today # 查看某个 Unit 的日志 $ sudo journalctl -u nginx.service $ sudo journalctl -u nginx.service --since today # 实时滚动显示某个 Unit 的最新日志 $ sudo journalctl -u nginx.service -f # 合并显示多个 Unit 的日志 $ journalctl -u nginx.service -u php-fpm.service --since today # 查看指定优先级（及其以上级别）的日志，共有8级 # 0: emerg # 1: alert # 2: crit # 3: err # 4: warning # 5: notice # 6: info # 7: debug $ sudo journalctl -p err -b # 日志默认分页输出，--no-pager 改为正常的标准输出 $ sudo journalctl --no-pager # 以 JSON 格式（单行）输出 $ sudo journalctl -b -u nginx.service -o json # 以 JSON 格式（多行）输出，可读性更好 $ sudo journalctl -b -u nginx.serviceqq -o json-pretty # 显示日志占据的硬盘空间 $ sudo journalctl --disk-usage # 指定日志文件占据的最大空间 $ sudo journalctl --vacuum-size=1G # 指定日志文件保存多久 $ sudo journalctl --vacuum-time=1years 定时器示例 邮件脚本 先写一个发邮件的脚本mail.sh。\n#!/usr/bin/env bash echo \u0026#34;This is the body\u0026#34; | /usr/bin/mail -s \u0026#34;Subject\u0026#34; someone@example.com 上面代码的someone@example.com，请替换成你的邮箱地址。\n然后，执行这个脚本。\n$ bash mail.sh 执行后，你应该就会收到一封邮件，标题为Subject。\n如果你的 Linux 系统不能发邮件，建议安装 ssmtp 或者 msmtp。另外，mail命令的用法，可以参考这里。\nService 单元 Service 单元就是所要执行的任务，比如发送邮件就是一种 Service。\n新建 Service 非常简单，就是在/usr/lib/systemd/system目录里面新建一个文件，比如mytimer.service文件，你可以写入下面的内容。\n[Unit] Description=MyTimer [Service] ExecStart=/bin/bash /path/to/mail.sh 注意，定义的时候，所有路径都要写成绝对路径，比如bash要写成/bin/bash，否则 Systemd 会找不到。\n现在，启动这个 Service。\n$ sudo systemctl start mytimer.service 如果一切正常，你应该就会收到一封邮件。\nTimer 单元 Service 单元只是定义了如何执行任务，要定时执行这个 Service，还必须定义 Timer 单元。\n/usr/lib/systemd/system目录里面，新建一个mytimer.timer文件，写入下面的内容。\n[Unit] Description=Runs mytimer every hour [Timer] OnUnitActiveSec=1h Unit=mytimer.service [Install] WantedBy=multi-user.target 这个 Timer 单元文件分成几个部分。\n[Timer]部分定制定时器。Systemd 提供以下一些字段。\n OnActiveSec：定时器生效后，多少时间开始执行任务 OnBootSec：系统启动后，多少时间开始执行任务 OnStartupSec：Systemd 进程启动后，多少时间开始执行任务 OnUnitActiveSec：该单元上次执行后，等多少时间再次执行 OnUnitInactiveSec： 定时器上次关闭后多少时间，再次执行 OnCalendar：基于绝对时间，而不是相对时间执行 AccuracySec：如果因为各种原因，任务必须推迟执行，推迟的最大秒数，默认是60秒 Unit：真正要执行的任务，默认是同名的带有.service后缀的单元 Persistent：如果设置了该字段，即使定时器到时没有启动，也会自动执行相应的单元 WakeSystem：如果系统休眠，是否自动唤醒系统  上面的脚本里面，OnUnitActiveSec=1h表示一小时执行一次任务。其他的写法还有OnCalendar=*-*-* 02:00:00表示每天凌晨两点执行，OnCalendar=Mon *-*-* 02:00:00表示每周一凌晨两点执行，具体请参考中文手册。\nSystem time 一个操作系统通过如下内容确定时间：时间数值、时间标准、时区和夏令时调节(中国已经废止)。本文分别介绍各个部分的定义及如何设置他们。要维护准确的系统时间，请参考 网络时间协议 一文。\n硬件时钟和系统时钟 系统用两个时钟保存时间：硬件时钟和系统时钟。\n硬件时钟(即实时时钟 RTC 或 CMOS 时钟)仅能保存：年、月、日、时、分、秒这些时间数值，无法保存时间标准(UTC 或 localtime)和是否使用夏令时调节。\n系统时钟(即软件时间) 与硬件时间分别维护，保存了：时间、时区和夏令时设置。Linux 内核保存为自 UTC 时间 1970 年1月1日经过的秒数。初始系统时钟是从硬件时间计算得来，计算时会考虑/etc/adjtime的设置。系统启动之后，系统时钟与硬件时钟独立运行，Linux 通过时钟中断计数维护系统时钟。\n如果系统时间是按 32 位整数保存的，最大只能记到 2038 年，所以 32 位 Linux 系统将在 2038 年停止工作。\n大部分操作系统的时间管理包括如下方面：\n 启动时根据硬件时钟设置系统时间 运行时通过时间同步联网校正时间 关机时根据系统时间设置硬件时间  读取时间 下面命令可以获得硬件时间和系统时间(硬件时钟按 localtime 显示):\n$ timedatectl Local time: Thu 2022-01-27 10:35:26 CST Universal time: Thu 2022-01-27 02:35:26 UTC RTC time: Thu 2022-01-27 02:35:26 Time zone: Asia/Shanghai (CST, +0800) System clock synchronized: yes NTP service: active RTC in local TZ: no 名词解释：\n CST：(China Standard Time,UTC+8:00) 中国沿海时间(北京时间) UTC：(Universal Time Coordinated,UTC) 世界协调时间 GMT：(Greenwich Mean Time ,GMT）格林威治时间 LT：(locale time）本地时间  设置时间 设置系统时间的本地时间：\n# timedatectl set-time \u0026quot;yyyy-MM-dd hh:mm:ss\u0026quot; 例如:\n# timedatectl set-time \u0026quot;2014-05-26 11:13:54\u0026quot; 设置时间为2014年，5月26日，11时13分54秒。\n时间标准 时间表示有两个标准：localtime 和 UTC(Coordinated Universal Time) 。UTC 是与时区无关的全球时间标准。尽管概念上有差别，UTC 和 GMT (格林威治时间) 是一样的。localtime 标准则依赖于当前时区。\n时间标准由操作系统设定，Windows 默认使用 localtime，Mac OS 默认使用 UTC，而 UNIX 系列的操作系统两者都有。使用 Linux 时，最好将硬件时钟设置为 UTC 标准，并在所有操作系统中使用。这样 Linux 系统就可以自动调整夏令时设置，而如果使用 localtime 标准那么系统时间不会根据夏令时自动调整。\n通过如下命令可以检查当前设置，systemd 默认硬件时钟为协调世界时（UTC）。\n$ timedatectl status | grep local RTC in local TZ: no 硬件时间可以用 hwclock 命令设置，将硬件时间设置为 localtime：\n# timedatectl set-local-rtc 1 硬件时间设置成 UTC：\n# timedatectl set-local-rtc 0 上述命令会自动生成/etc/adjtime，无需单独设置。\n注意： 如果不存在 /etc/adjtime，systemd 会假定硬件时间按 UTC 设置。\n系统启动装入 rtc 驱动时可能会根据系统时钟设置硬件时钟。是否设置依赖于平台、内核版本和内核编译选项。如果进行了设置，此时会假定硬件时钟为 UTC 标准，/sys/class/rtc/rtcN/hctosys(N=0,1,2,..) 会设置成 1。后面 systemd 会根据/etc/adjtime重新设置。\n如果设置成本地时间，处理夏令时有些麻烦。如果夏令时调整发生在关机时，下次启动时时间会出现问题（更多信息）。最新的内核直接从实时时钟芯片（RTC）读取时间，不使用 hwclock，内核把从 RTC 读取的时间当作 UTC 处理。所以如果硬件时间是地方时，系统启动一开始识别的时间是错误的，之后很快会进行矫正。这可能导致一些问题（尤其是时间倒退时）。\nWindows 系统使用 UTC 如果同时安装了 Windows 操作系统（默认使用地方时），那么一般 RTC 会被设置为地方时。Windows 其实也能处理 UTC，需要修改注册表。建议让 Windows 使用 UTC，而非让 Linux 使用地方时。Windows 使用 UTC 后，请记得禁用 Windows 的时间同步功能，以防 Windows 错误设置硬件时间。如上文所说，Linux 可以使用NTP服务来在线同步硬件时钟。\n使用 regedit,新建如下 DWORD 值，并将其值设为十六进制的 1。\nHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation\\RealTimeIsUniversal 也可以用管理员权限启动命令行来完成：\nreg add \u0026quot;HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\TimeZoneInformation\u0026quot; /v RealTimeIsUniversal /d 1 /t REG_DWORD /f 如果以上操作不起作用，并且你使用的是 Windows 64位系统，将 DWORD 修改为 QWORD。\n如果 Windows 要求根据夏令时更新时钟，可以允许。时钟仍然是 UTC，仅是显示时间会改变。\n设置时间标准后需要重新设置硬件时间和系统时间。\n如果你有时间偏移问题，再次设置你的时区:\n# timedatectl set-timezone Asia/Shanghai UTC 在Ubuntu的设置 Ubuntu及其衍生发行版会在安装时检测计算机上是否存在Windows，若存在则会默认使用localtime。这是为了让Windows用户能够在不修改注册表的情况下，在Ubuntu内看到正确的时间。\n要改变这种行为，请参见上面的内容。\n时区 检查当前时区：\n$ timedatectl status 显示可用时区：\n$ timedatectl list-timezones 修改时区：\n# timedatectl set-timezone \u0026lt;Zone\u0026gt;/\u0026lt;SubZone\u0026gt; 例如：\n# timedatectl set-timezone Asia/Shanghai 此命令会创建一个/etc/localtime软链接，指向/usr/share/zoneinfo/中的时区文件，如果手动创建此链接请确保是相对链接而不是绝对链接。\n注意： 如果pre-systemd配置的/etc/timezone仍然存在于你的系统，你可以放心地将其删除，因为它不再使用。\n时钟偏移 最能代表“真实时间”的是国际原子时钟)，所有的时钟都是有误差的。电子时钟的时间是不准的，但是一般有固定的偏移。这种于基值的差称为“time skew”或“时间偏移”。用 hwclock 设置硬件时间时，会计算每天偏移的秒数。偏移值是原硬件时间与新设置硬件时间的差，并且考虑上次硬件时间设置时的偏移。新的偏移值会在设置时钟时写到文件 /etc/adjtime 。\n注意： 如果硬件时间值与原值的差小于 24 小时，偏移量不会重新计算，因为时间过短，无法精确设置偏移。\n如果硬件时钟总是过快或过慢，可能是计算了错误的偏移值。硬件时钟设置错误或者时间标准与其他操作系统不一致导致。删除文件 /etc/adjtime 可以删除偏移值，然后设置正确的硬件时钟和系统时钟，并检查时间标准是不是设置正确。\n注意： 使用 Systemd 时，要使用 /etc/adjtime中的 drift 值(即无法或不想使用 NTP 时); 需要每次调用 hwclock --adjust命令，可以通过 cron 任务实现。\n提高系统时间精度的方法有：\nNTP 可以通过网络时间协议同步 Linux 系统的时间。NTP 也会修正中断频率和每秒滴答数以减少时间偏移。并且每隔 11 分钟同步一次硬件时钟。\n时钟同步 网络时间协议 (NTP) 是一个通过包交换和可变延迟网络来同步计算机系统时间的协议。下列为这个协议的实现：\n NTP 守护进程是这个协议的参考实现，推荐用于时间服务器。它也可以调节中断频率和每秒滴答次数以减少系统时钟误差，使得硬件时钟每隔11秒重新同步一次。 sntp 是一个 SNTP 客户端。它取代了 ntpdate ，并被推荐用于非服务器环境。 systemd-timesyncd 是一个简单的 SNTP 守护进程。它只实现了客户端，专用于从远程服务器查询时间，更适用于绝大部分安装的情形。 OpenNTPD 是 OpenBSD 项目的一部分，同时实现了客户端和服务器。 Chrony 是一个客户端和服务器，更适合漫游，是为不能始终保持在线的系统而特别设计。 ntpclient 是简单的命令行 NTP 客户端  防火墙 保障数据的安全性是继保障数据的可用性之后最为重要的一项工作。防火墙作为公网与内网之间的保护屏障，在保障数据的安全性方面起着至关重要的作用。\n防火墙管理工具 众所周知，相较于企业内网，外部的公网环境更加恶劣，罪恶丛生。在公网与企业内网之间充当保护屏障的防火墙虽然有软件或硬件之分，但主要功能都是依据策略对穿越防火墙自身的流量进行过滤。就像家里安装的防盗门一样，目的是保护亲人和财产安全。防火墙策略可以基于流量的源目地址、端口号、协议、应用等信息来定制，然后防火墙使用预先定制的策略规则监控出入的流量，若流量与某一条策略规则相匹配，则执行相应的处理，反之则丢弃。这样一来，就能够保证仅有合法的流量在企业内网和外部公网之间流动了。\n从RHEL 7系统开始，firewalld防火墙正式取代了iptables防火墙。对于接触Linux系统比较早或学习过RHEL 5/6系统的读者来说，当他们发现曾经掌握的知识在RHEL 7/8中不再适用，需要全新学习firewalld时，难免会有抵触心理。其实，iptables与firewalld都不是真正的防火墙，它们都只是用来定义防火墙策略的防火墙管理工具而已；或者说，它们只是一种服务。iptables服务会把配置好的防火墙策略交由内核层面的netfilter网络过滤器来处理，而firewalld服务则是把配置好的防火墙策略交由内核层面的nftables包过滤框架来处理。换句话说，当前在Linux系统中其实存在多个防火墙管理工具，旨在方便运维人员管理Linux系统中的防火墙策略，我们只需要配置妥当其中的一个就足够了。\n虽然这些工具各有优劣，但它们在防火墙策略的配置思路上是保持一致的。大家甚至可以不用完全掌握本章介绍的内容，只要在这多个防火墙管理工具中任选一款并将其学透，就足以满足日常的工作需求了。\nIptables 在早期的Linux系统中，默认使用的是iptables防火墙管理服务来配置防火墙。尽管新型的firewalld防火墙管理服务已经被投入使用多年，但是大量的企业在生产环境中依然出于各种原因而继续使用iptables。\n策略与规则链 防火墙会按照从上到下的顺序来读取配置的策略规则，在找到匹配项后就立即结束匹配工作并去执行匹配项中定义的行为（即放行或阻止）。如果在读取完所有的策略规则之后没有匹配项，就去执行默认的策略。一般而言，防火墙策略规则的设置有两种：“通”（即放行）和“堵”（即阻止）。当防火墙的默认策略为拒绝时（堵），就要设置允许规则（通），否则谁都进不来；如果防火墙的默认策略为允许，就要设置拒绝规则，否则谁都能进来，防火墙也就失去了防范的作用。\niptables服务把用于处理或过滤流量的策略条目称之为规则，多条规则可以组成一个规则链，而规则链则依据数据包处理位置的不同进行分类，具体如下：\n 在进行路由选择前处理数据包（PREROUTING）； 处理流入的数据包（INPUT）； 处理流出的数据包（OUTPUT）； 处理转发的数据包（FORWARD）； 在进行路由选择后处理数据包（POSTROUTING）。  一般来说，从内网向外网发送的流量一般都是可控且良性的，因此使用最多的就是INPUT规则链，该规则链可以增大黑客人员从外网入侵内网的难度。\n比如在您居住的社区内，物业管理公司有两条规定：禁止小商小贩进入社区；各种车辆在进入社区时都要登记。显而易见，这两条规定应该是用于社区的正门的（流量必须经过的地方），而不是每家每户的防盗门上。根据前面提到的防火墙策略的匹配顺序，可能会存在多种情况。比如，来访人员是小商小贩，则直接会被物业公司的保安拒之门外，也就无须再对车辆进行登记。如果来访人员乘坐一辆汽车进入社区正门，则“禁止小商小贩进入社区”的第一条规则就没有被匹配到，因此按照顺序匹配第二条策略，即需要对车辆进行登记。如果是社区居民要进入正门，则这两条规定都不会匹配到，因此会执行默认的放行策略。\n但是，仅有策略规则还不能保证社区的安全，保安还应该知道采用什么样的动作来处理这些匹配的流量，比如“允许”“拒绝”“登记”“不理它”。这些动作对应到iptables服务的术语中分别是ACCEPT（允许流量通过）、REJECT（拒绝流量通过）、LOG（记录日志信息）、DROP（拒绝流量通过）。“允许流量通过”和“记录日志信息”都比较好理解，这里需要着重讲解的是REJECT和DROP的不同点。就DROP来说，它是直接将流量丢弃而且不响应；REJECT则会在拒绝流量后再回复一条“信息已经收到，但是被扔掉了”信息，从而让流量发送方清晰地看到数据被拒绝的响应信息。\n下面举一个例子，让各位读者更直观地理解这两个拒绝动作的不同之处。比如有一天您正在家里看电视，突然听到有人敲门，您透过防盗门的猫眼一看是推销商品的，便会在不需要的情况下开门并拒绝他们（REJECT）。但如果看到的是债主带了十几个小弟来讨债，此时不仅要拒绝开门，还要默不作声，伪装成自己不在家的样子（DROP）。\n当把Linux系统中的防火墙策略设置为REJECT动作后，流量发送方会看到端口不可达的响应：\n[root@linuxprobe ~]# ping -c 4 192.168.10.10 PING 192.168.10.10 (192.168.10.10) 56(84) bytes of data. From 192.168.10.10 icmp_seq=1 Destination Port Unreachable From 192.168.10.10 icmp_seq=2 Destination Port Unreachable From 192.168.10.10 icmp_seq=3 Destination Port Unreachable From 192.168.10.10 icmp_seq=4 Destination Port Unreachable --- 192.168.10.10 ping statistics --- 4 packets transmitted, 0 received, +4 errors, 100 packet loss, time 3002ms 而把Linux系统中的防火墙策略修改成DROP动作后，流量发送方会看到响应超时的提醒。但是流量发送方无法判断流量是被拒绝，还是接收方主机当前不在线：\n[root@linuxprobe ~]# ping -c 4 192.168.10.10 PING 192.168.10.10 (192.168.10.10) 56(84) bytes of data. --- 192.168.10.10 ping statistics --- 4 packets transmitted, 0 received, 100 packet loss, time 3000ms 基本的命令参数 iptables是一款基于命令行的防火墙策略管理工具，具有大量的参数，学习难度较大。好在对于日常的防火墙策略配置来讲，大家无须深入了解诸如“四表五链”的理论概念，只需要掌握常用的参数并做到灵活搭配即可，这就足以应对日常工作了。\n根据OSI七层模型的定义，iptables属于数据链路层的服务，所以可以根据流量的源地址、目的地址、传输协议、服务类型等信息进行匹配；一旦匹配成功，iptables就会根据策略规则所预设的动作来处理这些流量。另外，再次提醒一下，防火墙策略规则的匹配顺序是从上到下的，因此要把较为严格、优先级较高的策略规则放到前面，以免发生错误。表8-1总结归纳了常用的iptables命令参数。再次强调，无须死记硬背这些参数，只需借助下面的实验来理解掌握即可。\n   参数 作用     -P 设置默认策略   -F 清空规则链   -L 查看规则链   -A 在规则链的末尾加入新规则   -I num 在规则链的头部加入新规则   -D num 删除某一条规则   -s 匹配来源地址IP/MASK，加叹号“!”表示除这个IP外   -d 匹配目标地址   -i 网卡名称 匹配从这块网卡流入的数据   -o 网卡名称 匹配从这块网卡流出的数据   -p 匹配协议，如TCP、UDP、ICMP   \u0026ndash;dport num 匹配目标端口号   \u0026ndash;sport num 匹配来源端口号    1．在iptables命令后添加-L参数查看已有的防火墙规则链。\n[root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination ACCEPT udp -- anywhere anywhere udp dpt:domain ACCEPT tcp -- anywhere anywhere tcp dpt:domain ACCEPT udp -- anywhere anywhere udp dpt:bootps ACCEPT tcp -- anywhere anywhere tcp dpt:bootps Chain FORWARD (policy ACCEPT) target prot opt source destination ACCEPT all -- anywhere 192.168.122.0/24 ctstate RELATED,ESTABLISHED ACCEPT all -- 192.168.122.0/24 anywhere ACCEPT all -- anywhere anywhere REJECT all -- anywhere anywhere reject-with icmp-port-unreachable REJECT all -- anywhere anywhere reject-with icmp-port-unreachable Chain OUTPUT (policy ACCEPT) target prot opt source destination ACCEPT udp -- anywhere anywhere udp dpt:bootpc 2．在iptables命令后添加-F参数清空已有的防火墙规则链。\n[root@linuxprobe ~]# iptables -F [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination 3．把INPUT规则链的默认策略设置为拒绝。\n[root@linuxprobe ~]# iptables -P INPUT DROP [root@linuxprobe ~]# iptables -L Chain INPUT (policy DROP) target prot opt source destination Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination 前文提到，防火墙策略规则的设置无非有两种方式：“通”和“堵”。当把INPUT链设置为默认拒绝后，就要往里面写入允许策略了，否则所有流入的数据包都会被默认拒绝掉。同学们需要留意的是，规则链的默认策略拒绝动作只能是DROP，而不能是REJECT。\n4．向INPUT链中添加允许ICMP流量进入的策略规则。\n在日常运维工作中，经常会使用ping命令来检查对方主机是否在线，而向防火墙的INPUT规则链中添加一条允许ICMP流量进入的策略规则就默认允许了这种ping命令检测行为。\n[root@linuxprobe ~]# iptables -I INPUT -p icmp -j ACCEPT [root@linuxprobe ~]# ping -c 4 192.168.10.10 PING 192.168.10.10 (192.168.10.10) 56(84) bytes of data. 64 bytes from 192.168.10.10: icmp_seq=1 ttl=64 time=0.154 ms 64 bytes from 192.168.10.10: icmp_seq=2 ttl=64 time=0.041 ms 64 bytes from 192.168.10.10: icmp_seq=3 ttl=64 time=0.038 ms 64 bytes from 192.168.10.10: icmp_seq=4 ttl=64 time=0.046 ms --- 192.168.10.10 ping statistics --- 4 packets transmitted, 4 received, 0 packet loss, time 104ms rtt min/avg/max/mdev = 0.038/0.069/0.154/0.049 ms 5．删除INPUT规则链中刚刚加入的那条策略（允许ICMP流量），并把默认策略设置为允许。\n使用-F参数会清空已有的所有防火墙策略；使用-D参数可以删除某一条指定的策略，因此更加安全和准确。\n[root@linuxprobe ~]# iptables -D INPUT 1 [root@linuxprobe ~]# iptables -P INPUT ACCEPT [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination 6．将INPUT规则链设置为只允许指定网段的主机访问本机的22端口，拒绝来自其他所有主机的流量。\n要对某台主机进行匹配，可直接写出它的IP地址；如需对网段进行匹配，则需要写为子网掩码的形式（比如192.168.10.0/24）。\n[root@linuxprobe ~]# iptables -I INPUT -s 192.168.10.0/24 -p tcp --dport 22 -j ACCEPT [root@linuxprobe ~]# iptables -A INPUT -p tcp --dport 22 -j REJECT [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination ACCEPT tcp -- 192.168.10.0/24 anywhere tcp dpt:ssh REJECT tcp -- anywhere anywhere tcp dpt:ssh reject-with icmp-port-unreachable ………………省略部分输出信息……………… 再次重申，防火墙策略规则是按照从上到下的顺序匹配的，因此一定要把允许动作放到拒绝动作前面，否则所有的流量就将被拒绝掉，从而导致任何主机都无法访问我们的服务。另外，这里提到的22号端口是ssh服务使用的。\n在设置完上述INPUT规则链之后，使用IP地址在192.168.10.0/24网段内的主机访问服务器（即前面提到的设置了INPUT规则链的主机）的22端口，效果如下：\n[root@Client A ~]# ssh 192.168.10.10 The authenticity of host \u0026#39;192.168.10.10 (192.168.10.10)\u0026#39; can\u0026#39;t be established. ECDSA key fingerprint is SHA256:5d52kZi1la/FJK4v4jibLBZhLqzGqbJAskZiME6ZXpQ. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added \u0026#39;192.168.10.10\u0026#39; (ECDSA) to the list of known hosts. root@192.168.10.10\u0026#39;s password: 此处输入服务器密码 Activate the web console with: systemctl enable --now cockpit.socket Last login: Wed Jan 20 16:30:28 2021 from 192.168.10.1 然后，再使用IP地址在192.168.20.0/24网段内的主机访问服务器的22端口（虽网段不同，但已确认可以相互通信），效果如下：\n[root@Client B ~]# ssh 192.168.10.10 Connecting to 192.168.10.10:22... Could not connect to \u0026#39;192.168.10.10\u0026#39; (port 22): Connection failed. 由上可以看到，提示连接请求被拒绝了（Connection failed）。\n7．向INPUT规则链中添加拒绝所有人访问本机12345端口的策略规则。\n[root@linuxprobe ~]# iptables -I INPUT -p tcp --dport 12345 -j REJECT [root@linuxprobe ~]# iptables -I INPUT -p udp --dport 12345 -j REJECT [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination REJECT udp -- anywhere anywhere udp dpt:italk reject-with icmp-port-unreachable REJECT tcp -- anywhere anywhere tcp dpt:italk reject-with icmp-port-unreachable ACCEPT tcp -- 192.168.10.0/24 anywhere tcp dpt:ssh REJECT tcp -- anywhere anywhere tcp dpt:ssh reject-with icmp-port-unreachable ………………省略部分输出信息……………… 8．向INPUT规则链中添加拒绝192.168.10.5主机访问本机80端口（Web服务）的策略规则。\n[root@linuxprobe ~]# iptables -I INPUT -p tcp -s 192.168.10.5 --dport 80 -j REJECT [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination REJECT tcp -- 192.168.10.5 anywhere tcp dpt:http reject-with icmp-port-unreachable REJECT udp -- anywhere anywhere udp dpt:italk reject-with icmp-port-unreachable REJECT tcp -- anywhere anywhere tcp dpt:italk reject-with icmp-port-unreachable ACCEPT tcp -- 192.168.10.0/24 anywhere tcp dpt:ssh REJECT tcp -- anywhere anywhere tcp dpt:ssh reject-with icmp-port-unreachable ………………省略部分输出信息……………… 9．向INPUT规则链中添加拒绝所有主机访问本机1000～1024端口的策略规则。\n前面在添加防火墙策略时，使用的是-I参数，它默认会把规则添加到最上面的位置，因此优先级是最高的。如果工作中需要添加一条最后“兜底”的规则，那就用-A参数吧。这两个参数的效果差别还是很大的：\n[root@linuxprobe ~]# iptables -A INPUT -p tcp --dport 1000:1024 -j REJECT [root@linuxprobe ~]# iptables -A INPUT -p udp --dport 1000:1024 -j REJECT [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination REJECT tcp -- 192.168.10.5 anywhere tcp dpt:http reject-with icmp-port-unreachable REJECT udp -- anywhere anywhere udp dpt:italk reject-with icmp-port-unreachable REJECT tcp -- anywhere anywhere tcp dpt:italk reject-with icmp-port-unreachable ACCEPT tcp -- 192.168.10.0/24 anywhere tcp dpt:ssh REJECT tcp -- anywhere anywhere tcp dpt:ssh reject-with icmp-port-unreachable REJECT tcp -- anywhere anywhere tcp dpts:cadlock2:1024 reject-with icmp-port-unreachable REJECT udp -- anywhere anywhere udp dpts:cadlock2:1024 reject-with icmp-port-unreachable ………………省略部分输出信息……………… 有关iptables命令的知识讲解到此就结束了，大家是不是意犹未尽？考虑到Linux防火墙的发展趋势，大家只要能把上面的实例吸收消化，就可以完全搞定日常的iptables配置工作了。但是请特别注意，使用iptables命令配置的防火墙规则默认会在系统下一次重启时失效，如果想让配置的防火墙策略永久生效，还要执行保存命令：\n[root@linuxprobe ~]# iptables-save  # Generated by xtables-save v1.8.2 on Wed Jan 20 16:56:27 2021 ………………省略部分输出信息……………… 对了，如果公司服务器是5/6/7版本的话，对应的保存命令应该是：\n[root@linuxprobe ~]# service iptables save iptables: Saving firewall rules to /etc/sysconfig/iptables: [ OK ] Firewalld RHEL 8系统中集成了多款防火墙管理工具，其中firewalld（Dynamic Firewall Manager of Linux systems，Linux系统的动态防火墙管理器）服务是默认的防火墙配置管理工具，它拥有基于CLI（命令行界面）和基于GUI（图形用户界面）的两种管理方式。\nRHEL 8系统中集成了多款防火墙管理工具，其中firewalld（Dynamic Firewall Manager of Linux systems，Linux系统的动态防火墙管理器）服务是默认的防火墙配置管理工具，它拥有基于CLI（命令行界面）和基于GUI（图形用户界面）的两种管理方式。\n相较于传统的防火墙管理配置工具，firewalld支持动态更新技术并加入了区域（zone）的概念。简单来说，区域就是firewalld预先准备了几套防火墙策略集合（策略模板），用户可以根据生产场景的不同而选择合适的策略集合，从而实现防火墙策略之间的快速切换。例如，我们有一台笔记本电脑，每天都要在办公室、咖啡厅和家里使用。按常理来讲，这三者的安全性按照由高到低的顺序来排列，应该是家庭、公司办公室、咖啡厅。当前，我们希望为这台笔记本电脑制定如下防火墙策略规则：在家中允许访问所有服务；在办公室内仅允许访问文件共享服务；在咖啡厅仅允许上网浏览。在以往，我们需要频繁地手动设置防火墙策略规则，而现在只需要预设好区域集合，然后轻点鼠标就可以自动切换了，从而极大地提升了防火墙策略的应用效率。firewalld中常见的区域名称（默认为public）以及相应的策略规则如表所示。\n   区域 默认规则策略     trusted 允许所有的数据包   home 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh、mdns、ipp-client、amba-client与dhcpv6-client服务相关，则允许流量   internal 等同于home区域   work 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh、ipp-client与dhcpv6-client服务相关，则允许流量   public 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh、dhcpv6-client服务相关，则允许流量   external 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh服务相关，则允许流量   dmz 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh服务相关，则允许流量   block 拒绝流入的流量，除非与流出的流量相关   drop 拒绝流入的流量，除非与流出的流量相关    终端管理工具 命令行终端是一种极富效率的工作方式，firewall-cmd是firewalld防火墙配置管理工具的CLI（命令行界面）版本。它的参数一般都是以“长格式”来提供的。大家不要一听到长格式就头大，因为RHEL 8系统支持部分命令的参数补齐，其中就包含这条命令（很酷吧）。也就是说，现在除了能用Tab键自动补齐命令或文件名等内容之外，还可以用Tab键来补齐表所示的长格式参数。这太棒了！\n   参数 作用     \u0026ndash;get-default-zone 查询默认的区域名称   \u0026ndash;set-default-zone=\u0026lt;区域名称\u0026gt; 设置默认的区域，使其永久生效   \u0026ndash;get-zones 显示可用的区域   \u0026ndash;get-services 显示预先定义的服务   \u0026ndash;get-active-zones 显示当前正在使用的区域与网卡名称   \u0026ndash;add-source= 将源自此IP或子网的流量导向指定的区域   \u0026ndash;remove-source= 不再将源自此IP或子网的流量导向某个指定区域   \u0026ndash;add-interface=\u0026lt;网卡名称\u0026gt; 将源自该网卡的所有流量都导向某个指定区域   \u0026ndash;change-interface=\u0026lt;网卡名称\u0026gt; 将某个网卡与区域进行关联   \u0026ndash;list-all 显示当前区域的网卡配置参数、资源、端口以及服务等信息   \u0026ndash;list-all-zones 显示所有区域的网卡配置参数、资源、端口以及服务等信息   \u0026ndash;add-service=\u0026lt;服务名\u0026gt; 设置默认区域允许该服务的流量   \u0026ndash;add-port=\u0026lt;端口号/协议\u0026gt; 设置默认区域允许该端口的流量   \u0026ndash;remove-service=\u0026lt;服务名\u0026gt; 设置默认区域不再允许该服务的流量   \u0026ndash;remove-port=\u0026lt;端口号/协议\u0026gt; 设置默认区域不再允许该端口的流量   \u0026ndash;reload 让“永久生效”的配置规则立即生效，并覆盖当前的配置规则   \u0026ndash;panic-on 开启应急状况模式   \u0026ndash;panic-off 关闭应急状况模式    与Linux系统中其他的防火墙策略配置工具一样，使用firewalld配置的防火墙策略默认为运行时（Runtime）模式，又称为当前生效模式，而且会随着系统的重启而失效。如果想让配置策略一直存在，就需要使用永久（Permanent）模式了，方法就是在用firewall-cmd命令正常设置防火墙策略时添加\u0026ndash;permanent参数，这样配置的防火墙策略就可以永久生效了。但是，永久生效模式有一个“不近人情”的特点，就是使用它设置的策略只有在系统重启之后才能自动生效。如果想让配置的策略立即生效，需要手动执行firewall-cmd \u0026ndash;reload命令。\n接下来的实验都很简单，但是提醒大家一定要仔细查看使用的是Runtime模式还是Permanent模式。如果不关注这个细节，就算正确配置了防火墙策略，也可能无法达到预期的效果。\n1．查看firewalld服务当前所使用的区域。\n这是一步非常重要的操作。在配置防火墙策略前，必须查看当前生效的是哪个区域，否则配置的防火墙策略将不会立即生效。\n[root@linuxprobe ~]# firewall-cmd --get-default-zone public 2．查询指定网卡在firewalld服务中绑定的区域。\n在生产环境中，服务器大多不止有一块网卡。一般来说，充当网关的服务器有两块网卡，一块对公网，另外一块对内网，那么这两块网卡在审查流量时所用的策略肯定也是不一致的。因此，可以根据网卡针对的流量来源，为网卡绑定不同的区域，实现对防火墙策略的灵活管控。\n[root@linuxprobe ~]# firewall-cmd --get-zone-of-interface=ens160 public 3．把网卡默认区域修改为external，并在系统重启后生效。\n[root@linuxprobe ~]# firewall-cmd --permanent --zone=external --change-interface=ens160 The interface is under control of NetworkManager, setting zone to \u0026#39;external\u0026#39;. success [root@linuxprobe ~]# firewall-cmd --permanent --get-zone-of-interface=ens160 external 4．把firewalld服务的默认区域设置为public。\n默认区域也叫全局配置，指的是对所有网卡都生效的配置，优先级较低。在下面的代码中可以看到，当前默认区域为public，而ens160网卡的区域为external。此时便是以网卡的区域名称为准。\n通俗来说，默认区域就是一种通用的政策。例如，食堂为所有人准备了一次性餐具，而环保主义者则会自己携带碗筷。如果您自带了碗筷，就可以用自己的；反之就用食堂统一提供的。\n[root@linuxprobe ~]# firewall-cmd --set-default-zone=public Warning: ZONE_ALREADY_SET: public success [root@linuxprobe ~]# firewall-cmd --get-default-zone  public [root@linuxprobe ~]# firewall-cmd --get-zone-of-interface=ens160 external 5．启动和关闭firewalld防火墙服务的应急状况模式。\n如果想在1s的时间内阻断一切网络连接，有什么好办法呢？大家下意识地会说：“拔掉网线！”这是一个物理级别的高招。但是，如果人在北京，服务器在异地呢？panic紧急模式在这个时候就派上用场了。使用\u0026ndash;panic-on参数会立即切断一切网络连接，而使用\u0026ndash;panic-off则会恢复网络连接。切记，紧急模式会切断一切网络连接，因此在远程管理服务器时，在按下回车键前一定要三思。\n[root@linuxprobe ~]# firewall-cmd --panic-on success [root@linuxprobe ~]# firewall-cmd --panic-off success 6．查询SSH和HTTPS协议的流量是否允许放行。\n在工作中可以不使用\u0026ndash;zone参数指定区域名称，firewall-cmd命令会自动依据默认区域进行查询，从而减少用户输入量。但是，如果默认区域与网卡所绑定的不一致时，就会发生冲突，因此规范写法的zone参数是一定要加的。\n[root@linuxprobe ~]# firewall-cmd --zone=public --query-service=ssh yes [root@linuxprobe ~]# firewall-cmd --zone=public --query-service=https no 7．把HTTPS协议的流量设置为永久允许放行，并立即生效。\n默认情况下进行的修改都属于Runtime模式，即当前生效而重启后失效，因此在工作和考试中尽量避免使用。而在使用\u0026ndash;permanent参数时，则是当前不会立即看到效果，而在重启或重新加载后方可生效。于是，在添加了允许放行HTTPS流量的策略后，查询当前模式策略，发现依然是不允许放行HTTPS协议的流量：\n[root@linuxprobe ~]# firewall-cmd --permanent --zone=public --add-service=https success [root@linuxprobe ~]# firewall-cmd --zone=public --query-service=https no 不想重启服务器的话，就用\u0026ndash;reload参数吧：\n[root@linuxprobe ~]# firewall-cmd --reload success [root@linuxprobe ~]# firewall-cmd --zone=public --query-service=https yes 8．把HTTP协议的流量设置为永久拒绝，并立即生效。\n由于在默认情况下HTTP协议的流量就没有被允许，所以会有“Warning: NOT_ENABLED: http”这样的提示信息，因此对实际操作没有影响。\n[root@linuxprobe ~]# firewall-cmd --permanent --zone=public --remove-service=http Warning: NOT_ENABLED: http success [root@linuxprobe ~]# firewall-cmd --reload  success 9．把访问8080和8081端口的流量策略设置为允许，但仅限当前生效。\n[root@linuxprobe ~]# firewall-cmd --zone=public --add-port=8080-8081/tcp success [root@linuxprobe ~]# firewall-cmd --zone=public --list-ports 8080-8081/tcp 10．把原本访问本机888端口的流量转发到22端口，要且求当前和长期均有效。\nSSH远程控制协议是基于TCP/22端口传输控制指令的，如果想让用户通过其他端口号也能访问ssh服务，就可以试试端口转发技术了。通过这项技术，新的端口号在收到用户请求后会自动转发到原本服务的端口上，使得用户能够通过新的端口访问到原本的服务。\n来举个例子帮助大家理解。假设小强是电子厂的工人，他喜欢上了三号流水线上的工人小花，但不好意思表白，于是写了一封情书并交给门卫张大爷，希望由张大爷转交给小花。这样一来，情书（信息）的传输由从小强到小花，变成了小强到张大爷再到小花，情书（信息）依然能顺利送达。\n使用firewall-cmd命令实现端口转发的格式有点长，这里为大家总结好了：\nfirewall-cmd --permanent --zone=\u0026lt;区域\u0026gt; --add-forward-port=port=\u0026lt;源端口号\u0026gt;:proto=\u0026lt;协议\u0026gt;:toport=\u0026lt;目标端口号\u0026gt;:toaddr=\u0026lt;目标IP地址\u0026gt; 上述命令中的目标IP地址一般是服务器本机的IP地址：\n[root@linuxprobe ~]# firewall-cmd --permanent --zone=public --add-forward-port=port=888:proto=tcp:toport=22:toaddr=192.168.10.10 success [root@linuxprobe ~]# firewall-cmd --reload success 在客户端使用ssh命令尝试访问192.168.10.10主机的888端口，访问成功：\n[root@client A ~]# ssh -p 888 192.168.10.10 The authenticity of host \u0026#39;[192.168.10.10]:888 ([192.168.10.10]:888)\u0026#39; can\u0026#39;t be established. ECDSA key fingerprint is b8:25:88:89:5c:05:b6:dd:ef:76:63:ff:1a:54:02:1a. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added \u0026#39;[192.168.10.10]:888\u0026#39; (ECDSA) to the list of known hosts. root@192.168.10.10\u0026#39;s password:此处输入远程root管理员的密码 Last login: Sun Jul 19 21:43:48 2021 from 192.168.10.10 11．富规则的设置。\n富规则也叫复规则，表示更细致、更详细的防火墙策略配置，它可以针对系统服务、端口号、源地址和目标地址等诸多信息进行更有针对性的策略配置。它的优先级在所有的防火墙策略中也是最高的。比如，我们可以在firewalld服务中配置一条富规则，使其拒绝192.168.10.0/24网段的所有用户访问本机的ssh服务（22端口）：\n[root@linuxprobe ~]# firewall-cmd --permanent --zone=public --add-rich-rule=\u0026#34;rule family=\u0026#34;ipv4\u0026#34; source address=\u0026#34;192.168.10.0/24\u0026#34; service name=\u0026#34;ssh\u0026#34; reject\u0026#34; success [root@linuxprobe ~]# firewall-cmd --reload success 在客户端使用ssh命令尝试访问192.168.10.10主机的ssh服务（22端口）：\n[root@client A ~]# ssh 192.168.10.10 Connecting to 192.168.10.10:22... Could not connect to \u0026#39;192.168.10.10\u0026#39; (port 22): Connection failed. 图形管理工具 在各种版本的Linux系统中，几乎没有能让刘遄老师欣慰并推荐的图形化工具，但是firewall-config做到了。它是firewalld防火墙配置管理工具的GUI（图形用户界面）版本，几乎可以实现所有以命令行来执行的操作。毫不夸张地说，即使读者没有扎实的Linux命令基础，也完全可以通过它来妥善配置RHEL 8中的防火墙策略。\n成功 firewall-config 安装后，其工具的界面如图所示：\n其功能具体如下。\n1：选择运行时（Runtime）或永久（Permanent）模式的配置。\n2：可选的策略集合区域列表。\n3：常用的系统服务列表。\n4：主机地址的黑白名单。\n5：当前正在使用的区域。\n6：管理当前被选中区域中的服务。\n7：管理当前被选中区域中的端口。\n8：设置允许被访问的协议。\n9：设置允许被访问的端口。\n10：开启或关闭SNAT（源网络地址转换）技术。\n11：设置端口转发策略。\n12：控制请求icmp服务的流量。\n13：管理防火墙的富规则。\n14：被选中区域的服务，若勾选了相应服务前面的复选框，则表示允许与之相关的流量。\n15：firewall-config工具的运行状态。\n除了图中列出的功能，还有用于将网卡与区域绑定的Interfaces选项，以及用于将IP地址与区域绑定的Sources选项。另外再啰唆一句。在使用firewall-config工具配置完防火墙策略之后，无须进行二次确认，因为只要有修改内容，它就自动进行保存。\n下面进行动手实践环节。\n先将当前区域中请求http服务的流量设置为允许放行，但仅限当前生效。具体配置如图所示：\n尝试添加一条防火墙策略规则，使其放行访问8080～8088端口（TCP协议）的流量，并将其设置为永久生效，以达到系统重启后防火墙策略依然生效的目的。在按照下图所示的界面配置完毕之后，还需要在Options菜单中单击Reload Firewalld命令，让配置的防火墙策略立即生效。这与在命令行中使用\u0026ndash;reload参数的效果一样。\n放行访问8080～8088端口的流量：\n让配置的防火墙策略规则立即生效：\n前面在讲解firewall-config工具的功能时，曾经提到了SNAT（Source Network Address Translation，源网络地址转换）技术。SNAT是一种为了解决IP地址匮乏而设计的技术，它可以使得多个内网中的用户通过同一个外网IP接入Internet。该技术的应用非常广泛，甚至可以说我们每天都在使用，只不过没有察觉到罢了。比如，当通过家中的网关设备（无线路由器）访问本书配套站点www.linuxprobe.com时，就用到了SNAT技术。\n大家可以看一下在网络中不使用SNAT技术和使用SNAT技术时的情况。在没有使用SNAT技术的局域网中有多台PC，如果网关服务器没有应用SNAT技术，则互联网中的网站服务器在收到PC的请求数据包，并回送响应数据包时，将无法在网络中找到这个私有网络的IP地址，所以PC也就收不到响应数据包了。在使用SNAT技术处理过的局域网中，由于网关服务器应用了SNAT技术，所以互联网中的网站服务器会将响应数据包发给网关服务器，再由后者转发给局域网中的PC。\n没有使用SNAT技术的网络：\n使用SNAT技术处理过的网络：\n使用iptables命令实现SNAT技术是一件很麻烦的事情，但是在firewall-config中却是小菜一碟了。用户只需按照下图进行配置，并选中Masquerade zone复选框，就自动开启了SNAT技术。\n为了让大家直观查看不同工具在实现相同功能时的区别，针对前面使用firewall-cmd配置的防火墙策略规则，这里使用firewall-config工具进行了重新演示：将本机888端口的流量转发到22端口，且要求当前和长期均有效，具体如下图所示：\n配置本地的端口转发：\n让防火墙效策略规则立即生效：\n用命令配置富规则可真辛苦，幸好我们现在有了图形用户界面的工具。让192.168.10.20主机访问本机的1234端口号，如下图所示。其中Element选项能够根据服务名称、端口号、协议等信息进行匹配；Source与Destination选项后的inverted复选框代表反选功能，将其选中则代表对已填写信息进行反选，即选中填写信息以外的主机地址；Log复选框在选中后，日志不仅会被记录到日志文件中，而且还可以在设置日志的级别（Level）后，再将日志记录到日志文件中，以方便后续的筛查。\n如果生产环境中的服务器有多块网卡在同时提供服务（这种情况很常见），则对内网和对外网提供服务的网卡要选择的防火墙策略区域也是不一样的。也就是说，可以把网卡与防火墙策略区域进行绑定，这样就可以使用不同的防火墙区域策略，对源自不同网卡的流量进行有针对性的监控，效果会更好。\n把网卡与防火墙策略区域进行绑定：\n网卡与策略区域绑定完成：\n最后再提一句，firewall-config工具真的非常实用，很多原本复杂的长命令被图形化按钮替代，设置规则也简单明了，足以应对日常工作。所以再次向大家强调配置防火墙策略的原则—只要能实现所需的功能，用什么工具请随君便。\n服务的访问控制列表 TCP Wrapper是RHEL 6/7系统中默认启用的一款流量监控程序，它能够根据来访主机的地址与本机的目标服务程序做出允许或拒绝的操作。在RHEL 8版本中，它已经被firewalld正式替代。换句话说，Linux系统中其实有两个层面的防火墙，第一种是前面讲到的基于TCP/IP协议的流量过滤工具，而TCP Wrapper服务则是能允许或禁止Linux系统提供服务的防火墙，从而在更高层面保护了Linux系统的安全运行。\nTCP Wrapper服务的防火墙策略由两个控制列表文件所控制，用户可以编辑允许控制列表文件来放行对服务的请求流量，也可以编辑拒绝控制列表文件来阻止对服务的请求流量。控制列表文件修改后会立即生效，系统将会先检查允许控制列表文件（/etc/hosts.allow），如果匹配到相应的允许策略则放行流量；如果没有匹配，则会进一步匹配拒绝控制列表文件（/etc/hosts.deny），若找到匹配项则拒绝该流量。如果这两个文件都没有匹配到，则默认放行流量。\n由于RHEL 8版本已经不再支持TCP Wrapper服务程序，因此我们接下来选择在一台老版本的服务器上进行实验。TCP Wrapper服务的控制列表文件配置起来并不复杂，常用的参数如表所示。\n   客户端类型 示例 满足示例的客户端列表     单一主机 192.168.10.10 IP地址为192.168.10.10的主机   指定网段 192.168.10. IP段为192.168.10.0/24的主机   指定网段 192.168.10.0/255.255.255.0 IP段为192.168.10.0/24的主机   指定DNS后缀 .linuxprobe.com 所有DNS后缀为.linuxprobe.com的主机   指定主机名称 www.linuxprobe.com 主机名称为www.linuxprobe.com的主机   指定所有客户端 ALL 所有主机全部包括在内    在配置TCP Wrapper服务时需要遵循两个原则：\n 编写拒绝策略规则时，填写的是服务名称，而非协议名称； 建议先编写拒绝策略规则，再编写允许策略规则，以便直观地看到相应的效果。  下面编写拒绝策略规则文件，禁止访问本机sshd服务的所有流量（无须修改/etc/hosts.deny文件中原有的注释信息）：\n[root@linuxprobe ~]# vim /etc/hosts.deny # # hosts.deny This file contains access rules which are used to # deny connections to network services that either use # the tcp_wrappers library or that have been # started through a tcp_wrappers-enabled xinetd. # # The rules in this file can also be set up in # /etc/hosts.allow with a \u0026#39;deny\u0026#39; option instead. # # See \u0026#39;man 5 hosts_options\u0026#39; and \u0026#39;man 5 hosts_access\u0026#39; # for information on rule syntax. # See \u0026#39;man tcpd\u0026#39; for information on tcp_wrappers sshd:* [root@linuxprobe ~]# ssh 192.168.10.10 ssh_exchange_identification: read: Connection reset by peer 接下来，在允许策略规则文件中添加一条规则，使其放行源自192.168.10.0/24网段，且访问本机sshd服务的所有流量。可以看到，服务器立刻就放行了访问sshd服务的流量，效果非常直观：\n[root@linuxprobe ~]# vim /etc/hosts.allow # # hosts.allow This file contains access rules which are used to # allow or deny connections to network services that # either use the tcp_wrappers library or that have been # started through a tcp_wrappers-enabled xinetd. # # See \u0026#39;man 5 hosts_options\u0026#39; and \u0026#39;man 5 hosts_access\u0026#39; # for information on rule syntax. # See \u0026#39;man tcpd\u0026#39; for information on tcp_wrappers sshd:192.168.10. [root@linuxprobe ~]# ssh 192.168.10.10 The authenticity of host \u0026#39;192.168.10.10 (192.168.10.10)\u0026#39; can\u0026#39;t be established. ECDSA key fingerprint is 70:3b:5d:37:96:7b:2e:a5:28:0d:7e:dc:47:6a:fe:5c. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added \u0026#39;192.168.10.10\u0026#39; (ECDSA) to the list of known hosts. root@192.168.10.10\u0026#39;s password: Last login: Wed May 4 07:56:29 2021 [root@linuxprobe ~]#  Cockpit 驾驶舱管理工具 首先，Cockpit是一个英文单词，即“（飞机、船或赛车的）驾驶舱、驾驶座”，它用名字传达出了功能丰富的特性。其次，Cockpit是一个基于Web的图形化服务管理工具，对用户相当友好，即便是新手也可以轻松上手。而且它天然具备很好的跨平台性，因此被广泛应用于服务器、容器、虚拟机等多种管理场景。最后，红帽公司对Cockpit也十分看重，直接将它默认安装到了RHEL 8系统中，由此衍生的CentOS和Fedora也都标配有Cockpit。\nCockpit在默认情况下就已经被安装到系统中。下面执行dnf命令对此进行确认：\n[root@linuxprobe ~]# dnf install cockpit Updating Subscription Management repositories. Unable to read consumer identity This system is not registered to Red Hat Subscription Management. You can use subscription-manager to register. AppStream 3.1 MB/s | 3.2 kB 00:00 BaseOS 2.7 MB/s | 2.7 kB 00:00 Package cockpit-185-2.el8.x86_64 is already installed. Dependencies resolved. Nothing to do. Complete! 但是，Cockpit服务程序在RHEL 8版本中没有自动运行，下面将它开启并加入到开机启动项中：\n[root@linuxprobe ~]# systemctl start cockpit [root@linuxprobe ~]# systemctl enable cockpit.socket Created symlink /etc/systemd/system/sockets.target.wants/cockpit.socket → /usr/lib/systemd/system/cockpit.socket. 在Cockpit服务启动后，打开系统自带的浏览器，在地址栏中输入“本机地址:9090”即可访问。由于访问Cockpit的流量会使用HTTPS进行加密，而证书又是在本地签发的，因此还需要进行添加并信任本地证书的操作。\n添加额外允许的证书：\n确认信任本地证书：\n进入Cockpit的登录界面后，输入root管理员的账号与系统密码，单击Log In按钮后即可进入：\n进入Cockpit的Web界面，发现里面可谓“别有洞天”。Cockpit总共分为13个功能模块：系统状态（System）、日志信息（Logs）、硬盘存储（Storage）、网卡网络（Networking）、账户安全（Accounts）、服务程序（Services）、软件仓库（Applications）、报告分析（Diagnostic Reports）、内核排错（Kernel Dump）、SElinux、更新软件（Software Updates）、订阅服务（Subscriptions）、终端界面（Terminal）。下面逐一进行讲解。\n1．System\n进入Cockpit界面后默认显示的便是System（系统）界面，在该界面中能够看到系统架构、版本、主机名与时间等信息，还能够动态地展现出CPU、硬盘、内存和网络的复杂情况，这有点类似于Web版的“Winodws系统任务管理器”，属实好用。\n系统状态界面：\n2．Logs\n这个模块能够提供系统的全部日志，但是同学们可能会好奇，“为什么下图中的内容这么有限呢”？原因出在图中的两个选项中：时间和日志级别。通过这两个选项可以让用户更快地找到所需信息，而不是像/var/log/message文件那样一股脑儿地都抛给用户。\n日志信息界面：\n3．Storage\n这个功能模块是同学们最喜欢的一个模块，原因不是这个模块显示了硬盘的I/O读写负载情况，而是可以让用户通过该界面，用鼠标创建出RAID、LVM、VDO和iSCSI等存储设备。是的，您没有看错，RAID和LVM都可以用鼠标进行创建了，是不是很开心呢？\n硬盘存储界面：\n4．Networking\n既然名为Networking模块，那么动态看网卡的输出和接收值肯定是这个模块的标配功能了。我们不仅可以在这里进行网卡的绑定（Bonding）和聚合（Team），还可以创建桥接网卡及添加VLAN。最下方会单独列出与网卡相关的日志信息。\n网卡网络界面：\n**5．**Accounts\n大家千万别小看Accounts模块，虽然它的账户安全界面有些简陋，只有一个用于创建账户的按钮，但只要点击进入某个用户的管理界面中，马上会发现“别有洞天”——账户管理界面，这个界面中的功能非常丰富，我们在这里可以对用户进行重命名，设置用户的权限，还可以锁定、修改密码以及创建SSH密钥信息。\n账户安全界面：\n账户管理界面：\n6．Services\n在Services功能模块的界面中，可以查看系统中已有的服务列表和运行状态。单击某一服务，进入该服务的管理界面后，可以对具体的服务进行开启、关闭操作。在Services功能模块中设置了服务并将其加入到开机启动项后，在系统重启后也依然会为用户提供服务。\n服务程序界面：\n服务管理界面：\n7．Applications\n后期采用Cockpit或红帽订阅服务安装的软件都会显示在这个功能模块中。\n软件仓库界面：\n8．Diagnostic Report\nDiagnostic Report模块的功能是帮助用户收集及分析系统的信息，找到系统出现问题的原因。单击Create Report按钮后大约两分钟左右，会出现报告生成完毕的弹窗。好吧，摊牌了，这个功能其实很鸡肋，就是将sosreport命令做成了一个网页按钮。\n报告分析界面：\n报告生成完毕：\n9．Kernel Dump\nKernel Dump（Kdump）是一个在系统崩溃、死锁或死机时用来收集内核参数的一个服务。举例来说，如果有一天系统崩溃了，这时Kdump服务就会开始工作，将系统的运行状态和内核数据收集到一个名为dump core的文件中，以便后续让运维人员分析并找出问题所在。由于我们在安装系统时没有启动该服务，所以可以等到后续使用时再开启该功能界面。\n内核排错界面：\n10．SElinux\n下图所示为SELinux服务的控制按钮和警告信息界面。\nSElinux管理界面：\n11．Software Updates\n这里提到的Software Updates并不是我们用来更新其他常规软件的一个界面，而是用来对红帽客户订阅的服务进行更新的界面。用户只有在购买了红帽第三方服务后才能使用这里面的功能。在购买了红帽订阅服务后，用户便可以在这里下载到相应服务程序的最新版本和稳定版本。\n更新软件界面：\n12．Subscriptions\n这里依然是一则红帽公司的“小广告”—如果想成为尊贵的红帽服务用户，要付费购买订阅服务。个人用户无须购买，而且这对我们的后续实验没有任何影响。\n订阅服务界面：\n12．Terminal\n压轴的总是在最后。Cockpit服务提供了Shell终端的在线控制平台，可方便用户通过网页上的终端功能管理服务器。这个功能深受运维人员喜爱。\n终端管理界面\n至此，相信各位读者已经充分掌握了防火墙的管理能力。防火墙管理工具有很多种，我们任选其一即可。在配置后续的服务前，大家要记得检查网络和防火墙的状态，以避免出现服务明明配置正确，但无法从外部访问的情况，最终影响实验效果。\n在 Ubuntu 上使用 UFW\u0026amp;GUFW Ubuntu 20.04 随附了一个称为UFW（非复杂防火墙）的防火墙配置工具。 它是用于管理iptables防火墙规则的用户友好型前端。 它的主要目标是使防火墙的管理变得更容易，或者顾名思义，变得简单。而GUFW是UFW的图形介面。\n检查UFW状态 UFW默认情况下处于禁用状态。 您可以使用以下命令检查UFW服务的状态：\n$ sudo ufw status verbose 输出将显示防火墙状态为非活动：\nStatus: inactive 如果UFW已激活，则输出将类似于以下内容：\nStatus: active UFW默认策略 UFW防火墙的默认行为是阻止所有传入和转发流量，并允许所有出站流量。 这意味着除非您专门打开端口，否则任何尝试访问您的服务器的人都将无法连接。 服务器上运行的应用程序和服务将可以访问外界。\n默认策略在/etc/default/ufw文件中定义，可以通过手动修改文件或使用sudo ufw default \u0026lt;policy\u0026gt; \u0026lt;chain\u0026gt;命令来更改。\n防火墙策略是建立更复杂和用户定义的规则的基础。 通常，最初的UFW默认策略是一个很好的起点。\n应用配置文件 应用程序配置文件是INI格式的文本文件，描述了服务并包含该服务的防火墙规则。 在安装软件包期间，会在/etc/ufw/applications.d目录中创建应用程序配置文件。\n您可以通过键入以下内容列出服务器上所有可用的应用程序配置文件：\n$ sudo ufw app list Available applications: Nginx Full Nginx HTTP Nginx HTTPS OpenSSH 要查找有关特定配置文件和包含的规则的更多信息，请使用以下命令：\n$ sudo ufw app info \u0026#39;Nginx Full\u0026#39; Profile: Nginx Full Title: Web Server (Nginx, HTTP + HTTPS) Description: Small, but very powerful and efficient web server Ports: 80,443/tcp 输出显示“ Nginx Full”配置文件打开了端口80和443。\n您也可以为应用创建自定义配置文件。\n启用UFW 如果要从远程位置连接到Ubuntu，则在启用UFW防火墙之前，必须明确允许传入的SSH连接。 否则，您将无法连接到计算机。\n要将您的UFW防火墙配置为允许传入的SSH连接，请键入以下命令：\n$ sudo ufw allow ssh Rules updated Rules updated (v6) 如果SSH在非标准端口上运行，则需要打开该端口。\n例如，如果您的ssh守护程序侦听端口7722，请输入以下命令以允许该端口上的连接：\n$ sudo ufw allow 7722/tcp 现在已将防火墙配置为允许传入的SSH连接，您可以通过键入以下内容来启用它：\n$ sudo ufw enable Command may disrupt existing ssh connections. Proceed with operation (y|n)? y Firewall is active and enabled on system startup 将警告您启用防火墙可能会破坏现有的ssh连接，只需键入y并单击Enter。\n打开端口 根据系统上运行的应用程序，您可能还需要打开其他端口。 打开端口的一般语法如下：\n$ ufw allow port_number/protocol 以下是有关如何允许HTTP连接的几种方法。\n第一种选择是使用服务名称。 UFW检查/etc/services文件中指定服务的端口和协议：\n$ sudo ufw allow http 您还可以指定端口号和协议：\n$ sudo ufw allow 80/tcp 如果未给出协议，则UFW会同时为tcp和udp创建规则。\n另一个选择是使用应用程序配置文件； 在这种情况下，“ Nginx HTTP”：\n$ sudo ufw allow \u0026#39;Nginx HTTP\u0026#39; UFW还支持使用proto关键字指定协议的另一种语法：\n$ sudo ufw allow proto tcp to any port 80 端口范围\nUFW还允许您打开端口范围。 起始端口和结束端口用冒号（:）分隔，并且您必须指定协议tcp或udp。\n例如，如果要同时在tcp和udp上允许端口从7100到7200，则可以运行以下命令：\n$ sudo ufw allow 7100:7200/tcp 特定的IP地址和端口\n要允许来自给定源IP的所有端口上的连接，请使用from关键字，后跟源地址。\n以下是将IP地址列入白名单的示例：\n$ sudo ufw allow from 64.63.62.61 如果要仅允许给定IP地址访问特定端口，请使用to any port关键字，后跟端口号。\n例如，要允许IP地址为64.63.62.61的计算机访问端口22，请输入：\n$ sudo ufw allow from 64.63.62.61 to any port 22 子网\n允许连接到IP地址子网的语法与使用单个IP地址时的语法相同。 唯一的区别是您需要指定子网掩码。\n下面是一个示例，显示了如何允许访问从192.168.1.1到192.168.1.254的IP地址到端口3360（MySQL ）：\n$ sudo ufw allow from 192.168.1.0/24 to any port 3306 特定网络接口\n要允许在特定的网络接口上进行连接，请使用in on关键字，后跟网络接口(网卡)的名称：\n$ sudo ufw allow in on eth2 to any port 3306 拒绝连接 所有传入连接的默认策略均设置为deny，如果您未更改默认策略，除非您专门打开连接，否则UFW会阻止所有传入连接。\n撰写拒绝规则与撰写允许规则相同； 您只需要使用deny关键字而不是allow。\n假设您打开了端口80和443，并且服务器受到23.24.25.0/24网络的攻击。 要拒绝来自23.24.25.0/24的所有连接，您可以运行以下命令：\n$ sudo ufw deny from 23.24.25.0/24 以下是拒绝访问23.24.25.0/24中的端口80和443的示例，您可以使用以下命令：\n$ sudo ufw deny proto tcp from 23.24.25.0/24 to any port 80,443 删除UFW规则 有两种方法可以通过规则编号和指定实际规则来删除UFW规则。\n按规则号删除规则比较容易，尤其是当您不熟悉UFW时。 要首先通过规则编号删除规则，您需要找到要删除的规则的编号。 要获取编号规则的列表，请使用ufw status numbered命令：\n$ sudo ufw status numbered Status: active To Action From -- ------ ---- [ 1] 22/tcp ALLOW IN Anywhere [ 2] 80/tcp ALLOW IN Anywhere [ 3] 8080/tcp ALLOW IN Anywhere 要删除规则号3，该规则号允许连接到端口8080，请输入：\n$ sudo ufw delete 3 第二种方法是通过指定实际规则来删除规则。 例如，如果您添加了打开端口8069的规则，则可以使用以下命令将其删除：\n$ sudo ufw delete allow 8069 禁用UFW 如果出于任何原因要停止UFW并停用所有规则，则可以使用：\n$ sudo ufw disable 以后，如果您想重新启用UTF并激活所有规则，只需键入：\n$ sudo ufw enable 重设UFW 重置UFW将禁用UFW，并删除所有活动规则。 如果您想还原所有更改并重新开始，这将很有帮助。\n要重置UFW，请输入以下命令：\n$ sudo ufw reset IP伪装 IP伪装是Linux内核中NAT（网络地址转换）的一种变体，它通过重写源IP地址和目标IP地址和端口来转换网络流量。 借助IP伪装，您可以使用一台充当网关的Linux计算机，允许专用网络中的一台或多台计算机与Internet通信。\n使用UFW配置IP伪装涉及几个步骤。\n首先，您需要启用IP转发。 为此，请打开/etc/ufw/sysctl.conf文件，查找并取消注释以下行：net.ipv4.ip_forward = 1：\n$ sudo nano /etc/ufw/sysctl.conf net/ipv4/ip_forward=1 接下来，您需要配置UFW以允许转发数据包。 打开UFW配置文件，找到DEFAULT_FORWARD_POLICY键，然后将值从DROP更改为ACCEPT：\n$ sudo nano /etc/default/ufw DEFAULT_FORWARD_POLICY=\u0026#34;ACCEPT\u0026#34; 现在，您需要在nat表中设置POSTROUTING链的默认策略和伪装规则。 为此，请打开/etc/ufw/before.rules文件，附加以下几行：\n$ sudo nano /etc/ufw/before.rules #NAT table rules *nat :POSTROUTING ACCEPT [0:0] # Forward traffic through eth0 - Change to public network interface -A POSTROUTING -s 10.8.0.0/16 -o eth0 -j MASQUERADE # don\u0026#39;t delete the \u0026#39;COMMIT\u0026#39; line or these rules won\u0026#39;t be processed COMMIT 别忘了在-A POSTROUTING行中替换eth0以匹配公共网络接口的名称：\n完成后，保存并关闭文件。\n最后，通过禁用和重新启用UFW重新加载UFW规则：\n$ sudo ufw disable $ sudo ufw e udev 如果你使用Linux比较长时间了，那你就知道，在对待设备文件这块，Linux改变了几次策略。在Linux早期，设备文件仅仅是是一些带有适当的属性集的普通文件，它由mknod命令创建，文件存放在/dev目录下。后来，采用了devfs, 一个基于内核的动态设备文件系统，他首次出现在2.3.46内核中。Mandrake，Gentoo等Linux分发版本采用了这种方式。devfs创建 的设备文件是动态的。但是devfs有一些严重的限制，从2.6.13版本后移走了。目前取代他的便是文本要提到的udev－－一个用户空间程序。\n目前很多的Linux分发版本采纳了udev的方式，因为它在Linux设备访问，特别是那些对设备有极端需求的站点(比如需要控制上千个硬盘)和热插拔设备(比如USB摄像头和MP3播放器)上解决了几个问题。下面我我们来看看如何管理udev设备。\n实际上，对于那些为磁盘，终端设备等准备的标准配置文件而言，你不需要修改什么。但是，你需要了解udev配置来使用新的或者外来设备，如果不修改配置， 这些设备可能无法访问，或者说Linux可能会采用不恰当的名字，属组或权限来创建这些设备文件。你可能也想知道如何修改RS－232串口，音频设备等文件的属组或者权限。这点在实际的Linux实施中是会遇到的。\n为什么使用udev 在此之前的设备文件管理方法(静态文件和devfs)有几个缺点：\n 不确定的设备映射。特别是那些动态设备，比如USB设备，设备文件到实际设备的映射并不可靠和确定。举一个例子：如果你有两个USB打印机。一个可能称 为/dev/usb/lp0,另外一个便是/dev/usb/lp1。但是到底哪个是哪个并不清楚，lp0,lp1和实际的设备没有一一对应的关系，因为 他可能因为发现设备的顺序，打印机本身关闭等原因而导致这种映射并不确定。理想的方式应该是：两个打印机应该采用基于他们的序列号或者其他标识信息的唯一 设备文件来映射。但是静态文件和devfs都无法做到这点。 没有足够的主/辅设备号。我们知道，每一个设备文件是有两个8位的数字：一个是主设备号 ，另外一个是辅设备号来分配的。这两个8位的数字加上设备类型(块设备或者字符设备)来唯一标识一个设备。不幸的是，关联这些身边的的数字并不足够。 /dev目录下文件太多。一个系统采用静态设备文件关联的方式，那么这个目录下的文件必然是足够多。而同时你又不知道在你的系统上到底有那些设备文件是激活的。 命名不够灵活。尽管devfs解决了以前的一些问题，但是它自身又带来了一些问题。其中一个就是命名不够灵活；你别想非常简单的就能修改设备文件的名字。缺省的devfs命令机制本身也很奇怪，他需要修改大量的配置文件和程序。 内核内存使用，devfs特有的另外一个问题是，作为内核驱动模块，devfs需要消耗大量的内存，特别当系统上有大量的设备时(比如上面我们提到的系统一个上有好几千磁盘时)  udev的目标是想解决上面提到的这些问题，他通采用用户空间(user-space)工具来管理/dev/目录树，他和文件系统分开。知道如何改变缺省配置能让你之大如何定制自己的系统，比如创建设备字符连接，改变设备文件属组，权限等。\nudev配置文件 主要的udev配置文件是/etc/udev/udev.conf。这个文件通常很短，他可能只是包含几行#开头的注释，然后有几行选项：\nudev_root=“/dev/” udev_rules=“/etc/udev/rules.d/” udev_log=“err“ 上面的第二行非常重要，因为他表示udev规则存储的目录，这个目录存储的是以.rules结束的文件。每一个文件处理一系列规则来帮助udev分配名字给设备文件以保证能被内核识别。\n你的/etc/udev/rules.d下面可能有好几个udev规则文件，这些文件一部分是udev包安装的，另外一部分则是可能是别的硬件或者软件包 生成的。比如在Fedora Core 5系统上，sane-backends包就会安装60-libsane.rules文件，另外initscripts包会安装60-net.rules文 件。这些规则文件的文件名通常是两个数字开头，它表示系统应用该规则的顺序。\n规则文件里的规则有一系列的键/值对组成，键/值对之间用逗号(,)分割。每一个键或者是用户匹配键，或者是一个赋值键。匹配键确定规则是否被应用，而赋 值键表示分配某值给该键。这些值将影响udev创建的设备文件。匹配键和赋值键操作符解释见下表：\n   操作符 匹配或赋值 解释     == 匹配 相等比较   != 匹配 不等比较   = 赋值 分配一个特定的值给该键，他可以覆盖之前的赋值。   += 赋值 追加特定的值给已经存在的键   := 赋值 分配一个特定的值给该键，后面的规则不可能覆盖它。    这有点类似我们常见的编程语言，比如C语言。只是这里的键一次可以处理多个值。有一些键在udev规则文件里经常出现，这些键的值可以使用通配符(*,?,甚至范围，比如[0-9])，这些常用键列举如下：\n   键 含义     ACTION 一个时间活动的名字，比如add，当设备增加的时候   KERNEL 在内核里看到的设备名字，比如sd*表示任意SCSI磁盘设备   DEVPATH 内核设备路径，比如/devices/*   SUBSYSTEM 子系统名字，比如sound,net   BUS 总线的名字，比如IDE,USB   DRIVER 设备驱动的名字，比如ide-cdromID 独立于内核名字的设备名字   SYSFS{ value} sysfs属性值，他可以表示任意   ENV{ key} 环境变量，可以表示任意   PROGRAM 可执行的外部程序，如果程序返回0值，该键则认为为真(true)   RESULT 上一个PROGRAM调用返回的标准输出。   NAME 根据这个规则创建的设备文件的文件名。注意：仅仅第一行的NAME描述是有效的，后面的均忽略。 如果你想使用使用两个以上的名字来访问一个设备的话，可以考虑SYMLINK键。   SYMLINK 根据规则创建的字符连接名   OWNER 设备文件的属组   GROUP 设备文件所在的组。   MODE 设备文件的权限，采用8进制   RUN 为设备而执行的程序列表   LABEL 在配置文件里为内部控制而采用的名字标签(下下面的GOTO服务)   GOTO 跳到匹配的规则（通过LABEL来标识），有点类似程序语言中的GOTO   IMPORT{ type} 导入一个文件或者一个程序执行后而生成的规则集到当前文件   WAIT_FOR_SYSFS 等待一个特定的设备文件的创建。主要是用作时序和依赖问题。   PTIONS 特定的选项： last_rule 对这类设备终端规则执行； ignore_device 忽略当前规则； ignore_remove 忽略接下来的并移走请求。all_partitions 为所有的磁盘分区创建设备文件。    我们给出一个列子来解释如何使用这些键。下面的例子来自Fedora Core 5系统的标准配置文件。\nKERNEL==\u0026#34;*\u0026#34;, OWNER=\u0026#34;root\u0026#34; GROUP=\u0026#34;root\u0026#34;, MODE=\u0026#34;0600\u0026#34; KERNEL==\u0026#34;tty\u0026#34;, NAME=\u0026#34;%k\u0026#34;, GROUP=\u0026#34;tty\u0026#34;, MODE=\u0026#34;0666\u0026#34;, OPTIONS=\u0026#34;last_rule\u0026#34; KERNEL==\u0026#34;scd[0-9]*\u0026#34;, SYMLINK+=\u0026#34;cdrom cdrom-%k\u0026#34; KERNEL==\u0026#34;hd[a-z]\u0026#34;, BUS==\u0026#34;ide\u0026#34;, SYSFS{removable}==\u0026#34;1\u0026#34;, SYSFS{device/media}==\u0026#34;cdrom\u0026#34;, SYMLINK+=\u0026#34;cdrom cdrom-%k\u0026#34; ACTION==\u0026#34;add\u0026#34;, SUBSYSTEM==\u0026#34;scsi_device\u0026#34;, RUN+=\u0026#34;/sbin/modprobe sg\u0026#34; 上面的例子给出了5个规则，每一个都是KERNEL或者ACTION键开头：\n 第一个规则是缺省的，他匹配任意被内核识别到的设备，然后设定这些设备的属组是root，组是root，访问权限模式是0600(-rw——-)。这也是一个安全的缺省设置保证所有的设备在默认情况下只有root可以读写 第二个规则也是比较典型的规则了。它匹配终端设备(tty)，然后设置新的权限为0600，所在的组是tty。它也设置了一个特别的设备文件名:%K。在这里例子里，%k代表设备的内核名字。那也就意味着内核识别出这些设备是什么名字，就创建什么样的设备文件名。 第三行开始的KERNEL==”scd[0-9]*”,表示 SCSI CD-ROM 驱动. 它创建一对设备符号连接：cdrom和cdrom-%k。 第四行，开始的 KERNEL==”hd[a-z]“, 表示ATA CDROM驱动器。这个规则创建和上面的规则相同的符号连接。ATA CDROM驱动器需要sysfs值以来区别别的ATA设备，因为SCSI CDROM可以被内核唯一识别。. 第五行以 ACTION==”add”开始，它告诉udev增加 /sbin/modprobe sg 到命令列表，当任意SCSI设备增加到系统后，这些命令将执行。其效果就是计算机应该会增加sg内核模块来侦测新的SCSI设备。  当然，上面仅仅是一小部分例子，如果你的系统采用了udev方式，那你应该可以看到更多的规则。如果你想修改设备的权限或者创建信的符号连接，那么你需要熟读这些规则，特别是要仔细注意你修改的那些与之相关的设备。\n修改你的udev配置 在修改udev配置之前，我们一定要仔细，通常的考虑是：你最好不要修改系统预置的那些规则，特别不要指定影响非常广泛的配置，比如上面例子中的第一行。不正确的配置可能会导致严重的系统问题或者系统根本就无法这个正确的访问设备。\n而我们正确的做法应该是在/etc/udev/rules.d/下创建一个新的规则文件。确定你给出的文件的后缀是rules文件名给出的数字序列应该比标准配置文件高。比如，你可以创建一个名为99-my-udev.rules的规则文件。在你的规则文件中，你可以指定任何你想修改的配置，比如，假设你 修改修改floppy设备的所在组，还准备创建一个新的符号连接/dev/floppy，那你可以这么写：\nKERNEL==”fd[0-9]*“, GROUP=“users“, SYMLINK+=“floppy“ 有些发行版本，比如Fedora，采用了外部脚本来修改某些特定设备的属组，组关系和权限。因此上面的改动可能并不见得生效。如果你遇到了这个问题，你就需要跟踪和修改这个脚本来达到你的目的。或者你可以修改PROGRAM或RUN键的值来做到这点。\n某些规则的修改可能需要更深的挖掘。比如，你可能想在一个设备上使用sysfs信息来唯一标识一个设备。这些信息最好通过udevinfo命令来获取。\n$ udevinfo –a –p $(udevinfo –q path –n /dev/hda) 上面的命令两次使用udevinfo：一次是返回sysfs设备路径(他通常和我们看到的Linux设备文件名所在路径－－/dev/hda－－不同)；第 二次才是查询这个设备路径，结果将是非常常的syfs信息汇总。你可以找到最够的信息来唯一标志你的设备，你可以采用适当的替换udev配置文件中的 SYSFS选项。下面的结果就是上面的命令输出\n[root@localhost rules.d]# udevinfo -a -p $(udevinfo -q path -n /dev/hda1) Udevinfo starts with the device specified by the devpath and then walks up the chain of parent devices. It prints for every device found,all possible attributes in the udev rules key format. A rule to match, can be composed by the attributes of the device and the attributes from one single parent device. looking at device \u0026#39;/block/hda/hda1\u0026#39;: KERNEL==\u0026#34;hda1\u0026#34; SUBSYSTEM==\u0026#34;block\u0026#34; DRIVER==\u0026#34;\u0026#34; ATTR{stat}==\u0026#34; 1133 2268 2 4\u0026#34; ATTR{size}==\u0026#34;208782\u0026#34; ATTR{start}==\u0026#34;63\u0026#34; ATTR{dev}==\u0026#34;3:1\u0026#34; looking at parent device \u0026#39;/block/hda\u0026#39;: KERNELS==\u0026#34;hda\u0026#34; SUBSYSTEMS==\u0026#34;block\u0026#34; DRIVERS==\u0026#34;\u0026#34; ATTRS{stat}==\u0026#34;28905 18814 1234781 302540 34087 133247 849708 981336 0 218340 1283968\u0026#34; ATTRS{size}==\u0026#34;117210240\u0026#34; ATTRS{removable}==\u0026#34;0\u0026#34; ATTRS{range}==\u0026#34;64\u0026#34; ATTRS{dev}==\u0026#34;3:0\u0026#34; looking at parent device \u0026#39;/devices/pci0000:00/0000:00:1f.1/ide0/0.0\u0026#39;: KERNELS==\u0026#34;0.0\u0026#34; SUBSYSTEMS==\u0026#34;ide\u0026#34; DRIVERS==\u0026#34;ide-disk\u0026#34; ATTRS{modalias}==\u0026#34;ide:m-disk\u0026#34; ATTRS{drivename}==\u0026#34;hda\u0026#34; ATTRS{media}==\u0026#34;disk\u0026#34; looking at parent device \u0026#39;/devices/pci0000:00/0000:00:1f.1/ide0\u0026#39;: KERNELS==\u0026#34;ide0\u0026#34; SUBSYSTEMS==\u0026#34;\u0026#34; DRIVERS==\u0026#34;\u0026#34; looking at parent device \u0026#39;/devices/pci0000:00/0000:00:1f.1\u0026#39;: KERNELS==\u0026#34;0000:00:1f.1\u0026#34; SUBSYSTEMS==\u0026#34;pci\u0026#34; DRIVERS==\u0026#34;PIIX_IDE\u0026#34; ATTRS{broken_parity_status}==\u0026#34;0\u0026#34; ATTRS{enable}==\u0026#34;1\u0026#34; ATTRS{modalias}==\u0026#34;pci:v00008086d000024CAsv0000144Dsd0000C009bc01sc01i8a\u0026#34; ATTRS{local_cpus}==\u0026#34;1\u0026#34; ATTRS{irq}==\u0026#34;11\u0026#34; ATTRS{class}==\u0026#34;0x01018a\u0026#34; ATTRS{subsystem_device}==\u0026#34;0xc009\u0026#34; ATTRS{subsystem_vendor}==\u0026#34;0x144d\u0026#34; ATTRS{device}==\u0026#34;0x24ca\u0026#34; ATTRS{vendor}==\u0026#34;0x8086\u0026#34; looking at parent device \u0026#39;/devices/pci0000:00\u0026#39;: KERNELS==\u0026#34;pci0000:00\u0026#34; SUBSYSTEMS==\u0026#34;\u0026#34; DRIVERS==\u0026#34;\u0026#34; 举一个例子：假设你想修改USB扫描仪的配置。通过一系列的尝试，你已经为这个扫描仪标识了Linux设备文件(每次打开扫描仪时，名字都会变)。你可以使 用上面的命令替换这个正确的Linux设备文件名，然后定位输出的采用SYSFS{idVendor}行和SYSFS{idProduct}行。最后你可 以使用这些信息来为这个扫描仪创建新的选项。\nSYSFS{idVendor}==\u0026#34;0686\u0026#34;, SYSFS{idProduct}==\u0026#34;400e\u0026#34;, SYMLINK+=\u0026#34;scanner\u0026#34;, MODE=\u0026#34;0664\u0026#34;, group=\u0026#34;scanner\u0026#34; 上面的例子表示将扫描仪的组设置为scanner，访问权限设置为0664,同时创建一个/dev/scanner的符号连接。\nMounting usb automatically \u0026amp; having usb\u0026rsquo;s label as mountpoint Note for Ubuntu Server 11.10: This script fails on Ubuntu Server 11.10 due to the obsolete vol_id command. vol_id has been superseded by blkid. To fix the script, replace \u0026ldquo;vol_id\u0026rdquo; by \u0026ldquo;blkid -o udev\u0026rdquo; in the udev-auto-mount.sh script.\nI\u0026rsquo;ve been banging my head around this for a while now, and I think I\u0026rsquo;ve found a working solution. This is developed and tested on a Debian-based system, so it should work on Ubuntu. I\u0026rsquo;ll point out the assumptions it makes so it can be adapted to other systems as well.\n It will automatically mount USB drives on plugin, and shouldn\u0026rsquo;t take much to adapt for Firewire. It uses UDEV, so no monkeying with HAL/DeviceKit/GNOME-Anything. It automagically creates a /media/LABEL directory to mount the device to. However, it may interfere with other automounters; I can\u0026rsquo;t test for that. I expect that, with Gnome-VFS active, both may try to do the mount \u0026hellip; if Gnome-VFS fails the mount, it might not configure a desktop icon. Unmounting from Gnome should be possible, but might require gksudo or similar.  I have not tested this on system boot, but the only reason I can see that it might not work is if it tries to mount the USB drive before the system is ready for mounts. If that\u0026rsquo;s the case, you\u0026rsquo;ll probably need one additional tweak to the mount script. (I\u0026rsquo;m checking with ServerFault to see if there\u0026rsquo;s any advice, but not much interest in it over there.)\nOn to it, then.\nUDEV references  Writing udev Rules (the reference for udev rules) man udev (see your system for the latest version) man udevadm (udev admin tool; again see your system for latest) Backup to USB drive on mount (completely different problem, but helpful for understanding the solution)  Background (UDEV? Whuzzat?) UDEV is the kernel\u0026rsquo;s hotplug system. It\u0026rsquo;s what automagically configures the proper devices and device symlinks (eg /dev/disk/by-label/\u0026lt;LABEL\u0026gt;), both at boot time and for devices added while the system is running.\nD-Bus and HAL are used for sending hardware events to listeners like Desktop Environments. So when you log into GNOME and insert a CD or plug in a USB drive, that event follows this chain:\nkernel -\u0026gt; udev -\u0026gt; dbus -\u0026gt; hal -\u0026gt; gnome-vfs/nautilus (mount) And presto, your drive gets mounted. But in a headless system, we don\u0026rsquo;t want to have to log in to get the benefits of automounting.\nUdev Rules Since UDEV lets us write rules and run programs on device insertion, this is an ideal choice. We\u0026rsquo;re going to take advantage of Debian/Ubuntu\u0026rsquo;s existing rules, let them setup the /dev/disk/by-label/\u0026lt;LABEL\u0026gt; symlink for us, and add another rule that will mount the device for us.\nUDEV\u0026rsquo;s rules are kept in /etc/udev/rules.d (and /lib/udev/rules.d on Karmic), and are processed in numerical order. Any file not starting with a number gets processed after the numbered files. On my system, HAL rules are in a file called 90-hal.rules, so I put my rules in 89-local.rules so they get processed before they get to HAL. Primarily, you need to make sure these rules happen after the 60-persistent-storage.rules. local.rules may be good enough.\nPut this in your new rules file:\n# /etc/udev/rules.d/local.rules # /etc/udev/rules.d/89-local.rules # ADD rule: if we have a valid ID_FS_LABEL_ENC, and it's USB, mkdir and mount ENV{ID_FS_LABEL_ENC}==\u0026quot;?*\u0026quot;, ACTION==\u0026quot;add\u0026quot;, SUBSYSTEMS==\u0026quot;usb\u0026quot;, \\ RUN+=\u0026quot;/usr/local/sbin/udev-automounter.sh %k\u0026quot;  Make sure there\u0026rsquo;s no spaces after the \\, just a newline (\\n). Change SUBSYSTEMS==\u0026quot;usb\u0026quot; to SUBSYSTEMS==\u0026quot;usb|ieee1394\u0026quot; for Firewire support. If you want the device to always be owned by a particular user, add an OWNER=\u0026quot;username\u0026quot; clause. If you just need the files owned by a particular user, tweak the mount script instead.  Reading the Rule\nThis adds a program to run to the device\u0026rsquo;s list of programs to run. It identifies USB partition devices by \u0026lt;LABEL\u0026gt;, then passes this information to a script that performs the mount. Specifically, this rule is matching:\n  ENV{ID_FS_LABEL_ENC}==\u0026quot;?\\*\u0026quot; \u0026ndash; an environment variable set by an earlier system rule. Doesn\u0026rsquo;t exist for non-filesystems, so that\u0026rsquo;s why we check for it. We actually want to use ID_FS_LABEL for the mount point, but I haven\u0026rsquo;t convinced UDEV to escape it for me, so we\u0026rsquo;ll let the mount script handle that.\nThis and other environment variables are obtained by udev using the vol_id command (deprecated). It\u0026rsquo;s a handy tool to see nice quick details on a partition:\n$ sudo vol_id /dev/sdc1 ID_FS_TYPE=ext2 ID_FS_UUID=a40d282a-4a24-4593-a0ab-6f2600f920dd ID_FS_LABEL=Travel Dawgs ID_FS_LABEL_ENC=Travel\\x20Dawgs ID_FS_LABEL_SAFE=Travel_Dawgs   ACTION==\u0026quot;add\u0026quot; \u0026ndash; only match add events\u0026hellip;\n  SUBSYSTEMS==\u0026quot;usb\u0026quot; \u0026ndash; only match devices that are on the USB bus. We use SUBSYSTEMS here because this matches against our device\u0026rsquo;s parents; the device we\u0026rsquo;re interested in will actually be SUBSYSTEM==\u0026ldquo;scsi\u0026rdquo;. Matching against a parent USB device avoids adding our program to the internal drives.\n  RUN+=\u0026quot;...\u0026quot; \u0026ndash; not a match, but an action: add this program to the list of programs to run. In the program\u0026rsquo;s arguments, %k gets expanded to the device name (eg sdc1, not /dev/sdc1) and $env{FOO} gets the contents of environment variable FOO.\n  Testing the Rule\nThe first reference link (above) is an excellent UDEV tutorial, but it\u0026rsquo;s slightly out of date. The programs it runs for testing your rules (udevtest in particular) have been replaced by the catch-all udevadm utility.\nAfter you\u0026rsquo;ve added the rule, plug in your device. Give it a few seconds, then check to see what device it\u0026rsquo;s been assigned to with:\n$ ls -l /dev/disk/by-label/* lrwxrwxrwx 1 root root 10 2009-10-25 07:27 label_Foo -\u0026gt; ../../sda1 lrwxrwxrwx 1 root root 10 2009-10-25 07:27 label_Bar -\u0026gt; ../../sdb1 lrwxrwxrwx 1 root root 10 2009-10-25 07:27 label_Baz -\u0026gt; ../../sdc1 If your removeable drive contains label_Baz, it\u0026rsquo;s on device sdc1. Run this and look at the output towards the end:\n$ sudo udevadm test /sys/block/sdc/sdc1 parse_file: reading (...) (many lines about files it reads) import_uevent_var: import into environment: (...) (many lines about env variables) (...) (many lines tracing rule matches \u0026amp; programs run) update_link: found 1 devices with name 'disk/by-label/LABEL_BAZ' update_link: found '/block/sdc/sdc1' for 'disk/by-label/LABEL_BAZ' update_link: compare (our own) priority of '/block/sdc/sdc1' 0 \u0026gt;= 0 update_link: 'disk/by-label/LABEL_BAZ' with target 'sdc1' has the highest priority 0, create it udevtest: run: '/usr/local/sbin/udev-automounter.sh sdc1 LABEL_BAZ' udevtest: run: 'socket:/org/freedesktop/hal/udev_event' udevtest: run: 'socket:@/org/kernel/udev/monitor' Look for the script name from our RUN+= rule in the last few lines (3rd from the bottom in this example). You can see the arguments that would be used for this device. You can run that command now to check that the arguments are sound; if it works on your commandline, it should work automatically when a device is inserted.\nYou can also monitor UDEV events in realtime: run sudo udevadm monitor (see man udevadm for details on the switches). Then just plug in a new device and watch events scroll by. (Probably overkill unless you\u0026rsquo;re into really low-level details\u0026hellip;)\nReloading the Rules\nOnce you\u0026rsquo;ve verified the rule is getting read properly, you need to tell UDEV to reload its rules so the new one takes effect. Use any of these methods (if the first doesn\u0026rsquo;t work, the second should\u0026hellip; but try the first first):\n run sudo udevadm control --reload-rules run sudo /etc/init.d/udev reload reboot  Script! Actually, 2 Scripts\u0026hellip; Here\u0026rsquo;s the first script. Since the program we run needs to complete quickly, this just spins the second script off in the background. Put this in /usr/local/sbin/udev-automounter.sh:\n#!/bin/sh # # USAGE: usb-automounter.sh DEVICE # DEVICE is the actual device node at /dev/DEVICE /usr/local/sbin/udev-auto-mount.sh ${1} \u0026amp; Here\u0026rsquo;s the second script. This does a bit more input checking. Put this in /usr/local/sbin/udev-auto-mount.sh. You may want to tweak the mount options below. This script now handles finding the partition LABEL on its own; UDEV only sends the DEVICE name.\nIf there\u0026rsquo;s a problem mounting drives at boot-time, you can put a nice long sleep 60 in this script, to give the system time to come all the way up before the script attempts to mount the drive.\nI\u0026rsquo;ve given a suggestion in the comments for how to check (run ps to see if a webserver is running), but you\u0026rsquo;ll want to tweak that for your system. I think most any network servers you might be using would suffice for this purpose \u0026ndash; nfsd, smbd, apache, etc. The risk, of course, is that the mount script will fail if the service isn\u0026rsquo;t running, so maybe testing a particular file\u0026rsquo;s existence would be a better solution.\n#!/bin/sh # # USAGE: udev-auto-mount.sh DEVICE # DEVICE is the actual device node at /dev/DEVICE # # This script takes a device name, looks up the partition label and # type, creates /media/LABEL and mounts the partition. Mount options # are hard-coded below. DEVICE=$1 # check input if [ -z \u0026quot;$DEVICE\u0026quot; ]; then exit 1 fi # test that this device isn't already mounted device_is_mounted=`grep ${DEVICE} /etc/mtab` if [ -n \u0026quot;$device_is_mounted\u0026quot; ]; then echo \u0026quot;error: seems /dev/${DEVICE} is already mounted\u0026quot; exit 1 fi # If there's a problem at boot-time, this is where we'd put # some test to check that we're booting, and then run # sleep 60 # so the system is ready for the mount below. # # An example to experiment with: # Assume the system is \u0026quot;booted enough\u0026quot; if the HTTPD server is running. # If it isn't, sleep for half a minute before checking again. # # The risk: if the server fails for some reason, this mount script # will just keep waiting for it to show up. A better solution would # be to check for some file that exists after the boot process is complete. # # HTTPD_UP=`ps -ax | grep httpd | grep -v grep` # while [ -z \u0026quot;$HTTPD_UP\u0026quot; ]; do # sleep 30 # HTTPD_UP=`ps -ax | grep httpd | grep -v grep` # done # pull in useful variables from vol_id, quote everything Just In Case eval `/sbin/vol_id /dev/${DEVICE} | sed 's/^/export /; s/=/=\u0026quot;/; s/$/\u0026quot;/'` if [ -z \u0026quot;$ID_FS_LABEL\u0026quot; ] || [ -z \u0026quot;$ID_FS_TYPE\u0026quot; ]; then echo \u0026quot;error: ID_FS_LABEL is empty! did vol_id break? tried /dev/${DEVICE}\u0026quot; exit 1 fi # test mountpoint - it shouldn't exist if [ ! -e \u0026quot;/media/${ID_FS_LABEL}\u0026quot; ]; then # make the mountpoint mkdir \u0026quot;/media/${ID_FS_LABEL}\u0026quot; # mount the device # # If expecting thumbdrives, you probably want # mount -t auto -o sync,noatime [...] # # If drive is VFAT/NFTS, this mounts the filesystem such that all files # are owned by a std user instead of by root. Change to your user's UID # (listed in /etc/passwd). You may also want \u0026quot;gid=1000\u0026quot; and/or \u0026quot;umask=022\u0026quot;, eg: # mount -t auto -o uid=1000,gid=1000 [...] # # case \u0026quot;$ID_FS_TYPE\u0026quot; in vfat) mount -t vfat -o sync,noatime,uid=1000 /dev/${DEVICE} \u0026quot;/media/${ID_FS_LABEL}\u0026quot; ;; # I like the locale setting for ntfs ntfs) mount -t auto -o sync,noatime,uid=1000,locale=en_US.UTF-8 /dev/${DEVICE} \u0026quot;/media/${ID_FS_LABEL}\u0026quot; ;; # ext2/3/4 don't like uid option ext*) mount -t auto -o sync,noatime /dev/${DEVICE} \u0026quot;/media/${ID_FS_LABEL}\u0026quot; ;; esac # all done here, return successful exit 0 fi exit 1 Super Bonus Cleanup Script! One more script. All this does is unmount the device and remove the mountpoint directories. It assumes it has privs to do this, so you\u0026rsquo;ll need to run it with sudo. This script now takes the full mountpoint on the commandline, eg:\n$ /usr/local/sbin/udev-unmounter.sh \u0026quot;/media/My Random Disk\u0026quot; Put this in /usr/local/sbin/udev-unmounter.sh:\n#!/bin/sh # # USAGE: udev-unmounter.sh MOUNTPT # MOUNTPT is a mountpoint we want to unmount and delete. MOUNTPT=\u0026quot;$1\u0026quot; if [ -z \u0026quot;$MOUNTPT\u0026quot; ]; then exit 1 fi # test mountpoint - it should exist if [ -e \u0026quot;${MOUNTPT}\u0026quot; ]; then # very naive; just run and pray umount -l \u0026quot;${MOUNTPT}\u0026quot; \u0026amp;\u0026amp; rmdir \u0026quot;${MOUNTPT}\u0026quot; \u0026amp;\u0026amp; exit 0 echo \u0026quot;error: ${MOUNTPT} failed to unmount.\u0026quot; exit 1 fi echo \u0026quot;error: ${MOUNTPT} does not exist\u0026quot; exit 1 GPG 前两篇文章，我介绍了RSA算法。\n今天，就接着来看，现实中怎么使用这个算法，对信息加密和解密。这要用到GnuPG软件（简称GPG），它是目前最流行、最好用的加密工具之一。\n什么是GPG 要了解什么是GPG，就要先了解PGP。\n1991年，程序员Phil Zimmermann为了避开政府监视，开发了加密软件PGP。这个软件非常好用，迅速流传开来，成了许多程序员的必备工具。但是，它是商业软件，不能自由使用。所以，自由软件基金会决定，开发一个PGP的替代品，取名为GnuPG。这就是GPG的由来。\nGnuPG 是完整实现了 RFC4880 （即PGP） 所定义的 OpenPGP 标准的自由软件。\nGnuPG 可以加密和签名你的数据和通讯信息，包含一个通用的密钥管理系统以及用于各种公钥目录的访问模块。\nGnuPG 是一个易于与其它程序整合的命令行工具，拥有很多前端程序和函数库。\nGnuPG 还支持 S/MIME 和 Secure Shell (ssh)。\nGPG有许多用途，本文主要介绍文件加密。至于邮件的加密，不同的邮件客户端有不同的设置，请参考Ubuntu网站的介绍。\n本文的使用环境为Linux命令行。如果掌握了命令行，Windows 或 Mac OS 客户端，就非常容易掌握。GPG并不难学，学会了它，从此就能轻松传递加密信息。建议读者一步步跟着教程做，对每条命令都自行测试。\n安装 GPG有两种安装方式。可以下载源码，自己编译安装。\n$ ./configure $ make $ make install 也可以安装编译好的二进制包。\n$ sudo apt-get install gnupg 安装完成后，键入下面的命令：\n$ gpg --help 如果屏幕显示GPG的帮助，就表示安装成功。\n配置 目录位置 GnuPG 用环境变量 $GNUPGHOME 定位配置文件的位置，默认情况下此变量并未被设置，会直接使用 $HOME，所以默认的配置目录是 ~/.gnupg。\n要改变默认位置，执行 $ gpg --homedir path/to/file 或在 startup files 中设置 GNUPGHOME。\n配置文件 默认的配置文件是 ~/.gnupg/gpg.conf 和 ~/.gnupg/dirmngr.conf.\ngnupg 目录的默认 权限 是 700，其中文件的权限是 600. 仅目录的所有者有权读写，访问这些文件。这是基于安全考虑，请不要变更。如果不使用这样的安全权限设置，会收到不安全文件的警告。\n在文件中附加需要的文件：/usr/share/gnupg 包含基本架构文件. gpg，第一次运行时，如果配置文件不存在，会自动复制文件到 ~/.gnupg。\n新用户的默认选项 要给新建用户设定一些默认选项，把配置文件放到 /etc/skel/.gnupg/。系统创建新用户时，就会把文件复制到 GnuPG 目录。还有一个 addgnupghome 命令可以为已有用户创建新 GnuPG 主目录：\n# addgnupghome user1 user2 此命令会将对检查 /home/user1/.gnupg 和 /home/user2/.gnupg，如果用户的 GnuPG 主目录不存在，就会从 skeleton 目录复制文件过去。\n生成密钥 安装成功后，使用 --full-generate-key 参数生成自己的密钥。\n$ gpg --full-generate-key 或用 gpg --gen-key 快速生成。以下使用 gpg2 --full-generate-key 演示。\n回车以后，会跳出一大段文字：\ngpg (GnuPG) 2.2.19; Copyright (C) 2019 Free Software Foundation, Inc. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Please select what kind of key you want: (1) RSA and RSA (default) (2) DSA and Elgamal (3) DSA (sign only) (4) RSA (sign only) (14) Existing key from card Your selection? 第一段是版权声明，然后让用户自己选择加密算法。默认选择第一个选项，表示加密和签名都使用RSA算法。\n然后，系统就会问你密钥的长度。\nRSA keys may be between 1024 and 4096 bits long. What keysize do you want? (3072) 密钥越长越安全。\n接着，设定密钥的有效期。\nPlease specify how long the key should be valid. 0 = key does not expire \u0026lt;n\u0026gt; = key expires in n days \u0026lt;n\u0026gt;w = key expires in n weeks \u0026lt;n\u0026gt;m = key expires in n months \u0026lt;n\u0026gt;y = key expires in n years Key is valid for? (0) 如果密钥只是个人使用，并且你很确定可以有效保管私钥，建议选择第一个选项，即永不过期。回答完上面三个问题以后，系统让你确认。\nIs this correct? (y/N) 输入y，系统就要求你提供个人信息。\nGnuPG needs to construct a user ID to identify your key. Real name: Email address Comment: \u0026ldquo;真实姓名\u0026quot;填入你姓名的英文写法，\u0026ldquo;电子邮件地址\u0026quot;填入你的邮件地址，\u0026ldquo;注释\u0026quot;这一栏可以空着。\n然后，你的\u0026quot;用户ID\u0026quot;生成了。\nYou selected this USER-ID: \u0026#34;Vane Hsiung \u0026lt;1664548605@qq.com\u0026gt;\u0026#34; 系统会让你最后确认一次。\nChange (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? 输入O表示\u0026quot;确定\u0026rdquo;。\n接着，系统会要求你做一些随机的举动，以生成一个随机数。同时系统会让你设定一个私钥的密码。这是为了防止误操作，或者系统被侵入时有人擅自动用私钥。\nWe need to generate a lot of random bytes. It is a good idea to performsome other action (type on the keyboard, move the mouse, utilize thedisks) during the prime generation; this gives the random numbergenerator a better chance to gain enough entropy. 然后，系统就开始生成密钥了，\n几分钟以后，系统提示密钥已经生成了。\ngpg: key B893B73ABC92D2CA marked as ultimately trusted gpg: revocation certificate stored as \u0026#39;\u0026#39;public and secret key created and signed. 请注意上面的字符串\u0026quot;B893B73ABC92D2CA\u0026rdquo;，这是\u0026quot;用户ID\u0026quot;的Hash字符串，可以用来替代\u0026quot;用户ID\u0026rdquo;。\n这时，最好再生成一张\u0026quot;撤销证书\u0026quot;，以备以后密钥作废时，可以请求外部的公钥服务器撤销你的公钥。\n$ gpg --gen-revoke [用户ID] 上面的\u0026quot;用户ID\u0026quot;部分，可以填入你的邮件地址或者Hash字符串（以下同）。\n密钥管理 列出密钥\nlist-keys参数列出系统中已有的密钥．\n$ gpg --list-keys 显示结果如下：\ngpg: checking the trustdb gpg: marginals needed: 3 completes needed: 1 trust model: pgp gpg: depth: 0 valid: 1 signed: 0 trust: 0-, 0q, 0n, 0m, 0f, 1u /home/vane/.gnupg/pubring.kbx ----------------------------- pub rsa3072 2021-10-17 [SC] BC158F7500033355B5324CF14C701F8BF2E03463 uid [ultimate] Vane Hsiung \u0026lt;1664548605@qq.com\u0026gt; sub rsa3072 2021-10-17 [E] 第一行显示公钥文件名（pubring.gpg），第二行显示公钥特征（4096位，Hash字符串和生成时间），第三行显示\u0026quot;用户ID\u0026quot;，第四行显示私钥特征。\n如果你要从密钥列表中删除某个密钥，可以使用如下参数。\n$ gpg --delete-secret-keys [用户ID] $ gpg --delete-key [用户ID] 输出密钥\n公钥文件（.gnupg/pubring.gpg）以二进制形式储存，armor参数可以将其转换为ASCII码显示。\n$ gpg --armor --output public-key.txt --export [用户ID] \u0026ldquo;用户ID\u0026quot;指定哪个用户的公钥，output参数指定输出文件名（public-key.txt）。\n类似地，export-secret-keys参数可以转换私钥。\n$ gpg --armor --output private-key.txt --export-secret-keys 上传公钥\n公钥服务器是网络上专门储存用户公钥的服务器。send-keys参数可以将公钥上传到服务器。\n$ gpg --send-keys [用户ID] --keyserver hkp://subkeys.pgp.net 使用上面的命令，你的公钥就被传到了服务器subkeys.pgp.net，然后通过交换机制，所有的公钥服务器最终都会包含你的公钥。\n由于公钥服务器没有检查机制，任何人都可以用你的名义上传公钥，所以没有办法保证服务器上的公钥的可靠性。通常，你可以在网站上公布一个公钥指纹，让其他人核对下载到的公钥是否为真。fingerprint参数生成公钥指纹。\n$ gpg --fingerprint [用户ID] 输入密钥\n除了生成自己的密钥，还需要将他人的公钥或者你的其他密钥输入系统。这时可以使用import参数。\n$ gpg --import [密钥文件] 为了获得他人的公钥，可以让对方直接发给你，或者到公钥服务器上寻找。\n$ gpg --keyserver hkp://subkeys.pgp.net --search-keys [用户ID] 正如前面提到的，我们无法保证服务器上的公钥是否可靠，下载后还需要用其他机制验证．\n加密和解密 加密\n假定有一个文本文件demo.txt，怎样对它加密呢？\nencrypt参数用于加密。\n$ gpg --recipient [用户ID] --output demo.en.txt --encrypt demo.txt recipient参数指定接收者的公钥，output参数指定加密后的文件名，encrypt参数指定源文件。运行上面的命令后，demo.en.txt就是已加密的文件，可以把它发给对方。\n解密\n对方收到加密文件以后，就用自己的私钥解密。\n$ gpg --output demo.de.txt --decrypt demo.en.txt output 指定解密后生成的文件，decrypt参数指定需要解密的文件。运行上面的命令，demo.de.txt就是解密后的文件。\nGPG允许省略decrypt参数。\n$ gpg demo.en.txt 签名 对文件签名\n有时，我们不需要加密文件，只需要对文件签名，表示这个文件确实是我本人发出的。sign参数用来签名。\n$ gpg --sign demo.txt 运行上面的命令后，当前目录下生成demo.txt.gpg文件，这就是签名后的文件。这个文件默认采用二进制储存，如果想生成ASCII码的签名文件，可以使用clearsign参数。\n$ gpg --clearsign demo.txt 运行上面的命令后 ，当前目录下生成demo.txt.asc文件，后缀名asc表示该文件是ASCII码形式的。\n如果想生成单独的签名文件，与文件内容分开存放，可以使用detach-sign参数。　$ gpg --detach-sign demo.txt 运行上面的命令后，当前目录下生成一个单独的签名文件demo.txt.sig。该文件是二进制形式的，如果想采用ASCII码形式，要加上armor参数。　$ gpg --armor --detach-sign demo.txt 签名+加密\n上一节的参数，都是只签名不加密。如果想同时签名和加密，可以使用下面的命令。\n$ gpg --local-user [发信者ID] --recipient [接收者ID] --armor --sign --encrypt demo.txt local-user参数指定用发信者的私钥签名，recipient参数指定用接收者的公钥加密，armor参数表示采用ASCII码形式显示，sign参数表示需要签名，encrypt参数表示指定源文件。\n验证签名\n我们收到别人签名后的文件，需要用对方的公钥验证签名是否为真。verify参数用来验证。\n$ gpg --verify demo.txt.asc demo.txt 举例来说，openvpn网站就提供每一个下载包的gpg签名文件。你可以根据它的说明，验证这些下载包是否为真。\nLinux Kernel 来自 Wikipedia:\n 内核是计算机操作系统的核心组件，对系统有完全的控制。开机时最先启动，然后负责后续的启动工作。它负责处理其它软件的请求，将这些请求转化为中央处理器的数据处理请求。内核还负责管理内存，管理系统和其它打印机、扬声器等外围设备的通讯，是操作系统最基础的部分。\n 内核包安装在/boot/下的文件系统上。为了能够引导到内核，必须适当配置启动加载器。\nKernel module 内核模块是可以按需加载或卸载的内核代码，可以不重启系统就扩充内核的功能。\n要创建内核模块，请阅读此指南。模块可以设置成内置或者动态加载，要编译成可动态加载，需要在内核配置时将模块配置为 M (模块)。\n获取信息 模块保存在 /lib/modules/kernel_release (使用 uname -r 命令显示当前内核版本)。\n注意： 模块名通常使用 (_) 或 - 连接，但是这些符号在 modprobe 命令和 /etc/modprobe.d/ 配置文件中都是可以相互替换的。\n显示当前装入的内核模块：\n$ lsmod 在上面的输出中：\n Module 显示每个模块的名称 Size 显示每个模块的大小（并不是它们占的内存大小） Used by 显示每个模块被使用的次数和使用它们的模块  显然，这里有很多模块。加载的模块数量取决于你的系统和版本以及正在运行的内容。我们可以这样计数：\n$ lsmod | wc -l 67 modules.builtin 文件中列出了所有构建在内核中的模块\n$ more /lib/modules/$(uname -r)/modules.builtin | head -10 kernel/arch/x86/crypto/crc32c-intel.ko kernel/arch/x86/events/intel/intel-uncore.ko kernel/arch/x86/platform/intel/iosf_mbi.ko kernel/mm/zpool.ko kernel/mm/zbud.ko kernel/mm/zsmalloc.ko kernel/fs/binfmt_script.ko kernel/fs/mbcache.ko kernel/fs/configfs/configfs.ko kernel/fs/crypto/fscrypto.ko 显示模块信息：\n$ modinfo module_name 显示所有模块的配置信息：\n$ modprobe -c | less 显示某个模块的配置信息：\n$ modprobe -c | grep module_name 显示一个装入模块使用的选项：\n$ systool -v -m module_name 显示模块的依赖关系：\n$ modprobe --show-depends module_name 使用systemd自动加载模块 目前，所有必要模块的加载均由 udev 自动完成。所以，如果不需要使用任何额外的模块，就没有必要在任何配置文件中添加启动时加载的模块。但是，有些情况下可能需要在系统启动时加载某个额外的模块，或者将某个模块列入黑名单以便使系统正常运行。\n内核模块可以在/etc/modules-load.d/ 下的文件中明确列出，以便systemd在引导过程中加载它们。 每个配置文件都以 /etc/modules-load.d/\u0026lt;program\u0026gt;.conf的样式命名。 配置文件仅包含要加载的内核模块名称列表，以换行符分隔。 空行和第一个非空白字符为#或;的行被忽略。\n$ cat /etc/modules-load.d/virtio-net.conf # Load virtio_net.ko at boot virtio_net 另见modules-load.d(5)。\n手动加载卸载 控制内核模块载入/移除的命令是kmod 软件包提供的, 要手动装入模块的话，执行:\n# modprobe module_name 按文件名加载模块:\n# insmod filename [args] 注意： 如果升级了内核但是没有重启，路径 /usr/lib/modules/$(uname -r)/ 已经不存在。modprobe 会返回错误 1，没有额外的错误信息。如果出现 modprobe 加载失败，请检查模块路径以确认是否是这个问题导致。\n如果要移除一个模块：\n# modprobe -r module_name 或者:\n# rmmod module_name 配置模块参数 手动加载时设置 传递参数的基本方式是使用 modprobe 选项，格式是 key=value：\n# modprobe module_name parameter_name=parameter_value 使用 /etc/modprobe.d/中的文件 要通过配置文件传递参数，在 /etc/modprobe.d/ 中放入任意名称 .conf 文件，加入:\n$ sudo gedit /etc/modprobe.d/myfilename.conf options modname parametername=parametercontents 例如\n$ sudo gedit /etc/modprobe.d/thinkfan.conf # On thinkpads, this lets the thinkfan daemon control fan speed options thinkpad_acpi fan_control=1 注意： 如果要在启动时就修改内核参数(从 init ramdisk 开始)，需要将相应的.conf-文件加入 mkinitcpio.conf 的 FILES 参数中。\n使用内核命令行 如果模块直接编译进内核，也可以通过启动管理器(GRUB, LILO 或 Syslinux)的内核行加入参数：\nmodname.parametername=parametercontents 例如:\nthinkpad_acpi.fan_control=1 别名 $ cat /etc/modprobe.d/myalias.conf # Lets you use \u0026#39;mymod\u0026#39; in MODULES, instead of \u0026#39;really_long_module_name\u0026#39; alias mymod really_long_module_name 有些模块具有别名，以方便其它程序自动装入模块。禁用这些别名可以阻止自动装入，但是仍然可以手动装入。\n$ cat /etc/modprobe.d/modprobe.conf # Prevent autoload of bluetooth alias net-pf-31 off # Prevent autoload of ipv6 alias net-pf-10 off 黑名单 禁用内核模块 对内核模块来说，黑名单是指禁止某个模块装入的机制。当对应的硬件不存在或者装入某个模块会导致问题时很有用。\n有些模块作为 initramfs 的一部分装入。\nmkinitcpio -M 会显示所有自动检测到到模块：要阻止 initramfs 装入某些模块，可以在 /etc/modprobe.d中将它们加入黑名单。并应在映像生成过程中通过modconf挂钩将其添加。\n运行 mkinitcpio -v 会显示各种钩子(例如 filesystem 钩子, SCSI 钩子等)装入的模块。如果您的HOOKS 数组中没有 modconf 钩子（例如，和默认配置不同）则请将该\u0026rdquo;.conf\u0026quot;文件添加到/etc/mkinitcpio.conf中的FILES数组中。一旦您将其列入黑名单，请重新生成 initramfs，然后重新启动。\n使用 /etc/modprobe.d/ 中的文件 在 /etc/modprobe.d/ 中创建 .conf 文件，使用 blacklist 关键字屏蔽不需要的模块，例如如果不想装入 pcspkr 模块：\n$ sudo gedit /etc/modprobe.d/nobeep.conf # Do not load the pcspkr module on boot blacklist pcspkr 注意： blacklist 命令将屏蔽一个模板，所以不会自动装入，但是如果其它非屏蔽模块需要这个模块，系统依然会装入它。\n要避免这个行为，可以让 modprobe 使用自定义的 install 命令，而不是像往常一样将模块插入内核，因此您可以通过以下方式强制模块始终无法加载：\n$ sudo gedit /etc/modprobe.d/blacklist.conf ... install MODULE /bin/true ... 这样就可以 \u0026ldquo;屏蔽\u0026rdquo; 模块及所有依赖它的模块。\n使用内核命令行 提示： 如果模块损坏导致无法引导系统，这将非常有用。\n您也可以从引导加载程序中将模块列入黑名单。\n如Kernel参数.中所述，只需将module_blacklist=modname1,modname2,modname3 添加到引导加载程序的内核行中即可。\n注意： 将多个模块列入黑名单时，请注意，它们之间仅用逗号分隔。 空格或其他内容可能会破坏语法。\nKernel parameters 一共有三种办法，可以给内核传递参数，用于控制其行为方式：\n 在编译内核时（这个最根本，会决定后面两种方法） 内核启动时(通常是在一个启动管理器里设置). 在运行时 (通过修改在 /proc 和 /sys中的文件).  本页面主要是讲第二种方法。\n配置 内核参数可以在启动时临时修改，也可以永久性写到启动管理器的配置文件中，永远起作用。\n下面示例把参数quiet 和 splash 加到启动管理器。\nsystemd-boot   当启动菜单出现时 按 e进入编辑界面:\ninitrd=\\initramfs-linux.img root=/dev/sda2 quiet splash   如果想永久加入参数，编辑 /boot/loader/entries/arch.conf (假设你已经设置好了 EFI system partition) 的options 行:\n  注意：\n 如果没有设置显示启动菜单, 你需要按住Space启动电脑来进入启动菜单 。 如果不能够从启动菜单上进行编辑，修改 /boot/loader/loader.conf 加入 editor 1 来开启编辑功能。  更多信息请参见 systemd-boot .\nGRUB   在菜单出现后按 e 然后将它们添加至 linux 行：\nlinux /boot/vmlinuz-linux root=UUID=978e3e81-8048-4ae1-8a06-aa727458e8ff ro quiet splash 按 b 以便用这些参数启动。\n  要使改变在重启后仍生效，您可以手动编辑 /boot/grub/grub.cfg 中的如上内容。对于初学者，建议编辑 /etc/default/grub 并将您的内核选项添加至 GRUB_CMDLINE_LINUX_DEFAULT 行：\nGRUB_CMDLINE_LINUX_DEFAULT=\u0026quot;quiet splash\u0026quot; 然后重新生成 grub.cfg 文件：\n# grub-mkconfig -o /boot/grub/grub.cfg   有关配置GRUB的更多信息，请参阅 GRUB 。\n发布时间表 内核发布时间表：有吗？ 短的回答是，每两到三个月就有一个新的内核版本发布。长的回答是，这不是一个硬性规定。\n这个意思是，你经常会看到每两到三个月就有一个新的内核版本发布。这是内核维护者团队的目标，但并没有规定新版本必须在前一个版本的 8 周后准时发布的期限。\n新的内核版本（通常）是由 Linus Torvalds 在它准备好的时候发布的。通常是每 2 到 3 个月发布一次。该版本被宣布为“稳定”，一般以 X.Y 的格式编号。\n但这并不是 X.Y 开发的结束。稳定版会有更多的小版本以进行错误的修复。这些小版本在稳定版的内核上又增加了一个点，就像是 X.Y.Z。\n虽然 X.Y（通常）是由 Linux 创造者 Linus Torvalds 发布的，但是维护稳定的 X.Y 内核、合并错误修复和发布 X.Y.Z 版本的责任是由另外的内核开发者负责的。\n一个内核版本支持多长时间？ 和发布一样，一个内核版本支持多长时间也没有固定的日期和时间表。\n一个普通的稳定内核版本通常会被支持两个半月到三个月，这取决于下一个稳定内核版本的发布时间。\n例如，稳定版内核 5.14 会在稳定版内核 5.15 发布后的几周内达到生命末期。结束支持是由该稳定内核版本的维护者在 Linux 内核邮件列表中宣布的。用户和贡献者会被要求切换到新发布的稳定版本。\n但这只适用于正常的稳定内核版本，还有 LTS（长期支持）内核版本，它们的支持期要比 3 个月长得多。\nLTS 内核：它支持多长时间？ LTS 内核也没有固定的发布时间表。通常，每年都有一个 LTS 内核版本，一般是当年的最后一个版本，它至少会被支持两年。但同样，这里也没有固定的规则。\nLTS 内核的维护者可以同意某个 LTS 内核的维护时间超过通常的两年。这个协议是根据必要性和参与的人员来达成的。\n这种情况经常发生在 Android 项目中。由于两年的时间不足以让制造商结束对他们的硬件和软件功能的支持，你经常会发现一些 LTS 内核会被支持六年之久。\n你可以 在 Linux 内核网站上 找到这个信息。\n你的发行版可能没有跟随通常的 Linux 内核版本 如果你检查你的 Linux 内核版本，你可能会发现 你的发行版使用了一个旧的内核。也有可能该发行版提供的内核已经在内核网站上被标记为到达了生命末期。\n不要惊慌。你的发行版会负责修补内核的错误和漏洞。除非你真的在使用一个不知名的 Linux 发行版，否则你可以相信你的发行版会保持它的安全和健全。\n如果你有足够的理由，比如为了支持更新的硬件，你可以自由地在你使用的任何发行版或 Ubuntu 中安装最新的 Linux 内核 。\n如果你想了解更多细节，我已经 在这里解释了为什么你的发行版使用过时的 Linux 内核。\n安装内核 dpkg 从 kernel.ubuntu.com 网站手动下载可用的最新 Linux 内核：\n linux-image-X.Y.Z-generic-.deb linux-modules-X.Y.Z-generic-.deb  手动安装内核：\n$ sudo dpkg --install *.deb 重启系统，使用新内核：\n$ sudo reboot 检查是否如你所愿：\n$ uname -r apt-get 不同于上一个方法，这种方法会从 Ubuntu 官方仓库下载、安装内核版本：\n运行：\n$ sudo apt-get upgrade linux-image-generic 安装 xanmod 内核 最新内核集成的一些新特性的确是可以提升性能的。xanmod 内核的安装可以去它们的官方网站来查询，xanmod 内核的特性很多地方都有，官方也写的有很多，不过大多数还是以下几点：\n 改善了 CPU 调度能力 改善了 I/O 的调度能力 增加了一些和性能有关的第三方补丁 使用了最新的 GCC 进行编译 使用了最新的 MicroCode  安装的方式也比较简单，添加源并且更新安装就行了：\n$ echo \u0026#39;deb http://deb.xanmod.org releases main\u0026#39; | sudo tee /etc/apt/sources.list.d/xanmod-kernel.list \u0026amp;\u0026amp; wget -qO - https://dl.xanmod.org/gpg.key | sudo apt-key add - 然后安装，我个人安装的是最新的 5.8.1 的 edge：\n$ sudo apt update \u0026amp;\u0026amp; sudo apt install linux-xanmod-edge 安装完毕后还可以安装最新的微码：\n$ sudo apt update \u0026amp;\u0026amp; sudo apt install linux-xanmod 重启以应用\n$ sudo reboot 删除旧内核 随着时间的流逝，持续的内核更新会在系统中积聚大量的不再使用的内核，浪费你的磁盘空间。每个内核镜像和其相关联的模块/头文件会占用200-400MB的磁盘空间，因此由不再使用的内核而浪费的磁盘空间会快速地增加。\nGRUB管理器为每个旧内核都维护了一个GRUB入口，以备你想要使用它们。\n作为磁盘清理的一部分，如果你不再使用这些，你可以考虑清理掉这些镜像。\n在删除旧内核之前，记住最好留有2个最近的内核（最新的和上一个版本），以防主要的版本出错。\n在Ubuntu内核镜像包含了以下的包。\n linux-image-: 内核镜像 linux-image-extra-: 额外的内核模块 linux-headers-: 内核头文件  首先检查系统中安装的内核镜像。\n$ dpkg --list | grep linux-image $ dpkg --list | grep linux-headers 在列出的内核镜像中，你可以移除一个特定的版本。\n$ sudo apt-get purge linux-image-3.19.0-15 $ sudo apt-get purge linux-headers-3.19.0-15 上面的命令会删除内核镜像和它相关联的内核模块和头文件。\n注意如果你还没有升级内核那么删除旧内核会自动触发安装新内核。这样在删除旧内核之后，GRUB配置会自动升级来移除GRUB菜单中相关GRUB入口。\n如果你有很多没用的内核，你可以用shell表达式来一次性地删除多个内核。注意这个括号表达式只在bash或者兼容的shell中才有效。\n$ sudo apt-get purge linux-image-3.19.0-{18,20,21,25} $ sudo apt-get purge linux-headers-3.19.0-{18,20,21,25} 上面的命令会删除4个内核镜像：3.19.0-18、3.19.0-20、3.19.0-21 和 3.19.0-25。\n如果GRUB配置由于任何原因在删除旧内核后没有正确升级，你可以尝试手动用update-grub2命令来更新配置。\n$ sudo update-grub2 现在就重启来验证GRUB菜单是否已经正确清理了。\n编写第一个内核模块 TIPS BackupYourSystem Remote backup 用于那些不常用、体积大、但是必要的资料，比如多媒体（视频、音频、图片等）、电子书、游戏、软件等等。本地存储的话成本太高，百度云有2T的完全免费空间（虽然下载慢）。\nLocal backup 本地同一硬盘备份\n目的在于恢复系统出现的错误。类似于虚拟机的快照。我使用 rsync\n#!/bin/bash  set -o errexit set -o nounset set -o pipefail readonly SOURCE_DIR=\u0026#34;/\u0026#34; readonly BACKUP_DIR=\u0026#34;/backup\u0026#34; readonly DATETIME=\u0026#34;$(date \u0026#39;+%Y-%m-%d_%H:%M:%S\u0026#39;)\u0026#34; readonly BACKUP_PATH=\u0026#34;${BACKUP_DIR}/${DATETIME}\u0026#34; readonly LATEST_LINK=\u0026#34;${BACKUP_DIR}/latest\u0026#34; rsync -av \\ \t--delete \u0026#34;${SOURCE_DIR}/\u0026#34; \\ \t--link-dest \u0026#34;${LATEST_LINK}\u0026#34; \\ \t--exclude={\u0026#34;dev\u0026#34;,\u0026#34;proc\u0026#34;,\u0026#34;sys\u0026#34;,\u0026#34;tmp\u0026#34;,\u0026#34;run\u0026#34;,\u0026#34;mnt\u0026#34;,\u0026#34;media\u0026#34;,\u0026#34;lost+found\u0026#34;,\u0026#34;.cache\u0026#34;,\u0026#34;Trash\u0026#34;,\u0026#34;你的备份目录\u0026#34;} \\ \t\u0026#34;${BACKUP_PATH}\u0026#34; rm -rf \u0026#34;${LATEST_LINK}\u0026#34; ln -s \u0026#34;${BACKUP_PATH}\u0026#34; \u0026#34;${LATEST_LINK}\u0026#34; 注意：\n ${SOURCE_DIR}/必须带反斜杠，否则会备份SOURCE_DIR这个目录，而不是这个目录里的内容。 --exclude=\u0026quot;Trash\u0026quot;，Trash被认为为目录，而非文件或文件和目录，并且，它不支持路径~/.local/share/Trash 还原的时候，如果带 --delete，那么就会删除备份时 --exclude= 不包含的内容。还原的时候，同名文件内容会恢复到备份时候的状态。  $ rsync -av 备份目录 源目录 $ rsync -av /backup/latest/ / 查看备份大小\n$ sudo du -hs /backup/ 16G\t/backup/ 整个备份为16GB，所花时间 12m。\n通过 crontab 使之每周一12点自动备份：\n$ sudo crontab -e 0 12 * * 1 /path/.backup.sh 本地不同硬盘备份\n目的在于保存重要数据，以防硬盘损坏。\n#!/bin/bash rsync -av --delete --exclude={\u0026#39;Backup\u0026#39;,\u0026#39;lost+found\u0026#39;} DataToo/ DataOne/Backup/ 备份解决方案 最近，我发起了一个 投票，让读者投票选出他们最喜欢的开源备份解决方案。在我们的 版主社区 上，我们提供了六个推荐的解决方案：\n Cronopete Deja Dup Rclone Rdiff-backup Restic Rsync  而参与的读者也在评论区分享了一些其它的选择。并且读者提供的这 13 个其它的解决方案：\n BorgBackup：带有压缩和加密特性以用具有数据去重功能的备份解决方案。它基于 BSD 许可证，支持 Linux、MacOS 和 BSD。 UrBackup：它可以做镜像和文件的完整和增量备份；你可以保存整个分区或单个目录。它有 Windows、Linux、和 MacOS 客户端，并且采用 GNU Affero 公共许可证。 LuckyBackup：根据其网站介绍，“它是一个易于使用、快速（只传输变化部分，而不是全部数据）、安全（在做任何数据操作之前，先检查所有需要备份的目录，以确保数据安全）、可靠和完全可定制的备份解决方案。它在 GPL 许可证下发行。 Casync ：一个可寻址内容的同步解决方案 —— 它设计用于备份、同步、存储和检索大文件系统的多个相关版本。它使用 GNU Lesser 公共许可证。 Syncthing：用于在两台计算机之间同步文件。它基于 Mozilla 公共许可证使用，根据其网站介绍，它是安全和私密的。它可以工作于 MacOS、Windows、Linux、FreeBSD、Solaris 和 OpenBSD。 Duplicati：一个可工作于 Windows、MacOS 和 Linux 上的、并且支持多种标准协议（比如 FTP、SSH、WebDAV 和云服务）、免费的备份解决方案。它的特性是强大的加密功能，并且它使用 GPL 许可证。 Dirvish ：一个基于磁盘的虚拟镜像备份系统，它使用 OSL-3.0 许可证。它要求必须安装有 Rsync、Perl5、SSH。 Bacula：允许系统管理员去管理备份、恢复、和跨网络的不同种类计算机上的多种数据的一套计算机程序，它支持在 Linux、FreeBSD、Windows、MacOS、OpenBSD 和 Solaris 上运行，并且它的大部分源代码都是基于 AGPLv3 许可证的。 BackupPC：一个高性能的、企业级的、可以备份 Linux、Windows 和 MacOS 系统的 PC 和笔记本电脑上的数据到服务器磁盘上的备份解决方案。它是基于 GPLv3 许可证的。 Amanda ：一个使用 C 和 Perl 写的备份系统，它允许系统管理员去备份整个网络中的客户端到一台服务器上的磁带、磁盘或基于云的系统。它是由马里兰大学于 1991 年开发并拥有版权，并且它有一个 BSD 式的许可证。 Back in Time ：一个为 Linux 设计的简单的备份实用程序。它提供了命令行和图形用户界面，它们都是用 Python 写的。去执行一个备份，只需要指定存储快照的位置、需要备份的文件夹，和备份频率即可。它使用的是 GPLv2 许可证。 Timeshift ：一个 Linux 上的备份实用程序，它类似于 Windows 上的系统恢复和 MacOS 上的时间胶囊。它的 GitHub 仓库上介绍说：“Timeshift 通过定期递增的文件系统快照来保护你的系统。这些快照可以在日后用于数据恢复，以撤销某些对文件系统的修改。” Kup ：一个能够帮助用户备份它们的文件到 USB 驱动器上的备份解决方案，但它也可以用于执行网络备份。它的 GitHub 仓库上介绍说：”当插入你的外部硬盘时，Kup 将自动启动并复制你的最新的修改。“  清理系统 删除不再需要的包 $ sudo apt autoremove APT cache # see the size of this cache $ sudo du -sh /var/cache/apt # remove only the outdated packages $ sudo apt-get autoclean # delete apt cache in its entirety $ sudo apt-get clean apt-get 和软件中心下载的软件包一般放在 /var/cache/apt/archives/ 目录，一般都安装在 /usr/\nJournal logs # check the log size $ journalctl --disk-usage # clear the logs that are older than a certain days $ journalctl --vacuum-time=3d Thumbnails cache # check the size of thumbnail cache $ du -sh ~/.cache/thumbnails $ rm -rf ~/.cache/thumbnails/* Duplicate files Find and remove duplicate files：You can use a GUI tool like FSlint or a command line tool like FDUPES for this task\nOld Linux kernels Remove old Linux kernels\n# List all installed Linux kernels $ sudo dpkg --list \u0026#39;linux-image*\u0026#39; $ apt-get remove linux-image-VERSION 命令行技巧 Bash 快捷键 编辑命令\n Ctrl + a ：移到命令行首 Ctrl + e ：移到命令行尾 Ctrl + f ：按字符前移（右向） Ctrl + b ：按字符后移（左向） Alt + f ：按单词前移（右向） Alt + b ：按单词后移（左向） Ctrl + xx：在命令行首和光标之间移动 Ctrl + u ：从光标处删除至命令行首 Ctrl + k ：从光标处删除至命令行尾 Ctrl + w ：从光标处删除至字首 Alt + d ：从光标处删除至字尾 Ctrl + d ：删除光标处的字符 Ctrl + h ：删除光标前的字符 Ctrl + y ：粘贴至光标后 Alt + c ：从光标处更改为首字母大写的单词 Alt + u ：从光标处更改为全部大写的单词 Alt + l ：从光标处更改为全部小写的单词 Ctrl + t ：交换光标处和之前的字符 Alt + t ：交换光标处和之前的单词 Alt + Backspace：与 Ctrl + w 类似，分隔符有些差别  重新执行命令\n Ctrl + r：逆向搜索命令历史 Ctrl + g：从历史搜索模式退出 Ctrl + p：历史中的上一条命令 Ctrl + n：历史中的下一条命令 Alt + .：使用上一条命令的最后一个参数  控制命令\n Ctrl + l：清屏 Ctrl + o：执行当前命令，并选择上一条命令 Ctrl + s：阻止屏幕输出 Ctrl + q：允许屏幕输出 Ctrl + c：终止命令 Ctrl + z：挂起命令  Bang (!) 命令\n !!：执行上一条命令 !blah：执行最近的以 blah 开头的命令，如 !ls !blah:p：仅打印输出，而不执行 !$：上一条命令的最后一个参数，与 Alt + . 相同 !$:p：打印输出 !$ 的内容 !*：上一条命令的所有参数 !*:p：打印输出 !* 的内容 ^blah：删除上一条命令中的 blah ^blah^foo：将上一条命令中的 blah 替换为 foo ^blah^foo^：将上一条命令中所有的 blah 都替换为 foo  你可能不知道的SHELL Shell也叫做命令行界面，它是*nix操作系统下用户和计算机的交互界面。Shell这个词是指操作系统中提供访问内核服务的程序。\n这篇文章向大家介绍Shell一些非广为人知、但却实用有趣的知识，权当品尝shell主食后的甜点吧。\n科普\n先科普几个你可能不知道的事实：\n  Shell几乎是和Unix操作系统一起诞生，第一个Unix Shell是肯·汤普逊（Ken Thompson）以Multics上的Shell为模范在1971年改写而成，并命名Thompson sh。即便是后来流行的bash（shell的一种变体），它的年龄实际上比当前流行的所有的Linux kernel都大，可谓在Linux系统上是先有Shell再有Kernel。\n  当前绝大部分*nix和MacOS操作系统里的默认的Shell都是bash，bash由Brian Fox在1987年创造，全称Bourne Again shell ( bash)。\n  你或许听说除了bash之外，还有Bourne shell ( sh)，Korn shell ( ksh)，C shell （包括 csh and tcsh），但是你知道这个星球上一共存在着大约50多种不同的shell么？想了解他们，请参考 http://www.freebsd.org/ports/shells.html。\n  一些强大的命令\n  在命令行前加空格，该命令不会进入history里。\n  ctrl-x e\n快速启动你的默认编辑器（由变量$EDITOR设置）。\n  为什么说 zsh 是 shell 中的极品？ 色彩高亮\n并不是传统基于正则表达式的色彩高亮，而是真的会判断你输入的是啥的色彩高亮。\n比如一个主题白色代表普通命令或者程序，红色代表错误命令，青色的代表内建命令或者 alias （echo 和 ls ），这些都不是正则判断出来的，是真的去检查的。非零的错误码（上一条命令错误），也可以高亮显示。\n命令提示\n注意，命令提示和补全是两个完全不同的系统，很多时候提示比补全更有用。你输入命令，后面就用灰色给你提示命令的参数，而且是随着你动态输入完每一个字母不断修正变化。\n这个命令提示是基于你的历史命令数据库进行分析的，随着你输入的命令越来越多，提示将会越来越准确和顺手。\n如果你觉得它提示的正确，你可以 CTRL+F 表示采纳，后面就会自动帮你一次性全部输入完了。\n智能补全\n缩写路径补全：\n$ cd /v/w/h 敲一个TAB\n$ cd /var/www/html/ 补全目录、命令参数补全连敲两次TAB进入选择模式，除了 tab/shift+tab 可以前后切换外，你还可以使用光标键上下左右移动。回车表示确认选择，用 CTRL+G 表示退出。\n快速跳转\n输入 cd 后面加一个减号后，按一次 tab 马上就列出本次登陆后去过的最近几次路径，接着根据下面的提示输入数字按回车就过去了，比如输入：\n$ cd -5 \u0026lt;回车\u0026gt; 当然你还可以不输入数字，而是再按一次 tab 进入选择模式，上下键或者 ctrl+n/p 来选择，回车确认，ctrl+g 返回。\n自动跳转\n敲入 z 命令，列出了自从我开始用zsh进入过的目录和他们的权重，进入次数越多，权重越大。z 后面加一个关键词就能跳转到所有匹配的历史路径中权重最高的那个了。空格分隔多个关键字，z会先匹配出第一个来，然后再匹配第二个\u0026hellip;\n使用：“z -l foo\u0026quot; 可以列出包含 foo 的所有历史路径。\n# 按下ALT+O 就执行 cd .. 命令 bindkey -s \u0026#39;\\eo\u0026#39; \u0026#39;cd ..\\n\u0026#39; # 按下 ALT+; 就执行 ls -l 命令 bindkey -s \u0026#39;\\e;\u0026#39; \u0026#39;ls -l\\n\u0026#39; 热键绑定\nzsh 里面使用 bindkey 命令可以设置一系列热键，用来运行某一个 zsh 内部命令或者某个 shell 命令。\n应该知道的LINUX技巧 首先，我想告诉大家，在Unix/Linux下，最有效率技巧的不是操作图形界面，而是命令行操作，因为命令行意味着自动化。\n日常\n  请man bash后查找Readline Key Bindings一节来看看bash的默认热键，比如：Alt-. 把上一次命令的最后一个参数打出来，而Alt-* 则列出你可以输入的命令。\n  回到上一次的工作目录： cd – （回到home是 cd ~）\n  pstree -p 可以帮你显示进程树。\n  使用 pgrep 和 pkill 来找到或是kill 某个名字的进程。 (-f 选项很有用).\n  通过 \u0026lt;(some command) 可以把某命令当成一个文件。示例：比较一个本地文件和远程文件 /etc/hosts： diff /etc/hosts \u0026lt;(ssh somehost cat /etc/hosts)\n  在 bash中，使用重定向到标准输出和标准错误。如： some-command \u0026gt;logfile 2\u0026gt;\u0026amp;1。\n  使用 man ascii 来查看 ASCII 表。\n  系统调试\n  如果你想知道磁盘、CPU、或网络状态，你可以使用 iostat, netstat, top (或更好的 htop), 还有 dstat 命令。你可以很快地知道你的系统发生了什么事。关于这方面的命令，还有iftop, iotop等。\n  要了解内存的状态，你可以使用free和vmstat命令。具体来说，你需要注意 “cached” 的值，这个值是Linux内核占用的内存。还有free的值。\n  如果你要找到哪个socket或进程在使用网络带宽，你可以使用 iftop 或 nethogs。\n  如果你要抓网络包的话，试试 wireshark 或 tshark。\n  了解 strace 和 ltrace。这两个命令可以让你查看进程的系统调用，这有助于你分析进程的hang在哪了，怎么crash和failed的。你还可以用其来做性能profile，使用 -c 选项，你可以使用-p选项来attach上任意一个进程。\n  了解用ldd命令来检查相关的动态链接库。注意：ldd的安全问题\n  使用gdb来调试一个正在运行的进程或分析core dump文件。参看我写的《GDB中应该知道的几个调试方法》\n  学会到 /proc 目录中查看信息。这是一个Linux内核运行时记录的整个操作系统的运行统计和信息，比如： /proc/cpuinfo, /proc/xxx/cwd, /proc/xxx/exe, /proc/xxx/fd/, /proc/xxx/smaps.\n  如果你调试某个东西为什么出错时，sar命令会有用。它可以让你看看 CPU, 内存, 网络, 等的统计信息。\n  使用 dmesg 来查看一些硬件或驱动程序的信息或问题。\n  powerline-shell 不想每次都安装 zsh 与 ohmyzsh？\n$ pip install powerline-shell Add the following to your .bashrc file:\nfunction _update_ps1() { PS1=$(powerline-shell $?) } if [[ $TERM != linux \u0026amp;\u0026amp; ! $PROMPT_COMMAND =~ _update_ps1 ]]; then PROMPT_COMMAND=\u0026#34;_update_ps1; $PROMPT_COMMAND\u0026#34; fi 默认的话，路径会完整显示，会很长\ngenerate the default config at this location using:\n$ mkdir -p ~/.config/powerline-shell \u0026amp;\u0026amp; \\ powerline-shell --generate-config \u0026gt; ~/.config/powerline-shell/config.json Segment Configuration\n{ \u0026#34;segments\u0026#34;: [ \u0026#34;virtual_env\u0026#34;, \u0026#34;username\u0026#34;, \u0026#34;hostname\u0026#34;, \u0026#34;ssh\u0026#34;, \u0026#34;cwd\u0026#34;, \u0026#34;git\u0026#34;, \u0026#34;hg\u0026#34;, \u0026#34;jobs\u0026#34;, \u0026#34;root\u0026#34; ], + \u0026#34;cwd\u0026#34;: + { + \u0026#34;max_depth\u0026#34;: 1 +\t} } 检测硬盘坏道和坏块 硬盘坏道分为物理坏道和逻辑坏道。\n 物理坏道：就是硬盘实体有坏的地方，物理坏道推荐换硬盘，当然也有办法重新分区来隔离坏道，不过可能也用不久，所以不推荐。 逻辑坏道：是磁盘磁道上面的校验信息（ECC）跟磁道的数据对不上号所致。出现这一故障的原因，通常都是因为一些程序的错误操作或是该处扇区的磁介质开始出现不稳定的先兆。物理坏道也是逻辑坏道产生的一种原因。  发现 dmesg：当有硬盘坏道时，通常在dmesg输出的信息中会有 Buffer I/O Error，所以经常检查dmesg的输出可以及时发现是否存在硬盘问题。\n检测 通过fdisk 查看显示所有磁盘或闪存的信息\n$ sudo fdisk -l /dev/sd* 使用 badlocks检查 linux 硬盘上的坏道/坏块\n$ sudo badblocks -s -v /dev/sdb \u0026gt; badsectors.txt 修复 查看上述分区检查出来的坏道信息\n$ tail -f badsectors.txt 先备份数据再修复磁盘。硬盘在使用时不能修复，否则可能存在写并发的问题，所以修复前需要umount对应分区,或使用 Live CD\n$ sudo umount MountPoint umount 分区成功后，修复命令如下，其中-w表示写入修复的，后面是结束（END）和开始（START）块号，注意END在前，START在后。\n$ sudo badblocks -s -w /dev/sdb 205971590 205971595 修复后再次检查\n$ sudo badblocks -s -v /dev/sdb 205971590 205971595 屏蔽 执行e2fsck（针对 ext2/ext3/ext4 文件系统）或fsck命令，命令中还需要用到 badsectors.txt 文件和设备文件。\n# for ext2/ext3/ext4 $ sudo e2fsck -l badsectors.txt /dev/sdb # others $ sudo fsck -l badsectors.txt /dev/sdb 如何探索 從「指令」找到「使用說明」\n找使用說明\n$ man -f ls 閱讀使用說明\n$ man ls $ man 1 ls # 若是「bash」內建的指令，則是可以使用「help」 $ help if 上面的「man 1 ls」，「1」指的是「Manpage Sections」。\n執行下面指令可以看到各個「Section」的簡介。\n$ whatis intro 然後分別執行下面的指令，可以閱讀更詳細的說明\n$ man 1 intro $ man 2 intro $ man 3 intro $ man 4 intro $ man 5 intro $ man 6 intro $ man 7 intro $ man 8 intro 從「指令」找到「所屬套件」\n先透過「whereis」來找到「ls」所在的確切路徑。\n$ whereis ls ls: /bin/ls 然後根據這個結果，再執行下面的指令\n$ rpm -qf /bin/ls $ dpkg -S /bin/ls coreutils-8.32-1.2.x86_64 找「已安裝套件」的「檔案列表」\n$ rpm -ql coreutils $ dpkg -L coreutils Transfer files between Linux and Android  Connect Using USB Cable Apps  KDE Connect/GSConnect Android File Transfer AirDroid   Bluetooth  Xorg vs Wayland X即X11、X Window System，是用于在类UNIX的操作系统上的位图显示的窗口系统，提供了GUI环境的基本框架。X由X.Org Foundation维护，遵守MIT协议，当前参考实现为X.Org Server。在架构方面，X使用了C/S模型，客户端和服务器可以在同一个机器上，也可以在不同的机器上，X作为Server为应用程序这个Client提供显示和I/O服务。\nWayland是一个显示服务协议，服务端为Wayland Compositor，把X的X Server和Compositor合二为一，旨在替换X，作为类Unix操作系统上更现代、简介的窗口系统，遵守MIT协议，提供了Wayland Compositor的参考C语言实现Weston。\n时至今日，原本在X Server中做的事很多已被移到kernel或者单独的库中，因此X Server就显得比较累赘了。Wayland在架构上去掉了这个中间层，将compositor作为display server，使client与compositor直接通信，从而在灵活性和性能等方面上能够比前辈更加出色。\n查看是否使用 wayland\n$ echo $XDG_SESSION_TYPE Fedora、openSUSE 群讨论\nAppImage的制造者就是其中一个。主要反对的是Wayland声称自己取代X11，但在功能集合上二者完全不在一个层面，后者比前者强太多了。\n而他反对红帽的东西主要是因为红帽一直就是Linux桌面领域比较强权的那个企业，比如早期PulseAudio，比如SystemD，早期多灾多难制造了很多麻烦。\n推出一个新技术，在其不完善的前提下就想着取代旧技术，对于旧技术存在的但新技术不存在的功能却完全不考虑过渡方案，导致技术迭代的过程中用户就一次又一次地被抛弃。尤其和微软对比起来，微软在砍掉很重要的旧功能的时候会有完备的过渡方案，并且对于旧技术依然保持极长的支持周期。不过毕竟Windows 8那时候用户啥反应大家也不是不知道。\n能理解，并且我有时候也会有同样的抱怨，刚学会一个新软件，结果过半年这个软件就被下一次更新抛弃了。AppImage的制造者可能是希望Linux桌面能学习一下微软的一些策略。\n至于为什么反对Flatpak，因为Flatpak是红帽随同Wayland、Gnome一起强推的技术。\nX11 为什么强?\n远程应用，只把远程系统的一个应用程序在本机打开。X下面非常轻松，这就是X功能的一部分。微软的RDP也有同样的功能。并且渲染工作是在发起远程连接的那一段完成的。Wayland下面，没有，完全依赖窗口管理器自己提供的功能，而目前能做到的极限就是个VNC。\n统一的图形库，Xlib，Windows下与之对应的是Win32的UI部分。所有X11的窗口管理器都提供稳定且统一的图形库。在Wayland下面，没有，只能给你push一堆像素点，这就意味着Wayland的应用程序的向下兼容性会比原先X的程序更差。\n统一的窗口管理方式，也是X服务器的标准功能之一，在Windows下面我也不知道对标啥，但只要一个桌面环境用了X，那么应用程序就能确保自己使用一个标准的方法就能管理程序窗口，在Windows下也有同样的保障。Wayland下面，没有，完全依赖窗口管理器暴露的API或者无障碍API。\n接上述，统一的自动化工具实现方式。Windows下面的AutoHotkey不知道多少人用过，在X11下面对应的软件是xdotool。在Wayland下面，没有。ydotool先不说它已经被半弃坑了，最主要的是ydotool调用uinput，只能输入不能获得窗口状态。\n程序的可靠性。在X下面，桌面环境或者渲染器崩溃，应用程序依然健在。并且Windows也是如此的。Wayland下面就不是这么一回事了，至少对于Gnome来讲，shell崩溃就会连着所有程序全部崩溃。KDE的Kwin实现了自己的程序留活机制，但这样便从“所有X11桌面都支持”变成了“只有KDE支持”。\nWayland没有上述所有功能的原因很简单，Wayland不是软件、不是具体实现，它只是个标准，用来显示画面的标准。\n是的，没错，这些本来确实应该交给窗口管理器和渲染器完成。但是，Wayland在不支持这些功能的前提下却表示自己是X11的替代品/延续发展，这就非常地有问题，因为Wayland并没有做到功能上的延续。\n而且，Linux桌面下面的向下兼容性问题极度严重，我不想在这再重复一遍。桌面在用X11的时候，至少还能确保X的功能是一致的，无论跑在什么桌面组合上都不用担心兼容性问题，Wayland的出现，只会让原本离散的桌面更加离散。\nwlroots被称作有希望统一Wayland渲染器的实现方式，可惜在此之前Gnome和KDE已经开始做自己的Wayland实现了，这就意味着从X11转向Wayland，至少分裂成了Gnome、KDE和wlroots，其它桌面会不会突然想不开自己做Wayland实现我们也不知道。而且，三家的分裂，难道还不够折磨吗？\n看看Flameshot的Wayland支持，因为发现Gnome和KDE的运行表现不同，于是放弃了Portals API打算等待wlroots的标准，然而wlroots的标准和Gnome的不互通，于是它的支持计划被延期，无ETA。\n再看看Barrier的Wayland支持，它fork的项目是symless的synergy，这是个商业开源软件。Ubuntu 17.04的时候曾经短暂切换到Wayland，那时候symless就计划开始适配Wayland，之后Ubuntu换回X11，于是Wayland适配计划就被放弃。当一部分软件只跟着一部分发行版走、而不考虑整个Linux桌面生态的时候，Linux桌面便从事实上消失了。接下来便只剩Ubuntu桌面、openSUSE桌面、Fedora桌面了，至少对于ISV来讲是这样的，因为不然的话指数级别的适配难度会把开发者累死。\n我并不是在吹X11诋毁Wayland。只是指出现状。我知道这不是Wayland该做的事情，只是问题是：有谁能来做？\n用户关心的是能不能用上对应的功能，Wayland之后功能少了，那用户就会把锅甩给Wayland。\n这也是AppImage创造者一直反感Wayland的原因之一。\n为什么执行自己的程序要在前面加./ shell是如何运行程序的：如果不给出相对路径，或者绝对路径，那么它会经历下面的查找过程。\n alias中查找 内置命令中查找 PATH中查找  $ cd /temp $ ./ls_bak 等同于\n$ /temp/ls_bak shell通常可以执行两种程序，一种是二进制程序，一种是脚本程序。如果是文本程序，且开头没有指定解释程序，则按照shell脚本处理，如果指定了解释程序，则使用解释程序来解释运行；对于二进制程序，则直接创建新的进程即可。\nLTS There is a new release every 6 months (in April and October), with the version number being year.month (e.g.: 16.04 was released in April 2016). Every two years, the April release is a Long Term Support version.\nLTS releases are the ‘enterprise grade’ releases of Ubuntu and are used the most. An estimated 95% of all Ubuntu installations are LTS releases.\nInterim releases (normal releases) will introduce new capabilities from Canonical and upstream open source projects, they serve as a proving ground for these new capabilities.\n All Interim releases (13.04 and later) are only supported for 9 months. All LTS releases (12.04 and later) are supported for five years (now is ten years) on both the desktop and the server.  Now, support means:\n Updates for potential security problems and bugs (not new versions of software) Availability of Commercial support contracts from Canonical Support by Landscape, Canonical\u0026rsquo;s enterprise oriented server management tool set  Ubuntu releases additional versions of the last LTS between releases—such as 14.04.1, that incorporate all of the updates up to this point. This is called a Point-Release (or sometimes snapshot). Those are released every quarter to half year, as needed.\nThe most important thing (for most people) is how long you get to use an install without having to do a release upgrade. A non-LTS version of Ubuntu only gets updates for 9 months from its release so to stay up-to-date —which is critically important— you need to upgrade twice a year; you need to upgrade through every Ubuntu version…\nConversely an Ubuntu LTS release is supported for 5 years and you can upgrade directly from LTS to LTS. This gives you long-lived, solid base to target and test on that makes it super-easy to release-upgrade when you decide to. It\u0026rsquo;s therefore ideal for mass deployment, high-availability systems, and just people who don\u0026rsquo;t like doing release-upgrades.\n设计shell脚本选项 getopt 写shell脚本的时候，通过while、case、shift来设计脚本的命令行选项是一件比较麻烦的事，因为Unix命令行的选项和参数自由度很高，支持短选项和长选项，参数可能是可选的，选项顺序可能是无所谓的，等等。\nbash下的getopt命令可以解析命令行的选项和参数，将散乱、自由的命令行选项和参数进行改造，得到一个完整的、规范化的参数列表，这样再使用while、case和shift进行处理就简单的太多了。\ngetopt有不同的版本，本文介绍的是它的增强版(enhanced)，相比传统的getopt(也称为兼容版本的getopt)，它提供了引号保护的能力。另外，除了不同版本的getopt，bash还有一个内置命令getopts(注意，有个尾随的字符s)，也用来解析命令行选项，但只能解析短选项。\n要验证安装的getopt是增强版的还是传统版的，使用getopt -T判断即可。如果它什么都不输出，则是增强版，此时它的退出状态码为4。如果输出\u0026quot;\u0026ndash;\u0026quot;，则是传统版的getopt，此时它的退出状态码为0。如果想在脚本中进行版本检查，可以参考如下代码：\n$ getopt -T \u0026amp;\u0026gt;/dev/null;[ $? -ne 4 ] \u0026amp;\u0026amp; { echo \u0026#34;not enhanced version\u0026#34;;exit 1; } \u0026hellip;\n在中文介面下，如何只用英文目錄名稱？  先切到英文介面再重新開機，此時 Fedora 會問你要不要將子目錄換為英文名稱（選 Yes），再切回中文介面重新開機，Fedora 會再問你一次要不要更改子目錄為中文名稱（選 No），收工！ LANG=C xdg-user-dirs-gtk-update # 同意更新 xdg-user-dirs-gtk-update # 保留且不再問 手動修正配置文件~/.config/user-dirs.dirs ,然後在主目錄下創建對應目錄,重啟即可解決.  dd 制作U盘启动盘 $ dd bs=4M if=fileName.iso of=/dev/sdx status=progress \u0026amp;\u0026amp; sync Windows 下用 Rufus 且 dd 写入模式\n为什么 Linux 要用 tar.gz，很少用 7Z 或 ZIP？ 因为 7z 和 zip 压缩格式都不能保留 unix 风格的文件权限，比如解压出个可执行文件要重新 chmod chown 才能恢复正常。而 tar 格式可以。而 tar 本身不提供压缩，无非就是把包括所有文件的內容和权限拼成一个文件而己，所以用另外如 gzip 格式压缩。为什么是 gzip，因为几乎所有 linux 都支持而已。\n置默认编辑器 visudo 等操作会打开默认编辑器，在linux中默认编辑器读取EDITOR环境变量，可通过一下命令设置\nexport EDITOR=nano 可将其加入~/.bashrc文件，使得每次登录都可使用\n$ nano ~/.bashrc export EDITOR=nano $ . ~/.bashrc debian系统提供了一个管理工具来设置默认编辑器\n$ sudo update-alternatives --config editor 有两个相似选项\n /usr/bin/vim.basic /usr/bin/vim.tiny  它们的区别：\nim.basic is just plain vanilla Vim (as you can check with apt-file vim.basic or dpkg -S /usr/bin/vim.basic).\nWhile vim.tiny, as the name implies, is a trimmed-down version of Vim (this question explains it further).\n$ vim.tiny --version 通过Linux系统进入 BIOS $ sudo systemctl reboot --firmware-setup 5 Ways to Check CPU Info in Linux  lscpu /proc/cpuinfo lshw hwinfo dmidecodes  exFAT 文件系统\n所谓文件系统，就是文件的储存方式。通过文件系统可以准确找到存储在硬盘中的数据。储存设备都需要指定文件系统，计算机才能读写。\nWindows 的文件系统\n FAT32：是最老的文件系统，所有操作系统都支持，兼容性最好。但是，它是为 32 位计算机设计的，文件不能超过 232 - 1 个字节，也就是不能超过 4GB，分区不能超过 8TB。 NTFS：是 Windows 的默认文件系统，用来替换 FAT32。 exFAT：是 FAT32 的 64位升级版，ex 就是 extended 的缩写（表示\u0026quot;扩展的 FAT32\u0026quot;），功能不如 NTFS，但是解决了文件和分区的大小问题，两者最大都可以到 128PB。  Linux 的 exFAT 格式化\n$ sudo mkfs.exfat /dev/sdX1 分区表\n所谓硬盘分区，就是指一块硬盘上面，同时存在多个文件系统。每个文件系统管理的区域，就称为一个分区（partition）。\n分区大小、起始位置、结束位置、文件系统等信息，都储存在分区表里面。\n分区表也分成两种格式：MBR 和 GPT。前者是传统格式，兼容性好；后者更现代，功能更强大。\nLogging in as Root in Ubuntu with Live CD $ sudo passwd root How To Download A Large File Faster From Google Drive? Step 1: Fetching Your File ID\n Open your browser and go to your google drive, open login with the account that has the file you wish to download. Locate the file that you wish to download and select it. Right click the file and click on “get shareable link” You don’t need to copy the entire link here; you only need the file ID that we will be using later.  The link will look like this: https://drive.google.com/file/d/XXXXX/view?usp=sharing\nIn this link, you only need to pay attention to the alphanumeric file ID, displayed by XXXXX here.\nStep 2: Getting an OAuth Code\n Visit OAuth 2.0 Playground by clicking here. On the developer’s webpage, in the “Select \u0026amp; authorize APIs” click on the “Drive API v3” option, and select the: https://www.googleapis.com/auth/drive.readonly option from the available options. Once selected click Authorize APIs button on the bottom right corner of the tab. After you click on the Authorize APIs button you will be transferred to the google account login screen. Select the same google account in which you have your file stored. Allow Google OAuth 2.0 to access your drive if asked. When you get redirected back to the OAuth 2.0 playground screen click on the “Exchange Authorization Code for Tokens” button as shown. Copy the newly generated Access Token and save it on your notepad. You will be needing this in the next step.  Step 3: Downloading The File Using A Command Line Script\n$ curl -H \u0026#34;Authorization: Bearer YYYYY\u0026#34; https://www.googleapis.com/drive/v3/files/XXXXX?alt=media -o ZZZZZ In your command, replace “XXXXX” with the file ID from above, “YYYYY” with the access token from above, and “ZZZZZ” with the file name that will be saved (for example, “myFile.mp4” if you’re downloading an mp4 file).\nPress Enter and let the download begin.\nUSB插槽鬆動怎麼辦  手机  充电宝  笔记本  笔记本  nmcheck.gnome.org nmcheck.gnome.org is not malware. It is the gnome network manager connectivity check (for captive portals/hotspots). Click the link and you will see a single text file with a text in it. It should be \u0026ldquo;NetworkManager is online\u0026rdquo;.\nCheck /etc/NetworkManager/NetworkManager.conf. There probably is a section with this in it:\n[Connectivity] uri=http://nmcheck.gnome.org/check_network_status.txt on Ubuntu 20.04 no [Connectivity]  line like accepted answer in /etc/NetworkManager/NetworkManager.conf.\nBut you can disable the auto connectivity check by:\n Go to Settings app Go to Privacy menu On Connectivity tab, uncheck Connectivity Checking  XDG_TEMPLATES_DIR If you drop any files in \u0026ldquo;Templates\u0026rdquo; folder. Then when you right-click and create a new document, you can select any of these files as a basis for the new file.\nIf you have deleted the folder and need to restore this functionality:\n$ gedit ~/.config/user-dirs.dirs Check that there is a line containing the following - if not, add this line.\nXDG_TEMPLATES_DIR=\u0026quot;$HOME/Templates\u0026quot; 软件的稳定性 软件的稳定性其实往往来源于：足够多的使用者与足够多的反馈跟改进。\nLinux系统，在服务器端的大多数常用软件都有足够多的使用者，所以就足够稳定，由于它在服务器端市场占有率远高于微软，所以服务器端就是比微软稳定，很正常的事。\n在桌面端，市场占用率远低于微软，不稳定也是自然的。\n为什么Linux下命令行程序往往又好用又稳定？是因为用户喜欢装逼吗？不是，因为命令行程序是服务器端跟桌面端通用的，而服务器端程序经过了足够多用户的使用，经过了足够的反馈开发迭代，所以稳定。而图形界面只有桌面用户用，桌面占有率那么低，这些程序往往缺乏足够的测试人力也缺乏足够的开发维护人力，所以并不会非常稳定。\n那么，你要想体验Linux稳定，怎么办？答案就是只使用市场占有率高，用户量大，因而获得了充分测试的软件，这就稳定了。比方说只使用服务器端。或者桌面端只使用最常用的那些，例如终端仿真器，浏览器，输入法，gcc编译器之类，肯定是稳定的。\n你看我就用浏览器，输入法，xterm，screen，编程ide，vim，以及一堆命令行的东西，稳定得很啊，六个月才重启一次电脑，重启的那一次还是因为ubuntu升级。\n如何将Google搜索限制为特定语言的结果 只是想在Google搜索中添加有关语言参数的更全面的答案。\n有4种与语言相关的选项。\nWeb界面语言： hl=\n例： www.google.com/search?q=vilnius\u0026amp;hl=lt\nWeb Interface Language Codes hl=zh-CN Chinese (Simplified) hl=zh-TW Chinese (Traditional) hl=en English hl=ja Japanese 指定语言的页面： lr=lang_\n例： www.google.com/search?q=vilnius\u0026amp;lr=lang_lt\nSearch Language Codes lr=lang_zh-CN Chinese (Simplified) lr=lang_zh-TW Chinese (Traditional) lr=lang_en English lr=lang_ja Japanese 来自指定国家/地区的页面： cr=country\n示例：www.google.com/search?q=vilnius\u0026amp;cr=countryLT 请注意，两个国家/地区代码字符必须大写！否则，Google会忽略该参数（自2017年1月3日起）（即使小写字母对于hl=和都适用lr=lang_）。\n还有另一个参数\u0026ndash; gl=用于搜索结果，因为它们将显示在指定的国家/地区。我尝试对其进行测试，但对我而言，不同参数值的结果没有不同。浏览器或我的Google帐户的某些其他参数/设置可能已过时或覆盖了该设置。\nTwo Options to Recover Your PC With Android If your PC is out of action, you can install a new operating system or run a recovery environment thanks to Android. Two solid options are available:\n ISO 2 USB: Lets you burn an ISO file directly to a USB flash drive over USB-OTG. DriveDroid: Enables you to store bootable ISO files on Android. With the paid version, support for Windows 10 installation images is added.  good practice to avoid using sudo su It is good practice to avoid performing more actions as root than you need to. sudo facilitates this by allowing you to run individual commands as root without having to log in as root and without needing an interactive root shell for tasks you would otherwise not run a shell to do. But sudo su is not a \u0026ldquo;backdoor,\u0026rdquo; it is simply a somewhat less elegant way to do what sudo is designed to allow you to do with sudo -s. Similarly, sudo -i is the more elegant way to achieve what sudo su - would get you: a simulated initial login shell whose environment is like what you would get if you could log in as root on the command line. See man sudo.\nSSHFS: How to Mount Remote File Systems Over SSH SSHFS (SSH File System) is a client for mounting a file system located on a remote machine onto your local system through an SSH connection. Using the SFTP (SSH file transfer protocol), the SSHFS command-line tool mounts a physical or virtual disk locally, allowing file transfer between a local and remote machine.\nThis article demonstrates the installation and usage of SSHFS to mount a remote folder or file system over SSH.\nInstall SSHFS $ sudo apt install sshfs Mount a Remote File System on Linux Step 1: Create Mount Point\nCreate a mount point directory in the mnt folder where the remote file system will be mounted:\n$ sudo mkdir /mnt/\u0026lt;folder name\u0026gt; Step 2: Mount the Remote File System Using SSHFS\nMount the remote file system to the created mount point using the SSHFS tool:\n$ sudo sshfs [-o \u0026lt;options\u0026gt;] \u0026lt;remote user\u0026gt;@\u0026lt;remote host\u0026gt;:/\u0026lt;path to remote directory\u0026gt; /mnt/\u0026lt;folder name\u0026gt;/ Enter the login password when requested if using password authentication. If the remote server uses SSH key authorization, provide the path of the private key. For example:\n$ sudo sshfs -o allow_other,IdentityFile=/home/kb/.ssh/id_rsa ubuntu@131.153.142.254:/home/ubuntu/ /mnt/test/ The allow_other option allows access to users other than root.\nStep 3: Unmount a Remote File System on Linux\nLastly, when finished with the mount point, unmount the remote file system with:\n$ sudo umount /mnt/\u0026lt;folder name\u0026gt; img转化成iso IMG是一种文件归档格式（archive format），主要是为了创建磁盘的映像文件（disk image），它可以用来封装存储整个磁盘（通常指软磁盘，Floppy Disk或Diskette）或整片光盘的内容，使用\u0026quot;.IMG\u0026quot;这个扩展名的文件就是利用这种文件格式来创建的。\n.IMG这个文件格式可视为.ISO格式的一种超集合。由于.ISO只能封存使用ISO9660和UDF这两种文件系统的存储介质，意即.ISO只能拿来封存CD或DVD，因此才发展出了.IMG，它是以.ISO格式为基础另外新增可封存使用其它文件系统的存储介质的能力，.IMG可向后兼容于.ISO，如果是拿来封存CD或DVD，则使用.IMG和.ISO这两种格式所产生出来的内容是一样的。\n将img 转化成iso的有 nrg2iso 或 ccd2iso，分别下载如下：\n$ sudo apt-get install nrg2iso $ sudo apt-get install ccd2iso 使用如下：\n$ nrg2iso image.nrg image.iso $ ccd2iso \u0026lt;.img filename\u0026gt; \u0026lt;.iso filename\u0026gt; HWE The Ubuntu LTS enablement (also called HWE or Hardware Enablement) stacks provide newer kernel and X support for existing Ubuntu LTS releases.\nThe 20.04 LTS HWE Stacks continue to follow Rolling Update Model, as has been in use since 16.04 LTS.\nMicrocode 每当听到有人说“这个问题更新一下微码就好了”，就觉得这个哥哥怎么这么迷人，好像在哪里见过。为了也让自己变成这种迷人的哥哥，我也研究了一下到底什么是微码。\n这里说的是跑在CPU处理器上的微码，不是IBM那群人嘴里说的那个微码。如果你之前没和IBM打过交道那就当这段话不存在。\n计算机体系结构是一层又一层的抽象，典型的比如操作系统对底层硬件的抽象。但鲜有人知的是，操作系统和底层硬件，尤其是CPU之间还存在着几层抽象。什么叫抽象，当然有很多种学术流的解释，但我土气一点的解释就是“不关心”，就是“Don’t care”，就是爱咋地咋地。\n用这个模式套用一下我们熟悉的抽象：操作系统要将数据写入磁盘，它不关心怎么操作磁盘；应用要给某个服务器发个数据包，它也不关心怎么操作网卡。\n回到我们的微码上来。我们现在常见的操作系统都是用C语言编写，它相对于汇编语言来说，也算是一种“高级语言”。编译器会将这种高级语言编译成汇编语言。只要C语言编写时“不关心”汇编指令是啥，那么就是相对汇编语言做了一次抽象。\n马上就到微码了。我们知道汇编指令是执行在CPU上的，那么汇编指令会关心在某个具体型号的CPU上是怎么执行的吗？肯定不会的。汇编的一条ADD指令在80286上可以执行，在最新的Icelake上也能执行，但这两个CPU内部早已发生了天翻地覆的变化，执行ADD的操作已经完全不同了。\n换句话说，就是汇编指令并“不关心”是如何在CPU上执行的。\n操作系统不关心如何操作磁盘和网卡，是因为这些都有对应的设备驱动操心。汇编指令不关心具体如何在CPU中执行，这个就是由微码来操心了。所以用类比的方式，可以把微码类比成汇编指令针对某一型号CPU的驱动。\n同样的汇编指令，会由该型号CPU的微码转成可以跑在该CPU上的微操作（Micro-ops/uops）。这些微操作指导CPU的电路完成汇编指令要求的意图。\n在大家还在编写汇编语言代码的时代，微码为汇编语言的编写提供了方便：\n 只关心汇编逻辑，而不用关心CPU内部电路设计和具体的执行方式 方便设计出新的汇编指令，由微码翻译成具体的执行逻辑，比如循环中“变量自减若大于零则转跳”，可以用一条汇编指令代替，脏活累活都交给微码去干 修复或绕过一些很难修复的处理器数字电路中的Bug  上述第二点也为CISC指令集的实现提供了技术基础。因为不可能所有复杂的指令都是由专门的执行复杂指令的硬件来完成的，也是由简单的数字逻辑模块组合而成的。\n在现代CPU里，是存在专门的将汇编指令翻译成微操作的硬件解码器的。但微码依旧存在（就是CPU微架构图中前端那个Microcode sequencer），它作为一个Lookup Table保存在一块ROM中，用来解码复杂的指令，比如浮点运算的指令等。一般是硬件解码器解码得比较快，而用微码解码会比较慢。\n理论上，如果你能更改某一个处理器的微码，那么经它翻译的指令可以变成任意其他的指令。因为它关心指令如何在CPU电路中执行。所以现在升级微码主要是用来解决处理器的稳定和安全性的问题。\n当然你也可以用它模拟自己没有的汇编指令，比如AVX系列，我只要在看到AVX512的汇编之后，把它翻译成两个“SIMD256”或者四个“SIMD128”指令就好了。\n看到这里，你给自己就又加了一层微码的buff。最后贴心地推荐一篇详细说明Microcode怎么执行的文章：Microprocessor Microcode Simple Example\n安装/更新微码 微码就是由 Intel/AMD 提供的 CPU 固件。Linux 的内核可以在引导时更新 CPU 固件，而无需 BIOS 更新。处理器的微码保存在内存中，在每次启动系统时，内核可以更新这个微码。这些来自 Intel/AMD 的微码的更新可以去修复 bug 或者使用补丁来防范 bug。\n查看当前的微码状态：\n$ sudo dmesg | grep microcode 使用包管理器\n$ sudo apt install intel-microcode 必须重启以激活微码更新：\n$ sudo reboot 手动\n只有在你的 CPU 制造商建议这么做的时候，才可以使用下列的方法去更新/安装微码，除此之外，都应该使用上面的方法去更新。大多数 Linux 发行版都可以通过包管理器来维护、更新微码。使用包管理器的方法是经过测试的，对大多数用户来说是最安全的方式。\nAutomatic Light / Dark Mode for GNOME, this shell extension exists: Night Theme Switcher\n将du的输出按文件大小排序 sdu () { du -sk $@ | sort -n | awk \u0026#39; BEGIN { split(\u0026#34;K,M,G,T\u0026#34;, Units, \u0026#34;,\u0026#34;); FS=\u0026#34;\\t\u0026#34;; OFS=\u0026#34;\\t\u0026#34;; } { u = 1; while ($1 \u0026gt;= 1024) { $1 = $1 / 1024; u += 1 } $1 = sprintf(\u0026#34;%.1f%s\u0026#34;, $1, Units[u]); sub(/\\.0/, \u0026#34;\u0026#34;, $1); print $0; }\u0026#39; } 改善触摸板体验 众所周知，Macbook 的触摸板是体验最好的，很多果粉都吹 Macbook 的触摸板用了之后“就不再想要去用鼠标”。\n有一群人搞了一个项目：「Linux Touchpad like Macbook Update」。顾名思义，就是“把 Linux 的触摸板搞的像 Macbook 一样”。\n这个项目的主要作用就是针对现在 Linux 下对于触摸板管理的相关驱动进行一些修改和优化，以提升触摸的使用体验，尤其是包括“多点触摸”等等等。\n$ sudo add-apt-repository ppa:p12/xorg-gestures $ sudo apt-get update 当然，尽管如此，我们也只是在驱动层面改善了触摸，在应用层面还需要另一个工具的帮忙：touchegg\n安装完毕之后你的三指上滑和三指下滑都可以正常使用了，譬如三指上滑是窗口最大化，三指下滑是窗口最小化。\nReset lost root password 警告： 攻击者都可以使用上述方法修改系统，要保证系统安全，请限制物理上的访问，或者使用全磁盘加密。\n使用 LiveCD 通过 LiveCD 可以使用好几种方法：chroot并且使用passwd命令或者擦除密码域条目。任何Linux的LiveCD都可以使用，chroot时它必须匹配已经安装的架构类型。这里仅介绍 chroot 方式，因为这个方法更不容易出错。\n  启动LiveCD，挂载根文件系统.\n  然后通过下列命令重置密码：\n$ passwd --root MOUNT_POINT USER_NAME   卸载根文件系统。\n  重启，记下你的密码。\n  用 Bash 作为 Init   将 init=/bin/bash 内核参数加入启动加载器的启动项.\n  启动后可以看到 Bash 提示符。\n  根文件系统应该是只读挂载，需要以可读写模式重新挂载：\nmount -n -o remount,rw /   用 passwd 创建新的管理员密码。\n  通过 reboot -f 重启，不要再次忘记你的密码。\n  注意： 使用此法时有的键盘不能被初始系统正确加载，你可能不能在bash提示符后输入任何东西。如果出现这种情况，你不得不使用其他方法。\nHow to block internet access to certain programs on Linux The solution for me happened to be straight forward.\n  Create, validate new group; add required users to this group:\n  Create: groupadd no-internet\n  Validate: grep no-internet /etc/group\n  Add user: useradd -g no-internet username\nNote: If you\u0026rsquo;re modifying already existing user you should run: usermod -a -G no-internet userName check with : sudo groups userName\n    Create a script in your path and make it executable:\n  Create: nano /home/username/.local/bin/no-internet\n  Executable: chmod 755 /home/username/.local/bin/no-internet\n  Content:\n#!/bin/bash sg no-internet \u0026quot;$@\u0026quot;     Add iptables rule for dropping network activity for group no-internet:\n  iptables -I OUTPUT 1 -m owner --gid-owner no-internet -j DROP\nNote: Don\u0026rsquo;t forget to make the changes permanent, so it would be applied automatically after reboot. Doing it, depends on your Linux distribution.\n    Check it, for example on Firefox by running: no-internet \u0026quot;firefox\u0026quot;\n  In case you would want to make an exception and allow a program to access local network:\n iptables -A OUTPUT -m owner --gid-owner no-internet -d 192.168.1.0/24 -j ACCEPT iptables -A OUTPUT -m owner --gid-owner no-internet -d 127.0.0.0/8 -j ACCEPT iptables -A OUTPUT -m owner --gid-owner no-internet -j DROP  NOTE: In case of spawning the rules will be maintained. For example, if you run a program with no-internet rule and that program will open browser window, still the rules will be applied.\nHow does Ubuntu make money? Firstly a lot of people work on Ubuntu in their free time (many of them programming, but also those of here for instance answering people\u0026rsquo;s questions). Also some people donate to Ubuntu.\nHowever there is more to the story. Canonical Ltd. is a private company that created and continues to pay for Ubuntu. We know Canonical hadn\u0026rsquo;t been making a profit, but Canonical was initially founded by multi-millionaire Mark Shuttleworth which meant it didn\u0026rsquo;t have to focus on making money right away.\nHowever Canonical is now looking towards to making Ubuntu profitable. (After all, they have 600+ employees to pay every month!) There are some indications this has been successful. Their key revenue streams offer services around Ubuntu:\n Support services (mostly to business) alongside which they sell Landscape Contracting services to businesses (for instance working with OEMs such as Dell, or helping Google with Chrome OS). As Ubuntu makes its way onto mobile phones and TVs then this will grow. Ubuntu Software Centre\u0026rsquo;s paid section (Canonical takes a cut of purchases) The Canonical Store (selling physical Ubuntu branded items) - discontinued Closed-source projects wishing to use Launchpad.net can purchase a license Ubuntu One (online file storage and synchronization service) and Music Store (selling music from within Ubuntu) - discontinued. Amazon referrals. When you search the Ubuntu Dash, you may see Amazon products (unless you have turned it off). Ubuntu takes a cut of these.[ref]  All of these are areas that Canonical hopes will grow.\n启用 TRIM 当我在运行 Linux 的计算机上安装我的第一块固态驱动器（SSD）后，我开始探索如何用好它们。SSD 在操作方式上与传统磁性驱动器不同，并且它们需要在软件上另行处理以达到功能优化。\n在传统磁盘驱动器上，删除时所删除的文件不会从磁盘中完全删除。这就是为什么你可以恢复已删除的文件的原因。基本上，文件系统仅引用磁盘上文件的位置，并且当文件被删除时，该引用被擦除，以允许你在这些空间中写入新数据覆盖原来的数据。然而，对于 SSD，新数据只能写在驱动器上完全新的或已擦除的单元上。因为必须在写入之前清除空间，如果在写入文件时尚未有足够的可用空间，则必须首先擦除该空间。这可能会对性能产生负面影响。\n如果操作系统在写入新数据之前就擦除了未使用的空间，而不是在写入时同时进行擦除，则可以提高文件保存性能。这种做法就是 TRIM。 TRIM 命令本质上允许你的操作系统告诉驱动器哪些区域的数据不再使用，以便擦除它们，加快驱动器将来的写入，可以 SSD 的用户提供更佳的体验。\n在 Linux 中，fstrim 提供此功能，它可以为写入新数据而准备驱动器，并延长驱动器的使用寿命。由于在我使用的 Linux 发行版上 SSD 的 trim 不是自动的，所以必须去调度该操作，否则 SSD 的性能会随着时间的推移而降低。\n为了在驱动器上运行 fstrim，驱动器本身以及其上的文件系统必须支持 TRIM。TRIM SSD 可以在命令行或 cron 任务中手动完成。作为超级用户（使用 su 或 sudo），运行 fstrim / -v 以完成手动 trim，或者设置 cron 任务以在计算机未使用时定期为你运行此命令。对于 fstrim 的完整选项列表请参考它的 man 手册。\n注：可以定期执行fstrim命令，但是不建议在mount / fstab 中使用discard 选项。因为这个选项要求SSD每次删除文件都进行trim操作，比较耗资源，尤其是在文件操作很频繁的时候。所以可以考虑用cron来定期trim。\n硬件支持根据使用的驱动器接口类型如 PCI、ATA、SCSI 还是 SD/MMC 而有所不同。你需要咨询你的 Linux 供应商以了解你的特定发行版是如何支持 TRIM 的。\n例如，红帽提供以下 SSD 磁盘指南。“性能随着所使用的块数接近磁盘容量而降低，性能影响程度因供应商而异，但是所有设备都会遇到一些性能降低。为了解决性能降低问题，主机系统（例如 Linux 内核）使用丢弃请求以通知存储器给定范围的块不再使用。”\nDebian wiki 提供了 SSD 使用的一些基本注意事项：使用 Linux 3.2 或更高版本内核，使用 SSD 的最新固件，使用 EXT4 文件系统，并且“在正常工作负载下有足够的 DRAM 用来操作而不用使用交换空间“。\nQUESTIONS Ubuntu 无法关机 $ sudo vim /etc/systemd/system.conf DefaultTimeoutStartSec=5s DefaultTimeoutStopSec=5s $ sudo systemctl reload DefaultTimeoutStartSec=, DefaultTimeoutStopSec= 设置启动/停止一个单元所允许的最大时长。若仅设置一个整数而没有单位，那么单位是秒。 也可以在整数后面加上时间单位后缀： \u0026ldquo;ms\u0026rdquo;(毫秒), \u0026ldquo;s\u0026rdquo;(秒), \u0026ldquo;min\u0026rdquo;(分钟), \u0026ldquo;h\u0026rdquo;(小时), \u0026ldquo;d\u0026rdquo;(天), \u0026ldquo;w\u0026rdquo;(周) 。 对于 Type=oneshot 类型的 service 单元， 这些选项没有意义(相当于全部被禁用)。 对于其他类型的 service 单元，可以在单元文件中设置 TimeoutStartSec=, TimeoutStopSec=, RestartSec= 以覆盖此处设置的默认值 (参见systemd.service(5))。 对于其他非 service 类型的单元， DefaultTimeoutStartSec= 是 TimeoutSec= 的默认值。\n注1：尽量不要使用上面更改。应该在完全清楚自己的更改造成的影响、产生的作用的前提下，做出更改。\n注2：作为桌面操作系统，如果有硬件驱动或其他各种莫名问题，可以尝试升级到最新版本来解决。\nACPI ERROR: AE_ALREADY_EXISTS These kinds of \u0026ldquo;errors\u0026rdquo; have been discussed ad nauseam, it\u0026rsquo;s simply the kernel telling you that the ACPI information received from the system seems to be incomplete in some way, update your BIOS/UEFI in hopes for a proper fix or ignore the error if you don\u0026rsquo;t notice anything off with your system.\n(And please don\u0026rsquo;t do something dumb like setting acpi=off just to get rid of these messages)\n解压zip乱码 $ unzip -O CP936 xxx.zip 用GBK, GB18030也可以\nCan\u0026rsquo;t run CS:GO at fullscreen  Open Steam Go to the \u0026ldquo;Library\u0026rdquo; Right-click the game which needs to be reconfigured Select \u0026ldquo;Properties\u0026rdquo; from the menu Click the \u0026ldquo;Set launch options\u0026hellip;\u0026rdquo; button type: -full and save  How To Disable Lock In Kubuntu open Workspace \u0026gt; Desktop Behavior \u0026gt; Screen Locking \u0026gt; uncheck Lock screen option\nGnome 3 displays two icons for same app No, there\u0026rsquo;s nothing wrong with your system.\nThe duplicated launcher icons explained:\nThe different icons are different commandline options. Some context applications with call the associated *.desktop icon. The exec option of the icon will depend on how the application is called.\nSome of the Icons you show in your image may be obvious because of the difference in the way they are named. You can see the difference in the way the app is called by right clicking and clicking on properties to see other differences.\nSome of the *.desktop files have a %U argument, used so the application will accept arguments.\nSome of the Launchers are different commands that are called differently and are named differently often by a symbolic link.\nSome exampes from the list in you image are:\nName: Online Accounts Command: unity-control-center credentials Name: Online Accounts Command: Online account credentials and settings Name: Personal File Sharing Command: gnome-file-share-properties Name: Rhythmbox Command: rhythmbox %U Name: Rhythmbox Command rhythmbox-client --select-source %U ssh_exchange_identification: Connection closed by remote host 原因是 Clash 开了 TUN 模式。关闭掉就好了。\n","permalink":"https://sakamotokurome.github.io/posts/ubuntu/","summary":"友邦拓 乌班图 During the first ten years of this HOWTO\u0026rsquo;s life, I reported that from a new user\u0026rsquo;s point of view, all Linux distributions are almost equivalent. But in 2006-2007, an actual best choice emerged: Ubuntu. While other distros have their own areas of strength, Ubuntu is far and away the most accessible to Linux newbies. Beware, though, of the hideous and nigh-unusable \u0026ldquo;Unity\u0026rdquo; desktop interface","title":"Ubuntu"},{"content":"Hexo Hexo 是一个快速、简洁且高效的博客框架。\n安装   安装 Git：\n Windows: Download \u0026amp; install git. Mac: Install it with Homebrew, MacPorts or installer. Linux (Ubuntu, Debian): sudo apt-get install git-core Linux (Fedora, Red Hat, CentOS): sudo yum install git-core    安装 node.js：\n Windows: Install it with nvs (recommended) or nvm. Mac: Install it with Homebrew or MacPorts. Linux (DEB/RPM-based): Install it with NodeSource. Others: Install it through respective package manager. Refer to the guide provided by Node.js.    安装 Hexo：-g 表示全局安装，会将 Hexo 命令加入环境变量中。\n$ npm --registry https://registry.npm.taobao.org install -g hexo-cli # 持久使用镜像 $ npm config set registry https://registry.npm.taobao.org Where do global npm packages get installed\n$ npm root -g   建站 $ hexo init [folder] $ cd \u0026lt;folder\u0026gt; $ npm install 新建完成后，指定文件夹的目录如下：\n. ├── node_modules\t//依赖安装目录 ├── scaffolds\t//模板文件夹，Hexo的模板是指在新建的文章文件中默认填充的内容。 | ├── draft.md\t//草稿模板 | ├── page.md\t//页面模板 | └── post.md\t//文章模板 ├── source\t//资源文件夹 | └── _posts\t//文章目录 ├── themes\t//主题文件夹，Hexo 会根据主题来生成静态页面。 | └── landscape\t//默认主题 ├── .gitignore\t//指定不纳入git版本控制的文件 ├── _config.yml\t//站点配置文件 ├── db.json ├── package.json\t//应用程序的信息 └── package-lock.json source：资源文件夹是存放用户资源的地方。除 _posts 文件夹之外，开头命名为 _ (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。\n配置 您可以在 _config.yml 中修改大部分的配置。\n网站    参数 描述     title 网站标题   subtitle 网站副标题   description 网站描述   keywords 网站的关键词。支持多个关键词。   author 您的名字   language 网站使用的语言。对于简体中文用户来说，使用不同的主题可能需要设置成不同的值，请参考你的主题的文档自行设置，常见的有 zh-Hans和 zh-CN。   timezone 网站时区。Hexo 默认使用您电脑的时区。请参考 时区列表 进行设置，如 America/New_York, Japan, 和 UTC 。一般的，对于中国大陆地区可以使用 Asia/Shanghai。    其中，description主要用于SEO，告诉搜索引擎一个关于您站点的简单描述，通常建议在其中包含您网站的关键词。author参数用于主题显示文章的作者。\n网址    参数 描述 默认值     url 网址, 必须以 http:// 或 https:// 开头    root 网站根目录 url's pathname   permalink 文章的 永久链接 格式 :year/:month/:day/:title/   permalink_defaults 永久链接中各部分的默认值    pretty_urls 改写 permalink 的值来美化 URL    pretty_urls.trailing_index 是否在永久链接中保留尾部的 index.html，设置为 false 时去除 true   pretty_urls.trailing_html 是否在永久链接中保留尾部的 .html, 设置为 false 时去除 (对尾部的 index.html无效) true     网站存放在子目录\n如果您的网站存放在子目录中，例如 http://example.com/blog，则请将您的 url 设为 http://example.com/blog 并把 root 设为 /blog/。\n 例如：\n# 比如，一个页面的永久链接是 http://example.com/foo/bar/index.html pretty_urls: trailing_index: false # 此时页面的永久链接会变为 http://example.com/foo/bar/ 目录    参数 描述 默认值     source_dir 资源文件夹，这个文件夹用来存放内容。 source   public_dir 公共文件夹，这个文件夹用于存放生成的站点文件。 public   tag_dir 标签文件夹 tags   archive_dir 归档文件夹 archives   category_dir 分类文件夹 categories   code_dir Include code 文件夹，source_dir 下的子目录 downloads/code   i18n_dir 国际化（i18n）文件夹 :lang   skip_render 跳过指定文件的渲染。匹配到的文件将会被不做改动地复制到 public 目录中。您可使用 glob 表达式来匹配路径。     例如：\nskip_render: \u0026#34;mypage/**/*\u0026#34; # 将会直接将 `source/mypage/index.html` 和 `source/mypage/code.js` 不做改动地输出到 \u0026#39;public\u0026#39; 目录 # 你也可以用这种方法来跳过对指定文章文件的渲染 skip_render: \u0026#34;_posts/test-post.md\u0026#34; # 这将会忽略对 \u0026#39;test-post.md\u0026#39; 的渲染  提示\n如果您刚刚开始接触 Hexo，通常没有必要修改这一部分的值。\n 文章    参数 描述 默认值     new_post_name 新文章的文件名称 :title.md   default_layout 预设布局 post   auto_spacing 在中文和英文之间加入空格 false   titlecase 把标题转换为 title case false   external_link 在新标签中打开链接 true   external_link.enable 在新标签中打开链接 true   external_link.field 对整个网站（site）生效或仅对文章（post）生效 site   external_link.exclude 需要排除的域名。主域名和子域名如 www 需分别配置 []   filename_case 把文件名称转换为 (1) 小写或 (2) 大写 0   render_drafts 显示草稿 false   post_asset_folder 启动 Asset 文件夹 false   relative_link 把链接改为与根目录的相对位址 false   future 显示未来的文章 true   highlight 代码块的设置, 请参考 Highlight.js 进行设置    prismjs 代码块的设置, 请参考 PrismJS 进行设置      相对地址\n默认情况下，Hexo 生成的超链接都是绝对地址。例如，如果您的网站域名为 example.com,您有一篇文章名为 hello，那么绝对链接可能像这样：http://example.com/hello.html，它是绝对于域名的。相对链接像这样：/hello.html，也就是说，无论用什么域名访问该站点，都没有关系，这在进行反向代理时可能用到。通常情况下，建议使用绝对地址。\n 分类 \u0026amp; 标签    参数 描述 默认值     default_category 默认分类 uncategorized   category_map 分类别名    tag_map 标签别名     日期 / 时间格式 Hexo 使用 Moment.js 来解析和显示时间。\n   参数 描述 默认值     date_format 日期格式 YYYY-MM-DD   time_format 时间格式 HH:mm:ss   updated_option 当 Front Matter 中没有指定 updated 时 updated 的取值 mtime     updated_option\nupdated_option 控制了当 Front Matter 中没有指定 updated 时，updated 如何取值：\n mtime: 使用文件的最后修改时间。这是从 Hexo 3.0.0 开始的默认行为。 date: 使用 date 作为 updated 的值。可被用于 Git 工作流之中，因为使用 Git 管理站点时，文件的最后修改日期常常会发生改变 empty: 直接删除 updated。使用这一选项可能会导致大部分主题和插件无法正常工作。  use_date_for_updated 选项已经被废弃，将会在下个重大版本发布时去除。请改为使用 updated_option: 'date'。\n use_date_for_updated` | 启用以后，如果 Front Matter 中没有指定 `updated`， [`post.updated`](https://hexo.io/zh-cn/docs/configuration) 将会使用 `date` 的值而不是文件的创建时间。在 Git 工作流中这个选项会很有用 | `true 分页    参数 描述 默认值     per_page 每页显示的文章量 (0 = 关闭分页功能) 10   pagination_dir 分页目录 page    扩展    参数 描述     theme 当前主题名称。值为false时禁用主题   theme_config 主题的配置文件。在这里放置的配置会覆盖主题目录下的 _config.yml 中的配置   deploy 部署部分的设置   meta_generator Meta generator 标签。 值为 false 时 Hexo 不会在头部插入该标签    包括或不包括目录和文件\n在 Hexo 配置文件中，通过设置 include/exclude 可以让 Hexo 进行处理或忽略某些目录和文件夹。你可以使用 glob 表达式 对目录和文件进行匹配。\ninclude and exclude options only apply to the source/ folder, whereas ignore option applies to all folders.\n   参数 描述     include Hexo 默认会忽略隐藏文件和文件夹（包括名称以下划线和 . 开头的文件和文件夹，Hexo 的 _posts 和 _data 等目录除外）。通过设置此字段将使 Hexo 处理他们并将它们复制到 source 目录下。   exclude Hexo 会忽略这些文件和目录   ignore Ignore files/folders    举例：\n# Include/Exclude Files/Folders include: - \u0026#34;.nojekyll\u0026#34; # 包括 \u0026#39;source/css/_typing.css\u0026#39; - \u0026#34;css/_typing.css\u0026#34; # 包括 \u0026#39;source/_css/\u0026#39; 中的任何文件，但不包括子目录及其其中的文件。 - \u0026#34;_css/*\u0026#34; # 包含 \u0026#39;source/_css/\u0026#39; 中的任何文件和子目录下的任何文件 - \u0026#34;_css/**/*\u0026#34; exclude: # 不包括 \u0026#39;source/js/test.js\u0026#39; - \u0026#34;js/test.js\u0026#34; # 不包括 \u0026#39;source/js/\u0026#39; 中的文件、但包括子目录下的所有目录和文件 - \u0026#34;js/*\u0026#34; # 不包括 \u0026#39;source/js/\u0026#39; 中的文件和子目录下的任何文件 - \u0026#34;js/**/*\u0026#34; # 不包括 \u0026#39;source/js/\u0026#39; 目录下的所有文件名以 \u0026#39;test\u0026#39; 开头的文件，但包括其它文件和子目录下的单文件 - \u0026#34;js/test*\u0026#34; # 不包括 \u0026#39;source/js/\u0026#39; 及其子目录中任何以 \u0026#39;test\u0026#39; 开头的文件 - \u0026#34;js/**/test*\u0026#34; # 不要用 exclude 来忽略 \u0026#39;source/_posts/\u0026#39; 中的文件。你应该使用 \u0026#39;skip_render\u0026#39;，或者在要忽略的文件的文件名之前加一个下划线 \u0026#39;_\u0026#39; # 在这里配置一个 - \u0026#34;_posts/hello-world.md\u0026#34; 是没有用的。 ignore: # Ignore any folder named \u0026#39;foo\u0026#39;. - \u0026#34;**/foo\u0026#34; # Ignore \u0026#39;foo\u0026#39; folder in \u0026#39;themes/\u0026#39; only. - \u0026#34;**/themes/*/foo\u0026#34; # Same as above, but applies to every subfolders of \u0026#39;themes/\u0026#39;. - \u0026#34;**/themes/**/foo\u0026#34; 列表中的每一项都必须用单引号或双引号包裹起来。\ninclude 和 exclude 并不适用于 themes/ 目录下的文件。如果需要忽略 themes/ 目录下的部分文件或文件夹，可以使用 ignore 或在文件名之前添加下划线 _。\n使用代替配置文件\n可以在 hexo-cli 中使用 --config 参数来指定自定义配置文件的路径。你可以使用一个 YAML 或 JSON 文件的路径，也可以使用逗号分隔（无空格）的多个 YAML 或 JSON 文件的路径。例如：\n# use \u0026#39;custom.yml\u0026#39; in place of \u0026#39;_config.yml\u0026#39; $ hexo server --config custom.yml # use \u0026#39;custom.yml\u0026#39; \u0026amp; \u0026#39;custom2.json\u0026#39;, prioritizing \u0026#39;custom3.yml\u0026#39;, then \u0026#39;custom2.json\u0026#39; $ hexo generate --config custom.yml,custom2.json,custom3.yml 当你指定了多个配置文件以后，Hexo 会按顺序将这部分配置文件合并成一个 _multiconfig.yml。如果遇到重复的配置，排在后面的文件的配置会覆盖排在前面的文件的配置。这个原则适用于任意数量、任意深度的 YAML 和 JSON 文件。\n例如，使用 --options 指定了两个自定义配置文件：\n$ hexo generate --config custom.yml,custom2.json 如果 custom.yml 中指定了 foo: bar，在 custom2.json 中指定了 \u0026quot;foo\u0026quot;: \u0026quot;dinosaur\u0026quot;，那么在 _multiconfig.yml 中你会得到 foo: dinosaur。\n使用代替主题配置文件\n通常情况下，Hexo 主题是一个独立的项目，并拥有一个独立的 _config.yml 配置文件。\n除了自行维护独立的主题配置文件，你也可以在其它地方对主题进行配置。\n配置文件中的 theme_config\n 该特性自 Hexo 2.8.2 起提供\n # _config.yml theme: \u0026#34;my-theme\u0026#34; theme_config: bio: \u0026#34;My awesome bio\u0026#34; foo: bar: \u0026#39;a\u0026#39; # themes/my-theme/_config.yml bio: \u0026#34;Some generic bio\u0026#34; logo: \u0026#34;a-cool-image.png\u0026#34; foo: baz: \u0026#39;b\u0026#39; 最终主题配置的输出是：\n{ bio: \u0026#34;My awesome bio\u0026#34;, logo: \u0026#34;a-cool-image.png\u0026#34;, foo: { bar: \u0026#34;a\u0026#34;, baz: \u0026#34;b\u0026#34; } } 独立的 _config.[theme].yml 文件\n 该特性自 Hexo 5.0.0 起提供\n 独立的主题配置文件应放置于站点根目录下，支持 yml 或 json 格式。需要配置站点 _config.yml 文件中的 theme 以供 Hexo 寻找 _config.[theme].yml 文件。\n# _config.yml theme: \u0026#34;my-theme\u0026#34; # _config.my-theme.yml bio: \u0026#34;My awesome bio\u0026#34; foo: bar: \u0026#39;a\u0026#39; # themes/my-theme/_config.yml bio: \u0026#34;Some generic bio\u0026#34; logo: \u0026#34;a-cool-image.png\u0026#34; foo: baz: \u0026#39;b\u0026#39; 最终主题配置的输出是：\n{ bio: \u0026#34;My awesome bio\u0026#34;, logo: \u0026#34;a-cool-image.png\u0026#34;, foo: { bar: \u0026#34;a\u0026#34;, baz: \u0026#34;b\u0026#34; } }  我们强烈建议你将所有的主题配置集中在一处。如果你不得不在多处配置你的主题，那么这些信息对你将会非常有用：Hexo 在合并主题配置时，Hexo 配置文件中的 theme_config 的优先级最高，其次是 _config.[theme].yml 文件，最后是位于主题目录下的 _config.yml 文件。\n 指令   version 显示 Hexo 版本：\nhexo version   list 列出网站资料：\nhexo list   新建一篇文章：如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。\nhexo new [layout] \u0026lt;title\u0026gt; hexo n [layout] \u0026lt;title\u0026gt;   Hexo 有三种默认布局：\n   布局 路径     post source/_posts   page source   draft source/_drafts      预览草稿，publish 发表草稿：\nhexo server --draft hexo publish [layout] \u0026lt;filename\u0026gt;   clean 清除缓存文件 (db.json) 和已生成的静态文件 (public)：\nhexo clean   generate 生成静态文件：\nhexo generate hexo g   启动 hexo 的内置 Web 服务器：该命令将会调用 Markdown 引擎解析项目中的博客内容生成网页资源，资源将会存于内存中。\nhexo server hexo s --debug\t# 开启调试模式（--debug） hexo s --port 8000\t# 添加 -p / --port 参数来设置 Web 服务监听的端口号 hexo s --static\t# 加 -s / --static 参数，本地改动不触发 hexo 实时解析更新。   deploy 部署网站：\nhexo deploy hexo d   写作   Front-matter： 是文件最上方以 --- 分隔的区域，用于指定个别文件的变量\n--- layout: # 布局 title: # 标题 date: # 建立日期 updated: # 更新日期 comments: # 开启文章的评论功能 tags:\t# 标签 - 标签1 - 标签2 categories: [分类1, 分类2]\t# 分类, 不适用与分页 permalink: # 覆盖文章网址 --- 标签是一种列表结构，而分类是一种树结构。\n  文本居中标签：在引用单行文本时使用\n\u0026lt;blockquote class=\u0026quot;blockquote-center\u0026quot;\u0026gt;blah blah blah\u0026lt;/blockquote\u0026gt;\t# HTML方式 {% centerquote %}blah blah blah{% endcenterquote %}\t# 标签方式 {% cq %} blah blah blah {% endcq %}\t# 标签别名   引用块\n{% blockquote [author[, source]] [link] [source_link_title] %} content {% endblockquote %}   代码块\n``` [language] [title] [url] [link text] code snippet  - `langugae`：语言名称，引导渲染引擎正确解析并高亮显示关键字 - `title`：代码块标题，将会显示在左上角 - `url`：链接地址，如果没有指定 link text 则会在右上角显示 link - `link text`：链接名称，指定 url 后有效，将会显示在右上角 - 如果设置语言为 diff，可以在代码前添加 `+` 和 `-` 来使用如上所示的高亮增删行提示效果，在展示代码改动痕迹时比较实用。   note 标签：通过 note 标签可以为段落添加背景色\n{% note [class] %} 文本内容 (支持行内标签) {% endnote %}  支持的 class 种类包括 default、primary、success、info、warning、danger    label 标签：通过 label 标签可以为文字添加背景色\n{% label [class]@text %}  支持的 class 种类包括 default、primary、success、info、warning、danger    button 按钮：通过 button 标签可以快速添加带有主题样式的按钮\n{% button /path/to/url/, text, icon [class], title %} {% btn /path/to/url/, text, icon [class], title %}   tab 标签：tab 标签用于快速创建 tab 选项卡\n{% tabs [Unique name], [index] %} \u0026lt;!-- tab [Tab caption]@[icon] --\u0026gt; 标签页内容（支持行内标签） \u0026lt;!-- endtab --\u0026gt; {% endtabs %}  Unique name: 全局唯一的 Tab 名称，将作为各个标签页的 id 属性前缀 index: 当前激活的标签页索引，如果未定义则默认选中显示第一个标签页，如果设为 - 1 则默认隐藏所有标签页 Tab caption: 当前标签页的标题，如果不指定则会以 Unique name 加上索引作为标题 icon: 在标签页标题中添加 Font awesome 图标    引用站内链接\n{% post_path slug %} {% post_link slug [title] %}  slug 表示 _post 目录下的 Markdown 文件名。 post_path 标签将会渲染为文章的地址，即 permalink；而 post_link 标签将会渲染为链接，可以通过 title 指定链接标题。    插入 Swig 代码：通过 raw 标签来禁止 Markdown 引擎渲染标签内的内容。该标签通常用于在页面内引入三方脚本实现特殊功能。\n{% raw %} content {% endraw %}   插入 Gist\n{% gist gist_id [filename] %}  gist_id: Gist 仓库页面 url 中最后一段随机字符串 filename: Gist 中的文件名，如果 Gist 中只有一个文件，可以不用指定 filename，如果 Gist 中有多个文件，可以在标签内输入 filename 来指定只引入某个文件，如果没有指定 filename，将会引入 Gist 中的所有文件。    插入图片：\n  Markdown 并不会保存插入的图片资源本身，只是记录了获取资源的链接。\n  相对路径引用的标签插件\n{% asset_img slug [title] %}   slug 是资源文件夹下的图片名\n  Embedding an image using markdown：allows you to embed an image in markdown without using asset_img tag plugin.\npost_asset_folder: true marked: prependRoot: true postAsset: true ![](image.jpg) will be rendered as \u0026lt;img src=\u0026quot;/2020/01/02/foo/image.jpg\u0026quot;\u0026gt;.\n    用Typora编写Hexo博客时能实预览图片\n  思路是在before_post_render阶段将markdown文件中图片的路径转换为asset_img函数。\nnpm install hexo-image-link --save       文章加密\n  Install\nnpm install --save hexo-blog-encrypt   Quick start: Add the \u0026ldquo;password\u0026rdquo; value to your post\u0026rsquo;s front matter like\n--- password: mikemessi ---     Hexo 添加文章时自动打开编辑器\n  在 Hexo 目录下的 scripts 目录中创建一个 JavaScript 脚本文件。通过这个脚本，我们用其来监听 hexo new 这个动作，并在检测到 hexo new 之后，执行编辑器打开的命令。\n  将下列内容写入你的脚本\nvar spawn = require('child_process').exec; hexo.on('new', function(data){ spawn('start \u0026quot;markdown编辑器绝对路径.exe\u0026quot; ' + data.path); });     文章置顶\n--- sticky: true ---   资源文件夹 资源（Asset）代表 source 文件夹中除了文章以外的所有文件。\n文章资源文件夹\npost_asset_folder: true 当资源文件管理功能打开后，Hexo将会在你每一次通过 hexo new [layout] \u0026lt;title\u0026gt; 命令创建新文章时自动创建一个文件夹。这个资源文件夹将会有与这个文章文件一样的名字。将所有与你的文章有关的资源放在这个关联文件夹中之后，你可以通过相对路径来引用它们。\n部署 持续集成（Continuous Integration，简称 CI）\nSimply Push to Deploy：热部署，只需要将代码 push 到 Git 远程仓库即可自动构建及更新。\nNetlify\nGitHub Action：\n  Add your ssh key pair\n  Run the following terminal command, replacing the email with one connected to your GitHub account.\nssh-keygen -t rsa -C \u0026#34;username@example.com\u0026#34; Windows 下自定义 ssh key 文件需写成 GIT\\BlogSrc/.ssh/id_rsa\n  In Github Pages repo: Add the contents of the public key（id_rsa.pub） within your repositories deploy keys menu. You can find this option by going to Settings \u0026gt; Deploy Keys, you can name the public key whatever you want, but you do need to give it write access.\n  In hexo source code repo: Add the contents of the private key（id_rsa） to the Settings \u0026gt; Secrets menu as DEPLOY_KEY.\n    Configure github workflows：Create a workflow .yml file in your .github/workflows directory.\nname: Deploy on: [push] jobs: build: runs-on: ubuntu-latest name: A job to deploy blog. steps: - name: Checkout uses: actions/checkout@v1 with: submodules: true # Checkout private submodules(themes or something else). # Caching dependencies to speed up workflows. (GitHub will remove any cache entries that have not been accessed in over 7 days.) - name: Cache node modules uses: actions/cache@v1 id: cache with: path: node_modules key: ${{ runner.os }}-node-${{ hashFiles(\u0026#39;**/package-lock.json\u0026#39;) }} restore-keys: | ${{ runner.os }}-node- - name: Install Dependencies if: steps.cache.outputs.cache-hit != \u0026#39;true\u0026#39; run: npm ci # Deploy hexo blog website. - name: Deploy id: deploy uses: sma11black/hexo-action@v1.0.3 with: deploy_key: ${{ secrets.DEPLOY_KEY }} user_name: your github username  # (or delete this input setting to use bot account) user_email: your github useremail  # (or delete this input setting to use bot account) commit_msg: ${{ github.event.head_commit.message }}  # (or delete this input setting to use hexo default settings) # Use the output from the `deploy` step(use for test action) - name: Get the output run: | echo \u0026#34;${{ steps.deploy.outputs.notify }}\u0026#34;   一键部署\n  新建一个空的 repository（没有init任何内容）。你的 repository 必须直接命名为 \u0026lt;你的 GitHub 用户名.github.io\u0026gt;。从而能通过 \u0026lt;你的 GitHub 用户名.github.io\u0026gt; 域名直接访问你的blog。\n  安装 hexo-deployer-git。\nnpm install hexo-deployer-git --save   修改_config.yml配置。\ndeploy: type: git repo: git@github.com:yourname/yourname.github.io.git branch: master   生成站点文件并推送至远程库。执行 hexo clean \u0026amp; hexo deploy。\n  登入 Github，在库设置（Repository Settings）中将默认分支设置为_config.yml配置中的分支名称。稍等片刻（Blog 不会立马加载出来，需多刷新几下），您的站点就会显示在您的Github Pages中。\n  这是如何发生的：当执行 hexo deploy 时，Hexo 会将 public 目录中的文件和目录推送至 _config.yml 中指定的远端仓库和分支中，并且完全覆盖该分支下的已有内容。\n  部署分支与写作分支：hexo d 部署到 GitHub 的是 hexo 编译后的文件，不包含源文件。可以利用git的分支管理，将源文件上传到 GitHub。一个好的实践是放在两个不同的 Git 仓库中。\n  主题 创建 Hexo 主题非常容易，您只要在 themes 文件夹内，新增一个任意名称的文件夹，并修改 _config.yml 内的 theme 设定，即可切换主题。\n _config.yml：主题的配置文件。和 Hexo 配置文件不同，主题配置文件修改时会自动更新，无需重启 Hexo Server。 languages：语言文件夹。 layout：布局文件夹。 scripts：脚本文件夹。 source：资源文件夹。  在 GitHub 搜索 Hexo 即可找到流行的 Hexo 主题。各主题都有相应的使用文档。\n其他 列表之后不能立即接一个代码块，否则会解析出错。如\n- ```bash code... ``` 一行代码没有问题\n- `code` 首页展示最新博客 index_generator: path: \u0026#39;\u0026#39; per_page: 10 - order_by: -date + order_by: {updated: -1}  -updated_option: \u0026#39;mtime\u0026#39; +updated_option: \u0026#39;date\u0026#39; Are there more order options?\n  Api Document：https://hexojs.github.io/warehouse/Query.html#sort\n  sort(orderby, orderopt) → {Query}\n  Example:\nquery.sort('date', -1); query.sort({date: -1, title: 1}); query.sort('-date title');   If the order equals to -1, desc or descending, the data will be returned in reversed order.\n  Parameters:\n   Name Type Attributes     orderby String Object   order String Number        Sort is to sort the object properties (Page-Variables), refer to the above document for details。\n   Variable Description Type     page.title Article title string   page.date Article created date Moment.js object   page.updated Article last updated date Moment.js object      hexo-generator-index\nconst posts = locals.posts.sort(config.index_generator.order_by);   updated_option\nupdated_option 控制了当 Front Matter 中没有指定 updated 时，updated 如何取值：\n mtime: 使用文件的最后修改时间。这是从 Hexo 3.0.0 开始的默认行为。 date: 使用 date 作为 updated 的值。可被用于 Git 工作流之中，因为使用 Git 管理站点时，文件的最后修改日期常常会发生改变 empty: 直接删除 updated。使用这一选项可能会导致大部分主题和插件无法正常工作。    NexT Getting Started Installation\n  Installation\ncd hexo-site npm install hexo-theme-next   Usage, theme config file\ntheme: next   Update\ncd hexo-site npm update hexo-theme-next   Configuration\nInstalled through npm\ncp node_modules/hexo-theme-next/_config.yml _config.next.yml Theme Settings Choosing Scheme:\nBy using Scheme NexT gives you different views. And nearly all config can be used by those Schemes.\n# next/_config.yml scheme: Muse Configuring Favicon:\nBy default the Hexo site use NexT favicons in hexo-site/themes/next/source/images/ directory with different size for different device.\nYou can replace them with your own favicons.\nFor example, you can put your favicons in hexo-site/source/images/ directory. Then you need to rename them and change the settings in favicon section in theme config file.\nCreative Commons:\nNexT supports the display of Creative Commons 4.0 International License in sidebar and post.\n# next/_config.yml creative_commons: license: by-nc-sa sidebar: true post: false language: en 通行的版权协议是一种限制性的协议，就是说，只有它明文许可你可以做的事，你才能做，否则就是侵权行为。\n而\u0026quot;开放内容许可证\u0026quot;（open content licenses）只明文禁止使用者不能做的事，除此以外，可以随意使用这些作品。创作共用许可证（Creative Commons licenses，简称cc），就是这样一种许可证。\n使用创作共用许可证，作者可以选择保留四种权利：\n 署名（Attribution，简写为by）：必须提到原作者。 非商业用途（Noncommercial，简写为nc）：不得用于盈利性目的。 禁止演绎（No Derivative Works，简写为nd）：不得修改原作品。 相同方式共享（Share Alike，简写为sa）：如果允许修改原作品，那么必须使用相同的许可证发布。  Configuring Menu Items:\nMenu settings items have format Key: /link/ || icon which contains 3 values:\n Key → is the name of menu item (home, archives, etc.). /link/ → is the target link to relative url inside your site. icon → is the name of Font Awesome icon.  To customize menu items, edit the following content in theme config file\nmenu: home: / || fa fa-home about: /about/ || fa fa-user tags: /tags/ || fa fa-tags archives: /archives/ || fa fa-archive Google Calendar Page\nschedule: /schedule/ || fa fa-calendar sitemap：为了让博文被google或百度检索，需要使用hexo的sitemap功能。\nsitemap: /sitemap.xml || fa fa-sitemap   Install\nnpm install hexo-generator-sitemap --save   Hexo Config\nsitemap: path: sitemap.xml   Except home and archives, all custom pages under menu section need to be created manually!\nSidebar Setting\nConfiguring Avatar：\nPut your avatar under site directory source/uploads/ (create directory if it doesn\u0026rsquo;t exists).And then change option to url: /uploads/avatar.png.\navatar: url: /uploads/avatar.png rounded: true 点击头像回到首页：\n主要是将\u0026lt;img class=\u0026quot;site-author-image\u0026quot; ... /\u0026gt;加入到\u0026lt;a href=\u0026quot;/\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;。\nSidebar Social Links：\n  Edit the social section in theme config file as following:\nsocial: GitHub: https://github.com/yourname || fab fa-github E-Mail: mailto:yourname@example.com || fa fa-envelope   取消社交图标前的小圆点：\n# create hexo-site/source/_data/styles.styl .links-of-author a, .links-of-author .exturl { \u0026amp;:before { display: none; } }   Sidebar Blogrolls (友链):\nlinks: Title1: https://example.com/ Sidebar TOC:\ntoc: number: false expand_all: true max_depth: 5 Footer\nSite Footer Icon:\nBy default NexT shows red heart icon between year and copyright information in the footer.\nfooter: icon: animated: true Site Copyright Name:\nBy default NexT shows the name of author from site config file.\nfooter: copyright: YourName Site Platform Information:\nBy default NexT shows Hexo and Theme \u0026amp; scheme information.\nfooter: powered: false Site Beian Information:\nBeian information is for Chinese users.\nfooter: beian: enable: true icp: 京ICP备 1234567890号-1 gongan_id: 1234567890 gongan_num: 京公网安备 1234567890号 gongan_icon_url: /uploads/beian.png Post Settings\nPreamble Text:\nYou can use following ways to show summary of articles and a Read More button.\nUse \u0026lt;!-- more --\u0026gt; in your article to break your article manually, which is recommended by Hexo. (recommended)\nIf you have added description and set its value to your article summary in front-matter, NexT excerpts description as preamble text in homepage by default. Without description, the full contents would be the preamble text in homepage.\nPost Wordcount:\n  Installation\ncd hexo-site npm install hexo-word-counter hexo clean   Hexo Config\nsymbols_count_time: total_symbols: false\t# By default NexT shows the number of all posts words in footer section. total_time: false\t# By default NexT shows the estimated reading time of all posts in footer section.    Donate Settings:\n  Get your WeChat / Alipay receive money QRcode image(s) and put into source/images .\n  Set needed values in theme config file:\nreward_settings: enable: true animation: false comment: Buy me a coffee reward: wechatpay: /images/wechatpay.png alipay: /images/alipay.png   Follow Me:\nfollow_me: WeChat: /images/wechat_channel.jpg || fab fa-weixin RSS: /atom.xml || fa fa-rss  安装RSS插件  npm i hexo-generator-feed  配置站点配置文件(/_config.yml)的Extensions  plugin: - hexo-generator-feed # Feed Atom feed: type: atom path: atom.xml limit: 20  编辑主题配置文件(/theme/next/_config.yml)的social links，开启RSS的页面功能  rss: /atom.xml  关注RSS：把 https://vanehsiung.github.io/atom.xml 复制到RSS阅读器上，就能关注了。  Custom Pages\nCustom Page Support:\n  Adding New Page\ncd hexo-site hexo new page tags   Setting Front-matter Values\n--- title: Tags date: title: 2020-11-14 22:50:2 type: \u0026quot;tags\u0026quot; ---   Editting Menu\nmenu: tags: /tags/ || fa fa-tags   Custom 404 Page:\n  Create a new page called 404\ncd hexo-site hexo new page 404 --- title: 404 permalink: /404.html\t# 在 Github Docs 中 Github Pages 章有写 comments: false ---   Make sure relative_link is disabled in site config file\nrelative_link: false   Whether users can be redirected to the 404 page depends on the settings of the website hosting service or web server, not Hexo.\n  为 GitHub Pages 站点创建自定义 404 页面\n  Misc Theme Settings\nMobile Devices Adaptation:\nreduce padding/margin indents on devices with narrow width\nmobile_layout_economy: true Codeblock Style:\nNexT uses the Highlight.js and Prism package to support code highlight\n  Read Hexo\u0026rsquo;s documentation on Syntax Highlighting first, and set it up in site config file（在 _config.yml 中开启 Highlight 或 Prism）\nhighlight: enable: true   Preview all available Code Highlight themes here: NexT Highlight Theme Preview\n  Change the value of theme and prism to choose the highlight style you like\ntheme: light: xcode   NexT supports the copy-and-paste functionality of codeblock\ncodeblock: copy_button: enable: true style: mac\t# Mac Panel风格代码块 Back To Top:\nback2top: scrollpercent: true Fonts Customization：\nfont: enable: true host: https://fonts.loli.net global: family: Architects Daughter, Ma Shan Zheng codes: family: Share Tech Mono   host：查看字体与使用字体的网址是不一样的；可能不能查看字体，但可以使用字体\n  查看 Google Fonts，使用 Google Fonts https://fonts.googleapis.com，以下为镜像\n  https://fonts.loli.net\n  https://fonts.googleapis.cnpmjs.org\n  https://fonts.proxy.ustclug.org\n      查看谷歌字体中文版，使用 https://fonts.font.im\n  技巧：先放 latin 文字，再放 chinese 文字，就可以分别定制英文与中文（有些中文字体包含英文字母）。手机无法显示自定义的中文字体，但可以显示自定义的英文字体。\n  SEO\nSEO Setting:\nNext provides useful options for better Search Engine Optimization (SEO).\nBy default a canonical link tag is created in Hexo after you have set up your URL url: http://example.com in site config file.\n# theme config file disable_baidu_transformation: true index_with_subtitle: true exturl: true Webmaster Tools:\n  Google Webmaster Tools\n  Login to Google Webmaster Tools and go to verification methods and choose HTML Tag, you will get some code:\n\u0026lt;meta name=\u0026quot;google-site-verification\u0026quot; content=\u0026quot;XXXXXXXXXXXXXXXXXXXXXXX\u0026quot;\u0026gt;   Copy XXXXXXXXXXXXXXXXXXXXXXX value of content key.Edit theme config file and add or change google_site_verification section:\ngoogle_site_verification: XXXXXXXXXXXXXXXXXXXXXXX   submit sitemap\n  That the new console says \u0026lsquo;couldnt fetch\u0026rsquo; is a bug in the console. Pending is the real status!\n    Bing Webmaster Tools\n  Login to Bing Webmaster Tools and go to verification methods and choose HTML Tag, you will get some code:\n\u0026lt;meta name=\u0026quot;msvalidate.01\u0026quot; content=\u0026quot;XXXXXXXXXXXXXXXXXXXXXXX\u0026quot;\u0026gt;   Copy XXXXXXXXXXXXXXXXXXXXXXX value of content key. Edit theme config file and add or change bing_site_verification section:\nbing_site_verification: XXXXXXXXXXXXXXXXXXXXXXX   submit sitemap\n  Bing 收录最快，立马就可以看到\n    Baidu Webmaster Tools\n  Login to Baidu Webmaster Tools and go to verification methods and choose HTML Tag, you will get some code:\n\u0026lt;meta name=\u0026quot;baidu-site-verification\u0026quot; content=\u0026quot;XXXXXXXXXXXXXXXXXXXXXXX\u0026quot;\u0026gt;   Copy XXXXXXXXXXXXXXXXXXXXXXX value of content key.Edit theme config file and add or change baidu_site_verification section:\nbaidu_site_verification: XXXXXXXXXXXXXXXXXXXXXXX   Push the url to baidu automatically\nbaidu_push: true   submit sitemap\n    Third-party Services Comment Systems\nLiveRe (Korea):\n  Create an account or log into LiveRe, click on the installation button and select the free city version, then click on the install now button.\n  Copy the data-uid field in the installation code to get your LiveRe UID.\n  Add the obtained LiveRe UID to the livere_uid section in the theme config file as following:\nlivere_uid:   Valine (China)：\n  Create an account or log into LeanCloud, and then click on the bottom left corner to create the application in dashboard.\n  Go to the application you just created, select Settings → App Keys in the lower left corner, and you will see your APP ID and APP Key.\n  Edit configurations in valine section in the theme config file as following:\nvaline: enable: true appId: appKey:   评论数据管理：请自行登录Leancloud应用管理。具体步骤：登录\u0026gt;选择你创建的应用\u0026gt;存储\u0026gt;选择Class Comment\n  Statistics and Analytics\nAnalytics Tools:\n  Baidu Analytics (China)\n  Login to Baidu Analytics and locate to site code getting page.\n  Copy the script ID after hm.js?.\n  Edit theme config file and change section baidu_analytics to your script ID.\nbaidu_analytics:     Google Analytics\n  Create an account and log into Google Analytics.\n  Edit theme config file and fill tracking_id under section google_analytics with your Google track ID. Google track ID always starts with UA- (最新版 Google Analytics 是 G-).\ngoogle_analytics: tracking_id: G-XXXXXXXX only_pageview: false     Counting Tools:\nBusuanzi Counting (China), Edit busuanzi_count option in theme config file.\n不蒜子是基于域名来进行统计计算的。数据比百度统计多很多。网络不好的话，数据与图标不一定显示得出来。\nbusuanzi_count: enable: true Search Services\nLocal Search:\nThis search method is recommended for most users.\n  Installation\nnpm install hexo-generator-searchdb   Hexo Config\nsearch: path: search.xml field: post content: true format: html   NexT Config\nlocal_search: enable: true   External Libraries\nPJAX：\n  You can enable it by setting value pjax to true in theme config file.\npjax: true   It listens to every click on links you want (by default all of them).When an internal link is clicked, Pjax fetches the page\u0026rsquo;s HTML via AJAX.\n  Please use the absolute path of the image or Hexo asset_img tag in your posts, otherwise the images may fail to load during Pjax refresh.\n  例子：添加音乐播放器并保持跳转时不中断播放状态；fireworks 特效更流畅，不存在点击链接时的卡顿现象（点击链接时不会触发fireworks）。\n  Fancybox:\nA jQuery lightbox script for displaying images, videos and more.\nfancybox: true Lazyload:\nIt delays loading of images in long web pages. Images outside of viewport will not be loaded before user scrolls to them.\nlazyload: true Progress Bar:\nNProgress will automatically monitor your Ajax requests, event loop lag, document ready state and elements on your page to decide on the progress.\nnprogress: enable: true spinner: false Canvas Ribbon：\ncanvas_ribbon: enable: true size: 300\t# The width of the ribbon. alpha: 0.6\t# The transparency of the ribbon. zIndex: -1\t# The display level of the ribbon. 粒子漂浮聚合：\n该功能由 theme-next-canvas-nest 插件提供：\n  Create a file named footer.njk  in hexo/source/_data directory, Edit this file and add the following content\n\u0026lt;script color=\u0026quot;0,0,255\u0026quot; opacity=\u0026quot;0.5\u0026quot; zIndex=\u0026quot;-1\u0026quot; count=\u0026quot;99\u0026quot; src=\u0026quot;https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;   In the NexT _config.yml, uncomment footer under the custom_file_path section.\ncustom_file_path: footer: source/_data/footer.njk   Tag Plugins Mermaid\n  Settings\nmermaid: enable: true   Usage\n{% mermaid type %} {% endmermaid %}   Advanced Settings Custom Files\n  uncomment under the section in theme config file.stylecustom_file_path。\ncustom_file_path: head: source/_data/head.njk header: source/_data/header.njk ...   Edit in site root directory and add files:source/_data/...。\n  Then use it。\n  Stylus 是 CSS 的预处理框架，给 CSS 添加了可编程的特性。Stylus支持三种注释，单行注释（//)，多行注释(/* */)。\n  Nunjucks 是 jinja2 的 javascript 的实现，可以使用 {# and #} 来写注释，渲染时将会去除所有的注释。\n  不要直接修改 model 文件，而要使用 custom file，方便之后升级。\n  Front Matter\n--- photos: /uploads/png.png --- Misc Settings 想要什么功能可以搜一下，看是否有现成的 model 可以使用。\n网易云音乐\n 在网页版云音乐中找到歌曲，点击生成外链播放器 根据个人喜好选择播放器尺寸和播放模式 将获取到的 iframe 代码添加到页面中  Aplayer 音频播放器\n  借助 hexo-tag-aplayer 插件，可以通过标签的形式方便快捷的插入音频组件。\n  Installation\nnpm install --save hexo-tag-aplayer   Usage\n{% aplayer \u0026quot;title\u0026quot; \u0026quot;author\u0026quot; \u0026quot;url\u0026quot; [\u0026quot;picture_url\u0026quot;, \u0026quot;narrow\u0026quot;, \u0026quot;autoplay\u0026quot;, \u0026quot;width:xxx\u0026quot;, \u0026quot;lrc:xxx\u0026quot;] %}  title: 曲目标题 author: 曲目作者 url: 音乐文件 URL 地址 picture_url: (可选) 音乐对应的图片地址 narrow: （可选）播放器袖珍风格 autoplay: (可选) 自动播放，移动端浏览器暂时不支持此功能 width:xxx: (可选) 播放器宽度 (默认: 100%) lrc:xxx: （可选）歌词文件 URL 地址    当开启 Hexo 的 文章资源文件夹功能时，可直接引用\n{% aplayer \u0026quot;Caffeine\u0026quot; \u0026quot;Jeff Williams\u0026quot; \u0026quot;caffeine.mp3\u0026quot; \u0026quot;picture.jpg\u0026quot; \u0026quot;lrc:caffeine.txt\u0026quot; %}   Dpalyer 视频播放器\n  Installation\nnpm install hexo-tag-dplayer --save   Usage\n{% dplayer \u0026quot;url=video-url\u0026quot; \u0026quot;pic=image-url\u0026quot; ... [\u0026quot;key=value\u0026quot;] %}   部分重要 key\n 播放器  autoplay：是否开启视频自动播放，默认为 fasle loop：是否开启视频循环播放，默认为 false screenshot：是否开启截图，默认为 false mutex：是否禁止多个播放器同时播放，默认为 true dmunlimited：是否开启海量弹幕模式，默认为 false preload：预加载模式，可选 note metadata auto theme：主题色 lang：语言，可选 en zh-cn zh-tw logo：左上角的 Logo volume：默认音量，默认为 0.7 width：播放器宽度 height：播放器长度   视频  url：视频链接 pic：视频封面 thumbnails：视频缩略图，可以使用 DPlayer-thumbnails 生成 vidtype：视频类型，可选 auto hls flv dash 或其他自定义类型   字幕  suburl：字幕链接 subtype：字幕类型，可选 webvtt ass，目前只支持 webvtt subbottom：字幕距离播放器底部的距离，如 10px 10% subcolor：字幕颜色   弹幕  id：弹幕 id api：弹幕 api token：弹幕后端验证 token addition：额外外挂弹幕 dmuser：弹幕用户名 maximum：弹幕最大数量      看板娘\n该功能由 hexo-helper-live2d 插件支持\n  Installation\nnpm install --save hexo-helper-live2d   Config：在站点配置文件中设置，主题配置文件中设置没用\nlive2d: enable: true scriptFrom: local pluginRootPath: live2dw/ pluginJsPath: lib/ pluginModelPath: assets/ tagMode: false log: false model: use: live2d-widget-model-shizuku display: position: right width: 150 height: 300 mobile: show: true react: opacity: 0.7   Models：可以从 hexo live2d 模型预览 里找到你喜欢的角色，然后根据 live2d-widget-models 中提供的方法来下载模型数据.\nnpm install live2d-widget-model-shizuku   Fireworks\n一个鼠标点击动画特效\nnpm install next-theme/hexo-next-fireworks activate-power-mode\n一个为博客添加酷炫打字特效的插件\n  编辑 /hexo-site/source/_data/footer.njk\n\u0026lt;script src=\u0026quot;https://cdn.jsdelivr.net/gh/suyin-long/activate-power-mode@1.0/dist/activate-power-mode.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; POWERMODE.colorful = true; // make power mode colorful POWERMODE.shake = false; // turn off shake document.body.addEventListener('input', POWERMODE); \u0026lt;/script\u0026gt;   取消footer: source/_data/footer.njk的注释\n  搞怪网页标题\n  编辑 /hexo-site/source/_data/head.njk，添加\n{# 搞怪网页标题 #} {% if theme.title_trick.enable %} \u0026lt;script\u0026gt; var OriginTitile = document.title; var titleTime; document.addEventListener(\u0026quot;visibilitychange\u0026quot;, function() { if (document.hidden) { document.title = \u0026quot;{{ theme.title_trick.leave }}\u0026quot;; clearTimeout(titleTime); } else { document.title = \u0026quot;{{ theme.title_trick.enter }}\u0026quot;; titleTime = setTimeout(function() { document.title = OriginTitile; }, 2000); } }); \u0026lt;/script\u0026gt; {% endif %}   在主题配置文件中添加\n# a trick on website title title_trick: enable: true leave: \u0026#34;(つェ⊂)我藏好了哦~\u0026#34; enter: \u0026#34;(*´∇｀*) 被你发现啦~\u0026#34;   我先是放在 sorce/_data/head.njk 中，问题是改变一次标题后就只显示网址。我认为 script 可能在 \u0026lt;title\u0026gt; 之前加载，所以就放在 source/_data/header.njk，正常运行。\n  Hexo NexT Three\n  Install\nnpm install next-theme/hexo-next-three   Configure\n# JavaScript 3D library. # Dependencies: https://github.com/next-theme/hexo-next-three three: enable: true defer: true cdn: waves: enable: false cdn: lines: enable: false cdn: sphere: enable: false cdn:   hexo-cake-moon-menu\n  How to use\nnpm install hexo-cake-moon-menu   Config: In hexo _config.yml\nmoon_menu: back2top: enable: true icon: fas fa-chevron-up func: back2top order: -1 back2bottom: enable: true icon: fas fa-chevron-down func: back2bottom order: -2   permalink\n  默认的文章 url 地址为 http://yoursite.com/:year/:month/:day/:title/，这种 url 格式层级太多，并且如果文章标题是中文的话可能会发生转义而出现一堆乱码，不利于搜索引擎的爬取分析，因此建议在站点配置中修改 permalink 的格式来简化页面 url，并尽量采用英文命名 Markdown 文件。(这个根据个人选择，我认为有更有组织的文件结构更重要)\n  这个 front matter 必须是 html 文件，文件会生成到 public 根目录。\n --- permalink: /post-name.html ---   robots.txt\nrobots.txt（统一小写）是一种存放于网站根目录下的ASCII编码的文本文件，它通常告诉网络搜索引擎的漫游器（又称网络蜘蛛），此网站中的哪些内容是不应被搜索引擎的漫游器获取的，哪些是可以被漫游器获取的。\nrobots.txt在线生成器\nCDN CDN 的全称是(Content Delivery Network)，即内容分发网络。其目的是通过在现有的 Internet 中增加一层新的CACHE(缓存)层，将网站的内容发布到最接近用户的网络“边缘”的节点，使用户可以就近取得所需的内容，提高用户访问网站的响应速度。从技术上全面解决由于网络带宽小、用户访问量大、网点分布不均等原因，提高用户访问网站的响应速度。\nCDN 工作原理 传统访问过程：\n 用户输入访问的域名，操作系统向 LocalDns 查询域名的ip地址 LocalDns 向 ROOT DNS 查询域名的授权服务器（这里假设LocalDns缓存过期） ROOT DNS 将域名授权 dns 记录回应给 LocalDns LocalDns 得到域名的授权 dns 记录后，继续向域名授权 dns 查询域名的 ip 地址 域名授权 dns 查询域名记录后，回应给 LocalDns LocalDns 将得到的域名 ip 地址，回应给用户端 用户得到域名 ip 地址后，访问站点服务器 站点服务器应答请求，将内容返回给客户端  CDN 访问过程：\n 用户输入访问的域名，操作系统向 LocalDns 查询域名的 ip 地址 LocalDns 向 ROOT DNS 查询域名的授权服务器（这里假设LocalDns缓存过期） ROOT DNS 将域名授权 dns 记录回应给 LocalDns LocalDns 得到域名的授权 dns 记录后，继续向域名授权 dns 查询域名的 ip 地址 域名授权 dns 查询域名记录后（一般是CNAME），回应给 LocalDns LocalDns 得到域名记录后，向智能调度 DNS 查询域名的 ip 地址 智能调度 DNS 根据一定的算法和策略，将最适合的 CDN 节点 ip 地址回应给 LocalDns LocalDns 将得到的域名 ip 地址，回应给用户端 用户得到域名 ip 地址后，访问站点服务器 CDN 节点服务器应答请求，将内容返回给客户端  参考 CDN加速原理\nNPM npm makes it easy for JavaScript developers to share and reuse code, and it makes it easy to update the code that you\u0026rsquo;re sharing.\n基本：\n  package.json 和 package-lock.json\n package.json 执行 npm init 命令生成，描述项目模块信息 package-lock.json 执行 npm install 命令生成，描述模块来源及依赖信息，可删除    安装模块：\n  全局安装\nnpm install -g 模块名称   本地安装：读取 package.json 并下载模块到 node_modules 的目录，模块分为两类 dependencies 和devDependencies，分别对应生产环境需要的安装包和开发环境需要的安装包\nnpm install \u0026lt;package_name\u0026gt; # 在安装模块的时候，可以通过指定参数来修改 package.json 文件 npm install \u0026lt;package_name\u0026gt; --save npm install \u0026lt;package_name\u0026gt; --save-dev     更新模块\nnpm update   卸载模块\nnpm uninstall -g \u0026lt;package_name\u0026gt; npm uninstall \u0026lt;package_name\u0026gt; # 卸载模块的同时，也从 package.json 文件中移除 npm uninstall --save \u0026lt;package_name\u0026gt; npm uninstall --save-dev \u0026lt;package_name\u0026gt;   解决问题：\n  Ubuntu 安装最新 LTS 版本：官方教程，Windows 版本更好\nsudo mkdir -p /usr/local/lib/nodejs sudo tar -xJvf node-$VERSION-$DISTRO.tar.xz -C /usr/local/lib/nodejs vi ~/.profile # Nodejs VERSION=v10.15.0 DISTRO=linux-x64 export PATH=/usr/local/lib/nodejs/node-$VERSION-$DISTRO/bin:$PATH . ~/.profile\t# Refresh profile sudo ln -s /usr/local/lib/nodejs/node-$VERSION-$DISTRO/bin/node /usr/bin/node   查看 npm 配置\nnpm config list -l npm config ls   配置镜像：淘宝镜像不好用，特对对于 update\nnpm config set registry https://registry.npmjs.org --global   配置 NPM 不做严格的 SSL 校验\nnpm config set strict-ssl false   npm ERR! Unexpected end of JSON input while parsing near \u0026hellip;\nnpm cache clean --force   npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents：不管\n  npm ERR! code EINTEGRITY\ngrep -ir \u0026quot;sha1-WYr+VHVbKGilMw0q/51Ou1Mgm2U\u0026quot; ~/.npm\t# wanted sha1 npm cache clean --force grep -ir \u0026quot;sha1-WYr+VHVbKGilMw0q/51Ou1Mgm2U\u0026quot; ~/.npm npm install   getaddrinfo EAI_AGAIN registry.npmjs.org：网络问题，重新运行 npm install\n  升级为最新稳定版本的 node.js：超慢\nsudo npm cache clean -f sudo npm install -g n\t# n 是 Node版本管理控制器 sudo n stable   NPM 中文文档\nGreat Blogs yearito ，suyin ，yleao ，dlzhang\nVersion    Name Version     npm 7.0.8   hexo 5.2.0   hexo-theme-next 8.0.2    ","permalink":"https://sakamotokurome.github.io/posts/hexo/","summary":"Hexo Hexo 是一个快速、简洁且高效的博客框架。 安装 安装 Git： Windows: Download \u0026amp; install git. Mac: Install it with Homebrew, MacPorts or installer. Linux (Ubuntu, Debian): sudo apt-get install git-core Linux (Fedora, Red Hat, CentOS): sudo yum install git-core 安装 node.js： Windows: Install it with","title":"Hexo"},{"content":"Workspace：工作区，Index / Stage：暂存区，Repository：仓库区（或本地仓库），Remote：远程仓库\n远程仓库 安装，windows需要处理换行符 sudo yum install git 设置姓名和邮箱地址 git config --global user.name \u0026#34;Vane Hsiung\u0026#34; git config --global user.email \u0026#34;1664548605@qq.com\u0026#34; 提高输出可读性 git config --global color.ui auto 设置文件   显示当前的 Git 配置\ngit config --list cat ~/.giconfig   编辑Git配置文件\ngit config -e [--global]   设置SSH，添加认证密码 ssh-keygen -t rsa -C \u0026#34;1664548605@qq.com\u0026#34; 添加公开密钥 将下面的密钥添加到 GitHub 设置中的 SSH key 中\ncat ~/.ssh/id_rsa.pub 查看是否认证和通信成功 ssh -T git@github.com 获取远程仓库 clone 后默认在 master 分支下自动将 origin 设置为远程仓库标识符\ngit clone SSH 提速：\ngit clone SSH --depth=1 加上 \u0026ndash;depth 会只下载一个 commit，所以内容少了很多，速度也就上去了。\n而且下载下来的内容是可以继续提交新的 commit、创建新的分支的。不影响后续开发，只是不能切换到历史 commit 和历史分支。\n在一些场景下还是比较有用的：当需要切换到历史分支的时候也可以计算需要几个 commit，然后再指定 depth，这样也可以提高速度。\n获取远程非master分支 -b 后是新建分支名称\ngit checkout -b branchName origin/branchName 获取指定分支 使用git拉代码时可以使用 -b 指定分支，拉取 develop 分支代码：\ngit clone -b develop http://gitslab.yiqing.com/declare/about.git 查看当前项目拉的是哪个分支的代码详情：\ngit branch -v 查看分支上的递交情况:\ngit show-branch 获取最新的远程仓库分支 远程仓库拉取代码并合并到本地，可简写为 git pull 等同于 git fetch \u0026amp;\u0026amp; git merge\ngit pull \u0026lt;远程主机名\u0026gt; \u0026lt;远程分支名\u0026gt;:\u0026lt;本地分支名\u0026gt; # 取回远程仓库的变化，并与本地分支合并 git pull origin branchName # 使用rebase的模式进行合并 git pull --rebase \u0026lt;远程主机名\u0026gt; \u0026lt;远程分支名\u0026gt;:\u0026lt;本地分支名\u0026gt; # 获取远程仓库特定分支的更新 git fetch \u0026lt;远程主机名\u0026gt; \u0026lt;分支名\u0026gt; # 获取远程仓库所有分支的更新 git fetch --all 问题：For those who found this searching for an answer to fatal: 'origin/remote-branch-name' is not a commit and a branch 'local-branch-name' cannot be created from it, you may also want to try this first:\ngit fetch --all 与 git pull 不同的是 git fetch 操作仅仅只会拉取远程的更改，不会自动进行 merge 操作。对你当前的代码没有影响。\ngit rebase 让你的提交记录更加清晰可读\nrebase 翻译为变基，他的作用和 merge 很相似，用于把一个分支的修改合并到当前分支上。\n即逐个应用了 mater 分支的更改，然后以 master 分支最后的提交作为基点，再逐个应用 feature 的每个更改。\n大部分情况下，rebase 的过程中会产生冲突的，此时，就需要手动解决冲突，然后使用依次 git add  、git rebase --continue  的方式来处理冲突，完成 rebase 的过程，如果不想要某次 rebase 的结果，那么需要使用 git rebase --skip  来跳过这次 rebase 操作。\ngit merge 和 git rebase 的区别\n不同于 git rebase 的是，git merge 在不是 fast-forward（快速合并）的情况下，会产生一条额外的合并记录，类似 Merge branch 'xxx' into 'xxx' 的一条提交信息。\n另外，在解决冲突的时候，用 merge 只需要解决一次冲突即可，简单粗暴，而用 rebase 的时候 ，需要依次解决每次的冲突，才可以提交。\n同一台电脑配置多个 GItHub 账号 在日常使用 git 作为仓库使用的时候，有时可能会遇到这样的一些情况：\n 有两个 github 账号，一台电脑怎么同时连接这两个账号进行维护呢？ 自己用一个 github 账号，平时用来更新自己的一些资料；公司使用的 gitlab（也是 git 的衍生产品）  如下是解决方案：\n  创建默认 SSH Key\nssh-keygen -t rsa -C \u0026#34;one@example.com\u0026#34;   将公钥添加到 one@example.com 的 GitHub SSH key 中。\n  测试 ssh key 是否成功\nssh -T git@github.com   如果设置过全局，则清除 git 的全局设置\n# 查看当前配置 git config --list # 取消 global user.name user.email git config --global --unset user.name git config --global --unset user.email   生成另外一个账号新的SSH keys\nssh-keygen -t rsa -C \u0026#34;two@example.com\u0026#34; 私钥需重命名，如 id_rsa_two。然后将对应的公钥添加到two@example.com的 Github SSH key 中。\n  需添加新私钥到 SSH agent 中，因为默认只读取 id_rsa\n# Windows 在管理员下运行 Get-Service ssh-agent Set-Service ssh-agent -StartupType Manual Start-Service ssh-agent # Linux eval `ssh-agent -s` # 添加私钥 ssh-add ~/.ssh/id_rsa_new unable to start ssh-agent service\nCould not open a connection to your authentication agent\n  配置 ~/.ssh/config 文件，用于配置私钥对应的服务器\n# Default github user(one@example.com) Host git@github.com HostName github.com User \u0026#34;Your GitHub Account Name\u0026#34; IdentityFile ~/.ssh/id_rsa # another user(two@example.com) # 建一个别名，新建的帐号使用这个别名做克隆和更新 # \u0026#34;Host\u0026#34; 如果带了 \u0026#34;git@\u0026#34;，如 \u0026#34;git@two.github.com\u0026#34;，就会连接到 two.github.com # \u0026#34;Host\u0026#34; 没有带 \u0026#34;git@\u0026#34;，就会正确的连接到 github.com Host two.github.com HostName github.com User \u0026#34;Your GitHub Account Name\u0026#34; IdentityFile ~/.ssh/id_rsa_two 测试\n# default ssh -T git@github.com # another ssh -T git@two.github.com   使用\n# default git remote add origin git@github.com:one/demo.git # another git remote add origin git@two.github.com:two/demo.git   设置每个项目的自己的 user.name 和 user.email\ngit config user.email \u0026#34;two@example.com\u0026#34; git config user.name \u0026#34;two\u0026#34;   Git 中 HTTPS 和 SSH 的 Clone 方式区别  HTTPS：不管是谁，拿到url随便clone，但是在push的时候需要验证用户名和密码； SSH：clone的项目你必须是拥有者或者管理员，而且需要在clone前添加SSH Key。SSH 在push的时候，是不需要输入用户名的，如果配置SSH key的时候设置了密码，则需要输入密码的。  本地仓库 初始化仓库 生成 .git 目录, 也就是当前目录的仓库，当前目录称为“附属于该仓库的工作树”\ngit init [project-name] 查看仓库的状态 git status\t# 显示有变更的文件 向暂存区添加文件   添加指定文件到暂存区\ngit add [file1] [file2] ...   添加指定目录到暂存区，包括子目录\ngit add [dir]   添加当前目录的所有文件到暂存区\ngit add .   删除工作区文件，并且将这次删除放入暂存区\ngit rm [file1] [file2] ...   改名文件，并且将这个改名放入暂存区\ngit mv [file-original] [file-renamed]   原理（git add 为如下两步简写）：\n  为 example.txt 创建一个副本。git hash-object 命令把 example.txt 的当前内容压缩成二进制文件，称为一个 Git 对象，保存在 .git/objects 目录。并计算当前内容的哈希值，前 2 个字符作为目录名，后 38 个字符作为该对象的文件名\ngit hash-object -w example.txt 二进制对象里面会保存一些元数据，如果想看该文件原始的文本内容，需用git cat-file命令\ngit cat-file -p e69de29bb2d1d6434b8b29ae775ad8c2e48c5391   所有变动的文件，Git 都记录在\u0026quot;暂存区\u0026quot;，git update-index 命令用于在暂存区记录一个发生变动的文件\ngit update-index --add --cacheinfo 100644 e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 example.txt git ls-files 命令显示暂存区当前内容\ngit ls-files --stage   查看更改前后的差别 习惯：git commit 前先 git diff HEAD\ngit diff 默认查看工作树和暂存区的差别\nHEAD查看工作树与最新提交的差别，HEAD 为指向当前分支中最新一次提交的指针，HEAD^ 指向 HEAD 的前一个提交，HEAD~6 则是 HEAD 之前的第6个提交。每一个分支都是一个文本文件，保存在 .git/refs/heads/ 目录中，文件的内容是最新提交的哈希值\ngit diff [HEAD] 将暂存区中文件保存到仓库历史记录中 -m 用于记录一行信息；不加 -m 记录详细信息，会新开编辑器进行编辑\n  相当与 git add 与 git commit\ngit commit -am \u0026#34;Message\u0026#34;\t  提交暂存区的指定文件到仓库区\ngit commit [file1] [file2] ... -m \u0026#34;Message\u0026#34;   提交工作区自上次commit之后的变化，直接到仓库区\ngit commit -a   提交时显示所有diff信息\ngit commit -v   原理（git commit -m \u0026quot;first commit\u0026quot; 为如下两步简写）：\n  git write-tree 命令保存当前的目录结构，生成一个 Git 对象\ngit write-tree   git commit-tree 命令用目录结构 Git 对象生成一个 Git 对象，需添加提交说明，-p 参数用来指定父提交\necho \u0026#34;first commit\u0026#34; | git e5a60f66d9966270c835343d4facc1c4bf44ed7a -p c9053865e9dff393fd2f7a92a18f9bd7f2caa7fa   修改提交信息 产生一个新的提交对象，替换掉上一次提交产生的提交对象\ngit commit --amend -m \u0026#34;Message\u0026#34; 重做上一次 commit，并包括指定文件的新变化\ngit commit --amend [file1] [file2] ... 压缩历史 用于拼错单词等简单的错误，选定当前分支中包含 HEAD（最新提交）在内的 number 个最新历史记录为对象并在编辑器中打开，pick 为合并对象，fixup 为被合并对象，最后 pick 提交信息会保留\ngit rebase -i HEAD~[number] 查看提交日志   --pretty=short 用于只显示第一行简述信息\n  FileName 为文件名或目录名，只显示指定文件的日志\n  -p 用于显示文件的改动\n  --stat 显示 commit 历史，以及每次 commit 发生变更的文件\ngit log [--pretty=short][FileName][-p][--stat]\t# 显示当前分支的版本历史   查看文件每次提交的diff\ngit log -p FileName   搜索提交历史，根据关键词\ngit log -S [keyword]   显示某个 commit 之后的所有变动，每个commit占据一行\ngit log [tag] HEAD --pretty=format:%s   显示某个 commit 之后的所有变动，其\u0026quot;提交说明\u0026quot;必须符合搜索条件\ngit log [tag] HEAD --grep feature   显示某个文件的版本历史，包括文件改名\ngit log --follow [file] git whatchanged [file]   git log 的运行过程\n 查找 HEAD 指针对应的分支 找到分支的最新提交 找到父节点（前一个提交） 依此类推，显示当前分支的所有提交  查看当前仓库操作日志 git reflog 怎么查看当前的git分支是基于哪个分支创建的\ngit reflog --date=local | grep \u0026lt;branchname\u0026gt;\n类似于如下\n6b3db1f HEAD@{Fri Jul 9 16:05:23 2021}: checkout: moving from development to feature/api_xiongwen_dump 可知 feature/api_xiongwen_dump 基于 development\n从暂存区撤销文件 停止追踪指定文件，但该文件会保留在工作区\ngit rm --cached [filename] 撤销提交 在当前提交后面，新增一次提交，抵消掉上一次提交导致的所有变化\ngit revert HEAD 想抵消多个提交，必须在命令行依次指定这些提交\ngit revert [倒数第一个提交] [倒数第二个提交] 回溯历史版本   重置暂存区的指定文件，与上一次 commit 保持一致，但工作区不变\ngit reset [file]   重置暂存区与工作区，与上一次 commit 保持一致\ngit reset --hard   让最新提交的指针回到以前某个时点，该时点之后的提交都从历史中消失\ngit reset 目标时间点哈希值\t# 重置当前分支的指针为指定 commit，同时重置暂存区，但工作区不变   默认情况下，git reset不改变工作区的文件（但会改变暂存区），--hard参数可以让工作区里面的文件也回到以前的状态\ngit reset --hard 目标时间点哈希值\t# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致   重置当前 HEAD 为指定 commit，但保持暂存区和工作区不变\ngit reset --keep [commit]   添加远程仓库 origin 为远程仓库的标识符\ngit remote add origin SSH\t# 增加一个新的远程仓库，并命名 git remote -v\t# 显示所有远程仓库 git remote show [remote]\t# 显示某个远程仓库的信息 推送至远程仓库  推送的是当前分支 -u 在推送的同时将远程仓库的（origin仓库）的 branch 分支设为本地仓库当前分支的 upstream（上游） 运行 git pull 从远程仓库获取内容时，就可以省略参数  git push [-u origin branchName]\t# 上传本地指定分支到远程仓库 git push --set-upstream origin [branchName]\t# To push the current branch and set the remote as upstream 如果每次 git push 都需要输入账号和密码\n  首先在 git 工作目录下：\ngit config [--global] credential.helper store   然后执行一次 git pull，这次输入账号和密码之后就不用再输入了。\n  Git push existing repo to a new and different remote repo server? 需求：从公司的账户 clone repo 到本地，添加注释，pull 到自己账户的私有 repo 中。\n Create a new repo at github. git remote rename origin upstream git remote add origin URL_TO_GITHUB_REPO git push origin master  Now you can work with it just like any other github repo. To pull in patches from upstream, simply run git pull upstream master \u0026amp;\u0026amp; git push origin master.\n分支 创建并切换分支 # 切换分支，并更新工作区 git checkout branchName\t#切换至上一分支 git checkout -\t# 新建一个分支，并切换到该分支 git checkout -b branchName\t# 新建本地分支，但不切换 git branch \u0026lt;branch-name\u0026gt; # 新建一个分支，指向指定commit git branch [branch] [commit]\t# 新建一个分支，与指定的远程分支建立追踪关系 git branch --track [branch] [remote-branch]\t以图表形式查看分支 git log --graph 显示分支 # 列出所有本地分支 git branch\t# 列出所有远程分支 git branch -r\t# 同时显示本地仓库和远程仓库的分支信息 git branch -a\t# 用于创建分支 git branch branchName\t# 本地分支对应哪个远程分支 git branch -vv 合并分支  --no-ff 用于记录本次分支合并 消除冲突：打开冲突的文件，在编辑器中改为想要的样子  git merge [--no-ff] branchName\t# 合并指定分支到当前分支 git cherry-pick [commit]\t# 选择一个 commit，合并进当前分支 删除分支   删除分支\n# 删除本地分支 git branch -d [branch-name]   删除远程分支\ngit push origin --delete [branch-name] git branch -dr [remote/branch]   撤销工作区的文件修改   先找暂存区，如果该文件有暂存的版本，则恢复该版本，否则恢复上一次提交的版本\ngit checkout -- [filename]   恢复某个 commit 的指定文件到暂存区和工作区\ngit checkout [commit] [file]   恢复暂存区的所有文件到工作区\ngit checkout .   分支重命名   重命名本地分支：\n  在当前分支时\ngit branch -m new_branch_name   当不在当前分支时\ngit branch -m old_branch_name new_branch_name     重命名远端分支：\n假设是在当前分支，并且远端分支与本地分支名是一致的重命名本地分支\ngit branch -m new_branch_name 删除远程分支\ngit push --delete origin old_branch_name 上传新命名的本地分支\ngit push origin new_branch_name 关联修改后的本地分支与远程分支\ngit branch --set-upstream-to origin/new_branch_name   标签   列出所有 tag\ngit tag   新建一个 tag 在当前commit\ngit tag [tag]   新建一个tag在指定commit\ngit tag [tag] [commit]   删除本地 tag\ngit tag -d [tag]   删除远程 tag\ngit push origin :refs/tags/[tagName]   查看 tag 信息\ngit show [tag]   提交指定 tag\ngit push [remote] [tag]   提交所有tag\ngit push [remote] --tags   新建一个分支，指向某个tag\ngit checkout -b [branch] [tag]   Git Ignore git 为我们提供了一个 .gitignore 文件，只要在这个文件中申明哪些文件你不希望添加到git中去，这样当你使用 git add . 的时候这些文件就会被自动忽略掉。\n经实验，可以为每一个平行非包含的目录设定一个 .gitignore。\nPull Request 当你想更正别人仓库里的错误时，要走一个流程：\n 先 fork 别人的仓库，相当于拷贝一份，相信我，不会有人直接让你改修原仓库的。 clone 到本地分支，做一些 bug fix。 发起 pull request 给原仓库，让他看到你修改的 bug。 原仓库 review 这个 bug，如果是正确的话，就会 merge 到他自己的项目中  至此，整个 pull request 的过程就结束了。\n拉取请求，就是请求对方拉取我本地仓库的 bug fix，合并到对方的 repo 中。以对方的视角来看，我的本地仓库就是一个远程仓库。因为我们是在请求对方做什么，所以要以对方视角来看，即 pull，因为对方可能同意，也可能不同意，所以是请求，即 pull request。\nGitHub Hosts GitHub520 本项目无需安装任何程序，通过修改本地 hosts 文件，试图解决：\n GitHub 访问速度慢的问题 GitHub 项目中的图片显示不出的问题  花 5 分钟时间，让你\u0026quot;爱\u0026quot;上 GitHub。\n# GitHub520 Host Start 140.82.112.26 alive.github.com 140.82.114.25 live.github.com 185.199.108.154 github.githubassets.com 140.82.113.22 central.github.com 185.199.108.133 desktop.githubusercontent.com 185.199.108.153 assets-cdn.github.com 185.199.108.133 camo.githubusercontent.com 185.199.108.133 github.map.fastly.net 199.232.69.194 github.global.ssl.fastly.net 140.82.113.4 gist.github.com 185.199.108.153 github.io 140.82.114.3 github.com 140.82.114.5 api.github.com 185.199.108.133 raw.githubusercontent.com 185.199.108.133 user-images.githubusercontent.com 185.199.108.133 favicons.githubusercontent.com 185.199.108.133 avatars5.githubusercontent.com 185.199.108.133 avatars4.githubusercontent.com 185.199.108.133 avatars3.githubusercontent.com 185.199.108.133 avatars2.githubusercontent.com 185.199.108.133 avatars1.githubusercontent.com 185.199.108.133 avatars0.githubusercontent.com 185.199.108.133 avatars.githubusercontent.com 140.82.112.10 codeload.github.com 52.216.170.203 github-cloud.s3.amazonaws.com 52.217.98.76 github-com.s3.amazonaws.com 52.216.164.3 github-production-release-asset-2e65be.s3.amazonaws.com 52.216.160.147 github-production-user-asset-6210df.s3.amazonaws.com 52.217.103.12 github-production-repository-file-5c1aeb.s3.amazonaws.com 185.199.108.153 githubstatus.com 64.71.168.201 github.community 185.199.108.133 media.githubusercontent.com # Update time: 2021-07-04T08:07:49+08:00 # Star me GitHub url: https://github.com/521xueweihan/GitHub520 # GitHub520 Host End GitHub Pages 使用 GitHub GitHub Pages 是一项静态站点托管服务，它直接从 GitHub 上的仓库获取 HTML、CSS 和 JavaScript 文件，（可选）通过构建过程运行文件，然后发布网站。\n有三种类型的 GitHub Pages 站点：项目、用户和组织。 项目站点连接到 GitHub 上托管的特定项目。 用户和组织站点连接到特定的 GitHub 帐户。\nTo publish a user site, you must create a repository owned by your user account that\u0026rsquo;s named \u0026lt;username.github.io\u0026gt;. Repositories using the legacy \u0026lt;username.github.com\u0026gt; naming scheme will still be published, but visitors will be redirected from http(s)://\u0026lt;username.github.com\u0026gt; to http(s)://\u0026lt;username.github.io. If both a \u0026lt;username.github.com\u0026gt; and \u0026lt;username.github.io\u0026gt; repository exist, only the \u0026lt;username.github.io\u0026gt; repository will be published.\nGitHub Pages sites are publicly available on the internet, even if the repository for the site is private or internal. 如果站点的仓库中有敏感数据，您可能想要在发布前删除它。\nGitHub Pages 站点的发布来源是存储站点源文件的分支和文件夹。用户和组织站点的默认发布源是仓库默认分支的根目录。 项目站点的默认发布来源是 gh-pages 分支的根目录。\n您可以创建自己的静态文件或使用静态站点生成器为您构建站点。默认情况下，GitHub Pages 将使用 Jekyll 来构建您的站点。\nGitHub Pages 站点受到以下使用限制的约束：\n GitHub Pages source repositories have a recommended limit of 1GB. 发布的 GitHub Pages 站点不得超过 1 GB。 GitHub Pages sites have a soft bandwidth limit of 100GB per month. GitHub Pages sites have a soft limit of 10 builds per hour.  可在 Repository 的 Settings 中配置 GitHub Pages 站点的发布源或取消发布 GitHub Pages 站点。\n使用 jekyll Github Docs 与 Jekyll 文档不一致，Windows 并未正式支持 Jekyll。\n使用 Hexo 我选择 Hexo，一个是安装简单；一个是文档好。\nGitHub Actions GitHub Actions 是什么 持续集成由很多操作组成，比如自动抓取代码、运行测试、登录远程服务器、发布到第三方服务等。GitHub 把这些操作就称为 actions。\n很多操作在不同项目里面是类似的，可以共享。GitHub 允许开发者把每个操作写成独立的脚本文件，存放到代码仓库，使得其他开发者可以引用。\n可在官方市场与 awesome actions 找 action。\nworkflow 文件 GitHub Actions 的配置文件叫做 workflow 文件，存放在代码仓库的 .github/workflows 目录。\nworkflow 文件采用 YAML 格式，一个库可以有多个 workflow 文件。GitHub 发现 .github/workflows 目录里有 .yml 文件，就会自动运行该文件。\n配置字段：\n  name：工作流程的名称。如果省略 name，GitHub 将其设置为相对于仓库根目录的工作流程文件路径\n  on：必要，触发工作流程的 GitHub 事件的名称\non: [push, pull_request]   on.\u0026lt;push|pull_request\u0026gt;.\u0026lt;branches|tags\u0026gt;：您可以将工作流配置为在特定分支或标记上运行\non: push: branches: - main - \u0026#39;mona/octocat\u0026#39; - \u0026#39;releases/**\u0026#39; tags: - v1 - v1.*    jobs：工作流程运行包括一项或多项作业。每项作业必须关联一个 ID\n  jobs.\u0026lt;job_id\u0026gt;.name：job_id 里面的 name 字段是任务的说明\njobs: my_first_job: name: My first job my_second_job: name: My second job   jobs.\u0026lt;job_id\u0026gt;.needs：作业默认是并行运行。needs字段指定当前任务的运行顺序\njobs: job1: job2: needs: job1 job3: needs: [job1, job2] 此例中作业执行顺序：job1、job2、job3\n  jobs.\u0026lt;job_id\u0026gt;.runs-on：必需，运行作业的机器类型\nruns-on: ubuntu-latest     jobs.\u0026lt;job_id\u0026gt;.steps：作业包含一系列任务，称为 steps\n  jobs.\u0026lt;job_id\u0026gt;.steps.name：步骤名称\n  jobs.\u0026lt;job_id\u0026gt;.steps.uses：引用的 Actions\nsteps: # Reference a specific commit - uses: actions/setup-node@74bc508 # Reference a minor version of a release - uses: actions/setup-node@v1.2 # Reference a branch - uses: actions/setup-node@main   jobs.\u0026lt;job_id\u0026gt;.steps.run：使用操作系统 shell 运行命令行程序\n- name: Clean install dependencies and build run: |npm ci npm run build     参考 GitHub Actions 入门教程\nGitHub Actions\n持续集成（Continuous integration，简称CI） 概念 持续集成指的是，频繁地（一天多次）将代码合并（集成）到主干源码仓库。在 CI 中可以通过自动化等手段高频率地去获取产品反馈并响应反馈的过程。\n流程  提交：开发者向代码仓库提交代码 测试（第一轮）：代码仓库对提交的代码跑自动化测试  单元测试：针对函数或模块的测试 集成测试：针对整体产品的某个功能的测试，又称功能测试 端对端测试：从用户界面直达数据库的全链路测试   构建：将源码转换为可以运行的实际代码，会安装依赖，配置各种资源等。常用的构建工具如下  Jenkins：开源 Travis Codeship Strider：开源   测试（第二轮）：第二轮是全面测试 部署：直接部署 回滚：当前版本发生问题，回滚到上一个版本的构建结果  Commit message 社区有多种 Commit Message Conventions。本文介绍 Angular 规范。\n格式化的 Commit message 好处   提供更多的历史信息，方便浏览\ngit log HEAD --pretty=format:%s   可以过滤某些 commit，便于查找信息\ngit log HEAD --grep feature   可以直接从 commit 生成 Change Log\n  Commit message 的格式 \u0026lt;type\u0026gt;(\u0026lt;scope\u0026gt;): \u0026lt;subject\u0026gt; // 空一行 \u0026lt;body\u0026gt; // 空一行 \u0026lt;footer\u0026gt;   Header 只有一行\n type 用于说明 commit 的类别  feat：新功能 fix：修补bug docs：文档 style： 格式 refactor：重构 test：增加测试 chore：构建过程或辅助工具的变动 Revert：当前 commit 用于撤销以前的 commit   scope 用于说明 commit 影响的范围 subject 是 commit 目的的简短描述  以动词开头，使用第一人称现在时 第一个字母小写 结尾不加句号      Body 部分是对本次 commit 的详细描述\n  Footer\n  不兼容变动：如果当前代码与上一个版本不兼容，则以 BREAKING CHANGE 开头，后面是对变动的描述、以及变动理由和迁移方法\n  关闭 Issue：如果当前 commit 针对某个issue，那么可以在 Footer 部分关闭这个 issue\nCloses #123, #245, #992     Commitizen Commitizen 是一个撰写 Commit message 的工具\n  Install the Commitizen cli tools\nnpm install commitizen -g   Initialize your project to use the cz-conventional-changelog adapter\ncommitizen init cz-conventional-changelog --save-dev --save-exact   以后，凡是用到 git commit 命令，一律改为使用 git cz。\n  参考 Commit message 和 Change log 编写指南\nYAML（YAML Ain\u0026rsquo;t a Markup Language） YAML 是专门用来写配置文件的语言\n简介 规则：\n 大小写敏感 使用缩进表示层级关系 缩进时不允许使用 Tab 键，只允许使用空格。 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可 # 表示注释，从这个字符一直到行尾，都会被解析器忽略 对象和数组可以结合使用，形成复合结构  对象 一组键值对\nanimal: pets 行内表示法\nhash: { name: Steve, foo: bar }  数组 一组连词线开头的行\n- Cat - Dog - Goldfish 数据结构的子成员是一个数组，则可以在该项下面缩进一个空格\n- - Cat - Dog - Goldfish 行内表示法\nanimal: [Cat, Dog] 纯量   字符串：字符串默认不使用引号表示\nstr: 这是一行字符串 包含空格或特殊字符，需要放在引号之中，单引号和双引号都可以使用，双引号不会对特殊字符转义\nstr: \u0026#39;内容： 字符串\u0026#39; 单引号之中如果还有单引号，必须连续使用两个单引号转义\nstr: \u0026#39;labor\u0026#39;\u0026#39;s day\u0026#39; 字符串可以写成多行，从第二行开始，必须有一个单空格缩进。换行符会被转为空格\nstr: 这是一段 多行 字符串 多行字符串可以使用|保留换行符，也可以使用\u0026gt;折叠换行\nthis: |Foo Bar that: \u0026gt;Foo Bar +表示保留文字块末尾的换行，-表示删除字符串末尾的换行\ns1: | Foo s2: |+ Foo s3: |- Foo 字符串之中可以插入 HTML 标记\nmessage: | \u0026lt;p style=\u0026#34;color: red\u0026#34;\u0026gt; 段落 \u0026lt;/p\u0026gt;   参考 YAML 语言教程\nThe Official YAML Web Site\n开源许可证 一般情况下，软件的源代码只由编写者拥有，而开源（即开放源代码，Open Source Code）是指一种更自由的软件发布模式。简单来说，开源软件的特点就是把软件程序和源代码文件一起打包提供给用户，让用户在不受限制地使用某个软件功能的基础上还可以对代码按需修改，让软件更贴合硬件环境，让功能更符合工作需求。用户还可以将其编制成衍生产品再发布出去。用户一般享有使用自由、复制自由、修改自由、创建衍生品自由，以及收费自由。是的，您没有看错，用户具备创建衍生品和收费的自由。这也就是说，可以对一个开源软件进行深度定制化加工。如果修改过的程序更加好用，或者颇具新的特色，只要符合原作者的许可要求，我们就完全可以合法地将软件进行商标注册，以商业版的形式再发布出去，只要有新用户使用您的软件并支付相应的费用，那就是您的收入。这也正好符合了黑客和极客对自由的追求，因此在合作与竞争中，国内外的开源社区慢慢生长出了强健的根基，人气也非常高。\n但是，如果开源软件只单纯追求“自由”而牺牲了程序员的利益，这肯定会影响程序员的创作热情。为了平衡两者的关系，截至目前，世界上已经有100多种被开源促进组织（OSI，Open Source Initiative）确认的开源许可证，用于保护开源工作者的权益。对于那些只知道一味抄袭、篡改、破解或者盗版他人作品的不法之徒，终归会在某一天收到法院的传票。\n考虑到大家没准儿以后会以开源工作者的身份编写出一款畅销软件，因此刘遄老师根据开源促进组织的推荐建议以及实际使用情况，为大家筛选出了程序员最喜欢的前6名的开源许可证，并教大家怎么从中进行选择。提前了解最热门的开源许可证，并在未来选择一个合适的可最大程度地保护自己软件权益的开源许可证，这对创业公司来讲能起到事半功倍的作用。\n开源许可证总览：https://opensource.org/licenses/alphabetical\nTips：上述提到的“开源许可证”与“开源许可协议”的含义完全相同，只不过是英文翻译后两种不同的叫法，这里不作区别。\nTips：自由软件基金会（Free Software Foundation，FSF）是一个非营利组织，其使命是在全球范围内促进计算机用户的自由，捍卫所有软件用户的权利。\n大家经常会在开源社区中看到Copyleft这个单词，这是一个由自由软件运动所发展出的概念，中文被翻译为“著佐权”或者“公共版权”。与Copyright截然相反，Copyleft不会限制使用者复制、修改或再发布软件。\n此外，大家应该经常会听到别人说开源软件是free的，没错，开源软件就是自由的。这里的free千万不要翻译成“免费”，这样就大错特错了，这与您去酒吧看到的“第一杯免费”的意思可相差甚远。\n下面我们来看一下程序员最喜欢的前6名的开源许可证，以及它们各自赋予用户的权利。\nGPL **GNU通用公共许可证（**General Public License，GPL）：目前广泛使用的开源软件许可协议之一，用户享有运行、学习、共享和修改软件的自由。GPL最初是自由软件基金会创始人Richard Stallman起草的，其版本目前已经发展到了第3版。GPL的目的是保证程序员在开源社区中所做的工作对整个世界是有益的，所开发的软件也是自由的，并极力避免开源软件被私有化以及被无良软件公司所剥削。\n现在，只要软件中包含了遵循GPL许可证的产品或代码，该软件就必须开源、免费，因此这个许可证并不适合商业收费软件。遵循该许可证的开源软件数量极其庞大，包括Linux内核在内的大多数的开源软件都是基于GPL许可证的。GPL赋予了用户著名的五大自由。\n **使用自由：**允许用户根据需要自由使用这个软件。\n**复制自由：**允许把软件复制到任何人的计算机中，并且不限制复制的数量。\n**修改自由：**允许开发人员增加或删除软件的功能，但软件修改后必须依然基于GPL许可证。\n**衍生自由：**允许用户深度定制化软件后，为软件注册自己的新商标，再发行衍生品的自由。\n**收费自由：**允许在各种媒介上出售该软件，但必须提前让买家知道这个软件是可以免费获得的。因此，一般来讲，开源软件都是通过为用户提供有偿服务的形式来营利的。\n LGPL 较宽松通用公共许可证（Lesser GPL, LGPL）：一个主要为保护类库权益而设计的GPL开源协议。与标准GPL许可证相比，LGPL允许商业软件以类库引用的方式使用开源代码，而不用将其产品整体开源，因此普遍被商业软件用来引用类库代码。简单来说，就是针对使用了基于LGPL许可证的开源代码，在涉及这部分代码，以及修改过或者衍生出来的代码时，都必须继续采用LGPL协议，除此以外的其他代码则不强制要求。\n如果您觉得LGPL许可证更多地是关注对类库文件的保护，而不是软件整体，那就对了。因为该许可证最早的名字是Library GPL，即GPL类库开源许可证，保护的对象有glibc、GTK widget toolkit等类库文件。\nBSD **伯克利软件发布版（**Berkeley Software Distribution, BSD）许可证：另一款被广泛使用的开源软件许可协议。相较于GPL许可证，BSD更加宽松，适合于商业用途。用户可以使用、修改和重新发布遵循该许可证的软件，并且可以将软件作为商业软件发布和销售，前提是需要满足下面3个条件。\n 如果再发布的软件中包含开源代码，则源代码必须继续遵循BSD许可证。\n如果再发布的软件中只有二进制程序，则需要在相关文档或版权文件中声明原始代码遵循了BSD许可证。\n不允许用原始软件的名字、作者名字或机构名称进行市场推广。\n Apache Apache许可证（Apache License）：顾名思义，是由Apache软件基金会负责发布和维护的开源许可协议。作为当今世界上最大的开源基金会，Apache不仅因此协议而出名，还因市场占有率第一的Web服务器软件而享誉行业。目前使用最广泛的Apache许可证是2004年发行的2.0版本，它在为开发人员提供版权及专利许可的同时，还允许用户拥有修改代码及再发布的自由。该许可证非常适合用于商业软件，现在热门的Hadoop、Apache HTTP Server、MongoDB等项目都是基于该许可证研发的。程序开发人员在开发遵循该许可证的软件时，要严格遵守下面4个条件。\n 该软件及其衍生品必须继续使用Apache许可证。\n如果修改了程序源代码，需要在文档中进行声明。\n若软件是基于他人的源代码编写而成的，则需要保留原始代码的许可证、商标、专利声明及原作者声明的其他内容信息。\n如果再发布的软件中有声明文件，则需在此文件中注明基于了Apache许可证及其他许可证。\n MIT MIT许可证（Massachusetts Institute of Technology License）：源于麻省理工学院，又称为X11协议。MIT许可证是目前限制最少的开源许可证之一，用户可以使用、复制、修改、再发布软件，而且只要在修改后的软件源代码中保留原作者的许可信息即可，因此普遍被商业软件（例如jQuery与Node.js）所使用。也就是说，MIT许可证宽松到一个新境界，即用户只要在代码中声明了MIT许可证和版权信息，就可以去做任何事情，而无须承担任何责任。\nMPL **Mozilla公共许可证（**Mozilla Public License，MPL）：于1998年初由Netscape公司的Mozilla小组设计，原因是它们认为GPL和BSD许可证不能很好地解决开发人员对源代码的需求和收益之间的平衡关系，因此便将这两个协议进行融合，形成了MPL。2012年年初，Mozilla基金会发布了MPL 2.0版本（目前为止也是最新的版本），后续被用在Firefox、Thunderbird等诸多产品上。最新版的MPL公共许可证有以下特点。\n 在使用基于MPL许可证的源代码时，后续只需要继续开源这部分特定代码即可，新研发的软件不用完全被该许可证控制。\n开发人员可以将基于MPL、GPL、BSD等多种许可证的代码一起混合使用。\n开发人员在发布新软件时，必须附带一个专门用于说明该程序的文件，内容要有原始代码的修改时间和修改方式。\n 总结 估计大家在看完上面琳琅满目的许可证后，会心生怨念：“这不都差不多吗？到底该选哪个呢？”写到这里时，刘遄老师也是一脸无助：“到底该怎么让大家进行选择呢？”搜肠刮肚之际突然眼前一亮，乌克兰程序员Paul Bagwell创作的一幅流程图正好对刚才讲过的这6款开源许可证进行了汇总归纳，具体如下图所示。\n开源许可证的选择流程图\n众所周知，绝大部分的开源软件在安装完毕之后即可使用，很难在软件界面中找到相关的收费信息。所以经常会有同学提问：“刘老师，开源社区的程序员总要吃饭的呀，他们是靠什么营利呢？”针对这个问题，网络上好像只有两种声音：\n **情怀——**开源社区的程序员觉悟好，本领强，写代码纯粹是为了兴趣以及造福社会；\n**服务——**先让用户把软件安装上，等用好、用习惯之后，再通过提供一些维护服务来营利。\n 这两种解释都各有道理，但是不够全面。读者也不要把开源软件和商业软件完全对立起来，因为好的项目也需要好的运营模式。就开源软件来讲，营利模式具体包括以下5种。\n 多条产品线：如MySQL数据库便有个人版和企业版两个版本，即个人版完全免费，起到了很好的推广作用；企业版则通过销售授权许可来营利。\n技术服务型：JBoss应用服务器便是典型代表，JBoss软件可自由免费使用，软件提供方通过技术文档、培训课程以及定制开发服务来盈利。\n软硬件结合：比如IBM公司在出售服务器时，一般会为用户捆绑销售AIX或Linux系统来确保硬件设施的营利。\n技术出版物：比如O\u0026rsquo;Reilly既是一家开源公司，也是一家出版商，诸多优秀图书都是由O\u0026rsquo;Reilly出版的。\n品牌和口碑：微软公司曾多次表示支持开源社区。大家对此可能会感到意外，但这是真的！Visual Studio Code、PowerShell、TypeScript等软件均已开源。大家是不是瞬间就对微软公司好感倍增了呢？买一份正版系统表示支持也就是人之常情了。\n SSH 原理与运用 数字签名与数字证书 鲍勃有两把钥匙，一把是公钥，另一把是私钥。\n鲍勃把公钥送给他的朋友们——帕蒂、道格、苏珊——每人一把。\n苏珊要给鲍勃写一封保密的信。她写完后用鲍勃的公钥加密，就可以达到保密的效果。\n鲍勃收信后，用私钥解密，就看到了信件内容。只要鲍勃的私钥不泄露，这封信就是安全的，即使落在别人手里，也无法解密。\n鲍勃给苏珊回信，决定采用\u0026quot;数字签名\u0026quot;。他写完后先用Hash函数，生成信件的摘要（digest）。\n然后，鲍勃使用私钥，对这个摘要加密，生成\u0026quot;数字签名\u0026quot;（signature）。\n鲍勃将这个签名，附在信件下面，一起发给苏珊。\n苏珊收信后，取下数字签名，用鲍勃的公钥解密，得到信件的摘要。由此证明，这封信确实是鲍勃发出的。\n苏珊再对信件本身使用Hash函数，将得到的结果，与上一步得到的摘要进行对比。如果两者一致，就证明这封信未被修改过。\n复杂的情况出现了。道格想欺骗苏珊，他偷偷使用了苏珊的电脑，用自己的公钥换走了鲍勃的公钥。此时，苏珊实际拥有的是道格的公钥，但是还以为这是鲍勃的公钥。因此，道格就可以冒充鲍勃，用自己的私钥做成\u0026quot;数字签名\u0026quot;，写信给苏珊，让苏珊用假的鲍勃公钥进行解密。\n后来，苏珊感觉不对劲，发现自己无法确定公钥是否真的属于鲍勃。她想到了一个办法，要求鲍勃去找\u0026quot;证书中心\u0026quot;（certificate authority，简称CA），为公钥做认证。证书中心用自己的私钥，对鲍勃的公钥和一些相关信息一起加密，生成\u0026quot;数字证书\u0026quot;（Digital Certificate）。\n鲍勃拿到数字证书以后，就可以放心了。以后再给苏珊写信，只要在签名的同时，再附上数字证书就行了。\n苏珊收信后，用CA的公钥解开数字证书，就可以拿到鲍勃真实的公钥了，然后就能证明\u0026quot;数字签名\u0026quot;是否真的是鲍勃签的。\n远程登录   1995年，芬兰学者 Tatu Ylonen 设计了 SSH 协议，用于计算机之间的加密登录。本文针对的实现是 OpenSSH。\n  基本用法：\n  假定你要以用户名 user，登录远程主机 host\nssh user@host   如果本地用户名与远程用户名一致，登录时可以省略用户名\nssh host   SSH 的默认端口是 22，使用 p 参数修这个端口\nssh -p 2222 user@host     中间人攻击（Man-in-the-middle attack）\n  SSH 加密登录过程\n 远程主机收到用户的登录请求，把自己的公钥发给用户。 用户使用这个公钥，将登录密码加密后，发送给远程主机。 远程主机用自己的私钥，解密登录密码，如果密码正确，就同意用户登录。      中间人攻击：攻击者插在用户与远程主机之间，用伪造的公钥，获取用户的登录密码，再用这个密码登录远程主机。\n  口令登录：第一次登录远程主机时，会询问是否接受远程主机公钥（是否继续连接），并显示公钥指纹——公钥长度较长（这里采用RSA算法，长达 1024 位），很难比对，所以对其进行MD5计算，将它变成一个 128 位的指纹。用户通过比对远程网站上贴出的公钥指纹，决定是否接受这个远程主机的公钥。当远程主机的公钥被接受以后，它就会被保存在文件 $HOME/.ssh/known_hosts 之中。\n  公钥登录：省去口令登录每次都必须输入密码的步骤。用户将自己的公钥储存在远程主机上，登录的时候，远程主机会向用户发送一段随机字符串，用户用自己的私钥加密后，再发回来，远程主机用事先储存的公钥进行解密，如果成功，就证明用户是可信的，直接允许登录shell，不再要求密码。\n  ssh-keygen\n在 $HOME/.ssh/ 目录下生成两个文件：公钥 id_rsa.pub 和私钥 id_rsa。\n    远程操作与端口转发   SSH 可以在用户和远程主机之间，建立命令和数据的传输通道\n  绑定本地端口：让那些不加密的网络连接，全部改走 SSH 连接\nssh -D 8080 user@host 建立一个 socket，去监听本地的 8080 端口。一旦有数据传向那个端口，就自动把它转移到 SSH 连接上面，发往远程主机。\n  本地端口转发：假定 host1 是本地主机，host2 是远程主机。由于种种原因，这两台主机之间无法连通。但是，另外还有一台 host3，可以同时连通前面两台主机。因此，很自然的想法就是，通过 host3，将 host1 连上 host2。\nssh -L 2121:host2:21 host3 L 参数接受三个值——\u0026ldquo;本地端口:目标主机:目标主机端口\u0026rdquo;。SSH 绑定本地端口 2121，指定 host3 将所有的数据转发到目标主机 host2 的 21 端口。本地端口转发使得 host1 和 host3 之间仿佛形成一个数据传输的秘密隧道，因此又被称为\u0026quot;SSH 隧道\u0026quot;。\n  远程端口转发：host1 与 host2 之间无法连通，必须借助 host3 转发，而 host3 是一台内网机器，它可以连接外网的 host1，但是反过来就不行。解决办法是从 host3 上建立与 host1 的 SSH 连接，然后在 host1 上使用这条连接。在 host3 执行下面的命令\nssh -R 2121:host2:21 host1 R 参数也是接受三个值——\u0026ldquo;远程主机端口:目标主机:目标主机端口\u0026rdquo;。它让 host1 监听它自己的 2121 端口，然后将所有数据经由 host3，转发到 host2 的 21 端口。\n  GitHub Packages Learn to safely publish and consume packages, store your packages alongside your code, and share your packages privately with your team or publicly with the open source community. You can also automate your packages with GitHub Actions.\nTip \u0026amp; Questions Repository size limits for GitHub.com Hard limits:\n Individual files in a repository are strictly limited to a 100 MB maximum size limit. Repositories have a hard size limit of 100GB.  解决SSH自动断线问题 在连接远程SSH服务的时候，经常会发生长时间后的断线，或者无响应（无法再键盘输入）。 总体来说有两个方法：\n一、客户端定时发送心跳\nputty、SecureCRT、XShell都有这个功能，设置请自行搜索\n此外在Linux下：\n  修改本机/etc/ssh/ssh_config\n# vim /etc/ssh/ssh_config   添加\nServerAliveInterval 30 ServerAliveCountMax 100 即每隔30秒，向服务器发出一次心跳。若超过100次请求，都没有发送成功，则会主动断开与服务器端的连接。\n  二、服务器端定时向客户端发送心跳（一劳永逸）\n  修改服务器端 ssh配置 /etc/ssh/sshd_config\n# vim /etc/ssh/sshd_config   添加\nClientAliveInterval 30 ClientAliveCountMax 6 ClientAliveInterval表示每隔多少秒，服务器端向客户端发送心跳，是的，你没看错。\n下面的ClientAliveInterval表示上述多少次心跳无响应之后，会认为Client已经断开。\n所以，总共允许无响应的时间是60*3=180秒。\n  ","permalink":"https://sakamotokurome.github.io/posts/git/","summary":"Workspace：工作区，Index / Stage：暂存区，Repository：仓库区（或本地仓库），Remote：远程仓库 远程仓库 安装，","title":"Git"},{"content":"Fedora [fəˈdɔrə] 费多拉\nFedora 定制版 为什么 Linus Torvalds 用 Fedora  2008：linus对发行版的要求是\u0026quot;易安装，比较贴近上游\u0026quot;即可。 2010年的时候，他指出了Fedora 14的一个bug。 2011年Fedora 15换Gnome3作为默认DE了，Linus直言\u0026quot;unholy mess\u0026quot; ，然后转投XFCE。 2011年末，Linus提出并修补了openSUSE中Xorg的一个严重bug。 2013年5月：Linus尝试将自己手头的MacBook Air装上Linux，把几个大的发行版全部都试了一遍。发现只有Fedora能正常工作。 之后的所有消息就是各种fedora了  SELinux 长久以来，每当遇到授权问题或者新安装的主机，我的第一反应是通过setenforce 0命令禁用SELinux，来减少产生的权限问题，但是这并不是一个良好的习惯。这篇文章尝试对SELinux的基本概念和用法进行简单介绍，并且提供一些更深入的资料。\nLinux下默认的接入控制是DAC，其特点是资源的拥有者可以对他进行任何操作（读、写、执行）。当一个进程准备操作资源时，Linux内核会比较进程和资源的UID和GID，如果权限允许，就可以进行相应的操作。此种方式往往会带来一些问题，如果一个进程是以root的身份运行，也就意味着他能够对系统的任何资源进行操作，而且不被限制。 假如我们的软件存在漏洞呢？这个往往是一个灾难性的问题。因此，就引出了另外的一种安全接入控制机制MAC，Linux下的一种现实是SELinux，也就是我们将要讨论的内容。\n基本概念 Mandatory Access Control (MAC) SELinux 属于MAC的具体实现，增强了Linux系统的安全性。MAC机制的特点在于，资源的拥有者，并不能决定谁可以接入到资源。具体决定是否可以接入到资源，是基于安全策略。而安全策略则是有一系列的接入规则组成，并仅有特定权限的用户有权限操作安全策略。\n一个简单的例子，则是一个程序如果要写入某个目录下的文件，在写入之前，一个特定的系统代码，将会依据进程的Context和资源的Context查询安全策略，并且根据安全策略决定是否允许写入文件。\nFlask Security Architecture SELinux的软件设计架构是参照Flask，Flask是一种灵活的操作系统安全架构，并且在Fluke research operating system中得到了实现。Flask的主要特点是把安全策略执行代码和安全策略决策代码，划分成了两个组件。安全策略决策代码在Flask架构中称作Security Server。除了这两个组件以外，另外一个组件Vector Cache(AVC), 主要提供策略决策结果的缓存，以此提高Security Server的性能。其具体执行流程为，安全策略执行代码通过AVC查询Security Server的安全策略决策结果，并将其缓存以备下次使用。\nLinux Security Module 前面两部分介绍了MAC机制和Flask架构，最终SELinux的实现是依赖于Linux提供的Linux Security Module框架简称为LSM。其实LSM的名字并不是特别准确，因为他并不是Linux模块，而是一些列的hook，同样也不提供任何的安全机制。LSM的的重要目标是提供对linux接入控制模块的支持。\nLSM 在内核数据结构中增加了安全字段，并且在重要的内核代码（系统调用）中增加了hook。可以在hook中注册回调函数对安全字段进行管理，以及执行接入控制。\nSELinux Security Enhanced Linux(SELinux) 为Linux 提供了一种增强的安全机制，其本质就是回答了一个“Subject是否可以对Object做Action?”的问题，例如 Web服务可以写入到用户目录下面的文件吗？其中Web服务就是Subject而文件就是Object，写入对应的就是Action。\n依照上面的例子，我们引入了几个概念，分别是Subject、Object、Action、以及例子没有体现出来的Context：\n Subject: 在SELinux里指的就是进程，也就是操作的主体。 Object： 操作的目标对象，例如 文件 Action： 对Object做的动作，例如 读取、写入或者执行等等 Context： Subject和Object都有属于自己的Context，也可以称作为Label。Context有几个部分组成，分别是SELinux User、SELinux Role、SELinux Type、SELinux Level。  用户程序执行的系统调用（例如读取文件），都要被SELinux依据安全策略进行检查。如果安全策略允许操作，则继续，否则将会抛出错误信息给应用程序。SELinux决策的同时还需要Subject和Object的Context信息，确定所属的User、Role和Type等信息，以此查询对应的安全策略进行决策。SELinux同样也使用了AVC机制用于缓存决策结果，以此来提高性能。\nSELinux Context 进程和文件都有属于自己的Context信息，Context分为几个部分，分别是 SELinux User、Role、Type 和一个可选的Level信息。SELinux在运行过程中将使用这些信息查询安全策略进行决策。\n SELinux User：每一个Linux用户都会映射到SELinux用户，每一个SELinux User都会对应相应的Role。 SELinux Role：每个Role也对应几种SELinux Type，并且充当了User和Type的‘中间人’ SELinux Type：安全策略使用SELinux Type制定规则，定义何种Domian（Type）的Subject，可以接入何种Type的Object。  显示进程的Context\n# ps -Z LABEL PID TTY TIME CMD unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 9509 pts/1 00:00:00 sudo unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 9515 pts/1 00:00:00 su unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 9516 pts/1 00:00:00 bash unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 9544 pts/1 00:00:00 ps 显示文件的Context信息\n# ls -Z system_u:object_r:admin_home_t:s0 anaconda-ks.cfg 临时修改文件的 SELinux Type\n# chcon -t httpd_sys_content_t file-name 恢复Context信息\n# restorecon [选项] \u0026lt;文件或目录 1\u0026gt; [\u0026lt;文件或目录 2\u0026gt;...]    选项 功能     -v 打印操作过程   -R 递归操作    添加目录的默认安全上下文\n如果提示找不到命令的话请安装 policycoreutils-python 软件包\n# semanage fcontext -a -t \u0026lt;文件安全上下文中的类型字段\u0026gt; \u0026#34;\u0026lt;目录（后面不加斜杠）\u0026gt;(/.*)?\u0026#34; 注：目录或文件的默认安全上下文可以通过 semanage fcontext -l 命令配合 grep 过滤查看。\n为 Nginx 新增一个网站目录 /usr/share/nginx/html2 之后，需要为其设置与原目录相同的默认安全上下文。\n# semanage fcontext -a -t httpd_sys_content_t \u0026#34;/usr/share/nginx/html2(/.*)?\u0026#34; 添加某类进程允许访问的端口\n# semanage port -a -t \u0026lt;服务类型\u0026gt; -p \u0026lt;协议\u0026gt; \u0026lt;端口号\u0026gt; 注：各种服务类型所允许的端口号可以通过 semanage port -l 命令配合 grep 过滤查看。\n为 Nginx 需要使用 10080 的端口用于 HTTP 服务。\nsemanage port -a -t http_port_t -p tcp 10080 SELinux 的运行状态 SELinux 有三个运行状态，分别是disabled, permissive 和 enforcing\n Disable： 禁用SELinux，不会给任何新资源打Label，如果重新启用的话，将会给资源重新打上Lable，过程会比较缓慢。 Permissive：如果违反安全策略，并不会真正的执行拒绝操作，替代的方式是记录一条log信息。 Enforcing: 默认模式，SELinux的正常状态，会实际禁用违反策略的操作  查看当前的运行状态\n# getenforceEnforcing 临时改变运行状态为Permissive\n# setenforce 0# getenforcePermissive 临时改变运行状态为 Enforcing\n# setenforce 1# getenforceEnforcing 使用sestatus可以查看完整的状态信息\n# sestatusSELinux status: enabledSELinuxfs mount: /sys/fs/selinuxSELinux root directory: /etc/selinuxLoaded policy name: targetedCurrent mode: enforcingMode from config file: enforcingPolicy MLS status: enabledPolicy deny_unknown status: allowedMax kernel policy version: 30 怎么启用SELinux 如果您的环境中禁用了 SELinux，则可以通过编辑 /etc/selinux/config 并设置 SELINUX=permissive 来启用 SElinux。由于 SELinux 当前尚未启用，因此最好不要将其设为立即强制执行，因为此时系统可能会出现误标记的事件，它会妨碍系统的正常启动。\n您可以在根目录中创建名为 .autorelabel 的空文件，然后重新启动，以此来强制系统自动为整个文件系统重新标记SELinux。如果系统中错误过多，应在允许模式下重新启动，以确保启动成功。重新标记所有内容后，利用 /etc/selinux/config 将 SELinux 设置为强制模式并重新启动，或运行 setenforce 1。\n如果系统管理员不太熟悉命令行，还可以选择用于管理 SELinux 的图形工具。\n针对 Linux 发行版中内置的系统，SELinux 提供了一道额外的防护层。保持开启 SELinux，就能在系统遭到破坏时保护您的系统。\nSELinux Log SELinux 的Log日志默认记录在/var/log/audit/audit.log\n# cat /var/log/audit/audit.logtype=AVC msg=audit(1223024155.684:49): avc: denied { getattr } for pid=2000 comm=\u0026#34;httpd\u0026#34; path=\u0026#34;/var/www/html/file1\u0026#34; dev=dm-0 ino=399185 scontext=unconfined_u:system_r:httpd_t:s0 tcontext=system_u:object_r:samba_share_t:s0 tclass=file /var/log/message 也会记录相应的信息，例如：\nMay 7 18:55:56 localhost setroubleshoot: SELinux is preventing httpd (httpd_t) \u0026#34;getattr\u0026#34; to /var/www/html/file1 (samba_share_t). For complete SELinux messages. run sealert -l de7e30d6-5488-466d-a606-92c9f40d316d SELinux 配置文件 SELinux的配置文件位于/etc/selinux/config。默认配置文件主要两部分，一个是SELinux的运行状态和SELinuxType。直接在配置文件中修改SELinux将会在下次启动时生效。\n# This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX=enforcing # SELINUXTYPE= can take one of these two values: # targeted - Targeted processes are protected, # mls - Multi Level Security protection. SELINUXTYPE=targeted SELinux Booleans Booleans允许在运行时修改SELinux安全策略。\n列出所有的Booleans选项\n# semanage boolean -l SELinux boolean State Default Description smartmon_3ware (off , off) Determine whether smartmon can... mpd_enable_homedirs (off , off) Determine whether mpd can traverse... 您可以通过运行 getsebool -a，找出系统中已设置的布尔值。\n临时修改httpd_can_network_connect_db状态为开启\n# setsebool [选项] \u0026lt;规则名称\u0026gt; \u0026lt;on|off\u0026gt; # setsebool httpd_can_network_connect_db on    选项 功能     -P 重启依然生效    Tips\u0026amp;Questions flatpak Cannot install apps. - Error: Failed to read commit it works for me:\nsudo flatpak repair Cannot open acess to console, the root account is locked\u0026hellip; 先是添加一个 LV 到 /etc/fstab，结果开机报错，原因是写错了：\nTime out ...Dependency failed for ... 结束后就 Cannot open acess to console, the root account is locked，什么也干不了，只能强制关机。\n解决方案是重启进入 Fedora Live CD，挂载 root，修改 /etc/fstab。但是无法挂载，挂载的是 Fedora Live CD 的 root，我 TM 佛了，原因应该是这两个名一模一样，Live CD 覆盖了 root。最后是用 Ubntu Live CD 解决。\n这告诉我们，不要只有一个 Live CD。这还告诉我们，先找自己的原因才能有耐心去解决问题。\ndmesg-x86/cpu: SGX disabled by BIOS SGX技术的分析和研究\nsnd_hda_codec_hdmi hdaudioC0D2: Monitor plugged-in, Failed to power up codec ret=[-13] set Kernel parameters，要使改变在重启后仍生效，您可以手动编辑 /boot/grub/grub.cfg。对于初学者，建议编辑 /etc/default/grub 并将您的内核选项添加至 GRUB_CMDLINE_LINUX_DEFAULT 行：\nGRUB_CMDLINE_LINUX_DEFAULT=\u0026quot;snd_hda_codec_hdmi.enable_silent_stream=0\u0026quot; 然后重新生成 grub.cfg 文件：\n# grub2grub-mkconfig2 -o /boot/grub2/grub.cfg Speed Up DNF 尝试更改参数\n$ sudo vi /etc/dnf/dnf.conf fastestmirror=true max_parallel_downloads=10 metadata_expire=2d  fastermirror 选择最快的镜像 max_parallel_downloads 一次下载多个包  尝试更换为清华源。\n如果在更新过程中某个小包下载不了，导致无法更新，尝试只使用 ipv4\n$ sudo dnf update -4 -v -y 第三方源 rpmfusion 第一步下载基础包(开源和闭源)， 这里我们使用bfsu来下载，以避免网络问题，终端输入:\nsudo yum install --nogpgcheck https://mirrors.bfsu.edu.cn/rpmfusion/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm https://mirrors.bfsu.edu.cn/rpmfusion/nonfree/fedora/rpmfusion-nonfree-release-$(rpm -E %fedora).noarch.rpm 第二步，使用bfsu镜像\nsudo sed -e \u0026#39;s/metalink/#metalink/g\u0026#39; -e \u0026#39;s|#baseurl=http://download1.rpmfusion.org/|baseurl Fedorafun 这里有一些国内常用软件，以及一些开源软件,终端输入：\nsudo sh -c \u0026#34;echo \u0026#39;[fedorafun] name=fedorafun baseurl=https://repo.fedora.fun/ enabled=1 countme=1 metadata_expire=7d repo_gpgcheck=0 type=rpm gpgcheck=0 skip_if_unavailable=False\u0026#39; \u0026gt; /etc/yum.repos.d/fedorafun.repo\u0026#34; CentOS Red Hat Enterprise Linux Developer Subscription Need to log in to download RHEL.\n怎样使用 Red Hat Subscription Manager (RHSM) 将系统注册到红帽客户门户网站？\n# subscription-manager register --username \u0026lt;username\u0026gt; --password \u0026lt;password\u0026gt; --auto-attach 配置 Red Hat Enterprise Linux 8 中基本系统设置的指南\nFrey\u0026rsquo;s Blog\n 所有文章 分类   关于多线程 概述 每个正在系统上运行的程序都是一个进程。每个进程包含一到N个线程。进程也可能是整个程序或者是部分程序的动态执行。线程是一组指令的集合，或者是程序的特殊段，它可以在程序里独立执行。也可以把它理解为代码运行的上下文。所以线程基本上是轻量级的进程，它负责在单个程序里执行多任务。通常由操作系统负责多个线程的调度和执行。线程是程序中一个单一的顺序控制流程。在单个程序中同时运行多个线程完成不同的工作,称为多线程。\n线程和进程的区别在于,子进程和父进程有不同的代码和数据空间,而多个线程则共享数据空间,每个线程有自己的执行堆栈和程序计数器为其执行上下文.多线程主要是为了节约CPU时间,发挥利用,根据具体情况而定. 线程的运行中需要使用计算机的内存资源和CPU。\n同步多线程（SMT）是一种在一个CPU 的时钟周期内能够执行来自多个线程的指令的硬件多线程技术。本质上，同步多线程是一种将线程级并行处理（多CPU）转化为指令级并行处理（同一CPU）的方法。 同步多线程是单个物理处理器从多个硬件线程上下文同时分派指令的能力。同步多线程用于在商用环境中及为周期/指令（CPI）计数较高的工作负载创造性能优势。 处理器采用超标量结构，最适于以并行方式读取及运行指令。同步多线程使您可在同一处理器上同时调度两个应用程序，从而利用处理器的超标量结构性质。\n超线程（HT, Hyper-Threading）是英特尔研发的一种技术，于2002年发布。通过此技术，英特尔实现在一个实体CPU中，提供两个逻辑线程。\n其实可以将SMT和HT理解为一个技术。\n Hyper-threading (officially called Hyper- ThreadingTechnology or HT Technology, and abbreviated as HTT orHT) is Intel’s proprietary simultaneous multithreading (SMT) implementation used to improve parallelization ofcomputations (doing multiple tasks at once) performed onx86 microprocessors.\n来自 https://cn.bing.com/search?q=intel+ht\u0026amp;go=%E6%8F%90%E4%BA%A4\u0026amp;qs=ds\u0026amp;form=QBLHCN\n 与多进程的区别  “进程——资源分配的最小单位，线程——程序执行的最小单位”\n 实际应用中基本上都是“进程+线程”的结合方式，千万不要真的陷入一种非此即彼的误区。\n   对比维度 多进程 多线程 总结     数据共享、同步 数据共享复杂，需要用IPC；数据是分开的，同步简单 因为共享进程数据，数据共享简单，但也是因为这个原因导致同步复杂 各有优势   内存、CPU 占用内存多，切换复杂，CPU利用率低 占用内存少，切换简单，CPU利用率高 线程占优   创建销毁、切换 创建销毁、切换复杂，速度慢 创建销毁、切换简单，速度很快 线程占优   编程、调试 编程简单，调试简单 编程复杂，调试复杂 进程占优   可靠性 进程间不会互相影响 一个线程挂掉将导致整个进程挂掉 进程占优   分布式 适应于多核、多机分布式；如果一台机器不够，扩展到多台机器比较简单 适应于多核分布式 进程占优     需要注意：   1）需要频繁创建销毁的优先用线程\n2）需要进行大量计算的优先使用线程\n3）强相关的处理用线程，弱相关的处理用进程\n一般的Server需要完成如下任务：消息收发、消息处理。“消息收发”和“消息处理”就是弱相关的任务，而“消息处理”里面可能又分为“消息解码”、“业务处理”，这两个任务相对来说相关性就要强多了。因此“消息收发”和“消息处理”可以分进程设计，“消息解码”、“业务处理”可以分线程设计。当然这种划分方式不是一成不变的，也可以根据实际情况进行调整。\n4）可能要扩展到多机分布的用进程，多核分布的用线程\n5）都满足需求的情况下，用你最熟悉、最拿手的方式\n来自 https://blog.csdn.net/lishenglong666/article/details/8557215\n 如何使用？ 需要CPU、BIOS、操作系统、应用软件都支持多线程技术才可以。\n支持多线程的CPU Power CPU 支持的SMT技术：\n Simultaneous multithreading (SMT) is a processor technology that allows multiple instruction streams (threads) to run concurrently on the same physical processor, improving overall throughput. To the operating system, each hardware thread is treated as an independent logical processor. Single-threaded (ST) execution mode is also supported.\n来自 https://www.ibm.com/support/knowledgecenter/SSFHY8_6.2/reference/am5gr_f0106.html?view=embed\n Intel CPU 支持的HT技术：\n Intel® Hyper-Threading Technology (Intel® HT Technology) uses processor resources more efficiently, enabling multiple threads to run on each core. As a performance feature, it also increases processor throughput, improving overall performance on threaded software. Intel® HT Technology is available on the latest Intel® Core™ vPro™ processors, the Intel® Core™ processor family, the Intel® Core™ M processor family, and the Intel® Xeon® processor family. By combining one of these Intel® processors and chipsets with an operating system and BIOS supporting Intel® HT Technology.\n来自 https://www.intel.com/content/www/us/en/architecture-and-technology/hyper-threading/hyper-threading-technology.html\n SMT/HT支持情况  Intel CPU : 2 Thread/Core Power9 CPU： 8 Thread /Core Sparc: 8 Thread /Core  RHEL7/CentOS7 \u0026amp; Intel CPU BIOS 中修改SMT/HT 的设置，使用这种方式Enable或者Disable后，将永久生效，需要重启。\nHyper-Threading Technology BIOS Setup Options For Intel® Desktop/Server Boards setup option location is the main menu of the BIOS setup program. • Located on the same menu screen that already had Processor Type, Processor Speed, System Bus Speed, and other related processor fields. • Setup Option Text ○ The field is called Hyper-Threading Technology. • Setup Option Values ○ The setup option values are Enabled and Disabled. • Setup Option Help Text 来自 \u0026lt;https://www.intel.com/content/www/us/en/support/articles/000007645/boards-and-kits/desktop-boards.html\u0026gt; RHEL/CentOS操作系统中查看多线程情况：（更多信息：https://access.redhat.com/solutions/rhel-smt）\n# lscpu | grep -e Socket -e Core -e Thread Thread(s) per core: 2 # 线程数 Core(s) per socket: 6 # core 数量 Socket(s): 2 或者\n# grep -H . /sys/devices/system/cpu/cpu*/topology/thread_siblings_list | sort -n -t ':' -k 2 -u # 显示 /sys/devices/system/cpu/cpu0/topology/thread_siblings_list:0 # 表示HT关闭 # 显示 /sys/devices/system/cpu/cpu0/topology/thread_siblings_list:0-1 # 表示 HT 启用 操作系统层关闭多线程有几种办法：\n 方法一：使用nosmt启动参数，需要新的x86 CPU，需要重启  # grubby --args=nosmt --update-kernel=DEFAULT # grub2-mkconfig -o /boot/grub/grub.conf # 创建新的grub.conf # reboot #重启  方法二：临时关闭，重启后失效  # echo off \u0026gt; /sys/devices/system/cpu/smt/control /sys/devices/system/cpu/smt/control: This file allows to read out the SMT control state and provides the ability to disable or (re)enable SMT. The possible states are: ============== =================================================== on SMT is supported by the CPU and enabled. All logical CPUs can be onlined and offlined without restrictions. off SMT is supported by the CPU and disabled. Only the so called primary SMT threads can be onlined and offlined without restrictions. An attempt to online a non-primary sibling is rejected forceoff Same as 'off' but the state cannot be controlled. Attempts to write to the control file are rejected. notsupported The processor does not support SMT. It's therefore not affected by the SMT implications of L1TF. Attempts to write to the control file are rejected. ============== =================================================== The possible states which can be written into this file to control SMT state are: - on - off - forceoff /sys/devices/system/cpu/smt/active: This file reports whether SMT is enabled and active, i.e. if on any physical core two or more sibling threads are online. AIX \u0026amp; Power Power9 CPU默认支持8线程，使用smtctl命令可以查看和修改 smt级别。更多内容查看https://www.ibm.com/support/knowledgecenter/ssw_aix_72/com.ibm.aix.cmds5/smtctl.htm\n 查看 SMT level  smtctl  临时修改 SMT level, # 可以是 1, 2, 4 or 8，重启后将恢复原来的smt level  smtctl -t 2 -w now  修改 SMT level永久生效，# 可以是 1, 2, 4 or 8，完成后需要使用bosboot创建启动设备   smtctl -t 4 -w boot bosboot -a # Creates complete boot image and device. RHEL7 \u0026amp; Power OpenPower CPU 默认支持4线程，安装RHEL后可以使用开源的工具 ppc64_cpu进行查看和修改多线程（更多查看 https://github.com/ibm-power-utilities/powerpc-utils）。\nppc64_cpu --------- This allows users to set the smt state, smt-snooze-delay and other settings on ppc64 processors. It also allows users to control the number of processor cores which are online (not in the sleep state). 来自 \u0026lt;https://github.com/ibm-power-utilities/powerpc-utils\u0026gt; 1，查看 SMT level\nppc64_cpu --smt 2，修改 SMT 级别， # is 1, 2, 4 or on\nppc64_cpu --smt=# 3， 关闭 smt支持\nppc64_cpu --smt=off 其他 oracle数据库 Oracle Database 在12c之前windows平台下支持多线程，Unix和Linux只支持多进程模式。在Oracle Database 12c中，Oracle引入了多线程模式，允许在Windows平台之外的Unix、Linux系统使用多线程模式，结合多进程与多线程模式，Oracle可以改进进程管理与性能。\n通过设置初始化参数threaded_execution，可以启用或关闭多线程模式，该参数缺省值为False，设置为TRUE启用12c的这个新特性：\nSQL\u0026gt; show parameter threaded_exec NAME TYPE VALUE --- threaded_execution boolean FALSE SQL\u0026gt; alter system set threaded_execution=true scope=spfile; System altered. 该参数重新启动数据库后生效，但是注意，多线程模式，不支持操作系统认证，不能直接启动数据库，需要提供SYS的密码认证后方能启动数据库：\nSQL\u0026gt; shutdown immediate; SQL\u0026gt; startup ORA-01017: invalid username/password; logon denied # 需要通过用户名和密码登录数据库。 用ps -ef 检查一下进程/线程：\n[oracle@enmocoredb dbs]$ ps -ef|grep ora_ oracle 27404 1 0 17:00 ? 00:00:00 ora_pmon_core oracle 27406 1 0 17:00 ? 00:00:00 ora_psp0_core oracle 27408 1 3 17:00 ? 00:00:05 ora_vktm_core oracle 27412 1 0 17:00 ? 00:00:00 ora_u004_core oracle 27418 1 0 17:00 ? 00:00:00 ora_u005_core oracle 27424 1 0 17:00 ? 00:00:00 ora_dbw0_core 其中U\u0026lt;NNN\u0026gt;进程是共享线程的\u0026quot;容器进程\u0026quot;，每个进程可以容纳100个线程。 来自 https://www.eygle.com/archives/2013/07/oracle_database_12c_multithreaded_model.html 连接热点   打开WIFI\nifconfig interface up   查看所有可用的无线网络信号\niw wlp2s0 scan | grep SSID   连接无线网\nwpa_supplicant -B -i wlp2s0 -c \u0026lt;(wpa_passphrase \u0026#34;SSID\u0026#34; \u0026#34;passwd\u0026#34;)   分配IP地址\ndhclient interface   查看无线网卡地址信息，有ip地址表示网络连接成功\nifconfig interface   PPPOE （ADSL）拨号上网   安装拨号软件\ndnf install rp-pppoe* ppp*   设定\npppoe-setup   拨号上网\npppoe-stoppppoe-start   安装中文输入法   安装 fcitx\ndnf install fcitx-im fcitx-configtool fcitx-googlepinyin   配置\n$ nano ~/.xprofile # or ~/.bashrc export GTK_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=\u0026#34;@im=fcitx\u0026#34;   fcitx 没图标：重装fcitx，在fcitx配置里关掉Kimpanel\n  关闭触摸板 $ dnf install xorg-x11-apps synclient TouchpadOff=1\t# 关闭 synclient TouchpadOff=0\t# 开启 用 MTP 挂载手机   安装jmtpfs\ndnf install jmtpfs   查看手机 “busnum”和“devnum”\njmptfs -l   建立挂载点\nmkdir /media/dir   挂载手机\njmtpfs -device=busnum,devnum /media/dir/   查找依赖 $ yum whatprovide package $ dnf provides package 默认字体 CentOS 默认字体目录 /lib/kbd/consolefonts\n纯命令行是不能使用系统之外的字体的。\nCentOS Minimal + Xfce base 源与 epel 源，使用用阿里镜像: https://developer.aliyun.com/mirror/\n  安装Xfce4，先安装 Xfce 可以保证不安装多余的包\ndnf group listdnf groupinstall Xfce   安装 X Window system\ndnf groupinstall \u0026#34;X Window system\u0026#34;   验证\nsystemctl isolate graphical.target   设置\n# 设置成命令模式systemctl set-default multi-user.target\t# 设置成图形模式systemctl set-default graphical.target\t   安装中文字体和中文输入法楷体字体\ndnf install cjkuni-ukai-fonts   输入法需要安装如下包：\n ibus， 这个包里有ibus-daemon这个平台服务器程序和ibus这个配置助手。 ibus-libpinyin， 这个是ibus平台下具体的拼音输入法。 im-chooser,这个是输入法平台选择助手程序。 执行im-chooser，选择输入法平台和输入法。重新登录系统。    xfce 主题\n 网站：xfce-look.org 主题目录： /usr/share/themes 或 ~/.themes 图标鼠标目录： /usr/share/icons 或 ~/.icons 壁纸： /usr/share/background , /usr/share/wallpapers Plank    EPEL EPEL的全称叫 Extra Packages for Enterprise Linux 。EPEL是由 Fedora 社区打造，为 RHEL 及衍生发行版如 CentOS、Scientific Linux 等提供高质量软件包的项目。装上了 EPEL之后，就相当于添加了一个第三方源。\n如果你知道rpmfusion.org的话，拿 rpmfusion 做比较还是很恰当的，rpmfusion 主要为桌面发行版提供大量rpm包（只有开源驱动才能进官方源，想要闭源驱动装rpmfusion），而EPEL则为服务器版本提供大量的rpm包，而且大多数rpm包在官方 repository 中是找不到的。\nopenSUSE /ˌoʊpənˈsuːzə/\n为什么选择 openSUSE Free and Open Source 确定你心目中的贡献者们是什么样的，从而聚拢到这样的人。\n狭义的自由开源概念 狭义的自由开源概念是：自由地开放源代码。即：软件作者把源代码公开发布，给予你修改并二次发布的权利。就这样，没别的了。\n测试、调试、故障受理与修复、接受新功能请求、接受代码合并请求、接受别人的帮助、用户社区建立、互动、整个自由开源生态的维护，统统都是完全没有，谁愿意干谁干，跟我没有关系。或者这么说：“写完拉倒”，哪怕洪水滔天。这从 GPL 许可证的“无保声明”中可以看出端倪。\n广义的自由开源概念 实际上如果你看过操作系统革命你就会明白：开放源代码其实并不是这一运动想要实现的全部，它的最终目的是普及自由精神，建立自由社区。\n目前这一精神在自由开源软件上的表现有：\n 源代码开源。 来自软件所有者的开发门槛为零。 不重新发明轮子。如果有已有实现并可以扩展，那么扩展它。 文档开源。使用维基等。 组织并形成用户互助社区。积极帮助用户（在不影响开发的前提下）。同时在开发上尽量面向用户，把用户的反应纳入到重大修改的考量因素当中去，积极采纳合理意见。 积极回应故障汇报并提供修复。 积极回应新功能请求。能做的做，不能做的解释原因寻求理解。 形成良性的贡献者添加内容和用户反馈渠道。 重视并维护由类似软件共同组成的生态的和谐稳定。（简单说就是：我开发 KDE 是因为 GNOME 满足不了我的需求，而不是为了搞死 GNOME。）  现在您可以拿来同狭义的自由开源概念做比较，发现如果说狭义的自由开源概念只是指某种行为，那么广义的自由开源概念已经是指一种氛围了。\nopenSUSE 秉持的自由开源概念 openSUSE 项目是完全做到“广义的自由开源概念”的社区。\n同时我们一直持有的相关理念还有：\n 积极的与上游合作。不“内化”补丁或修改，除非上游出于种种原因不收。 积极的为整个生态着想。 不搞歧视或二等公民。 尊重许可证、版权甚至是专利  如果你认同这些，那么您适合这个社区。\n配置 Install 语言请选择 English，因为 Linux 需要经常使用 Terminal，中文家目录并不方便。\n分区请选择默认的 btrfs 文件系统，有需要选择 Guided setup 和 Expert Partitioner。\nUse Snapper 默认开启。\nopenSUSE 镜像 我们官方的态度是不鼓励直接使用镜像的。\n因为比起「其它」发行版，我们 openSUSE 的技术力量比较强，开发了两个东西。\n一个叫做 Metalink，意思是这个格式（BT、Megalink 磁力链一样的格式）可以自动从 BT/FTP/HTTP 同时下载。\n另一个叫做 MirrorBrain，意思是我把所有的镜像地址隐藏起来，只暴露出一个中央服务器，所有人只需使用这个中央服务器（download.opensuse.org ），它会根据你的 IP 地理位置为你分配一个离你最近的镜像，但是在你那边显示的依旧是来自 download.opensuse.org。而如何分配是根据镜像管理员和中央服务器管理员当初的协定来确定的，比如镜像每月能够承受的流量、所愿意扮演的角色（是区域中心、地标式的镜像比如北交大、中科大，还是小镜像）等。\n而根据 openSUSE 软件源的构造，所有的 RPM 包都是从镜像获得的，所有的 metadata（元数据）都是从主镜像（位于德国）获得的，所以你源刷新的慢，只能证明你被我们光荣伟大的放火长城拖住了，而不能证明 openSUSE 项目有错，也代表不了你下载 RPM 包时的速度。\n申报自己为官方镜像。\nUninstall Discover Discover is the software center that is shipped with Plasma 5. Discover is infamous for its crashes, and it’s not a very good app overall. On top of that, it also adds redundancy since we already have Yast.\nYou can safely remove Discover:\nOpen Yast → Software Management → Search for `discover` → Right-click → Delete → Toggle #1 (deinstallation of discover packages) → Accept or\nsudo zypper remove packagekit 在 System Tray Setting 里面关闭 Software Updates 的通知。\n取消推荐的软件包 \u0026amp; 删除模组 打开 YaST ，点击 软件管理 ，再点击左上角的 依赖项 ，取消勾选 安装被推荐的软件包 。这样你的电脑就不会在某次更新后出现一些不是你主动安装的软件包。\n在 软件管理 页面，点击 视图，选择 模组 ，然后你就能看到按模组分类的包。例如你可以在此页面直接用鼠标右键单击 游戏 ，选择 不安装 或 卸载，卸载全部的预装的 KDE/Gnome 游戏包。\nUpdate System openSUSE Leap 是 openSUSE 打造定期释出的 Linux 发行版本的一种全新方式。 Leap 使用 SUSE Linux Enterprise（SLE） 的源代码，使 Leap 具有其它 Linux 发行版无法比拟的稳定性，并将其与社区开发相结合，为用户、开发人员和系统管理员提供最佳的 Linux 体验。贡献者和企业为 Leap 所做的贡献使它成为了提供成熟的软件包的 SLE 和提供最新的软件包的 Tumbleweed 这两者之间的桥梁。\nLeap 用户将会定期收到安全更新和补丁修复，如果你希望应用这些更新，在终端下用 Root 运行：\nsudo zypper patch zypper patch 只会更新列在 patchinfo 上面的包。\n有时，第三方软件源会提供一些功能性的更新，如果你希望应用这些更新，在终端下用 Root 运行：\nsudo zypper update OBS Package Installer \u0026amp; Flatpak 如果你想在终端直接查找来自 OBS 的软件包，你可以先安装 opi，同理添加 fltapak 仓库。\nsudo zypper in opi sudo flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo 然后输入你想要查找的软件包的名称，例如你要安装 qbittorrent enhanced edition ，你可以：\n$ opi qbittorrent $ flathub install netease 中文社区源是 openSUSE 中文社区的开发者们为用户构建、打包和收录一些发起自中文 Linux 圈子的软件或中文 Linux 圈子常用的软件。\nAdd Community Repositories That’s where community repositories come in. The most important one is Packman. For Leap:\nsudo zypper ar -cfp 90 'https://ftp.gwdg.de/pub/linux/misc/packman/suse/openSUSE_Leap_$releasever/' packman Open RPM with Yast Select any RPM package → Right-click → Properties → File Type Options → Move Yast to the first place → Apply Install Multimedia Codecs openSUSE 默认是没有部分多媒体编解码器的，包括家喻户晓的 MP3、AVI 等。这是因为它们是受限媒体格式。具体解释见openSUSE 编解码器一键安装、常见编解码器对应软件包/源说明、及版权须知。\nsudo zypper in opi \u0026amp;\u0026amp; opi codecs or, In order to install the H264/AVC support on your system, type in:\nsudo zypper install x264 libx265-130 libx264-148 或者通过 Packman 安装解码器\nzypper ar -cfp 90 https://mirrors.ustc.edu.cn/packman/suse/openSUSE_Leap_$releasever packmansudo zypper refreshsudo zypper dist-upgrade --from packman --allow-vendor-changesudo zypper install --from packman ffmpeg gstreamer-plugins-{good,bad,ugly,libav} libavcodec-full vlc-codecs Turn on Night Color Night color reduces the amount of blue light at night.\nOpen System Settings → Display and Monitor → Night Color → Activate Night Color → Apply Theme 在系统设置 startup and shutdown 下载使用个主题，因为默认主题输入密码的时候密码总是没有居中，跑到上面去了。\n或者，使用一个全局主题，例如 Layan。\nDisable touchpad 对于 touchpad 选择 Disable touchpad when mouse is pulgged in\n用户字体 Dolphin 下单击安装字体目录为\n/home/用户名/.fonts 如果下载好的字体文件无法直接点开安装（例如 *.ttc），或者字体太多，不想一个一个地安装，可以将字体文件全部放到字体文件夹中。然后运行：\nfc-cache -fv 输入法 在Yast中安装第二语言，就会自动安装fcitx并添加中文支持。\n词库\nFcitx 的 Libpinyin 可以直接在线导入搜狗细胞词库。不需要安装sougou输入法。\n需要安装 fcitx-pinyin-tools/fcitx-table-tools 这两个包，以添加处理词库的工具。\nsudo zypper in fcitx-pinyin-tools fcitx-table-tools 词库少了的话，也不好用，但是一次只能导入一个细胞词库。网上可以找到比较全的词库包。\n通过 7zr 解压过后将所有 txt 词库拷贝到 ~/.config/fcitx/libpinyin/importdict 即可。\n7zr x txt.7z 搜狗拼音\nsudo opi sogou-pinyin cloudpinyin\n根据文档，可以使用 libpinyin + cloudpinyin，哪怕不用导入词典，依旧很好用。果然，还是云词库的力量强大。\nsudo zypper in fcitx-cloudpinyin 默认的云输入引擎是 Google ，国内直接访问很不流畅，你可以打开输入法的配置，点击 Addon Config，找到 Cloud Pinyin ，点击右侧的设置，在弹出的窗口中，将 Google 替换为 Baidu 。\nKDE Connect KDE Connect 是一款能够方便手机与电脑进行连接的应用。\n 文件互传 共享剪贴板 远程输入 响铃，即既可以用电脑来找手机，也可以用手机找电脑。 幻灯片遥控器 多媒体控制 执行命令 共享通知  默认 kdeconnect 在防火墙那边是没放开的，要操作一下\nsudo firewall-cmd --zone=public --permanent --add-service=kdeconnect-kdesudo firewall-cmd --reload 装入 NTFS 分区   安装 ntfs-3g。\nsudo zypper in ntfs-3g   创建一个要充当安装点的目录，如 ~/mounts/windows。\nmkdir ~/mounts/windows   确定所需的 Windows 分区。\nsudo fdisk -l   以读写模式装入分区。使用相应的 Windows 分区替换占位符 DEVICE：\nntfs-3g /dev/DEVICE MOUNT POINT 要在只读模式下使用 Windows 分区，请追加 -o ro\nntfs-3g /dev/DEVICE MOUNT POINT -o ro ntfs-3g 命令使用当前用户 (UID) 和组 (GID) 装入给定设备。如果要为其他用户设置写权限，请使用命令 id  USER 获取 UID 和 GID 值的输出。设置方式：\nid usernamentfs-3g /dev/DEVICE MOUNT POINT -o uid=1000,gid=100   要卸载资源，请运行 fusermount -u 安装点。\n  任务栏透明化 Go to System Settings | Window Management | Window Rules. Press New\u0026hellip; button. Give some description to the new rule, Dock Transparency, for example. Then select only Dock (panel) in \u0026ldquo;Window type\u0026rdquo; field.\n之后在 Appearance \u0026amp; Fixes 中调整 opacity。\nBtrfs 文件系统似乎是内核中比较稳定的部分，多年来，人们一直使用 ext2/3，ext 文件系统以其卓越的稳定性成为了事实上的 Linux 标准文件系统。近年来 ext2/3 暴露出了一些扩展性问题，于是便催生了 ext4 。在 2008 年发布的 Linux2.6.19 内核中集成了 ext4 的 dev 版本。 2.6.28 内核发布时，ext4 结束了开发版，开始接受用户的使用。似乎 ext 就将成为 Linux 文件系统的代名词。然而当您阅读很多有关 ext4 的文章时，会发现都不约而同地提到了 btrfs，并认为 ext4 将是一个过渡的文件系统。 ext4 的作者 Theodore Tso 也盛赞 btrfs 并认为 btrfs 将成为下一代 Linux 标准文件系统。 Oracle，IBM， Intel 等厂商也对 btrfs 表现出了极大的关注，投入了资金和人力。为什么 btrfs 如此受人瞩目呢。这便是本文首先想探讨的问题。\nKevin Bowling 有一篇介绍各种文件系统的文章，在他看来，ext2/3 等文件系统属于“古典时期”。文件系统的新时代是 2005 年由 Sun 公司的 ZFS 开创的。 ZFS 代表” last word in file system ”，意思是此后再也不需要开发其他的文件系统了。 ZFS 的确带来了很多崭新的观念，对文件系统来讲是一个划时代的作品。\n如果您比较 btrfs 的特性，将会发现 btrfs 和 ZFS 非常类似。也许我们可以认为 btrfs 就是 Linux 社区对 ZFS 所作出的回应。从此往后在 Linux 中也终于有了一个可以和 ZFS 相媲美的文件系统。\nBtrfs 的特性 您可以在 btrfs 的主页上看到 btrfs 的特性列表。我自作主张，将那张列表分成了四大部分。\n首先是扩展性 (scalability) 相关的特性，btrfs 最重要的设计目标是应对大型机器对文件系统的扩展性要求。 Extent，B-Tree 和动态 inode 创建等特性保证了 btrfs 在大型机器上仍有卓越的表现，其整体性能而不会随着系统容量的增加而降低。\n其次是数据一致性 (data integrity) 相关的特性。系统面临不可预料的硬件故障，Btrfs 采用 COW 事务技术来保证文件系统的一致性。 btrfs 还支持 checksum，避免了 silent corrupt 的出现。而传统文件系统则无法做到这一点。\n第三是和多设备管理相关的特性。 Btrfs 支持创建快照 (snapshot)，和克隆 (clone) 。 btrfs 还能够方便的管理多个物理设备，使得传统的卷管理软件变得多余。\n最后是其他难以归类的特性。这些特性都是比较先进的技术，能够显著提高文件系统的时间 / 空间性能，包括延迟分配，小文件的存储优化，目录索引等。\n扩展性相关的特性 B-Tree\nbtrfs 文件系统中所有的 metadata 都由 BTree 管理。使用 BTree 的主要好处在于查找，插入和删除操作都很高效。可以说 BTree 是 btrfs 的核心。\n一味地夸耀 BTree 很好很高效也许并不能让人信服，但假如稍微花费一点儿时间看看 ext2/3 中元数据管理的实现方式，便可以反衬出 BTree 的优点。\n妨碍 ext2/3 扩展性的一个问题来自其目录的组织方式。目录是一种特殊的文件，在 ext2/3 中其内容是一张线性表格。\n图中展示了一个 ext2 目录文件的内容，该目录中包含四个文件。分别是 \u0026ldquo;home1\u0026rdquo;，\u0026ldquo;usr\u0026rdquo;，\u0026ldquo;oldfile\u0026rdquo; 和 \u0026ldquo;sbin\u0026rdquo; 。如果需要在该目录中查找目录 sbin，ext2 将遍历前三项，直至找到 sbin 这个字符串为止。\n这种结构在文件个数有限的情况下是比较直观的设计，但随着目录下文件数的增加，查找文件的时间将线性增长。 2003 年，ext3 设计者开发了目录索引技术，解决了这个问题。目录索引使用的数据结构就是 BTree 。如果同一目录下的文件数超过 2K，inode 中的 i_data 域指向一个特殊的 block 。在该 block 中存储着目录索引 BTree 。 BTree 的查找效率高于线性表，\n但为同一个元数据设计两种数据结构总是不太优雅。在文件系统中还有很多其他的元数据，用统一的 BTree 管理是非常简单而优美的设计。\nBtrfs 内部所有的元数据都采用 BTree 管理，拥有良好的可扩展性。 btrfs 内部不同的元数据由不同的 Tree 管理。在 superblock 中，有指针指向这些 BTree 的根。如图 2 所示：\nFS Tree 管理文件相关的元数据，如 inode，dir 等； Chunk tree 管理设备，每一个磁盘设备都在 Chunk Tree 中有一个 item ； Extent Tree 管理磁盘空间分配，btrfs 每分配一段磁盘空间，便将该磁盘空间的信息插入到 Extent tree 。查询 Extent Tree 将得到空闲的磁盘空间信息； Tree of tree root 保存很多 BTree 的根节点。比如用户每建立一个快照，btrfs 便会创建一个 FS Tree 。为了管理所有的树，btrfs 采用 Tree of tree root 来保存所有树的根节点； checksum Tree 保存数据块的校验和。\n基于 Extent 的文件存储\n现代很多文件系统都采用了 extent 替代 block 来管理磁盘。 Extent 就是一些连续的 block，一个 extent 由起始的 block 加上长度进行定义。\nExtent 能有效地减少元数据开销。为了进一步理解这个问题，我们还是看看 ext2 中的反面例子。\next2/3 以 block 为基本单位，将磁盘划分为多个 block 。为了管理磁盘空间，文件系统需要知道哪些 block 是空闲的。 Ext 使用 bitmap 来达到这个目的。 Bitmap 中的每一个 bit 对应磁盘上的一个 block，当相应 block 被分配后，bitmap 中的相应 bit 被设置为 1 。这是很经典也很清晰的一个设计，但不幸的是当磁盘容量变大时，bitmap 自身所占用的空间也将变大。这就导致了扩展性问题，随着存储设备容量的增加，bitmap 这个元数据所占用的空间也随之增加。而人们希望无论磁盘容量如何增加，元数据不应该随之线形增加，这样的设计才具有可扩展性。\n下图比较了 block 和 extent 的区别：\n在 ext2/3 中，10 个 block 需要 10 个 bit 来表示；在 btrfs 中则只需要一个元数据。对于大文件，extent 表现出了更加优异的管理性能。\nExtent 是 btrfs 管理磁盘空间的最小单位，由 extent tree 管理。 Btrfs 分配 data 或 metadata 都需要查询 extent tree 以便获得空闲空间的信息。\n动态 inode 分配\n为了理解动态 inode 分配，还是需要借助 ext2/3 。下表列举了 ext2 文件系统的限制：\n限制最大文件数量文件系统空间大小 V / 8192\n比如 100G 大小的文件系统中，能创建的文件个数最大为 131072\n下图显示了 ext2 的磁盘布局：\n在 ext2 中 inode 区是被预先固定分配的，且大小固定，比如一个 100G 的分区中，inode table 区中只能存放 131072 个 inode，这就意味着不可能创建超过 131072 个文件，因为每一个文件都必须有一个唯一的 inode 。\n为了解决这个问题，必须动态分配 inode 。每一个 inode 只是 BTree 中的一个节点，用户可以无限制地任意插入新的 inode，其物理存储位置是动态分配的。所以 btrfs 没有对文件个数的限制。\n针对 SSD 的优化支持\nSSD 是固态存储 Solid State Disk 的简称。在过去的几十年中，CPU/RAM 等器件的发展始终遵循着摩尔定律，但硬盘 HDD 的读写速率却始终没有飞跃式的发展。磁盘 IO 始终是系统性能的瓶颈。\nSSD 采用 flash memory 技术，内部没有磁盘磁头等机械装置，读写速率大幅度提升。 flash memory 有一些不同于 HDD 的特性。 flash 在写数据之前必须先执行擦除操作；其次，flash 对擦除操作的次数有一定的限制，在目前的技术水平下，对同一个数据单元最多能进行约 100 万次擦除操作，因此，为了延长 flash 的寿命，应该将写操作平均到整个 flash 上。\nSSD 在硬件内部的微代码中实现了 wear leveling 等分布写操作的技术，因此系统无须再使用特殊的 MTD 驱动和 FTL 层。虽然 SSD 在硬件层面做了很多努力，但毕竟还是有限。文件系统针对 SSD 的特性做优化不仅能提高 SSD 的使用寿命，而且能提高读写性能。 Btrfs 是少数专门对 SSD 进行优化的文件系统。 btrfs 用户可以使用 mount 参数打开对 SSD 的特殊优化处理。\nBtrfs 的 COW 技术从根本上避免了对同一个物理单元的反复写操作。如果用户打开了 SSD 优化选项，btrfs 将在底层的块空间分配策略上进行优化：将多次磁盘空间分配请求聚合成一个大小为 2M 的连续的块。大块连续地址的 IO 能够让固化在 SSD 内部的微代码更好的进行读写优化，从而提高 IO 性能。\n数据一致性相关的特性 COW 事务\n理解 COW 事务，必须首先理解 COW 和事务这两个术语。\n所谓 COW，即每次写磁盘数据时，先将更新数据写入一个新的 block，当新数据写入成功之后，再更新相关的数据结构指向新 block 。\nCOW 只能保证单一数据更新的原子性。但文件系统中很多操作需要更新多个不同的元数据，比如创建文件需要修改以下这些元数据：\n 修改 extent tree，分配一段磁盘空间 创建一个新的 inode，并插入 FS Tree 中 增加一个目录项，插入到 FS Tree 中  任何一个步骤出错，文件便不能创建成功，因此可以定义为一个事务。\n下面将演示一个 COW 事务。\nA 是 FS Tree 的根节点，新的 inode 的信息将被插入节点 C 。首先，btrfs 将 inode 插入一个新分配的 block C ’中，并修改上层节点 B，使其指向新的 block C ’；修改 B 也将引发 COW，以此类推，引发一个连锁反应，直到最顶层的 Root A 。当整个过程结束后，新节点 A ’变成了 FS Tree 的根。但此时事务并未结束，superblock 依然指向 A 。\n接下来，修改目录项（E 节点），同样引发这一过程，从而生成新的根节点 A ’’。\n此时，inode 和目录项都已经写入磁盘，可以认为事务已经结束。 btrfs 修改 superblock，使其指向 A ’’，如下图所示：\nCOW 事务能够保证文件系统的一致性，并且系统 Reboot 之后不需要执行 fsck 。因为 superblock 要么指向新的 A ’’，要么指向 A，无论哪个都是一致的数据。\nChecksum\nChecksum 技术保证了数据的可靠性，避免 silent corruption 现象。由于硬件原因，从磁盘上读出的数据会出错。比如 block A 中存放的数据为 0x55，但读取出来的数据变是 0x54，因为读取操作并未报错，所以这种错误不能被上层软件所察觉。\n解决这个问题的方法是保存数据的校验和，在读取数据后检查校验和。如果不符合，便知道数据出现了错误。\next2/3 没有校验和，对磁盘完全信任。而不幸的是，磁盘的错误始终存在，不仅发生在廉价的 IDE 硬盘上，昂贵的 RAID 也存在 silent corruption 问题。而且随着存储网络的发展，即使数据从磁盘读出正确，也很难确保能够安全地穿越网络设备。\nbtrfs 在读取数据的同时会读取其相应的 checksum 。如果最终从磁盘读取出来的数据和 checksum 不相同，btrfs 会首先尝试读取数据的镜像备份，如果数据没有镜像备份，btrfs 将返回错误。写入磁盘数据之前，btrfs 计算数据的 checksum 。然后将 checksum 和数据同时写入磁盘。\nBtrfs 采用单独的 checksum Tree 来管理数据块的校验和，把 checksum 和 checksum 所保护的数据块分离开，从而提供了更严格的保护。假如在每个数据 block 的 header 中加入一个域保存 checksum，那么这个数据 block 就成为一个自己保护自己的结构。这种结构下有一种错误无法检测出来，比如本来文件系统打算从磁盘上读 block A，但返回了 block B，由于 checksum 在 block 内部，因此 checksum 依旧是正确的。 btrfs 采用 checksum tree 来保存数据块的 checksum，避免了上述问题。\nBtrfs 采用 crc32 算法计算 checksum，在将来的开发中会支持其他类型的校验算法。为了提高效率，btrfs 将写数据和 checksum 的工作分别用不同的内核线程并行执行。\n多设备管理相关的特性 每个 Unix 管理员都曾面临为用户和各种应用分配磁盘空间的任务。多数情况下，人们无法事先准确地估计一个用户或者应用在未来究竟需要多少磁盘空间。磁盘空间被用尽的情况经常发生，此时人们不得不试图增加文件系统空间。传统的 ext2/3 无法应付这种需求。\n很多卷管理软件被设计出来满足用户对多设备管理的需求，比如 LVM 。 Btrfs 集成了卷管理软件的功能，一方面简化了用户命令；另一方面提高了效率。\n多设备管理\nBtrfs 支持动态添加设备。用户在系统中增加新的磁盘之后，可以使用 btrfs 的命令将该设备添加到文件系统中。\n为了灵活利用设备空间，Btrfs 将磁盘空间划分为多个 chunk 。每个 chunk 可以使用不同的磁盘空间分配策略。比如某些 chunk 只存放 metadata，某些 chunk 只存放数据。一些 chunk 可以配置为 mirror，而另一些 chunk 则可以配置为 stripe 。这为用户提供了非常灵活的配置可能性。\nSubvolume\nSubvolume 是很优雅的一个概念。即把文件系统的一部分配置为一个完整的子文件系统，称之为 subvolume 。\n采用 subvolume，一个大的文件系统可以被划分为多个子文件系统，这些子文件系统共享底层的设备空间，在需要磁盘空间时便从底层设备中分配，类似应用程序调用 malloc() 分配内存一样。可以称之为存储池。这种模型有很多优点，比如可以充分利用 disk 的带宽，可以简化磁盘空间的管理等。\n所谓充分利用 disk 的带宽，指文件系统可以并行读写底层的多个 disk，这是因为每个文件系统都可以访问所有的 disk 。传统的文件系统不能共享底层的 disk 设备，无论是物理的还是逻辑的，因此无法做到并行读写。\n所谓简化管理，是相对于 LVM 等卷管理软件而言。采用存储池模型，每个文件系统的大小都可以自动调节。而使用 LVM，如果一个文件系统的空间不够了，该文件系统并不能自动使用其他磁盘设备上的空闲空间，而必须使用 LVM 的管理命令手动调节。\nSubvolume 可以作为根目录挂载到任意 mount 点。 subvolume 是非常有趣的一个特性，有很多应用。\n假如管理员只希望某些用户访问文件系统的一部分，比如希望用户只能访问 /var/test/ 下面的所有内容，而不能访问 /var/ 下面其他的内容。那么便可以将 /var/test 做成一个 subvolume 。 /var/test 这个 subvolume 便是一个完整的文件系统，可以用 mount 命令挂载。比如挂载到 /test 目录下，给用户访问 /test 的权限，那么用户便只能访问 /var/test 下面的内容了。\n快照和克隆\n快照是对文件系统某一时刻的完全备份。建立快照之后，对文件系统的修改不会影响快照中的内容。这是非常有用的一种技术。\n比如数据库备份。假如在时间点 T1，管理员决定对数据库进行备份，那么他必须先停止数据库。备份文件是非常耗时的操作，假如在备份过程中某个应用程序修改了数据库的内容，那么将无法得到一个一致性的备份。因此在备份过程中数据库服务必须停止，对于某些关键应用这是不能允许的。\n利用快照，管理员可以在时间点 T1 将数据库停止，对系统建立一个快照。这个过程一般只需要几秒钟，然后就可以立即重新恢复数据库服务。此后在任何时候，管理员都可以对快照的内容进行备份操作，而此时用户对数据库的修改不会影响快照中的内容。当备份完成，管理员便可以删除快照，释放磁盘空间。\n快照一般是只读的，当系统支持可写快照，那么这种可写快照便被称为克隆。克隆技术也有很多应用。比如在一个系统中安装好基本的软件，然后为不同的用户做不同的克隆，每个用户使用自己的克隆而不会影响其他用户的磁盘空间。非常类似于虚拟机。\nBtrfs 支持 snapshot 和 clone 。这个特性极大地增加了 btrfs 的使用范围，用户不需要购买和安装昂贵并且使用复杂的卷管理软件。下面简要介绍一下 btrfs 实现快照的基本原理。\n如前所述 Btrfs 采用 COW 事务技术，从图 COW transaction 3 可以看到，COW 事务结束后，如果不删除原来的节点 A,C,E，那么 A,C,E,D,F 依然完整的表示着事务开始之前的文件系统。这就是 snapshot 实现的基本原理。\nBtrfs 采用引用计数决定是否在事务 commit 之后删除原有节点。对每一个节点，btrfs 维护一个引用计数。当该节点被别的节点引用时，该计数加一，当该节点不再被别的节点引用时，该计数减一。当引用计数归零时，该节点被删除。对于普通的 Tree Root, 引用计数在创建时被加一，因为 Superblock 会引用这个 Root block 。很明显，初始情况下这棵树中的所有其他节点的引用计数都为一。当 COW 事务 commit 时，superblock 被修改指向新的 Root A ’’，原来 Root block A 的引用计数被减一，变为零，因此 A 节点被删除。 A 节点的删除会引发其子孙节点的引用计数也减一，图 COW transaction 3 中的 B，C 节点的引用计数因此也变成了 0，从而被删除。 D,E 节点在 COW 时，因为被 A ’’所引用，计数器加一，因此计数器这时并未归零，从而没有被删除。\n创建 Snapshot 时，btrfs 将的 Root A 节点复制到 sA，并将 sA 的引用计数设置为 2 。在事务 commit 的时候，sA 节点的引用计数不会归零，从而不会被删除，因此用户可以继续通过 Root sA 访问 snapshot 中的文件。\n软件 RAID\nRAID 技术有很多非常吸引人的特性，比如用户可以将多个廉价的 IDE 磁盘组合为 RAID0 阵列，从而变成了一个大容量的磁盘； RAID1 和更高级的 RAID 配置还提供了数据冗余保护，从而使得存储在磁盘中的数据更加安全。\nBtrfs 很好的支持了软件 RAID，RAID 种类包括 RAID0,RAID1 和 RAID10.\nBtrfs 缺省情况下对 metadata 进行 RAID1 保护。前面已经提及 btrfs 将设备空间划分为 chunk，一些 chunk 被配置为 metadata，即只存储 metadata 。对于这类 chunk，btrfs 将 chunk 分成两个条带，写 metadata 的时候，会同时写入两个条带内，从而实现对 metadata 的保护。\n其他特性 Btrfs 主页上罗列的其他特性不容易分类，这些特性都是现代文件系统中比较先进的技术，能够提高文件系统的时间或空间效率。\nDelay allocation\n延迟分配技术能够减少磁盘碎片。在 Linux 内核中，为了提高效率，很多操作都会延迟。\n在文件系统中，小块空间频繁的分配和释放会造成碎片。延迟分配是这样一种技术，当用户需要磁盘空间时，先将数据保存在内存中。并将磁盘分配需求发送给磁盘空间分配器，磁盘空间分配器并不立即分配真正的磁盘空间。只是记录下这个请求便返回。\n磁盘空间分配请求可能很频繁，所以在延迟分配的一段时间内，磁盘分配器可以收到很多的分配请求，一些请求也许可以合并，一些请求在这段延迟期间甚至可能被取消。通过这样的“等待”，往往能够减少不必要的分配，也有可能将多个小的分配请求合并为一个大的请求，从而提高 IO 效率。\nInline file\n系统中往往存在大量的小文件，比如几百个字节或者更小。如果为其分配单独的数据 block，便会引起内部碎片，浪费磁盘空间。 btrfs 将小文件的内容保存在元数据中，不再额外分配存放文件数据的磁盘块。改善了内部碎片问题，也增加了文件的访问效率。\n上图显示了一个 BTree 的叶子节点。叶子中有两个 extent data item 元数据，分别用来表示文件 file1 和 file2 所使用的磁盘空间。\n假设 file1 的大小仅为 15 个字节； file2 的大小为 1M 。如图所示，file2 采用普通的 extent 表示方法：extent2 元数据指向一段 extent，大小为 1M，其内容便是 file2 文件的内容。\n而对于 file1， btrfs 会把其文件内容内嵌到元数据 extent1 中。如果不采用 inline file 技术。如虚线所示，extent1 指向一个最小的 extent，即一个 block，但 file1 有 15 个字节，其余的空间便成为了碎片空间。\n采用 inline 技术，读取 file1 时只需要读取元数据 block，而无需先读取 extent1 这个元数据，再读取真正存放文件内容的 block，从而减少了磁盘 IO 。\n得益于 inline file 技术，btrfs 处理小文件的效率非常高，也避免了磁盘碎片问题。\nDirectory index\n当一个目录下的文件数目巨大时，目录索引可以显著提高文件搜索时间。 Btrfs 本身采用 BTree 存储目录项，所以在给定目录下搜索文件的效率是非常高的。\n然而，btrfs 使用 BTree 管理目录项的方式无法同时满足 readdir 的需求。 readdir 是 POSIX 标准 API，它要求返回指定目录下的所有文件，并且特别的，这些文件要按照 inode number 排序。而 btrfs 目录项插入 BTree 时的 Key 并不是 Inode number，而是根据文件名计算的一个 hash 值。这种方式在查找一个特定文件时非常高效，但却不适于 readdir 。为此，btrfs 在每次创建新的文件时，除了插入以 hash 值为 Key 的目录项外，还同时插入另外一种目录项索引，该目录项索引的 KEY 以 sequence number 作为 BTree 的键值。这个 sequence number 在每次创建新文件时线性增加。因为 Inode number 也是每次创建新文件时增加的，所以 sequence number 和 inode number 的顺序相同。以这种 sequence number 作为 KEY 在 BTree 中查找便可以方便的得到一个以 inode number 排序的文件列表。\n另外以 sequence number 排序的文件往往在磁盘上的位置也是相邻的，所以以 sequence number 为序访问大量文件会获得更好的 IO 效率。\n压缩\n大家都曾使用过 zip，winrar 等压缩软件，将一个大文件进行压缩可以有效节约磁盘空间。 Btrfs 内置了压缩功能。\n通常人们认为将数据写入磁盘之前进行压缩会占用很多的 CPU 计算时间，必然降低文件系统的读写效率。但随着硬件技术的发展，CPU 处理时间和磁盘 IO 时间的差距不断加大。在某些情况下，花费一定的 CPU 时间和一些内存，但却能大大节约磁盘 IO 的数量，这反而能够增加整体的效率。\n比如一个文件不经过压缩的情况下需要 100 次磁盘 IO 。但花费少量 CPU 时间进行压缩后，只需要 10 次磁盘 IO 就可以将压缩后的文件写入磁盘。在这种情况下，IO 效率反而提高了。当然，这取决于压缩率。目前 btrfs 采用 zlib 提供的 DEFALTE/INFLATE 算法进行压缩和解压。在将来，btrfs 应该可以支持更多的压缩算法，满足不同用户的不同需求。\n目前 btrfs 的压缩特性还存在一些不足，当压缩使能后，整个文件系统下的所有文件都将被压缩，但用户可能需要更细粒度的控制，比如针对不同的目录采用不同的压缩算法，或者禁止压缩。我相信，btrfs 开发团队将在今后的版本中解决这个问题。\n对于某些类型的文件，比如 jpeg 文件，已经无法再进行压缩。尝试对其压缩将纯粹浪费 CPU 。为此，当对某文件的若干个 block 压缩后发现压缩率不佳，btrfs 将不会再对文件的其余部分进行压缩操作。这个特性在某种程度上提高了文件系统的 IO 效率。\n预分配\n很多应用程序有预先分配磁盘空间的需要。他们可以通过 posix_fallocate 接口告诉文件系统在磁盘上预留一部分空间，但暂时并不写入数据。如果底层文件系统不支持 fallocate，那么应用程序只有使用 write 预先写一些无用信息以便为自己预留足够的磁盘空间。\n由文件系统来支持预留空间更加有效，而且能够减少磁盘碎片，因为所有的空间都是一次分配，因而更有可能使用连续的空间。 Btrfs 支持 posix_fallocate 。\n总结 至此，我们对 btrfs 的很多特性进行了较为详细的探讨，但 btrfs 能提供的特性却并不止这些。 btrfs 正处于试验开发阶段，还将有更多的特性。\nBtrfs 也有一个重要的缺点，当 BTree 中某个节点出现错误时，文件系统将失去该节点之下的所有的文件信息。而 ext2/3 却避免了这种被称为”错误扩散”的问题。\n但无论怎样，希望您和我一样，开始认同 btrfs 将是 Linux 未来最有希望的文件系统。\nBtrfs 使用 了解了 btrfs 的特性，想必您一定想亲身体验一下 btrfs 的使用。本章将简要介绍如何使用 btrfs 。\n要使用一些用户空间工具的话，需要 安装 基础操作必须的 btrfs-progs 软件包。\n创建文件系统 单一设备上的文件系统\n要在分区 /dev/partition 上创建一个 Btrfs 文件系统，执行：\n# mkfs.btrfs -L mylabel /dev/partition Btrfs 用于元数据的默认节点大小 (nodesize) 为 16KB，而用于数据的默认扇区大小 (sectorsize) 等于页面大小 (page size) 并会自动检测。 要对元数据使用较大的节点大小 (必须为扇区大小的倍数，最大允许 64KB)，请通过 -n 开关为 nodesize 指定一个值。如下例所示，使用 32KB 块大小：\n# mkfs.btrfs -L mylabel -n 32k /dev/partition 注意： 根据 mkfs.btrfs(8) § OPTIONS 手册页内容：“较小的节点大小会增加碎片，但也会让 B-trees 更高，进而使得锁定争用（locking contention）更少。较高的节点大小则能有更好的打包（packing）和更少的碎片，但代价是，更新元数据块时会使用更多的内存”。\n多设备文件系统 RAID\n多个设备可以用来创建一组 RAID。支持的 RAID 级别有 RAID 0、RAID 1、RAID 10、RAID 5 和 RAID 6。从 5.5 版本内核开始，新增对 RAID1c3 和 RAID1c4 的支持，分别是 3 份冗余和 4 份冗余的 RAID 1。可以使用 -d 和 -m 参数分别为数据和元数据配置 RAID 等级。默认情况下，数据有一份副本（single），元数据则被镜像（RAID1）。\n# mkfs.btrfs -d single -m raid1 /dev/part1 /dev/part2 ... subvolume 创建子卷\n要创建一个子卷:\n# btrfs subvolume create /path/to/subvolume 列出子卷列表\n要列出当前路径 (path) 下的子卷和它们的 ID:\n# btrfs subvolume list -p path 删除子卷\n要删除一个子卷:\n# btrfs subvolume delete /path/to/subvolume 自 Linux 4.18 起, 用户可以像移除常规目录一样删除一个子卷 (用 rm -r, rmdir 命令)。\n挂载子卷\n可以使用 subvol=*/path/to/subvolume* 或 subvolid=*objectid* 挂载标志来安装子卷，就像文件系统分区一样。\n$ sudo mount /dev/sdb1 -o subvol=projects /tmp/projects$ sudo mount /dev/sdb1 -o subvolid=261 /tmp/projects 使用 Btrfs 快照进行增量备份 *快照(snapshot)*是 Btrfs 的一个有趣的功能。快照是一个子卷的副本。生成快照是立即的。然而，生成快照与执行 rsync 或 cp 不同，快照并不是一创建就会占用空间。\n 编者注：来自 BTRFS Wiki：快照简单的来说就是一个子卷，它使用 Btrfs 的 COW 功能与其他子卷共享其数据（和元数据）。\n 占用的空间将随着原始子卷或快照本身（如果它是可写的）的数据变化而增加。子卷中已添加/修改的文件和已删除的文件仍然存在于快照中。这是一种方便的备份方式。\n使用快照进行备份\n快照驻留在子卷所在的同一磁盘上。你可以像浏览普通目录一样浏览它，并按照生成快照时的状态恢复文件的副本。顺便说一下，在快照子卷的同一磁盘上生成快照并不是一个理想的备份策略：如果硬盘坏了，快照也会丢失。快照的一个有趣的功能是可以将快照发送到另一个位置。快照可以被发送到外部硬盘或通过 SSH 发送到远程系统（目标文件系统也需要格式化为 Btrfs）。要实现这个，需要使用命令 btrfs send 和 btrfs receive。\n生成快照\n要使用 btrfs send 和 btrfs receive 命令，重要的是要将快照创建为只读，而快照默认是可写的。\n要创建一个快照:\n# btrfs subvolume snapshot source [dest/]name source为要创建快照的对象，[dest/]name为快照安放路径。\n下面的命令将对 /home 子卷进行快照。请注意 -r 标志代表只读。\nsudo btrfs subvolume snapshot -r /home /.snapshots/home-day1 快照的名称可以是当前日期，而不是 day1，比如 home-$(date +%Y%m%d)。快照看起来像普通的子目录。你可以把它们放在任何你喜欢的地方。目录 /.snapshots 可能是一个不错的选择，以保持它们的整洁和避免混淆。\n 编者注：快照不会对自己进行递归快照。如果你创建了一个子卷的快照，子卷所包含的每一个子卷或快照都会被映射到快照里面的一个同名的空目录。\n 使用 btrfs send 进行备份\n在本例中，U 盘中的目标 Btrfs 卷被挂载为 /run/media/user/mydisk/bk。发送快照到目标卷的命令是：\nsudo btrfs send /.snapshots/home-day1 | sudo btrfs receive /run/media/user/mydisk/bk 这被称为初始启动，它相当于一个完整的备份。这个任务需要一些时间，取决于 /home 目录的大小。显然，后续的增量发送只需要更短的时间。\n增量备份\n快照的另一个有用的功能是能够以增量的方式执行发送任务。让我们再来生成一个快照。\nsudo btrfs subvolume snapshot -r /home /.snapshots/home-day2 为了执行增量发送任务，需要指定上一个快照作为基础，并且这个快照必须存在于源文件和目标文件中。请注意 -p 选项。\nsudo btrfs send -p /.snapshot/home-day1 /.snapshot/home-day2 | sudo btrfs receive /run/media/user/mydisk/bk 再来一次（一天之后）：\nsudo btrfs subvolume snapshot -r /home /.snapshots/home-day3sudo btrfs send -p /.snapshot/home-day2 /.snapshot/home-day3 | sudo btrfs receive /run/media/user/mydisk/bk 清理\n操作完成后，你可以保留快照。但如果你每天都执行这些操作，你可能最终会有很多快照。这可能会导致混乱，并可能会在你的磁盘上使用大量的空间。因此，如果你认为你不再需要一些快照，删除它们是一个很好的建议。\n请记住，为了执行增量发送，你至少需要最后一个快照。这个快照必须存在于源文件和目标文件中。\nsudo btrfs subvolume delete /.snapshot/home-day1sudo btrfs subvolume delete /.snapshot/home-day2sudo btrfs subvolume delete /run/media/user/mydisk/bk/home-day1sudo btrfs subvolume delete /run/media/user/mydisk/bk/home-day2 注意：第 3 天的快照被保存在源文件和目标文件中。这样，明天（第 4 天），你就可以执行新的增量 btrfs send。\n最后的建议是，如果 U 盘的空间很大，可以考虑在目标盘中保留多个快照，而在源盘中只保留最后一个快照。\n压缩 给现存文件启用压缩，可使用 btrfs filesystem defragment -c alg 命令，alg 处可选填为 zlib，lzo 或 zstd。举例来说，要用 zstd 方式给整个文件系统重新压缩，执行下列命令：\n# btrfs filesystem defragment -r -v -c zstd / 要在新的 Btrfs 分区上安装 Arch Linux 时就启用压缩功能 (充分利用压缩特性)，请在 挂载 文件系统时使用 compress 选项：mount -o compress=zstd /dev/sd*xY* /mnt/。在配置过程中，请在 fstab 中把 compress=zstd 添加到根目录文件系统的挂载选项里。\nBtrfs 和 LVM-ext4 两者的共性 尽管两个文件系统之间存在核心差异，但 Btrfs 和 LVM-ext4 实际上有很多共同之处。两者都是成熟且经过充分测试的存储技术。从 Fedora Core 的早期开始，就一直在使用 LVM，而 ext4 在 2009 年成为 Fedora 11 的默认设置。Btrfs 在 2009 年并入 Linux 主线内核，并且 Facebook 广泛使用了该文件系统。SUSE Linux Enterprise 12 在 2014 年使其成为默认文件系统。因此，它在生产环境中也有着长久的运行时间。\n这两个系统都能很好地防止因意外停电而导致的文件系统损坏，尽管它们的实现方式不同。它们支持的配置包括使用单盘设置和跨越多个设备，并且这两种配置都能够创建近乎即时的快照。有各种工具可以帮助管理这两种系统，包括命令行和图形界面。这两种解决方案在家用台式机和高端服务器上都同样有效。\nLVM-ext4 的优势 ext4 文件系统 专注于高性能和可伸缩性，没有太多额外的花哨之处。它能有效地防止长时间后的碎片化，并当碎片化出现后提供了 很好的工具。ext4 之所以坚如磐石，是因为它构建在前代的 ext3 文件系统之上，带来了多年的系统内测试和错误修复。\nLVM-ext4 环境中的大多数高级功能都来自 LVM 本身。LVM 位于文件系统的“下方”，这意味着它支持任何文件系统。逻辑卷Logical volume（LV）是通用的块设备，因此 虚拟机可以直接使用它们。这种灵活性使得每个逻辑卷都可以使用合适的文件系统，用合适的选项应对各种情况。这种分层方法还遵循了“小工具协同工作”的 Unix 哲学。\n从硬件抽象出来的卷组volume group（VG）允许 LVM 创建灵活的逻辑卷。每个逻辑卷都提取自同一个存储池，但具有自己的设置。调整卷的大小比调整物理分区的大小容易得多，因为没有数据有序放置的限制。LVM 物理卷physical volume（PV）可以是任意数量的分区，甚至可以在系统运行时在设备之间移动。\nLVM 支持只读和读写的 快照，这使得从活动系统创建一致的备份变得很容易。每个快照都有一个定义的大小，更改源卷或快照卷将占用其中的空间。又或者，逻辑卷也可以是稀疏配置池thinly provisioned pool的一部分。这允许快照自动使用池中的数据，而不是使用在创建卷时定义的固定大小的块。\n有多个磁盘驱动器的 LVM\n当有多个设备时，LVM 才真正大放异彩。它原生支持大多数 RAID 级别，每个逻辑卷可以具有不同的 RAID 级别。LVM 将自动为 RAID 配置选择适当的物理设备，或者用户可以直接指定它。基本的 RAID 支持包括用于性能的数据条带化（RAID0）和用于冗余的镜像（RAID1）。逻辑卷也可以使用 RAID5、RAID6 和 RAID10 等高级设置。LVM RAID 支持已经成熟，因为 LVM 在底层使用的 设备映射器（dm） 和 多设备（md） 内核支持， 与 mdadm 使用的一样。\n对于具有快速和慢速驱动器的系统，逻辑卷也可以是 缓存卷。经典示例是 SSD 和传统磁盘驱动器的组合。缓存卷使用较快的驱动器来存储更频繁访问的数据（或用作写缓存），而慢速的驱动器则用于处理大量数据。\nLVM 中大量稳定的功能以及 ext4 的可靠性在既往的使用中早已被证明了。当然，功能越多就越复杂。在配置 LVM 时，要找到合适的功能选项是很有挑战性的。对于单驱动器的台式机系统，LVM 的功能（例如 RAID 和缓存卷）不适用。但是，逻辑卷比物理分区更灵活，快照也很有用。对于正常的桌面使用，LVM 的复杂性会成为典型的用户可能遇到的问题恢复的障碍。\nBtrfs 的优势 从前几代文件系统中学到的经验指导了构建到 Btrfs 的功能设计。与 ext4 不同，它可以直接跨越多个设备，因此它具有通常仅在卷管理器中才能找到的功能。它还具有 Linux 文件系统空间中独有的功能（ZFS 具有相似的功能集，但不要指望它在 Linux 内核中出现）。\nBtrfs 的主要功能\n也许最重要的功能是对所有数据进行校验和checksumming。校验和与写时复制copy-on-write（COW）一起，提供了在意外断电后确保文件系统完整性的 关键方法。更独特的是，校验和可以检测数据本身中的错误。悄然的数据损坏（有时也称为 bitrot）比大多数人意识到的更常见。如果没有主动验证，损坏最终可能会传播到所有可用的备份中。这使得用户没有有效的副本。通过透明地校验所有数据，Btrfs 能够立即检测到任何此类损坏。启用正确的 dup 或 raid 选项，文件系统也可以透明地修复损坏。\n写时复制也是 Btrfs 的基本功能，因为它在提供文件系统完整性和即时子卷快照方面至关重要。从公共子卷创建快照后，快照会自动共享底层数据。另外，事后的重复数据删除deduplication 使用相同的技术来消除相同的数据块。单个文件可以通过使用 cp 的 reflink 选项 来使用 COW 功能。reflink 副本对于复制大型文件（例如虚拟机镜像）特别有用，这些文件往往随着时间的推移具有大部分相同的数据。\nBtrfs 支持跨越多个设备，而无需卷管理器。多设备支持可提供数据镜像功能以实现冗余和条带化以提高性能。此外，还实验性地支持更高级的 RAID 级别，例如 RAID 5 和 RAID 6。与标准 RAID 设置不同，Btrfs 的 RAID1 实际上允许奇数个设备。例如，它可以使用 3 个设备，即使它们的大小不同。\n所有 RAID 和 dup 选项都是在文件系统级别指定的。因此，各个子卷不能使用不同的选项。请注意，使用多设备的 RAID1 选项意味着即使一个设备发生故障，卷中的所有数据都是可用的，并且校验功能可以保持数据本身的完整性。这超出了当前典型的 RAID 设置所能提供的范围。\n附加功能\nBtrfs 还支持快速简便的远程备份。子卷快照可以 发送到远程系统 进行存储。通过利用文件系统中固有的 COW 元数据，这些传输通过仅发送先前发送的快照中的增量更改而非常有效。诸如 snapper 之类的用户应用程序使管理这些快照变得容易。\n另外，Btrfs 卷可以具有 透明压缩 功能，并且 chattr +c 可以标记进行压缩的单个文件或目录。压缩不仅可以减少数据消耗的空间，还可以通过减少写入操作量来帮助延长 SSD 的寿命。压缩当然会带来额外的 CPU 开销，但是有很多选项就可以权衡取舍。\nBtrfs 集成了文件系统和卷管理器功能，这意味着总体维护比 LVM-ext4 更简单。当然，这种集成的灵活性较低，但是对于大多数台式机甚至服务器而言，设置已足够。\nLVM 上使用 Btrfs Btrfs 可以 就地转换 ext3/ext4 文件系统。就地转换意味着无需将数据复制出来然后再复制回去。数据块本身甚至都不需要修改。因此，对于现有的 LVM-ext4 系统，一种选择是将 LVM 保留在原处，然后简单地将 ext4 转换为 Btrfs。虽然可行且受支持，但有一些原因使它不是最佳选择。\nBtrfs 的吸引力之一是与卷管理器集成的文件系统所带来的更轻松的管理。要是在 LVM 之上运行，对于系统维护，仍然要对额外的卷管理器进行一些设置。同样，LVM 设置通常具有多个固定大小的逻辑卷，并具有独立文件系统。虽然 Btrfs 支持给定的计算机上的多个卷，但是许多不错的功能都需要单一卷具有多个子卷。如果每个 LVM 卷都有一个独立的 Btrfs 卷，则用户仍然需要手动管理固定大小的 LVM 卷。虽然能够收缩挂载的 Btrfs 文件系统的能力确实使处理固定大小的卷的工作变得更轻松。通过在线收缩功能，就无需启动 实时镜像 了。\n在使用 Btrfs 的多设备支持时，必须仔细考虑逻辑卷的物理位置。对于 Btrfs 而言，每个逻辑卷都是一个单独的物理设备，如果实际情况并非如此，则某些数据可用性功能可能会做出错误的决定。例如，如果单个驱动器发生故障，对数据使用 RAID1 通常可以提供保护。如果实际逻辑卷在同一物理设备上，则没有冗余。\n如果强烈需要某些特定的 LVM 功能，例如原始块设备或高速缓存的逻辑卷，则在 LVM 之上运行 Btrfs 是有意义的。在这种配置下，Btrfs 仍然提供其大多数优点，例如校验和和易于发送的增量快照。尽管使用 LVM 会产生一些操作开销，但 Btrfs 的这种开销并不比任何其他文件系统大。\n总结 当尝试在 Btrfs 和 LVM-ext4 之间进行选择时，没有一个正确的答案。每个用户都有独特的要求，并且同一用户可能拥有具有不同需求的不同系统。看一下每个配置的功能集，并确定是否有令人心动的功能。如果没有，坚持默认值没有错。选择这两种设置都有很好的理由。\nSnapper Snapper 是 openSUSE 下用于创建和管理文件系统快照（以下简称快照）的工具。快照保存了文件系统在某个时间点的状态，从而可以轻松实现系统回滚或数据备份。\nSnapper 可以在 Btrfs 文件系统（推荐）及采用 XFS 或 Ext4 文件系统的 LVM 精简配置卷上使用，本文主要介绍在 Btrfs 文件系统上使用 Snapper 的方法。\n快照类型 Snapper 快照可分为两大类型：\n 快照对：由一对快照组成，在进行某项操作前拍摄一个“前快照”（pre），操作后再拍摄一个“后快照”（post），从而可以比较两个快照对差异而撤销该操作。快照对是一一对应的，如果删除了某一快照，则对应的快照也会被删除。 单一快照（single）：由一个单独的快照组成，与其他快照没有特殊联系。可用于备份或回滚整个系统等操作。  快照对和单一快照既可以手动创建，也可以根据配置自动创建。自动创建的快照又可分为三种类型：\n 时间线快照：每小时自动创建的单一快照。 安装快照：在安装软件包前后自动创建的一对快照对。可用于撤销软件包更改。 管理快照：在使用 YaST 管理系统前后自动创建的一堆快照对。可用于撤销配置更改。  这三种自动创建的快照均可单独启用和配置，从而提供了极大的灵活性。\n默认配置 要在分区或 Btrfs 子卷启用快照，需要创建配置文件。Snapper 的配置文件存储在 /etc/snapper/configs 中。\n如果你的根分区大于 16 GB，并且在安装 openSUSE 时使用默认分区配置，则根分区的配置文件应已被自动创建。默认配置启用了安装快照和管理快照，并排除了部分目录，可以满足大多数需求。以下列表显示了排除的所有目录：\n  /boot/grub2/i386-pc、/boot/grub2/x86_64-efi、/boot/grub2/powerpc-ieee1275、/boot/grub2/s390x-emu\n不能回滚引导加载程序配置。上面列出的目录是架构专属目录。前两个目录位于 AMD64/Intel 64 计算机上，后两个目录分别位于 IBM POWER 和 IBM Z 上。\n  /home\n如果独立的分区中没有 /home，便会将该目录排除以免在回滚时发生数据丢失。\n  /opt、/var/opt\n第三方产品通常安装到 /opt 下。排除此目录是为了防止在回滚时卸装这些应用程序。\n  /srv\n包含 Web 和 FTP 服务器的数据。排除此目录是为了防止在回滚时发生数据丢失。\n  /tmp、/var/tmp、/var/cache、/var/crash\n包含临时文件和超速缓存的所有目录都会排除在快照范围之外。\n  /usr/local\n在手动安装软件时会用到此目录。系统会将该目录排除以免在回滚时卸载这些安装的软件。\n  /var/lib/libvirt/images\n使用 libvirt 管理的虚拟机映像的默认位置。为确保回滚期间虚拟机映像不会替换为旧版本而被排除。默认情况下，此子卷是使用写入时不复制选项创建的。\n  /var/lib/mailman、/var/spool\n包含邮件或邮件队列的目录会排除，以免在回滚后造成邮件丢失。\n  /var/lib/bind\n包含 DNS 服务器的区域数据。排除该目录是为了确保回滚后名称服务器仍能运作。\n  /var/lib/mariadb、/var/lib/mysql、/var/lib/pgqsl\n这些目录包含数据库数据。默认情况下，这些子卷是使用写入时不复制选项创建的。\n  /var/log\n日志文件所在的位置。排除该目录是为了在对受损的系统进行回滚后能够对日志文件进行分析。\n  如果你希望使用 openSUSE 的默认配置，但在安装 openSUSE 时未开启快照功能，可以使用以下命令创建根分区的默认配置文件：\n注意： 要使用该默认配置文件，请确保根分区大小至少为 16 GB，并使用 openSUSE 安装程序建议的包含子卷的 Btrfs 根文件系统（安装程序默认分区设置）\nsnapper -c root create-config / 确保 snapper-zypp-plugin 软件包已安装以启用安装快照：\nzypper install snapper-zypp-plugin 手动配置 创建和装入新子卷 系统支持在 / 层次下创建新的子卷，并永久性装入该卷。此类子卷将从快照中排除。切勿在现有快照中创建此类子卷，因为在回滚之后，您将无法再删除快照。\nSUSE Linux Enterprise Server 上配置了 /@/ 子卷，该子卷充当永久性子卷（例如 /opt、/srv、/home 等）的独立根目录。您创建和永久装入的任何新子卷都需要在这个初始根文件系统中创建。\n为此，请运行以下命令。在此示例中，从 /dev/sda2 创建了一个新子卷 /usr/important。\nsudo mount /dev/sda2 -o subvol=@ /mntsudo btrfs subvolume create /mnt/usr/importantsudo umount /mnt /etc/fstab 中的相应项需类似于：\n/dev/sda2 /usr/important btrfs subvol=@/usr/important 0 0 提示：子卷可能包含经常更改的文件，例如虚拟化的磁盘映像、数据库文件或日志文件。如果是这样，可考虑对此卷禁用写入时复制功能，以免复制磁盘块。可在 /etc/fstab 中使用 nodatacow 装入选项来实现此目的：\n/dev/sda2 /usr/important btrfs nodatacow,subvol=@/usr/important 0 0 或者，要为单个文件或目录禁用写入时复制功能，请使用命令 chattr +C 路径。\n创建配置文件 希望在特定分区或子卷启用快照，可以以下命令创建相应的配置文件：\nsnapper -c 配置文件名 create-config 分区或子卷的挂载点 这将根据 /etc/snapper/config-templates/default 提供的默认值创建配置文件。\n注意： 在创建配置文件前请确保目标分区或子卷已被创建。不能为同一分区或子卷创建多个配置文件。\n例如，为防止回滚时数据丢失，默认的根分区配置排除了 /home 目录，可以使用上述命令为 /home 创建配置文件：\nsnapper -c home create-config /home 该命令会使用 /etc/snapper/config-templates/default 提供的默认值创建 /etc/snapper/configs/home 文件。\n可以使用\nsnapper list-configs 查看现有配置文件。\n启用/禁用自动快照 你可以选择性地启用/禁用自动创建的快照类型：\n启用时间线快照\nsnapper -c 配置文件名 set-config \u0026quot;TIMELINE_CREATE=yes\u0026quot; 禁用时间线快照\nsnapper -c 配置文件名 set-config \u0026quot;TIMELINE_CREATE=no\u0026quot; 时间线快照默认会启用，但根分区除外。\n注意： 以下两种快照包含的内容由安装的软件包或修改的配置而定，与特定分区或子卷无关。默认为启用状态。\n启用安装快照\nzypper install snapper-zypp-plugin 禁用安装快照\nzypper remove snapper-zypp-plugin 使用 YaST 或 Zypper 安装包时所创建的快照会由 snapper-zypp-plugin 进行处理。何时创建快照由 XML 配置文件 /etc/snapper/zypp-plugin.conf 定义。\n启用管理快照\n在 /etc/sysconfig/yast2 中将 USE_SNAPPER 设置为 yes 禁用管理快照\n在 /etc/sysconfig/yast2 中将 USE_SNAPPER 设置为 no 配置文件参数 Snapper 的行为由配置文件参数定义，除了直接使用文本编辑器编辑配置文件外，还可以使用\nsnapper -c 配置文件名称 set-config \u0026quot;参数名称=参数\u0026quot; 修改配置文件参数。\n以下对几个常用配置案例进行说明，完整的参数说明可参阅 snapper-configs(5) ：\nman snapper-configs 允许普通用户管理快照\n默认情况下仅 root 用户可以管理快照，要允许普通用户或组管理快照，可运行：\nsnapper -c 配置文件名称 set-config \u0026quot;ALLOW_USERS=用户名\u0026quot; \u0026quot;ALLOW_GROUPS=组名\u0026quot; \u0026quot;SYNC_ACL=yes\u0026quot; 必须配置“SYNC_ACL=yes”以允许普通用户访问快照所在目录。\n自动清理旧快照\n为防止快照占据全部磁盘空间，Snapper 提供了几种自动清理旧快照的机制，可通过一系列参数配置自动清理过程：\n   清理机制 说明 启用选项 配置参数 含义 备注     编号 根据快照编号进行清理 NUMBER_CLEANUP=yes NUMBER_LIMIT=数字或范围 定义要保留的快照数量。 如果启用了定额支持，应使用范围。如果未启用定额支持，应使用单个数字。   NUMBER_LIMIT_IMPORTANT=数字或范围 定义要保留的含 important 标签的快照数量，内核更新等的安装快照自带该标签。       NUMBER_MIN_AGE=秒 定义满足上述条件的快照被清理前最少应保留的时间。0 表示无限制。       时间线 根据快照创建时间进行清理 TIMELINE_CLEANUP=yes TIMELINE_LIMIT_HOURLY=数字或范围 定义要保留的每小时首张快照的数量。 如果启用了定额支持，应使用范围。如果未启用定额支持，应使用单个数字。   TIMELINE_LIMIT_DAILY=数字或范围 定义要保留的每日首张快照的数量。       TIMELINE_LIMIT_WEEKLY=数字或范围 定义要保留的每周首张快照的数量，此处的周由星期一开始。       TIMELINE_LIMIT_MONTHLY=数字或范围 定义要保留的每月首张快照的数量。       TIMELINE_LIMIT_YEARLY=数字或范围 定义要保留的每年首张快照的数量。       TIMELINE_MIN_AGE=秒 定义满足上述条件的快照被清理前最少应保留的时间。0 表示无限制。       无差异快照对 清理没有差异的快照对。如运行 Yast2 后未作任何修改，则自动清理创建的管理快照。 EMPTY_PRE_POST_CLEANUP=yes EMPTY_PRE_POST_CLEANUP=秒 定义无差异快照对被清理前最少应保留的时间。0 表示无限制。    磁盘定额 定义快照可占用空间的百分比 运行snapper setup-quota SPACE_LIMIT=表示百分比的小数 定义快照可占用空间的百分比 仅支持 Btrfs 文件系统需至少启用编号或时间线清理算法中的一个启用定额支持后，编号和时间线清理算法的部分参数应当使用范围值。清理算法会清理快照至上限值，如果未满足定额配置则在下限值范围内尽量清理快照以满足定额。    管理配置文件 可以使用 snapper 命令快速管理配置文件：\n列出配置文件\nsnapper list-configs 显示特定的配置文件\nsnapper -c 配置文件名称 get-config 删除配置文件\nsnapper -c 配置文件名称 delete-config 快照管理 可以使用 snapper 工具或 Yast2 模块进行查看、创建、比较快照等操作。\nsnapper 工具提供了一系列子命令，可以在文本界面进行快照管理。本节介绍了一些常用命令和参数，更多信息可参阅 snapper(8)：\nman snapper 注意： 管理快照时可使用 “-c 配置文件名” 指定配置文件，如未指定则默认使用 root 配置文件，下述示例均未指定配置文件。\n查看快照\nsnapper list 将列出 root 配置的所有快照。\n可以使用 “-t” 参数列出特定类型的快照。\n例如，列出 root 配置下的所有快照对：\nsnapper list -t pre-post 列出 home 配置下的所有单一快照：\nsnapper -c home list -t single 你还可以使用\nsnapper list -a 列出所有配置下的快照。\n创建快照\nsnapper create 将使用 root 配置文件创建一个单一快照。\n可以使用“-t”参数指定快照类型（默认值为 single），使用“-d”参数添加描述。手动创建的快照默认不会自动被清理，使用“\u0026ndash;cleanup-algorithm”参数指定自动清理算法。还可以使用“\u0026ndash;userdata”参数定义自定义数据（如 important 标记）。\n例如，创建当前系统的单一快照，标记为重要，并指定时间线清理算法：\nsnapper create -t single --description \u0026quot;系统快照\u0026quot; --userdata \u0026quot;important=yes\u0026quot; --cleanup-algorithm timeline 要创建一个快照对，首先创建一个前快照，使用“\u0026ndash;print-number”选项以列出快照编号：\nsnapper create -t pre --print-number --description \u0026quot;Before\u0026quot; 假设列出的快照编号为 30，将其作为“\u0026ndash;pre-number”参数的值创建后快照：\nsnapper create -t post --pre-number 30 --description \u0026quot;After\u0026quot; 你也可以使用\nsnapper create --command \u0026quot;要运行的命令\u0026quot; 以自动创建运行命令前后的快照对。\n比较快照\n有两种比较方法：\nsnapper status \u0026lt;第一个快照编号\u0026gt;..\u0026lt;第二个快照编号\u0026gt; //第一个快照的创建时间要早于第二个 将显示您在两个快照时间内修改的全部文件的路径和文件名。\n例如，下述命令可以比较当前系统状态与 161 号快照的差异：\nsnapper status 161..0 //0 表示当前系统，它不是快照，但你可以认为是比所有快照都新的一个快照。 第二种：\nsnapper diff \u0026lt;第一个快照编号\u0026gt;..\u0026lt;第二个快照编号\u0026gt; 文件名 将以 diff 的格式显示指定文件的差异，如果未指定文件名，将显示所有文件的差异。\n撤销修改\nsnapper undochange \u0026lt;修改前的快照编号\u0026gt;..\u0026lt;修改后的快照编号\u0026gt; \u0026lt;文件名\u0026gt; 比如你误删除了某个文件，可以使用：\nsnapper undochange \u0026lt;删除文件前的快照编号\u0026gt;..0 文件名 //0 表示当前系统，它不是快照，但你可以认为是比所有快照都新的一个快照。 来撤销。\n删除快照\nsnapper delete 快照编号或范围 例如，要删除 16 号快照：\nsnapper delete 16 要删除 10 号到 15 号快照：\nsnapper delete 10-15 可以结合“-s”参数以在删除快照后立刻释放可用空间而不必等待 Btrfs 进程回收。\n回滚整个系统\nSUSE Linux Enterprise Server 上包含的 GRUB 2 版本可以从 Btrfs 快照进行引导。与 Snapper 的回滚功能相结合，就能恢复配置错误的系统。只有针对默认 Snapper 配置（根）创建的快照才可引导。\n注意： 要回滚整个系统，请确保根文件系统为 openSUSE 安装程序默认的带子卷的 Btrfs 文件系统。从 SUSE Linux Enterprise Server 15 开始，只有在根分区的默认子卷配置未更改过的情况下，才支持系统回滚。\n如果因为更新或病毒等原因导致系统出现重大错误，并保留了错误前的快照，则可以回滚整个系统到错误前的状态。\nsnapper rollback 要回滚的快照编号 该命令将创建当前系统状态的只读快照 A 及指定编号快照的可读写快照 B，并使用快照 B 替换根分区的默认子卷，重新启动系统后即可实现回滚。\n你还可以在引导系统时选择Start bootloader from a read-only snapshot，以引导想要回滚的快照，在检查无误后在引导的快照中执行：\nsnapper rollback 不指定快照编号时，将创建根分区默认子卷（即原系统）的只读快照 A 和当前系统（即目前引导的快照）的可读写快照 B，并使用快照 B 替换根分区的默认子卷，重新启动系统后选择默认引导项即可实现回滚。\nFirewall-cmd firewall-cmd(firewalld command line client) 是 firewalld 的主要命令行工具。它可以用来获取 firewalld 的状态信息，获取运行时和永久环境的防火墙配置，也可以用来修改这些配置。\n基本概念 firewalld 将所有的网络数据流量划分为多个区域，再根据数据包的源IP地址或传入网络接口等条件，将数据流量转入相应区域的防火墙规则中。\n block：拒绝所有传入的网络连接。只有从系统内部发起的网络连接才可能有效； dmz：隔离区域也称为非军事化区域，为您的局域网提供有限的访问权限，并且只允许选定的传入端口； drop：终止所有传入链接，只允许传出的链接； external：对路由器类型的连接很有用。你需要局域网和广域网的接口来进行伪装（NAT）才能正常工作。 home：适用于家庭电脑，如局域网内的笔记本电脑和台式机，您可以信任其他电脑。只允许选定的 TCP/IP 端口； internal：用于内部网络，当你几乎信任局域网内的其他服务器或计算机时； public（系统默认值）：适用于始终处于公共区域的云服务器或托管在您处的服务器。您不信任网络上的任何其他计算机和服务器。您只允许使用所需的端口和服务； trusted：允许任何的网络链接； work：适用于您信任您的同事和其他服务器的工作场所。  查看默认区域：\n$ firewall-cmd --get-default-zone 当 NetworkManager 添加新的接口连接（如 eth0 或 ens3）时，它们将被连接到默认的区域。通过运行以下命令进行验证：\n$ firewall-cmd --get-active-zones 服务（services） 服务是一个包含了本地端口、协议、源端口、目的地和防火墙帮助模块 (firewall helper modules) 的列表。\n查询服务 # 查询当前区域允许的服务 $ sudo firewall-cmd --list-services # 查询特定区域允许的服务 $ sudo firewall-cmd --list-services --zone=[区域] # 查询全部区域的服务或防火墙规则 $ sudo firewall-cmd --list-all-zones 如查询与 public 相关的防火墙规则或服务：\n$ sudo firewall-cmd --list-all --zone=public public (active) target: default icmp-block-inversion: no interfaces: wlan0 sources: services: dhcpv6-client ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: 在该查询结果中，默认区域是 public ，允许的服务是 dhcpv6-client 。\n删除服务 $ sudo firewall-cmd --remove-service=[服务] --permanent --zone=[区域] $ sudo firewall-cmd --reload \u0026ndash;permanent 指定永久规则则。运行时的 firewalld 配置更改是临时性的，当你重新启动 openSUSE 或 firewalld 时，它们就会消失。而永久规则则不受影响。\n添加服务 $ sudo firewall-cmd --add-service=[服务] --permanent --zone=[区域] $ sudo firewall-cmd --reload sudo 许多命令和系统实用程序都需要以 root 身份运行才能执行。为了确保安全和避免发生意外运行危险命令，通常建议不要直接以 root 身份登录。建议的做法是以非特权的普通用户身份工作，并使用 sudo 命令来运行需要较高特权的命令。\n在 SUSE Linux Enterprise Server 上，sudo 默认配置与 su 的工作方式类似。但是，sudo 可让用户以高度可配置的方式使用任何其他用户的特权来运行命令。这样，便可为某些用户和组指派具有特定特权的角色。举例来说，可以允许组 users 的成员使用 wilber 的特权运行命令。通过禁止指定任何命令选项，可以进一步限制对命令的权限。虽然 su 始终需要 root 口令才能使用 PAM 进行身份验证，但是您可以将 sudo 配置为使用您自己的身份凭证进行身份验证。这样就不需要共享 root 口令，从而提高了安全性。\nsudo 基本用法 虽然 sudo 简单易用，功能却十分强大。\n运行单个命令 以普通用户身份登录后，您可以在命令前加上 sudo 以 root 身份运行任何命令。按照提示输入口令后，如果身份验证成功，您便能以 root 身份运行命令：\n# id -un 命令会打印当前用户的登录名 $ id -un tux # 在输入过程中不会显示口令，无论是明文还是密文均不显示。  $ sudo id -un root\u0026#39;s password: root # 只有以 sudo 开头的命令才会使用较高的特权运行。如果是不带 sudo 前缀的相同命令，仍会使用当前用户的特权运行。  $ id -un tux # 在限定时间内，您无需再次输入 root 口令。  $ sudo id -un root I/O 重定向的工作方式与您预期的可能不同：\n$ sudo echo s \u0026gt; /proc/sysrq-trigger bash: /proc/sysrq-trigger: Permission denied $ sudo cat \u0026lt; /proc/1/maps bash: /proc/1/maps: Permission denied 只有 echo/cat 二进制会使用较高特权运行，重定向则由用户外壳使用用户特权执行。您可以按启动外壳中所述启动外壳，也可以使用 dd 实用程序来启动：\n$ echo s | sudo dd of=/proc/sysrq-trigger $ sudo dd if=/proc/1/maps | cat 启动外壳 必须在每条命令前加上 sudo 可能很繁琐。虽然可以将外壳指定为命令 sudo bash，但还是建议您使用以下其中一种内置机制来启动外壳：\n  sudo -s (\u0026lt;命令\u0026gt;)\n启动 SHELL 环境变量所指定的外壳或目标用户的默认外壳。如果给定了命令，则会将该命令传递给外壳（使用 -c 选项），否则外壳会以交互模式运行。\n$ sudo -s root's password: $ exit   sudo -i (\u0026lt;命令\u0026gt;)\n  与 -s 类似，但是会将外壳启动为登录外壳。也就是说，系统会对外壳的启动文件（.profile 等）进行处理，并会将当前的工作目录设置为目标用户的主目录。\n$ sudo -i root's password: $ exit   环境变量 默认情况下，sudo 不会传播环境变量：\n$ ENVVAR=test env | grep ENVVAR ENVVAR=test $ ENVVAR=test sudo env | grep ENVVAR root's password: $ 输出为空即表明在使用 sudo 运行的命令的环境中不存在环境变量 ENVVAR。\n此行为可通过 env_reset 选项进行更改，请参见下文有用的标志和选项。\n配置 sudo sudo 是一个非常灵活的工具，提供各种配置选项。\n注意：如果您不小心将自己锁定在 sudo 之外，则可以使用 su - 及 root 口令来获取 root 外壳。要修复该错误，请运行 visudo。\n编辑配置文件 sudo 的主要策略配置文件为 /etc/sudoers。如果此文件中存在错误，您可能便会无法进入系统，因此强烈建议您使用 visudo 来编辑配置文件。此举可防止同时更改打开的文件，并会在保存修改之前检查语法错误。\n您还可以通过设置 EDITOR 环境变量来使用除 vi 以外的编辑器（不论名字如何），例如：\n$ sudo EDITOR=/usr/bin/nano visudo 不过，/etc/sudoers 文件本身是由系统包提供的，更新时这些修改可能会取消。因此，建议您将自定义配置放到 /etc/sudoers.d/ 目录下的文件中。该目录下的任何文件都会自动纳入系统中。要在该子目录下创建或编辑文件，请运行：\nsudo visudo -f /etc/sudoers.d/NAME 或者，使用其他编辑器（例如 nano）：\nsudo EDITOR=/usr/bin/nano visudo -f /etc/sudoers.d/NAME 注意：/etc/sudoers 中的 #includedir 命令（用于 /etc/sudoers.d）会忽略以 ~（波浪号）结尾或包含 .（点）的文件。\n关于 visudo 命令的详细信息，请运行 man 8 visudo。\nsudoers 基本配置语法 在 sudoers 配置文件中，有两种类型的选项：字符串和标志。字符串可以包含任何值，而标志则只能在“ON”或“OFF”之间切换。sudoers 配置文件最重要的语法构造为：\n# Everything on a line after a # gets ignored, Defaults !insults # Disable the insults flag Defaults env_keep += \u0026quot;DISPLAY HOME\u0026quot; # Add DISPLAY and HOME to env_keep tux ALL = NOPASSWD: /usr/bin/frobnicate, PASSWD: /usr/bin/journalctl  #include 和 #includedir 这两个普通命令例外。其后跟数字，用于指定 UID。 去除 ! 可将指定的标志设置为“ON”。  有用的标志和选项\n   选项名称 说明 示例     targetpw 此标志控制调用用户是需要输入目标用户（例如 root）的口令 (ON) 还是需要输入调用用户的口令 (OFF)。 Defaults targetpw # Turn targetpw flag ON   rootpw 如果设置了该选项，sudo 会提示输入 root 口令，而非目标用户或调用者的口令。默认值为“OFF”。 Defaults !rootpw # Turn rootpw flag OFF   env_reset 如果设置了该选项，sudo 会构造一个仅包含 TERM、PATH、HOME、MAIL、SHELL、LOGNAME、USER、USERNAME 和 SUDO_* 集的最小环境。此外，会从调用环境导入 env_keep 中列出的变量。默认值为“ON”。 Defaults env_reset # Turn env_reset flag ON   env_keep env_reset 标志设为“ON”时要保留的环境变量列表。 # Set env_keep to contain EDITOR and PROMPT Defaults env_keep = \u0026quot;EDITOR PROMPT\u0026quot; Defaults env_keep += \u0026quot;JRE_HOME\u0026quot; # Add JRE_HOME Defaults env_keep -= \u0026quot;JRE_HOME\u0026quot; # Remove JRE_HOME   env_delete env_reset 标志设为“OFF”时要去除的环境变量列表。 # Set env_delete to contain EDITOR and PROMPT Defaults env_delete = \u0026quot;EDITOR PROMPT\u0026quot; Defaults env_delete += \u0026quot;JRE_HOME\u0026quot; # Add JRE_HOME Defaults env_delete -= \u0026quot;JRE_HOME\u0026quot; # Remove JRE_HOME    还可以使用 Defaults 令牌为用户、主机和命令集合创建别名。并且，可以仅将选项应用到特定用户集。\n关于 /etc/sudoers 配置文件的详细信息，请参见 man 5 sudoers。\nsudoers 中的规则 sudoers 配置中的规则可能会非常复杂，因此本节仅涉及基本内容。每个规则都遵循基本模式（[] 标记的是可选部分）：\n#Who Where As whom Tag What User_List Host_List = [(User_List)] [NOPASSWD:|PASSWD:] Cmnd_List   User_List\n一个或多个（用 , 分隔）标识符：用户名、格式为 %GROUPNAME 的组或格式为 #UID 的用户 ID。可以使用 ! 前缀来取反。\n  Host_List\n一个或多个（用 , 分隔）标识符：（完全限定的）主机名或 IP 地址。可以使用 ! 前缀来取反。Host_List 的惯常选项为 ALL。\n  NOPASSWD:|PASSWD:\n如果用户在 NOPASSWD: 后面运行的命令与 CMDSPEC 匹配，系统不会提示用户输入口令。\nPASSWD 为默认选项，仅当两个选项位于同一行时才需要指定它：\ntux ALL = PASSWD: /usr/bin/foo, NOPASSWD: /usr/bin/bar   Cmnd_List\n一个或多个（用 , 分隔）区分符：可执行文件的路径，后跟允许使用的自变量或什么也不跟。\n/usr/bin/foo # Anything allowed /usr/bin/foo bar # Only \u0026quot;/usr/bin/foo bar\u0026quot; allowed /usr/bin/foo \u0026quot;\u0026quot; # No arguments allowed   ALL 可以用作 User_List、Host_List 和 Cmnd_List。\n允许 tux 在无需输入口令的情况下以 root 身份运行所有命令的规则：\ntux ALL = NOPASSWD: ALL 允许 tux 运行 systemctl restart apache2 的规则：\ntux ALL = /usr/bin/systemctl restart apache2 允许 tux 在不带自变量的情况下以 admin 身份运行 wall 的规则：\ntux ALL = (admin) /usr/bin/wall \u0026quot;\u0026quot; 警告：以下类型的构造\nALL ALL = ALL 在没有 Defaults targetpw 的情况下切勿使用，否则任何人都能以 root 身份运行命令。\n常见使用情况 尽管默认配置对于简单的设置和桌面环境通常已经够用，但是自定义配置非常有用。\n在无需 root 口令的情况下使用 sudo 在具有特殊限制（“用户 X 只能以 root” 身份运行命令 Y）的情况下，无法实现此目的。在其他情况下，还是建议进行某种分隔。按照惯例，组 wheel 的成员能以 root 身份运行所有带有 sudo 的命令。\n  将自己添加到 wheel 组\n如果您自己的用户帐户尚不是 wheel 组的成员，请添加该帐户，具体做法是运行 sudo usermod -a -G wheel 用户名然后注销并再次登录。运行 groups 用户名以确认更改是否成功。\n  将使用调用用户的口令进行身份验证的选项设为默认设置。\n使用 visudo 创建文件 /etc/sudoers.d/userpw并添加：\nDefaults !targetpw   选择新默认规则。\n根据是否想要用户重新输入口令，取消对 /etc/sudoers 中特定行的注释，并将默认规则注释掉。\n## Uncomment to allow members of group wheel to execute any command # %wheel ALL=(ALL) ALL ## Same thing without a password # %wheel ALL=(ALL) NOPASSWD: ALL   提高默认规则的限制性\n将 /etc/sudoers 中允许一切操作的规则注释掉或去除：\nALL ALL=(ALL) ALL # WARNING! Only use this together with 'Defaults targetpw'!   警告：切勿漏掉这一步，否则任何用户都能以 root 身份执行任何命令。\n  测试配置\n尝试以 wheel 的成员和非成员身份运行 sudo。\n# user tux $ groups users wheel $ sudo id -un tux's password: root # use wilber $ groups users $ sudo id -un wilber is not in the sudoers file. This incident will be reported.   对 X.Org 应用程序使用 sudo 在使用 sudo 启动图形应用程序时，可能会出现以下错误：\n$ sudo xterm xterm: Xt error: Can't open display: %s xterm: DISPLAY is not set YaST 会选择 ncurses 界面而非图形界面。\n要在通过 sudo 启动的应用程序中使用 X.Org，需要传播环境变量 DISPLAY 和 XAUTHORITY。要进行此项配置，请创建文件 /etc/sudoers.d/xorg并添加下面一行：\nDefaults env_keep += \u0026quot;DISPLAY XAUTHORITY\u0026quot; 如尚未设置 XAUTHORITY 变量，请按如下方式设置：\nexport XAUTHORITY=~/.Xauthority 现在，X.Org 应用程序便可正常运行：\nsudo yast2 Zypper Zypper 是用于安装、更新和去除包的命令行包管理器。它还可管理储存库。这一点对于完成远程软件管理任务或从外壳脚本管理软件尤其有用。\n一般使用 Zypper 的常用语法为：\nzypper [--global-options] COMMAND [--command-options] [arguments] 有关常规选项和所有命令的列表，请参见 zypper help。要获取有关特定命令的帮助，请键入 zypper help 命令。\n  Zypper 命令\n执行 Zypper 最简单的方式是，键入其名称后跟一个命令。例如，要将所有需要的增补程序应用于系统，请使用：\n$ sudo zypper patch   全局选项\n此外，您还可以选择使用一个或多个全局选项，只需在命令前面键入它们即可：\n$ sudo zypper --non-interactive patch 在上面的示例中，选项 --non-interactive 表示在不询问任何问题的情况下运行命令（自动应用默认回答）。\n  命令特定的选项\n要使用特定于某个命令的选项，请紧接在该命令后面键入这些选项：\n$ sudo zypper patch --auto-agree-with-licenses 在上面的示例中，--auto-agree-with-licenses 用于将所有需要的增补程序应用于系统，不要求您确认任何许可条款，而是自动接受许可条款。\n  自变量\n某些命令需要一个或多个自变量。例如，使用 install 命令时，需要指定您要安装的一个或多个包：\n$ sudo zypper install mplayer 某些选项还需要单个自变量。用以下命令可列出所有已知模式：\n$ zypper search -t pattern   您可以组合上述所有模式。例如，下面的命令在冗长模式下运行时将安装 mc and vim 包（来自 factory 储存库）：\n$ sudo zypper -v install --from factory mc vim --from 选项确保了在从指定储存库请求包时保留所有储存库的启用状态（用于解析任何依赖项）。\n多数 Zypper 命令都有 dry-run 选项，它模拟给定的命令。它可用于测试。\n$ sudo zypper remove --dry-run MozillaFirefox Zypper 支持 --userdata 字符串全局选项。您可以使用此选项指定一个将会写入 Zypper 的日志文件和插件（例如 Btrfs 插件）的字符串。它可以用于标记和标识日志文件中的事务。\n$ sudo zypper --userdata STRING patch 使用 Zypper 安装和删除软件 要安装或去除包，请使用以下命令：\n$ sudo zypper install PACKAGE_NAME$ sudo zypper remove PACKAGE_NAME 警告：不要去除必需的系统包，例如 glibc 、zypper、kernel。如果去除这些包，系统可能会变得不稳定，或完全停止工作。\n选择要安装或去除的包 可以使用 zypper install 和 zypper remove 命令通过多种方法来找到包。\n  按确切的包名称\n$ sudo zypper install MozillaFirefox   按确切的包名称和版本号\n$ sudo zypper install MozillaFirefox-52.2   按储存库别名和包名称\n$ sudo zypper install mozilla:MozillaFirefox 其中 mozilla 是用于安装的储存库别名。\n  使用通配符按包名称\n您可以选择名称以特定字符串开头或结尾的所有包。使用通配符要小心，特别是去除包的时候。以下命令将安装名称以“Moz”开头的所有包：\n$ sudo zypper install 'Moz*' 提示：在调试问题时，您有时需要临时安装大量的 -debuginfo 包，以获取有关正在运行的进程的详细信息。在调试会话完成后，如果您需要清理环境，请运行以下命令：\n$ sudo zypper remove '*-debuginfo'   按功能\n例如，要安装不知道名称的包，这些功能就很有用。下面的命令将安装包 MozillaFirefox：\n$ sudo zypper install firefox   按功能、硬件体系结构或版本\n  所需硬件体系结构的名称需要追加在功能的后面，两者以句点分隔。例如，要指定 AMD64/Intel 64 体系结构（在 Zypper 中命名为 x86_64），请使用：\n$ sudo zypper install 'firefox.x86_64'   版本必须追加到字符串的末尾，并且前面必须带有一个运算符：\u0026lt;（小于）、\u0026lt;=（小于等于）、=（等于）、\u0026gt;=（大于等于）或 \u0026gt;（大于）。\n$ sudo zypper install 'firefox\u0026gt;=52.2'   还可以指定硬件体系结构与版本组合要求：\n$ sudo zypper install 'firefox.x86_64\u0026gt;=52.2'     按 RPM 文件的路径\n您还可以指定包的本地或远程路径：\n$ sudo zypper install /tmp/install/MozillaFirefox.rpm$ sudo zypper install http://download.example.com/MozillaFirefox.rpm   同时安装和去除包 要同时安装和去除包，请使用 +/- 修饰符。要安装 emacs 并同时去除 vim ，请使用：\n$ sudo zypper install emacs -vim 要去除 emacs 并同时安装 vim ，请使用：\n$ sudo zypper remove emacs +vim 为避免 - 开头的包名称被解释为命令行选项，要始终把它用作第二个自变量。如果做不到这点，在它之前加上 --：\n$ sudo zypper install -emacs +vim # Wrong$ sudo zypper install vim -emacs # Correct$ sudo zypper install -- -emacs +vim # Correct$ sudo zypper remove emacs +vim # Correct 清理已去除包的依赖项 如果您想将在指定的包去除后不再需要的所有包（随指定的包）自动去除，请使用 --clean-deps 选项：\n$ sudo zypper rm PACKAGE_NAME --clean-deps 在脚本中使用 Zypper 默认情况下，在安装或删除选定包之前发生问题时，Zypper 会要求确认。您可以使用 --non-interactive 选项覆盖此行为。必须在实际命令（install、remove 和 patch）的前面指定此选项，如下所示：\n$ sudo zypper --non-interactive install PACKAGE_NAME 该选项允许在脚本和 cron 任务中使用 Zypper。\n安装或下载源包 要安装某个包的对应源代码包，请使用：\n$ zypper source-install PACKAGE_NAME 以 root 身份执行时，源包的默认安装位置为 /usr/src/packages/；以用户身份运行时，则为 ~/rpmbuild。可以在本地 rpm 配置中更改这些值。\n使用此命令还会安装指定包的版本依赖项。如果不想执行此操作，请添加开关 -D：\n$ sudo zypper source-install -D PACKAGE_NAME 要只安装版本依赖项，请使用 -d。\n$ sudo zypper source-install -d PACKAGE_NAME 当然，只有当储存库列表中启用了含有源包的储存库时，才能这样做（默认添加但不启用它）。\n可使用以下方法来获取储存库中所有源包的列表：\n$ zypper search -t srcpackage 您也可以将所有已安装软件包的源包下载到本地目录。要下载源包，请使用：\n$ zypper source-download 默认的下载目录是 /var/cache/zypper/source-download。您可以使用 --directory 选项更改下载目录。若只想显示缺失或多余的包而不进行下载或删除任何内容，请使用 --status 选项。要删除多余的源包，请使用 --delete 选项。要禁用删除，请使用 --no-delete 选项。\n从禁用的储存库安装包 通常，您只能安装或刷新来自启用的储存库的包。--plus-content 标记选项可帮助您指定要刷新的、要在当前 Zypper 会话期间暂时启用的，以及要在会话完成后禁用的储存库。\n例如，要启用可以提供其他 -debuginfo 或 -debugsource 包的储存库，请使用 --plus-content debug。可以多次指定此选项。\n要暂时启用此类“调试”储存库以安装特定的 -debuginfo 包，请按如下所示使用该选项：\n$ sudo zypper --plus-content debug \\ install \u0026quot;debuginfo(build-id)=eb844a5c20c70a59fc693cd1061f851fb7d046f4\u0026quot; 对于缺少的 debuginfo 包，gdb 将会报告 build-id 字符串。\n实用程序 要校验所有依赖项是否仍然满足，并修复缺少的依赖项，请使用：\n$ zypper verify 除了依赖项必须满足外，某些包还“推荐”其他包。只有在实际可用并可安装时才会安装这些推荐包。如果推荐的包在推荐它们的包已安装（通过添加其他包或硬件）之后才可用，请使用以下命令：\n$ sudo zypper install-new-recommends 此命令在插入网络摄像头或 Wi-Fi 设备后非常有用。如果可用，它将安装设备驱动程序和相关软件。只有在满足特定硬件依赖项后，才可安装驱动程序和相关软件。\n使用 Zypper 更新软件 用 Zypper 更新软件有三种方式：安装包、安装包的新版本或更新整个分发包。最后一种方式可通过 zypper dist-upgrade 来实现。\n安装全部所需的增补程序 要安装所有适用于您系统的正式发布的增补程序，请运行：\n$ sudo zypper patch 系统将会检查您计算机上配置的储存库中提供的所有增补程序是否与您的安装相关。如果相关（未分为可选或功能类别），则会立即安装这些增补程序。\n如果即将安装的增补程序所包含的更改要求重引导系统，您会在重引导前收到警告。\n单纯使用 zypper patch 命令不会应用来自第三方储存库的包。要同时更新第三方储存库，请使用 with-update 命令选项，如下所示：\n$ sudo zypper patch --with update 要额外安装可选增补程序，请使用：\n$ sudo zypper patch --with-optional 要安装与特定 Bugzilla 问题相关的所有增补程序，请使用：\n$ sudo zypper patch --bugzilla=NUMBER 要安装与特定 CVE 数据库项相关的所有增补程序，请使用：\n$ sudo zypper patch --cve=NUMBER 例如，要安装 CVE 编号为 CVE-2010-2713 的安全增补程序，请执行：\n$ sudo zypper patch --cve=CVE-2010-2713 如果只想安装影响 Zypper 和包管理本身的增补程序，请使用：\n$ sudo zypper patch --updatestack-only 请记住，如果您使用了 updatestack-only 命令选项，将会丢弃原本还会更新其他储存库的其他命令选项。\n列出增补程序 为了让您确定增补程序是否可用，Zypper 允许您查看以下信息：\n  所需增补程序的数目\n要列出所需增补程序（适用于您的系统但尚未安装的增补程序）的数目，请使用 patch-check：\n$ zypper patch-checkLoading repository data...Reading installed packages...5 patches needed (1 security patch) 可以结合 --updatestack-only 选项使用此命令，以便仅列出影响 Zypper 和包管理本身的增补程序。\n  所需增补程序的列表\n要列出全部所需的增补程序（适用于您的系统但尚未安装的增补程序），请使用 list-patches：\n$ zypper list-patchesLoading repository data...Reading installed packages...Repository | Name | Version | Category | Status | Summary---------------+-------------+---------+----------+---------+---------SLES12-Updates | SUSE-2014-8 | 1 | security | needed | openssl: Update for OpenSSL   所有增补程序的列表\n要列出可用的所有增补程序，而不管它们是否已安装或适用于您的安装，请使用 zypper patches。\n还可以列出并安装与特定问题相关的增补程序。要列出特定的增补程序，请使用带以下选项的 zypper list-patches 命令：\n  按 Bugzilla 问题\n要列出与 Bugzilla 问题相关的全部所需增补程序，请使用 --bugzilla 选项。\n要列出针对特定 Bug 的增补程序，您也可以指定 Bug 编号：--bugzilla=编号。要搜索与多个 Bugzilla 问题相关的增补程序，请在 bug 编号之间添加逗号，例如：\n$ zypper list-patches --bugzilla=972197,956917   按 CVE 编号\n要列出与 CVE（公共漏洞和披露）数据库中某个项相关的全部所需增补程序，请使用 --cve 选项。\n要列出针对特定 CVE 数据库项的增补程序，您也可以指定 CVE 编号：--cve=*编号*。要搜索与多个 CVE 数据库项相关的增补程序，请在 CVE 编号之间添加逗号，例如：\n$ zypper list-patches --bugzilla=CVE-2016-2315,CVE-2016-2324     要列出所有增补程序而不管是否需要安装它们，请另外使用 --all 选项。例如，要列出指派有 CVE 编号的所有增补程序，请使用：\n$ zypper list-patches --all --cveIssue | No. | Patch | Category | Severity | Status------+---------------+-------------------+-------------+-----------+----------cve | CVE-2015-0287 | SUSE-SLE-Module.. | recommended | moderate | neededcve | CVE-2014-3566 | SUSE-SLE-SERVER.. | recommended | moderate | not needed[...] 安装新的包版本 如果某个安装源只包含新包，但未提供增补程序，则 zypper patch 不会产生任何作用。要使用可用的较新版本更新所有已安装的包（同时还要保持系统完整性），请使用︰\n$ sudo zypper update 要更新个别包，请用更新或安装命令指定包：\n$ sudo zypper update PACKAGE_NAME$ sudo zypper install PACKAGE_NAME 可使用此命令来获取所有新的可安装包的列表：\n$ zypper list-updates 请注意，此命令只会列出符合以下准则的包︰\n 与已安装的包拥有相同的供应商， 由至少与已安装包拥有相同优先级的储存库提供， 可安装（满足所有依赖项）。  所有新的可用包（无论是否可安装）的列表可通过以下方式获取：\n$ sudo zypper list-updates --all 要找出新包无法安装的原因，请使用上面所述的 zypper install 或 zypper update 命令。\n识别孤立的包 每当您从 Zypper 中去除某个储存库或者升级系统时，某些包可能会进入“孤立”状态。这些孤立的包不再属于任何活动储存库。以下命令可以列出这些包：\n$ sudo zypper packages --orphaned 借助此列表，您可以确定是否仍然需要某个包，或者是否可以安全去除某个包。\n识别使用已删除文件的进程和服务 在增补、更新或去除包时，系统上可能有一些正在运行的进程会继续使用更新或去除后已被删除的文件。运行 zypper ps 可以列出使用已删除文件的进程。如果此类进程属于某个已知的服务，则会列出服务名称，方便您重启动该服务。默认情况下，zypper ps 会显示一个表：\nPID | PPID | UID | User | Command | Service | Files------+------+-----+-------+--------------+--------------+-------------------814 | 1 | 481 | avahi | avahi-daemon | avahi-daemon | /lib64/ld-2.19.s-\u0026gt; | | | | | | /lib64/libdl-2.1-\u0026gt; | | | | | | /lib64/libpthrea-\u0026gt; | | | | | | /lib64/libc-2.19-\u0026gt;[...]  PID：进程的 ID PPID：父进程的 ID UID：运行进程的用户的 ID User：运行进程的用户的登录名 Command：用于执行进程的命令 Service：服务名称（仅当命令与系统服务关联时才显示） Files：已删除文件的列表  通过如下方式可控制 zypper ps 的输出格式：\n  zypper ps -s\n创建一份简短表格，其中不会显示已删除的文件。\nPID | PPID | UID | User | Command | Service------+------+------+---------+--------------+--------------814 | 1 | 481 | avahi | avahi-daemon | avahi-daemon817 | 1 | 0 | root | irqbalance | irqbalance1567 | 1 | 0 | root | sshd | sshd1761 | 1 | 0 | root | master | postfix1764 | 1761 | 51 | postfix | pickup | postfix1765 | 1761 | 51 | postfix | qmgr | postfix2031 | 2027 | 1000 | tux | bash |   zypper ps -ss\n仅显示与系统服务关联的进程。\nPID | PPID | UID | User | Command | Service------+------+------+---------+--------------+--------------814 | 1 | 481 | avahi | avahi-daemon | avahi-daemon817 | 1 | 0 | root | irqbalance | irqbalance1567 | 1 | 0 | root | sshd | sshd1761 | 1 | 0 | root | master | postfix1764 | 1761 | 51 | postfix | pickup | postfix1765 | 1761 | 51 | postfix | qmgr | postfix   zypper ps -sss\n仅显示使用已删除文件的系统服务。\navahi-daemonirqbalancepostfixsshd   zypper ps --print \u0026quot;systemctl status %s\u0026quot;\n显示用于检索可能需要重启动的服务状态信息的命令。\nsystemctl status avahi-daemonsystemctl status irqbalancesystemctl status postfixsystemctl status sshd   用 Zypper 管理安装源 Zypper 的所有安装或增补程序命令均基于已知安装源列表。要列出系统已知的所有储存库，请使用命令：\n$ zypper repos 结果将类似于与以下输出：\n# | Alias | Name | Enabled | Refresh--+--------------+---------------+---------+--------1 | SLEHA-12-GEO | SLEHA-12-GEO | Yes | No2 | SLEHA-12 | SLEHA-12 | Yes | No3 | SLES12 | SLES12 | Yes | No 当在各个命令中指定储存库时，可以使用别名、URI 或 zypper repos 命令输出中的储存库编号。储存库别名是用于储存库处理命令中的储存库名称的简短版本。请注意，在修改储存库列表后，储存库编号可能会更改。别名本身不会更改。\n默认情况下不显示储存库的 URI 或优先级之类的细节。用以下命令可以列出所有细节：\n$ zypper repos -d 添加安装源 要添加安装源，请运行\n$ sudo zypper addrepo URI ALIAS URI 可以是因特网储存库、网络资源、目录、CD 或 DVD。ALIAS 是储存库的唯一简写标识符。您可以随意选择别名，前提是它必须唯一。如果指定的别名已在使用，Zypper 将发出警告。\n刷新储存库 zypper 可让您从配置的储存库中提取包的更改。要提取更改，请运行：\n$ sudo zypper refresh 注意：有些命令默认会自动执行 refresh，因此您不需要明确运行该命令。\n使用 refresh 命令时搭配 --plus-content 选项还可查看已禁用储存库中的更改：\n$ sudo zypper --plus-content refresh 该选项虽然会提取储存库中的更改，但会使禁用储存库的状态保持不变，即仍为禁用。\n删除储存库 要从列表中去除某个储存库，请将命令 zypper removerepo 与要删除的储存库的别名或编号结合使用。例如\n$ sudo zypper removerepo 1$ sudo zypper removerepo \u0026quot;SLEHA-12-GEO\u0026quot; 修改储存库 用 zypper modifyrepo 启用或禁用储存库。您还可以用该命令更改储存库的属性（例如刷新行为、名称或优先级）。以下命令将会启用名为 updates 的储存库、打开自动刷新并将其优先级设置为 20：\n$ sudo zypper modifyrepo -er -p 20 'updates' 修改储存库并不局限于单个储存库 —— 您也可以对组执行该操作︰\n -a：所有储存库 -l：本地储存库 -t：远程储存库 -m 类型：特定类型的储存库（其中类型可以是以下之一：http、https、ftp、cd、dvd、dir、file、cifs、smb、nfs、hd 和 iso）  要重命名安装源别名，请使用 renamerepo 命令。以下示例将别名从 Mozilla Firefox 更改为 firefox：\n$ sudo zypper renamerepo 'Mozilla Firefox' firefox 用 Zypper 查询储存库和包 Zypper 提供各种查询储存库或包的方式。要获取所有可用的产品、模式、包或增补程序的列表，请使用以下命令：\n$ zypper products$ zypper patterns$ zypper packages$ zypper patches 要查询特定包的所有储存库，请使用 search。要获得有关特定包的信息，请使用 info 命令。\n搜索软件 zypper search 命令可对包名或（视情况）对包摘要和说明执行搜索。括在 / 中的字符串会解译为正则表达式。默认情况下搜索不区分大小写。\n  执行简单搜索来查找包含 fire 的包名称\n$ zypper search \u0026quot;fire\u0026quot;   执行简单搜索来查找确切的包 MozillaFirefox\n$ zypper search --match-exact \u0026quot;MozillaFirefox\u0026quot;   同时在包描述和摘要中搜索\n$ zypper search -d fire   仅显示尚未安装的包\n$ zypper search -u fire   显示包含字符串 fir 且该字符串后面不是 e 的包\n$ zypper se \u0026quot;/fir[^e]/\u0026quot;   搜索特定功能 要搜索提供特殊功能的包，请使用命令 what-provides。例如，如果您想知道哪个包提供 Perl 模块 SVN::Core，请使用以下命令：\n$ zypper what-provides 'perl(SVN::Core)' what-provides 包名 与 rpm -q --whatprovides 包名 类似，不过 RPM 只能查询 RPM 数据库（即所有已安装的包的数据库）。另一方面，Zypper 将告诉您任意储存库的功能的提供商，而非仅已安装的储存库功能的提供商。\n显示包信息 要查询个别包，请使用 info 命令，并用完整包名称作为自变量。这会显示有关某个包的详细信息。如果包名与储存库中的所有包名都不匹配，该命令会输出非包匹配项的详细信息。如果您请求特定类型（通过使用 -t 选项），但该类型不存在，该命令会输出其他可用的匹配项，但不提供详细信息。\n如果您指定源包，该命令会显示基于该源包构建的二进制包。如果您指定二进制包，该命令会输出用来构建该二进制包的源包。\n如果还要显示该包必需/推荐的包，则使用选项 --requires 和 --recommends：\nzypper info --requires MozillaFirefox 显示生命周期信息 要检查您的产品和所支持包的生命周期，请如下所示使用 zypper lifecycle 命令：\n$ zypper lifecycleProduct end of supportCodestream: SUSE Linux Enterprise Server 15 2028-04-23 SUSE Linux Enterprise Server 15 n/a*Module end of supportBasesystem Module 2021-07-31No packages with end of support different from product.*) See https://www.suse.com/lifecycle for latest information 配置 Zypper Zypper 现在随附配置文件，允许您永久更改 Zypper 的行为（系统范围或用户特定）。要进行系统范围更改，请编辑 /etc/zypp/zypper.conf。要进行用户特定的更改，请编辑 ~/.zypper.conf。如果 ~/.zypper.conf 尚不存在，您可以使用 /etc/zypp/zypper.conf 作为模板：将其复制到 ~/.zypper.conf 并根据您的喜好进行调整。请参见文件中的注释，获取有关可用选项的帮助。\n查错 如果您在访问配置的储存库中的包时遇到问题（例如，尽管您知道某个包在某个储存库中，但 Zypper 找不到该包），刷新储存库或许可以解决问题：\nsudo zypper refresh 如果不起作用，则尝试\nsudo zypper refresh -fdb 这会强制完全刷新和重构建数据库，包括强制下载原始元数据。\nBtrfs 文件系统上的 Zypper 回滚功能 如果根分区上使用的是 Btrfs 文件系统，且系统中安装了 snapper，当 Zypper 提交对文件系统所做的更改以创建相应的文件系统快照时，会自动调用 snapper。这些快照可用于还原 Zypper 进行的任何更改。\nRPM RPM（RPM 程序包管理器）用于管理软件包。其主要程命令为 rpm 和 rpmbuild。用户、系统管理员和包构建人员可以查询强大的 RPM 数据库以获得有关已安装软件的详细信息。\nrpm 有五种模式：安装、卸装（或更新）软件包、重构建 RPM 数据库、查询 RPM 库或独立 RPM 存档、对包执行完整性检查以及对包签名。rpmbuild 可用于从原始源构建可安装的包。\n用特殊的二进制格式对可安装 RPM 存档进行打包。这些存档由要安装的程序文件和某些元信息组成，这些元信息供 rpm 在安装过程中配置软件包使用或者储存在 RPM 数据库中进行存档。RPM 存档通常具有扩展名 .rpm。\n对于一些包，软件开发所需的组件（库、报头、包含文件等）已纳入独立的包中。只有当您要自己编译软件时才需要这些开发包（例如最新的 GNOME 包）。可以通过扩展名 -devel 确定这些开发包，例如包 alsa-devel 和 gimp-devel。\n校验包真实性 RPM 包具有 GPG 签名。要校验 RPM 包的签名，请使用 rpm --checksig PACKAGE-1.2.3.rpm 命令确定该包是来自 SUSE 还是另一个可信机构。特别建议对来自因特网的更新包使用此命令。\n修复操作系统中的问题时，您可能需要将问题临时修复 (PTF) 安装到生产系统中。SUSE 提供的包已使用特殊的 PTF 密钥签名。要手动导入该密钥，请使用以下命令：\nsudo rpm --import \\/usr/share/doc/packages/suse-build-key/suse_ptf_key.asc 导入该密钥后，您可以在系统上安装 PTF 包。\n管理包：安装、更新和卸装 安装 RPM 存档的步骤通常十分简单，执行运行：rpm -i PACKAGE.rpm。使用此命令可以安装包，但前提是满足其依赖关系并且不与其他包冲突。如果出现错误消息，rpm 将请求那些需要安装的包以满足依赖关系要求。在后台，RPM 数据库确保不出现冲突 － 一个特定文件只能属于一个包。通过选择不同的选项，您可以强制 rpm 忽略这些默认设置，但这只供专家用户使用。否则，将影响系统的完整性并可能使系统无法更新。\n选项 -U 或 --upgrade 以及 -F 或 --freshen 可用于更新包（例如，rpm -F PACKAGE.rpm）。此命令将删除旧版本的文件并立即安装新文件。两个版本之间的差别是：-U 安装系统中以前不存在的包，而 -F 只更新以前安装的包。更新时，rpm 使用以下策略小心更新配置文件：\n 如果配置文件未被系统管理员更改，则 rpm 将安装适当文件的新版本。系统管理员无需执行任何操作。 如果配置文件在更新前曾被系统管理员更改，则 rpm 会以扩展名 .rpmorig 或 .rpmsave（备份文件）保存更改的文件，并安装新包中的版本。仅当原先安装的文件和较新的版本不同时，才执行此操作。如果是这种情况，则将备份文件（.rpmorig 或 .rpmsave）与新安装的文件进行比较，并在新文件中再次进行更改。之后，请删除所有 .rpmorig 和 .rpmsave 文件，以免以后的更新出现问题。 如果配置文件已存在并且 .spec 文件中指定了 noreplace 标签，则出现 .rpmnew 文件。  更新后，在使用 .rpmsave 和 .rpmnew 文件进行比较后应将它们删除，从而防止它们阻碍以后的更新。如果 RPM 数据库以前未能识别文件，则将为其指派扩展名 .rpmorig。 否则，将使用 .rpmsave。换句话说，.rpmorig 是从异系统格式更新为 RPM 的结果。而 .rpmsave 是从较早的 RPM 更新为较新的 RPM 的结果。.rpmnew 不提供任何有关系统管理员是否对配置文件进行过任何更改的信息。/var/adm/rpmconfigcheck 中提供这些文件的列表。不覆盖某些配置文件（如 /etc/httpd/httpd.conf）以允许继续进行操作。\n-U 开关的作用并不完全等同于使用 -e 选项进行卸载以及使用 -i 选项进行安装，它还有其他作用。只要可能，就可以使用 -U。\n要去除包，请输入 rpm -e PACKAGE。仅当不存在未解决的依赖项问题时，此命令才会删除包。例如，只要有其他程序需要 Tcl/Tk，理论上就不能删除它。即使是在这种情况下，RPM 也会向数据库寻求帮助。如果出于任何原因无法进行此删除操作（即使不存在其他依赖项），则最好使用选项 --rebuilddb 重构建 RPM 数据库。\n增量 RPM 包 增量 RPM 包包含旧版本和新版本的 RPM 包之间的差别。在旧 RPM 上应用增量 RPM 将得到全新的 RPM。不需要旧 RPM 的副本，因为增量 RPM 也可以与已安装的 RPM 一起工作。增量 RPM 包的大小甚至比增补程序 RPM 小，这有利于通过因特网传送更新包。缺点是，涉及增量 RPM 的更新操作与使用纯粹 RPM 或增补程序 RPM 进行更新的情况相比，占用的 CPU 周期要长得多。\nmakedeltarpm 和 applydelta 二进制文件是增量 RPM 套件（包 deltarpm）的一部分，可帮助您创建和应用增量 RPM 包。使用以下命令可以创建名为 new.delta.rpm 的增量 RPM。以下命令假设 old.rpm 和 new.rpm 是存在的：\nsudo makedeltarpm old.rpm new.rpm new.delta.rpm 如果旧包已经安装，则使用 applydeltarpm 可以从文件系统重新构建新的 RPM：\nsudo applydeltarpm new.delta.rpm new.rpm 如果不访问文件系统而从旧 RPM 得到它，请使用 -r 选项：\nsudo applydeltarpm -r old.rpm new.delta.rpm new.rpm RPM 查询 带 -q 选项的 rpm 将启动查询，如此用户便可查看 RPM 存档（通过添加选项 -p）并查询已安装包的 RPM 数据库。可以使用多个开关指定所需信息的类型。\n   选项 含义     -i 包信息   -l 文件列表   -f FILE 查询包含文件 FILE 的包（必须使用 FILE 指定完整路径）   -s 带有状态信息的文件列表（间接指定 -l）   -d 仅列出文档文件（间接指定 -l）   -c 仅列出配置文件（间接指定 -l）   --dump 带有完整详细信息的文件列表（将用于 -l、-c 或 -d）   --provides 列出包中可被另一个包通过 --requires 请求的功能   --requires, -R 包需要的功能   --scripts 安装脚本（预安装、后安装、卸载）    例如，命令 rpm -q -i wget 显示\nName : wgetVersion : 1.14Release : 17.1Architecture: x86_64Install Date: Mon 30 Jan 2017 14:01:29 CETGroup : Productivity/Networking/Web/UtilitiesSize : 2046483License : GPL-3.0+Signature : RSA/SHA256, Thu 08 Dec 2016 07:48:44 CET, Key ID 70af9e8139db7c82Source RPM : wget-1.14-17.1.src.rpmBuild Date : Thu 08 Dec 2016 07:48:34 CETBuild Host : sheep09Relocations : (not relocatable)Packager : https://www.suse.com/Vendor : SUSE LLC \u0026lt;https://www.suse.com/\u0026gt;URL : http://www.gnu.org/software/wget/Summary : A Tool for Mirroring FTP and HTTP ServersDescription :Wget enables you to retrieve WWW documents or FTP files from a server.This can be done in script files or via the command line.Distribution: SUSE Linux Enterprise 12 只有当您指定带有完整路径的完整文件名时，选项 -f 才起作用。根据需要提供任意多个文件名。例如：\nrpm -q -f /bin/rpm /usr/bin/wgetrpm-4.11.2-15.1.x86_64wget-1.14-17.1.x86_64 如果只知道部分文件名，则可以使用外壳脚本。当运行所显示的脚本时，将部分文件名以参数的形式传递给脚本。\n#! /bin/shfor i in $(rpm -q -a -l | grep $1); do echo \u0026quot;\\\u0026quot;$i\\\u0026quot; is in package:\u0026quot; rpm -q -f $i echo \u0026quot;\u0026quot;done rpm -q --changelog PACKAGE 命令会按日期排序显示有关特定包的详细更改信息列表。\n借助已安装的 RPM 数据库，可以进行校验检查。使用 -V 或 --verify 启动这些检查。使用此选项，rpm 显示安装后已被更改的包中的所有文件。rpm 使用 8 个字符符号给出有关以下更改的一些提示：\n   符号 含义     5 MD5 校验和   S 文件大小   L 符号链接   T 修改时间   D 主要和次要设备编号   U 拥有者   G 组   M 方式（权限和文件类型）    对于配置文件，将输出字母 c。例如，对于 /etc/wgetrc（wget 包）的更改：\nrpm -V wgetS.5....T c /etc/wgetrc RPM 数据库的文件被放置在 /var/lib/rpm 中。如果分区 /usr 的大小为 1 GB，则此数据库可能会占用将近 30 MB，特别是在完全更新之后。如果数据库比预期大得多，则最好使用选项 --rebuilddb 重构建数据库。在执行此操作之前，制作旧数据库的备份。cron 脚本 cron.daily 每天制作数据库的副本（用 gzip 打包）并将这些副本储存在 /var/adm/backup/rpmdb 中。副本的数目是由 /etc/sysconfig/backup 中的变量 MAX_RPMDB_BACKUPS（默认值为 5）控制的。对于 1 GB 的 /usr，单个备份的大小大约为 1 MB。\n安装和编译源包 所有源包都带有 .src.rpm 扩展名（源 RPM）。\n源包可以从安装媒体复制到硬盘并使用 YaST 解压缩。但是，在包管理器中它们不会被标记为已安装 ([i])。这是因为源包不是在 RPM 数据库中输入的。只有已安装的操作系统软件列在 RPM 数据库中。安装源包时，只将源代码添加到系统中。\n以下目录必须可用于 /usr/src/packages 中的 rpm 和 rpmbuild（除非在诸如 /etc/rpmrc 这样的文件中指定自定义设置）：\n  SOURCES\n代表原始源（.tar.bz2 或 .tar.gz 文件等）和特定于发布版本的调整（多为 .diff 或 .patch 文件）\n  SPECS\n代表 .spec 文件，类似于元 Makefile，该文件控制构建进程\n  BUILD\n在此目录中解压缩、增补和编译所有源\n  RPMS\n储存完整的二进制包的位置\n  SRPMS\n这里是源 RPM\n  使用 YaST 安装源包时，将在 /usr/src/packages 中安装所有需要的组件：源和调整在 SOURCES 中，相关的 .spec 文件在 SPECS 中。\n警告：不要对系统组件（glibc、rpm 等）进行试验，因为这样做会影响系统的稳定性。\n下面的示例使用 wget.src.rpm 包。安装源包后，应具有类似以下列表中的文件：\n/usr/src/packages/SOURCES/wget-1.11.4.tar.bz2/usr/src/packages/SOURCES/wgetrc.patch/usr/src/packages/SPECS/wget.spec rpmbuild -bX /usr/src/packages/SPECS/wget.spec 会启动编译。X 是通配符，代表构建进程的不同阶段。以下简要描述：\n  -bp\n在 /usr/src/packages/BUILD 中准备源：解压和打增补程序。\n  -bc\n执行与 -bp 相同的操作，但还进行编译。\n  -bi\n执行与 -bp 相同的操作，但还安装生成的软件。注意：如果包不支持 BuildRoot 功能，则可能会重写配置文件。\n  -bb\n执行与 -bi 相同的操作，但还创建二进制包。如果编译成功，二进制包应该在 /usr/src/packages/RPMS 中。\n  -ba\n执行与 -bb 相同的操作，但还创建源 RPM。如果编译成功，二进制包应该在 /usr/src/packages/SRPMS 中。\n  --short-circuit\n跳过某些步骤。\n  现在可以使用 rpm -i 或最好使用 rpm -U 来安装创建的二进制 RPM。使用 rpm 进行安装使它显示在 RPM 数据库中。\n使用 build 编译 RPM 包 许多包存在的风险是构建进程中会将许多不需要的文件添加到正在运行的系统中。为防止发生这种情况，请使用 build，它将创建构建包的已定义环境。要建立这一 chroot 环境，build 脚本必须和完整的包树结构一起提供。可以通过 NFS 或从 DVD 使用硬盘上的此树。使用 build --rpms DIRECTORY 设置位置。与 rpm 不同，build 命令在源目录中查找 .spec 文件。要用系统中 /media/dvd 下装入的 DVD 构建 wget（如上例所示），请以 root 用户身份使用以下命令：\ncd /usr/src/packages/SOURCES/mv ../SPECS/wget.spec .build --rpms /media/dvd/suse/ wget.spec 随后，将在 /var/tmp/build-root 建立一个最小的环境。在此环境中构建包。完成后，生成的包位于 /var/tmp/build-root/usr/src/packages/RPMS 中。\nbuild 脚本提供多个其他选项。例如，使脚本优先选择您自己的 RPM、忽略构建环境的初始化或者将 rpm 命令限制在上述阶段之一。\n用于 RPM 存档和 RPM 数据库的工具 Midnight Commander (mc) 可以显示 RPM 存档的内容并复制部分内容。它将存档表示为虚拟文件系统，提供 Midnight Commander 所有常用的菜单选项。使用 F3 键显示 HEADER。使用光标键和 Enter 键查看存档结构。使用 F5 键复制部分存档。\n拥有全部功能的包管理器将作为 YaST 模块提供。\nPackman 什么是 Packman ？ openSUSE 的 Packman 是 Package man 的缩写。意即指一群打包狂组成的团体。他们在尊重并重视版权的基础上做一些规避专利的事。总之，他们想要自由打包从多媒体到大型软件到游戏到甚至是自己的回收站的所有内容。\nPackman 和 openSUSE 的关系 Packman 不隶属于任何 openSUSE 官方，是独立于 openSUSE 社区之外的社区，只是基于 openSUSE 打给 openSUSE 用的软件包。注意 openSUSE 社区也是官方，同样有在专利法最为严苛的美国和欧洲注册，这也是为什么 OBS 不能打包专利软件的原因，另一个原因是 OBS 的服务器坐落于德国诺伦堡。\nPackman 的资源来自于成员捐献，不能和 openSUSE 官方有任何的联系，也就是说即使是 SuSE 的捐献，也要放弃一切权利。不能像社区董事会那样，主席要由 SuSE 指定，一般是 SuSE 员工。\nPackman 欢迎大学和社区为它做镜像。\nPackman 收纳什么样的软件 ？ 由于英文的 free 很有迷惑性（大部分外国人喜欢用法语 Libre，也就是自由）：\n 这里的自由，仍然不包括商业和私有软件，版权产品应该尊重他们自有的分发渠道。也就是说，这里仍然不做盗版，也不做免费使用的商业软件。不规避版权，只规避专利。版权同样是保护 Linux 下的开源作品不被盗版的力量，而专利则是大公司用来牟利的工具。 这里只接纳由于或有专利纠纷而不能存在于官方构建服务中的软件。比如 FFMPEG，MPLAYER，MP3, AMULE。和依赖它们的软件。以及可以自由分发的软件，并且愿意允许从源代码编译。  也就是说，大部分时候这里的软件都是 FOSS/LOSS （自由和开源软件），而不是免费软件。而且是存在或有专利纠纷的软件，想想看什么软件最容易发生专利纠纷呢？ 多媒体。于是 Packman 里有那么多多媒体软件也就不奇怪了。\n另外 Packman 还允许两类软件：发行版中长期不更新的软件的最新版，和发行版中没有的软件。但这是 FTP 做源的时代延续下来的。目前这两类软件都建议走 OBS 流程来做，因为 OBS 的服务器比 Packman 的多快好省。\nTips\u0026amp;Questions 解决KDE下KDE Wallet重装系统后每次登陆需要输入密码 在每次重装或者配置桌面后kdewallet总是在登陆系统之后提示输入密码，虽然在输入密码后能够继续正常使用，但是每次登陆系统都需要输入一次密码还是很烦人的。\n出现的原因：\n在重新配置桌面或者重装系统之后KDE Wallet所需要的一些必备需要依赖组件未能找到，所以导致不能正确运行KDE Wallet，所以只要安装其所需的组件即可。而其所需的但是未能自动安装的依赖组件正是 pam_kwallet，kwallet-pam 与 GnuPG keys 不兼容，所以 KDE Wallet 必须使用 blowfish 加密方式。\n解决方案 ：\n安装缺失的组件\nsudo zypper in pam_kwallet 为了保险起见，查看个人目录下是否存在~/.kde4/share/apps/kwallet文件夹，如果存在则将其删除或者重命名以避免出现冲突，并且还需要确定使用的钱包名为kdewallet并且密码为当前用户的密码。\n如此便可完全正常使用KDE Wallet\n解决方案参考arch wiki的KDE Wallet小节中。\nCould not open a connection to your authentication agent 执行ssh-add时出现\nssh-agent bash 无法读取 exfat 、 .7z 和 .rar sudo zypper in fuse-exfat exfat-utilssudo zypper in p7zip-fullsudo zypper in unrar 不关闭单击运行 Dolphin 默认单击运行，多数人都熟悉双击运行，但是其实只要点击文件左上角的加号，就可以不运行，相当于双击下的单击选择文件。\n杀死窗口 按 CTRL + ESC ，启动系统卫士，点击 工具 ，然后点击 杀死窗口 ，然后点击你想干掉的窗口。\n主题 不是我喜欢黑暗主题，而是热门的好看的主题都是黑暗主题。所以尝试如下：\n 全局黑暗主题为 Sweet chrome 黑暗主题  系统设置 Theme 使用 GTK+，可以使标题栏，设置菜单栏为黑暗，但是网页、设置页为白色。 Chrome 黑暗模式：在网址栏输入 chrome://flags/#enable-force-dark，启用。可以使设置页面黑暗，网页黑暗，但是进入 segmentfault，你会发现 segment 不见了。 安装 dark reader 插件。可以使网页黑暗，比 chrome 自带表现要好。但是打开新页面时，还是有短暂的白色。   Firefox 黑暗主题  设置页的颜色会与系统一致，也就是与 chrome 相反。 firefox theme 会改变标题栏、设置菜单栏颜色。    实际上你会发现，无法达到一致的黑暗，反而使得眼睛不舒服，所以我放弃了黑暗主题。\n亮色混合主题：\n Global Theme 为 openSUSE Plasma 为 Edna-light Window Decorations 为 Edna-light Font 为 Source Hans Sans CN 和 Jet Brains Moon Icon 为 Papirus SSDM Theme 为 chili for plasma kconsole 主题为 sweet 开始改为 application dashboard  实际你会发现，混合主题没有一个单独主题搭配的那么协调。\n窗体内容亮色，其他部分为黑暗，即标准主题:\n 全局主题 Sweet Colors 为 Breeze，使得 window 内容为亮色 Window Decorations 为 sweet-dark-transparent，设置标题栏 Icon 为 Papirus SSDM Theme 为 sweet fcitx 为 dartmouth。  感觉可以。\nDesktop Effects：\n Magic Lamp 400ms Wobbly Windows  不如不要。\nopenSUSE 的默认 /etc/sudoers Defaults targetALL ALL=(ALL) ALLroot ALL=(ALL) ALL 并把root密码设置为安装时用户密码。\n这导致你在装完系统后，如果改了密码，依旧需要通过原来的密码获取 root 权限。\nvscode keychain issues for KDE $ sudo zypper in gnome-keyring 提示添加密码的时候为空就行了，否则每次启动 vscode 都需要输入一次密码。\nNVIDIA 有两种为英伟达（NVIDIA）显卡提供的驱动：\n 为 NVIDIA 硬件提供的自由开源的驱动名叫 nouveau。 来自 NVIDIA 厂商自己的驱动名为 nvidia，但由于许可证问题，它不能直接被集成进入 openSUSE 。  添加 Nvdia 软件源\n# zypper addrepo --refresh 'https://download.nvidia.com/opensuse/leap/$releasever' NVIDIA 确定显卡型号\n# hwinfo --gfxcard | grep Model 安装驱动\n# zypper in x11-video-nvidiaG05 重启确认是否加载\n# lsmod | grep nvidia 常用软件 Typora 字体 如果 Typora 字体如上面那样，每个字大小不一样：\n  整个应用的语言设置为英语\n  在 conf.user.json 指定字体\n{ \u0026#34;defaultFontFamily\u0026#34;: { \u0026#34;standard\u0026#34;: \u0026#34;Source Han Sans CN\u0026#34;, //String - Defaults to \u0026#34;Times New Roman\u0026#34;.  \u0026#34;serif\u0026#34;: \u0026#34;Source Han Sans CN\u0026#34;, // String - Defaults to \u0026#34;Times New Roman\u0026#34;.  \u0026#34;sansSerif\u0026#34;: \u0026#34;Source Han Sans CN\u0026#34;, // String - Defaults to \u0026#34;Arial\u0026#34;.  \u0026#34;monospace\u0026#34;: \u0026#34;JetBrains Mono\u0026#34; // String - Defaults to \u0026#34;Courier New\u0026#34;.  } }   flatpak run: Invalid MIT-MAGIC-COOKIE-1 key rm .Xauthority Linux Deploy 准备 一个 Root 了的 Android 手机\nBusy Box：Linux Deploy 支撑软件。\nLinux deploy：Linux 系统支撑软件。\n安装 Busy Box 点击安装，等待程序自行运行，在界面中输出 ## END 后退出程序。\nLinux deploy  点击左图左上角部分，选择 设置，在设置界面中找到PATH变量，赋予其值 /system/xbin。 建议开启 锁定Wifi 功能。 接着退回主界面，点击右下角部分。 发行版 看个人喜好选择，Debian 系（Debian，Kaili，Ubuntu）较热门。 架构 默认。 源 默认。如果下的慢的话，就仿照默认的源换为国内的源，如 USTC MIRRORS，但是不要特意去换源，官方的源用的了的话官方的源最好。 安装路径 ：安装在手机自带的存储空间中，则在路径开头加上${ENV_DIR}；安装在 sdcard 中，加上${EXTERNAL_STORAGE}。 文件系统 ：推荐 ext4。 用户名 和 密码 自定义。 DNS 默认。 本地化 ：简体中文可以选择 zh_CN.UTF-8，建议选择 en_US.UTF-8 。 挂载列表：添加访问手机内容的目录，手机目录：挂载点，如 /sdcard:/mnt，之后会自动挂载。 开启SSH。 图形界面功能，需要的话就选 XFce 为桌面，XFce`是轻量级桌面环境。 退出系统设置界面，点击主界面右上角，选择安装。 等待程序自行安装Linux系统，开始时会自动创造一个4G左右大小的img文件，这个是默认的大小，你可以根据你手机的容量自定义，创造文件需要一点时间，屏幕会很安静，再然后会安装各种东西，屏幕会输出很多信息，根据你的源的速度，等待时间不等，看到 \u0026lt;\u0026lt;\u0026lt;deploy 则安装完毕。如果中间没有 failed 则安装成功。安装失败的话就需要重新安装，换个快一点的网，或者好一点的源。 注意：安装完毕后要先点击停止按钮，再按启动按钮。这个很重要，不然你就得重装了。  使用   Andorid 端用 ConnectBox\n  Windows用 putty ，图形界面用 VNC Viewer。VNC Viewer 直接搜主机IP就行，VNC Server 在你选择安装图形界面功能时就自动安装了，不需要再安装 vnc4server。\n  Linux 输入ssh username@hostname就行。\n  其他   安装后如果用 vnc viewer 只有一个点的话，可以换一个发行版，我尝试的 CentOS 有这个问题。\n  Linux连的时候出现 WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!：\nssh-keygen -R + 输入服务器的IP   altarch 架构的手机 CentOS 系统换源\ncp CentOS-7-armhfp.repo CentOS-Base.repo mv CentOS-7-armhfp.repo CentOS-7-armhfp.repo.backup vi CentOS-Base.repo baseurl=https://mirrors.ustc.edu.cn/centos-altarch/7.6.1810/os/armhfp/ yum makecache yum update   如果你之前没有安装VNC的话，现在又想装：\nyum -y install tigervnc-server   ","permalink":"https://sakamotokurome.github.io/posts/distributions/","summary":"Fedora [fəˈdɔrə] 费多拉 Fedora 定制版 为什么 Linus Torvalds 用 Fedora 2008：linus对发行版的要求是\u0026quot;易安装，比较贴近上游\u0026quot;即可。 201","title":"Distributions"},{"content":" The goals of the FreeBSD Project are to provide software that may be used for any purpose and without strings attached. Many of us have a significant investment in the code (and project) and would certainly not mind a little financial compensation now and then, but we are definitely not prepared to insist on it. We believe that our first and foremost \u0026ldquo;mission\u0026rdquo; is to provide code to any and all comers, and for whatever purpose, so that the code gets the widest possible use and provides the widest possible benefit. This is, I believe, one of the most fundamental goals of Free Software and one that we enthusiastically support.\nThat code in our source tree which falls under the GNU General Public License (GPL) or Library General Public License (LGPL) comes with slightly more strings attached, though at least on the side of enforced access rather than the usual opposite. Due to the additional complexities that can evolve in the commercial use of GPL software we do, however, prefer software submitted under the more relaxed BSD license when it is a reasonable option to do so.\nJordan Hubbard - FreeBSD Handbook\n Install FreeBSD BIOS Disable unused and unwanted options.\nInstall   To put the image on the pendrive we will use the dd tool available on almost any Mac OS X (macOS) and Linux system. For Windows You will have to download it from here – dd for windows( bs=1M on Linux/Windows ).（可用 Rufus 替代）\nsudo dd if=FreeBSD-11.1-RELEASE-amd64-memstick.img of=/dev/da1 bs=1m   When we have a new machine there is always a problem with new name for it. The RFC 1178 Choosing a Name for Your Computer from 1990 year tries to address that issue\n  We will use ZFS because we want to use Boot Environments with sysutils/beadm port.\n Hit [ENTER] on the Pool Type/Disks to select target disk to install FreeBSD on. Now (in FreeBSD 12.x) it is possible to install FreeBSD on GELI encrypted root on ZFS pool without any additional partitions or filesystems. You need to select is Yes for the Encryption part . I advice using GPT (BIOS+UEFI) as it will support both system types so when you are running BIOS system now and will move the disk to other system that boots with UEFI it will also just work out of the box. We will set SWAP size to 0 (no SWAP) as it will not be needed. If we will need SWAP in the future, then we will create ZVOL on ZFS and use it as a SWAP device.     Select services as shown below.   Enable all security hardening features as shown below.  X11 Window System X 最初設計是以網路為中心，採用 “client-server” 架構。在此架構下 “X 伺服器” 在有鍵盤、螢幕、滑鼠的電腦上運作。該伺服器負責的工作包含管理顯示、處理來自鍵盤、滑鼠的輸入及來自其他設備)的輸入或輸出。\n每個 X 應用程式，如 XTerm、Firefox 都是 “客戶端”。\n視窗管理程式規定螢幕上的視窗該長什麼樣、要如何移動滑鼠指標、 要用什麼鍵來在視窗切換、每個視窗的標題列長相，及是否該有關閉按鈕，等等。視窗管理程式負責滑鼠指標的聚焦政策。 聚焦政策指的是如何決定使用中及接收鍵盤輸入的視窗。通常較為人熟悉的聚焦政策叫做 “click-to-focus”，這個模式中，滑鼠點選到的視窗便會處於作用中 (Active) 的狀態。\nKDE 與 GNOME 會被稱作桌面環境是因為包含了完整常用桌面作業的應用程式。\nBIOS or UEFI If you find a device that is not supported by any ‘accelerated’driver like intel or nvidia. You would use vesa driver (Video Electronics Standards Association) while booting in BIOS mode and You will use scfb driver (System Console Frame Buffer) while booting on UEFI mode. This can be checked by\nsudo sysctl machdep.bootmethod Packages sudo pkg install xorg Xorg Configuration   顯示卡、顯示器以及輸入裝置會自動偵測，無須任何手動設置。除非自動設置失敗，否則請勿建立 xorg.conf 或執行 -configure 步驟。\n  加入要執行 Xorg 的使用者到 video 或 wheel 群組，以便在可用時能開啟 3D 加速。要加入使用者 jru 到任一個可用的群組：\nsudo pw groupmod video -m jru || pw groupmod wheel -m jru   Login Class(可解决中文乱码，powershell 字符显示方形)\nAdd this login class to the /etc/login.conf file.\nvideo:\\  :charset=UTF-8:\\  :lang=en_US.UTF-8:\\  :tc=default: Rebuild the login class database.\nsudo cap_mkdb /etc/login.conf Lets set the login class to video for the vuk user.\nsudo pw usermod -L video -n vuk How the account looks after setting the login class.\nsudo grep vuk /etc/master.passwd vuk:{REMOVED}:1000:1000:video:0:0:vuk:/home/vuk:/bin/sh Now logout and login again to make that work. View the changes through the locale command.\n  显卡驱动：使用多檔，每一個檔案只設定一個指定項目會較傳統使用單一 /etc/X11/xorg.conf 設定來的簡單。完整路徑為 /usr/local/etc/X11/xorg.conf.d/。（安装 intel 显卡驱动与 nvidia 驱动难，scfb 与 vesa 驱动无法调整分辨率）\nsudo vi /usr/local/etc/X11/xorg.conf.d/driver-intel.conf Section \u0026#34;Device\u0026#34; Identifier \u0026#34;Card0\u0026#34; Driver \u0026#34;scfb\u0026#34; BusID \u0026#34;PCI:0:2:0\u0026#34; EndSection 若有多張顯示卡，可取消註解 BusID identifier 然後設定為想要的顯示卡，顯示卡的 Bus ID 清單可以使用 pciconf -lv | grep -B3 display 取得。\n  手動設定\n  設定檔可由 Xorg 根據偵測到的硬體產生，這個檔案對一開始自訂設定很有幫助。\nXorg -configure   設定檔會儲存至 /root/xorg.conf.new，做任何需要的更改，然後使用以下指令測試該檔案：\nXorg -config /root/xorg.conf.new 在新設定檔調整與測試過後，便可分開成較小的檔案放置到正常的位置 /usr/local/etc/X11/xorg.conf.d/。\n    Install Desktop Enviroment   FreeBSD 桌面发行版\n GhostBSD 是 FreeBSD 桌面发行版，注意使用 Official 版本，不能直接使用 FreeBSD 源升级。 nomadbsd 是个非常漂亮的 FreeBSD 桌面发行版 ，德国产。 可以在虚拟机里面安装 FreeBSD 桌面发行版，然后找到自己想用的桌面工具，再定制自己的 FreeBSD 桌面。    Install Desktop Environment\nsudo pkg install gnome3 sudo pkg install gnome3-lite sudo pkg install x11/kde5 sudo pkg install xfce sudo pkg install mate   Install/Enable Display Manager: You have to decide how You want to start your X11 Window Server, you may login in plan text console and then type xinit or startx to read your ~/.xinitrc configuration and daemons (The difference between xinit and startx is that startx command executes xinit command with arguments.) or You may want to use X11 Login manager such as xdm/sddm/slim with ~/.xsession configuration to load after successful login.\nsudo pkg install xdm sudo pkg install slim\t# xfce,mate，slim 有个 slim-themes 软件包 sudo pkg install x11/sddm\t# kde While xinit run commands based on the ~/.xinitrc file the XDM login manager looks for the ~/.xsession file. As You will be loading same stuff regardless of the startup method we will create a link of ~/.xsession pointing to the ~/.xinitrc file. This way either method You choose You will always end with started X11 session.\nln -s ~/.xinitrc ~/.xsession One more case about the ~/.xinitrc (or ~/.xsession) file. It is interpreted as a shell script (and yes you can do if/then/else/fi and case/esac or for/while POSIX shell scripting in it) but it does not need to be executable. The last command in this file MUST NOT to be put in the background (must be without the \u0026amp; char at the end) because the X11 session will end.\n  Setting\nsudo vi /etc/ttys\t# xdm ttyv8 \u0026#34;/usr/local/bin/xdm -nodaemon\u0026#34; xterm on secure sudo vi /etc/fstab\t# gnome, kde proc /proc procfs rw 0 0 sudo vi /etc/rc.conf moused_enalbe=\u0026#34;YES\u0026#34; dbus_enable=\u0026#34;YES\u0026#34;\t# gnome, kde, xfce hald_enable=\u0026#34;YES\u0026#34;\t# gnome, kde, mate gdm_enalbe=\u0026#34;YES\u0026#34;\t# gnome 启动 sddm_enable=\u0026#34;YES\u0026#34;\t# kde 启动 slim_enable=\u0026#34;YES\u0026#34;\t# xfce,mate gnome_enable=\u0026#34;YES\u0026#34;\t# gnome 服务   slim Usage(Failed to execute login command)\nsudo vi ~/.xinitrc exec mate-session\t# mate exec xfce4-session\t# xfce   Components   Window Manager: Openbox\u0026hellip;\n  Status Bar: Also known as information bar, the place on the screen that would provide You needed information such as current date and time, CPU, RAM and storage usage, current network information or battery status.\n  While Xmobar is nice solution it comes with about 2 GB of dependencies of Haskell and Haskell libraries.\n  While Polybar can look very nice on screenshots it is a lot more heavy on resources and is limited only to modules/features that were implemented in it.\n  I have used Conky for quite long time but after recent tests I made Dzen2 is a lot less on resources then Conky while doing the same thing.\n    Task Bar: A taskbar is an element of a graphical user interface which has various purposes. It typically shows which programs are currently running.\n  You can use classic taskbar like XFCE Panel used in the XFCE desktop environment.\n  You can also configure Tint2 that way. But it only shows applications that are active on the current desktop.\n  One of the greatest taskbars of all time was/is the Mac OS X Dock (now macOS Dock). It also has an indicator showing if application is launched. Currently the best and lightest solution for providing the dock-like functionality on open desktops seems to be Plank.\n    Application Launcher: While not being any crucial role of the desktop environment it have its uses and sometimes save time.\nLets start with resources, the Rofi implementation of application launcher uses almost 3 times more RAM then Dmenu solution.\n  Desktop with Dmenu launched and with alc characters inserted to ‘filter’ commands in the search of a calculator application.\n  The Rofi requires simple command.\nrofi -show run -theme solarized_alternate -font \u0026#34;Monaco 8\u0026#34;     Blue Light Spectrum Suppress: Automatically adjusts color temperature of the screen according to your current time in your location.\n  While F.lux (closed source) does not provide a native binary for FreeBSD it does offer such binary for Linux and as FreeBSD provides Linux Binary Compatibility its possible to use it on FreeBSD. To use F.lux just start it in the ~/.xinitrc or ~/.xsession file like that.\n~/path/to/bin/xflux -l 33.54321 -g 11.12345 \u0026amp; Of course 33.54321 is latitude and 11.12345 is longitude of your localization.\n  Redshift is the solution that I propose to use as open source blue light spectrum suppressor. Similarly like with the F.lux to start Redshift just put it in the ~/.xinitrc or ~/.xsession file like that.\nredshift -l 33.54321:11.12345 -g 0.9 \u0026amp;   Someone else suggested trying sctd which is sct but rewritten/modified to be a daemon that will automatically change the color temperature during the day (or night). The sctd uses smaller about of RAM memory, uses less libraries and size of these libraries is smaller then what redshfit needs.\n    Binary 套件 搜寻软件：FreeBSD Ports、FreshPorts\n因編譯選項不同，有些 Port 會有多個版本可使用。\n  USTC Mirrors：注意使用 Latest 源，有很多流行软件。创建 /usr/local/etc/pkg/repos/FreeBSD.conf 覆盖官方源 /etc/pkg/FreeBSD.conf 配置\nsudo vi /usr/local/etc/pkg/repos/FreeBSD.conf FreeBSD: { url: \u0026#34;pkg+http://mirrors.ustc.edu.cn/freebsd-pkg/${ABI}/latest\u0026#34;, } sudo pkg update -f\t# 更新索引   163 Mirrors\n url: \u0026quot;pkg+http://mirrors.163.com/freebsd-pkg/${ABI}/latest\u0026quot;,   要啟動 (Bootstrap) 系統，請執行\nsudo /usr/sbin/pkg   當升級原使用舊版 pkg_* 工具的既有系統時，必須將資料庫轉換成新的格式\nsudo pkg2ng   Update the available remote repositories as listed in pkg.conf\nsudo pkg update   Search for a package\nsudo pkg search perl   在指定要安裝的套件時，最好使用 Port 來源來指定該應用程式，Port 來源是指應用程式在 Port 樹中的路徑\nsudo pkg search -o perl   Install a package: Installing must specify a unique origin or version otherwise it will try installing all matches\nsudo pkg install perl-5.14   列出已經安裝的 Port 中有那些已過時\nsudo pkg version -l \u0026#34;\u0026lt;\u0026#34;   Upgrade from remote repository\nsudo pkg upgrade   Delete an installed package\nsudo pkg delete perl-5.14   Remove unneeded dependencies\nsudo pkg autoremove   List installed packages\nsudo pkg info   Display information about installed packages\nsudo pkg info perl-5.14   Show the pkg-message of a package\nsudo pkg info -D perl-5.14   要查詢已安在系統上的軟體是否有任何已知的漏洞\nsudo pkg audit -F   因為相依所安裝的套件稱作自動 (Automatic) 套件，而非自動套件即套件被安裝的原因不是因為其他套件所相依\nsudo pkg prime-list\t# deprecated   Clean the local cache of fetched remote packages\nsudo pkg clean   Packages\nsudo pkg install linux-sublime3 sudo pkg install mysql180-server mysql180-client   Port 套件 優點：\n 可更改編譯選項 部份軟體的授權條款中禁止以 Binary 格式發佈。 這種軟體必須以原始碼發佈並由終端使用者編譯。 原始碼可套用自訂的修補。  Port 中並不含實際的原始碼，在編譯 Port 解壓縮時會自動下載的原始碼到 /usr/ports/distfiles。\n  USTC Mirrors：在 /etc/make.conf 中添加以下内容\nMASTER_SITE_OVERRIDE?=http://mirrors.ustc.edu.cn/freebsd-ports/distfiles/${DIST_SUBDIR}/   163 Mirrors\nMASTER_SITE_OVERRIDE?=http://mirrors.163.com/freebsd-ports/distfiles/${DIST_SUBDIR}/   安裝 Port 套件集：下載壓縮後的 Port 套件集快照 (Snapshot) 到 /var/db/portsnap\nsudo portsnap fetch   第一次執行 Portsnap 時，要先解壓縮快照到 /usr/ports\nsudo portsnap extract   執行以下指令來更新 /usr/ports\nsudo portsnap fetch sudo portsnap update   要找到 Port 所在的分類\nsudo whereis lsof   使用 Port 套件集內建的搜尋機制來找軟體\nsudo cd /usr/ports sudo make search name=lsof sudo make quicksearch name=lsof\t# 不接受多資訊   若要進行更有深度的搜尋\nsudo make search key=string sudo make quicksearch key=string   一次設定所有Port 編譯選項\nsudo make config-recursive   重新進入 Port 的編譯選項清單\nsudo make config\t# or sudo make showconfig\t# or sudo make rmconfig   編譯並安裝 Port\nsudo cd /usr/ports/sysutils/lsof sudo make install   編譯在 /usr/ports Port 並安裝到 /usr/home/example/local\nsudo make WRKDIRPREFIX=../ports PREFIX=../local install   安裝過程中會建立工作用的子目錄用來儲存編譯時暫存的檔案。可移除此目錄來節省磁碟空間並漸少往後升級新版 Port 時造成問題\nsudo make clean   移除已安裝的 Port\nsudo cd /usr/ports/sysutils/lsof sudo make deinstall   Example\ncd /usr/ports/java/linux-oracle-jdk18 sudo make install   安裝後的注意事項：\n 大部份應用程式安裝會在 /usr/local/etc 安裝至少一個預設的設定檔。 應用程式提供的文件會安裝到 /usr/local/share/doc。 部份應用程式會以服務的方式執行，在啟動應用程式前前需要加入設定到 /etc/rc.conf。這些應用程式通常會安裝啟動 Script 到 /usr/local/etc/rc.d。  Linux® Binary 相容性 FreeBSD 提供 Linux® Binary 的相容性，允許使用者在 FreeBSD 系統上不需要修改就可以安裝和執行大部份的 Linux® Binary。\n最好不要直接安装 Linux 的软件，而使用 FreeBSD 源中的 Linux 软件，一般以 linux-package 命名。\n  載入 Linux® 核心模組\nsudo kldload linux   對 64-位元的相容性\nsudo kldload linux64   確認模組已載入\nsudo kldstat   安裝基本的 Linux® 程式庫和 Binary\nsudo pkg install emulators/linux_base-c7   Add the following line\nsudo vi /etc/fstab linprocfs /compat/linux/proc\tlinprocfs\trw\t0\t0 linsysfs /compat/linux/sys\tlinsysfs\trw\t0\t0 tmpfs /compat/linux/dev/shm\ttmpfs\trw,mode=1777\t0\t0   開機時開啟 Linux® 相容性\nsudo vi /etc/rc.conf linux_enable=\u0026#34;YES\u0026#34;   安裝 Linux® ELF Binary\nsudo brandelf -t Linux my-linux-elf-binary   安裝以 Linux® RPM 為基礎的應用程式,需先安裝 archivers/rpm4 套件或 Port\nsudo pkg install rpm4 sudo cd /compat/linux sudo rpm2cpio \u0026lt; /path/to/linux.archive.rpm | cpio -id   手動安裝其他程式庫   在 Linux® 系統，可使用 ldd 來找出應用程式需要哪個共用程式庫\nldd linuxdoom libXt.so.3 (DLL Jump 3.1) =\u0026gt; /usr/X11/lib/libXt.so.3.1.0   複製 Linux® 系統輸出結果中最後一欄需要的的檔案到 FreeBSD 系統的 /compat/linux。 複製完後，建立符號連結 (Symbolic link) 至輸出結果第一欄的名稱\n/compat/linux/usr/X11/lib/libXt.so.3.1.0 /compat/linux/usr/X11/lib/libXt.so.3 -\u0026gt; libXt.so.3.1.0   自訂核心 為何要編譯自訂的核心? 自訂核心有許多項優點，如：\n 加速開機，因為自訂的核心只需要偵測您系統上存在的硬體，所以讓啟動所花的過程更流暢快速。 減少記憶體使用，自訂的核心通常會比 GENERIC 核心使用更少的記憶體，這很重要，因為核心必須一直存放在實體記憶體內。 支援額外的硬體，自訂的核心可以增加一些 GENERIC 核心沒有提供的硬體支援。  偵測系統硬體   dmesg or /var/run/dmesg.boot or /var/log/messages\n  pciconf -lv\n  在 man指令加上 -k 旗標可列出有包含指定裝置品牌或名稱的手冊頁面清單：man -k Intel\n  設定檔 /usr/src/sys 下子目錄代表著支援的硬體架構 (Architecture)，每個支援的硬體架構中會有 conf 子目錄，裡面含有供該架構使用的 GENERIC 核心設定檔。\n說明在GENERIC 同目錄的 NOTES 檔案中。所有架構通用選項，參考 /usr/src/sys/conf/NOTES。\n备份与恢复 dump \u0026amp; restore FreeBSD 系统的备份就是对系统文件的打包，然后放到一个安全的地方，使用的打包工具是 dump；FreeBSD 系统的恢复就是把你保存好的系统文件从安全的地方里面拿出来放到你的硬盘上去，使用的恢复工具是 restore；\n  需要备份的目录：\n / 这个目录存放很多基本工具，包括内核，需要备份； /home 用户数据，需要备份； /usr 很多工具以及系统的源代码都放在这里面，需要备份； /usr/local 所有安装的软件基本上都在这里，需要备份； /var 系统的日志，ports系统的数据库，需要备份；    备份方法：以 / 目录为例，把移动硬盘挂载在 /mnt/fender_01 目录，/ 目录对应硬盘上面的 /dev/ad12s1a 分区，备份整个目录的命令如下：\ndump -0Lauf /mnt/fender_01/dump/ad12sa1.dump /dev/ad12s1a  -0 备份所有的文件系统中的内容，也就是不使用增量备份； -f 指定备份结果存放的文件名； -a 告诉 dump 不考虑备份的介质的大小问题，早期备份使用磁带，dump 会预先计算一下需要的空间，使用这个选项告诉 dump 忽略这个问题； -u 告诉 dump 更新一下 /etc/dumpdates，这个文件记录了你在系统上搜有的备份活动； -L 备份已经挂载的文件系统时需要，这个选项会使用 UFS2 的 snapshot 功能来保证文件系统的一致性。    恢复方法\n  恢复 / 以外的目录：以恢复 /home 目录为例，重启系统进入单用户模式，挂载 /tmp 分区，挂载移动硬盘，这时备份生成的文件保存在 /mnt/01/dump/dev/ad12s1h.dump，格式化 /dev/ad12s1h：\nnewfs -U /dev/ad12s1h\t# -U 选型来打开 softupdate 挂载这个分区，例如 /mnt/02/，恢复目录：\ncd /mnt/02 restore -rf /mnt/01/dump/ad12s1h.dump   恢复 /：因为 restore 在 / 目录中，所以不能使用上面方法恢复 / 目录。解决办法是使用 freebsd_livefs_cd 启动系统。\n    备份 MBR\n  备份\ndd if=/dev/da0 of=/path/to/mbr.img bs=512 count=1   恢复\ndd if=/path/to/mbr.img of=/dev/da0 bs=512 count=1     参考：FreeBSD dump 备份\nrsync（remote sync） 可以在本地计算机与远程计算机之间，或者两个本地目录之间同步文件，且仅传输有变动的部分。\n  将源目录同步到目标目录\nrsync -r source1 source2 destination\t# -r 表示递归，即包含子目录 rsync -a source/ destination\t# -a 除了可以递归同步以外，还可以同步元信息（比如修改时间、权限等）   排除文件：同步时排除某些文件或目录，这时可以用 --exclude 参数指定排除模式，多个排除模式，可以用多个 --exclude 参数\nrsync -av --exclude dir source/ destination\t# 排除所有 TXT 文件   增量备份：除了源目录与目标目录直接比较，rsync 还支持使用基准目录，即将源目录与基准目录之间变动的部分，同步到目标目录。--link-dest 参数用来指定同步时的基准目录。\nrsync -a --delete --link-dest /compare/path /source/path /target/path   远程同步：rsync 默认使用 SSH 进行远程登录和数据传输\nrsync -av source/ username@remote_host:destination\t# 将本地内容同步到远程服务器 rsync -av username@remote_host:source/ destination\t# 将远程内容同步到本地   使用 rsync 来备份系统\nrsync -aH --delete --exclude dir --link-dest /compare/path source destination  -H 选项用来保持硬链接 默认情况下，rsync 只确保源目录的所有内容（明确排除的文件除外）都复制到目标目录。它不会使两个目录保持相同，并且不会删除文件。如果你想让那些在源目录里被删除的文件在目标目录里也被删除，那么你可以加上 --delete 选项来删除。--delete 参数会使得 destination 成为 source 的一个镜像。    参考：rsync 用法教程，使用 rsync 来备份 Linux 系统\nZ 檔案系統 (ZFS) ZFS 的設計目標主要有三個：\n 資料完整性：所有資料都會有一個資料的校驗碼 (checksum)，資料寫入時會計算校驗碼然後一併寫入，往後讀取資料時會再計算一次校驗碼，若校驗碼與當初寫入時不相符，便可偵測到資料錯誤，此時若有可用的資料備援 (Data redundancy)，ZFS 會嘗試自動修正錯誤。 儲存池：實體的儲存裝置都會先被加入到一個儲存池 (Pool)，這個共用的儲存池可用來配置儲存空間，儲存池的空間可被所有的檔案系統使用且透過加入新的儲存裝置來增加空間。 效能：提供多個快取機制來增加效能。先進、以記憶體為基礎的讀取快取可使用 ARC。第二層以磁碟為基礎的讀取快取可使用 L2ARC，以磁碟為基礎的同步寫入快取則可使用 ZIL。  Others Screen resolution on FreeBSD on VirtualBox 问题描述：在virtualbox虚拟机下，无法改变桌面分辨率为1366x768\nVBoxManage setextradata \u0026#34;FreeBSD\u0026#34; VBoxInternal2/EfiGraphicsResolution 1366x768 Disable the Forward/Back buttons on my mouse 问题描述：浏览网页时，鼠标滑轮滚动浏览器就会前进后退。\nSalved：\n  执行下面命令后，上下滑动鼠标滑轮，看看映射到那些button，一般是buttons 8 and 9\nsudo xev | grep -A2 ButtonPress   then disable button 8 and 9（前提是有上面的问题，否则就不要禁）\nsudo vi ~/.Xmodmap pointer = 1 2 3 4 5 6 7 0 0 0 0 0   test it with the command,command automatically when you log in; if yours doesn\u0026rsquo;t, arrange for it to run when X starts.\nsudo xmodmap ~/.Xmodmap   Install chinese font sudo pkg install zh-CJKUnifonts\t# CJK（中日韩统一表意文字） 设单使用模式为不安全 sudo vi /etc/ttys console none\tunknown off insecure No space left on device 问题描述：使用 pkg update 时提示这个问题。原因是 /tmp is too small。\nSalved:\nsudo vi /etc/fstab tmpfs\t/tmp\ttmpfs\trw,size=256000000\t0\t0\t# size 以Byte为单位 VirtualBox™ guest additions sudo cd /usr/ports/emulators/virtualbox-ose-additions \u0026amp;\u0026amp; make install clean sudo vi /etc/rc.conf vboxguest_enable=\u0026#34;YES\u0026#34; vboxservice_enable=\u0026#34;YES\u0026#34; vboxservice_flags=\u0026#34;--disable-timesync\u0026#34;\t# 若有使用 ntpd或 ntpdate，便可關閉主機時間同步功能 Fish Fish 是\u0026quot;the friendly interactive shell\u0026quot;的简称，最大特点就是方便易用。\nFish 会自动在光标后面给出建议，表示可能的选项，颜色为灰色。如果采纳建议，可以按下→或Control + F。如果只采纳一部分，可以按下Alt + →。\n输入命令时，Fish 会自动显示匹配的上一条历史记录。如果没有匹配的历史记录，Fish 会猜测可能的结果，自动补全各种输入。\nHow to start things at boot time   主流的桌面环境都自带应用程序自启动设置程序。\n  These directories are defined in /etc/defaults/rc.conf（主要是运行脚本）\n  Default startup directory is /usr/local/etc/rc.d/. if you need the files to be executed in a specific order, try numbering the files. For example:\n000This.Will.Run.First.sh 020This.Will.Run.Next.sh 030And.Then.This.sh   deprecated: /etc/rc.local\n    DSBAutostart is a Qt program that allows you to add commands to be executed at session start.\n（本质就是在 .xinitrc 调用程序指令，GUI 程序开机启动都需放入 .xinitrc，在 Xorg 启动后运行）\n  Installation\ncd /usr/ports/x11/dsbautostart \u0026amp;\u0026amp; make install distclean   Usage\n  Manual\n  Setup: Add the following command to your ~/.xinitrc, or to your window manager\u0026rsquo;s startup script (e.g. ~/.config/openbox/autostart.sh)\nsh ~/.config/DSB/autostart.sh\u0026amp;   ~/.config/DSB/autostart.sh\nPlank\u0026amp;     GUI: Setting -\u0026gt; DSBAutostart -\u0026gt; Add Command, example plank, then Save and Quit\n      FreeBSD Insall Oracle JDK  安装 Linux Compact 在 /usr/ports/java/linux-oracle-jdk18 运行 sudo make install 根据提示在 Oracle Java Archive 下载需要的 JDK 版本安装包，复制到 /usr/ports/distfiles 在 /usr/ports/java/linux-oracle-jdk18 运行 sudo make install，安装成功  FreeBSD Install Python and pip sudo pkg install python python --version Python 3.7.9 sudo pkg install py37-pip 简化启动 FreeBSD 默认启动过程相当详细，包含大量调试信息以及内核消息。\n Add the boot_mute=YES option to the /boot/loader.conf file. Add autoboot_delay=2 parameter to the /boot/loader.conf file. Add rc_startmsgs=\u0026quot;NO\u0026quot; to your /etc/rc.conf file.  连接网络 If You will have attached LAN cable and your interface is em0 (check ifconfig command output) then dhclient em0 command should grant You the working connection to the Internet – assuming that You have DHCP server on that network.\nifconfig em0 up dhclient em0 To test the network connectivity use the ping command.\nping -c 3 freebsd.org If You would like to connect to the World with wireless connection then here are the needed commands. First lets check what wireless card You have.\nsysctl net.wlan.devices We will now create wlan virtual device on top of our iwn0 device and bring it up.\nifconfig wlan0 create wlandev iwn0 ifconfig wlan0 up We can scan for existing nearby WiFi access points if needed.\nifconfig wlan0 scan Now we need to add the desired WiFi network to the /etc/wpa_supplicant.conf file as shown below.\nnetwork={ ssid=\u0026quot;WIFI-NETWORK-NAME\u0026quot; psk=\u0026quot;PASSWORD\u0026quot; } Then You may connect to it using the wpa_supplicant daemon. Hit the [CTRL]+[Z] key combination to put the process into suspended state. Then we type the bg command to put it back into running state, but in the background so we can continue to type next commands.\nwpa_supplicant -i wlan0 -c /etc/wpa_supplicant.conf Now we will request for the IP address from the access point DHCP server.\ndhclient wlan0 How To Add and Remove Users on FreeBSD   Add a User: adduser\n  Grant Sudo Privileges: On FreeBSD, users that are members of the wheel group are allowed to use sudo. This is due to the following line in the default sudoers file, /usr/local/etc/sudoers\n%wheel ALL=(ALL) NOPASSWD: ALL   Remove a User: rmuser\n  Lock a User Account: pw lock username\n  Unlock a User: pw unlock username\n  其他 NetBSD: huaweicloud、aliyun、tsinghua\nOpenBSD: huaweicloud、aliyun、tsinghua\n一篇好文：FreeBSD的现状和未来\nFreeBSD Desktop\nFreeBSD 使用手冊\n","permalink":"https://sakamotokurome.github.io/posts/freebsd/","summary":"The goals of the FreeBSD Project are to provide software that may be used for any purpose and without strings attached. Many of us have a significant investment in the code (and project) and would certainly not mind a little financial compensation now and then, but we are definitely not prepared to insist on it. We believe that our first and foremost \u0026ldquo;mission\u0026rdquo; is to provide code to any and","title":"FreeBSD"},{"content":"Just a little conversation\nAbout give me your picture\nOn the cover of a magazine\nOn the cover of a magazine\nJust a little conversation\nBut how long it might take one?\nTo get along with such thing?\nTo get along with such thing?\nBut everybody knows\nIt\u0026rsquo;s easier to fall apart\nJust a little conversation\nAbout give me your picture\nOn the cover of a magazine\nOn the cover of a magazine\n  ","permalink":"https://sakamotokurome.github.io/posts/conversation/","summary":"Just a little conversation\nAbout give me your picture\nOn the cover of a magazine\nOn the cover of a magazine\nJust a little conversation\nBut how long it might take one?\nTo get along with such thing?\nTo get along with such thing?\nBut everybody knows\nIt\u0026rsquo;s easier to fall apart\nJust a little conversation\nAbout give me your picture\nOn the cover of a magazine\nOn the cover of a magazine","title":"Conversation"},{"content":"","permalink":"https://sakamotokurome.github.io/links/","summary":"","title":""}]