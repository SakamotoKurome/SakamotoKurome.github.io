[{"content":" Installation guide Arch Linux 安装使用教程 Archlinux 简明指南 给 GNU/Linux 萌新的 Arch Linux 安装指南  了解 Archlinux 为什么使用 Linux？ 简单来说，现在世界上流行的 PC 操作系统有三个，Windows，Linux 与 macOS。\n如果你是计算机相关专业的学生或者从业者，非常建议你使用 Linux 作为自己的日常系统。在使用 Linux 系统的过程中，可以无形中接触到各个方面的计算机知识，并且在未来的工作中也会为你带来相关方面的优势。 macOS 在一些方面（即大致为 BSD 与 GNU/Linux 各方面的区别 )与 Linux 的操作并不同，并且由于其封闭的特性，我们不建议使用。Windows 在很多编程环境的配制过程中异常痛苦，且会出现各种各样的问题，强烈不建议使用 Windows 进行编程(除非你学的就是 Windows 系统编程)。\n更重要的是，GNU/Linux 是自由软件运动的相关重要产物。自由软件运动(free software movement)拒绝专有软件并推广自由软件,它的终极目标在于解放网络世界中的每个人——即每个电脑用户。每个人都应拥有完全掌控所运行软件的权利。自由软件有如下四项原则：\n 自由度 0：无论用户出于何种目的，必须可以按照用户意愿，自由地运行该软件。 自由度 1：用户可以自由地学习并修改该软件，以此来帮助用户完成用户自己的计算。作为前提，用户必须可以访问到该软件的源代码。 自由度 2：用户可以自由地分发该软件的拷贝，这样就可以助人。 自由度 3：用户可以自由地分发该软件修改后的拷贝。借此，用户可以把改进后的软件分享给整个社区令他人也从中受益。作为前提，用户必须可以访问到该软件的源代码。  如果你只是一个普通用户，你一定见识过没有经过你的授权，电脑被装上了成堆的流氓软件的类似经历。专有软件不仅在各个维度强奸着用户，更包含着难以想象的恶意功能。用户的数据，隐私等重要信息会轻而易举被大公司们收集走，并加以滥用，这成为业内公开的秘密已是不争的事实。在专用软件有同类的自由软件替代时，强烈建议你迁移至自由软件。本书会同时记录专有软件与自由软件，因为如果完全摒弃专有软件，一定会直接将很多人阻挡在 linux 之外，这不是我们所希望的，我们希望先将更多人接纳到 GNU/Linux 中，至少这是踏出的第一步。但这并不代表我们支持使用专有软件，我们希望你至少可以先踏入 linux，逐渐使用自由软件替代专有软件。专有软件在本书中仅作简要记录，不会详细描述，因为我们不希望你长期依赖于它。只要某个专有软件有足够优秀的自由软件替代品出现，我们就会移除本教程中的那个专有软件。专有软件在本书中会被角标专有或描述额外标记。如果你是有能力的开发者，更希望你可以开发出替代某些专有软件的自由软件。\n最后，如果你想尝试完全免费的系统，或是喜欢探索充满新鲜与挑战的事物，Linux 也是你不可错过的体验。\n为什么使用 Arch Linux？  Archlinux 的许多特点如同双刃剑，既是优点，也是缺点\n 简洁 Archlinux 将简洁定义为：避免任何不必要的添加、修改和复杂增加。简单来说，Archlinux 是一个可以让用户自己动手打造的操作系统。从安装到管理，Archlinux 放手让用户处理一切。\n用户可以自己决定使用哪种桌面环境、安装哪些组件和服务。这种精细化的控制能够赋予你一个精简的操作系统，可以让用户自由选择所需的组件来构建属于用户自己的系统。\n但也正因为此配置 Archlinux 相对于其它 Linux 发行版来说是繁琐。但繁琐是自由的代价。如果你是一个 DIY 爱好者，那么相信你会爱上 Archlinux 的 ❤️。\n滚动更新（现代） 滚动更新（rolling update）是指软件开发中经常性将更新发送到软件的概念。相较于滚动发行，有标准版本和小数点版本的版本号开发模式，必需通过重新安装以取代先前的发行版。Archlinux 是没有版本概念的，它始终保持最新的状态，通俗的理解就相当于把发行版比喻为一部车，ubuntu 更新就是换一部新的，而 Archlinux 就是把车里面旧的配件换成新的。\nArchlinux 是一个滚动发行版，这意味着：\n 新的内核和应用程序版本一经发布，就会立即向用户推送 当大多数其它 Linux 发行版还在提供旧的 Linux 内核版本时，Archlinux 会迅速向用户提供最新的内核 而软件也是如此。如果 Archlinux 仓库中的软件发布了新版本，Archlinux 用户通常会比其他用户先获得新版本 在滚动发行模式下，一切都是新鲜和前沿的。用户不必把操作系统从一个版本升级到另一个版本，只要使用 pacman 的升级命令，便会始终保持最新的版本  实用 Archlinux 注重实用性，避免意识形态之争。最终的设计决策都是由开发者的共识决定。开发者依赖基于事实的技术分析和讨论，避免政治因素，不会被流行观点左右。\nArchlinux 的仓库中包含大量的软件包和编译脚本。用户可以按照需要自由选择。仓库中既提供了开源、自由的软件，也提供了闭源软件（大部分闭源软件在 AUR 仓库中）。实用性大于意识形态。\n以用户为中心 许多 Linux 发行版都试图变得更“用户友好”，Archlinux 则一直是且永远会是“以用户为中心”。Archlinux 是为了满足贡献者的需求，而不是为了吸引尽可能多的用户。Archlinux 适用于乐于自己动手的用户，他们愿意花时间阅读文档，解决自己的问题。\nArchlinux 鼓励每一个用户 参与 和贡献，报告和帮助修复 bugs，提供软件包补丁和参加核心 项目 —— Archlinux 开发者都是志愿者，通过持续的贡献成为团队的一员。\nArchers 可以自行贡献软件包到 Arch 用户仓库（AUR）；提升 archWiki 文档质量；在 论坛、邮件列表、IRC 中给其他用户提供技术支持. Archlinux 是全球很多用户的选择，已经有很多 国际社区 提供帮助和文档翻译。\n同样的，若希望为本指南做出贡献，以帮助更多的人，请参阅 贡献指南。\nArch 用户仓库（AUR） AUR 即 Arch 用户仓库（Arch User Repository）。它包含名为 PKGBUILD 的包描述，它可让用户使用 makepkg 从源代码编译软件包，然后通过 pacman 安装。\n创建 AUR 的目的是组织和共享社区中的新软件包，并帮助加速将流行的软件包纳入社区仓库。进入官方仓库的大量新软件包都从 AUR 开始。在 AUR 中，用户可以贡献自己的软件包构建（PKGBUILD 和相关文件）。AUR 社区可以对 AUR 中的软件包进行投票。如果一个软件包变得足够流行（且具有兼容的许可证和良好的打包技术），那么可以将其加入 pacman 直接访问的社区仓库中。\n激进的内核更新机制 Archlinux 在更新内核的时候会立即删除旧内核（因为内核也是一个软件包 linux / linux-zen\u0026hellip;，由 pacman 更新）\n立即删除旧的内核要求 Archlinux 必须重启来加载新的内核，否则容易发生诡异的问题。这是因为 Linux 所谓的“内核”包含有大量的动态加载模块，如果在某次启动后，某个模块没有被加载过，然后系统内核更新了并且删除了旧的内核，那么这些模块将永远不能被加载了——因为它们随着旧内核被删掉了。除非用户重启系统以完整切换到新的内核以使用新版的动态加载模块。\n笔者曾经就因为在升级内核后插上声卡无法工作而感到困惑，后来才意识到问题所在。所以建议在更新内核后重新启动系统以避免问题的产生。（win10 更新也要重启，对吧？）\n软件包管理体系 不同于 Debian 系列的 apt / dpkg 和 Red Hat 系列的 dnf（yum）/ rpm 包管理体系，Archlinux 只用了一个工具 pacman 就解决了获取和安装两个功能。这降低了为 Archlinux 制作软件包的门槛，这也是 AUR 几乎能涵盖整个 Linux 软件生态的主要原因。但是这也导致 pacman 不支持虚包（virtual package），虚包是一个通用名称，适用于一组提供类似的基本功能的包中的任何一个包。\n由社区创建、支持和拥有 Ubuntu 由 Canonical 支持，Fedora 来自 Red Hat（现在是 IBM 的一部分），openSUSE 来自 SUSE。这些主流发行版都是企业支持的。\n这本身并不是坏事或过错，但是有一些人不喜欢企业参与开源项目。\n正如 Debian 一样，Archlinux 是为数不多的仅由社区创建、支持和拥有的的 Linux 发行项目之一。\n安装前的准备 Arch Linux 能运行在最少 512 MiB 内存的 x86_64 机器上，但从安装媒介启动系统并成功安装需要更多的内存。[1] 基本安装将占用小于 2 GiB 的存储空间。由于安装过程中需要从远程存储库获取软件包，计算机将需要一个有效的互联网连接。\n由于当前 UEFI 已普及十余年，安装将全部以 UEFI+GPT 的形式进行，传统 BIOS 方式不再赘述。\n确保网络环境 如果你可以使用路由器分接出来的网线，以 dhcp 的方式直接上网，那么不用准备什么。如果你的环境只能使用无线网络安装，需要事先把自己所用的 wifi 名称改成自己能记住的英文名称。因为安装时无法显示和输入中文名的 wifi，你会看到一堆不知道是什么的方块，并且在安装过程中你将没有办法输入中文的无线名称进行连接。虽然通过一些繁琐的步骤可以解决终端中文的问题，但是显然这么做在安装 Arch Linux 时毫无必要。\n其次，有些笔记本电脑上存在无线网卡的硬件开关或者键盘控制，开机后安装前需要确保你的无线网卡硬件开关处于打开状态。\n刻录启动优盘 准备一个 2G 以上的优盘，刻录一个安装启动盘。安装镜像 iso 在下载页面下载，你需要选择通过磁力链接或 torrent 下载，下载完成后，还需要在 Archlinux 下载页面下载PGP signature签名文件(不要从镜像源下载签名文件)，将签名文件和 iso 镜像置于同一文件夹，随后进行对镜像的签名校验，以保证下载的镜像是完整，无错误的，未被篡改的。在一台已经安装 GnuPG 的系统上，执行以下命令，确保输出完好的签名。具体镜像名根据名字自行修改。\n$ gpg --keyserver-options auto-key-retrieve --verify Archlinux-202x.0x.01-x86_64.iso.sig 注意，这里的签名校验非常重要，这可以保证你的安装镜像是未被篡改的，同时可以保证你在使用安装盘安装系统时，用正确的公钥校验安装包。\n另外，在一台已经安装 Arch Linux 的计算机上可以通过以下方式验证：\n$ pacman-key -v Archlinux-version-x86_64.iso.sig  Windows 下推荐使用ventoy或者Rufus或者etcher进行优盘刻录。三者皆为自由软件。具体操作请自行查阅，都非常简单。\nLinux 下可以直接用 dd 命令进行刻录。注意 of 的参数为 sdx,不是 sdx1 sdx2 等。\n$ sudo dd bs=4M if=/path/to/Archlinux.iso of=/dev/sdx status=progress oflag=sync  bs=4M 指定一个较为合理的文件输入输出块大小。 status=progress 用来输出刻录过程总的信息。 oflag=sync 用来控制写入数据时的行为特征。确保命令结束时数据及元数据真正写入磁盘，而不是刚写入缓存就返回。\n 进入主板 BIOS 进行设置 插入优盘并开机。在开机的时候，按下 F2/F8/F10/DEL 等(取决与你的主板型号，具体请查阅你主板的相关信息)按键，进入主板的 BIOS 设置界面。\n关闭主板设置中的 Secure Boot Arch Linux 安装镜像不支持安全启动（Secure Boot）。要引导安装媒介，需要禁用安全启动。在类似名为 security 的选项卡中，找到一项名为 Secure Boot(名称可能略有差异)的选项，选择 Disable 将其禁用。如果需要，可在完成安装后重新配置 安全启动。\n 具体怎么关因为每种电脑的方法不一样于是汝要自己 STFW (Search the f**king Web，搜索一下) 了\n 调整启动方式为 UEFI 在某些旧的主板里，需要调整启动模式为 UEFI,而非传统的 BIOS/CSM。在类似名为 boot 的选项卡中，找到类似名为 Boot Mode 的选项，确保将其调整为 UEFI only，而非 legacy/CSM。\n调整硬盘启动顺序 在类似名为 boot 的选项卡中，找到类似名为 Boot Options(名称可能略有差异)的设置选项，将 USB 优盘的启动顺序调至首位。\n准备安装 最后保存 BIOS 设置并退出，一般的按键是 F10。此时系统重启，不出意外你应该已经进入 Archlinux 的安装界面。\n基础安装 本节从安装最基础的无图形化 Archlinux 系统开始。官方安装指南\n如果想一边安装，一边使用 Lynx 查看本指南，可以使用 Alt+箭头 快捷键切换不同的控制台。\n键盘布局 控制台键盘布局默认为 us（美式键盘映射）。列出所有可用的键盘布局，可以使用：\n# ls /usr/share/kbd/keymaps/**/*.map.gz 如果您想要更改键盘布局，可以将一致的文件名添加进 loadkeys(1)，但请省略路径和扩展名。比如，要添加 德语 键盘布局：\n# loadkeys de-latin1 禁用 reflector 2020 年，Archlinux 安装镜像中加入了 reflector 服务，它会自己更新 mirrorlist（软件包管理器 pacman 的软件源）。在特定情况下，它会误删某些有用的源信息。这里进入安装环境后的第一件事就是将其禁用。也许它是一个好用的工具，但是很明显，因为地理上造成的特殊网络环境，这项服务并不适合启用。\n# systemctl stop reflector.service 再次确保是否为 UEFI 模式 在一系列的信息刷屏后，可以看到已经以 root 登陆安装系统了，请用下列命令列出 efivars 目录：\n# ls /sys/firmware/efi/efivars 如果命令结果显示了目录且没有报告错误，则系统以 UEFI 模式引导。 如果目录不存在，则系统可能以 BIOS 模式 (或 CSM 模式) 引导。\n连接网络 一般来说，你连接的网络几乎均可以通过 DHCP 的方式来进行 IP 地址和 DNS 的相关设置，你无需进行额外操作。在没有合适网络的情况下，使用手机的移动热点也是很方便的选择。如果你的网络环境需要配置静态 IP 和 DNS,请自行参考 Arch Wiki。\n对于有线连接来说，直接插入网线即可。\n对于无线连接，则需进行如下操作进行网络连接。\n无线连接使用 iwctl 命令进行，按照如下步骤进行网络连接：\niwctl #执行iwctl命令，进入交互式命令行 device list #列出设备名，比如无线网卡看到叫 wlan0 station wlan0 scan #扫描网络 station wlan0 get-networks #列出网络 比如想连接YOUR-WIRELESS-NAME这个无线 station wlan0 connect YOUR-WIRELESS-NAME #进行连接 输入密码即可 exit #成功后exit退出 可以等待几秒等网络建立链接后再进行下面测试网络的操作。\nping www.gnu.org  如果你不能正常连接网络，首先确认系统已经启用网络接口[1]。\nip link #列出网络接口信息，如不能联网的设备叫wlan0 ip link set wlan0 up #比如无线网卡看到叫 wlan0 如果随后看到类似Operation not possible due to RF-kill的报错，继续尝试rfkill命令来解锁无线网卡。\nrfkill unblock wifi  如果汝明明有无线网卡却没识别的话，有可能汝是某无线网卡厂商受害者😂😂。这时可以：\n 有 Android 手机的话，手机连 WiFi ，然后用“USB 网络共享”共享给电脑。 找个 USB 无线网卡插上 😂 连有线   移动宽带调制解调器（移动网卡） - 使用 mmcli 实用程序连接到移动网络。\n 另外，如果汝连接的网络需要网页登录（Captive Portal）,可以用 elinks 碰碰运气 😂\n# elinks http://\u0026lt;your_captive_portal_url\u0026gt;  用汝的门户的 URL 替换 \u0026lt;your_captive_portal_url\u0026gt; 如果不知道的话，随便访问一个 HTTP 网站试试，应该就会被重定向到 Portal 了  更新系统时间 使用 timedatectl(1) 确保系统时间是准确的：用 timedatectl set-ntp true 保证时间同步 。\ntimedatectl set-ntp true #将系统时间与网络时间进行同步 timedatectl status #检查服务状态 因为有不少操作需要准确的时间呐，例如 HTTPS 和 GnuPG 都需要准确的时间来验证证书的有效性。\n但是如果因为各种原因没法同步的话，那就只好手动设置咯~\n# timectl set-time \u0026#34;yyyy-MM-dd hh:mm:ss\u0026#34; # timectl set-time \u0026#34;2016-10-28 17:39:42\u0026#34; 分区 系统如果识别到磁盘，就会将其分配为一个块设备，如 /dev/sda、/dev/nvme0n1 或 /dev/mmcblk0。可以使用 lsblk 或者 fdisk -l 查看。结果中以 rom、loop 或者 airoot 结尾的设备可以被忽略。\n对于一个选定的设备，以下分区是必须要有的：\n 一个根分区（挂载在 根目录）/； 要在 UEFI 模式中启动，还需要一个 EFI 系统分区。  如果需要创建多级存储例如 LVM、disk encryption 或 RAID，请在此时完成。\n使用 Ext4 这里总共设置三个分区，是一个我们认为较为通用的方案。此步骤会清除磁盘中全部内容，请事先确认。\n EFI 分区[2]： /boot/efi 至少 300 MiB Linux swap (交换空间)： 大于 512 MiB Linux x86-64 根目录 ： / 剩余空间   这里根目录的大小仅为参考，一般来说个人日常使用的 linux 分配 100G 已经够用了。根目录最小建议不小于 50G，根目录过小会造成无法更新系统软件包等问题。\n 首先将磁盘转换为 gpt 类型，这里假设比如你想安装的磁盘名称为 sdx。如果你使用 NVME 的固态硬盘，你看到的磁盘名称可能为 nvme0n1。\nlsblk #显示分区情况 找到你想安装的磁盘名称 parted /dev/sda #执行parted，进入交互式命令行，进行磁盘类型变更 (parted)mktable #输入mktable New disk label type? gpt #输入gpt 将磁盘类型转换为gpt 如磁盘有数据会警告，输入yes即可 quit #最后quit退出parted命令行交互 接下来使用 cfdisk 命令对磁盘分区。进入 cfdisk 后的操作很直观，用键盘即可操作分配各个分区的大小与格式。一般建议将 EFI 分区设置为磁盘的第一个分区，据说有些主板如果不将 EFI 设置为第一个分区，可能有不兼容的问题。其中 EFI 分区选择EFI System类型，其余两个分区选择Linux filesystem类型。\ncfdisk /dev/sda #来执行分区操作,分配各个分区大小，类型 fdisk -l #分区结束后， 复查磁盘情况 格式化\n建立好分区后，需要对分区用合适的文件系统进行格式化。这里用mkfs.ext4命令格式化根分区与 home 分区，用mkfs.vfat命令格式化 EFI 分区。如下命令中的 sdax 中，x 代表分区的序号。格式化命令要与上一步分区中生成的分区名字对应才可以。\n磁盘若事先有数据，会提示你: \u0026lsquo;proceed any way?\u0026rsquo; 按 y 回车继续即可。\nmkfs.ext4 -L ROOT /dev/sda3 #格式化根目录和home目录的两个分区 mkfs.fat -F 32 -n EFI /dev/sda1 #格式化 EFI 分区 如果创建了 交换分区，请使用 mkswap(8) 将其初始化：\nmkswap -L SWAP /dev/sda2 #交换空间分区 挂载\n首先还是用 lsblk 确定一下分区的名称，为了以防万一记得加上 -f 参数\n# lsblk -f 在挂载时，挂载是有顺序的，先挂载根分区，再挂载 EFI 分区。 这里的 sdax 只是例子，具体根据你的实际情况来。\n$ mkdir -p /mnt/arch $ mount /dev/sda3 /mnt/arch $ mkdir -p /mnt/arch/boot/efi $ mount /dev/sda1 /mnt/arch/boot/efi 如果创建了 swap 交换空间卷，请使用 swapon(8) 启用它：\nswapon /dev/sda2 #交换空间分区 使用 Btrfs 纵观 Btrfs 的历史，可以说 Btrfs 未来的发展是道阻且长的。也让我们感受到开源社区也并不是一根绳上的蚂蚱 —— 开源社区之间也有着各种各样的分歧。\n但不管怎么说，Btrfs 的未来现在来看是光明的；我们也可以在 archlinux 上享受到 Btrfs 文件系统的特性带来的好处：\n 快照 —— archlinux 作为滚动发行版，若滚挂了可以使用 Btrfs 的快照特性快速回滚  若使用传统的 ext4 文件系统，我们可以使用 timeshift 的 RSYNC 模式进行增量备份。但是，一般来说 RSYNC 方式的快照大小略大于当前实际使用大小，也就是说实际上开启了 timeshift 的 RSYNC 模式快照相当于磁盘可用空间直接少了一半多。因为虽然 RSYNC 方式的快照是增量的，但历史最久远的快照依然是完整备份，随后才是增量的   透明压缩 —— 可以大大减少磁盘的使用空间（压缩率大概在 10% 左右）  首先我们需要将整一个分区格式化为 Btrfs 文件系统。使用如下命令进行格式化：\n# mkfs.btrfs -L myArch /dev/sda3 -L 选项后指定该分区的 LABLE，这里以 myArch 为例，也可以自定义，但不能使用特殊字符以及空格，且最好有意义\n为了创建子卷，我们需要先将 Btrfs 分区挂载到 /mnt 下\n# mount -t btrfs -o compress=zstd /dev/sda3 /mnt/arch  -t 选项后指定挂载分区文件系统类型 -o选项后添加挂载参数：  compress=zstd —— 开启透明压缩    通过以下命令创建两个 Btrfs 子卷，之后将分别挂载到 / 根目录和 /home 用户主目录：\nbtrfs subvolume create /mnt/arch/@ #创建 / 目录子卷 btrfs subvolume create /mnt/arch/@home #创建 /home 目录子卷 通过以下命令复查子卷情况：\n# btrfs subvolume list -p /mnt/arch 子卷创建好后，我们需要将 /mnt 卸载掉，以挂载子卷：\n# umount /mnt/arch 在挂载时，挂载是有顺序的，需要从根目录开始挂载。使用如下命令挂载子卷：\n# mount -t btrfs -o subvol=/@,compress=zstd /dev/sda3 /mnt/arch # mkdir /mnt/arch/home # mount -t btrfs -o subvol=/@home,compress=zstd /dev/sda3 /mnt/arch/home # mkdir -p /mnt/arch/boot/efi # mount /dev/sda1 /mnt/arch/boot/efi # swapon /dev/sda2 镜像源的选择 文件 /etc/pacman.d/mirrorlist 定义了软件包会从哪个镜像源下载。使用如下命令编辑镜像列表：\n# mv /etc/pacman.d/mirrorlist /etc/pacman.d/mirrorlist.bak # cat \u0026gt; /etc/pacman.d/mirrorlist 在列表中越前的镜像在下载软件包时有越高的优先权。添加北外、中科大或者清华的放在最上面即可。\nServer = https://mirrors.bfsu.edu.cn/archlinux/$repo/os/$arch Server = https://mirrors.tuna.tsinghua.edu.cn/archlinux/$repo/os/$arch Server = https://mirrors.ustc.edu.cn/archlinux/$repo/os/$arch 如果其速度不佳，可以手动指定其他镜像源。完整的镜像源列表可参考官方镜像源生成器。\n然后用 pacman -Syy 刷新一下软件包数据库。\n# pacman -Syy 安装系统 必须的基础包\n# pacstrap /mnt/arch base base-devel linux linux-headers linux-firmware  base 元包：包含基本系统所需的依赖，如果汝在别的地方见到说 base 是个软件包组的说法，忘了它吧…… 要通过 AUR 或者 ABS 编译安装软件包,还需要安装 base-devel 啦 （现在它还是个软件包组）。 然后大多数情况下，汝还需要一个内核。目前官方仓库里有这些  linux : 当前的稳定版本内核 linux-lts : 当前的长期支持版本内核 linux-hardened : 来自 https://github.com/anthraxx/linux-hardened 的安全强化内核 linux-zen : 来自 https://github.com/zen-kernel 的预载一定量优化的内核， 有人觉得在心理上会觉得跑得比 linux 快\u0026hellip;\u0026hellip;.   对于大多数情况下，汝可能会考虑安装固件包 linux-firmware 。  必须的功能性软件\n# pacstrap /mnt/arch dhcpcd iwd vim e2fsprogs dosfstools bash-completion man-db   dhcpcd 不论有限还是无限网络都需要\n  要通过刚刚用过的 iwctl 连接无线网络的话，记得安装 iwd 。\n  一个文字编辑器，例如刚才用到的 nano 或 vim 。建立自己的 .vimrc\n$ cp /usr/share/vim/vim82/defaults.vim .vimrc   一些文件系统工具，例如 操作 ext4 的 e2fsprogs，操作 FAT/FAT32 的 dosfstools， 需要读写其它文件系统的话，可以在 https://wiki.Archlinux.org/index.php/File_system 找到相应的用户空间工具。\n  访问 man 和 info 页面中文档的工具：man-db，man-pages 和 texinfo。\n  诶，base 组不包含 live 环境中所有的软件包么？是的， https://projects.Archlinux.org/archiso.git/tree/configs/releng/packages.x86_64 列出了在 ISO 中的 live 环境中安装的但不在 base 包中的软件包。\n 可选，安装 openssh\n# pacstrap /mnt/arch openssh # cat \u0026gt;\u0026gt; /mnt/arch/etc/ssh/sshd_config PermitRootLogin yes PasswordAuthentication yes 生成 fstab 文件 fstab 用来定义磁盘分区\n  use UUID\n# genfstab -U /mnt/arch \u0026gt; /mnt/arch/etc/fstab   use Label\n# genfstab -L /mnt/arch \u0026gt; /mnt/arch/etc/fstab   复查一下 /mnt/etc/fstab 确保没有错误\n# cat /mnt/arch/etc/fstab change root 把环境切换到新系统的/mnt 下\n# arch-chroot /mnt/arch 时区设置 设置时区，在/etc/localtime 下用/usr 中合适的时区创建符号连接。如下设置上海时区。\n# ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 随后进行硬件时间设置，将当前的正确 UTC 时间写入硬件时间。\n# hwclock --systohc 这个命令假定已设置硬件时间为 UTC 时间，并调整时间漂移:。详细信息请查看 System time#Time standard。\n如果汝正在尝试安装双系统，在进入 Windows 以后可能会发现 Windows 的时间不对了 ，因为 Windows 默认的硬件时钟是 localtime（\n可以用一条注册表键值让 Windows 使用 UTC 作为硬件时钟（在早于 Windows 7 的系统上发现过这样做会出现一些严重的问题： http://www.cl.cam.ac.uk/~mgk25/mswish/ut-rtc.html ）\nreg add \u0026#34;HKEY_LOCAL_MACHINESystemCurrentControlSetControlTimeZoneInformation\u0026#34; /v RealTimeIsUniversal /d 1 /t REG_DWORD /f 设置 Locale 进行本地化 Locale 决定了地域、货币、时区日期的格式、字符排列方式和其他本地化标准。\n编辑 /etc/locale.gen，在最后添加：\n# cat \u0026gt;\u0026gt; /etc/locale.gen en_US.UTF-8 UTF-8 zh_CN.UTF-8 UTF-8 然后使用如下命令生成 locale。\n# locale-gen 向 /etc/locale.conf 导入内容\n# echo \u0026#39;LANG=en_US.UTF-8\u0026#39; \u0026gt;\u0026gt; /etc/locale.conf 如果需要修改 #键盘布局，可编辑 vconsole.conf(5) 使其长期生效，例如：\n# vim /etc/vconsole.conf KEYMAP=de-latin1 设置主机名 首先在/etc/hostname设置主机名\n# vim /etc/hostname myarch 加入你想为主机取的主机名，这里比如叫 myarch。\n接下来在/etc/hosts设置与其匹配的条目。\n# vim /etc/hosts 加入如下内容\n127.0.0.1 localhost ::1 localhost 127.0.1.1 myarch.localdomain\tmyarch  某些情况下如不设置主机名，在 KDE 下可能会存在网络情况变更时无法启动 GUI 应用的问题，在终端中出现形如No protocol specified qt.qpa.xcb: could not connect to display的错误，这种情况较为少见[3][4][5]。\n Initramfs Creating a new initramfs is usually not required, because mkinitcpio was run on installation of the kernel package with pacstrap.\nFor LVM, system encryption or RAID, modify mkinitcpio.conf(5) and recreate the initramfs image:\n# mkinitcpio -P 具体例子查看 dm-crypt/Encrypting an entire system\n为 root 用户设置密码 # passwd root 安装微码 pacman -S intel-ucode #Intel pacman -S amd-ucode #AMD 安装引导程序 # pacman -S grub efibootmgr # pacman -S os-prober # grub-install --target=x86_64-efi --efi-directory=/boot/efi --bootloader-id=GRUB  rub是启动引导器，efibootmgr被 grub 脚本用来将启动项写入 NVRAM。 如果汝的硬盘上没有其它系统，那么可以不用装 os-prober --efi-directory=/efi —— 将 grubx64.efi 安装到之前的指定位置（EFI 分区） --bootloader-id=GRUB —— 取名为 GRUB  接下来编辑/etc/default/grub 文件，去掉GRUB_CMDLINE_LINUX_DEFAULT一行中最后的 quiet 参数，同时把 log level 的数值从 3 改成 5。这样是为了后续如果出现系统错误，方便排错。同时在同一行加入 nowatchdog 参数，这可以显著提高开关机速度。\n# vim /etc/default/grub GRUB_CMDLINE_LINUX_DEFAULT=\u0026#34;loglevel=5 nowatchdog\u0026#34; 最后生成 GRUB 所需的配置文件\n# grub-mkconfig -o /boot/grub/grub.cfg 我们在之前的命令中指定了 bootloader-id 为 GRUB，这一般不会出现问题。然而在某些主板安装完成后，你会发现没有 nvme 启动条目。这是因为某些主板的 UEFI 固件在显示 UEFI NVRAM 引导条目之前，需要在特定的位置存放可引导文件，不支持自定义存放 efi 文件[6]。解决方式是使用--removable 参数解决一些主板 NVRAM 的兼容性问题（包括虚拟机）。\n# grub-install --target=x86_64-efi --efi-directory=/boot/efi --bootloader-id=GRUB --removable # grub-mkconfig -o /boot/grub/grub.cfg 除此之外，如果你的主板是一些较老的型号，如 intel 9 系列以下或者较老 AMD 的主板，它们很可能不支持从 nvme 启动系统，虽然可以通过修改 BIOS 加入 NVME 支持模块来解决，但这不在本文讨论范围内。\n 为了引导 win10，则还需要添加新的一行 GRUB_DISABLE_OS_PROBER=false\n# GRUB boot loader configuration ... GRUB_DISABLE_OS_PROBER=false 如果汝安装了 os-prober 然后看到这样的警告：\n WARNING: Failed to connect to lvmetad. Falling back to device scanning.\n 这是因为在 chroot 环境里面 /run 是不可用的。只要每个步骤都做对了，这些警告不会影响系统启动， 汝可以放心继续进行下一步的系统安装咯。 如果汝重启之后没看到 Windows 的启动项，试着进入 Arch 之后再运行那条生成配置文件的命令。\n完成安装 exit # 退回安装环境# umount -R /mnt/arch # 卸载新分区 reboot # 重启 注意，重启前要先拔掉优盘，否则你重启后还是进安装程序而不是安装好的系统。重启后，开启 dhcp 服务，即可连接网络\nsystemctl enable --now dhcpcd #立即启动dhcp ping www.gnu.org #测试网络连接 若为无线链接，则还需要启动 iwd 才可以使用 iwctl 连接网络\nsystemctl enable --now iwd #立即启动iwd iwctl #和之前的方式一样，连接无线网络 到此为止，一个基础的，无 UI 界面的 Arch Linux 已经安装完成了。紧接着下一节，我们来安装图形界面。\n桌面环境与常用应用 官方文档: 安装后的工作 本节只介绍最基本的，能使系统真正意义上可用所需的组件\n注: 文档中带有 AUR 角标的软件代表是用户自行打包的第三方软件AUR，不在 Arch 官方支持范围内，可能会出现更新不及时、无法安装、使用出错等各种问题。如果遇到问题，你可自行去其 AUR 页面查看其他人的评论中是否有解决方法。如果不是实在没有官方支持的同类软件，则不建议使用。\n确保系统为最新 如果你在做完上一节的内容后，重启并放置过一段时间，那需要先按照上节末尾处的方式重新连接网络，然后更新系统。\npacman -Syyu #升级系统中全部包 准备非 root 用户 添加用户，比如新增加的用户叫 testuser\n# useradd -m -G wheel -s /bin/bash kurome  wheel附加组可sudo，以root用户执行命令 -m同时创建用户家目录  设置新用户 testuser 的密码\n# passwd kurome 编辑 sudoers 配置文件\n# pacman -S sudo # EDITOR=vim visudo 找到下面这样的一行，把前面的注释符号 # 去掉，:wq 保存并退出即可。\n#%wheel ALL=(ALL) ALL 这里稍微解释一下：\n %wheel —— 用户名或用户组，此处则代表是 wheel 组，% 是用户组的前缀 ALL= —— 主机名，此处则代表在所有主机上都生效（如果把同样的 sudoers 文件下发到了多个主机上） (ALL) —— 用户名，此处则代表可以成为任意目标用户 最后的 ALL —— 代表可以执行任意命令  几个更详细的例子:\n在 mailadmin 组里的用户可以作为 root 用户，在 snow 和 rain 这两台主机执行一些邮件服务器控制命令（命令之间用 , 分隔）：\n%mailadmin snow,rain=(root) /usr/sbin/postfix, /usr/sbin/postsuper, /usr/bin/doveadm 用户 whoami 可以在所有主机上以 root 用户不输入密码执行 rndc reload 这条命令（正常来说 sudo 都是要求输入调用方的密码的）：\nwhoami ALL=(root) NOPASSWD: /usr/sbin/rndc reload 当在 users 组里的用户以 sudo passwd 或者 sudo passwd root 方式运行命令的时候，可以直接把 root 用户的密\u0026gt; 码 改掉，这真是太危险了！必须要把这两条命令禁止掉，但我们又希望用户可以通过 sudo passwd 修改其它用户的密码。那么我们可以在命令前面加上 ! 来表示不可执行的命令：\n%users ALL=(root) !/usr/bin/passwd, /usr/bin/passwd [A-Za-z]*, !/usr/bin/passwd root 总结一下，语法如下：\n用户名/%用户组名 主机名=(目标用户名) 命令1, 命令2, !命令3 安装桌面环境 安装桌面环境需要的基础包 （就是 xorg 啦）\n# pacman -S xorg  xorg group includes xorg-server packages, packages from the xorg-apps group and fonts.  这时会让汝选择需要哪些软件包啦,其实大多数时候默认的就行……\n接下来挑一个喜欢的桌面环境包组装上咯~。咱这里就只举例 GNOME 、KDE 和 xfce 啦，其他官方支持的桌面环境可以去 https://wiki.Archlinux.org/index.php/Desktop_environment 查看\n  GNOME , 想要 GNOME 全家桶的话带上 gnome-extras\n# pacman -S gnome   KDE Plasma , 想要 KDE 全家桶的话用 kde-applications-meta 代替 。 kde-applications 会提示汝选择要安装哪些包。以及一个显示管理器， KDE 和 sddm 一起使用最好。\n# pacman -S plasma sddm kde-applications 或者只安装一些基本组件（例如文件管理器和终端模拟器）。\n# pacman -S plasma sddm kde-applications-meta   xfce4，xfce 不带显示管理器，所以要装个其他的（例如 lightdm，还要装一个 greeter）\n# pacman -S xfce4 xfce4-goodies lightdm lightdm-gtk-greeter 桌面环境大多数使用 NetworkManager ，xfce 的话，记得安装 network-manager-applet， 一个控制 NetworkManager 的小工具：\n# pacman -S network-manager-applet   配置 greeter sddm # systemctl enable sddm 设置交换文件 swap(可选) 在桌面环境中，交换分区或文件用来实现休眠(hibernate)的功能，即将当前环境保存在磁盘的交换文件或分区部分。除此之外，某些特定软件需要 swap 才可以正确运行。交换文件与分区性能相同，且交换文件更为灵活，可随时变更大小，增加与删除。[1]\nfallocate -l 4G /swapfile #创建4G的交换空间 大小根据需要自定 chmod 600 /swapfile #设置正确的权限 mkswap /swapfile #格式化swap文件 swapon /swapfile #启用swap文件 最后，向/etc/fstab 中追加如下内容：\n/swapfile none swap sw 0 0 KDE 自身提供开箱即用的睡眠功能(suspend)，即将系统挂起到内存，消耗少量的电量。休眠(hibernate)会将系统挂起到交换分区或文件，几乎不消耗电量。睡眠功能已可满足绝大多数人的需求，如果你一定需要休眠功能，可以参考官方文档设置休眠相关步骤。\n开启 32 位支持库 # vim /etc/pacman.conf 去掉[multilib]一节中两行的注释，来开启 32 位库支持。\n[multilib] Include = /etc/pacman.d/mirrorlist 最后:wq 保存退出，刷新 pacman 数据库\n# pacman -Syyu 重启电脑，即可看到欢迎界面，输入新用户的密码即可登录桌面\n添加中文社区仓库 在 /etc/pacman.conf 结尾处加入下面的文字，来添加 archlinuxcn 源。推荐的镜像源（选一个即可）也一并列出：\n$ vim /etc/pacman.conf [archlinuxcn] # 北京外国语大学 Server = https://mirrors.bfsu.edu.cn/archlinuxcn/$arch # 清华大学开源软件镜像站 Server = https://mirrors.tuna.tsinghua.edu.cn/archlinuxcn/$arch # 中国科学技术大学开源镜像站 Server = https://mirrors.ustc.edu.cn/archlinuxcn/$arch # 哈尔滨工业大学开源镜像站 Server = https://mirrors.hit.edu.cn/archlinuxcn/$arch # 华为开源镜像站 Server = https://repo.huaweicloud.com/archlinuxcn/$arch $ sudo pacman -Sy $ sudo pacman -S archlinuxcn-keyring  此外，还有其它镜像源在 archlinuxcn 官方 Github Repoopen in new window 列出，可以根据自己实际情况另行选择。 若安装 archlinuxcn-keyring 时报错，是由于密钥环的问题。可先按照 archlinuxcn 官方说明 执行其中的命令，再安装 archlinuxcn-keyring。  通过以下命令刷新 pacman 数据库并更新：\npacman -Syyu 安装基础功能包 进入桌面后，搜索 konsole。它是 KDE 桌面环境默认的命令行终端。\n首先先进行桌面环境中的网络设置：\n# 确保iwd开机处于关闭状态，其无线连接会与NetworkManager冲突 $ sudo systemctl disable iwd # 同上，立即关闭iwd $ sudo systemctl stop iwd # 确保先启动NetworkManager，并进行网络连接 若iwd已经与NetworkManager冲突 则执行完上一步重启一下电脑即可。 $ sudo systemctl enable --now NetworkManager 接下来安装一些基础功能包。\n# 识别NTFS格式的硬盘 $ sudo pacman -S ntfs-3g # 安装几个开源中文字体 一般装上文泉驿就能解决大多wine应用中文方块的问题 $ sudo pacman -S adobe-source-han-serif-cn-fonts wqy-zenhei # 安装谷歌开源字体及表情 $ sudo pacman -S noto-fonts-cjk noto-fonts-emoji noto-fonts-extra # 安装常用的火狐、谷歌浏览器 $ sudo pacman -S firefox chromium # 与dolphin同用右键解压 $ sudo pacman -S ark # 安装ark可选依赖 $ sudo pacman -S p7zip unrar unarchiver lzop lrzip # 确保Discover(软件中心）可用 需重启 $ sudo pacman -S packagekit-qt5 packagekit appstream-qt appstream # 图片查看器 $ sudo pacman -S gwenview # 一些工具 $ sudo pacman -S git wget kate bind  不要安装过多字体：在字体超过 255 种时，某些 QT 程序可能无法正确显示某些表情和符号，详见链接2。\n 设置 DNS 一般来说，如今大多电脑连接的路由器是可以自动处理 DNS 的，如果你的路由器不能处理，则需要额外进行 DNS 的设置。同时，如果使用 ISP 提供的默认 DNS,你的网络访问记录将存在更大的，被泄露或被当局存储记录的风险。除此之外，使用 ISP 提供的 DNS 还有可能将某些服务解析至一些已经失效或劣化的服务器。即使你的网络环境可以自动处理 DNS 设置，我们还是建议你使用可信的国际通用 DNS 设置。如下的配置将固定使用谷歌的 DNS,但是网络访问延迟可能增加。在阅读完随后的代理设置一节后，你的 DNS 请求将均通过代理发送，这将在 DNS 发送方面最大限度的保障你的隐私和安全。\nvim 编辑/etc/resolv.conf，删除已有条目，并将如下内容加入其中\nnameserver 8.8.8.8 nameserver 2001:4860:4860::8888 nameserver 8.8.4.4 nameserver 2001:4860:4860::8844 如果你的路由器可以自动处理 DNS,resolvconf 会在每次网络连接时用路由器的设置覆盖本机/etc/resolv.conf 中的设置，执行如下命令加入不可变标志，使其不能覆盖如上加入的配置[3][4]。\n$ sudo chattr +i /etc/resolv.conf 设置系统为中文 打开 System Settings \u0026gt; Regional Settings \u0026gt; Language -\u0026gt; Add languages 中选择中文加入，再拖拽到第一位，Apply。\n再将System Settings \u0026gt; Regional Settings \u0026gt; Formats 中的值设为中文-简体中文(zh_CN)\n最后重新登陆即可。\n 很多人会错误的更改 System Settings \u0026gt; Regional Settings \u0026gt; Formats 中的值为中文蒙古(mn_CN)，默认，或者其他值，这会导致系统中一半英文一半中文。这里的值要保持默认的 en_US 或 zh_CN,或者改为你在 locale.gen 中添加的任意一种语言。\n 也可以用 su 切换到刚建立的用户，然后编辑 ~/.config/locale.conf 修改自己用户级别的 Locale，例如：\nLANG=zh_CN.UTF-8 LC_CTYPE=\u0026#34;zh_CN.UTF-8\u0026#34; LC_NUMERIC=\u0026#34;zh_CN.UTF-8\u0026#34; LC_TIME=\u0026#34;zh_CN.UTF-8\u0026#34; LC_COLLATE=\u0026#34;zh_CN.UTF-8\u0026#34; LC_MONETARY=\u0026#34;zh_CN.UTF-8\u0026#34; LC_MESSAGES=\u0026#34;zh_CN.UTF-8\u0026#34; LC_PAPER=\u0026#34;zh_CN.UTF-8\u0026#34; LC_NAME=\u0026#34;zh_CN.UTF-8\u0026#34; LC_ADDRESS=\u0026#34;zh_CN.UTF-8\u0026#34; LC_TELEPHONE=\u0026#34;zh_CN.UTF-8\u0026#34; LC_MEASUREMENT=\u0026#34;zh_CN.UTF-8\u0026#34; LC_IDENTIFICATION=\u0026#34;zh_CN.UTF-8\u0026#34; LC_ALL= 安装 yay AUR 为 Archlinux user repository。任何用户都可以上传自己制作的 AUR 包，这也是 Arch Linux 可用软件众多的原因。由于任何人都可上传，也存在对应的风险，一般选用大众认可的包即可。\n使用 yay 可以安装 AUR 中的包。执行如下命令安装 yay。\n$ sudo pacman -S yay 或者\n$ pacman -S --needed git base-devel $ git clone https://aur.Archlinux.org/yay-bin.git $ cd yay-bin $ makepkg -si 安装输入法 Fcitx5 官方文档 中文及日文输入法均体验良好。\n$ sudo pacman -S fcitx5-im #基础包组 $ sudo pacman -S fcitx5-chinese-addons #官方中文输入引擎 $ sudo pacman -S fcitx5-anthy #日文输入引擎 $ yay -S fcitx5-pinyin-moegirl #萌娘百科词库 $ sudo pacman -S fcitx5-pinyin-zhwiki #中文维基百科词库 $ sudo pacman -S fcitx5-material-color #主题 更多皮肤：\n fcitx5-nord fcitx5-gruvbox  设置环境变量：编辑文件 EDITOR=vim sudoedit /etc/environment 加入以下内容。konsole 以及 dolphin 都需要这些环境变量，倒是 chrome 和 firefox 都不需要就可以输入中文\nGTK_IM_MODULE=fcitx QT_IM_MODULE=fcitx XMODIFIERS=@im=fcitx INPUT_METHOD=fcitx SDL_IM_MODULE=fcitx GLFW_IM_MODULE=ibus 打开 系统设置 \u0026gt; 区域设置 \u0026gt; 输入法，先点击运行Fcitx即可，拼音为默认添加项。如你还需要更多输入法如五笔，则再点击添加输入法，找到简体中文下的五笔 ，点击添加即可加入五笔输入法。\n接下来点击 拼音 右侧的配置按钮，点选云拼音和在程序中显示预编辑文本 最后应用。\n回到输入法设置，点击配置附加组件，找到 经典用户界面 在主题里选择一个你喜欢的颜色 最后应用。\n注销，重新登陆，就可以发现已经可以在各个软件中输入中文了\n配置系统默认编辑器 默认情况下，Arch Linux 在一些终端编辑场景使用 vi 编辑器，但是我们使用 vim。如果不做一个额外配置，在 git 等场景下，在终端调用编辑器会出错。编辑 EDITOR=vim sudoedit /etc/profile 文件，加入如下内容，将 vim 设置为默认 EDITOR\nexport EDITOR=\u0026#39;vim\u0026#39; 这样就不用在每次执行命令时都指定一遍 EDITOR=vim 了。\n启用蓝牙(若有) 如果你有蓝牙设备，需要安装蓝牙软件包并启用蓝牙服务。随后在系统设置中进行添加设备与连接即可。\n$ sudo pacman -S bluez bluez-utils $ sudo systemctl enable --now bluetooth 如果要连接蓝牙音频设备，需要安装 pulseaudio-bluetooth 并重启 pulseaudio。\n$ sudo pacman -S pulseaudio-bluetooth $ pulseaudio -k 设置 Timeshift 快照 通过以下命令安装 Timeshiftcn / aur：\n$ yay -S aur/timeshift 打开 Timeshift，第一次启动会自动启动设置向导。\n提示：Timeshift 只支持快照操作系统安装在具有 Ubuntu 类型的子卷布局（@ 和 @home 子卷）的 BTRFS 分区。\nProxy Enviroment set http or socks proxy environment variables\n# set http proxy export http_proxy=http://PROXYHOST:PROXYPORT # set http proxy with user and password export http_proxy=http://USERNAME:PASSWORD@PROXYHOST:PROXYPORT # set http proxy with user and password (with special characters) export http_proxy=http://`urlencode \u0026#39;USERNAME\u0026#39;`:`urlencode \u0026#39;PASSWORD\u0026#39;`@PROXYHOST:PROXYPORT # set socks proxy (local DNS) export http_proxy=socks5://PROXYHOST:PROXYPORT # set socks proxy (remote DNS) export http_proxy=socks5h://PROXYHOST:PROXYPORT # export other env variables export https_proxy=$http_proxy \\ ftp_proxy=$http_proxy \\ rsync_proxy=$http_proxy \\ all_proxy=$http_proxy # export other env variables (another way) export {https,ftp,rsync,all}_proxy=$http_proxy export HTTP_PROXY=$http_proxy \\ HTTPS_PROXY=$http_proxy \\ FTP_PROXY=$http_proxy \\  RSYNC_PROXY=$http_proxy \\ ALL_PROXY=$http_proxy \\ NO_PROXY=$no_proxy export {HTTP,HTTPS,FTP,RSYNC,ALL}_PROXY=$http_proxy # set git http(s) proxy git config --global http.sslverify false git config --global http.proxy $http_proxy git config --global https.proxy $http_proxy # only for \u0026#39;github.com\u0026#39; git config --global http.https://github.com.proxy $http_proxy set ssh proxy environment variables\n# use \u0026#39;nc\u0026#39; with http protocol export ssh_proxy=\u0026#39;ProxyCommand=nc -X connect -x PROXYHOST:PROXYPORT %h %p\u0026#39; # use \u0026#39;nc\u0026#39; with http protocol and proxy user export ssh_proxy=\u0026#39;ProxyCommand=nc -X connect -x PROXYHOST:PROXYPORT -P \u0026#39;USERNAME\u0026#39; %h %p\u0026#39; # use \u0026#39;nc\u0026#39; with socks5 protocol export ssh_proxy=\u0026#39;ProxyCommand=nc -X 5 -x PROXYHOST:PROXYPORT %h %p\u0026#39; # use \u0026#39;connect\u0026#39; with http protocol export ssh_proxy=\u0026#39;ProxyCommand=connect -H PROXYHOST:PROXYPORT %h %p\u0026#39; # use \u0026#39;connect\u0026#39; with http protocol and proxy user export ssh_proxy=\u0026#39;ProxyCommand=connect -H USER@PROXYHOST:PROXYPORT %h %p\u0026#39; # use \u0026#39;connect\u0026#39; with HTTP_PROXY environment export ssh_proxy=\u0026#39;ProxyCommand=connect -h %h %p\u0026#39; # use \u0026#39;connect\u0026#39; with socks5 protocol export ssh_proxy=\u0026#39;ProxyCommand=connect -S PROXYHOST:PROXYPORT %h %p\u0026#39; # use \u0026#39;connect\u0026#39; with socks5 protocol and user export ssh_proxy=\u0026#39;ProxyCommand=connect -S USER@PROXYHOST:PROXYPORT %h %p\u0026#39; # use \u0026#39;connect\u0026#39; with SOCKS5_SERVER environment export SOCKS5_SERVER=\u0026#39;PROXYHOST:PROXYPORT\u0026#39; export SOCKS5_USER=\u0026#39;USERNAME\u0026#39; export SOCKS5_PASSWD=\u0026#39;PASSWORD\u0026#39; export ssh_proxy=\u0026#39;ProxyCommand=connect -s %h %p\u0026#39; # connect to ssh server over proxy ssh -o \u0026#34;$ssh_proxy\u0026#34; USER@FINAL_DEST # set git ssh proxy git config --global core.sshCommand \u0026#34;ssh -o $ssh_proxy\u0026#34; set no proxy to ignore private network address\nno_proxy=\u0026#34;127.0.0.1,localhost,.localdomain.com\u0026#34; no_proxy=$no_proxy,`echo 10.{0..255}.{0..255}.{0..255}|tr \u0026#39; \u0026#39; \u0026#39;,\u0026#39;` no_proxy=$no_proxy,`echo 172.{16..31}.{0..255}.{0..255}|tr \u0026#39; \u0026#39; \u0026#39;,\u0026#39;` no_proxy=$no_proxy,`echo 192.168.{0..255}.{0..255}|tr \u0026#39; \u0026#39; \u0026#39;,\u0026#39;` export no_proxy # for more private network addresses, check following url # https://segmentfault.com/q/1010000010521593 # https://en.wikipedia.org/wiki/Private_network unset proxy environment variables\nunset http_proxy https_proxy ftp_proxy rsync_proxy all_proxy HTTP_PROXY HTTPS_PROXY FTP_PROXY RSYNC_PROXY ALL_PROXY unset {http,https,ftp,rsync,all}_proxy {HTTP,HTTPS,FTP,RSYNC,ALL}_PROXY git config --global --unset http.proxy git config --global --unset https.proxy git config --global --unset core.sshCommand git config --global --unset http.https://github.com.proxy unset ssh_proxy A remind:\n /etc/environment is not a script. It only supports KEY=VALUE syntax ($variable is not supported either) /etc/profile does not support export {HTTP,HTTPS,FTP,RSYNC,ALL}_PROXY=$http_proxy, it may hang your login  ubuntu gnome 下环境变量\n$ sudo nano /etc/environment http_proxy=http://127.0.0.1:7890/ HTTP_PROXY=http://127.0.0.1:7890/ https_proxy=http://127.0.0.1:7890/ HTTPS_PROXY=http://127.0.0.1:7890/ ftp_proxy=http://127.0.0.1:7890/ FTP_PROXY=http://127.0.0.1:7890/ all_proxy=socks://127.0.0.1:7891/ ALL_PROXY=socks://127.0.0.1:7891/ no_proxy=localhost,127.0.0.0/8,::1 NO_PROXY=localhost,127.0.0.0/8,::1 显卡驱动 现在是 2022 年，显卡驱动的安装在 Arch Linux 上已经变得非常容易。本文区分核芯显卡和独立显卡两大类描述显卡驱动的安装。注意，确保你已经按照本教程之前的章节安装配置好科学上网、安装好必要的包后再向下进行，不要多个教程混着看，你可能漏掉了本教程前置步骤中的某些操作，从而造成问题。\n 所有 AMD 显卡建议使用开源驱动。英伟达显卡建议使用闭源驱动，因为逆向工程的开源驱动性能过于低下，本文也只描述英伟达闭源驱动安装。如果你支持自由软件运动，请尽可能使用具有官方支持开源驱动的英特尔和 AMD 显卡。\n 核芯显卡 英特尔核芯显卡 官网文档\n英特尔核芯显卡安装如下几个包即可。\n$ sudo pacman -S mesa lib32-mesa vulkan-intel lib32-vulkan-intel  xf86-video-intel arch wiki 里写的很多发行版不建议安装它，而应使用 xorg 的 modesetting 驱动(也就是什么都不用装的意思)。经过我们测试目前确实是默认 modesetting 驱动较为稳定。\n 注意，只有 Intel HD 4000 及以上的核显才支持 vulkan。\nAMD 核芯显卡 对于具有核芯显卡的 AMD 处理器，需要先确定核显架构(Architecture)是什么，再决定安装什么驱动。推荐在 techpowerup 网站进行查询，信息非常全面。\n在确定了显卡架构后，再根据架构对照这个文档决定安装什么驱动。**对于 GCN2.0 及以下架构的老显卡，直接安装开源 ATI 驱动即可，原本闭源的老旧的 Catalyst 驱动在 2021 年已被废弃。GCN2.0 及以下架构的老显卡也不要使用开源的 AMDGPU 驱动，因为其仅处于实验性质，需要各种自定义内核编译选项与配置，非常麻烦，得不偿失。**对于新型号，即 GCN3 架构及更新型的核芯显卡，直接安装开源驱动 AMDGPU 即可，也就是以下这几个包。\n$ sudo pacman -S mesa lib32-mesa xf86-video-amdgpu vulkan-radeon lib32-vulkan-radeon libva-mesa-driver lib32-libva-mesa-driver mesa-vdpau lib32-mesa-vdpau  比如你的笔记本 cpu 是目前常见的 AMD R7 4800U，那么它的核显为 Vega 8。通过查询，可知其为 GCN 5.0 架构，那么对照 arch 官方文档，你可选择安装 AMDGPU 开源驱动。 再比如你的台式机 cpu 是目前常见的 锐龙 5 3400G，那么它的核显为 Vega 11。通过查询，可知其为 GCN 5.0 架构，那么对照 arch 官方文档，你可选择安装 AMDGPU 开源驱动。 再老一些的 apu A10-9700 处理器 ，它的核显为 Radeon R7。通过查询，可知其为 GCN 2.0 架构，那么对照 arch 官方文档，你选择安装 ATI 开源驱动。  独立显卡 这部分会分为仅有独立显卡(无核显)与同时拥有独立显卡和核芯显卡两种情况进行讲解。\n英伟达独立显卡 较新型号的独立显卡直接安装如下几个包即可。官方文档\n$ sudo pacman -S nvidia nvidia-settings lib32-nvidia-utils 如果是 GeForce 630 以上到 GeForce 920 以下的老卡，安装 nvidia-470xx-dkms AUR及其 32 位支持包。使用 dkms 驱动同时需要 headers。\n$ yay -S nvidia-470xx-dkms nvidia-settings lib32-nvidia-470xx-utils linux-headers 如果是 GeForce 630 以下到 GeForce 400 系列的老卡，安装 nvidia-390xx-dkmsAUR及其 32 位支持包。使用 dkms 驱动同时需要 headers。\n$ yay -S nvidia-390xx-dkms nvidia-settings lib32-nvidia-390xx-utils linux-headers 再老的显卡直接使用开源驱动即可。\n$ sudo pacman -S mesa lib32-mesa xf86-video-nouveau NVIDIA Optimus 在同时拥有核芯显卡和英伟达独立显卡的笔记本上安装驱动是大多数人关注的事情，这里着重讲述。\n 再次提醒请按照本书前置章节配置好系统后再进行，不要多个教程混看，尤其是一些过时的教程。尤其需要注意的是确保 base-devel 包的安装以及配置好科学上网软件，以及使用 X11 模式。\n 英伟达双显卡模式官方文档 /// optimus-manager 官方文档\n若为同时拥有核芯显卡与英伟达独显的笔记本电脑，同样需要按照上述步骤先安装各个软件包。除此之外还需要安装 optimus-manager。可以在核芯显卡和独立显卡间轻松切换。optimus-manager 提供三种模式，分别为仅用独显，仅用核显，和 hybrid 动态切换模式。\n$ yay -S optimus-manager optimus-manager-qt 安装完成后重启即可使用。optimus-manager 安装完成后会默认 enable optimus-manager 的服务，你可在重启前检查其状态，若没有 enable 则手动将其 enable。重启后在菜单栏搜索 optimus-manager 点击即可使用。可在其设置中设置开机自动启动。\n$ sudo systemctl enable optimus-manager 此时你应该已经可以进行显卡切换了，如果有问题，请详细阅读 optimus-manager 的文档，里面有详细的描述。由于各类问题太多，本文不进行描述，optimus-manager 的文档很详尽，请自行查看。此处仅列出几项较为重要的注意事项:\n 如果需要在独显和核显模式间切换，要注意你没安装各类 GPU 监控插件，它们会阻止显卡切换，导致不可预料的错误。 不要使用 Nvidia Control Panel 中的Save to X Configuration file按钮。会导致配置冲突。 在显卡之间的切换时，重新登陆后如在 splash screen 卡住或者黑屏，可以尝试在 tty1 tty2 之间进行切换。 如果你在安装 optimus manager 并重启后，直接黑屏卡死，不能进入系统，很有可能是遇到了常见的\u0026quot;ACPI ISSUE\u0026quot;，简单来说，这是笔记本制造商的实现问题。可以尝试在内核启动参数中加入acpi_osi=! acpi_osi=\u0026quot;Windows 2009\u0026quot; 后再尝试。[1]  最后详细说下动态切换模式。本质上其还是使用官方的 PRIME对闭源驱动的方法进行切换。需要设置三个环境变量，或者用 nvidia-prime 包提供的命令 prime-run，二者本质也是一样的，都是设置三个环境变量。\n$ sudo pacman -S nvidia-prime # 使用prime-run前缀来用独显运行某些程序 $ prime-run some_program 对于 AMD 核显+N 卡独显的读者，optimus-manager 对于这套组合的支持目前已经发布，最新可用版本为 1.4。\n 如果你不是强烈追求能效控制以及注重电池寿命的用户，那么可以不用往下看了，如果你是，那么需要针对你的硬件以及笔记本型号尝试正确的电源管理方式。此部分的设置可能导致黑屏，并且尝试过程可能较长，也会遇到各类问题，请根据你个人的操作水平自行斟酌是否操作\n电源控制做的事情是，在只用核显的模式下，确保正确关闭独立显卡。而在混合模式下，绝大多数情况下 Nvidia 模块实际是始终开启的，电源控制并不生效。这件事情其实很复杂，因为对于不同的显卡型号，以及笔记本型号的组合，可行的方案都是不同的。笼统来说，最广泛适用的办法是 bbswitch。但仍不建议上来就按照此方式安装使用，因为某些特定的硬件就是会出问题，也就是黑屏。这里建议按照 optimus-manager 官方的文档一步一步来，按步骤尝试，最后找到属于你自己的电脑合适的电源管理方式。此文档必须详细阅读！\n针对大多数笔记本适用的 Bbswitch,此处进行安装使用的讲解。首先安装包 bbswitch。若使用其它内核，则安装包 bbswitch-dkms。\nsudo pacman -S bbswitch #安装 bbswitch 切换方式 接下来右键点击 optimus-manager 的托盘设置，在 Optimus 选项卡中的 switch method 选择 Bbswitch 即可。\nPRIME To use the NVIDIA driver as an RandR 1.4 output source provider, also known as “PRIME”, the X server needs to be configured to use the NVIDIA driver for its primary screen and to use the “modesetting” driver for the other graphics device. This can be achieved by placing the following in /etc/X11/xorg.conf:\nSection \u0026#34;ServerLayout\u0026#34; Identifier \u0026#34;layout\u0026#34; Screen 0 \u0026#34;nvidia\u0026#34; Inactive \u0026#34;intel\u0026#34; EndSection Section \u0026#34;Device\u0026#34; Identifier \u0026#34;nvidia\u0026#34; Driver \u0026#34;nvidia\u0026#34; BusID \u0026#34;\u0026lt;BusID for NVIDIA device here\u0026gt;\u0026#34; EndSection Section \u0026#34;Screen\u0026#34; Identifier \u0026#34;nvidia\u0026#34; Device \u0026#34;nvidia\u0026#34; Option \u0026#34;AllowEmptyInitialConfiguration\u0026#34; EndSection Section \u0026#34;Device\u0026#34; Identifier \u0026#34;intel\u0026#34; Driver \u0026#34;modesetting\u0026#34; EndSection Section \u0026#34;Screen\u0026#34; Identifier \u0026#34;intel\u0026#34; Device \u0026#34;intel\u0026#34; EndSection The X server does not automatically enable displays attached using the output sink in this configuration. To do that, use the xrandr command line tool.\nFor NVIDIA as an output source:\n$ xrandr --setprovideroutputsource modesetting NVIDIA-0 $ xrandr --auto AMD 独立显卡 AMD 独立显卡的驱动安装步骤实际上 AMD 核芯显卡是相同的，都需要先确定架构，然后选定正确的驱动安装即可。真正需要关注的是如何在核芯显卡和独立显卡间进行切换。可以使用 PRIME 对开源驱动的双显卡切换方式。\n此外，可以使用 glmark2，DRI_PRIME=1 glmark2 分别对核显和独显进行测试，选择分数更高的一个进行使用。可以在 steam 游戏的启动前缀中加入DRI_PRIME=1 mangohud %command%来使用独显。(关于 mangohud)。\n笔记本上使用独立显卡运行 steam 游戏的另一个例子。\nDRI_PRIME=1 steam steam://rungameid/570 #运行dota2 DRI_PRIME=1 steam steam://rungameid/730 #运行cs go 显卡性能测试 官方文档。\n最传统和广为人知的方式为使用glxgears命令进行测试，其属于mesa-utils包。但其仅仅只能提供简单的测试场景及帧数显示，只测试了当前 OpenGL 功能的一小部分，功能明显不足。我们推荐如下两种工具。\nglmark2 glmark 提供了一系列丰富的测试，涉及图形单元性能（缓冲，建筑，照明，纹理等）的不同方面，允许进行更全面和有意义的测试。 每次测试单独计算帧速率。 最终，用户根据以前的所有测试获得了一个成绩分数。在 Archlinux 上属于包glmark2\nUnigine benchmark Unigine 3D 引擎是一个更全面的基准测试工具。 截止目前有五个版本，从旧到新分别是\n sanctuary(2007) tropics(2008) heaven(2009) valley(2013) superposition(2017)  可从AUR下载全部版本。它们均为专有软件。\n显卡信息查看 对于英伟达显卡，nvidia-settings 这个包即可全面的展示显卡相关信息。\n对于 AMD 显卡，稍微麻烦一些，通过 yay 安装 radeon-profile-git 这个包，同时安装其依赖 radeon-profile-daemon，最后启动这个进程。即可以图形化的方式查看 amd 显卡信息。github 项目地址\n$ sudo systemctl enable --now radeon-profile-daemon.service 注意，不要对左下角的 auto low high 进行更改 有 bug 会卡死。同时，显存占用在某些型号显卡上展示可能有误。\n后续 如果作为一个普通使用者，到这里你的系统已经配置完毕了。不会命令行也没太大关系，你可以慢慢探索 KDE 这个桌面环境，记住时常用如下命令或 Discover 软件更新系统即可。\n# 更新官方仓库 $ sudo pacman -Syyu # 同时更新官方仓库与AUR $ yay -Syyu 接下来你可以查阅娱乐、办公、多媒体等章节了解更多使用软件的安装与使用。如果你需要成为一名较为专业的人员，那么请阅读进阶、以及编程等章节。\n其他 Operation too slow 修改文件/etc/pacman.conf：\n#XferCommand = /usr/bin/curl -C - -f %u \u0026gt; %o #XferCommand = /usr/bin/wget --passive-ftp -c -O %o %u 把其中一行注释取消掉(删除#)就行了。\nath9k Weak And Unstable Connection ath9k 尝试：\n$ lspci -k ... 03:00.0 Network controller: Qualcomm Atheros QCA9565 / AR9565 Wireless Network Adapter (rev 01) Subsystem: Lite-On Communications Inc QCA9565 / AR9565 Wireless Network Adapter Kernel driver in use: ath9k Kernel modules: ath9k $ modprobe ath9k nohwcrypt=1 # manually $ sudo vim /etc/modprobe.d/ath9k-nohwcrypt.conf # Using files options ath9k nohwcrypt=1 or\n$ yay -S backports-patches-git ssh-agent $ vim ~/.bashrc if ! pgrep -u \u0026#34;$USER\u0026#34; ssh-agent \u0026gt; /dev/null; then ssh-agent \u0026gt; \u0026#34;$XDG_RUNTIME_DIR/ssh-agent.env\u0026#34; fi if [[ ! \u0026#34;$SSH_AUTH_SOCK\u0026#34; ]]; then source \u0026#34;$XDG_RUNTIME_DIR/ssh-agent.env\u0026#34; \u0026gt;/dev/null fi Tip: To make all ssh clients, including git store keys in the agent on first use, add the configuration setting AddKeysToAgent yes to ~/.ssh/config. Other possible values are confirm, ask and no (default). for example:\nHost github-proj1 HostName github.com User git IdentityFile ~/.ssh/id_rsa AddKeysToAgent yes Host github-proj2 HostName github.com User git IdentityFile ~/.ssh/kurome AddKeysToAgent yes Chrome 无法连接代理 通过环境变量设置代理，结果 chrome 无法浏览网页，报错 ERR_EMPTY_RESPONSE\n可以 man google-chrome 找到设置代理的参数 proxy-server 指定代理，如\n$ google-chrome-stable --proxy-server=\u0026#34;127.0.1:7890\u0026#34; Optimization “Arch安装器” 特点是使用 Arch Linux 主软件库，定制桌面，使用图形 LiveCD 安装等。\n EndeavourOS Garuda Linux FireRain OS 更多 Arch-based distributions aui archcraft  Archinstall May 2nd, 2022\n本文将指导使用 archinstall 安装 Arch Linux 和 KDE 桌面环境。\n前言 众所周知，安装 Arch Linux 是一件非常复杂并痛苦的事情，您需要一定的 Linux 基础，然后使用命令行进行硬盘分区，安装自己需要的软件，Arch Linux 官方也并未提供 GUI 安装程序，所以很多想尝试 Arch Linux 的用户都会被劝退在安装这一步骤上。\narchinstall 是一个 Python 写的 Arch Linux 安装向导程序，我们可以很方便地使用 archinstall 安装 Arch Linux。\nArch Linux 发布 2022.05.01 的 iso 后，已经默认集成了 archinstall，于是您可以参考本教程无痛安装 Arch Linux。\n准备工作 首先，获取安装映像，您可以在下载页面下载最新的 iso 镜像文件，您可以选择速度最快的 mirror 进行下载，这里推荐两个下载链接\n 国外用户，使用官方镜像 国内用户，使用清华大学镜像  下载后您需要准备个 U 盘或移动硬盘，然后使用一些工具，比如 Rufus，这里不再阐述，其他方法请参考这里。\n另外，您需要确认主板 BIOS 里没有奇奇怪怪的设置，比如某些针对 Windows 系统的设置，比如快速启动、CSM 安全启动、TPM 模块等都设置需要自己调整，否则默认配置可能会导致安装完 Arch Linux 后无法进入系统引导。\n安装系统   启动进入引导后，我们会看到熟悉的 Arch Linux 界面，默认进入后即可看到 Live CD 已经正常工作。\n  我们可以运行 installation_guide 命令查看安装文档，当然都是英文的，按 Q 退出。\n  我们可以直接运行 archinstall 进行图形化安装向导，然后我们会看到 archinstall 的向导界面。然后我们就一步一步来安装：\n Archinstall language 这里可以选择 archinstall 的界面语言，很可惜，截止本文发布，并没有中文。 Keyboard layout 选择键盘布局，默认情况你的键盘布局应该都是 us，除非你是德国等国家的用户，那么请自行选择。 Mirror region 可以选择最合适的镜像，建议选择和您当前网络一致的国家或地区，记得按空格选择，然后按回车继续。 Drive(s) 可以选择安装的硬盘，请自行选择需要安装的硬盘，切记看清楚硬盘大小，不要装错了硬盘最后拍大腿。 Disk layout让您选择如何分区，如果没有特殊需求，直接选择 Wipe all selected drives and use a best-effort default partition layout，这样会把你的硬盘全部格式化，切记备份重要数据，不然安装了以后拍大腿。  然后会询问您硬盘分区格式，可选 btrfs，ext4，f2fs 或 xfs，如果没有特殊需求，可以选最常用的 ext4。 然后会询问您是否要对 /home 目录单独分区，这里主要存放用户的数据，默认建议单独分区，实际操作中会分配大概 80% 的硬盘空间给 /home 目录，你也可以一股脑都分给 /，请自行决定。   Encryption password 选项，如果您需要对硬盘加密，可以选择，如果没需要可以跳过。 然后我们直接跳过 Bootloader 和 Use swap，因为他已经自动给您设置好了。 如果您喜欢的话，可以给您的机器设置 Hostname 和 Root password ，如果没有特殊需求，也可以跳过， 来到 User account，设置一个拥有 sudo 权限的超级用户，这个用户是日常登录和操作使用，请务牢记用户名和密码。成功后选择 Confirm and exit 即可。 Profile选项选择系统的使用场景，比如desktop提供kde/gnome/sway等，我们这里选择 kde Audio选项选择音频服务器，有pluseaudio和pipewire Kernels选项可选择linux/linux-lts/linux-zen等 来到 Network configuration，因为我们希望安装 KDE 桌面环境，所以选择 Use NetworkManager，如果是服务器环境，可以选择 Manual configuration 手工配置网络。 然后我们选择时区，进入 Timezone，按照您本地的时区来选择，可以使用 / 然后输入前几个字符快速搜索，比如 /shanghai。 一切准备就绪，我们可以选择 Save configuration 来保存配置，也可以直接选 Install 进行安装。系统会提示 Would you like to chroot into the newly created installation and perform post-installation configuration?，这里我们直接选择 Yes，然后进入安装。    安装完成后开启 sddm：\n$ systemctl enable sddm 然后我们使用 exit 命令退出并使用 reboot 命令重启。\npacman pacman是arclinux中的软件管理工具，可以直接从网络上的软件仓库下载安装及删除软件，自动处理依赖关系。\n详情查看 pacman(8)\n安装软件   pacman -S 软件名: 安装软件。也可以同时安装多个包，只需以空格分隔包名即可。\n  -S, \u0026ndash;sync\nSynchronize packages.\n    pacman -S --needed 软件名1 软件名2: 安装软件，但不重新安装已经是最新的软件。\n  \u0026ndash;needed\nDo not reinstall the targets that are already up-to-date.\n    pacman -Sy 软件名：安装软件前，先从远程仓库下载软件包数据库(数据库即所有软件列表)。\n  -y, \u0026ndash;refresh\nDownload a fresh copy of the master package database from the server(s) defined in pacman.conf(5). Passing two \u0026ndash;refresh or -y flags will force a refresh of all package databases, even if they appear to be up-to-date.\n    pacman -Sv 软件名：在显示一些操作信息后执行安装。\n  -v, \u0026ndash;verbose\nOutput paths such as the Root, Conf File, DB Path, Cache Dirs, etc.\n    pacman -Sw 软件名: 只下载软件包，不安装。\n  -w, \u0026ndash;downloadonly\nRetrieve all packages from the server, but do not install/upgrade anything.\n    pacman -U 软件名.pkg.tar.gz：安装本地软件包。\n  -U, \u0026ndash;upgrade\nUpgrade or add package(s) to the system and install the required dependencies from sync repositories.\n    pacman -U http://www.example.com/repo/example.pkg.tar.xz : 安装一个远程包（不在 pacman 配置的源里面）。\n  更新系统   pacman -Sy: 从服务器下载新的软件包数据库（实际上就是下载远程仓库最新软件列表到本地）。\n  pacman -Su: 升级所有已安装的软件包。\n  -u, \u0026ndash;sysupgrade\nUpgrades all packages that are out-of-date.\n    pacman 可以用一个命令就可以升级整个系统。花费的时间取决于系统有多老。这个命令会同步非本地(local)软件仓库并升级系统的软件包：\npacman -Syu 在Arch linux中，只支持系统完整升级，不支持部分升级。\n如果升级时，网络比较慢，觉得既浪费时间又浪费硬盘，实在不想升级那么多东西，可以逐个软件包升级。用下面命令可以升级核心包：\npacman -S --needed \u0026lt;packages...\u0026gt; 详解（小写为在上面固定搭配下的含义）：\n卸载软件   pacman -R 软件名: 该命令将只删除包，保留其全部已经安装的依赖关系\n  -R, \u0026ndash;remove\nRemove package(s) from the system.\n    pacman -Rv 软件名: 删除软件，并显示详细的信息\n  pacman -Rs 软件名: 删除软件，同时删除本机上只有该软件依赖的软件。\n  -s, \u0026ndash;recursive\nRemove each target specified including all of their dependencies, provided that (A) they are not required by other packages; and (B) they were not explicitly installed by the user.\n    pacman -Rsc 软件名: 删除软件，并删除所有依赖这个软件的程序，慎用\n  -c, \u0026ndash;cascade\nRemove all target packages, as well as all packages that depend on one or more target packages.\n    pacman -Ru 软件名: 删除软件,同时删除不再被任何软件所需要的依赖\n  -u, \u0026ndash;unneeded\nRemoves targets that are not required by any other packages.\n    详解（小写为在上面固定搭配下的含义）：\n搜索软件   pacman -Ss 关键字: 在仓库中搜索含关键字的软件包（本地已安装的会标记）\n参数加q可以简洁方式显示结果，比如 pacman -Ssq gcc 会比 pacman -Ss gcc 显示的好看一些。\n  -s, \u0026ndash;search \nThis will search each package in the sync databases for names or descriptions that match regexp.\n    pacman -Sl \u0026lt;repo\u0026gt;:显示软件仓库中所有软件的列表\n  通常这样用:pacman -Sl | 关键字\n  ``pacman -Sl | gcc跟pacman -Ssq gcc` 很接近，但是会少一些和gcc有关但软件名不包含gcc的包。\n  -l, \u0026ndash;list\nList all packages in the specified repositories.\n    pacman -Qs 关键字: 搜索已安装的软件包\n  -Q, \u0026ndash;query\nQuery the package database.\n    pacman -Qu: 列出所有可升级的软件包\n  -u, \u0026ndash;upgrades\nRestrict or filter output to packages that are out-of-date on the local system.\n    pacman -Qt: 列出不被任何软件要求的软件包\n  -t, \u0026ndash;unrequired\nRestrict or filter output to print only packages neither required nor optionally required by any currently installed package.\n    查询软件信息\n  pacman -Q 软件名: 查看软件包是否已安装，已安装则显示软件包名称和版本\n  pacman -Qi 软件名: 查看某个软件包信息，显示较为详细的信息，包括描述、构架、依赖、大小等等\n  -i, \u0026ndash;info\nDisplay information on a given package.\n    pacman -Ql 软件名: 列出软件包内所有文件，包括软件安装的每个文件、文件夹的名称和路径\n  -l, \u0026ndash;list\nList all files owned by a given package.\n    软件包组   pacman -Sg: 列出软件仓库上所有的软件包组\n  -g, \u0026ndash;groups\nDisplay all the members for each package group specified.\n    pacman -Qg: 列出本地已经安装的软件包组和子包\n  pacman -Sg 软件包组: 查看某软件包组所包含的所有软件包\n  pacman -Qg 软件包组: 和pacman -Sg 软件包组完全一样\n  很多人建议通过安装软件组来安装工具链，但是这样比较浪费空间。实际上如果把gcc, qt, clang等安装上，msys2就要占掉超过10G的硬盘空间，所以个人很少直接安装软件组。\n清理缓存   pacman -Sc：清理未安装的包文件，包文件位于 /var/cache/pacman/pkg/ 目录。\n  -c, \u0026ndash;clean\nRemove packages that are no longer installed from the cache as well as currently unused sync databases to free up disk space. Use one \u0026ndash;clean switch to only remove packages that are no longer installed; use two to remove all files from the cache.\n    pacman -Scc：清理所有的缓存文件。\n  配置 ZRAM ZRAM 介绍 随着现代应用程序的多样化和复杂化发展，那个曾经只需要 640KB 内存就能运行市面上所有软件的时代已经一去不复返，而比应用程序发展更快的则是用户对多任务的需求。现在的主流操作系统都提供了内存压缩的功能，以保证活跃应用程序拥有尽可能多的可用内存：\n macOS 从 OS X 10.9 之后默认开启内存压缩 Windows 从 Win10 TH2 之后默认开启内存压缩 大部分 Android 手机厂商都默认开启了内存压缩  Android（Linux）的内存压缩是依靠 Swap 机制实现的，大部分情况下是使用 ZRAM 技术来模拟 Swap。\nZRAM 早在 2014 年就伴随 Linux 3.14 内核合入主线，但由于 Linux 用途十分广泛，这一技术并非默认启用，只有 Android 和少部分的 Linux 桌面发行版如 Fedora 默认启用了这一技术，以保证多任务场景下内存的合理分层存储。\nZRAM 运行机制 ZRAM 的原理是划分一块内存区域作为虚拟的块设备（可以理解为支持透明压缩的内存文件系统），当系统内存不足出现页面交换时，可以将原本应该交换出去的页压缩后放在内存中，由于部分被『交换出去』的页得到了压缩，因此可用的物理内存就能随之变多。\n由于 ZRAM 并没有改变 Linux 内存模型的基本结构，因此我们只能利用 Linux 中 Swap 的优先级能力，将 ZRAM 作为高优先级 Swap 看待，这也解释了为什么闪存比较脆弱的手机上会出现 Swap，其本质还是 ZRAM。\n随着部分手机开始使用真正的固态硬盘，也有将 Swap 放在硬盘上的手机，但是一般也都会优先使用 ZRAM。\n由于这一运行机制的存在，ZRAM 可以设计得足够简单：内存交换策略交给内核、压缩算法交给压缩库，ZRAM 本身基本上只需要实现块设备驱动，因此具有极强的可定制性和灵活性，这也是 Windows、macOS 等系统所无法比拟的。\nLinux5.16 中关于 ZRAM 的源码只有不到 100KB，实现非常精简，对 Linux 驱动开发感兴趣的朋友也可以从这里开始研究：linux/Kconfig at v5.16 · torvalds/linux\nZRAM 配置与自启动 确认内核是否支持\u0026amp;有无启用 ZRAM 既然 ZRAM 是内核模块，就需要先检查当前 Linux 机器的内核是否存在这一模块。\n在配置之前，需要读者先确认一下自己的内核版本是否在 3.14 以上，部分 VPS 由于依旧使用 Xen、OpenVZ 等虚拟/容器化技术，内核版本往往卡在 2.6，那么这样的机器是无法开启 ZRAM 的。\n$ uname -r 但根据内核版本判断毕竟不可靠，如 CentOS 7，虽然内核版本是 3.10，却支持 ZRAM，也有极少数发行版或嵌入式 Linux 为了降低资源占用，选择不编译 ZRAM，因此我们最好使用 modinfo 命令来检查一下有无 ZRAM 支持：\n$ modinfo zram 部分发行版会默认启用但不配置 ZRAM，我们可以使用lsmod检查 ZRAM 是否启用：\n$ lsmod | grep zram 启用 ZRAM 内核模块 如果确定 ZRAM 没有被启用，我们可以新建文件 /etc/modules-load.d/zram.conf，并在其中输入 zram，然后重启机器以生效。\n$ echo \u0026#39;zram\u0026#39; | sudo tee /etc/modules-load.d/zram.conf 上文我们提到，ZRAM 本质上是块设备驱动，那么当我们输入 lsblk 会发生什么呢？\n$ lsblk 可以看到，其中并没有 zram 相关字眼，这是因为我们需要先新建一个块设备。\n打开 ZRAM 源码 中的Kconfig文件，可以找到如下说明：\n Creates virtual block devices called /dev/zramX (X = 0, 1, …). Pages written to these disks are compressed and stored in memory itself. These disks allow very fast I/O and compression provides good amounts of memory savings.\nIt has several use cases, for example: /tmp storage, use as swap disks and maybe many more.\nSee Documentation/admin-guide/blockdev/zram.rst for more information.\n 其中提到了一篇位于 Documentation/admin-guide/blockdev/zram.rst 的 说明文档。\n根据说明文档，我们可以使用 modprobe zram num_devices=1 的方式来让内核在启用 ZRAM 模块时开启一个 ZRAM 设备（一般只需要一个就够了），但这样开启设备的方式依旧在重启后就会失效，并不方便。\n好在modprobe的 说明文档 中提到了modprobe.d的存在：modprobe.d(5) – Linux manual page。\n继续阅读 modprobe.d 的文档，我们会发现它主要用于modprobe时预定义参数，即只需要输入 modprobe zram，辅以 modprobe.d中的配置，就可以自动加上参数。由于我们使用 modules-load.d 实现了 ZRAM 模块的开机自启，因此只需要在modprobe.d中配置参数即可。\n按照上文所述的文档，新建文件/etc/modprobe.d/zram.conf，在其中输入options zram num_devices=1，即可配置一个 ZRAM 块设备，同样重启后生效。\n$ echo \u0026#39;options zram num_devices=1\u0026#39; | sudo tee /etc/modprobe.d/zram.conf 配置 zram0 设备 重启后输入lsblk，却发现所需的 ZRAM 设备依旧没有出现？\n不用担心，这是因为我们还没有为这个块设备建立文件系统，lsblk虽然名字听起来像是列出块设备，但本质上读取的确是/sys目录里的文件系统信息，再将其与udev中的设备信息比对。\n阅读udev的文档：udev(7) – Linux manual page，其中提到udev会从/etc/udev/rules.d目录读取设备信息，按照文档中的指示，我们新建一个名为/etc/udev/rules.d/99-zram.rules的文件，在其中写入如下内容：\n$ echo \u0026#39;KERNEL==\u0026#34;zram0\u0026#34;,ATTR{disksize}=\u0026#34;30G\u0026#34;,TAG+=\u0026#34;systemd\u0026#34;\u0026#39; | sudo tee /etc/udev/rules.d/99-zram.rules 其中，KERNEL属性用于指明具体设备，ATTR属性用于给设备传递参数，这里我们需要阅读zram的文档，其中提到：\n Set disk size by writing the value to sysfs node ‘disksize’. The value can be either in bytes or you can use mem suffixes. Examples:\n# Initialize /dev/zram0 with 50MB disksize echo $((50*1024*1024)) \u0026gt; /sys/block/zram0/disksize # Using mem suffixes echo 256K \u0026gt; /sys/block/zram0/disksize echo 512M \u0026gt; /sys/block/zram0/disksize echo 1G \u0026gt; /sys/block/zram0/disksize Note: There is little point creating a zram of greater than twice the size of memory since we expect a 2:1 compression ratio. Note that zram uses about 0.1% of the size of the disk when not in use so a huge zram is wasteful.\n 即该块设备接受名为disksize的参数，且不建议分配内存容量两倍以上的 ZRAM 空间。笔者的 Linux 环境拥有 60G 内存，考虑到实际使用情况，设置了 30G 的 ZRAM，这样一来理想情况下就能获得60G - (30G / 2) + 30G \u0026gt; 75G以上的内存空间，已经足够使用。读者可以根据自己的实际情况选择 ZRAM 空间大小，一般来说一开始可以设置小一些，不够用再扩大。\nTAG属性用于标记设备类型（设备由谁管理），根据systemd.device的文档：systemd.device(5) – Linux manual page，大部分块设备和网络设备都建议标记 TAG 为systemd，这样systemd就可以将这个设备视作一个Unit，便于控制服务的依赖关系（如块设备加载成功后再启动服务等），这里我们也将其标记为systemd即可。\n $ sudo systemctl status dev-zram0.device 可以使用如 dev-zram0.device 或者 dev-sda1.device 等方式获取设备的 Device Unit\n 配置结束后，再次重启 Linux，就能在lsblk 命令中看到zram0设备了。\n将 zram0 设备配置为 Swap 获取到了一个 30G 大小的 ZRAM 设备，接下来需要做的就是将这个设备配置为 Swap，有经验的读者应该已经猜到接下来的操作了：\n$ sudo mkswap /dev/zram0 $ sudo swapon /dev/zram0 是的，将zram0设备配置为 Swap 和将一个普通设备/分区/文件配置为 Swap 的方式是一模一样，但该如何让这一操作开机自动执行呢？\n首先想到的自然是使用fstab，但好巧不巧，启用 ZRAM 内核模块使用的modules-load.d也难逃 Systemd 的魔爪：modules-load.d(5) – Linux manual page。既然从一开始就上了 Systemd 的贼船，那就贯彻到底吧！\n在 Systemd 的体系下，开机自启的命令可以被注册为一个 Service Unit，我们新建一个文件/usr/lib/systemd/system/zram.service，在其中写入如下内容：\n$ sudo modprobe zram $ sudo nano /usr/lib/systemd/system/zram.service [Unit] Description=ZRAM BindsTo=dev-zram0.device After=dev-zram0.device [Service] Type=oneshot RemainAfterExit=true ExecStartPre=/sbin/mkswap /dev/zram0 ExecStart=/sbin/swapon -p 2 /dev/zram0 ExecStop=/sbin/swapoff /dev/zram0 [Install] WantedBy=multi-user.target 接下来运行systemctl daemon-reload重载配置文件，再运行systemctl enable zram --now，如果没有出现报错，可以运行swapon -s 查看 Swap 状态，如果看到存在名为/dev/zram0的设备，恭喜你！现在 ZRAM 就已经配置完成并能实现自启动了~\n$ sudo systemctl daemon-reload $ sudo systemctl enable zram --now $ swapon -s  里为了帮助读者了解 ZRAM 和 Systemd 的原理，因此采取了全手动的配置方式。如果读者觉得比较麻烦，或有大规模部署的需求，可以使用 systemd/zram-generator: Systemd unit generator for zram devices，大部分默认启用 ZRAM 的发行版（如 Fedora）都使用了这一工具，编写配置文件后运行systemctl enable /dev/zram0 --now即可启用 ZRAM。\n 配置双层 Swap（可选） 上一节我们配置了 ZRAM，并将其设置为了 Swap，但此时 ZRAM 依旧是不生效的。为什么呢？眼尖的读者应该发现了，/swapfile的优先级高于/dev/zram0，这导致当 Linux 需要交换内存时，依旧会优先将页换入/swapfile，而非 ZRAM。\n解决这个问题可以通过两种方式：禁用 Swapfile，或者降低 Swapfile 的优先级，这里为了避免 ZRAM 耗尽后出现 OOM 导致服务掉线，我们采取后者，即配置双层 Swap，当高优先级的 ZRAM 耗尽后，会继续使用低优先级的 Swapfile。\n我们打开 Swapfile 的配置文件（笔者的配置文件在/etc/fstab中），增加 pri(Priority) 参数：\n$ sudo nano /etc/fstab /swapfile none swap sw,pri=1 0 0 如果使用其他方式配置 Swapfile（如 Systemd），只要保证执行swapon时携带-p参数即可，数字越低，优先级越低。对于 ZRAM 同理，如上文的zram.service中就配置 ZRAM 的优先级为 2。\n设置后重启 Linux，再次执行 swapon -s 查看 Swap 状态，保证 ZRAM 优先级高于其他 Swap 优先级即可：\n$ swapon -s ZRAM 监控 启用 ZRAM 后，我们该如何查看 ZRAM 的实际效用，如压缩前后大小，以及压缩率等状态呢？\n最直接的办法自然是查看驱动的 源码，和 文档，可以发现函数mm_stat_show()定义了/sys/block/zram0/mm_stat文件的输出结果，从左到右分别代表：\n$ cat /sys/block/zram0/mm_stat # orig_data_size - 当前压缩前大小 (Byte) 4096 # compr_data_size - 当前压缩后大小 (Byte) 74 # mem_used_total - 当前总内存消耗，包含元数据等 Overhead（Byte） 12288 # mem_limit - 当前最大内存消耗限制（页） 0 # mem_used_max - 历史最高内存用量（页） 1223118848 # same_pages - 当前相同（可被压缩）的页 0 # pages_compacted - 历史从 RAM 压缩到 ZRAM 的页 50863 # huge_pages - 当前无法被压缩的页（巨页） 0 该文件适合输出到各种监控软件进行监控，但无论是 Byte 还是页，这些裸数值依旧不便阅读，好在util-linux包提供了一个名为zramctl的工具（和 systemctl 其实是雷锋与雷峰塔的关系），在安装util-linux后执行zramctl，即可获得结果：\n$ zramctl 根据上文mm_stat的输出，可以类推每项数值的含义，或者我们可以找到zramctl的 源码，了解每项输出的含义与单位：\nstatic const struct colinfo infos[] = { [COL_NAME] = { \u0026#34;NAME\u0026#34;, 0.25, 0, N_(\u0026#34;zram device name\u0026#34;) }, [COL_DISKSIZE] = { \u0026#34;DISKSIZE\u0026#34;, 5, SCOLS_FL_RIGHT, N_(\u0026#34;limit on the uncompressed amount of data\u0026#34;) }, [COL_ORIG_SIZE] = { \u0026#34;DATA\u0026#34;, 5, SCOLS_FL_RIGHT, N_(\u0026#34;uncompressed size of stored data\u0026#34;) }, [COL_COMP_SIZE] = { \u0026#34;COMPR\u0026#34;, 5, SCOLS_FL_RIGHT, N_(\u0026#34;compressed size of stored data\u0026#34;) }, [COL_ALGORITHM] = { \u0026#34;ALGORITHM\u0026#34;, 3, 0, N_(\u0026#34;the selected compression algorithm\u0026#34;) }, [COL_STREAMS] = { \u0026#34;STREAMS\u0026#34;, 3, SCOLS_FL_RIGHT, N_(\u0026#34;number of concurrent compress operations\u0026#34;) }, [COL_ZEROPAGES] = { \u0026#34;ZERO-PAGES\u0026#34;, 3, SCOLS_FL_RIGHT, N_(\u0026#34;empty pages with no allocated memory\u0026#34;) }, [COL_MEMTOTAL] = { \u0026#34;TOTAL\u0026#34;, 5, SCOLS_FL_RIGHT, N_(\u0026#34;all memory including allocator fragmentation and metadata overhead\u0026#34;) }, [COL_MEMLIMIT] = { \u0026#34;MEM-LIMIT\u0026#34;, 5, SCOLS_FL_RIGHT, N_(\u0026#34;memory limit used to store compressed data\u0026#34;) }, [COL_MEMUSED] = { \u0026#34;MEM-USED\u0026#34;, 5, SCOLS_FL_RIGHT, N_(\u0026#34;memory zram have been consumed to store compressed data\u0026#34;) }, [COL_MIGRATED] = { \u0026#34;MIGRATED\u0026#34;, 5, SCOLS_FL_RIGHT, N_(\u0026#34;number of objects migrated by compaction\u0026#34;) }, [COL_MOUNTPOINT]= { \u0026#34;MOUNTPOINT\u0026#34;,0.10, SCOLS_FL_TRUNC, N_(\u0026#34;where the device is mounted\u0026#34;) }, }; 部分未默认输出的数值可以通过zramctl --output-all输出：\n$ zramctl --output-all 这个工具的输出结果混淆了 Byte 和页，混淆了历史最高、累计和当前的数值，且将不设置的参数（如内存限制）显示为 0B，因此输出结果仅作为参考，可读性依旧不高，一般来说只用了解DATA和COMPR字段即可。\n结合zramctl和mm_stat的输出，不难发现我们配置的 ZRAM 大小其实是未压缩的大小，而非是压缩后的大小，前面我们提到了一个算法，当 ZRAM 大小为 30GB 且压缩率为 2:1 时，可以获得60G - (30G / 2) + 30G \u0026gt; 75G的可用内存，这就是假设了 30GB 的未压缩数据可以压缩到 15G，占用 15G 物理内存空间，即60G - (30G / 2)，然后再加上 ZRAM 能存储最大的内存数据 30G 计算出来。\n计算压缩率的方式为 DATA / COMPR。，以 ElasticSearch 的工作负载为例，默认压缩率为1.1G / 97M = 11.6（如果是4K 74B则是没有负载）。\nZRAM 调优 尽管 ZRAM 的设置非常简单，其依然提供了大量可配置项供用户调整，如果在默认配置 ZRAM 后依旧觉得不满意，或者想要进一步发掘 ZRAM 的潜力，就需要对其进行优化。\n选择最适合的压缩算法 ZRAM 目前的默认压缩算法一般是lzo-rle，但其实 ZRAM 支持的压缩算法有很多，我们可以通过 cat /sys/block/zram0/comp_algorithm 获取支持的算法，当前启用的算法被[]括起来：\n$ cat /sys/block/zram0/comp_algorithm 压缩是一个时间换空间的操作，也就意味着这些压缩算法并不存在绝对优劣，只存在不同情况下的取舍，有的压缩率高、有的带宽大、有的 CPU 消耗少……在不同的硬件上，不同的选择也会遇到不同的瓶颈，因此只有进行真实的测试，才能帮助选择最适合的压缩算法。\n根据工作负载和需求的不同，读者可以选择适合自己的参数，也可以结合上面提到的多级 Swap，将 ZRAM 进一步分层，使用最高效的内存作为高优先级 Swap，压缩率最高的内存作为中低优先级 Swap。\n如果测试机和生产环境的架构/硬件存在差异，可以将测试过程中导出的内存拷贝到生产环境，前提是两者运行相同的工作负载，否则测试内存无参考价值。\n配置 ZRAM 调优参数 配置压缩算法，获得最佳压缩率\n首先将压缩算法从默认的lzo-rle切换为lz4hc，根据 ZRAM 的文档，只需要将压缩算法写入/sys/block/zram0/comp_algorithm即可，考虑到我们配置/sys/block/zram0/disksize时的操作，我们重新编辑/etc/udev/rules.d/99-zram.rules文件，将其内容修改为：\n$ sudo nano /etc/udev/rules.d/99-zram.rules KERNEL==\u0026#34;zram0\u0026#34;,ATTR{comp_algorithm}=\u0026#34;lz4hc\u0026#34;,ATTR{disksize}=\u0026#34;30G\u0026#34;,TAG+=\u0026#34;systemd\u0026#34; 需要注意的是，必须先指定压缩算法，再指定磁盘大小，无论是在配置文件中还是直接echo参数到/sys/block/zram0设备上，都需要按照文档的顺序进行操作。\n重启机器，再次执行cat /sys/block/zram0/comp_algorithm，就会发现当前压缩算法变成了lz4hc。\n配置 page-cluster，避免内存带宽和 CPU 资源的浪费\n简单来说，page-cluster的作用就是每次从交换设备读取数据时多读 2^n 页，一些块设备或文件系统有簇的概念，读取数据也是按簇读取，假设内存页大小为 4KiB，而每次读取的一簇数据为 32KiB，那么把多读出来的数据也换回内存，就能避免浪费，减少频繁读取磁盘的次数，这一点在 Linux 的文档中也有提到：linux/vm.rst · torvalds/linux。默认的page-cluster大小为 3，即每次会从磁盘读取4K*2^3=32K的数据。\n了解了page-cluster的原理后，我们会发现 ZRAM 并不属于传统的块设备，内存控制器默认设计就是按页读取，因此这一适用于磁盘设备的优化，在 ZRAM 场景下却是负优化，反而会导致过早触及内存带宽瓶颈和 CPU 解压缩瓶颈而导致性能下降，这也就可以解释为什么上面的表格中随着page-cluster的提升，吞吐量同样提升，而 IOPS 却变得更小，如果内存带宽和 CPU 解压缩不存在瓶颈，那么 IOPS 理论上应该保持不变。\n考虑到无论是理论上，还是实际测试，page-cluster都是一个多余的优化，我们可以直接将其设置为 0。直接编辑/etc/sysctl.d/99-sysctl.conf，在结尾新增一行：\n$ sudo nano /etc/sysctl.d/99-sysctl.conf vm.page-cluster=0 运行sysctl -p，即可让该设置生效，无需重启。\nOOM Killer SysRq SysRq （arch wiki）键在 QWERT 键盘上与 PrtSc 同键,通过按下 ALT+SysRq+\u0026lt;command key\u0026gt; 可以直接向linux kernel发送预设的系统操作指令。 这套组合键提供了一系列在系统崩溃时常用到的功能，比如同步数据、杀进程、卸载文件系统，甚至系统重启.\n启用SysRq 对内核的要求 启用 SysRq 的前提是在linux kernel编译时启用了 CONFIG_MAGIC_SYSRQ 选项.\n在目前主流的发行版linux中都启用了该选项，但若你是自己编译的内核，则有必要搜索一下内核的config文件了，确保里面有一句\nCONFIG_MAGIC_SYSRQ=y 内核中还有一个与SysRq相关的配置项:\nCONFIG_MAGIC_SYSRQ_DEFAULT_ENABLE=0x01b6 这个配置项指定了默认SysRq的值，这个值表示kernel会对哪些功能产生反应。\n查看当前SysRq的值 我们可以通过查看 /proc/sys/kernel/sysrq 的值来判断Kernel会对哪些功能产生反应.\n$ cat /proc/sys/kernel/sysrq 176 # Ubuntu 默认值 这里你会看到一个数字，这个数字可以转换成一个9位比特的形式，其中每一位的比特都有一个含义如下:\n   数字 位数 意义     0 1 完全禁用sysrq   1 1 允许所有的sysrq功能   2 2 允许控制终端日志级别   4 3 允许控制键盘输入类型(SAK,unraw)   8 4 允许调试进程dump   16 5 允许执行sync命令   32 6 允许重新挂载文件系统为之读   64 7 允许发送信号给进程(term,kill,oom-kill)   128 8 允许重启/关机   256 9 允许调整实时任务的优先级    因此，这里的 16 表示允许通过 SysRq 来同步数据到磁盘中去， 而数字 130 转换成二进制就是 010000010,根据表中的对应关系很容易看出允许重启/关机以及调整终端日志级别。\n更改SysRq的值 如果只是希望临时更改 SysRq 的值，那么很简单，只需要将新的值写入到 /proc/sys/kernel/sysrq 中去\n$ echo \u0026#34;1\u0026#34; |sudo tee /proc/sys/kernel/sysrq 或者通过 sysctl 来进行设置\n$ sysctl -w kernel.sysrq=1 如果需要每次启动时都自动修改SysRq的值，则需要修改配置文件\n$ echo \u0026#34;kernel.sysrq = 1\u0026#34; | sudo tee -a /etc/sysctl.d/99-sysctl.conf 使用SysRq 使用SysRq有两种方式:\n一种是直接通过键盘 Alt+SysRq+\u0026lt;command key\u0026gt;(部分笔记本上是Alt+Fn+PrtSrc+\u0026lt;command key\u0026gt;)来出发，\n还有一种是直接通过 /proc/sysrq-trigger 接口来完成.\n$ echo “ b ” | sudo tee /proc/sysrq-trigger 其中，这里每个 command-key 都对应一种kernel的行为，而且需要说明的是，不同种类的键盘上，相同kernel行为对应的 command-key 居然是不同的！\n下面表格就是各个kernel行为对应的 command-key 的说明:\n   Action QWERTY Dvorak AZERTY Colemak     设置控制台日志级别(console_loglevel),它决定了哪些kernel信息会被输出到控制台上 0 - 9 0 - 9 0 - 9(without ⇧ Shift) 0 - 9   不同步并卸载文件系统，立即重启系统 b x b b   让系统立即崩溃. 在配置得当的情况下会产生一个 crashdump c j c c   显示所有排它锁 (需要内核启用CONFIG_LOCKDEP选项) d e d s   发送 SIGTERM 信号到除了 init (PID 1) 外的所有进程 e . e f   触发 oom_kill, 会随机杀掉一个进程以缓解 OOM f u f t   当进入内核模式时，切换到内核的 framebuffer 控制台. 若有内核调试器 kdb，则进入该调试器中 g i g d   在控制台上输出一个简短的帮助信息. (其他不能识别的key也会输出帮助信息) h d h h   发送 SIGKILL 信号到除了 init (PID 1) 外的所有进程 i c i u   强制通过 FIFREEZE ioctl 冻结文件系统. j h j n   杀掉当前虚拟控制台中的所有进程 (包括 X 和 SVGALib 程序). k t k e   列出所有活动CPU上的 stack backtrace l n l i   在控制台上输出当前内存信息 m m , m   重置所有高优先级和实时任务的 nice 级别 n b n k   关闭系统 o r o y   在控制台输出当前寄存器和标志位信息 p l p ;   Display all active high-resolution timers and clock sources. q ' a q   将键盘从 raw 模式(常被诸如X11和SVGALib这样的程序所使用)切换到 XLATE模式 r p r p   同步所有已挂载的文件系统 s o s r   在控制台输出当前任务列表 t y t g   重新以只读模式重新挂载所有已挂载的文件系统 u g u l   强制恢复 framebuffer console. 若为ARM处理器,则会导致 ETM buffer dump. v k v v   显示所有阻塞状态(状态为D)的任务 w , z w   Used by xmon interface on PPC/PowerPC platforms. x q x x   显示全局的CPU寄存器内容 (仅对SPARC-64平台有效) y f y j   Dump the ftrace buffer z ; w z   输出一份简单的系统支持SysRq的键列表 space space space space    常见的几种功能键组合 下面列出几个常见的功能键组合:\nR-E-I-S-U-B:安全重启系统\n这套组合键大致相当于reboot命令：\n unRaw – 把键盘设置为 XLATE 模式，使按键可以穿透 x server 捕捉传递给内核 tErminate – 向除 init 外进程发送 SIGTERM 信号，让其自行结束. 这一步推荐等待30秒让进程有足够的时间进行收尾的嗯做。 kIll - 向除 init 以外所有进程发送 SIGKILL 信号，强制结束进程. 这一步推荐等待10秒，保证所有进程都退出了 Sync – 同步缓冲区数据到硬盘，避免数据丢失. 这一步在能看到输出的情况下等到\u0026quot;Emergency Sync complete\u0026quot; 后再做后续动作，否则推荐等待10秒 Unmount – 将所有已经挂载的文件系统 重新挂载为只读. 该操作通常也有一定延时,请等到\u0026quot;Emergency Remount complete\u0026quot; 出现过后再进行后续操作,否则推荐等待10秒 reBoot - 立即重启计算机  恢复系统挂起\n若仅仅是因为资源消耗过量引起系统挂起就重启系统显然是不好的，我们可以尝试通过回收一些资源的方式来回复系统挂起。\nSysRq中用来结束进程的command-key包括 E-I-K-F，其中:\n E 和 I 太凶残，它会杀掉除了 init 外的所有进程,属于杀敌一千自损八百的操作。因此在一般情况下不会轻易使用 F 则是利用 OOM-Kiler选择一个进程来结束,对于由于内存不足引起的挂起比较有效，但有时候OOMKiller也可能会误判杀掉一些长期运行的后台程序。 K 杀掉与当前控制台有关的进程组，比较推荐用这种方法回复系统  此外，若系统挂起是由于实时任务消耗太多CPU引起的，则可以通过 N 来降低实时任务运行的优先级来缓解挂起症状。\n获取系统信息\nSysRq还提供了几个用于获取系统信息的commandkey，在恢复系统挂起前推荐执行这些commandkey，以记录下当前系统状态。\n  M\n打印内存使用信息\n  W\n打印CPU寄存器上下文和程序调用栈回溯信息\n  P\n打印CPU寄存器信息,比如正在执行的进程名，运行函数，寄存器上下文，以及程序的调用栈回溯等\n  T\n打印进程列表,各进程的名称，进程 PID，父 PID 兄弟 PID 以及进程运行状态等相关信息\n  查看SysRq的输出信息 从上面的列表中我们可以看到，使用SysRq能够输出大量的信息。这些信息，默认会输出到syslog中. 同时，若设置的 console_loglevel(0-9) 大于 default_message_loglevel 则输出也会输出到本地控制台终端上去。 另外，若设置的 console_loglevel 大于 default_message_loglvel 则输出还会通过netconsole输出到远程机器上去。\n总体来说，syslog中记录的日志应该是最完整的，然而由于负责记录日志的 syslogd 本身是一个用户进程，在某些情况下可能会被杀掉，从而导致日志记录不下来。\n$ echo \u0026#34; \u0026#34; | sudo tee /proc/sysrq-trigger $ sudo dmesg | tail -n 1 [17899.255261] sysrq: SysRq : HELP : loglevel(0-9) reboot(b) crash(c) terminate-all-tasks(e) memory-full-oom-kill(f) kill-all-tasks(i) thaw-filesystems(j) sak(k) show-backtrace-all-active-cpus(l) show-memory-usage(m) nice-all-RT-tasks(n) poweroff(o) show-registers(p) show-all-timers(q) unraw(r) sync(s) show-task-states(t) unmount(u) force-fb(V) show-blocked-tasks(w) dump-ftrace-buffer(z) systemd-oomd.service 简介\nsystemd-oomd是为了改善Linux的内存不足/内存压力行为而开发的，基于Facebook的内存不足守护程序代码，已经扩展到不仅适用于Linux服务器，也适用于桌面系统。systemd-OOMD可以监测资源争用情况，当内存/SWAP压力超过预定义的阈值时，可以杀死选定的进程。\nsystemd-oomd守护进程会对启用了OOMD的cgroups进行监视，并根据内存压力或交换使用情况进行消杀。systemd-oomd行为可以通过新的oomd.conf配置文件进行配置。这个守护进程只有在设置了EnableOomdKill的情况下才会杀死组，因为显然不想因为内存使用情况而随机杀掉进程。\nEndeavourOS Usage $ sudo pacman -S fcitx5-im fcitx5-chinese-addons fcitx5-pinyin-zhwiki android-tools aria2 goldendict translate-shell kvantum google-chrome okular git xmind ttf-sarasa-gothic variety audacious fcitx5 详细看前面。\nKDE Connect $ sudo pacman -S kdeconnect sshfs Kdeconnectd\n$ cat /etc/xdg/autostart/org.kde.kdeconnect.daemon.desktop [Desktop Entry] Type=Application Exec=/usr/lib/x86_64-linux-gnu/libexec/kdeconnectd X-KDE-StartupNotify=false X-KDE-autostart-phase=1 X-KDE-Wayland-Interfaces=org_kde_kwin_fake_input X-GNOME-Autostart-enabled=true NoDisplay=true Icon=kdeconnect Name=KDE Connect 只有 KDE Connect 在连接的状态下，indicator 才会显示。\nZFS $ sudo pacman -S zfs-dkms $ sudo modprobe zfs $ echo zfs | sudo tee /etc/modules-load.d/zfs.conf Qemu $ sudo pacman -S qemu-base samba tigervnc plocate 依云推荐，a much faster locate\nZstd  arch 系用 zstd 打包 速度与压缩比如何兼得？压缩算法在构建部署中的优化：时间耗时的顺序为 Pzstd \u0026lt; ISA-L \u0026lt; Pigz \u0026lt; LZ4 \u0026lt; Zstd \u0026lt; Brotli \u0026lt; Gzip （排名越靠前越好） 参数命令  Redshift 安装：\n$ yay -S redshift-minimal 在 GeoNames.org 找到经纬度并测试：\n$ redshift -l 30.58333:114.26667 # WuHan 参考 How to get the display number I was assigned by X 获得 DISPLAY Number：\n$ echo $DISPLAY # OR $ cat /proc/$$/environ | tr \u0026#39;\\0\u0026#39; \u0026#39;\\n\u0026#39; | grep \u0026#39;^DISPLAY=\u0026#39; 参考 Redshift fails to run as systemd unit, works in terminal 建立 ~/.config/systemd/user/redshift.service 文件（官方给的模板不行）：\n[Unit] Description=Redshift display colour temperature adjustment Documentation=http://jonls.dk/redshift/ After=display-manager.service [Service] Environment=DISPLAY=:0 ExecStart=/usr/bin/redshift -l 30.58333:114.26667 Restart=always RestartSec=20 [Install] WantedBy=default.target 服务操作\n$ systemctl --user start redshift.service $ systemctl --user enable redshift.service $ journalctl --user -u redshift.service -f 字体调校 简介 很长时间以来，Linux上的中文字体呈现一直……不容乐观。但是随着 FreeType2 由于专利过期默认开启了高质量的 LCD 优化，以及一批高质量的开源字体的公布，Linux 上的中文字体渲染已经可以和 macOS 扳扳手腕了。\n当然，这里是 Linux，你需要一点小小的配置。\n现在，什么也不用做，打开一个中文页面，应该已经不会存在豆腐块了。Noto 字体家族正是得名于此。 Noto -\u0026gt; No Toufu -\u0026gt; 没有豆腐块。然而……看上去不大对劲，不是么？…怎么默认到日语字形上去了。这就是为什么我们需要 Fontconfig 。\nFontconfig 是一个用来 配置 字体渲染的程序。也就是说，fontconfig 本身没有将字体渲染成位图的能力，真正执行这个工作的是 FreeType，但是它能向程序提供可用字体列表并指导 FreeType 引擎将字体正确地渲染出来。\n常用命令 $ FC_DEBUG=4 google-chrome-stable # 看 FcConfigSubstitute donePattern 部分，这就是实际作用的字体 $ fc-match sans # 看请求 sans 字体实际返回的是什么字体  $ LANG=zh_CN.UTF-8 fc-match sans:lang=zh-cn # 看请求 sans 字体在zh实际返回的是什么字体  $ pacman -Qqo /usr/share/fonts # 查看安装了哪些字体 $ fc-list | grep Noto # 列出所有 Noto 字体 选字体 西文要求可以清晰区分\u0026quot;1lI\u0026quot;和\u0026quot;O0o\u0026quot;，当然等宽字体是必须可以区分了：\n 西文无衬线字体  Noto Sans：noto-fonts Ubuntu   西文有衬线字体  Noto Serif：noto-fonts Tinos：nerd-fonts-tinos   西文等宽字体：  Noto Sans Mono：noto-fonts Monaco： ttf-monaco Hack：ttf-hack Ubuntu Moon   中文无衬线字体  Noto Sans CJK SC： noto-fonts-cjk WenQuanYi Zen Hei：wqy-zenhei WenQuanYi Micro Hei： wqy-microhei HarmonyOS Sans SC：harmonyos-sans-git   中文有衬线字体  Noto Serif CJK SC Adobe Song Std：ttf-adobe-song 中文宋体(有衬线) Adobe Fangsong Std：ttf-adobe-fangsong 中文仿宋(有衬线) Adobe Kaiti Std：ttf-adobe-kaiti 中文楷体(书法)   中文等宽字体  Noto Sans Mono CJK SC WenQuanYi Zen Hei Mono   符号表情  Noto Color Emoji： noto-fonts-emoji Twemoji： ttf-twemoji   CJK 异形字  NotoSansCJK-Regular： noto-fonts-cjk NotoSerifCJK-Regular    Noto系列字体非常全，可用于追求一致的字体体验。还有 Adobe Source Hans 字体也很全，更多字体查看 Fonts。\n配置 以 《Linux字体美化实战(Fontconfig配置)》及fonts.conf 为蓝本，同时参考了如下部分配置文件：\n 双猫CC 字体顺序与异形字设置：《用 fontconfig 治理 Linux 中的字体》dotfiles 测试异形字（在firefox上） 喵\u0026rsquo;s StackHarbor的 Noto Color Emoji 设置：《Fontconfig 和 Noto Color Emoji 和抗锯齿》 local.conf Github 仓库《Linux字体美化实战》例子改版：best-fonts  基本思路：只有一个，设置默认字体为通用字体族名。设置完这个记得把所有软件的自定义字体设置里面无衬线设置为 sans-serif，有衬线设置为 serif，等宽设置为 monospace，这样才会遵守这里的回退顺序。\n建立 ~/.config/fontconfig/fonts.conf 并添加如下内容：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE fontconfig SYSTEM \u0026#34;fonts.dtd\u0026#34;\u0026gt; \u0026lt;fontconfig\u0026gt; \u0026lt;!-- ========================== 第三部分 扫描阶段 =================================== --\u0026gt; \u0026lt;!-- 规范化已安装核心字体的属性(西文字族名改为类名，中文字族名改为\u0026#34;zhXXX\u0026#34;，其他为\u0026#34;zzXXX\u0026#34;) --\u0026gt; \u0026lt;!-- English --\u0026gt; \u0026lt;!-- En Sans --\u0026gt; \u0026lt;match target=\u0026#34;scan\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Noto Sans\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Sans\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;langset\u0026gt; \u0026lt;string\u0026gt;en\u0026lt;/string\u0026gt; \u0026lt;/langset\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- En Serif --\u0026gt; \u0026lt;match target=\u0026#34;scan\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Noto Serif\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Serif\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;langset\u0026gt; \u0026lt;string\u0026gt;en\u0026lt;/string\u0026gt; \u0026lt;/langset\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- En Mono --\u0026gt; \u0026lt;match target=\u0026#34;scan\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Noto Sans Mono\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Monospace\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;langset\u0026gt; \u0026lt;string\u0026gt;en\u0026lt;/string\u0026gt; \u0026lt;/langset\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- Simplified Chinese --\u0026gt; \u0026lt;!-- ZH Sans --\u0026gt; \u0026lt;match target=\u0026#34;scan\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Noto Sans CJK SC\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zhSans\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;langset\u0026gt; \u0026lt;string\u0026gt;zh-cn\u0026lt;/string\u0026gt; \u0026lt;/langset\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- ZH Serif --\u0026gt; \u0026lt;match target=\u0026#34;scan\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Noto Serif CJK SC\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zhSerif\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;langset\u0026gt; \u0026lt;string\u0026gt;zh-cn\u0026lt;/string\u0026gt; \u0026lt;/langset\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- ZH Monospace --\u0026gt; \u0026lt;match target=\u0026#34;scan\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Noto Sans Mono CJK SC\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zhMonospace\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;langset\u0026gt; \u0026lt;string\u0026gt;zh-cn\u0026lt;/string\u0026gt; \u0026lt;/langset\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- Emoji --\u0026gt; \u0026lt;match target=\u0026#34;scan\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zzFailback\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;zzSymbol\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;familylang\u0026#34;\u0026gt; \u0026lt;string\u0026gt;en\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;en\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;style\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Regular\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;langset\u0026gt; \u0026lt;string\u0026gt;none\u0026lt;/string\u0026gt; \u0026lt;/langset\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- CJK(Chinese Japanese Korean)，作为中文下的备用字体 --\u0026gt; \u0026lt;!-- postscriptname 就是字体文件名，这样可以包括所有 SC/TC/HK/JP/KR 字体 --\u0026gt; \u0026lt;!-- Sans CJK --\u0026gt; \u0026lt;match target=\u0026#34;scan\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;postscriptname\u0026#34;\u0026gt; \u0026lt;string\u0026gt;NotoSansCJK-Regular\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zzFailback\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;zzSnasCJK\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;familylang\u0026#34;\u0026gt; \u0026lt;string\u0026gt;en\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;en\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;style\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Regular\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;langset\u0026gt; \u0026lt;string\u0026gt;zh-cn\u0026lt;/string\u0026gt; \u0026lt;/langset\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- Serif CJK --\u0026gt; \u0026lt;match target=\u0026#34;scan\u0026#34;\u0026gt; \u0026lt;!-- postscriptname 就是字体文件名 --\u0026gt; \u0026lt;test name=\u0026#34;postscriptname\u0026#34;\u0026gt; \u0026lt;string\u0026gt;NotoSerifCJK-Regular\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zzFailback\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;zzSerifCJK\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;familylang\u0026#34;\u0026gt; \u0026lt;string\u0026gt;en\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;en\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;style\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Regular\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;langset\u0026gt; \u0026lt;string\u0026gt;zh-cn\u0026lt;/string\u0026gt; \u0026lt;/langset\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- ========================== 第四部分 匹配阶段 =================================== --\u0026gt; \u0026lt;!-- 第一步，替换所有未安装的常见字体：西文替换为对应的字体类，中文替换为\u0026#34;西文字体类+zhXXX\u0026#34;，保持原有绑定不变 --\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;mono\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Consolas\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Courier\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Courier New\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Fixedsys\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Lucida Console\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Terminal\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Lucida Sans Typewriter\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Andale Mono\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Menlo\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Monaco\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Andale Mono WT\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Biwidth\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Bitstream Vera Sans Mono\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Cousine\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;DejaVu Sans Mono\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Droid Sans Mono\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Fira Mono\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Fixed\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;FreeMono\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Inconsolata\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Liberation Mono\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Luxi Mono\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Nimbus Mono L\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Source Code Pro\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Terminus\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Ubuntu Mono\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Unibit\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Unifont\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;sans serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;sans-serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Arial\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Arial Black\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Calibri\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Candara\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Century Gothic\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Copperplate Gothic\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Corbel\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Franklin Gothic Medium\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Impact\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Lucida Sans Unicode\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Microsoft Sans Serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;MS Sans Serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;News Gothic MT\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Segoe\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Segoe UI\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Tahoma\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Trebuchet MS\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Verdana\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Arial Narrow\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Arial Unicode MS\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Franklin Gothic Bold\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Franklin Gothic Heavy\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Gill Sans MT\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Haettenschweiler\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Lucida Sans\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Tw Cen MT\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Avenir\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Avenir Next\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Avenir Next Condensed\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Charcoal\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Chicago\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Futura\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Geneva\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Gill Sans\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Helvetica\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Helvetica Neue\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Lucida Grande\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Optima\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Thonburi\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Andika\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Akzidenz-Grotesk\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Arev Sans\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Arimo\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Bitstream Vera Sans\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Cantarell\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Carlito\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;DejaVu Sans\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;DejaVu Sans Condensed\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Droid Sans\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Droid Sans Fallback\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Fira Sans\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;FreeSans\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Frutiger\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Frutiger Linotype\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Gadget\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Gotham\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Liberation Sans\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Liberation Sans Narrow\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Linux Biolinum\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Luxi Sans\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Myriad\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Myriad Pro\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Nimbus Sans L\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Noto Sans\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Noto Sans UI\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Open Sans\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Roboto\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Roboto Condensed\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Source Sans Pro\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Ubuntu\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Ubuntu Condensed\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Univers\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Book Antiqua\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Calisto MT\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Cambria\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Constantia\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Gabriola\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Georgia\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;MS Serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Palatino Linotype\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Sitka\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Sitka Banner\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Sitka Display\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Sitka Heading\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Sitka Small\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Sitka Subheading\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Sitka Text\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Times New Roman\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Baskerville Old Face\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Bell MT\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Bodoni MT\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Bookman Old Style\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Californian FB\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Centaur\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Century\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Century Schoolbook\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Cooper Black\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Elephant\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Garamond\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Goudy Old Style\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;High Tower Text\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Lucida Bright\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Lucida Fax\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Perpetua\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Rockwell\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Baskerville\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Big Caslon\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Didot\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Hoefler Text\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;New York\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Palatino\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Times\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Bitstream Charter\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Bitstream CyberBase\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Bitstream Cyberbit\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Bitstream Vera Serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Century Schoolbook L\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Charis SIL\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Code2000\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Code2001\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;DejaVu Serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;DejaVu Serif Condensed\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Droid Serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;FreeSerif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Gentium\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Junicode\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Liberation Serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Linux Libertine\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Luxi Serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;New Athena Unicode\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Nimbus Roman No9 L\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Noto Serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Old Standard TT\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Source Serif Pro\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Tinos\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Utopia\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Source Han Sans\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Source Han Sans CN\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Source Han Sans SC\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Source Han Sans TC\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Source Han Sans TWHK\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;思源黑体\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;思源黑體\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;思源黑体 CN\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;思源黑體 TWHK\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK Simplified Chinese\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK Traditional Chinese\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Noto Sans S Chinese\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Noto Sans T Chinese\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Hiragino Sans GB\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;冬青黑體簡體中文\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;冬青黑体简体中文\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Adobe Heiti Std\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Adobe 黑体 Std\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Adobe Fan Heiti Std\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Adobe 繁黑體 Std\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Hei\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;LiHei Pro\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;STHeiti\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;SimHei\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;黑体\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Heiti TC\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;黑體-繁\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;黑体-繁\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Heiti SC\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;黑體-簡\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;黑体-简\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;STXihei\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;华文细黑\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Lantinghei SC\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;蘭亭黑-簡\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;兰亭黑-简\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Lantinghei TC\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;蘭亭黑-繁\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;兰亭黑-繁\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Microsoft JhengHei\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Microsoft JhengHei UI\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;微軟正黑體\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Microsoft YaHei\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Microsoft YaHei UI\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;微软雅黑\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;WenQuanYi Bitmap Song\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;WenQuanYi Zen Hei\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文泉驛微米黑\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文泉驿微米黑\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;WenQuanYi Zen Hei Mono\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文泉驛等寬微米黑\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文泉驿等宽微米黑\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;WenQuanYi Zen Hei\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文泉驛正黑\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文泉驿正黑\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;WenQuanYi Zen Hei Mono\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文泉驛等寬正黑\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文泉驿等宽正黑\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;WenQuanYi Zen Hei Sharp\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文泉驛點陣正黑\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文泉驿点阵正黑\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSans\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Adobe Song Std\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Adobe 宋体 Std\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Adobe Ming Std\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Adobe 明體 Std\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;AR PL UMing CN\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;AR PL UMing HK\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;AR PL UMing TW\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;AR PL UMing TW MBE\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Apple LiSung\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;GB18030 Bitmap\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;LiSong Pro\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Ming(for ISO10646)\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;STSong\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;华文宋体\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;STZhongsong\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;华文中宋\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;SimSun\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;宋体\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;NSimSun\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;新宋体\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;SimSun-ExtB\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;SimSun-18030\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;宋体-18030\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;NSimSun-18030\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;新宋体-18030\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Songti SC\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;宋體-簡\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;宋体-简\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Songti TC\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;宋體-繁\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;宋体-繁\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;AR PLBaosong2GBK Light\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文鼎ＰＬ报宋二GBK\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;AR PL SungtiL GB\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文鼎ＰＬ简报宋\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;AR PLMingU20 Light\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文鼎ＰＬ明體U20-L\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;AR PL Mingti2L Big5\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文鼎ＰＬ細上海宋\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;AR PL ShanHeiSun Uni\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文鼎PL细上海宋Uni\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文鼎PL細上海宋Uni\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;AR PL New Sung\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文鼎ＰＬ新宋\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;AR PL New Sung Mono\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文鼎ＰＬ新宋 Mono\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;MingLiU\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;細明體\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;MingLiU-ExtB\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;細明體-ExtB\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;PMingLiU\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;新細明體\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;PMingLiU-ExtB\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;新細明體-ExtB\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;MingLiU_HKSCS\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;細明體_HKSCS\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;MingLiU_HKSCS-ExtB\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;細明體_HKSCS-ExtB\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Adobe Fangsong Std\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Adobe 仿宋 Std\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;FangSong_GB2312\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;仿宋_GB2312\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;FangSong\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;仿宋\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;STFangsong\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;华文仿宋\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Adobe Kaiti Std\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Adobe 楷体 Std\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;AR PL UKai CN\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;AR PL UKai HK\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;AR PL UKai TW\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;AR PL UKai TW MBE\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;BiauKai\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Kai\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;DFKai-SB\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;標楷體\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;STKaiti\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;华文楷体\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;KaiTi\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;楷体\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Kaiti SC\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;楷體-簡\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;楷体-简\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;Kaiti TC\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;楷體-繁\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;楷体-繁\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;SimKai\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;KaiTi_GB2312\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;楷体_GB2312\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;AR PL KaitiM GB\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文鼎ＰＬ简中楷\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;AR PL New Kai\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文鼎ＰＬ新中楷\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;AR PL KaitiM Big5\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文鼎ＰＬ中楷\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Monospace\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;AR PL ZenKai Uni\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias binding=\u0026#34;same\u0026#34;\u0026gt; \u0026lt;family\u0026gt;文鼎PL中楷Uni\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;zhSerif\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;!-- 设置其他属性 --\u0026gt; \u0026lt;match\u0026gt; \u0026lt;!-- 设置合理的像素密度，确保pt与px之间能够合理转换 --\u0026gt; \u0026lt;edit name=\u0026#34;dpi\u0026#34;\u0026gt; \u0026lt;double\u0026gt;96\u0026lt;/double\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;!-- 设置等宽标记 --\u0026gt; \u0026lt;edit name=\u0026#34;isDengKuan\u0026#34;\u0026gt; \u0026lt;eq\u0026gt; \u0026lt;name\u0026gt;family\u0026lt;/name\u0026gt; \u0026lt;string\u0026gt;Monospace\u0026lt;/string\u0026gt; \u0026lt;/eq\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- 设置字体优先级 --\u0026gt; \u0026lt;!-- Default system-ui fonts --\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;system-ui\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;prepend\u0026#34; binding=\u0026#34;strong\u0026#34;\u0026gt; \u0026lt;string\u0026gt;sans-serif\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- Default sans-serif fonts--\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;sans-serif\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;prepend\u0026#34; binding=\u0026#34;strong\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Sans\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;zhSans\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;zzFailback\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- Default serif fonts--\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;serif\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;prepend\u0026#34; binding=\u0026#34;strong\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Serif\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;zhSerif\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;zzFailback\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- Default monospace fonts--\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;monospace\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;prepend\u0026#34; binding=\u0026#34;strong\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Monospace\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;zhMonospace\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;zzFailback\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- 默认 emoji 字体。 --\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34; qual=\u0026#34;any\u0026#34;\u0026gt; \u0026lt;string\u0026gt;emoji\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;prepend\u0026#34; binding=\u0026#34;strong\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zzSymbol\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- 解决异体字，让 Noto CJK 在不同语言下采用不同的汉字变体。 --\u0026gt; \u0026lt;!-- zh-HK Sans --\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zh-HK\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zhSans\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; binding=\u0026#34;strong\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Noto Sans CJK HK\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- zh-HK Serif --\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zh-HK\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zhSerif\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; binding=\u0026#34;strong\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Noto Serif CJK HK\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- zh-HK Monospace --\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zh-HK\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zhMonospace\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; binding=\u0026#34;strong\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Noto Sans Mono CJK HK\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- zh-TW Sans --\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zh-TW\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zhSans\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; binding=\u0026#34;strong\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Noto Sans CJK TC\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- zh-TW Serif --\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zh-TW\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zhSerif\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; binding=\u0026#34;strong\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Noto Serif CJK TC\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- zh-TW Monospace --\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zh-TW\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zhMonospace\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; binding=\u0026#34;strong\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Noto Sans Mono CJK TC\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- ja Sans --\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;string\u0026gt;ja\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zhSans\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; binding=\u0026#34;strong\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Noto Sans CJK JP\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- ja Serif --\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;string\u0026gt;ja\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zhSerif\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; binding=\u0026#34;strong\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Noto Serif CJK JP\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- ja Monospace --\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;string\u0026gt;ja\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zhMonospace\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; binding=\u0026#34;strong\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Noto Sans Mono CJK JP\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- ko Sans --\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;string\u0026gt;ko\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zhSans\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; binding=\u0026#34;strong\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Noto Sans CJK KR\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- ko Serif --\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;string\u0026gt;ko\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zhSerif\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; binding=\u0026#34;strong\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Noto Serif CJK KR\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- ko Monospace --\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;lang\u0026#34;\u0026gt; \u0026lt;string\u0026gt;ko\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;zhMonospace\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; binding=\u0026#34;strong\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Noto Sans Mono CJK KR\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- ========================== 第五部分 渲染阶段 =================================== --\u0026gt; \u0026lt;!-- 第一步，设置默认的渲染参数 --\u0026gt; \u0026lt;match target=\u0026#34;font\u0026#34;\u0026gt; \u0026lt;!-- 修整像素大小(小于10px的调整到10px，否则四舍五入到整数) --\u0026gt; \u0026lt;edit name=\u0026#34;pixelsize\u0026#34;\u0026gt; \u0026lt;if\u0026gt; \u0026lt;less\u0026gt; \u0026lt;name\u0026gt;pixelsize\u0026lt;/name\u0026gt; \u0026lt;double\u0026gt;10\u0026lt;/double\u0026gt; \u0026lt;/less\u0026gt; \u0026lt;int\u0026gt;10\u0026lt;/int\u0026gt; \u0026lt;round\u0026gt; \u0026lt;name\u0026gt;pixelsize\u0026lt;/name\u0026gt; \u0026lt;/round\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;!-- 开启抗锯齿(smooth) --\u0026gt; \u0026lt;!-- 除非你的屏幕DPI奇高否则建议开启. --\u0026gt; \u0026lt;edit name=\u0026#34;antialias\u0026#34;\u0026gt; \u0026lt;bool\u0026gt;true\u0026lt;/bool\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;!-- 优先使用内嵌微调，同时默认开足微调 --\u0026gt; \u0026lt;!-- 字体微调的程度, 可选为 hintnone, hintslight (默认), hintmedium, hintfull. --\u0026gt; \u0026lt;!-- 简单来说，更高的 hinting 等级可以使字体更锐利，但同时也会损失更多的细节. --\u0026gt; \u0026lt;!-- 如果你的显示器的 DPI 高得不像话 (\u0026gt;=300), 那么就可以关闭 hinting, 因为字体会自然对齐像素. --\u0026gt; \u0026lt;edit name=\u0026#34;hinting\u0026#34;\u0026gt; \u0026lt;bool\u0026gt;true\u0026lt;/bool\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;autohint\u0026#34;\u0026gt; \u0026lt;bool\u0026gt;false\u0026lt;/bool\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;hintstyle\u0026#34;\u0026gt; \u0026lt;const\u0026gt;hintslight\u0026lt;/const\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;!-- LCD特征设置 --\u0026gt; \u0026lt;!-- rgba 是显示器使用的像素排列方式. 现代显示器基本都是用rgb排列 --\u0026gt; \u0026lt;!-- 关于lcdfilter, 因为我们在使用 FreeType2 自带的 Harmony 子像素渲染, 应该是不需要设置的. --\u0026gt; \u0026lt;edit name=\u0026#34;rgba\u0026#34;\u0026gt; \u0026lt;const\u0026gt;rgb\u0026lt;/const\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;lcdfilter\u0026#34;\u0026gt; \u0026lt;const\u0026gt;lcddefault\u0026lt;/const\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;!-- 禁用内嵌点阵 --\u0026gt; \u0026lt;edit name=\u0026#34;embeddedbitmap\u0026#34;\u0026gt; \u0026lt;bool\u0026gt;false\u0026lt;/bool\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;!-- 禁用合成粗体 --\u0026gt; \u0026lt;edit name=\u0026#34;embolden\u0026#34;\u0026gt; \u0026lt;bool\u0026gt;false\u0026lt;/bool\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- 第二步，为没有原生斜体的字体使用合成斜体 --\u0026gt; \u0026lt;match target=\u0026#34;font\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;slant\u0026#34; compare=\u0026#34;eq\u0026#34;\u0026gt; \u0026lt;const\u0026gt;roman\u0026lt;/const\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;test name=\u0026#34;slant\u0026#34; compare=\u0026#34;not_eq\u0026#34; target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;const\u0026gt;roman\u0026lt;/const\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;slant\u0026#34;\u0026gt; \u0026lt;const\u0026gt;oblique\u0026lt;/const\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;matrix\u0026#34;\u0026gt; \u0026lt;times\u0026gt; \u0026lt;name\u0026gt;matrix\u0026lt;/name\u0026gt; \u0026lt;matrix\u0026gt; \u0026lt;double\u0026gt;1\u0026lt;/double\u0026gt; \u0026lt;double\u0026gt;0.2\u0026lt;/double\u0026gt; \u0026lt;double\u0026gt;0\u0026lt;/double\u0026gt; \u0026lt;double\u0026gt;1\u0026lt;/double\u0026gt; \u0026lt;/matrix\u0026gt; \u0026lt;/times\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- 第三步，为没有原生粗体的字体使用合成粗体 --\u0026gt; \u0026lt;match target=\u0026#34;font\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;weight\u0026#34; compare=\u0026#34;less\u0026#34;\u0026gt; \u0026lt;int\u0026gt;105\u0026lt;/int\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;test name=\u0026#34;weight\u0026#34; compare=\u0026#34;more\u0026#34; target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;int\u0026gt;105\u0026lt;/int\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;weight\u0026#34;\u0026gt; \u0026lt;const\u0026gt;bold\u0026lt;/const\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;embolden\u0026#34;\u0026gt; \u0026lt;bool\u0026gt;true\u0026lt;/bool\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- 第四步，标记\u0026#34;视觉大小\u0026#34;(原本的标称值)是否为奇数，为接下来修正等宽条件下的\u0026#34;标称大小\u0026#34;做准备 --\u0026gt; \u0026lt;match target=\u0026#34;font\u0026#34;\u0026gt; \u0026lt;edit name=\u0026#34;isOddPx\u0026#34;\u0026gt; \u0026lt;eq\u0026gt; \u0026lt;round\u0026gt; \u0026lt;divide\u0026gt; \u0026lt;plus\u0026gt; \u0026lt;name\u0026gt;pixelsize\u0026lt;/name\u0026gt; \u0026lt;double\u0026gt;0.5\u0026lt;/double\u0026gt; \u0026lt;/plus\u0026gt; \u0026lt;double\u0026gt;2\u0026lt;/double\u0026gt; \u0026lt;/divide\u0026gt; \u0026lt;/round\u0026gt; \u0026lt;ceil\u0026gt; \u0026lt;divide\u0026gt; \u0026lt;plus\u0026gt; \u0026lt;name\u0026gt;pixelsize\u0026lt;/name\u0026gt; \u0026lt;double\u0026gt;0.5\u0026lt;/double\u0026gt; \u0026lt;/plus\u0026gt; \u0026lt;double\u0026gt;2\u0026lt;/double\u0026gt; \u0026lt;/divide\u0026gt; \u0026lt;/ceil\u0026gt; \u0026lt;/eq\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- 第五步，修正合成粗体的\u0026#34;标称大小\u0026#34;，尽力确保其\u0026#34;视觉大小\u0026#34;与原本的标称值一致 --\u0026gt; \u0026lt;match target=\u0026#34;font\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;embolden\u0026#34;\u0026gt; \u0026lt;bool\u0026gt;true\u0026lt;/bool\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;!-- 标称大小=视觉大小-trunc((视觉大小+13.5)/25) --\u0026gt; \u0026lt;edit name=\u0026#34;pixelsize\u0026#34;\u0026gt; \u0026lt;minus\u0026gt; \u0026lt;name\u0026gt;pixelsize\u0026lt;/name\u0026gt; \u0026lt;trunc\u0026gt; \u0026lt;divide\u0026gt; \u0026lt;plus\u0026gt; \u0026lt;name\u0026gt;pixelsize\u0026lt;/name\u0026gt; \u0026lt;double\u0026gt;13.5\u0026lt;/double\u0026gt; \u0026lt;/plus\u0026gt; \u0026lt;double\u0026gt;25\u0026lt;/double\u0026gt; \u0026lt;/divide\u0026gt; \u0026lt;/trunc\u0026gt; \u0026lt;/minus\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- 第六步，在等宽条件下，为确保中西文对齐，进一步修正\u0026#34;标称大小\u0026#34;(也会影响\u0026#34;视觉大小\u0026#34;) --\u0026gt; \u0026lt;match target=\u0026#34;font\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;isDengKuan\u0026#34;\u0026gt; \u0026lt;bool\u0026gt;true\u0026lt;/bool\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;!-- 如果\u0026#34;视觉大小\u0026#34;是奇数 --\u0026gt; \u0026lt;test name=\u0026#34;isOddPx\u0026#34;\u0026gt; \u0026lt;bool\u0026gt;true\u0026lt;/bool\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;!-- 那么上调为偶像素，因为Monospace在奇像素下总是大一级显示 --\u0026gt; \u0026lt;edit name=\u0026#34;pixelsize\u0026#34;\u0026gt; \u0026lt;plus\u0026gt; \u0026lt;name\u0026gt;pixelsize\u0026lt;/name\u0026gt; \u0026lt;int\u0026gt;1\u0026lt;/int\u0026gt; \u0026lt;/plus\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- 第六步续，进一步专门处理等宽条件下\u0026#34;标称大小\u0026#34;为11px,12px的合成粗体 --\u0026gt; \u0026lt;match target=\u0026#34;font\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;isDengKuan\u0026#34;\u0026gt; \u0026lt;bool\u0026gt;true\u0026lt;/bool\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;test name=\u0026#34;embolden\u0026#34;\u0026gt; \u0026lt;bool\u0026gt;true\u0026lt;/bool\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;test name=\u0026#34;pixelsize\u0026#34; compare=\u0026#34;more\u0026#34;\u0026gt; \u0026lt;double\u0026gt;10.5\u0026lt;/double\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;test name=\u0026#34;pixelsize\u0026#34; compare=\u0026#34;less\u0026#34;\u0026gt; \u0026lt;double\u0026gt;12.5\u0026lt;/double\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;!-- 统一调整为12px常规体，只有这样才能对齐 --\u0026gt; \u0026lt;edit name=\u0026#34;pixelsize\u0026#34;\u0026gt; \u0026lt;int\u0026gt;12\u0026lt;/int\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;embolden\u0026#34;\u0026gt; \u0026lt;bool\u0026gt;false\u0026lt;/bool\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;weight\u0026#34;\u0026gt; \u0026lt;int\u0026gt;80\u0026lt;/int\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- 最后，删除等宽标记与奇偶标记 --\u0026gt; \u0026lt;match target=\u0026#34;font\u0026#34;\u0026gt; \u0026lt;edit name=\u0026#34;isDengKuan\u0026#34; mode=\u0026#34;delete\u0026#34;\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;edit name=\u0026#34;isOddPx\u0026#34; mode=\u0026#34;delete\u0026#34;\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;/fontconfig\u0026gt; 注意：配置完成后，请运行 fc-cache -fv 并重新登陆。\n这个配置文件的特点在于，好像在写代码，它将 sans 等通用字体名当作变量，更换字体只需要改第一部分就可以了。同时使用 isDengKuan 引入了条件逻辑，非常巧妙。\n我删除了参考配置中所有有关某特定程序（浏览器）的设置，个人认为没有必要。\n流程：\n  在 scan 阶段，将自己选用的英文字体名称重命名为通用字体名称，将需要用的其他字体做类似操作。\n  在 patten 阶段，将匹配的字体的返回结果替换为通用字体名称。如果这里没有涵盖所有系统已安装的字体，会返回该字体原名称，可能导致最终结果不符合预期，因为通用字体的优先级比常用字体优先级低。例如在 Ubuntu 上我就遇到这个问题，毕竟 Ubuntu 默认安装非常全的字体。\n  在 font 阶段，修改渲染参数，设置 fontfeatures。Font configuration/Examples 有例子如何关闭 fontfeatures，例如关闭等宽字体Monaco的连字功能：\n\u0026lt;match target=\u0026#34;font\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34; qual=\u0026#34;any\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Monaco\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;fontfeatures\u0026#34; mode=\u0026#34;append\u0026#34;\u0026gt; \u0026lt;string\u0026gt;liga off\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;dlig off\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt;   DPI DPI 即为 Dots per inch (每英尺点数), 可简单理解为显示器的像素密度。 由于在较低的像素密度下, 字形无法严格对齐像素格, 我们必须通过 hinting 和 antialias (抗锯齿) 让字形在较低DPI的屏幕上有较好的观感。为了得到你的显示器的具体 DPI 数值, 可以使用 DPI Calculator 。或者按如下操作：\nFind the DPI value for your screen\n$ xdpyinfo | grep -B 2 resolution screen #0: dimensions: 1366x768 pixels (340x191 millimeters) resolution: 96x96 dots per inch How to calculate the right DPI value\n  Get your screen size in millimeters by running the command:\n$ xrandr | grep -w connected eDP1 connected primary 1366x768+0+0 (normal left inverted right x axis y axis) 340mm x 190mm   Convert it to centimeters. My values are 34 x 19.\n  Convert centimeters to inches. Divide the values by 2.54. In my case, the values are as follows: 13.39in x 7.48in.\n  Finally, divide your screen resolution values by inch values. In my case, the values are as follows: 1366/13.39 = 102.016430=~102. 768/7.48 = 102.673796=~102.\n  How to change the DPI value\n  No desktop environment/barebones window manager\n$ vi ~/.Xresources Xft.dpi: 102 If your .Xresources file is not processed, add the following line to your startup file (e.g. .xinitrc or some window manager-specific file)\nxrdb -merge ~/.Xresources   Xfce\nThe DPI can be set to what you want under Settings - Appearance - Font.\n  其他   XFCE 全局：Settings =\u0026gt; Appearance =\u0026gt; Fonts，Font 设置为 Sans Regular 和 Monospace Regular。然后 Hinting 设置为 Slight，DPI 设置为 102。之所以重复设置，是因为这里的设置会覆盖 fontconfig 的设置，fontconfig 大约在只有 WM 下才能设置一切吧。之前设置 Hinting 为 Full，结果 Hinting 过重导致 Telegram 英文字符间距不太均匀\n  xed：Edit =\u0026gt; Preference =\u0026gt; Font，设置为 Monospace Regular，字号 10。\n  Google Chrome 中的字体设置：用户要想 Google Chrome 听点话，需要在「设置」-\u0026gt;「外观」-\u0026gt;「自定义字体」里设置为 sans，serif，sans，monospace\n  Emoji 简介：它是一个日语词，e表示\u0026quot;絵\u0026quot;，moji表示\u0026quot;文字\u0026quot;。连在一起，就是\u0026quot;絵文字\u0026quot;。Unicode 只是规定了 Emoji 的码点和含义，并没有规定它的样式。举例来说，码点U+1F600表示一张微笑的脸，但是这张脸长什么样，则由各个系统自己实现。\n  Typora: Preferences =\u0026gt; Open Advanced Settings\n  Xfce Terminal: Settings =\u0026gt; Xfce Terminal Settings =\u0026gt; Appearance =\u0026gt; Use system font\n  苹果字体：\n Meslo LG S（更接近 Apple 的 Menlo）：ttf-meslo SF Pro \u0026amp; New York：apple-fonts PingFang SC：ttf-pingfang-git(SC) Apple Color Emoji：ttf-apple-emoji    analyze font files: only support OpenType fonts.\n$ sudo pacman -S lcdf-typetools $ otfinfo --info *.ttf | grep Subfamily   Preview Fonts：真的只能查看，把字体预览转成图片，不能看字体的 metadata，没什么用的。\n$ pacman -S fontpreview $ fontpreview /path/of/fonts   有一些比较老的程序会忽略 Fontconfig 的设置，需要修改 Xresources。 ArchWiki 上提供的事例配置应该足够了。\n  Bluetooth $ pacman -S bluez bluez-utils $ lsmod | grep btusb $ sudo systemctl enable --now bluetooth.service $ sudo usermod -a -G lp kurome # re-login 要自动化 bluetoothctl 命令，使用 echo -e \u0026quot;command1\\ncommand2\\n\u0026quot; | bluetoothctl\n运行 bluetoothctl 交互命令。输入 help 来获取帮助。\n （可选操作）使用 select MAC_address 选择一个默认的蓝牙接收器。 使用命令 power on 打开蓝牙。蓝牙默认是关闭的，并且重启之后默认也会关闭。 使用命令 devices 获得要配对的设备的 MAC 地址。 如果设备没有出现在上一步的列表中，使用命令 scan on 去搜索发现所有可配对的设备。 使用命令 agent on 打开代理或者选择一个特定的代理：如果在 agent 命令后按下两次 tab 键，应该就能看到可用代理的列表。蓝牙代理用于管理蓝牙“配对码”。它可以回复外部发来的“配对码”，也可以主动发送。大部分情况下使用 default-agent 应该就足够了。 使用命令 pair MAC_address 配对设备（可用 tab 键补全 MAC 地址）。 如果配对设备不需要 PIN，那么你可能需要手动将设备添加到信任列表。使用命令 trust MAC_address。 使用命令 connect MAC_address 建立连接。  最后，音频输出选择蓝牙耳机。\n屏蔽网站 可以不需要插件的 一种简单的方式直接在 hosts 文件中添加一条记录即可\n$ sudo vim /etc/hosts # forbidden website  # 127.0.0.1 后面的网站可以替换成自己想要禁止访问的网页 127.0.0.1 www.csdn.net 但是上面依旧会显示在搜索结果中，同理 uBlock 等，只是无法访问，我想要的是不出现在搜索结果中，比如uBlacklist插件符合需求：\n*://www.csdn.net/* *://its401.com/* KolourPaint KDE 下免费、快速的图像编辑器，与Windows 7系统之前微软画图软件相似，但是添加了一些如支持透明度等的新特征。\npackages out-of-date First, you should flag the package out-of-date indicating details on why the package is outdated, preferably including links to the release announcement or the new release tarball.\nYou should also try to reach out to the maintainer directly by email. If there is no response from the maintainer after two weeks, you can file an orphan request.\nzbar Command-line QR-code decode: zbarimg\n$ yay -S zbar $ zbarimg \u0026#34;image-file-name.jpg\u0026#34; zsh 安装 zfs\n$ sudo pacman -S zsh zsh-autosuggestions zsh-syntax-highlighting zsh-completions autojump $ chsh -l # 查看安装了哪些 Shell $ chsh -s /usr/bin/zsh # 修改当前账户的默认 Shell $ nano ~/.zshrc # 让插件生效 # Plugin source /usr/share/zsh/plugins/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh source /usr/share/zsh/plugins/zsh-autosuggestions/zsh-autosuggestions.zsh source /usr/share/autojump/autojump.zsh  zsh-autosuggestions —— 命令自动补全插件 zsh-syntax-highlighting —— 语法上高亮插件 zsh-completions —— 补充补全定义 autojump —— 一种更快的文件系统导航方式  可能需要：\n 将在 ~/.bash_profile 所做的配置复制到 ~/.zsh_profile 将在 ~/.bashrc 所做的配置复制到 ~/.zshrc  安装 powerlevel10k\n$ git clone --depth=1 https://github.com/romkatv/powerlevel10k.git ~/.powerlevel10k $ echo \u0026#39;source ~/.powerlevel10k/powerlevel10k.zsh-theme\u0026#39; \u0026gt;\u0026gt; ~/.zshrc powerlevel10k 中包含许多特殊图标符号，需要与之兼容的字体。\n.zshrc\n# Enable Powerlevel10k instant prompt. Should stay close to the top of ~/.zshrc. # Initialization code that may require console input (password prompts, [y/n] # confirmations, etc.) must go above this block; everything else may go below. if [[ -r \u0026#34;${XDG_CACHE_HOME:-$HOME/.cache}/p10k-instant-prompt-${(%):-%n}.zsh\u0026#34; ]]; then source \u0026#34;${XDG_CACHE_HOME:-$HOME/.cache}/p10k-instant-prompt-${(%):-%n}.zsh\u0026#34; fi # Lines configured by zsh-newuser-install HISTFILE=~/.histfile HISTSIZE=1000 SAVEHIST=1000 bindkey -e # End of lines configured by zsh-newuser-install # The following lines were added by compinstall zstyle :compinstall filename \u0026#39;/home/kurome/.zshrc\u0026#39; autoload -Uz compinit compinit # End of lines added by compinstall # Plugin source /usr/share/zsh/plugins/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh source /usr/share/zsh/plugins/zsh-autosuggestions/zsh-autosuggestions.zsh source /usr/share/autojump/autojump.zsh # CUSTOM BEGIN ## User specific environment export PATH=\u0026#34;$HOME/.local/bin:$PATH\u0026#34; ## Alias alias lsptu=\u0026#34;lsof -i | grep -i listen\u0026#34; alias ls=\u0026#39;ls --color=auto\u0026#39; alias ll=\u0026#39;ls -lav --ignore=..\u0026#39; # show long listing of all except \u0026#34;..\u0026#34; alias l=\u0026#39;ls -lav --ignore=.?*\u0026#39; # show long listing but no hidden dotfiles except \u0026#34;.\u0026#34; # CUSTOM END source ~/.powerlevel10k/powerlevel10k.zsh-theme # To customize prompt, run `p10k configure` or edit ~/.p10k.zsh. [[ ! -f ~/.p10k.zsh ]] || source ~/.p10k.zsh 默认的 .bashrc\n# # ~/.bashrc # # If not running interactively, don\u0026#39;t do anything [[ $- != *i* ]] \u0026amp;\u0026amp; return [[ -f ~/.welcome_screen ]] \u0026amp;\u0026amp; . ~/.welcome_screen _set_liveuser_PS1() { PS1=\u0026#39;[\\u@\\h \\W]\\$ \u0026#39; if [ \u0026#34;$(whoami)\u0026#34; = \u0026#34;liveuser\u0026#34; ] ; then local iso_version=\u0026#34;$(grep ^VERSION= /usr/lib/endeavouros-release 2\u0026gt;/dev/null | cut -d \u0026#39;=\u0026#39; -f 2)\u0026#34; if [ -n \u0026#34;$iso_version\u0026#34; ] ; then local prefix=\u0026#34;eos-\u0026#34; local iso_info=\u0026#34;$prefix$iso_version\u0026#34; PS1=\u0026#34;[\\u@$iso_info\\W]\\$ \u0026#34; fi fi } _set_liveuser_PS1 unset -f _set_liveuser_PS1 ShowInstallerIsoInfo() { local file=/usr/lib/endeavouros-release if [ -r $file ] ; then cat $file else echo \u0026#34;Sorry, installer ISO info is not available.\u0026#34; \u0026gt;\u0026amp;2 fi } alias ls=\u0026#39;ls --color=auto\u0026#39; alias ll=\u0026#39;ls -lav --ignore=..\u0026#39; # show long listing of all except \u0026#34;..\u0026#34; alias l=\u0026#39;ls -lav --ignore=.?*\u0026#39; # show long listing but no hidden dotfiles except \u0026#34;.\u0026#34; [[ \u0026#34;$(whoami)\u0026#34; = \u0026#34;root\u0026#34; ]] \u0026amp;\u0026amp; return [[ -z \u0026#34;$FUNCNEST\u0026#34; ]] \u0026amp;\u0026amp; export FUNCNEST=100 # limits recursive functions, see \u0026#39;man bash\u0026#39; ## Use the up and down arrow keys for finding a command in history ## (you can write some initial letters of the command first). bind \u0026#39;\u0026#34;\\e[A\u0026#34;:history-search-backward\u0026#39; bind \u0026#39;\u0026#34;\\e[B\u0026#34;:history-search-forward\u0026#39; ########################################################################################################## ## Some generally useful functions. ## Consider uncommenting aliases below to start using these functions. ## ## October 2021: removed many obsolete functions. If you still need them, please look at ## https://github.com/EndeavourOS-archive/EndeavourOS-archiso/raw/master/airootfs/etc/skel/.bashrc _open_files_for_editing() { # Open any given document file(s) for editing (or just viewing). # Note1: # - Do not use for executable files! # Note2: # - Uses \u0026#39;mime\u0026#39; bindings, so you may need to use # e.g. a file manager to make proper file bindings. if [ -x /usr/bin/exo-open ] ; then echo \u0026#34;exo-open $@\u0026#34; \u0026gt;\u0026amp;2 setsid exo-open \u0026#34;$@\u0026#34; \u0026gt;\u0026amp; /dev/null return fi if [ -x /usr/bin/xdg-open ] ; then for file in \u0026#34;$@\u0026#34; ; do echo \u0026#34;xdg-open $file\u0026#34; \u0026gt;\u0026amp;2 setsid xdg-open \u0026#34;$file\u0026#34; \u0026gt;\u0026amp; /dev/null done return fi echo \u0026#34;$FUNCNAME: package \u0026#39;xdg-utils\u0026#39; or \u0026#39;exo\u0026#39; is required.\u0026#34; \u0026gt;\u0026amp;2 } #------------------------------------------------------------ ## Aliases for the functions above. ## Uncomment an alias if you want to use it. ## # alias ef=\u0026#39;_open_files_for_editing\u0026#39; # \u0026#39;ef\u0026#39; opens given file(s) for editing # alias pacdiff=eos-pacdiff ########################################################################################################## Emacs 学习Emacs有几条曲线\n  先会用基本的快捷键, 安装各种简单的插件, 抄各种各样的配置, 先体验一下Emacs的强大功能.\n  安装复杂插件, 被各种配置搞崩溃了, 越改挂的越厉害, 大部分人卡在这个阶段, 因为不会Elisp, 导致东拼西凑的方法对于复杂插件行不通\n  你搞不懂Emacs复杂的配置的原因是因为你不懂 Elisp 编程, 学习Elisp的方法: 老老实实读Emacs内置的 Elisp reference manual, 这么厚的手册怎么学?\n  一页一页的挨着看, 一个API一个API的读, 不要跳过\n  每个API, 都在 ielm 里面实践一下\n  遇到不知道啥鬼用的API, 去Google或EmacsWiki上搜索一下, 看看别人怎么用这些API的?\n    如果你花了一个月耐下心读完 Elisp reference manual 以后, Emacs 90% 以上的代码你都可以看懂了, 继续折腾复杂插件, 知道 require, autoload, set-key, 各种 hook, defadvice 的在不同环境下的细微差别, 编程上知道 save-excursion, ignore-errors 这些风骚 macro 的用法. 这个阶段可以尝试手动来写一写复杂的配置了, 这个阶段你已经是 Emacs 高级用户了.\n  如果还不满足, 可以像我这样造点有趣的轮子: My Emacs Plugins 50 , 如果你自己会写Elisp插件, 你会发现Emacs其实是越用越简单的, 因为包括正则表达式, 语法高亮, 模式, 异步子进程, hook, overlay, advice 这些代码你写熟悉以后, 你会发现所有插件的唯一差别就是复杂度和想象力的区别, 不存在想得出来写不出来的东西.\n  到了这个阶段, 唯一可以让你学习到更多知识的就是去 IRC #emacs 和那些古老的黑客们交流, 或者去扒Github Emacser, 我知道很多日本牛逼哄哄的Emacs开发者都把插件放到 ftp 上 (比如当年的 color-moccur.el ), 学点 Google 语法就可以定向搜索. 这些人都是你会写Emacs插件后, 需要学习和进阶的榜样, 这时候你再看Elisp代码, 你的注意力会放在他们Elisp编程的一些细节上, 比如代码写的更简洁, 方法用的妙, 架构设计上等等, 这是完全不同阶段的探索体验.\n  如果你还不满足, 好好学习C语言, 然后再找个赚钱的工作, 把自己和家人照顾好. 业余时间直接用C或Elisp给Emacs底层做贡献, 把你的代码贡献固化到Emacs中, 然后你的名字可以像我一样写到 Emacs AUTHORS 里面去装逼: Emacs AUTHORS 146\n  如果你已经看到这里, 而且也做到上面的所有7点, 你自己的能力和精神境界都会很高了, 再也不会咋咋呼呼的吵着自己的技术要咋样咋样, 因为你会发现学的越多, 自己就是傻逼一个, 啥都不懂, 这辈子即使终身学习也学习不完, 哈哈哈哈.\n上面就是我学习Emacs十多年的经验分享, 希望可以给同学们一点参考.\nQuestions “signature is marginal trust”, “signature is unknown trust”, or “invalid or corrupted package”\n如果您有任何错误，您可以清除 pacman 密钥环并重新开始：\n$ sudo rm -fr /etc/pacman.d/gnupg $ sudo pacman-key --init $ sudo pacman-key --populate archlinux archlinuxcn endeavouros $ sudo pacman -Syy archlinux-keyring archlinuxcn-keyring endeavouros-keyring $ sudo pacman -Syyu  记着将所有用到的仓库都添加，如上面分别是 archlinux、archlinuxcn、endeavouros 三个仓库 千万不要运行 pacman-key refresh,超级慢，个把小时，实在没必要。  当 chrome 使用 GTK+ 主题的时候，无法调整窗口大小\nenable \u0026ldquo;System title bars and borders\u0026rdquo;\n有时候正确输入密码但是提示密码错误\n问题来自一个经常需要特权并阻止我使用真实密码登录的流氓 cronjob。请参阅 pam_faillock 和 cron。\n一般只需要等一会儿之后就好了。\nFull Wayland Setup [译] 如果你遵循整个指南，到最后你将拥有：\n Sway 一个平铺式窗口管理器。 Waybar 一个与 Polybar 非常相似的状态条。 Wofi 一个纯 GTK（也就是 Wayland）的可定制应用程序启动器。 Alacritty 一个现代化的终端，“又不是不能用”。 Wayland 中的 Firefox 和 Chromium，可以进行屏幕共享。 Emacs 通过全新的纯 GTK 内部结构在 Wayland 中完全运行。 大多数 QT 应用程序在 Wayland 中运行。 如果可以的话，将 Steam 游戏设置为考虑 Wayland。 (可选）通过 Fcitx5 的日语输入。  你还将学习如何确认一个应用程序是否在 Wayland 中运行，并了解 XWayland 和那些仍然需要它才能正常运行的主要程序。 虽然本指南是以 Arch Linux 为基础编写的，但它应该可以适应你所运行的任何的 Linux 发行版。好好享受吧，祝你好运!\n注意：在继续之前，你可能希望在手机或第二台电脑上打开本指南，因为我们需要在整个过程中多次重启你的窗口管理器。\n开始之前 Wayland 是 Linux 的下一代显示协议。你可能听说过 X（或 X11 或 XOrg），但你可能不知道它的问题：年龄、性能、安全性和开发友好性。\n甚至 Adam Jackson（X 的长期发布和管理者），也 呼吁采用 Wayland。 不过，X 已经很成熟了，过渡不会在一夜之间发生。Linux 系统中的许多核心应用都与它的生态系统紧密相连。\n$ pacman -Qg xorg | wc -l 38 你可能会惊讶地发现，你几乎肯定已经安装了 wayland\n$ pacman -Qi wayland Name : wayland Version : 1.19.0-1 Description : A computer display server protocol Architecture : x86_64 URL : https://wayland.freedesktop.org/ Licenses : MIT # ... etc. 幸运的是，Linux 生态系统向 Wayland 的过渡在这些年里一直在 稳步向前推进。 主要的 GUI 框架如 GTK 和 QT 完全支持它。 Ubuntu 21.04 将默认使用 Wayland 运行。 但我们可以不需要等待主要发行版的行动：今天就可以直接使用 Wayland。\n你应该知道，有一些主要的应用程序并不（或不会 或不能）支持 Wayland。 像这样的程序仍然可以通过一个名为 XWayland 的独立的 X 实例在 Wayland 环境中运行。 这意味着向 Wayland 的过渡可以是渐进的：你不会无法使用旧的应用程序。\n 译者注：XWayland 本质上时 XOrg 的一个 Fork，可以在 Wayland 环境中使用 XOrg\n 在我们继续之前，还有一个好消息： 在 Wayland 中，你不需要像 picom 或 compiz 这样独立于窗口管理器的合成器程序。\n 解释一下？更少的活动组件，更少的配置管理，就可以实现终端透明化\n 前提条件 软件包\n在 Arch Linux 上，运行下面的命令来安装本指南主要部分和 Wayland 兼容性所需的环境。\n$ sudo pacman -S \\  sway alacritty waybar wofi \\  xorg-xwayland xorg-xlsclients qt5-wayland glfw-wayland qt5-wayland 和 glfw-wayland 分别为 QT5 和 GLFW 提供 Wayland 兼容 API 。\n用 xlsclients 检测 XWayland\n要获得当前通过 XWayland 运行的所有窗口的列表，请使用 xlsclients：\n$ xlsclients archlinux discord archlinux krita archlinux steam 这样，你就可以用各种应用程序快速测试你的 Wayland 配置。\nSway Sway 是一个平铺式窗口管理器，是一个在 Wayland 环境下 i3 的替代品。 和它的 i3 一样，它也是用 C 语言编写的，因此速度非常快，资源开销也很小。 尽管 Sway 可以按原样读取 i3 的配置（即 /home/you/.config/i3/config），但我建议从一个默认配置开始，然后在你需要时复制特定的绑定。\n首先，复制 Sway 的配置模板：\n$ mkdir -p ~/.config/sway/ $ cp /etc/sway/config ~/.config/sway/ 现在退出你所处的任何 桌面环境（DE） / 窗口管理器（WM），并回到你的基本登录终端。在这里，运行 sway，Sway 就会启动。恭喜你，你正在运行 Wayland!\n Q: Sway: cannot start: libseat: Could not activate session: Permission denied\n$ sudo pacman -S polkit Q: prime import not supported sway in qemu-kvm\nSway (and wayland) requires a drm backend (a graphic card).\nYou should try with qxl, never had any issue. Add -vga qxl for the simplest configuration.\nQ: Failed to pick cursor format\nDoes it work if you do export WLR_NO_HARDWARE_CURSORS=1 before you start sway? If it does, then your trackpad is working fine, it\u0026rsquo;s just your mouse cursor that is invisible. It\u0026rsquo;s a known bug with some graphics drivers.\nA: 在 Qemu-Kvm 中，不要使用 vnc，使用 Ctrl+alt+G 来 Grab Input，否则会按键冲突，无法实验。\n 好了，我们不要庆祝的太早。你可能已经习惯了在 .xinitrc 中加入 exec i3 这样的行，然后用 startx 启动 X。现在不一样了! 从这里开始，一切都发生在我们的 Sway 配置中。说到这，下面是一些重点。\n配置附加功能 这里是我的全部 Sway 配置。 其他方面，Sway 主要的文档是在它的 man pages 中记录的。如果有疑问，请先查看它们。 如果不行，你也可以参考 Sway Wiki。\n这里有一些有用的绑定，你马上就会需要，但以后可以自由改变。\n 重新加载 Sway：Super+Shift+c (不会关闭正在运行的程序) 退出 Sway：Super+Shift+e 打开一个终端：Super+Return 打开一个程序：Super+d  显示器设置\n我有两台显示器：我的笔记本电脑在我的左边，而我主显示器在我的正前方。要让我的鼠标在显示器边界上自然移动，需要做以下工作。\noutput eDP-1 mode 2560x1440 position 0,0 scale 2 output HDMI-A-2 mode 1920x1080 position 1280,0 在确定第二个显示器（第二行中的 1280）使用的适当偏移量时，涉及到一些数学问题。更多信息见 man sway-output。 你可以使用 swaymsg -t get_outputs 来查看你所有显示器的正式名称和可用分辨率。\nGaps\ni3-gaps 是一个流行的 i3 变种，允许窗口之间有间隙。幸运的是，这个功能已经包含在 Sway 中，可以通过在你的 Sway 配置中添加以下内容来激活。\n# A 10-pixel border around every window. gaps inner 10 # Removes the title bar of each window. default_border pixel 3 你需要退出 Sway 一次，然后从你的登录终端重新运行它，这样的改变才会生效。\n随机壁纸\n虽然还没有整合到我自己的配置中，但 setwall 可以用来设置一个随机的背景图片。\nsetwall random ~/Pictures/backgrounds/ -c sway  译者注：setwall 是这篇文章的原作者自己写的工具\n Alacritty Alacritty 是一个强大的现代终端模拟器，具有理想的默认值。当用 Super+Return 打开一个新的终端时，它也是 Sway 的默认快捷键。 我使用 urxvt 多年，但最近切换到 Alacritty 后，我遇到的一些问题就消失了。\n我对 Alacritty 的默认配置的唯一改变是背景的不透明度。在 /home/you/.config/alacritty/alacritty.yml 中。\nbackground_opacity: 0.8 看, 透明的终端!\n 译者注： 新版本的 Alacritty 推荐设置\nwindow: opacity: 0.8  Waybar Sway 的默认状态栏很好，但 Waybar 提供了更多的自定义功能。它还能在多个显示器上 “正常工作”，而不像 Polybar 那样需要自定义脚本。\n要使用 Waybar 而不是默认 bar ，请注释掉你的 Sway 配置中靠近结尾的 bar 部分，并在其位置上添加以下内容。\nbar { swaybar_command waybar } Waybar Wiki 有很多配置的例子，这里是我自己的 Waybar 配置， 以及 自定义的 CSS 样式。\n在调整了你的 Waybar 配置后，像往常一样通过 Super+Shift+c 刷新 Sway，就可以刷新你的 Waybar 了。\nWofi 默认情况下，Sway 使用 dmenu 来打开程序，但令人惊讶的是，它的用户界面在 XWayland 中运行。 有 许多可用的替代品，我选择了 Wofi。\n这是我设置的外观， 但由于它都是 CSS，所以你可以 自由地进行试验!\n请注意，你需要在你的 Sway 配置中加入以下内容。\nset $menu wofi --show=drun --lines=5 --prompt=\u0026quot;\u0026quot; 这有几种不同的提示模式。 drun 只匹配并显示那些在你的机器上有 Desktop 条目的程序（就是有 .desktop 文件的程序），而不是你的 PATH 上的所有程序。 事实上，不这样做会产生性能问题，是一个已知的问题。\n主要应用程序 大多数应用程序，如果在 GTK 或 QT 上运行，都有自动的 Wayland 支持，不需要进一步配置。一些特定的程序需要进行调整，我们将在下面讨论。\n目前有一些资源要求你需要设置 GTK 和 QT 的特定环境变量才能使用 Wayland，但 我发现这不是真的。\nFirefox 在 Firefox 的 about:support 页面上有一个名为 Window Protocol 的字段，告诉我们它是通过哪个协议运行的。 如果还在 X11 上，这个字段就会显示 X11。如果通过 Sway 而没有下面的调整，你应该看到 xwayland。 用 xlsclients 进行的快速测试也会发现，Firefox 还没有通过 Wayland 原生运行。让我们来解决这个问题。\n将 MOZ_ENABLE_WAYLAND 环境变量设为 1 ，我在我的 Fish 配置中设置了以下内容（其他 shell 的用户也需要类似的内容）。\nset -x MOZ_ENABLE_WAYLAND 1 退出 Sway 并完全注销一次。 一旦重新登录并重新打开 Sway，这个变量的变化应该已经传播到了所有重要的地方。 现在，如果你通过 Wofi 再次打开 Firefox，并检查 about:support，你应该发现已改变。\nChromium Chromium 的转换要简单一些。在 /home/you/.config/chromium-flags.conf 中，添加以下几行。\n--enable-features=UseOzonePlatform --ozone-platform=wayland 重新启动 Chromium，这样就可以了。你可以用 xlsclients 来确认。\nEmacs 是的，Emacs 可以纯粹地在 Wayland 中运行。你们中的一些人可能会说。\n 但是 Emacs 并不是一个真正的 GTK 应用程序!\n 是的，这曾经是真的。从 2021 年初开始，Emacs 可以用 “纯 GTK” 的内部结构构建，使其完全兼容 Wayland。 这项功能将在 Emacs 28 中实现（截至本文撰写时尚未发布），但幸运的是， 有一个 AUR 包 可以跟踪 Wayland 开发分支，并提供一个预构建的二进制文件。 我们可以用 AURA 这样的工具来安装它。\n 译者注：AURA 也是这篇文章的原作者写的，中文社区的用户可能更习惯使用 yay\n $ sudo aura -Axa emacs-gcc-wayland-devel-bin 注意，这个软件包 Provides: emacs，所以它将取代你所安装的任何其他 Emacs 软件包。\nSteam and Gaming 像 Among Us 这样的 Proton games 可以按原样运行， 因为它们在高度修改的 Wine/dependency 环境中运行，而这种环境对每个游戏都是已知的。 Among Us 对 Sway 中的窗口大小调整和重新定位反应良好。\n对于像 Half-life (old)、 Trine 2 (graphics heavy) 和 Tabletop Simulator（modern toolchain）这样的原生游戏， 我不得不将环境变量 SDL_VIDEODRIVER 设为 x11。否则它们就不能正常启动。\n来自 Arch Wiki：\n 注意: 许多专有游戏都捆绑了旧版本的 SDL，它们不支持 Wayland，如果你设置 SDL_VIDEODRIVER=wayland，可能会完全崩溃。\n 甚至 Stellaris 也需要 x11 才能工作。\n如果你不想把所有 SDL 的使用强制到 X11，你也不必这样做。Steam 允许我们为每个游戏设置特定的环境变量。 要设置这个，右键单击一个游戏，并访问其 Properties。在 GENERAL $ LAUNCH OPTIONS 中，输入SDL_VIDEODRIVER=x11 %command%，你的游戏应该可以运行了。\n所以重申一下，这里是我在 Fish 中设置的环境变量。\nset -x SDL_VIDEODRIVER \u0026#39;wayland\u0026#39; 而我在 Steam 中根据具体情况将其覆盖为 x11。\nSignal 在 2021 年 5 月初，Signal 发布了 5.1.0 版本，该版本使用与 Wayland 兼容的 Electron。 不幸的是，Arch 软件包 signal-desktop 还没有默认在这种模式下运行，所以手动激活是必要的。在命令行中。\nsignal-desktop --use-tray-icon --enable-features=UseOzonePlatform --ozon-platform=wayland 或者如果你通过启动器运行 Signal，我们可以编辑软件包提供的 .desktop 文件来尊重这些选项。 在 /usr/share/applications/signal-desktop.desktop 中，修改 Exec 一行，使其成为以下内容。\nExec=signal-desktop --use-tray-icon --enable-features=UseOzonePlatform --ozone-platform=wayland -- %u 类似的策略也适用于其他至少使用 12 版的 Electron 应用程序。\nOther Settings 如果这里的章节对你不适用，请随意跳过。\nKeyboard Layouts 我在打字时使用 Colemak 布局，所以我在我的 Sway 配置里有以下内容。\ninput * { xkb_layout \u0026quot;us\u0026quot; xkb_variant \u0026quot;colemak\u0026quot; } 不幸的是，似乎有 一个奇怪的 Bug，在某些窗口中布局会突然切换回 qwerty。 我注意到以下症状：当一个终端被打开时，最左边的 XWayland 窗口会切换回 qwerty。 我发现有两个办法可以解决这个问题。\n 尽可能多地使用纯 Wayland 应用程序，或者。 安装一个IME（Input Method Editor），例如用于输入 non-ASCII 语言（见下文）。  日语输入法 Sway 已经非常接近对切换输入法的一流支持（见 Sway#4740、 Sway#5890 和 Sway#4932）。 目前，这里有一个通过 dbus 工作的设置，允许我们在 除 Alacritty 之外的所有 Wayland 和 XWayland 窗口中改变方法和输入日文。\n首先，安装这些软件包。\nsudo pacman -S fcitx5 fcitx5-configtool \\ fcitx5-gtk fcitx5-mozc fcitx5-qt 然后在 /etc/environment 中添加以下内容：\nGTK_IM_MODULE=fcitx QT_IM_MODULE=fcitx XMODIFIERS=@im=fcitx 然后把这个放到你的 Sway 配置中：\nexec_always fcitx5 -d --replace 现在重新启动你的电脑。\n希望你现在能在你的 Waybar 托盘中看到一个键盘图标。要配置 fcitx5，请打开 fcitx5-configtool。\n你会看到，我特别将我的英文键盘设置为 Colemak，并从右边的列表中添加了 Mozc。 勾选 Global Options 标签，设置你的方法切换键绑定。 之后，点击 Apply，你现在应该可以切换输入法并输入日语了。 如果键盘绑定不起作用，你也可以通过点击 Waybar 托盘上的图标来切换方法。\n 译者注：对于中文用户，就是把 Mozc 换成 Rime\n 屏幕共享 在 Firefox 和 Chromium 中，通过 Pipewire 和一些辅助包可以实现屏幕共享，尽管目前我们只能共享整个屏幕，而不是单个窗口。要继续进行，首先安装以下软件包。\n$ sudo pacman -S xdg-desktop-portal-wlr libpipewire02 后者只对 Chromium 是必要的。 现在重新启动你的电脑。\n让我们先用 Mozilla 的 gum test page 测试一下 Firefox。 当浏览器提示你选择窗口时，选择 Use operating system settings\n你会注意到你的光标发生了变化；xdg-desktop-portal-wlr 正在期待你选择一个显示器来共享。点击一个，屏幕共享应该开始。\n对于 Chromium，我们需要激活一个功能标志，让 Chromium 与 Pipewire 对话。 首先访问 chrome://flags，然后找到并启用 WebRTC PipeWire support。这就是了!\n如果你在使用这些浏览器时遇到问题，请查看 XDPW FAQ。\nXWayland 和不兼容 您还知道其他不兼容的情况吗？请让我知道。\nKrita 数字艺术程序 Krita 是一个在 QT5 中运行的很棒的应用程序，但由于某些硬件支持不成熟的原因（对于手写板等）， 它不支持 Wayland，因此总是在 XWayland 中运行。\nElectron Apps 从 2021 年 5 月起，由于 Signal 和 VSCode 升级到 Electron 12，它们现在可以在 Wayland 中运行。\n而其他 Electron Apps，如 Discord 和 Slack，则必须在 XWayland 中运行，直到他们能够升级。\n社区提示 KWin 用户 感谢 flying-sheep 提供的这个提示。\n 对于使用 KWin 的人来说：你可以显示一个窗口，帮助你使用识别 XWayland 窗口。\n qdbus org.kde.KWin /KWin org.kde.KWin.showDebugConsole Polkit 感谢 Aaron Wiedemer 提出的以下建议。\n 一些应用程序有时需要权限，例如，软件管理器需要权限来启动更新，但只是搜索软件包不需要额外权限。 这些应用程序会弹出一个小盒子，要求输入密码。这需要一个不由 sway 启动的守护程序，所以我们需要用我们的 sway 配置自动启动一个。\n Polkit 客户端有很多选择。 例如，polkit-gnome 没有依赖性，可以通过以下方式在 sway 中启动：\nexec_always /usr/lib/polkit-gnome/polkit-gnome-authentication-agent-1 WM Window manager recommendation?\ni3 (sway for Wayland) is the easy peasy starter kit. I like Bspwm, it\u0026rsquo;s one big bash script basically to get configs going. Then there\u0026rsquo;s the more challenging one that you can pick based on your preferred programming language: Awesome (lua), Xmonad (haskell), DWM (C), Qtile (python)\nawesome wm, probably the most extensive wm, for one you can load whole libraries into it like xmonad, but using lua is do much easier than haskell, tho the api docs could get an overhaul as they are kind of ugly when giving code examples going straight from 1 to 10.\n常见的窗口管理相关的工具\n合成器\n Compton - Compton 是一款独立的合成管理器，适合同没有原生提供合成功能的窗口管理器一同使用。 Gamescope - Gamescope 是一款微合成器，提供一个带有独立输入，分辨率和刷新率的沙盒 Xwayland 桌面。 Sway - Sway 是平铺 Wayland 合成器和 X11 下 i3 窗口管理器的新替代。 Xcompmgr - Xcompmgr 是一个简单的合成管理器，能够渲染下拉阴影，使用 transset 工具的话，还可以实现简单的窗口透明。  叠加式窗口管理器\n 2bwm - 快速的浮动窗口管理，有两个特殊边界，基于 XCB 库，由 mcwm 衍生。 Blackbox - 快速，轻量化的 X 窗口系统窗口管理器，没有那些烦人的库依赖。 Fluxbox - 基于 Blackbox 0.61.1 代码的 X 窗口管理器。 Openbox - 高度可配置，带有可扩展标准支持的下一代窗口管理器。  平铺式窗口管理器\n Bspwm - bspwm 是一个平铺式窗口管理器，将窗口以二叉树的叶结点的方式展现。 Herbstluftwm - 使用 Xlib 和 Glib 的手工平铺式窗口管理器。 i3 WM - 更好的平铺及动态窗口管理器。完全重写。目标平台是 GNU/Linux 和 BSD 操作系统。 i3-gaps - i3-gaps 是拥有更多功能的 i3。 Pop!_OS Shell - Pop Shell 是基于 GNOME shell 的窗口管理器，键盘驱动，自动平铺。 Qtile - qtile 是一款全功能，可 hack 的平铺窗口管理器，使用 Python 编写和配置。  动态窗口管理器\n awesome - 高度可配置，下一代 X 框架窗口管理器。 dwm - X 动态窗口管理器。它以平铺，单片镜以及浮动布局的方式管理窗口。 spectrwm - 小型动态平铺 X11 窗口管理器。主要受 xmonad 和 dwm 启发。 xmonad - 动态平铺 X11 窗口管理器，用 Haskell 编写和配置。  长时间日常使用动态窗口管理器之后发现，相比与传统的DE型桌面，这种WM型窗口管理方式确实能很大程度上提高工作效率。\nDE和WM的区别\n首先说明一下我即将提到的东西是什么。\n DE：Desktop Environment WM：Window Manager  桌面环境是一个相对完整的概念，一般情况下DE包含WM，比如Gnome3的默认WM是Mutter，KDE5的默认WM是KWin。主流的桌面环境都提供了大量自带的桌面组件来构成其完整的桌面体验。\n窗口管理器只是管理出现在你的桌面上的各种窗口的组件，具体的管理内容包含比如：窗口堆叠方式，窗口移动规则等。大多数人接触到的是堆叠式窗口管理器，一个窗口可以叠放在其他窗口之上，调整窗口的主要方式是鼠标。我即将介绍的dwm（Dynamic Window Manager）属于动态窗口管理器，可以自定义不同窗口的出现规则如平铺或者堆叠，主要的调整窗口的方式是键盘。\n大多数窗口管理器只提供管理窗口的逻辑和人机交互的处理，并不自带其他组件如程序启动器、终端等软件，因此只运行一个窗口管理器理论上是要比运行一个完整的桌面环境更加节约资源，也有更好的可伸缩性。\n实际上WM这个概念是应用了奥卡姆剃刀原理，把那些看似有点用但实际上多余的功能全部剔除，只留下你真正需要的和最常用的功能并加以强化，Less is More.\n通用配置 因为一个可独立运行的窗口管理器默认不携带任何多余的软件，所以为了满足日常使用需要进行一定程度的自定义配置，下面给出一下通用的配置：\nXorg \u0026amp; font $ sudo pacman -S xorg-server xterm xorg-xinit $ sudo pacman -S noto-fonts noto-fonts-cjk noto-fonts-emoji xinitrc ~/.xinitrc 可以方便的启动依赖 X 的程序，并在 X 启动时设置环境变量。如果用户主目录中存在 .xinitrc，startx 和 xinit 会执行此文件。如果不存在，startx 会执行默认的 /etc/X11/xinit/xinitrc。这个文件默认启动 Twm 和 Xterm.\n要设置窗口管理器或桌面环境，先通过复制创建默认文件：\n$ cp /etc/X11/xinit/xinitrc ~/.xinitrc 根据示例文件修改可以保留一些默认行为，例如会引用 /etc/X11/xinit/xinitrc.d 中以 .sh 结尾的脚本。\n然后编辑 ~/.xinitrc ：\n$ vim ~/.xinitrc #!/bin/bash xscreensaver \u0026amp; xsetroot -cursor_name left_ptr \u0026amp; exec openbox-session ~/.xinitrc 中应该只有 一个 未注释掉的 exec 行，而且 exec 行必须位于配置文件的末尾。exec 后面的所有命令只有窗口退出后才会被执行。在窗口管理器前启动的命令，例如屏保和壁纸程序，必须自行 fork 后台进程或用\u0026amp;在后台启动, 否则启动程序会等待它们退出才会启动窗口管理器或桌面环境。使用 exec 作为前缀会替换当前的进程，这样进程进入后台时 X 不会退出。\n某些程序，比如 xrdb，不应该被 fork. 使用 exec 前缀时，程序将会用窗口管理器进程替换脚本进程，所以即使进程进入后台 X 也不会退出。\nxserverrc xserverrc 文件是一个启动 X server 的 shell 脚本。如果存在 ~/.xserverrc ，startx 和 xinit 都会执行这个文件。如果文件不存在，startx 会使用 /etc/X11/xinit/xserverrc.\n为了保持logind的 authenticated session 会话，并防止通过切换终端绕过屏幕锁定器， Xorg必须在发生登录的同一虚拟终端上启动。因此建议在~/.xserverrc 中指定 vt$XDG_VTNR:\n$ vim ~/.xserverrc #!/bin/sh exec /usr/bin/Xorg -nolisten tcp \u0026#34;$@\u0026#34; vt$XDG_VTNR 在登录时自动启用 X 如果使用Bash, 编辑 ~/.bash_profile,加入如下内容。如果文件不存在，从 /etc/skel/.bash_profile 复制一个。\n如果使用 zsh，则编辑 ~/.zprofile.\n$ vim ~/.bash_profile if [[ ! $DISPLAY \u0026amp;\u0026amp; $XDG_VTNR -eq 1 ]]; then exec startx fi 如果希望在 X 会话终止时保持登入状态，删除 exec.\nAutomatic login into Xorg without display manager $ yay -S xlogin-git $ sudo systemctl enable xlogin@username 常用软件的推荐 注意：大部分软件需要根据所使用的 wm 添加配置才能使用，具体参照他人的配置\n Font: nerd-fonts-ibm-plex-mono, nerd-fonts-fira-code, nerd-fonts-jetbrains-mono, ttf-sarasa-gothic(chinese only), infinality(字体渲染美化) Launcher：dmenu, rofi Terminal: alacritty, kitty, st, wezterm, termite Editor: neovim, neovide\u0026amp;glrnvim, doom emacs, vscode, sublime-text-nightly Compositor: picom-jonaburg-git, picom Shell: fish, zsh PDF reader: zathura, atril Player: mpd\u0026amp;ncmpcpp, deadbeaf-git Notification daemon: dunst\u0026amp;libnotify, notification-daemon Volume notificator: xob, volumeicon Screen locker: i3lock-color\u0026amp;betterlockscreen, xautolock, xscrennserver System monitor: conky, btop Theme controler: xsettingsd, lxappearance, qt5ct Gtk themes: Light: Orchis-light, Dark: Nordic Qt themes: use qt5ct and qt5-styleplugins to set qt theme follow gtk2 theme Icon theme: Papirus Touchpad: libinput, ibinput-gestures, xdotool Fetch tool: macchina, rxfetch Automounter: udiskie Trash: glib2, gvfs(gui) 壁纸设置器：feh, nitrogen(gui) 文件管理器：thunar, nemo(cli), ranger(cli), pcmanfm(轻量级文件管理器) 电源管理器：xfce4-power-manager, cbatticon 截图工具：flameshot, scrot 输入法：fcitx5 科学上网工具：qv2ray 剪切板管理器：copyq 云同步工具：nutstore（坚果云）, dropbox 护眼：redshift 屏幕亮度调节器：light, xorg-xbacklight, brightnessctl  关于平铺还是浮动\n个人建议多数窗口平铺，以下窗口默认浮动：\nvirtualbox, lxappearance, qq, gpick, qalculator, slickpicker\n关于GTK主题和QT主题\n我建议让QT程序使用GTK主题，除上文提到的qt5ct再安装qt5-styleplugins\n在qt5ct中设置风格为gtk2\n配置\n从上到下，基本上 star 越多，就越完善，越容易安装与使用：\n lcpz/awesome-copycats: awesome (2.5k) streetturtle/awesome-wm-widgets: awesome (1.5k) bakkeby/dwm-flexipatch: dwm (618) siduck/chadwm: dwm (612)：很好看的主题 antoniosarosi/dotfiles: Qtile/Sepctrwm/Openbox/Xmonad/Dwm (471) 很全的配置（包括Arch 系统安装、桌面环境以及常用软件） pw4ever/awesome-wm-config: awesome (223) ayamir/dotfiles: Gentoo/Arch/dwm/awesome (201) lilydjwg/myawesomerc: awesome (85) 依云的  dwm dwm与其他wm的区别 前面已经说明了dwm与堆叠式窗口管理器的区别，下面说明一下dwm与其他平铺\u0026amp;动态窗口管理器的区别。\ndwm使用C语言编写，使用修改源代码的方式来进行配置。说到源代码可能有些同学就有点害怕，其实修改源代码也很简单，因为有现成的例子可以复(bai)用(piao)嘛！通过直接修改源代码理论上可以确保你的dwm能满足你所有的需求，同时也没有多余的，你不需要的功能。\n相比之下，另外一个相当流行的动态窗口管理器i3wm也是使用C语言编写，但是通过修改其配置文件来配置，这相当于i3wm向你暴露可以被配置的接口来满足你的需求，但是这样的配置方式缺点在于你不能向其添加你需要的需求，只能向上游提交issue来完成enhancement。\n具有和dwm相似配置能力的窗口管理器是xmonad，它也是通过直接修改源代码的方式来调整配置，但是因为使用haskell编写的所以需要安装相当多的依赖，此外其运行效率也不及dwm。\ndwm安装 dwm\n$ sudo pacman -S libxinerama $ wget https://dl.suckless.org/dwm/dwm-6.3.tar.gz $ tar xpvf dwm-6.3.tar.gz $ mv dwm-6.3 ~/.dwm $ cd .dwm $ make clean install $ vim ~/.xinitrc #!/bin/bash exec dwm st\n$ wget https://dl.suckless.org/st/st-0.8.5.tar.gz 如果使用的终端模拟器不是st，需要修改config.def.h文件中的以下代码：\n/* 将其中的st修改为安装的终端模拟器 */ static const char *termcmd[] = { \u0026#34;st\u0026#34;, NULL}; dmenu\n$ wget https://dl.suckless.org/tools/dmenu-5.1.tar.gz dwm配置 配置dwm主要需要修改的文件是config.def.h，主要的配置方式是使用被人写好的patch加必要时候的手动修改。dwm的patch都在其官方网站\n具体过程是这样的：\n 找到你需要的patch并下载 将其移动到~/.dwm目录下  $ patch \u0026lt; dwm*.diff 之后会输出这个patch过程的详细情况，一般情况不会出现问题\n需要注意的是要一个一个来\n出现问题之后需要对照如：config.def.h.rej, dwm.c.rej等后缀为rej的文件来手动修改对应的没有rej后缀的源文件\n打开之后rej文件中行首标有+的行是需要添加的行，标有-的行是需要删除的行\n所有更改都修改完毕之后重新编译安装，执行：\n$ rm -f ./config.h \u0026amp;\u0026amp; sudo make clean install Starting Select Dwm from the menu in a display manager of choice. Alternatively, to start dwm with startx append exec dwm to ~/.xinitrc and prepend other programs to execute them as well, for example:\nredshift -O3500; xset r rate 300 50; exec dwm 字体和左侧状态栏图标 $ sudo pacman -S ttf-nerd-fonts-symbols-mono $ nvim ~/.local/applications/dwm/dwm-6.2/config.h /*设置dwm采用图标字体*/ static const char *fonts[] = {\u0026#34;Symbols Nerd Font:size=14\u0026#34;};\t/*图标对应的ASCLL码：https://www.nerdfonts.com/cheat-sheet*/ static const char *tags[] = {\u0026#34;\\ue795\u0026#34;,\u0026#34;\\ufc6e\u0026#34;,\u0026#34;\\ue235\u0026#34;,\u0026#34;\\uf308\u0026#34;};\tStatusbar The information that you want dwm to show in the statusbar should be defined with xsetroot -name \u0026quot;\u0026quot; command in ~/.xinitrc or ~/.xprofile (if you are using a display manager). For example:\n# Statusbar loop while true; do xsetroot -name \u0026#34;$( date +\u0026#34;%F %R\u0026#34; )\u0026#34; sleep 1m # Update time every minute done \u0026amp; # Autostart section pcmanfm \u0026amp; exec dwm Conky statusbar\nConky can be printed to the statusbar with xsetroot -name:\n(conky | while read LINE; do xsetroot -name \u0026quot;$LINE\u0026quot;; done) \u0026amp; exec dwm 自动更换壁纸 创建壁纸目录\n$ mkdir -p ~/pictures/wallpapers 安装图片查看器feh,编写更换壁纸的配置文件\n$ pacman -S feh $ nvim ~/.dwm/dwm-wallpaper.sh #!/bin/bash while true do feh --recursive --randomize --bg-fill ~/pictures/wallpapers/ sleep 5m done 启动DWM时，自动执行壁纸配置文件\n$ nvim ~/kler_profiles/.dwm/autostart.sh #!/bin/bash /bin/bash ~/kler_profiles/.dwm/dwm-wallpaper.sh \u0026amp; picom picom是Xorg的独立合成器，适用于不提供合成功能的窗口管理器（例如 i3，dwm） 他可以给窗口设置淡入淡出、半透明、阴影等视觉效果。\n推荐补丁 透明补丁：alphasystray.diff 临时小窗口：dwm-scratchpad-6.2.diff 隐藏空标签：dwm-hide_vacant_tags-6.2.diff 窗口间距：dwm-vanitygaps-20190508-6.2.diff 自动启动脚本：dwm-autostart-20161205-bb3bd6f.diff 窗口全屏：dwm-actualfullscreen-20191112-cb3f58a.diff 状态栏显示多个窗口信息：dwm-awesomebar-20191003-80e2a76.diff awesome awesome是一个高度可配置的、用于Xorg的下一代框架窗口管理器。它非常快而且可扩展。它主要针对的是高级用户、开发人员和任何处理日常计算任务的人，他们希望对其图形环境进行精细的控制。\n安装 Install the awesome package. The development version is awesome-gitAUR, which is considered unstable and may have a different configuration API.\n$ pacman -S awesome $ vim ~/.xinitrc #!/bin/bash exec awesome 自定义配置 Awesome提供了一个设置文件 rc.lua ，把它拷贝到~/.config/Awesome/里。\n$ mkdir -p ~/.config/awesome/ $ cp /etc/xdg/awesome/rc.lua ~/.config/awesome/  登录后顶部有一条类似Windows任务栏的东西，叫做状态栏（Status Bar）。 状态栏的最左侧是Awesome的图标，点击它将会打开一个小菜单，这就是Awesome的主菜单。 Awesome 图标的右侧可以看到阿拉伯数字1-9，这些叫做标签（Tag），类似GNome或者KDE下的虚拟桌面。 在状态栏最右侧是布局切换器，布局（Layout）是根据屏幕上的可用空间来调整窗口位置、尺寸的方式。Awesome支持多种布局。  每次修改完使用 Mod4 + ctrl + R 重新加载配置。\nSome good examples of rc.lua would be as follows:\n Awesome screenshot thread Setkeh\u0026rsquo;s Awesome Configuration User configuration that supports different themes, including a status bar Awesome configuration with two modern themes  定制布局和标签 定制布局 如果希望改变默认的布局和修改布局的切换顺序，可以通过修改 rc.lua 文件来实现。找到像这样的一段代码：\nlayouts = { awful.layout.suit.floating, awful.layout.suit.tile, awful.layout.suit.tile.left, awful.layout.suit.tile.bottom, awful.layout.suit.tile.top, awful.layout.suit.fair, awful.layout.suit.fair.horizontal, awful.layout.suit.spiral, awful.layout.suit.spiral.dwindle, awful.layout.suit.max, awful.layout.suit.max.fullscreen, awful.layout.suit.magnifier } 这是所有Awesome提供的布局方案，并且是按切换顺序排列的。可以通过调整顺序来改变实际的布局切换顺序。如果不喜欢其中的一些布局方案，你可以把相应的代码给去掉。比如，对于我而言，全屏、放大和螺旋式布局都是不常用的，并且我希望第一个布局是平铺，而不是浮动，因此可以改成：\nlayouts = { awful.layout.suit.tile, awful.layout.suit.tile.left, awful.layout.suit.tile.bottom, awful.layout.suit.tile.top, awful.layout.suit.fair, awful.layout.suit.fair.horizontal, awful.layout.suit.floating, awful.layout.suit.max } 完成后保存修改，然后按 Mod4 + Control + r 重启 Awesome看看变化。\n浮动窗口 有些程序的窗口不适合采用平铺的方式，比如Firefox的下载窗口，或者Gimp的图层窗口、工具栏窗口等，这时候我们希望将这样的窗口设置为浮动：\n-- 需要自动设置为浮动的程序 -- 只需要把你想要设置为浮动窗口的程序的Instance或者class按照下面的格式写进去就行 -- 了。在awesome下用Mod4 + Ctr + i就可以看到当前程序的instance和class名字 -- { { { Rules awful.rules.rules = { -- All clients will match this rule. {rule = {}, properties = {border_width = beautiful.border_width, border_color = beautiful.border_normal, focus = true, keys = clientkeys, buttons = clientbuttons}}, {rule = {class = \u0026#34;MPlayer\u0026#34;}, properties = {floating = true}}, {rule = {class = \u0026#34;Smplayer\u0026#34;}, properties = {floating = true, tag = tags[1][6]}}, { rule = { class = \u0026#34;pinentry\u0026#34; }, properties = { floating = true } }, { rule = { class = \u0026#34;gimp\u0026#34; }, properties = { floating = true } }, {rule = {class = \u0026#34;Firefox\u0026#34;}, properties = {tag = tags[1][1]}}, {rule = {class = \u0026#34;Firefox\u0026#34;, name = \u0026#34;Download\u0026#34;}, properties = {floating = true}}, {rule = {class = \u0026#34;VirtualBox\u0026#34;}, properties = {floating = true, tag = tags[1][2]}}, -- Set Firefox to always map on tags number 2 of screen 1. -- { rule = { class = \u0026#34;Firefox\u0026#34; }, -- properties = { tag = tags[1][2] } }, } -- } } } 定制标签 只要你愿意，你可以为每一个标签命名，并为每一个标签设置默认布局。这是 rc.lua 里默认的标签设置：\n-- { { { Tags -- Define a tag table which hold all screen tags. tags = {} for s = 1, screen.count() do -- Each screen has its own tag table. tags[s] = awful.tag({ 1, 2, 3, 4, 5, 6, 7, 8, 9 }, s, layouts[1]) end -- } } } 现在我们可以改变每个标签的名字，并为每一个设置默认布局。参考下面这段代码：\n-- { { { Tags -- Define a tag table which will hold all screen tags. tags = { names = { \u0026#34;main\u0026#34;, \u0026#34;www\u0026#34;, \u0026#34;im\u0026#34;, \u0026#34;gimp\u0026#34;, \u0026#34;office\u0026#34;, \u0026#34;music\u0026#34;, \u0026#34;virtual\u0026#34;, 8, 9 }, layout = { layouts[1], layouts[8], layouts[8], layouts[7], layouts[1], layouts[7], layouts[8], layouts[1], layouts[1] }} for s = 1, screen.count() do -- Each screen has its own tag table. tags[s] = awful.tag(tags.names, s, tags.layout) end -- } } } 在这个例子中，我们还为前5个标签分别命名为\u0026quot;main\u0026quot;, “www”, “im”, “gimp” 和\u0026quot;office\u0026quot;， 你可以根据自己的喜好进行更改。另外，我们还使用 layouts来指定每一个标签的布局， \u0026ldquo;[]\u0026ldquo;里的数字就是我们刚刚 定制布局的时候设置的布局的顺序，例如[1] 就是第1个布局。\n设置默认终端和编辑器 可以在 rc.lua 中修改下面的代码来设置默认的终端和编辑器：\nterminal = \u0026#34;xterm\u0026#34; editor = os.getenv(\u0026#34;EDITOR\u0026#34;) or \u0026#34;nano\u0026#34; 美化 更换主题 Beautiful是一个Lua库，它允许你使用外部文件来为awesome做主题，在不改变你的rc.lua的情况下，动态地改变你整个awesome的颜色和墙纸变得非常简单。\nAwesome自带了三套主题： default 、 sky 和 zenburn 。\nThe default theme is at /usr/share/awesome/themes/default. Copy it to ~/.config/awesome/themes/default (optionally copy them all) and change rc.lua:\n$ cp -av /usr/share/awesome/themes ~/.config/awesome/themes -- beautiful.init(gears.filesystem.get_themes_dir() .. \u0026#34;default/theme.lua\u0026#34;) local theme_path = string.format(\u0026#34;%s/.config/awesome/themes/%s/theme.lua\u0026#34;, os.getenv(\u0026#34;HOME\u0026#34;), \u0026#34;default\u0026#34;) beautiful.init(theme_path) 把其中的 default 更换成其他主题名字即可。\n或者直接添加路径\nbeautiful.init(\u0026#34;/usr/share/awesome/themes/default/theme.lua\u0026#34;) 如果嫌主题太少，这里有很多PP的用户定制主题： Github主页，下载下来然后拷贝到~/.config/awesome/themes即可以使用。\n更换背景图片 主题的 theme.lua 文件可以配置背景、字体等内容，改一下图片路径：\ntheme.wallpaper = themes_path .. \u0026#34;default/background.png\u0026#34; 我希望背景图片最大化但不要拉伸，所以我将原本的\ngears.wallpaper.maximized(wallpaper, s, true) 改成了\ngears.wallpaper.maximized(wallpaper, s, false) 同时背景设置还有其他的方法：\n centered (surf, s, background, scale) tiled (surf, s, offset) fit (surf, s, background)  可以参考官方文档 或者 源码\n修改主菜单 可以通过修改 rc.lua 的相应内容来定制主菜单的内容。下面是我的配置。里面的设置完全根据我个人口味，而且用了几个第三方的icon。因此代码仅供参考，不建议照搬：\n-- { { { Menu -- Create a laucher widget and a main menu myawesomemenu = { { \u0026#34;manual\u0026#34;, terminal .. \u0026#34; -e man awesome\u0026#34; }, { \u0026#34;edit config\u0026#34;, editor_cmd .. \u0026#34; \u0026#34; .. awesome.conffile }, { \u0026#34;restart\u0026#34;, awesome.restart }, { \u0026#34;quit\u0026#34;, awesome.quit } } -- 创建一个favorite子菜单 myfavoriteapps = { { \u0026#34;Terminal\u0026#34;, terminal }, { \u0026#34;Firefox\u0026#34;, \u0026#34;firefox\u0026#34; }, { \u0026#34;QQ\u0026#34;, \u0026#34;qq2012\u0026#34;}, { \u0026#34;XMind\u0026#34;, \u0026#34;/usr/local/xmind/xmind\u0026#34; }, { \u0026#34;Synaptic\u0026#34;, \u0026#34;gksudo synaptic\u0026#34; }, { \u0026#34;Transmission\u0026#34;, \u0026#34;transmission-gtk\u0026#34;}, { \u0026#34;Software-Center\u0026#34;, \u0026#34;gksudo software-center\u0026#34; }, { \u0026#34;Update-Manager\u0026#34;, \u0026#34;gksudo update-manager\u0026#34; }, { \u0026#34;JabRef\u0026#34;, \u0026#34;sh /home/ehome/JabRef.sh\u0026#34; } } mymainmenu = awful.menu({ items = { { \u0026#34;awesome\u0026#34;, myawesomemenu, beautiful.awesome_icon }, { \u0026#34;Debian\u0026#34;, debian.menu.Debian_menu.Debian , theme.deb_icon }, -- 添加Favorite菜单，并将icon设置为theme.fav_icon { \u0026#34;Favorite\u0026#34;, myfavoriteapps, theme.fav_icon }, { \u0026#34;Home\u0026#34;, \u0026#34;dolphin\u0026#34; , theme.home_icon }, -- 添加Emacs菜单项 { \u0026#34;Emacs\u0026#34;, \u0026#34;emacs\u0026#34; }, -- 添加Chrome菜单项 { \u0026#34;Chrome\u0026#34;, \u0026#34;google-chrome\u0026#34; }, -- 添加一个关机对话框 { \u0026#34;Log out\u0026#34;, \u0026#34;/usr/local/shutdown.sh\u0026#34; } } }) mylauncher = awful.widget.launcher({ image = image(beautiful.awesome_icon), menu = mymainmenu }) -- } } } GTK \u0026amp; QT 主题 安装工具\n$ pacman -S lxappearance qt5ct qt5-styleplugins $ export QT_QPA_PLATFORMTHEME=qt5ct   下载解压 Gtk themes Nordic 到 ~/.themes\n  下载解压 Icon theme Papirus 到 ~/.icons\n  $ lxappearance # 选择 theme $ qt5ct # set qt theme follow gtk2 theme 插件 Awesome 里的插件指的是你可以在 wibox 上添加的小插件，通过使用插件（Widget），我们可以在状态栏上添加一些有用的信息，例如内存使用、CPU温度、电池状态，等等。\n对于新手，可以使用其他用户创建的插件库，这些插件库集成了功能齐全的插件，因此免去了自己编写插件的工作。这类的插件库有很多，推荐的是 Vicious。\n创建插件 要创建插件，可以使用 widget() 函数，例如：\nmysystray = widget({type = \u0026#34;systray\u0026#34;}) myicon = widget({ type = \u0026#34;imagebox\u0026#34; }) myicon.image = image(awful.util.getdir(\u0026#34;config\u0026#34;) .. \u0026#34;/myicon.png\u0026#34;) mytextbox = widget({ type = \u0026#34;textbox\u0026#34; }) mytextbox.text = \u0026#34;Hello, world!\u0026#34; 插件的类型 使用 widget() 函数创建插件的时候需要指定插件类型，Awesome自带的插件包括：\n systray：系统托盘插件。Awesome默认已经添加，就在状态栏上位于日期和时间左侧的区域。对于一些支持最小化到系统托盘的程序，例如ibus、chrome、shutter等，它们的图标将被放置在这里。 imagebox：展示一张图片。常用来和textbox一起搭配使用，创建启动器、图标和分隔符。这里 收集了很多精美的图标。 textboxtextbox：插件用来显示一段文本，这是最常用的插件。例如，在创建插件部分我们已经创建了一个名为mytextbox的textbox插件，并且插件显示的文本内容是\u0026quot;Hello, World!\u0026quot;。要修改文本内容，可以直接修改 rc.lua文件中的相应代码，或在终端中使用下面命令：  $ echo \u0026#34;mytextbox.text = \u0026#34;Foo Bar!\u0026#34;\u0026#34; | awesome-client Awesome还提供了计时器的API， 允许我们周期性的执行或更新插件。例如：\nmytimer = timer({ timeout = 30 }) mytimer:add_signal(\u0026#34;timeout\u0026#34;, function() mytextbox.text = \u0026#34;Hello awesome world!\u0026#34; end) mytimer:start() textbox的文本属性（颜色、字体）是可以通过使用 Pango 标记语言来修改。最简单的例子是：\nmytextbox.text = \u0026#39;\u0026lt;span color=\u0026#34;white\u0026#34;\u0026gt;Sacrebleu, I have seen a ghost!\u0026lt;/span\u0026gt; \u0026#39; 要了解更多textbox的设置，例如改变背景颜色、边框、文本对齐等，可以参看Awesome的API文档。\n推荐：实用插件 awesome-wm-widgets 收集了丰富的插件：\n  battery-widget\n  brightness-widget\n  calendar-widget\n  logout-menu-widget\n  net-speed-widget\n  translate-widget\n  volume-widget: need amixer\n$ pacman -S pulseaudio alsa-utils $ pulseaudio --start custom shotcuts\nawful.key({ modkey }, \u0026#34;]\u0026#34;, function() volume_widget:inc(5) end, {description = \u0026#34;increase the volume\u0026#34;, group = \u0026#34;custom\u0026#34;}), awful.key({ modkey }, \u0026#34;[\u0026#34;, function() volume_widget:dec(5) end, {description = \u0026#34;decrease the volume\u0026#34;, group = \u0026#34;custom\u0026#34;}), awful.key({ modkey }, \u0026#34;\\\\\u0026#34;, function() volume_widget:toggle() end, {description = \u0026#34;switch between mute and unmute\u0026#34;, group = \u0026#34;custom\u0026#34;}),   weather-widget\n  音量控制插件 Awesome 自己不提供音量控制插件，如果未经设置，还会发现原本键盘上的多媒体按键都会失效，这是因为没有让 Awesome 绑定这些热键。下面实现一个音量控制插件，并且将音量控制绑定到多媒体键盘的音量加（XF86AudioRaiseVolume）、音量减（XF86AudioLowerVolume）、静音（XF86AudioMute）几个按键上。\n首先实现一个音量控制插件，将它保存为 ~/.config/awesome/volume.lua：\n-- Create a volume control volume_widget = widget({ type = \u0026#34;textbox\u0026#34;, name = \u0026#34;tb_volume\u0026#34;, align = \u0026#34;right\u0026#34; }) function update_volume(widget) local fd = io.popen(\u0026#34;amixer sget Master\u0026#34;) local status = fd:read(\u0026#34;*all\u0026#34;) fd:close() local volume = tonumber(string.match(status, \u0026#34;(%d?%d?%d)%%\u0026#34;)) / 100 -- volume = string.format(\u0026#34;% 3d\u0026#34;, volume) status = string.match(status, \u0026#34;%[(o[^%]]*)%]\u0026#34;) -- starting colour local sr, sg, sb = 0x3F, 0x3F, 0x3F -- ending colour local er, eg, eb = 0xDC, 0xDC, 0xCC local ir = volume * (er - sr) + sr local ig = volume * (eg - sg) + sg local ib = volume * (eb - sb) + sb interpol_colour = string.format(\u0026#34;%.2x%.2x%.2x\u0026#34;, ir, ig, ib) if string.find(status, \u0026#34;on\u0026#34;, 1, true) then volume = \u0026#34; \u0026lt;span background=\u0026#39;#\u0026#34; .. interpol_colour .. \u0026#34;\u0026#39;\u0026gt; \u0026lt;/span\u0026gt;\u0026#34; else volume = \u0026#34; \u0026lt;span color=\u0026#39;red\u0026#39; background=\u0026#39;#\u0026#34; .. interpol_colour .. \u0026#34;\u0026#39;\u0026gt; M \u0026lt;/span\u0026gt;\u0026#34; end widget.text = volume end update_volume(volume_widget) awful.hooks.timer.register(1, function () update_volume(volume_widget) end) 然后编辑 rc.lua ，在开头引入这个插件：\n-- Volume contrl local volume_widget = require(\u0026#34;volume\u0026#34;) 在 wibox 中添加这个插件，例如放在系统托盘的右侧：\n-- Add widgets to the wibox s.mywibox:setup { layout = wibox.layout.align.horizontal, { -- Left widgets ... }, s.mytasklist, -- Middle widget { -- Right widgets ... volume_widget ... }, 最后绑定到几个多媒体键：\n-- volume control awful.key({ }, \u0026#34;XF86AudioRaiseVolume\u0026#34;, function () awful.util.spawn(\u0026#34;amixer set Master 9%+\u0026#34;) end), awful.key({ }, \u0026#34;XF86AudioLowerVolume\u0026#34;, function () awful.util.spawn(\u0026#34;amixer set Master 9%-\u0026#34;) end), awful.key({ }, \u0026#34;XF86AudioMute\u0026#34;, function () awful.util.spawn(\u0026#34;amixer sset Master toggle\u0026#34;) end), 这个插件将在状态栏放置一个亮度随音量大小改变的白色小方块，当系统处于静音状态时，图标将变为一个红色的 M 字符。\nVicious $ pacman -S vicious 在 rc.lua 头部增加声明信息并添加 Date Widget：\nlocal vicious = require(\u0026#34;vicious\u0026#34;) datewidget = wibox.widget.textbox() vicious.register(datewidget, vicious.widgets.date, \u0026#34;%b %d, %R\u0026#34;) 最后添加到 wibox (statusbar) 中\n-- Add widgets to the wibox s.mywibox:setup { layout = wibox.layout.align.horizontal, { -- Left widgets ... }, s.mytasklist, -- Middle widget { -- Right widgets ... datewidget ... }, xob 音量控制 Awesome 自己不提供音量控制插件，如果未经设置，还会发现原本键盘上的多媒体按键都会失效，这是因为没有让 Awesome 。下面实现一个音量控制插件，并且将音量控制绑定到按键上。\nxob\ninstall pulseaudio\n$ sudo pacman -S pulseaudio pamixer install xob\n$ yay -S xob Ready to use volume bar for pulseaudio\n$ sudo pacman -S python-pip $ pip install pulsectl $ mkdir -p ~/.local/bin $ vim ~/.local/bin/pulse-volume-watcher.py # copy from xob doc $ chmod u+x ~/.local/bin/pulse-volume-watcher.py 为绑定音量热键，在 rc.lua 文件的 globalkeys 里加入\nawful.key({ modkey }, \u0026#34;]\u0026#34;, function () awful.util.spawn_with_shell(\u0026#34;pamixer -i 1\u0026#34;) end, {description = \u0026#34;increase the volume\u0026#34;, group = \u0026#34;custom\u0026#34;}), awful.key({ modkey }, \u0026#34;[\u0026#34;, function () awful.util.spawn_with_shell(\u0026#34;pamixer -d 1\u0026#34;) end, {description = \u0026#34;decrease the volume\u0026#34;, group = \u0026#34;custom\u0026#34;}), awful.key({ modkey }, \u0026#34;\\\\\u0026#34;, function () awful.util.spawn_with_shell(\u0026#34;pamixer -t\u0026#34;) end, {description = \u0026#34;switch between mute and unmute\u0026#34;, group = \u0026#34;custom\u0026#34;}), 开机启动 xob，配置下面自启动方案一后添加如下代码：\nrun_once({ \u0026#34;/home/kurome/.local/bin/pulse-volume-watcher.py | xob\u0026#34; }) 屏幕亮度控制 用 xbacklight 命令\npacman -S xorg-xbacklight xbacklight -set 50 # 亮度设置在 50% xbacklight -inc 10 # 亮度增加 10% xbacklight -dec 10 # 亮度减少 10% xbacklight -get # 获取当前亮度 消息交互 Naughty 是 Awesome 中的一个 lua 库，用于实现弹出消息框。利用 Naughty，我们可以实现在后台执行命令，然后在弹出消息框中显示结果。\n首先要确保 rc.lua 的开头有这一行：\nrequire(\u0026#34;naughty\u0026#34;) 如果想更改naughty的默认设置，可以添加下面的代码：\nnaughty.config.default_preset.timeout = 5 naughty.config.default_preset.screen = 1 naughty.config.default_preset.position = \u0026#34;top_right\u0026#34; naughty.config.default_preset.margin = 4 naughty.config.default_preset.height = 16 naughty.config.default_preset.width = 300 naughty.config.default_preset.gap = 1 naughty.config.default_preset.ontop = true naughty.config.default_preset.font = beautiful.font or \u0026#34;Verdana 8\u0026#34; naughty.config.default_preset.icon = nil naughty.config.default_preset.icon_size = 16 naughty.config.default_preset.fg = beautiful.fg_focus or \u0026#39;#ffffff\u0026#39; naughty.config.default_preset.bg = beautiful.bg_focus or \u0026#39;#535d6c\u0026#39; naughty.config.presets.normal.border_color = beautiful.border_focus or \u0026#39;#535d6c\u0026#39; naughty.config.default_preset.border_width = 1 naughty.config.default_preset.hover_timeout = nil 下面利用sdcv实现一个词典工具，绑定到 Mod4 + d 上，更多的例子可以参考 官方的教程 。\nawful.key({ modkey }, \u0026#34;d\u0026#34;, function () info = true awful.prompt.run({ fg_cursor = \u0026#34;black\u0026#34;,bg_cursor=\u0026#34;orange\u0026#34;, prompt = \u0026#34;\u0026lt;span color=\u0026#39;#008DFA\u0026#39;\u0026gt;sdcv:\u0026lt;/span\u0026gt;\u0026#34; }, mypromptbox[mouse.screen].widget, function(word) local f = io.popen(\u0026#34;sdcv -n \u0026#34; .. word) local fr = \u0026#34;\u0026#34; for line in f:lines() do fr = fr .. line .. \u0026#39;n\u0026#39; end f:close() naughty.notify({ title = \u0026#34;\u0026lt;span color=\u0026#39;red\u0026#39;\u0026gt;\u0026#34; .. word .. \u0026#34;\u0026lt;/span\u0026gt;:\u0026#34;, text = \u0026#39;\u0026lt;span font_desc=\u0026#34;Sans 7\u0026#34;\u0026gt;\u0026#39; .. fr ..\u0026#39;\u0026lt;/span\u0026gt;\u0026#39;, timeout = 5, width = 400, screen = mouse.screen }) end) end) ) 标题栏 搜索 titlebars_enabled ，设置为 false 来取消标题栏。\n{ rule_any = {type = { \u0026#34;normal\u0026#34;, \u0026#34;dialog\u0026#34; } }, properties = { titlebars_enabled = false } }, 自启动 最简单的方式是在 rc.lua 里添加类似这样的代码：\nawful.util.spawn_with_shell(\u0026#34;firefox\u0026#34;) awful.util.spawn_with_shell(\u0026#34;thunderbird\u0026#34;) awful.util.spawn_with_shell(\u0026#34;amarok\u0026#34;) awful.util.spawn_with_shell(\u0026#34;amule\u0026#34;) Rules of thumb when a shell(spawn_with_shell) is needed:\n A shell is required when the commands contain \u0026amp;\u0026amp;, ;, ||, \u0026amp; or any other unix shell language syntax When shell variables are defined as part of the command When the command is a shell alias  方案一 local function run_once(cmd_arr) for _, cmd in ipairs(cmd_arr) do awful.spawn.with_shell(string.format(\u0026#34;pgrep -u $USER-fx \u0026#39;%s\u0026#39; \u0026gt; /dev/null || (%s)\u0026#34;, cmd, cmd)) end end run_once({ \u0026#34;synergy\u0026#34; }) run_once({ \u0026#34;ibus-daemon -d -x -r -n awesome\u0026#34; }) run_once({ \u0026#34;compton --conf /home/kelu/.config/compton.conf\u0026#34; }) run_once({ \u0026#34;/home/kelu/Desktop/WeChat.desktop\u0026#34; }) 方案二 To implement the XDG autostart specification, create autorun.sh and insert the following:\n$ vim .config/awesome/autorun.sh #!/usr/bin/env bash function run { if ! pgrep -f \u0026#34;$1\u0026#34; ; then $@\u0026amp; fi } Then, make it executable.\n$ chmod u+x .config/awesome/autorun.sh 要在自动启动中添加程序，只需在autorun.sh中添加run \u0026quot;program [some arguments]\u0026quot;。run函数检查是否已经有一个参数相同的program实例，如果没有，则运行program。\n$ vim ~/.config/awesome/autorun.sh ... run \u0026#34;fcitx5\u0026#34; If everything is fine, add the following line to your rc.lua:\n$ vim ~/.config/awesome/rc.lua ... awful.spawn.with_shell(\u0026#34;~/.config/awesome/autorun.sh\u0026#34;) ... 自定义快捷键 查看键映射表\n$ xmodmap -pm shift Shift_L (0x32), Shift_R (0x3e) lock Caps_Lock (0x42) control Control_L (0x25), Control_R (0x69) mod1 Alt_L (0x40), Meta_L (0xcd) mod2 Num_Lock (0x94) mod3 mod4 Super_R (0x86), Super_L (0xce), Hyper_L (0xcf) mod5 ISO_Level3_Shift (0x5c), ISO_Level3_Shift (0x6c), Mode_switch (0x85), Mode_switch (0xcb) 编辑 rc.lua，在文件中查找文本\n-- {{{ Key bindings globalkeys = awful.util.table.join( 在此之下，可以添加您的自定义命令，例如：\n-- {{{ Key bindings globalkeys = awful.util.table.join( -- My Bindings awful.key({ }, \u0026#34;F1\u0026#34;, function () awful.util.spawn_with_shell(\u0026#34;terminator\u0026#34;) end), 以下是我的一些例子，注意不要和原有的快捷键冲突噢：\n-- Custom awful.key({ \u0026#34;Control\u0026#34; , }, \u0026#34;3\u0026#34;, function () awful.util.spawn_with_shell(\u0026#34;shutter -f\u0026#34;) end, {description = \u0026#34;screenshot\u0026#34;, group = \u0026#34;custom\u0026#34;}), awful.key({ \u0026#34;Control\u0026#34; , }, \u0026#34;4\u0026#34;, function () awful.util.spawn_with_shell(\u0026#34;shutter -a\u0026#34;) end, {description = \u0026#34;screenshot\u0026#34;, group = \u0026#34;custom\u0026#34;}), awful.key({ \u0026#34;Control\u0026#34; , }, \u0026#34;5\u0026#34;, function () awful.util.spawn_with_shell(\u0026#34;shutter -s\u0026#34;) end, {description = \u0026#34;screenshot\u0026#34;, group = \u0026#34;custom\u0026#34;}), awful.key({ modkey, }, \u0026#34;e\u0026#34;, function () awful.util.spawn_with_shell(\u0026#34;nautilus --no-desktop .\u0026#34;) end, {description = \u0026#34;nautilus\u0026#34;, group = \u0026#34;custom\u0026#34;}), awful.key({ modkey, }, \u0026#34;w\u0026#34;, function () awful.util.spawn_with_shell(\u0026#34;/usr/share/typora/Typora /home/kelu/Workspace/document/todo.md\u0026#34;) end, {description = \u0026#34;Typora\u0026#34;, group = \u0026#34;custom\u0026#34;}), -- awful.key({ modkey, }, \u0026#34;w\u0026#34;, function () awful.util.spawn_with_shell(\u0026#34;nautilus --no-desktop .\u0026#34;) end, -- {description = \u0026#34;nautilus\u0026#34;, group = \u0026#34;custom\u0026#34;}), awful.key({ modkey, }, \u0026#34;b\u0026#34;, function () awful.util.spawn_with_shell(\u0026#34;google-chrome-stable\u0026#34;) end, {description = \u0026#34;chrome\u0026#34;, group = \u0026#34;custom\u0026#34;}), 我配置了自己的group叫custom，所有快捷键的信息可以使用 Mod4+S 快捷键查询。\n关闭窗口快捷键 在方法 clientkeys = awful.util.table.join 内部添加：\nawful.key({ modkey, }, \u0026#34;q\u0026#34;, function (c) c:kill() end, {description = \u0026#34;close\u0026#34;, group = \u0026#34;custom\u0026#34;}), awful.key({ altkey, }, \u0026#34;q\u0026#34;, function (c) c:kill() end, {description = \u0026#34;close\u0026#34;, group = \u0026#34;custom\u0026#34;}), 关机  shutdown: systemctl poweroff reboot: systemctl reboot suspend: program pause \u0026amp;; systemctl suspend logout: loginctl terminate-session ${XDG_SESSION_ID-}  其他 picom compton，用于透明美化等功能的工具，如果你当前使用的软件支持窗口透明的功能，那么compton可以帮你设置透明度，阴影效果，窗口切换效果等：\n$ sudo pacman -S picom $ mkdir -p ~/.config/picom/ $ cp -av /etc/xdg/picom.conf ~/.config/picom/picom.conf   Screentearing with NVIDIA\u0026rsquo;s proprietary drivers, Try this setting in picom.conf:\nvsync = true;   picom.sample.conf\n  启动与添加到自启动\n$ picom \u0026amp; $ vim ~/.config/awesome/rc.lua run_once({ \u0026#34;picom\u0026#34; }) Start Numlock At Boot You can start numlock at boot by installing this package:\n$ sudo pacman -S numlockx Then, insert this line in the ~/.xinitrc file two lines above the exec line:\nnumlockx \u0026amp; Change Display Resolution And Refresh Rate If you want to change the display resolution or the refresh rate of your monitor, you can use any of these programs.\nNVIDIA cards:\n$ sudo pacman -S nvidia-settings XFCE settings manager:\n$ sudo pacman -S xfce4-settings You can also use Xrandr to set your resolution and refresh rate. For a single 1080p monitor with 120Hz refresh rate, you can run this command\n$ xrandr --output DP-0 --mode 1920x1080 --rate 120 You can also just use xrandr to see what displays are connected and what resolutions and refresh rates they support\n$ xrandr Awesome Menu Awesome has a menu at the top left corner by default which may be useless to some people. You can disable it if you want by commenting the lines like mentioned below. These lines should start from 83.\n-- {{{ Menu -- Create a launcher widget and a main menu --myawesomemenu = { -- { \u0026#34;hotkeys\u0026#34;, function() hotkeys_popup.show_help(nil, awful.screen.focused()) end }, -- { \u0026#34;manual\u0026#34;, terminal .. \u0026#34; -e man awesome\u0026#34; }, -- { \u0026#34;edit config\u0026#34;, editor_cmd .. \u0026#34; \u0026#34; .. awesome.conffile }, -- { \u0026#34;restart\u0026#34;, awesome.restart }, -- { \u0026#34;quit\u0026#34;, function() awesome.quit() end }, --}--mymainmenu = awful.menu({ items = { { \u0026#34;awesome\u0026#34;, myawesomemenu, beautiful.awesome_icon }, { \u0026#34;open terminal\u0026#34;, terminal } -- } -- }}--mylauncher - awful.widget.launcher({ image = beautiful.awesome_icon, -- menu = mymainmenu }) Force An Application To A Specific Tag You can force an application to always open in a specific tag. To do this, add these lines in the rc.lua file\n-- Set applications to always map on the tag 7 on screen 1. { rule = { class = \u0026#34;Thunderbird\u0026#34; }, properties = { screen = 1, tag = awful.util.tagnames[7] , switchtotag = true } }, Here, we want Thunderbird to open on tag 7 and on screen 1. You can modify and duplicate to as many applications you want\n输入法 安装\n$ pacman -S ibus ibus-rime 在 Awesome 的 rc.lua 中加入以下语句，让 Awesome 启动的时候顺便运行 ibus-daemon\nawful.util.spawn(\u0026#34;ibus-daemon -d -x -r -n awesome\u0026#34;)  -d: run ibus as background process. -x: execute ibus XIM server. -r: if there is an old ibus-daemon is running, it will be replaced. -n: specify the name of desktop session. [default=gnome]  另外为了让各种图形库都能识别 ibus ，还需要在 $HOME/.profile 中加入这几个 环境变量：\nexport GTK_IM_MODULE=ibus export XMODIFIERS=@im=ibus export QT_IM_MODULE=ibus 屏保和休眠管理 这个其实好办， Xorg 下的e屏保有很多选择，而且大都附带休眠管理的配置。我挑了 “老牌”的 xscreensaver\n$ pacman -S xscreensaver 在 Awesome 的 rc.lua 配置文件里加入：\nawful.util.spawn(\u0026#34;xscreensaver -no-splash\u0026#34;) xscreensaver 的配置选项也很多，不过我们可以通过 xscreensaver-demo 命令用图 形界面进行设置，所有选项都保存在 $HOME/.xscreensaver 文件中。\n添加一个快捷键：\nawful.key({ \u0026#34;Mod4\u0026#34; }, \u0026#34;l\u0026#34;, function () awful.util.spawn_with_shell(\u0026#34;xscreensaver-command --lock\u0026#34;) end, {description = \u0026#34;lock the screen immediately\u0026#34;, group = \u0026#34;custom\u0026#34;}), rofi 安装\n$ pacman -S rofi $ mkdir -p ~/.config/rofi/ $ rofi -dump-config \u0026gt; ~/.config/rofi/config.rasi 添加快捷键(base on awesome-copycats)\nawful.key({ modkey }, \u0026#34;r\u0026#34;, function () os.execute(string.format(\u0026#34;rofi -show %s -theme %s\u0026#34;, \u0026#39;drun\u0026#39;, \u0026#39;\u0026#39;)) end, {description = \u0026#34;show rofi\u0026#34;, group = \u0026#34;launcher\u0026#34;}), awful.key({ altkey }, \u0026#34;r\u0026#34;, function () os.execute(string.format(\u0026#34;rofi -show %s -theme %s\u0026#34;, \u0026#39;run\u0026#39;, \u0026#39;\u0026#39;)) end, {description = \u0026#34;show rofi\u0026#34;, group = \u0026#34;launcher\u0026#34;}), awful.key({ altkey }, \u0026#34;Tab\u0026#34;, function () os.execute(string.format(\u0026#34;rofi -show %s -theme %s\u0026#34;, \u0026#39;window\u0026#39;, \u0026#39;\u0026#39;)) end, {description = \u0026#34;show rofi\u0026#34;, group = \u0026#34;launcher\u0026#34;}), mpd\u0026amp;ncmpcpp 介绍\nmpd：mpd是一个播放本地音乐的后台服务\nncmpcpp：ncmpcpp是mpd的TUI前端，用来控制mpd的工作，此外也提供一些方便的功能比如查找歌曲，支持flac等多种音乐格式\n总之两者是client/server的关系\n安装即可：\n$ pacman -S mpd ncmpcpp 配置方法\n配置分为两步，一步是mpd的，另一步是ncmpcpp的\n这里建议直接用我的配置。记得把~/.config/mpd/mpd.conf和~/.config/ncmpcpp/config里面的音乐目录改成你的音乐路径即可\n我的配置声音输出用的是pulseaudio，所以你需要保证你的pulseaudio工作正常。\n使用\n启动mpd服务\n$ systemctl start mpd.service --user 之后启动ncmpcpp，具体用法这里不再赘述，直接查看archwiki或者在ncmpcpp里面按F1即可看到。\n出现问题之后首先检查mpd的日志\n$ systemctl status mpd --user 根据不同的提示来解决问题\n如果没有声音，首先检查一下pulseaudio，用pulseaudio的GUI配置工具pavucontrol即可\nflameshot awful.key({ modkey, \u0026#34;Shift\u0026#34; }, \u0026#34;Print\u0026#34;, function () awful.util.spawn_with_shell(\u0026#34;flameshot gui\u0026#34;) end, {description = \u0026#34;Switch between windows\u0026#34;, group = \u0026#34;custom\u0026#34;}), awesome-copycats $ git clone --recurse-submodules --remote-submodules --depth 1 -j 2 https://github.com/lcpz/awesome-copycats.git $ mv -bv awesome-copycats/{*,.[^.]*} ~/.config/awesome; rm -rf awesome-copycats $ mv -bv awesome-copycats/* ~/.config/awesome; rm -rf awesome-copycats Additional default software used:\n$ pacman -S curl alsa-utils dmenu firefox mpc mpd flameshot unclutter xorg-xbacklight xsel slock 然后再 rc.lua 取消掉一些注释以启用某些功能\n  rofi instead of dmenu\n  flameshot shotcut\n  slock: To unlock slock, simply type your user password at the blank screen. You can verify this is the process via slock\u0026rsquo;s readme.\nawful.key({ modkey }, \u0026#34;l\u0026#34;, function () os.execute(\u0026#34;slock\u0026#34;) end, {description = \u0026#34;lock screen\u0026#34;, group = \u0026#34;hotkey\u0026#34;}),   Unclutter hides your X mouse cursor when you do not need it, to prevent it from getting in the way.\n  xsel — Command-line program for getting and setting the contents of the X selection.\n  mpd \u0026amp; mpc: Music Player Daemon\n  Touchpad disable touchpad:\n$ sudo pacman -S xorg-xinput $ xinput list | grep Touchpad ⎜ ↳ FTE1200:00 0B05:0501 Touchpad id=15\t[slave pointer (2)] $ xinput disable \u0026#34;FTE1200:00 0B05:0501 Touchpad\u0026#34; $ vim .xinitrc xinput disable \u0026#34;FTE1200:00 0B05:0501 Touchpad\u0026#34; xbindkeys $ sudo pacman -S pulseaudio xbindkeys 之后通过 xbindkeys --multikey 获取键盘上与音量有关的 keycodes，也就是 f10、f11、f12\n$ xbindkeys --multikey \u0026#34;(Scheme function)\u0026#34; m:0x0 + c:76 F10 \u0026#34;(Scheme function)\u0026#34; m:0x0 + c:95 F11 \u0026#34;(Scheme function)\u0026#34; m:0x0 + c:96 F12 通过如下命令添加默认配置\n$ xbindkeys -d \u0026gt; ~/.xbbaindkeysrc 将如下代码添加到 ~/.xbindkeysrc 最后\n# Increase volume \u0026#34;pactl set-sink-volume @DEFAULT_SINK@ +1000\u0026#34; m:0x0 + c:96 F12 # Decrease volume \u0026#34;pactl set-sink-volume @DEFAULT_SINK@ -1000\u0026#34; m:0x0 + c:95 F11 # Mute volume \u0026#34;pactl set-sink-mute @DEFAULT_SINK@ toggle\u0026#34; m:0x0 + c:76 F10 然后启用：\n$ xbindkeys redshift $ sudo pacman -S redshift $ cat \u0026gt;\u0026gt; ~/.config/awesome/rc.lua awful.util.spawn(\u0026#34;redshift-gtk -l 39.5:116.2\u0026#34;) Tip: You can get the coordinates of a place with GeoNames.org\nautostart 效果不是很好，所以改为手动启用\n","permalink":"https://sakamotokurome.github.io/posts/archlinux/","summary":"Installation guide Arch Linux 安装使用教程 Archlinux 简明指南 给 GNU/Linux 萌新的 Arch Linux 安装指南 了解 Archlinux 为什么使用 Linux？ 简单来说，现在世界上流行的 PC 操作系统有三个，Windows，","title":"ArchLinux"},{"content":"Portage介绍 欢迎使用 Portage Portage 系统是 Gentoo 在软件管理方面最显著的创新之一。由于 Portage 的高度灵活性和数量庞大的特性，它时常被誉为 Linux 下最好的软件管理工具。\nPortage 是用 Python 和 Bash 两种语言编写的。因为它们都是脚本语言所以用户可以直接阅读它的代码。\n大多数用户通过 emerge 使用 Portage。本章的内容不是复述 emerge 的 man page。要了解 emerge 的所有可用选项，请查阅 emerge 的 man page（emerge 中文手册）：\n# man emerge Gentoo 软件仓库 查询 Portage 的信息\n# emerge --info Ebuild 当 Gentoo 的文档介绍某个软件包的时候，这意味着 Gentoo 的用户们可以在 Gentoo 的软件仓库里找到它。ebuild 是一种包含了所有 Portage 维护软件（比如安装，搜索，查询等等）所需信息的文件，而 Gentoo 的软件仓库是它们的一个集合。这些 ebuild 文件默认储存在 /var/db/repos/gentoo。\nPortage 对于软件的行为都是基于本地的 ebuild。为了能收到新的软件包，安全更新等等，时常更新本地 ebuild 是一件很重要的事情。\n更新 Gentoo 软件仓库 Gentoo 的软件仓库通常使用 rsync 进行同步，rsync 是一个快速的文件增量传输工具。要使用它很简单，Portage 的命令行前端 emerge 提供了一个调用 rsync 的方法：\n# emerge --sync 有时防火墙会干扰 rsync 与镜像的连接。这时，我们可以使用 emerge-webrsync 来自动下载和安装 Portage 树的快照版本：\n# emerge-webrsync 使用 emerge-webrsync 的另一个好处是可以只安装由 Gentoo release engineering 团队的 GPG 密钥签名过的快照。与此有关的详细信息可以在 fetching validated Gentoo repository snapshots 找到\n维护软件 搜索软件 有很多方法可以在 Gentoo 的软件仓库寻找软件。其中之一是使用 emerge 本身。在默认情况下 emerge \u0026ndash;search 会返回所有符合搜索条件的包名。\n举个例子，找出所有名字里含有 “pdf” 的包：\n# emerge -s \u0026lt;包名\u0026gt; # emerge --search pdf 如果要根据描述进行搜索，可以使用 --searchdesc （或 -S）选项:\n# emerge --searchdesc pdf 需要注意的是它会输出很多信息。不过由于都有很清楚的标识，我们就不再赘述它们的意思了。\n安装软件 当你找到了软件包的名字，安装它只需要简单得使用 emerge。举个例子，如果要安装 gnumeric：\n# emerge \u0026lt;包名\u0026gt; # emerge --ask app-office/gnumeric 由于很多软件依赖其它的软件，在安装该软件的同时很可能还会安装它的一些以来。不要担心，Portage 可以很好地处理依赖关系。如果要知道 Portage 会安装什么软件，可以在命令中加入 -p/--pretend选项。举个例子：\n# emerge --pretend gnumeric 在安装软件期间，Portage将从Internet下载必要的源代码（如果需要），并将其默认存储在 /var/cache/distfiles/ 中。 之后，它将解压缩，编译和安装包。 要让Portage仅下载源代码而不安装软件，请添加-f/--fetchonly选项到emerge命令：\n# emerge --fetchonly gnumeric 恢复上一次失败的 emerge\n# emerge -r 其它常用的选项有\n  -1/--oneshot 一般用在安装软件包时，不将该包添加到 world 集中\n  -O/--nodeps 不计算依赖关系，只操作指定的包（安装时可能会因为依赖不满足而导致安装失败）\n  -j/--jobs 设置 Portage 同时执行的最大任务数，如果未设置数量，那么 Portage 不会限制最大的任务数。如果要将该选项添加到默认选项下，那么建议配合 -l/--load-average 使用， -l/--load-average 用于配置 emerge 的负载阈值，当当前负载到达设定值后， emerge 将不再开启新任务，以避免负载过高，这在 CPU 不够强悍或者内存不宽裕的机器上很需要。比如在一个 8 核 16 线程 16G 内存的机器上，可以设置成 -j -l 12 ，这样的设定使 portage 的并行任务数不由硬性规定的数目来限制，而是通过动态负载来进行限制。\n  --keep-going 它会在安装出错时，跳过安装失败的包，并重新计算依赖后继续安装剩余包\n  -n/--noreplace 不重复安装已经安装的包（默认会忽略掉 USE 的改动以及升级的查询，除非对应加上 -D/-U 和 -u 选项）\n  -t/--tree 显示给定包的安装依赖树\n  --autounmask 类\n这是一组在新装软件包时便于解除安装限制的选项。之前有介绍，在 Portage 安装软件的过程中，可能会因为 USE/License/Keywords 等因素导致无法直接安装，需要配置后再进行，而这组选项可以自动化这个过程。个人建议的相关选项组合为 --autounmask --autounmask-keep-masks --autounmask-write=n ，此组合不会完全自动写入配置到系统下，但是提示了如何配置，方便手动写入，既简化了处理限制的流程，又能保证掌握每次安装包时的改动。\n  查找已安装软件的文档 许多软件包中包含有自己的文档，有些时候，doc的USE标记决定了软件包中的自带文档是否会被安装。您可以通过 emerge -vp category/包名命令来检查是否存在doc USE 标志：\n# emerge -vp media-libs/alsa-lib These are the packages that would be merged, in order: Calculating dependencies... done! [ebuild R ] media-libs/alsa-lib-1.1.3::gentoo USE=\u0026#34;python -alisp -debug -doc\u0026#34; ABI_X86=\u0026#34;(64) -32 (-x32)\u0026#34; PYTHON_TARGETS=\u0026#34;python2_7\u0026#34; 0 KiB 最好的启用 doc USE 的方式是在 /etc/portage/package.use里对想要启用的包单独启用，这样你就能只获得你想要的软件文档。了解更多信息请阅读 USE flags chapter。\n当一个软件包安装结束后，它的文档通常会存放在/usr/share/doc/目录下的，以软件包名命名的子目录中：\n$ ls -l /usr/share/doc/alsa-lib-1.1.3 total 16 -rw-r--r-- 1 root root 3098 Mar 9 15:36 asoundrc.txt.bz2 -rw-r--r-- 1 root root 672 Mar 9 15:36 ChangeLog.bz2 -rw-r--r-- 1 root root 1083 Mar 9 15:36 NOTES.bz2 -rw-r--r-- 1 root root 220 Mar 9 15:36 TODO.bz2 列出已安装文档文件的更可靠方法是使用 equery 的 --filter 选项。 equery 用于查询Portage的数据库，并作为 app-portage/gentoolkit 包的一部分：\n$ equery files --filter=doc alsa-lib * Searching for alsa-lib in media-libs ... * Contents of media-libs/alsa-lib-1.1.3: /usr/share/doc/alsa-lib-1.1.3/ChangeLog.bz2 /usr/share/doc/alsa-lib-1.1.3/NOTES.bz2 /usr/share/doc/alsa-lib-1.1.3/TODO.bz2 /usr/share/doc/alsa-lib-1.1.3/asoundrc.txt.bz2 --filter 选项可与其他规则一起使用，以查看许多其他类型文件的安装位置。可以在 equery 的手册中查看其他功能: man 1 equery。\n卸载软件 当您想把一个软件包从系统中移除的时候，使用 emerge \u0026ndash;unmerge命令。命令执行完成后，Portage将会移除此软件包安装到您系统中的所有文件，除了那些在安装软件后您修改过的配置文件。保留这些修改过的配置文件是为了便于您今后再次使用它。\n# emerge --unmerge gnumeric # emerge -C \u0026lt;包名\u0026gt; 当您从系统中移除一个软件包时，之前那些为了满足其依赖关系而被自动安装的软件包将会被保留在系统中。要使Portage找到现在可以删除的所有依赖项，可以使用 --depclean 功能。\n自动清理系统下的软件包\n# emerge --ask --depclean # emerge -ac 默认选项 emerge 支持配置一组默认选项，用于在每次运行 emerge 时采用。这个储存默认选项的变量名为 EMERGE_DEFAULT_OPTS ，在 /etc/portage/make.conf 文件下设置。\n这里一组比较推荐的默认选项配置为\nEMERGE_DEFAULT_OPTS=\u0026#34;--autounmask --autounmask-keep-masks --autounmask-write=n --keep-going -v -j -l 12\u0026#34; 其中的 12 请根据实际情况修改，如果配置了上文的 binhost ，那么对应选项也添加进入。\nUnderstanding Portage\u0026rsquo;s Formatted and Colored Output Output from portage is compactly formatted to indicate a plethora of information.\nEmerge \u0026ldquo;Pretend\u0026rdquo; Output\n N = new (not yet installed) S = new SLOT installation (side-by-side versions) U = updating (to another version) D = downgrading (best version seems lower) R = replacing (re-merging same version) F = fetch restricted (must be manually downloaded) f = fetch (already downloaded) B = blocked by an already installed package  USE Flags\n An unmarked USE flag is unchanged and enabled. - A dash preceding a USE flag (yellow, green or blue) shows that it is disabled. % A percent symbol following a USE flag indicates that it is new for this package. Identical to yellow output. ***** An asterisk following a USE flag indicates that its meaning/scope has been updated. Identical to green output. () Parentheses around a USE flag indicate that it is currently masked by your profile. This is usually because the USE flag can not be supported on the given platform (for example, the win32codecs on amd64 with non-binary packages) or is irrelevant (for example, sse is available on all amd64 CPU\u0026rsquo;s, so there\u0026rsquo;s no point being able to disable it in a 64-bit environment).  Color Output\nPortage returns information to you using both symbols and colors. While the combination makes for a pretty output it also may appear confusing on first glance. Note that the color information is not required, so it repeats the symbolic output.\n red - The USE flag is enabled and has not changed. yellow - The USE flag has been added since the package was last installed. green - The USE flag has changed since the last time the package was installed, as the asterisk after it indicates. blue - The USE flag is disabled, as the dash before it indicates.  Example\nIf you run the command\n# emerge --update --verbose --deep --newuse world you might get something similar to\n[ebuild R ] sys-kernel/linux-headers-2.6.11-r2 USE=\u0026quot;-gcc64%\u0026quot; 36,470 kB [ebuild U ] sys-process/psmisc-22.2 USE=\u0026quot;X* ipv6 nls (-selinux)\u0026quot; 238 kB In this example the sys-kernel/linux-headers package would be reinstalled as indicated by the \u0026ldquo;R\u0026rdquo; at the beginning of the line. The sys-process/psmisc package is being updated, as shown by the \u0026ldquo;U\u0026rdquo; at the beginning of the line.\n The gcc64 USE flag is colored yellow and followed by \u0026ldquo;%\u0026rdquo; showing that that option has been added since the package was last installed. The \u0026ldquo;-\u0026rdquo; shows that it will be disabled during this update. The X USE flag will be green and followed by \u0026ldquo;*\u0026rdquo; because that USE flag has changed since the last time the package was installed, as the asterisk after it indicates. No \u0026ldquo;-\u0026rdquo; shows that it will be enabled during this update. The ipv6 and nls USE flags would appear red since they are enabled (No \u0026ldquo;-\u0026quot;) and have not changed (No \u0026ldquo;*****\u0026quot;). The selinux USE flag will be blue because the flag is disabled, as the dash before it indicates. The parentheses also show that it is an unavailable or irrelevant option.  更新系统 要保持您的系统在最佳状态（更不用说安装那些最新的安全更新），您需要定期的更新您的系统。由于Portage只能检查本地已有文件，因此您首先应该更新您的Portage树。当您的Portage树更新后，您可以用 emerge \u0026ndash;update @world命令来更新系统。在下一个例子里，我们还会使用 --ask 选项来控制Portage显示它要更新的软件包列表， 并让您决定是否继续更新。\n# emerge --update --ask @world Portage将搜索已安装的程序的新版本。 然而，它只会验证明确安装的应用程序（在 /var/lib/portage/world 列出的应用程序）的版本，却不会检查它们的依赖项。若要更新这些包的依赖项，请添加 --deep 选项：\n# emerge --update --deep @world 但是，这并不意味着会更新所有的软件包：某些系统上的软件包，会在编译和构建软件的过程中需要，但是一旦安装完软件，就不再需要这些依赖项。 Portage 称这些依赖为“构建依赖”。 若要在更新时包含这些构建依赖，请添加 --with-bdeps=y 选项：\n# emerge --update --deep --with-bdeps=y @world 因为有时那些没有明确安装的包（但作为其他软件包的依赖而装入系统中）会推出安全更新，所以推荐偶尔运行一下这个命令。\n每当您改变了系统中任何的 USE 标记后，最好加入 --newuse 选项。这样 Portage 将会验证这个 USE 标记变动后，是否需要安装新的软件包或者将现有的软件包重新编译。\n# emerge --update --deep --with-bdeps=y --newuse @world Meta软件包\nGentoo中的一些软件包并没有包含任何实际的内容，而只是用来安装一系列软件包的集合。例如，kde-plasma/plasma-meta 包就是一个包含了一系列与Plasma相关的互相依赖的软件包的集合，您可以通过安装它来在系统中搭建起一个完整的KDE Plasma 桌面环境。\n如果您试图从系统中移除一个这样的软件包的集合体，只是单纯地使用 emerge \u0026ndash;unmerge 命令并不能完成您的要求，原因在于这些包的依赖关系仍然保留在系统中。\n不用担心，Portage也提供了移除孤立依赖的软件包的功能，但由于软件包间的依赖关系是动态的，您首先需要充分地更新您的整个系统，包括更改USE标记设定而导致的变化。在这之后您可以运行emerge \u0026ndash;depclean来移除那些完全没有被其他包依赖的软件包。移除之后你需要重新编译那些曾经与刚刚移除的这些包动态连接过的应用程序，因为实际上这些程序不需要那些包。\n所有这些可以用以下三个命令来实现：\n# emerge --update --deep --newuse @world # emerge --depclean # revdep-rebuild 关于配置文件的更新 有时候在更新了某些软件包后你会发现出现了一个类似如下的提示信息：\n* IMPORTANT: 2 config files in \u0026#39;/etc\u0026#39; need updating. * See the CONFIGURATION FILES and CONFIGURATION FILES UPDATE TOOLS * sections of the emerge man page to learn how to update config files. 一般出现这种情况的直接原因是你通过归属于一个软件包的文件修改了其默认配置，导致新安装的文件与现存文件不符，于是 Portage 出于保护现存文件的目的，将新文件重命名为了对应目录下的 ._cfgxxxx_\u0026lt;原名\u0026gt; 文件，这是一个很常见的情况。\n而每当出现这种情况后，需要做的操作就是人工介入，判断一下保留哪个文件，还是将两个文件合并。而自带用于进行此操作的对应命令有 dispatch-conf 与 etc-update 。\n以 dispatch-conf 为例，root 权限下执行后，它会逐个文件列出改动，然后提示你进行操作，比如按 z 保留旧的配置文件，按 u 使用新安装的配置文件替换旧的，等等。\n改变桌面环境/ Change Profile   首先修改 /var/lib/portage/world 文件，这个文件记录了用户主动安装的软件，换句话说，整个系统的构建就是围绕这 world 来创建的。将这个文件中不再需要的包删除，比方说 KDE 的软件和一些后续可以再安装，而目前保留可能造成构建麻烦的软件，比方说 htop，megasync，telegram-desktop，fcitx5 之类的，尽量减少到保留必须的就可以了，比方说内核，zfs 之类的。另外可以使用 emerge --deselect xxxx 命令清理 world 。\n  然后是修改或是删除暂时不需要的 USE 配置文件。这里需要强调一下，world 文件是我们手动安装的软件，这些软件用 /etc/portage/package.use/ 定义了其他附带安装的软件包和组。里面不再需要的包，就需要精简，甚至是删除。\n  其次使用 eselect profile 修改配置文件到需要的 Profile 。\n  再次就是运行 emerge --sync; emerge --depclean 来清理系统。一般情况下，这个步骤会删除数百个包，耐心等它完成。\n  最后就是一些收尾工作，清理结束后，运行一些小工具来解决一些新老软件依赖的问题，运行下面的命令一波清：\n# emerge -avj @preserved-rebuild; perl-cleaner --all; emerge --sync; emerge -avujDN --with-bdeps=y --autounmask-write=y @world 运行以后看看会不会有什么 Block 之类的包，或者循环依赖的包，手动删除下；还有时候解决不了看看是不是 USE 没有清理干净，多试几次就会清理干净，更新没有任何报错就可以开始后续的操作了。\n  这个时候一般会来一次全系统重构。命令如下：\n# emerge -ej --keep-going @world   清理 /home/\u0026lt;user\u0026gt;/ 下的各种配置文件，安装新的桌面环境。\n  Licenses 从Portage版本2.1.7开始，可以根据其授权协议接受或拒绝安装软件。 portage 树中的所有包在其ebuild中包含一个LICENSE选项。 运行emerge \u0026ndash;search package/category 将显示软件包的许可证。\nImportant：ebuild 中 的 LICENSE 变量仅是为 Gentoo 开发人员和用户准备的一份指南。它既不是法律声明，也不保证其真实性。因此不要过度依赖它，您需要深入检查软件包的本身，以及您使用的所有文件。\n默认情况下，Portage允许自由软件基金会，开源计划或遵循自由软件定义明确批准的许可。\n控制允许的许可证的变量称为ACCEPT_LICENSE，可以在/etc/portage/make.conf文件中设置。 在下一个示例中，将显示他的默认值：\nACCEPT_LICENSE=\u0026#34;-* @FREE\u0026#34; 使用此配置，可以安装具有自由软件或文档许可证的软件包。非自由软件将无法安装。\n可以在ACCEPT_LICENSE中全局设置 ACCEPT_LICENSE，或者在/etc/portage/package.license 文进行配置。\n举个例子，要允许www-client/google-chrome 包的google-chrome的授权协议， 把下面的内容添加到 /etc/portage/package.license:\n\u0026lt;类\u0026gt;/\u0026lt;名\u0026gt; \u0026lt;许可名称\u0026gt; www-client/google-chrome google-chrome # 亦可指定版本，比如对 20210818 及以上版本的 sys-kernel/linux-firmware 进行配置 \u0026gt;=sys-kernel/linux-firmware-20210818 linux-fw-redistributable no-source-code 这允许安装www-client/google-chrome 程序包，但禁止安装www-plugins/chrome-binary-plugins 程序包，即使它具有相同的 授权协议。\n重要：授权协议存储在 /var/db/repos/gentoo/licenses/ ，授权协议组在/var/db/repos/gentoo/profiles/license_groups 里面。CAPITAL字母中每行的第一个条目是许可证组的名称，之后的每个条目都是单独的许可证。\n在 ACCEPT_LICENSE 变量中定义的许可证组前缀为@ 符号。一种可能的设置（以前的Portage默认设置），是允许除“最终用户许可协议（EULA）”以外所有的许可证，“最终用户许可协议（EULA）”中的许可证需要阅读并签署接受协议。要完成此操作，请接受所有许可证（使用*），然后删除EULA组中的许可证，如下所示：\nACCEPT_LICENSE=\u0026#34;* -@EULA\u0026#34; 请注意，此设置也将接受非自由软件和文档。\nMasking \u0026amp; Unmasking packages package.mask中指定的软件将会不被安装（可以将其看成黑名单），当新版本的软件出现一些问题的时候（或者是不兼容）可以在这个文件中添加对应的记录。\n/etc/portage/package.unmask 文件的作用将会覆盖package.mask的效果（安装白名单）。\n屏蔽特定的包版本 如果它不存在，请创建/etc/portage/package.mask 文件：\n# echo \u0026#34;\u0026gt;x11-drivers/ati-drivers-12.6_beta_pre897\u0026#34; \u0026gt;\u0026gt; /etc/portage/package.mask 或者，创建/etc/portage/package.mask/ 目录：\n# mkdir -p /etc/portage/package.mask/ # echo \u0026#34;\u0026gt;x11-drivers/ati-drivers-12.6_beta_pre897\u0026#34; \u0026gt; /etc/portage/package.mask/ati-drivers 从 ebuild 存储库中屏蔽包 创建一个文件以从名为“larry”的 ebuild 存储库中屏蔽名称为www-client/firefox 的包\n# echo \u0026#34;www-client/firefox::larry\u0026#34; \u0026gt; /etc/portage/package.mask/firefox 屏蔽 overlay 所有的包\n常规操作都是enable repository 后把所有包都mask 掉，要用的时候单独一个个开，加上 autounmask 也不用自己写。\n*/*::overlay_name ACCEPT_KEYWORDS ACCEPT_KEYWORDS 变量告诉包管理器哪个 ebuild 的 KEYWORDS 允许接受。\n变量在哪里设置？ 这个变量通常通过 Gentoo 的 profile 设置。但是可以在用户的 /etc/portage/make.conf 文件里进行覆盖，以及在 /etc/portage/package.accept_keywords 文件/目录下的每个包里或者甚至在命令行中进行覆盖。\nImportant：通过命令行覆盖 ACCEPT_KEYWORDS 变量通常被认为是个坏主意，因为设置不会被包管理器保存而且可能导致不必要的行为。\n稳定与不稳定的 keywords 在绝大多数的 profile 中 ACCEPT_KEYWORDS 变量的默认值即系统架构本身，例如 ACCEPT_KEYWORDS=\u0026quot;amd64\u0026quot; 或者 ACCEPT_KEYWORDS=\u0026quot;arm\u0026quot;。在此情况下，包管理器只接受那些KEYWORDS 变量包含此架构的 ebuild。如果用户希望能够安装那些还未被认为适合生产环境使用的 ebuild，可以在架构前添加 ~ 前缀，例如：\n# nano -w /etc/portage/make.conf ACCEPT_KEYWORDS=\u0026#34;~amd64\u0026#34; 由于ACCEPT_KEYWORDS变量是增量的，在添加测试关键字 (~amd64)的时候，不应当指定稳定的关键字(amd64)。\n如果不是进行系统全局设置，那么可以在 /etc/portage/package.accept_keywords 文件或目录中对每个包进行单独设置：\n\u0026lt;类\u0026gt;/\u0026lt;名\u0026gt; [可选的关键字配置] # games games-fps/doomsday ~amd64 # 亦可指定版本，比如对 21.04.3 及以上版本的 kde-apps-meta 进行配置 \u0026gt;=kde-apps/kde-apps-meta-21.04.3 除了 ACCEPT_KEYWORDS 的通常值以外， package.accept_keywords 还支持三个特殊值：\n * — 如果包在任何系统架构是稳定的，那么它可见 ~* — 如果包在任何系统架构是测试的，那么它可见 ** — 这个包总是可见的 (KEYWORDS 被完全忽略)  最后一个选项对于版本经常改变的包 （当前 svn/git/mercurial/… 版本的包， 他们通过 live ebuild 来支持，并且没有 KEYWORDS 变量。\n当Portage报错的时候 简介 正如我们之前指出的那样，Portage是一个非常强大并支持许多特性的软件包管理工具，而这是其他类似工具所欠缺的。为了理解这一点，我们为您粗略地解释一些Portage的面貌。\n通过使用Portage，一个软件的不同版本可以共存于一个系统中。其他发行版倾向于直接在软件包名字中包含版本号（例如freetype 和 freetype2），Gentoo的Portage使用一种我们称之为SLO的技术来实现这种并存。一个ebuild为它自身的版本声明了一个确切的SLOT。具有不同SLOT的同一软件的Ebuild可以共存于同一个系统中。例如，上例中那个freetype包就拥有不同的ebuilds，里面分别有 SLOT=\u0026ldquo;1\u0026rdquo; 和SLOT=\u0026ldquo;2\u0026quot;的标志\n有一些不同的软件包提供了类似的功能。比如metalogd，sysklogd和syslog-ng都是系统日志记录工具。那些依赖于“系统日志记录工具”的程序并不能随便的依赖于其中之一，比如metalogd。因为其他的系统日志工具可能也是很好的选择。好在Portage允许使用虚拟包：每一个系统日志记录工具都可以提供virtual/logger包，因此应用程序们可以设定成仅仅依赖于virtual/syslog即可。\nPortage树中的软件可以存在于不同的分支中。您的系统默认只会接受那些Gentoo认为稳定的软件包。绝大多数新提交的软件会被添加到测试分支里。这意味着在此软件被标示为稳定版前需要进行更多的测试。尽管您可以看到那些软件的ebuilds已经加入Portage数据库，在它们未被加入稳定分支前Portage将不会安装它们。\n有些软件只能在某几个体系结构上使用。或者在其他体系结构中还不能运行，或者仍需要对其进行更多的测试，或者将软件提交到Portage树中的开发者还不能确定这个软件能否运行于其他体系结构。\n每一个Gentoo安装都依附于一个确定的profile，此文件里除了其他信息外还包含了一个正常工作的系统需要的软件包的列表。\n被阻挡的包 Portage关于被阻挡的包的警告(使用 \u0026ndash;pretend参数)\n[blocks B ] mail-mta/ssmtp (is blocking mail-mta/postfix-2.2.2-r1) Portage关于被阻挡的包的警告(不使用 \u0026ndash;pretend参数)\n!!! Error: the mail-mta/postfix package conflicts with another package. !!! both can't be installed on the same system together. !!! Please use 'emerge --pretend' to determine blockers. Ebuilds文件中包含了特定的字段，里面为Portage提供了此软件的各种依赖关系的信息。总计有两种可能的依赖关系：一种是编译依赖，在 DEPEND 区域进行声明;另一种是“运行时”依赖，在 RDEPEND 区域中进行声明。如果上述两种依赖关系中任何一个明确指明某个实体或者虚拟包（译注：可能已安装和正要安装）与要安装的包不相容的时候，就会阻挡软件的安装。\n虽然Portage的最新版本足够聪明，可以在没有用户干预的情况下解决轻微的问题，但偶尔也需要手动解决此类问题。\n为了使安装得以继续进行，您可以选择不安装这个软件包，或者先将发生冲突的包卸载。例如，在我们给出的这个例子中，您可以选择不安装postfix，或者先卸载ssmtp。\n你也可能会遇到某些特定版本的包被屏蔽的情况，比如\u0026lt;media-video/mplayer-1.0_rc1-r2。在这种情况下，升级到一个更新的版本就能解决问题。\n也有可能两个需要安装的包互相阻挡。这种少见的情况下，您应该明确自己为什么需要同时安装它们。绝大多数时候您只需要安装它们之中的一个就可以了。如果不是这样，请您到 Gentoo\u0026rsquo;s bugtracking system 中提交一个bug。\n被屏蔽的包 Portage关于被阻挡的包的警告\n!!! all ebuilds that could satisfy \u0026quot;bootsplash\u0026quot; have been masked. PPortage关于被屏蔽的包的警告——原因\n!!! possible candidates are: - gnome-base/gnome-2.8.0_pre1 (masked by: ~x86 keyword) - lm-sensors/lm-sensors-2.8.7 (masked by: -sparc keyword) - sys-libs/glibc-2.3.4.20040808 (masked by: -* keyword) - dev-util/cvsd-1.0.2 (masked by: missing keyword) - games-fps/unreal-tournament-451 (masked by: package.mask) - sys-libs/glibc-2.3.2-r11 (masked by: profile) - net-im/skype-2.1.0.81 (masked by: skype-eula license(s)) 当您想安装一个对于您系统不可用的软件包。您会收到类似这样的屏蔽错误提示。您应该试着安装那些对于您系统可用的程序或者等待那些不可用的包被置为可用的。通常一个软件包被屏蔽的原因在于：\n   Reason for mask Description     ~arch keyword 这个软件没有经过充分的测试，不能进入稳定分支，请等待一段时间后在尝试使用它。   -arch keyword or -* keyword 这个软件不能工作在您机器的体系结构中。如果您确信它能工作那么请到我们的bugzilla网站提交一个bug报告。   missing keyword 这个软件还没有在您机器的体系结构中进行过测试。您可以咨询相应体系结构移植小组是否能对它进行测试，或者您自己为他们进行这样的测试并将您得到的结论提交到我们的bugzilla网站。   package.mask 这个软件被认为是损坏的，不稳定的或者有更严重的问题，它被故意标识为“不应使用”。   profile 这个软件不适用于您的profile。安装这样的应用软件可能会破坏您的系统，或者只是不能与您使用的profile相兼容。   license 这个包的许可证的ACCEPT_LICENSE值不正确。 通过设置许可证或正确的许可证组来允许其许可证:/etc/portage/make.conf或 /etc/portage/package.license    USE必要的更改 Portage 提示 USE 标志需要进行更改\nThe following USE changes are necessary to proceed: #required by app-text/happypackage-2.0, required by happypackage (argument) \u0026gt;=app-text/feelings-1.0.0 test 如果未使用--autounmask参数，则错误消息也可能显示如下：\nemerge: there are no ebuilds built with USE flags to satisfy \u0026quot;app-text/feelings[test]\u0026quot;. !!! One of the following packages is required to complete your request: - app-text/feelings-1.0.0 (Change USE: +test) (dependency required by \u0026quot;app-text/happypackage-2.0\u0026quot; [ebuild]) (dependency required by \u0026quot;happypackage\u0026quot; [argument]) 当请求安装包时，发生这种警告或错误，这不仅取决于另一个包，而且还要求该包使用特定的USE标志（或一组USE标志）构建。 在给定的示例中，包应用文本/感觉需要使用 USE=\u0026ldquo;test\u0026quot;构建，但此系统上未设置此USE标志。\n要解决这个问题， 到/etc/portage/make.conf编辑里面的USE标志, 或者去/etc/portage/package.use设置一个特殊的包.\n缺失依赖 Portage提示依赖性不满足\nemerge: there are no ebuilds to satisfy \u0026quot;\u0026gt;=sys-devel/gcc-3.4.2-r4\u0026quot;. !!! Problem with ebuild sys-devel/gcc-3.4.2-r2 !!! Possibly a DEPEND/*DEPEND problem. 这表示您正尝试安装的应用程序依赖于您的系统不可用的另外一些软件包。请到bugzilla查看是否有此问题的记录，如果没有查找到相关信息的话请提交一个报告。除非您的系统混用了不同分支，否则这类问题不应该发生，若发生了那就是一个bug。\n意指不明的软件包 Portage对于意指不明的Ebuild名称的警告\n[ Results for search key : listen ] [ Applications found : 2 ] * dev-tinyos/listen [ Masked ] Latest version available: 1.1.15 Latest version installed: [ Not Installed ] Size of files: 10,032 kB Homepage: http://www.tinyos.net/ Description: Raw listen for TinyOS License: BSD * media-sound/listen [ Masked ] Latest version available: 0.6.3 Latest version installed: [ Not Installed ] Size of files: 859 kB Homepage: http://www.listen-project.org Description: A Music player and management for GNOME License: GPL-2 !!! The short ebuild name \u0026quot;listen\u0026quot; is ambiguous. Please specify !!! one of the above fully-qualified ebuild names instead. 您要安装的应用程序对应有多个同名的包。您需要同时指定类别的名称。Portage会列出所有可供选择的名称匹配的包。\n循环依赖 Portage关于循环依赖问题的警告\n!!! Error: circular dependencies: ebuild / net-print/cups-1.1.15-r2 depends on ebuild / app-text/ghostscript-7.05.3-r1 ebuild / app-text/ghostscript-7.05.3-r1 depends on ebuild / net-print/cups-1.1.15-r2 两个（或多个）您想安装的包由于循环依赖而不能安装。这很可能源于Portage树中的bug。请等一段时间后重新sync再尝试安装。您也可以去 Bugzilla 看看是否已经有此问题的报告，或者提交一个关于它的报告。\n当然，最后它也会有类似如下提示的解决方案\nIt might be possible to break this cycle by applying the following change: 下载失败 Portage关于下载失败的警告\n!!! Fetch failed for sys-libs/ncurses-5.4-r5, continuing... (...) !!! Some fetch errors were encountered. Please see above for details. 当Portage下载指定软件的源代码失败时，它会尝试继续安装其它（若适用）的应用程序。源代码下载失败可能源于镜像服务器没有正确同步，也可能因为ebuild文件给出了错误的下载地址。那些保存源代码的服务器也可能因为某些原因宕机。\n一小时后重试一次，看看问题是否仍然存在。\n系统Profile保护 Portage关于profile中保护的包的警告\n!!! Trying to unmerge package(s) in system profile. 'sys-apps/portage' !!! This could be damaging to your system. 您要求移除系统核心软件包中的一个。它是您的profile中所列出的必需的软件，因此不能从系统中移除。\nDigest验证失败 Digest验证失败\n\u0026gt;\u0026gt;\u0026gt; checking ebuild checksums !!! Digest verification failed: 这是Portage树中出现了错误的迹象，通常是由于将ebuild提交到Gentoo ebuild存储库时出错造成的。\n当digest校验失败的时候，请不要尝试自己去为此软件包重新产生digest。使用ebuild foo manifest 并不能修复问题，反而很可能会使问题变得更糟。\n取而代之的应该是等待一至两个小时以便让软件仓库安定下来。一般来说错误很有可能马上就会被注意到，但是修复程序可能需要一点时间来逐步扫描rsync镜像。当您等待的时候，到Bugzilla或者#gentoo (webchat) (IRC)看看是否已经有人报告了这个问题。如果没有，那就为那个损坏的ebuild提交一个bug报告吧。\n修复错误后，重新同步Gentoo ebuild仓库以获取修复的digest。\n重要：值得注意的是：不要每天多次同步Gentoo ebuild repository 仓库。正如（当您运行emerge \u0026ndash;sync时）Gentoo官方网络礼节策略所指出的那样，那些短时间内过于频繁进行多次sync的用户将会被更新服务器软封禁一段时间，一再不遵守这一政策的滥用者可能会被硬封禁。除非绝对必要，否则通常最好等待24小时再进行同步，因为这样您不会使Gentoo的rsync镜像服务器过载而影响其他用户的正常使用。\n其他工具 单纯 Portage 自带的工具对于日常管理其会显得有些吃力，这里推荐几个比较有用的软件用于辅助管理 Portage。\napp-portage/eix 这个可以说是非常有用的软件，主要用于查询 Portage 数据库，其优势在于更快的速度、更人性化的显示格式以及更方便的查询模式。\n使用前需执行 eix-update 以更新 eix 数据库，安装它之后，可以使用 eix-sync 命令来更新 Portage 数据库，更新完毕后会自动更新 eix 数据库，并显示更新前后的软件包对比情况。\n使用 eix 查询所需软件，最基本的命令为\n# eix \u0026lt;包名匹配字符串\u0026gt; 也可只查询已安装的包\n# eix -I \u0026lt;包名匹配字符串\u0026gt; 也可查询属于一个特定分类下的所有包\n# eix -C \u0026lt;类名\u0026gt; 等等，执行 man eix 查看更多用法。\napp-portage/gentoolkit 包含了 Gentoo 的一些管理脚本，常用的命令有用于查询依赖关系，文件归属，软件包内容的 equery ，以及用于清理 distfile 的 eclean-dist 。比如\n可以查询依赖 vim-core 的软件包（仅根据 ebuild 文件内容查询）\n# equery d vim-core 可以查询 vim 下属的依赖关系图\n# equery g vim 可以查询 vim 安装了哪些文件到系统下\n# equery f vim 可以查询这个文件属于哪个包\n# equery b /usr/bin/vim eclean eclean 是一个清理仓库源文件和二进制包的工具。它是 app-portage/gentoolkit 包的一部分，并由 Portage-Tools 项目维护。\n安装\n安装 eclean：\n# emerge --ask app-portage/gentoolkit 附注：关于 app-portage/gentoolkit 包中其他工具的信息请参看 Gentoolkit article。\n使用\n默认情况下，源文件存储在 /var/db/repos/gentoo/distfiles 目录下， 二进制包存储在 /var/db/repos/gentoo/packages 目录下；可以通过修改 /etc/portage/make.conf 中的 DISTDIR 和 PKGDIR 变量更改对应的存储位置。如果不定期清理，这两个目录可能会悄然无声地变得非常巨大；这就是创建eclean的原因。\n使用 eclean \u0026ndash;help 来查看全部的命令简介、参数列表和使用介绍：\n# eclean --help 通过 distfiles 参数清理源文件存放目录：\n# eclean distfiles 或者使用更简短的命令：\n# eclean-dist 使用下面的命令清理二进制包：\n# eclean packages 或者使用更简短的命令：\n# eclean-pkg 选项\n默认情况下，当前存储库中的任何ebuild相对应的源文件和二进制包都不会被删除。这样，只要程序包仍在当前存储库树中，系统管理员就可以轻松地降级程序包或安装以前删除的程序包。\n举个例子，比如包 foo-1.0 和 foo-1.1 都在存储库中。在从 foo-1.0 升级到 foo-1.1 之后，运行 elcean distfiles，两个版本的源文件依然被保留，因此如果 foo-1.1 出现问题，用户可以很方便的重新安装 foo-1.0，而不必重新下载。\n另一个可能的情况是安装之前删除的包。假设系统安装了 foo 包（任一版本）。在（不经意地）删除了这个包并运行了 eclean disfiles 之后，foo 的源文件依然被保留，可以重新安装而无需再次下载。\n对二进制包同样的例子也一样适用。\n为节省更多磁盘空间，请添加--deep选项：这将删除与某些当前安装的软件包（版本无关紧要）不对应的每个源文件或二进制软件包。请注意，这种方式当用户需要降级安装某个包或者重新安装之前删除的包的时候都必须重新下载。\n# eclean --deep distfiles # eclean --deep packages 一个替代方案是，同时使用 --deep 和 --package-names 选项：对于某些非当前安装的包（不管版本号是什么）的每个源文件或者二进制包都会被删除。这种方式当用户需重新安装之前删除的包的时候都必须重新下载，但是要降级安装某个包则不需要。\n更多细节请参阅 eclean(1) man page：\n# man 1 eclean app-portage/portage-utils 包含了 Portage 的帮助工具，与上面 gentoolkit 的功能有重合，他们具有互补性，常用的命令有用于分析 emerge 日志的 qlop 。它是用 C 写的，速度更快。\napp-portage/pfl Portage File List，可用于在线查询文件所归属的包，命令为 e-file \u0026lt;文件名\u0026gt; 。\n多版本管理 Gentoo Linux 支持同一软件多版本同时存在于系统上，这归功于 Portage 系统的 slotting 机制。当你执行命令 eix dev-lang/python 会发现它有好多行可用版本，最前圆括号内的内容即对应的 slot 名，不同 slot 下的版本可同时安装到系统上（ slot 名内 / 符号后的内容表示其 sub-slot，同 slot 但不同 sub-slot 的版本无法共存）。比如，sys-devel/gcc , sys-devel/clang , dev-lang/lua 等等都支持多版本共存。\n对于一些多版本共存的工具， Gentoo Linux 准备了对应的 eselect 命令以方便用户选择使用。其会在对应的 $PATH 目录下创建一个指向当前选定版本命令的软链接。比如，列出当前所有已经安装的 lua 版本\n# eselect lua list 设定了系统下用户交互环境的默认 lua 版本\n# eselect lua set {序号} 其它的类似，执行 eselect help 以查看当前所有支持的模块。不是所有的多版本共存的包都会有 eselect 模块，它们并不存在强制的依赖关系。执行 eix -I2 可以显示当前系统下安装的可多版本共存的包。\n为 Portage 包管理器设置代理 开门见山，本文介绍在 Gentoo Linux 下如何正确地对其包管理器 Portage 设置代理，即日常使用的 emerge 命令。这里介绍软件下载安装时需要的配置；对于同步 Portage 树，则是部分适用。\nGentoo 的默认设置  代理： 无 工具： 默认使用 wget 作为下载工具，但对于绝大部分的 live 包，会有针对的 eclass 使用对应的版本控制工具从远程仓库抓取，这里仅以 git 为例。  live 包：即版本号带 9999* 的这些包；用于匹配 live ebuild 文件名的正则表达式为 9999*(-r[0-9]{1,3})?.ebuild$ ，可还是有一些包使用了这种版本命名规则却并非真正的 live 包，比如 openjfx/openjfx-8.999.ebuild ；这里不会通过版本号来判断是否需要配置 git 参数，所以并不影响，仅作介绍。\n持久性地修改代理 通用配置 $ man make.conf 可以看到里面有说明如何配置代理，但是过于简要，这边详细说明。\n对于一般情况，在 /etc/portage/make.conf 文件下配置如下三个变量，就完全足够：\nhttp_proxy=\u0026#34;[protocol://][user[:password]@]proxyhost[:port]\u0026#34; https_proxy=\u0026#34;[protocol://][user[:password]@]proxyhost[:port]\u0026#34; ftp_proxy=\u0026#34;[protocol://][user[:password]@]proxyhost[:port]\u0026#34; 这些变量会在 emerge 命令运行时，传递给预配置的 FETCHCOMMAND 即 wget 命令。但，该命令有一个问题是不支持 socks 协议；所以，对于不同的协议需要有不同的代理服务，这样子很麻烦。\n修改以支持 socks 协议有一个应变的方法，即修改默认的获取命令为 curl ，同样是在 /etc/portage/make.conf 文件下配置变量，如下：\nFETCHCOMMAND=\u0026#34;curl --retry 3 --connect-timeout 60 --ftp-pasv -Lfo \\\u0026#34;\\${DISTDIR}/\\${FILE}\\\u0026#34; \\\u0026#34;\\${URI}\\\u0026#34;\u0026#34; RESUMECOMMAND=\u0026#34;curl -C - --retry 3 --connect-timeout 60 --ftp-pasv -Lfo \\\u0026#34;\\${DISTDIR}/\\${FILE}\\\u0026#34; \\\u0026#34;\\${URI}\\\u0026#34;\u0026#34; 其中 RESUMECOMMAND 是用于恢复意外中断的下载命令，保存后即完成修改，此时，就可以给不同协议配置同样的 socks 类协议的代理服务，均可生效。如：\nhttps_proxy=\u0026#34;socks5h://127.0.0.1:1080\u0026#34; 单独配置 git 抓取 对于 live 包，它们目前大多数直接使用 git 命令从远程仓库抓取。其它版本控制工具（目前支持的大致有 bzr, cvs, darcs, mercurial, subversion）同理，请自行修改后套用；当然也有直接使用 wget|curl 下载 live 包的情况，那么这种情况如上「一」述。\ngit 命令支持 socks 协议，并且除了能吃上述配置的环境变量外，\n配置 https_proxy 时也配好 http_proxy ，否则可能出现 SSL_ERROR_SYSCALL 错误。\n还能独立于其它包单独配置 git 自身的代理，方法有两种：\n  git 能配置针对整个 Linux 系统的参数，运行：\n$ git config --system http.proxy \u0026#39;[protocol://][user[:password]@]proxyhost[:port]\u0026#39; 此命令会将配置写入到 /etc/gitconfig 文件内，并生效于系统级别，会被用户/项目级别的配置覆盖。\n  通过 Portage 的全局 bashrc 文件 /etc/portage/bashrc 来配置临时的 git 代理\n这种方式会对系统配置造成最少的干扰，只略微繁琐一点，需要将下述脚本代码写入上述的 bashrc 文件内：\nif [[ ${EBUILD_PHASE} == \u0026#34;unpack\u0026#34; \u0026amp;\u0026amp; ${INHERITED} =~ git\\-r3 ]]; then git config --global http.proxy \u0026#39;[protocol://][user[:password]@]proxyhost[:port]\u0026#39; fi 这个 bashrc 只被 Portage 引用，会在进入每一个安装阶段时被导入。目前，Portage 下抓取 git 项目是通过 git-r3.eclass 实现，该 eclass 定义了 git 项目是在 src_unpack 阶段被更新，所以这里只需要在此阶段时设置即可。且，因为该目录不是被抓取包的 git 目录，所以只能设置用户级别的配置以生效，配置文件会被存放于 Portage 安装过程中沙盒的家目录下，即对应 安装软件临时目录 （这个目录是 Portage 在编译/安装软件过程中临时建立的，会在成功安装软件后被删除，所以不用担心会有文件残留。具体位置是可以自定义的，详情看 make.conf(5) 手册下 PORTAGE_TMPDIR 条目）下的 homedir/ 目录。\n  临时添加代理 对于需要临时添加代理以使用的情况，目前我知道两种方式：\n推荐：ProxyChains ProxyChains is a UNIX program, that hooks network-related libc functions in dynamically linked programs via a preloaded DLL and redirects the connections through SOCKS4a/5 or HTTP proxies.\n使用 net-misc/proxychains 软件适用所有下载方式。\n配置文件可以放在 ~/.proxychains/proxychains.conf，也可以放在 /etc/proxychains.conf，但是放在 etc 下更好，因为有时候要通过sudo安装软件。\n# emerge net-misc/proxychains # vi /etc/proxychains.conf ... socks5 127.0.0.1 7891 配置好代理列表后，通过如下命令使用：\n# proxychains -q emerge [\u0026lt;args\u0026gt;...] 临时指定环境变量 {ftp,http,https}_proxy 的方式，适用性同持久性配置。\n即如下命令：\n# export http_proxy=\u0026#34;...\u0026#34; https_... # emerge [\u0026lt;args\u0026gt;...] 或\n# http_proxy=\u0026#34;...\u0026#34; https_... emerge [\u0026lt;args\u0026gt;...] Project:Portage/Sync The new plug-in sync system is the next step in that migration. Using PORTDIR and PORTDIR_OVERLAY in make.conf could only list where the repository was location. Users could not specify other important attributes about that repository. The repos.conf style configuration allows for settings to be added on a per sync-type basis. Along with this new expandability and the plug-in sync system, it will be much easier to change to new repository syncing methods.\nGeneral help Note: While Portage can handle repos.conf as either a file or a directory of files. The preferred method is to be used as a directory. Other tools like layman and mirrorselect require and expect it to be a directory. Layman creates and manages its own layman.conf file to register installed overlays with Portage. mirrorselect looks for repos.conf/gentoo.conf file in order to modify the sync-uri parameter for the gentoo repository.\nMigration Portage configuration\nIf the /etc/portage/repos.conf directory does not exist:\n# mkdir /etc/portage/repos.conf # cp /usr/share/portage/config/repos.conf /etc/portage/repos.conf/gentoo.conf Then edit the file for your installation and desired settings, continue as needed with the remaining migration instructions. Edit all repos.conf/*.conf files, add the auto-sync option to each defined repository.\nFor sync-type, edit it to one of the installed supported types.\nCurrent supported sync types include:\n rsync git svn webrsync or websync (equivalent to running emerge-webrsync separately). cvs laymansync (if installed by Layman)  Example local overlay sync-able from a git backup:\n# nano -w /etc/portage/repos.conf/gentoo.conf [DEFAULT] main-repo = gentoo [gentoo] location = /var/db/repos/gentoo sync-type = git sync-uri = https://github.com/gentoo-mirror/gentoo.git auto-sync = yes priority = 1000 The above overlay can be synced with\n# emaint sync -r gentoo Operation Primary control of all sync operations has been moved from emerge to emaint. emerge \u0026ndash;sync now runs the emaint sync module with the --auto option. This --auto option performs a sync on only those repositories with the auto-sync setting set to yes or true. If the auto-sync option is not set to yes or is absent, then emerge \u0026ndash;sync may not sync any repositories.\nNote: As a result of the default auto-sync = True/Yes setting, commands like eix-sync, esync -l, emerge \u0026ndash;sync \u0026amp;\u0026amp; layman -S will cause many repositories to be synced multiple times in a row. Please adjust configuration files or scripts as necessary for the new operation.\nWarning: Due to the above default. For any repositories (repos) that you EXPLICITLY do not want to be synced. You MUST set auto-sync = no\nExamples # emaint sync -a Equivalent to emerge \u0026ndash;sync. Sync all repositories where auto-sync = true is set.\nNote: Due to the default auto-sync = true setting, this command will sync all repositories that do not have auto-sync = no explicitly set.\n# emaint sync -r foo Sync the foo repo (ignores auto-sync setting):\n# emaint sync --allrepos Sync all repositories with a valid sync-type and sync-url defined. (ignores auto-sync setting)\nUSE标记 什么是USE标志 USE标志的指导思想 你在安装gentoo（或者是其他发行版，甚至于其他特定操作系统）的时候，你要依据你工作的环境做出选择。服务器跟工作站的组织结构不同，游戏机跟3D工作站也会不一样。\n不单只是选择你想要安装的包时如此，选择某一个包需要的特性时同样如此。如果你不需要OpenGL，为什么还要花费时间安装OpenGL并在其他包中加入对OpenGL的支持？如果你不用KDE，而且软件包没有KDE也能完美运行，为什么还要在编译这些包的时候加入KDE支持？\n为了帮用户判断什么需要安装或激活，什么不需要；我们希望用户能用简单的方式设定他们自己的环境。这能促使用户判断他真正需要的东西，并让Portage做出有用的决定的过程变得简单。\nUSE标志的设定 我们来具体看看USE标志。每一个标志都是代表对某特定概念的支持和依赖关系信息的关键字。如果你设定了某个USE标志，Portage会明白他们需要支持所选关键字。当然这同时也改变了这个包的依赖关系信息。\n让我们看一个特殊示例：关键字 kde 。如果你的 USE 变量里面没有这个关键字，所有具有可选KDE支持的包在编译时都 不会 编译KDE支持。所有具有可选KDE依赖关系的包在安装时都 不会 （做为一个依赖关系而）安装KDE库。如果你设定了kde关键字，这些包在安装时都 会 编译KDE支持，而且KDE库也 会 （作为一个依赖关系而）被安装。\n通过正确设定关键字，你会得到一个根据你的需要而定制的系统。\n使用USE标志 声明永久USE标志 就像前面提到的，所有USE标志都声明在 USE 变量里面。为了让用户能方便地查找和选择USE标志，我们提供了一份默认的USE设定。这些设定是我们觉得Gentoo用户通常都要用到的USE标志的集合。这个默认设置在make.defaults 文件──你的profile声明。\n你的系统使用的profile是符号链接 /etc/portage/make.profile 所指向的目录。每个profile叠加于某个更大的profile之上，最终的结果是这些profile的并集。初始profile是base profile( /var/db/repos/gentoo/profiles/base)。\n要查看当前正在使用的USE标志（全部），请使用 emerge \u0026ndash;info：\n# emerge --info | grep ^USE USE=\u0026#34;a52 aac acpi alsa branding cairo cdr dbus dts ...\u0026#34; 就像你看到的那样，这个变量已经包括了非常多的关键字。不要通过修改make.defaults 文件里的 USE 变量来满足你的需要：在升级Portage的时候，这个文件将会被覆盖。\n要改变这个默认设置，你需要在 USE 变量里添加或移去关键字。这是通过在/etc/portage/make.conf里定义USE全局变量来实现的。在这个变量里，添加你需要的额外的USE标志，或者移去你不需要的USE标志。后者可通过在标记前面加个负号 (-).前缀来实现。\n例如，要移除对 KDE 和 QT 的支持，并添加对 LDAP 的支持，可以在/etc/portage/make.conf里声明USE如下：\nUSE=\u0026#34;-kde -qt4 -qt5 ldap\u0026#34; 为单个包声明USE标志 如果你不是想为整个系统声明USE标志，而是想要为一个（或者几个）程序声明USE标志，你需要编辑/etc/portage/package.use文件。package.use 通常是一个文件，不过它也可以是一个充满子文件的目录；请看下面的提示和 man 5 portage 以获得更多如何使用这个约定的信息。下面的例子假设 package.use 是一个文件。\n比如说，如果你不想全局的启用 Blu-ray 支持，你只想把它应用到 VLC 包，你可以这样做：\n\u0026lt;类\u0026gt;/\u0026lt;名\u0026gt; \u0026lt;USE\u0026gt; media-video/vlc bluray Tip：如果 package.use 是一个已经存在的“目录”（而不是一个单文件），只需简单地在 package.use/ 目录下创建文件，就可以修改软件包的本地USE标记。虽然任何文件命名规范都行，但是更明智的做法是统一命名方案。\n有一种规范是简单地使用包名作为子文件的标题。比如说，可以用如下方式为 media-video/vlc 软件包在本地设置 bluray USE 标记。\n# echo \u0026#34;media-video/vlc bluray\u0026#34; \u0026gt;\u0026gt; /etc/portage/package.use/vlc 你当然也可以直接为某一个程序禁用USE标志。比如说，禁用PHP的bzip2支持（但通过make.conf中的USE标志为其他包提供支持）：\ndev-lang/php -bzip2 -* 代表去除该匹配的包的所有已经添加的以及默认的 USE\n\u0026gt;=kde-apps/kde-apps-meta-21.04.3 -* admin Portage 有一个 USE Expand 功能，即把指定变量的值扩展成 USE，这些指定的变量被设置在 Portage 数据库路径下的 profiles/base/make.defaults 文件的 USE_EXPAND 变量中。这个功能很实用，简化了配置值，还能进行归类，更便于管理。上文有一个 显卡的配置 其实就是一个 USE_EXPAND 值。其它会使用到它的地方不多，但也有，比如配置全局的本地化配置，就可以在 make.conf 文件下配置\nL10N=\u0026#34;zh-CN zh-TW zh en-GB-oxendict en\u0026#34; 这样，那么以后当有包支持上述的本地化配置时，就会自动添加。\n其它比如可以对 qemu 这个虚拟机添加额外的模拟平台， 可以往 /etc/portage/package.use/qemu 文件写\napp-emulation/qemu QEMU_SOFTMMU_TARGETS: aarch x86_64 以支持 arm64 及 x86_64 平台。等等\n声明临时USE标志 有时，你只想暂时改变一个USE设置。你可以仅仅把USE 变量声明成一个环境变量，而不必两次修改/etc/portage/make.conf 。但是要记住，当你重新emerge或者升级这个程序的时候（不管是单独地还是作为系统升级的一部分），你的修改会被重置。\n下面的例子我们将在安装 SeaMonkey 的时候临时从 USE 变量中移去pulseaudio 值。\n# USE=\u0026#34;-pulseaudio\u0026#34; emerge www-client/seamonkey 优先级 当然，USE设置有一定的优先级。按优先级排序（第一优先级最低）：\n make.defaults 里面的USE默认设定 用户在/etc/portage/make.conf里面的USE默认设定 用户在 /etc/portage/package.use里面的USE默认设定 用户作为环境变量的USE设定  运行 emerge \u0026ndash;info可以看到Portage识别的最终的USE设定。它会列出Portage使用的所有相关变量（包括 USE 变量）。\n# emerge --info 在整个系统上应用新的USE标志 如果你已经修改了你的USE标志，而且你想用新的USE标志更新你的系统，可以使用emerge的 --newuse选项：\n# emerge --update --deep --newuse @world 然后运行Portage的depclean来移除已经安装到你的\u0026quot;旧\u0026quot;系统里但是在新USE标志中被废除的条件依赖关系。\n警告：运行emerge \u0026ndash;depclean是一项危险的操作，必须小心。请反复检查要删除的包的列表里确定没有你仍然需要的包。下面这个例子里，我们添加了 -p 选项──来只列出这些包而不删除他们：\n# emerge -p --depclean depclean完成之后， emerge会针对可能是已经删除的软件包提供的共享对象动态链接的应用程序提示重新构建。此操作完成前，为了防止破坏应用程序，Portage 将会保存必要的库。它存储着需要在 preserved-rebuild 设置的重建内容。若要重建必要的包，请运行：\n# emerge @preserved-rebuild 这些都完成之后，你的系统就已经应用上了新的USE标志的设定。\n软件包特有的USE标志 查看可用USE标志。\n让我们以seamonkey来作例子，看看它接收什么USE标志。我们可以以--pretend和 --verbose为选项执行 emerge来查看：\n# emerge --pretend --verbose www-client/seamonkey These are the packages that would be merged, in order: Calculating dependencies... done! [ebuild N ] www-client/seamonkey-2.48_beta1::gentoo USE=\u0026#34;calendar chatzilla crypt dbus gmp-autoupdate ipc jemalloc pulseaudio roaming skia startup-notification -custom-cflags -custom-optimization -debug -gtk3 -jack -minimal (-neon) (-selinux) (-system-cairo) -system-harfbuzz -system-icu -system-jpeg -system-libevent -system-libvpx -system-sqlite {-test} -wifi\u0026#34; L10N=\u0026#34;-ca -cs -de -en-GB -es-AR -es-ES -fi -fr -gl -hu -it -ja -lt -nb -nl -pl -pt-PT -ru -sk -sv -tr -uk -zh-CN -zh-TW\u0026#34; 216,860 KiB Total: 1 package (1 new), Size of downloads: 216,860 KiB emerge 并不是做这件事的唯一工具。事实上，我们有一个专门的包信息工具叫equery，它属于app-portage/gentoolkit。\n# emerge --ask app-portage/gentoolkit 现在以为参数执行 equery 来查看指定包的USE标志。例如：gnumeric包：\n# equery --nocolor uses =gnumeric-1.12.31 [ Legend : U - final flag setting for installation] [ : I - package is installed with flag ] [ Colors : set, unset ] * Found these USE flags for app-office/gnumeric-1.12.31: U I + + introspection : Add support for GObject based introspection - - libgda : Enable database support through gnome-extra/libgda. - - perl : Enable perl plugin loader. + + python : Enable python plugin loader. + + python_targets_python2_7 : Build with Python 2.7 满足 REQUIRED_USE 一些 ebuild 需要或禁止 USE 标志的某些组合才能正常工作。 这通过放置在 REQUIRED_USE ，用一组条件来表示。此条件确保所有功能和依赖性都已完成，并且构建将成功并按预期执行。 如果任何一个不符合，emerge 会提醒你，并要求你解决这个问题。\n下面是 REQUIRED_USE 的一个例子：\n   示例 描述     REQUIRED_USE=\u0026quot;foo? ( bar )\u0026quot; 如果设定 foo，则必须设定 bar。   REQUIRED_USE=\u0026quot;foo? ( !bar )\u0026quot; 如果设定 foo，则不得设定 bar。   `REQUIRED_USE=\u0026ldquo;foo? (    REQUIRED_USE=\u0026quot;^^ ( foo bar baz )\u0026quot; 必须在 foo、bar 或 baz 中设定一个。   `REQUIRED_USE=\u0026rdquo;    REQUIRED_USE=\u0026quot;?? ( foo bar baz )\u0026quot;     Portage功能特性 Portage特性 Portage有几个附加的特性，它们能够令您的Gentoo之旅更加愉快。这些特性中的大多数依赖于某些能够提高性能、可靠性、安全性等的软件工具。\n为了打开或者关闭某一Portage特性您需要编辑 /etc/portage/make.conf中的 FEATURES变量，这个变量包含不同的特性关键字，用空格分开。在一些情况下您可能还需要额外的安装被这个特性所依赖的工具。\n并不是所有Portage所支持的特性都在这里列出。完整的概述，请查阅make.conf手册页：\n# man make.conf 查看 FEATURES 的默认设置，运行emerge \u0026ndash;info并且查找FEATURES变量或者用grep 显示它：\n# emerge --info | grep ^FEATURES= 分布式编译 使用distcc distcc 是一个分布式编译程序，可以把编译任务分配给同一网络中的不同机器，这些机器的配置不必完全相同。distcc客户端发送所有必须的信息给所有可利用的distcc服务器（运行distccd的机器）。这样它们每一个都能为客户端编译一部分源码。所获得的效果就是更短的编译时间。\n您可以在Gentoo Distcc文档里找到更多的关于Distcc的信息（包括如何让它在Gentoo上工作）。\n安装 distcc Distcc使用一个图形化监视器来监视您的机器发送出去的编译工作。请把 USE=gnome 或 USE=gtk放进您的USE设置中。\n# merge --ask sys-devel/distcc 激活Portage的distcc支持 将 distcc 添加到/etc/portage/make.conf中的 FEATURES \u0026lt;/ var\u0026gt;变量中。 接下来，编辑MAKEOPTS变量，并增加系统允许的并行构建的数量。 一个已知的方法是填写 -jN 其中N 是运行distccd（包括当前主机）的CPU数量+1（或者核心数+1），但这只是一个建议。\n现在运行 distcc-config并输入已有的DistCC服务器。作为一个简单例子，我们假设已有的DistCC服务器是192.168.1.102（当前主机）、192.168.1.103和192.168.1.104（两个远端服务器）：\n# distcc-config --set-hosts \u0026#34;192.168.1.102 192.168.1.103 192.168.1.104\u0026#34; 当然，也不要忘了运行distccd系统服务：\n# rc-update add distccd default # /etc/init.d/distccd start 缓冲编译结果 关于ccache ccache是一个快速编译器缓存。 无论何时编译应用程序，它都将缓存中间结果，以便每当重新编译相同的程序时，编译时间大大减少。 第一次运行ccache时，它会比正常编译慢得多。 但是后续的重新编译应该更快。 ccache只有在相同的应用程序将被重新编译多次（或相同应用程序的升级频繁发生）时才有用; 因此它通常只对软件开发人员有用。\n如果您对ccache的工作机制有兴趣，请访问homepage主页.\n警告：已知ccache会导致大量的编译失败。 有时ccache会保留旧代码对象或损坏的文件，这可能导致无法破损的源码。 如果发生这种情况（例如\u0026quot;File not recognized: File truncated\u0026quot;出现在构建日志中），请尝试重新编译ccache导致错误的应用程序 。添加FEATURES=\u0026quot;-ccache\u0026quot; 到/etc/portage/make.conf或者\n# FEATURES=\u0026#34;-ccache\u0026#34; emerge \u0026lt;category/package\u0026gt; 安装 ccache 要安装ccache，只需要：\n# emerge --ask dev-util/ccache 激活Portage ccache 支持 打开 /etc/portage/make.conf并添加ccache到FEATURES变量:\nFEATURES=\u0026quot;ccache\u0026quot; CCACHE_SIZE=\u0026quot;2G\u0026quot; 要检查ccache是否运行，只需让它提供给您它的统计数据。因为Portage使用一个不同的ccache主目录，您需要设定CCACHE_DIR变量：\n# CCACHE_DIR=\u0026#34;/var/tmp/ccache\u0026#34; ccache -s /var/tmp/ccache/是Portage的默认ccache主目录；为了修改这个设置，您可以设定/etc/portage/make.conf中的CCACHE_DIR参数。\n不过，如果您运行 ccache ，它使用的默认目录是${HOME}/.ccache/。这就是为什么当您查询（Portage）ccache统计数据的时候您需要设定 CCACHE_DIR参数的原因。\n非Portage编译中使用ccache 如果您需要在非Portage编译中使用ccache，添加 /usr/lib/ccache/bin/到您 PATH参数里靠前的位置（在/usr/bin之前）。这一点可以通过编辑在您用户主目录中的~/.bash_profile文件来实现。使用~/.bash_profile是定义 PATH参数的一个方式\nPATH=\u0026#34;/usr/lib/ccache/bin:${PATH}\u0026#34; 二进制包支持 创建预编译包 Portage 也支持安装预编译软件包。尽管 Gentoo 本身并不提供预编译包，但 Portage 依然能够处理预编译包。\n如果某个包已经被安装在您的系统上，您可以用 quickpkg 来创建预编译包。也可以用带有 --buildpkg 或 --buildpkgonly 选项的 emerge 命令。\n如果您希望 Portage 为您所安装的每一个软件包创建预编译软件包，那么请在 FEATURES 中添加 buildpkg 变量。\n预编译包的更多扩展支持可以用 catalyst 得到。关于catalyst的更多信息请参阅 Catalyst FAQ。\n安装预编译包 尽管Gentoo并不提供，但是您可以自己建立一个“中心仓库”来存放预编译包。如果您希望使用这个仓库，您需要设定PORTAGE_BINHOST参数使Portage能够知道它。例如，如果预编译包在 ftp://buildhost/gentoo 上：\n# nano -w /etc/portage/make.conf PORTAGE_BINHOST=\u0026#34;ftp://buildhost/gentoo\u0026#34; 当您需要安装预编译包的时候，在emerge命令后的 --getbinpkg选项旁加入 --usepkg 选项。前者让emerge命令从预定的服务器上下载预编译包，后者让emerge首先试图安装预编译包，如果预编译包不存在，那么才下载并编译源码。\n例如：用预编译包安装gnumeric\n# emerge --usepkg --getbinpkg gnumeric 关于emerge的预编译包的更多信息请参阅emerge手册页:\n# man emerge 将预构建的软件包分发给他人 如果预构建的软件要分发给其他人，请确保这样做是被允许的。 检查上游软件包的分发要求。 例如，对于在GNU GPL协议下发布的软件，源代码必须与二进制文件一起提供。\n如果构建的二进制程序不可分发，则Ebuild可以在其RESTRICT 变量中定义 bindist限制。 有时，此限制取决于一个或多个USE标志。\n默认情况下，Portage将不会屏蔽任何包，因为有限制。 这可以通过在/etc/portage/make.conf中设置ACCEPT_RESTRICT变量来全局更改。 例如，要掩盖具有bindist 限制的软件包，请将以下行添加到make.conf：\nACCEPT_RESTRICT=\u0026#34;* -bindist\u0026#34; 还可以通过将ACCEPT_RESTRICT选项用于emerge命令，来覆盖--accept-restrict 变量。 例如， --accept-restrict=-bindist将临时屏蔽带有bindist 限制的包。\n还可以考虑在分发包时设置ACCEPT_LICENSE变量。 请参阅 授权许可。\n重要：每个 用户完全有责任遵守软件许可条款和每个用户国家的法律。 ebuilds（RESTRICT或LICENSE）定义的元数据变量可以为禁止预编译文件分发提供指导。但是Portage的输出或Gentoo开发人员的回答 不是 法律声明，不应该依赖他们。 谨慎遵守您的当地的法律。\n下载文件 并行下载 Portage 通常是以root 用户运行的， FEATURES=\u0026quot;userfetch\u0026quot;可以让Portage在下载源码包的时候弃用 root 权限，并以 portage:portage 的用户/组权限运行。这是一个小小的安全性的提高方法。\n如果在 FEATURES 设置了 userfetch，请确保在 root 权限下，使用 chown 命令更改在 /var/db/repos/gentoo 下所有文件的所有者：\n# chown --recursive --verbose portage:portage /var/db/repos/gentoo 验证源文件 要重新验证完整性并(可能)重新下载当前所有安装的软件包以前删除或损坏的 distfiles，请运行：\n# emerge --ask --fetchonly --emptytree @world 环境变量 环境变量 简介 环境变量是一个具有特定名字的对象，它包含了一个或者多个应用程序所将使用到的信息。通过使用环境变量，你可以很容易的修改一个牵涉到一个或多个应用程序的配置信息。\n重要的例子 下表展示了一些Linux系统使用的变量并说明了它们的用处。在表格后面将列举一些变量例值。\n   Variable Description     PATH 这个变量包含了一系列由冒号分隔开的目录，系统就从这些目录里寻找可执行文件。如果你输入的可执行文件（例如 ls, rc-update或者 emerge）不在这些目录中，系统就无法执行它（除非你输入这个命令的完整路径，如/bin/ls）。   ROOTPATH 这个变量的功能和 PATH相同，但它只罗列出超级用户（root）键入命令时所需检查的目录。   LDPATH 这个变量包含了一系列用冒号隔开的目录，动态链接器将在这些目录里查找库文件。   MANPATH 这个变量包含了一系列用冒号隔开的目录，命令 man 会在这些目录里搜索man页面。   INFODIR 这个变量包含了一系列用冒号隔开的目录，命令 info 将在这些目录里搜索info页面。   PAGER 这个变量包含了浏览文件内容的程序的路径，比如(less 或者 more)   EDITOR 这个变量包含了修改文件内容的程序（文件编辑器）的路径(比如 nano 或 vi).   KDEDIRS 这个变量包含了一系列用冒号隔开的目录，里面放的是KDE相关的资料。   CONFIG_PROTECT 这个变量包含了一系列用空格隔开的目录，它们在更新的时候会被Portage保护起来。   CONFIG_PROTECT_MASK 这个变量包含了一系列用空格隔开的目录，它们在更新的时候不会被Portage保护起来。    下面你可以找到所有这些变量定义的范例：\nPATH=\u0026quot;/bin:/usr/bin:/usr/local/bin:/opt/bin:/usr/games/bin\u0026quot; ROOTPATH=\u0026quot;/sbin:/bin:/usr/sbin:/usr/bin:/usr/local/sbin:/usr/local/bin\u0026quot; LDPATH=\u0026quot;/lib:/usr/lib:/usr/local/lib:/usr/lib/gcc-lib/i686-pc-linux-gnu/3.2.3\u0026quot; MANPATH=\u0026quot;/usr/share/man:/usr/local/share/man\u0026quot; INFODIR=\u0026quot;/usr/share/info:/usr/local/share/info\u0026quot; PAGER=\u0026quot;/usr/bin/less\u0026quot; EDITOR=\u0026quot;/usr/bin/vim\u0026quot; KDEDIRS=\u0026quot;/usr\u0026quot; CONFIG_PROTECT=\u0026quot;/usr/X11R6/lib/X11/xkb /opt/tomcat/conf \\ /usr/kde/3.1/share/config /usr/share/texmf/tex/generic/config/ \\ /usr/share/texmf/tex/platex/config/ /usr/share/config\u0026quot; CONFIG_PROTECT_MASK=\u0026quot;/etc/gconf\u0026quot; 全局变量的定义 env.d目录 Gentoo采用了/etc/env.d/目录来集中定义全局变量。在这个目录里，你会发现很多类似 00basic, 05gcc等等这样的文件，它们包含了文件名中提到的应用程序需要的变量。\n举个例子，当你安装 gcc时，一个名为 05gcc 的文件就会被ebuild所创建，里面包含了如下一些变量：\nPATH=\u0026quot;/usr/i686-pc-linux-gnu/gcc-bin/3.2\u0026quot; ROOTPATH=\u0026quot;/usr/i686-pc-linux-gnu/gcc-bin/3.2\u0026quot; MANPATH=\u0026quot;/usr/share/gcc-data/i686-pc-linux-gnu/3.2/man\u0026quot; INFOPATH=\u0026quot;/usr/share/gcc-data/i686-pc-linux-gnu/3.2/info\u0026quot; CC=\u0026quot;gcc\u0026quot; CXX=\u0026quot;g++\u0026quot; LDPATH=\u0026quot;/usr/lib/gcc-lib/i686-pc-linux-gnu/3.2.3\u0026quot; 其他的发行版会让你到/etc/profile或者其他地方修改和添加这些变量的定义。而Gentoo为用户（还有为Portage）提供了更加便捷的方式来维护和管理环境变量，以后你不再需要把精力放在那些众多的包含环境变量的文件身上了。\n比如，当你更新完gcc 的时候， /etc/env.d/05gcc也会被同时更新，而不需要你手工来完成。\n这不仅对Portage有益，作为用户，你也是受益者。有时候你需要设置某个系统范围的环境变量。我们拿http_proxy变量来做例子，为了避免http_proxy 搞乱，你只要新建一个文件/etc/env.d/99local然后添加你的定义：\nhttp_proxy=\u0026quot;proxy.server.com:8080\u0026quot; 通过使用同一个文件来定义你所有的变量，你对如何定义自己的变量有了个大概的了解。\nenv-update /etc/env.d/ 中的好几个文件都定义了PATH变量。这并没有错：当你运行env-update的时候，它会在更新环境变量之前把这些定义都追加到PATH里，因此对于软件包（或者用户）来说将会很容易地设置他们自己的环境变量，而不影响到现有变量的值。\nenv-update 脚本会根据 /etc/env.d/ 里文件的字母顺序来附加变量的值。这些文件名必须要以两位数字开头。\n00basic 99kde-env 99local +-------------+----------------+-------------+ PATH=\u0026quot;/bin:/usr/bin:/usr/kde/3.2/bin:/usr/local/bin\u0026quot; 变量并不总是被串联起来，只有下列变量才会被串联： ADA_INCLUDE_PATH, ADA_OBJECTS_PATH, CLASSPATH, KDEDIRS, PATH, LDPATH, MANPATH, INFODIR, INFOPATH, ROOTPATH, CONFIG_PROTECT, CONFIG_PROTECT_MASK, PRELINK_PATH, PRELINK_PATH_MASK, PKG_CONFIG_PATH,和PYTHONPATH。对于( /etc/env.d/) 里的文件中按照字母顺序排列后）其他所有变量，最新定义的值才会被使用到。\n可以通过将变量名添加到 COLON_SEPARATED or SPACE_SEPARATED （也在 /etc/env.d/ 文件）。\n当你运行 env-update的时候，它会在文件/etc/profile.env 里（会被/etc/profile使用）创建所有的环境变量。它也会从变量 LDPATH 中获取信息用来建立/etc/ld.so.conf。这些完成以后，它将运行 ldconfig来重建动态链接器需要的文件/etc/ld.so.cache。\n如果你想在运行env-update后立即看到效果，执行下面的命令来更新你的环境。自己安装过Gentoo的用户可能已经记住了这个安装指南中提到过的命令：\n# env-update \u0026amp;\u0026amp; source /etc/profile 附注：上面的命令只会更新你当前终端里的环境变量、新控制台以及它们的子程序。因此，假如你正在X11里工作，你要么在每一个你打开的终端里输入source /etc/profile ，要么重新启动X，这样所有新的终端才能引用到新的变量。如果你使用了登录管理器，登陆成root然后输入 /etc/init.d/xdm 。如果不是这样，你需要注销然后重新登录回X这样才能产生使用新变量值的子程序。\n重要：你在定义其他变量时不能使用shell变量。这意味着这样的定义 FOO=\u0026quot;$BAR\u0026quot;（此处$BAR 是另外一个变量）是不允许的。\n本地变量的定义 特定用户 你并不是一直都想定义全局变量。比如你想把/home/my_user/bin和当前目录（你当前所在的目录）添加到PATH 变量中，但又不想让其他用户的PATH变量中也有这个。如果你想定义一个本地变量，可以使用 ~/.bashrc 或者~/.bash_profile:\nPATH=\u0026quot;${PATH}:/home/my_user/bin:\u0026quot; 当你重新登录的时候，你的PATH变量将被更新。\n特定会话 有时候甚至需要更加严格的定义。你可能要使用一个你临时创建的目录里面的程序，而又不想输入它的路径或者为此短时间内内修改 ~/.bashrc。\n在这种情况下，你只需要在当前会话中使用export来定义 PATH 变量。只要你不注销，PATH变量将保持这个临时的设置。\n# export PATH=\u0026#34;${PATH}:/home/my_user/tmp/usr/bin\u0026#34; ebuild Gentoo Development Guide Chinese Ebuild 编写基本指南 一个 ebuild 文件是一个文本文件，供 Gentoo 包管理器使用，它标识一个特定的软件包以及 Gentoo 包管理器应该如何处理它。它使用一个 bash 类似语法风格，并通过 EAPI 版本进行标准化。\nGentoo Linux 使用 ebuild 作为单个软件的包管理格式。这些 ebuild 包含相关软件的元数据（软件的名称和版本、软件使用的许可证和主页）、依赖信息（构建时和运行时依赖）以及有关如何处理的说明使用软件（配置、构建、安装、测试\u0026hellip;）。\nGentoo 中 ebuild 的默认位置是 /var/db/repos/gentoo/，该位置由repos.conf文件确定。自定义ebuild建议放在自定义库中，比如/var/db/repos/larry。\nebuild 也是运行各种 ebuild 函数 的 Portage 命令。通过运行以下命令在本地找到相关信息：\n# man 1 ebuild # man 5 ebuild 实时 ebuild\n如果源代码是从修订控制系统 (VCS) 获取的，那么此 ebuild 就是“实时 ebuild”。它们往往（但不一定）具有版本号 9999，以便可以轻松将其与基于上游版本的普通 ebuild 区分开来。\n如果 ebuild 有一个变量 PROPERTIES，其中的值是“live”，那么它就是“实时的”。如果一个 ebuild 继承了一个 VCS eclass（例如 git-r3、mercurial、darcs），它将是实时的，因为这些 eclass 中有一行 PROPERTIES+=\u0026quot;live\u0026quot;。\n在 packages.gentoo.org 站点中，实时 ebuild 具有标志 L 。在 eix 的输出中，它用 *l 标记。\n如何创建一个 ebuild vim 的用户自动获取基本骨架（由 app-vim/gentoo-syntax 提供）：\n# vim ./foobar.ebuild 模板\n# Copyright 1999-2022 Gentoo Authors # Distributed under the terms of the GNU General Public License v2 EAPI=7 DESCRIPTION=\u0026#34;\u0026#34; HOMEPAGE=\u0026#34;\u0026#34; SRC_URI=\u0026#34;\u0026#34; LICENSE=\u0026#34;\u0026#34; SLOT=\u0026#34;0\u0026#34; KEYWORDS=\u0026#34;~amd64 ~x86\u0026#34; IUSE=\u0026#34;\u0026#34; DEPEND=\u0026#34;\u0026#34; RDEPEND=\u0026#34;${DEPEND}\u0026#34; BDEPEND=\u0026#34;\u0026#34; GNU Emacs 或 XEmacs 用户可以使用类似的工具（分别由 app-emacs/ebuild-mode 或 app-xemacs/ebuild-mode 提供）。\n其他编辑器的用户从 skel.ebuild 手动复制：\n# cp /var/db/repos/gentoo/skel.ebuild ./foobar.ebuild 应该知道新包的基本信息，并将其添加到 ebuild-defined variables。\n给定源压缩包示例 为 Scrub 创建一个 ebuild：\n# mkdir -p /var/db/repos/larry/app-misc/scrub # cd $_ # vim ./scrub-2.6.1.ebuild 模板\n# Copyright 1999-2022 Gentoo Authors # Distributed under the terms of the GNU General Public License v2 EAPI=7 DESCRIPTION=\u0026#34;Some words here\u0026#34; HOMEPAGE=\u0026#34;https://github.com/chaos/scrub\u0026#34; SRC_URI=\u0026#34;https://github.com/chaos/scrub/releases/download/2.6.1/scrub-2.6.1.tar.gz\u0026#34; LICENSE=\u0026#34;GPL-2\u0026#34; SLOT=\u0026#34;0\u0026#34; KEYWORDS=\u0026#34;~amd64 ~x86\u0026#34; IUSE=\u0026#34;\u0026#34; DEPEND=\u0026#34;\u0026#34; RDEPEND=\u0026#34;${DEPEND}\u0026#34; BDEPEND=\u0026#34;\u0026#34; 允许在SRC_URI中使用${PN} variable，但不建议。虽然它可能会缩小这条线，但一些 reasoning why not to use it也值得考虑。\nSRC_URI=\u0026#34;https://github.com/chaos/${PN}/releases/download/${PV}/${P}.tar.gz\u0026#34; 可以使用ebuild命令来测试它:\n# ebuild ./scrub-2.6.1.ebuild clean unpack 这应该下载并解压源压缩包。在极少数情况下，包应该可以工作，并且不需要在 ebuild 中进一步调整。\n打补丁 如果源代码需要打补丁，可以从 patches文章中解释的解压源代码创建补丁。\n补丁将被列在一个名为PATCHES的数组中，正如devmanual中所解释的那样。\nPATCHES=( \u0026#34;${FILESDIR}\u0026#34;/${P}-foo.patch \u0026#34;${FILESDIR}\u0026#34;/${P}-bar.patch ) src_prepare() { default ... } 初探 ebuild 2015-10-05\n无论你使用过多少/多久其他的 Linux 发行版，初次接触 Gentoo 时，极有可能会觉得它在软件包的安装方面很神奇。若要在 Gentoo 中安装一个软件包，通常要定义如何进行软件源代码包的下载、解包、打补丁、编译、安装以及合并。为了实现对软件包进行细微的定制，还需要定义一些有用的元数据（即 USE 旗标）、补丁文件以及一些操控软件包编译与安装的过程。Gentoo 是通过 GNU Bash shell 脚本来定义这一切，这种脚本就是所谓的 ebuild 文件。\nebuild 在哪里？ 我们在安装 Gentoo 时，一个必须的步骤是下载一个 Portage 树的镜像包，解包后通常安置于 /var/db/repos/gentoo 目录，之后每次执行 emerge --sync 时，便会根据官方远程网站上的 Portage 树来更新你本地的 Portage 树。\n粗枝大叶的看，Portage 树有四层结点。根结点便是 /var/db/repos/gentoo 目录，第 2 层结点是软件包所属分类目录，第 3 层结点是软件包的名称目录，叶子结点则是 ebuild 文件以及其他辅助性文件或目录。以 gnome-shell-3.12.2.ebuild 文件为例，它在 Portage 树中的完整路径是 /var/db/repos/gentoo/gnome-base/gnome-shell/gnome-shell-41.1.ebuild。\n对于我们期望的软件包，如果 Portage 树未提供针对它的 ebuild 文件，那么我们需要自己动手丰衣足食。一般是不建议将我们所写的 ebuild 文件放在 Portage 树中的，因为它们可能会在 emerge --sync 期间被冲刷（比如被官方的同名文件替换）。\nPortage 树支持一种被称为 Overlay 的技术。简单来说，就是我们可以另行建立一棵新的 Portage 树，这棵树的规模虽然比官方的 Portage 树小很多，但是 Portage 树的管理系统可以将这可新的 Portage 树与官方 Portage 树『合并』。如果新的 Portage 树中某些结点与官方的 Portage 树存在重叠，那么 Portage 树的管理系统会以前者覆盖后者，因此我们新建的 Portage 树通常被直呼为『Overlay』。\n建立自己的 Overlay 在 /var/db/repos/ 目录中创建自己的 Overlay：\n# mkdir -p /var/db/repos/localrepo/{metadata,profiles} # chown -R portage:portage /var/db/repos/localrepo 在该 /var/db/repos/localrepo/profiles/ 内添加 repo_name 文件。我们可以在这份文件中设置 Overlay 名称，只需将 Overlay 名称写入该文件即可。例如，我将我的 Overlay 命名为 localrepo：\n# echo \u0026#39;localrepo\u0026#39; \u0026gt; /var/db/repos/localrepo/profiles/repo_name 为了让我们的 Overlay 能够被 Portage 管理系统所接受，需要在 /var/db/repos/localrepo/metadata/layout.conf 内添加：\nmasters = gentoo auto-sync = false 需要将 Overlay 路径告知 Portage 管理系统，即在 /etc/portage/repos.conf/localrepo.conf 文件中添加以下代码：\n[localrepo] location = /var/db/repos/localrepo 今后，就在这个 Overlay 中学习 ebuild 文件的编写。\nHello World! 下面通过写一个非常简单的 ebuild 文件来获取一些直观的认识。假设在 app-misc 这个分类中有一个名为 hello-world 的软件包，现在我们要为这个软件包的 1.0 版的安装写一份 ebuild 文件。\n 注意：软件包的分类名并不是随意的，它必须要与 /var/db/repos/gentoo 中的某个子目录名一致。\n 首先在 Overlay 中建立软件包所在的分支：\n# mkdir -p /var/db/repos/localrepo/app-misc/hello-world 可从 /var/db/repos/gentoo/header.txt 文件中获得 ebuild 文件默认的文件头，即：\n# Copyright 2021 Gentoo Authors # Distributed under the terms of the GNU General Public License v2 只不过是一些 Bash 脚本注释形式的文件描述信息而已，但它们是必须的。可以直接将 /var/db/repos/gentoo/header.txt 文件复制为 hello-world-1.0.ebuild 文件，这样便可获得一个含有上述内容的空 ebuild 文件。ebuild 文件的名称必须符合 Portage 所认可的格式，即：软件包名称-版本号.ebuild。这一点很重要。\n# cp /var/db/repos/gentoo/header.txt /var/db/repos/localrepo/app-misc/hello-world/hello-world-1.0.ebuild 下面，为这份 ebuild 文件增加以下内容：\nSLOT=\u0026#34;0\u0026#34; 这样，我们便建立了一份最为简单的 ebuild 文件。接下来就是在这份文件上签个字……也就是为之生成一份签名文件，表示这个 ebuild 的是我们做的，出了事我们负责。\n# cd /var/db/repos/localrepo/app-misc/hello-world # ebuild ./hello-world-1.0.ebuild manifest 若签名成功，会在 ebuild 文件同一目录中生成一份名为 Manifest 的文件。将来发布这份 ebuild 文件时，需要将数字签名文件一起发出，这样他人便可以验证这份 ebuild 是不是我们做的。因为非常有可能我们在向朋友们发送 ebuild 文件的过程中会被坏人拦截，然后篡改 ebuild 文件。由于 ebuild 是可被系统执行的脚本，因此很有可能变成『病毒』。因此，ebuild 文件的数字签名非常有必要。不过，这里为了简单起见，没有涉及如何用自己的密钥实现对 ebuild 的签名，所得 Manifest 文件仅仅是为了让 ebuild 能够被 Portage 管理系统所认可。\n下面，继续向这份 ebuild 加入一些内容，使之变为：\n# Copyright 2021 Gentoo Authors # Distributed under the terms of the GNU General Public License v2 EAPI=\u0026#34;7\u0026#34; SLOT=\u0026#34;0\u0026#34; DESCRIPTION=\u0026#34;A classical example to use when starting on something new.\u0026#34; HOMEPAGE=\u0026#34;http://wiki.gentoo.org/index.php?title=Basic_guide_to_write_Gentoo_Ebuilds\u0026#34; LICENSE=\u0026#34;MIT\u0026#34; KEYWORDS=\u0026#34;~alpha ~amd64 ~arm ~hppa ~ia64 ~ppc ~ppc64 ~s390 ~sh ~sparc ~x86\u0026#34; 基本上就是在原来那份最简单的 ebuild 文件的基础上增加了几个变量：\n EAPI：Portage 系统已经为我们编写了许多有用的 Bash 函数，将 EAPI 的值设为 7 表示我们要用目前最新的 Bash 函数。这个变量必须要在 ebuild 文件头之后进行设定。 DESCRIPTION：这个变量存储了 hello-world 这个软件包的简介信息。 HOMEPAGE：定义了 hello-world 这个软件包的项目主页。 LICENSE：定义了 hello-world 这个软件包所使用的许可证，例如 LGPL，GPL V2，GPL V3，MIT 等。 KEYWORDS：如果你期望 hello-world 这个软件包能够安装在你的机器上，那么 KEYWORDS 变量的值必须要包含你在 /etc/make.conf 中所设定的 ACCEPT_KEYWORDS 值。  一旦改动了 ebuild 文件内容，那么必须重新生成 Manifest 文件：\n# ebuild ./hello-world-1.0.ebuild manifest 现在，便可以使用 emerge 命令安装这个目前依然是子虚乌有的软件包了。\n# emerge -a hello-world These are the packages that would be merged, in order: Calculating dependencies... done! [ebuild N ~] app-misc/hello-world-1.0::localrepo 0 KiB Total: 1 package (1 new), Size of downloads: 0 KiB 虽然到现在为止，还是什么也没有做出来，但是看着 emerge 神奇的发现了我写的 ebuild，心底还是蔓生了一些幸福。\nemerge 与 ebuild 有什么联系？ 简单的说，就是 emerge 这个 Python 脚本会调用 ebuild.sh 这个 Bash 脚本，让后者去执行 ebuild 文件定义的软件包的下载、编译及安装过程。\nebuild.sh 所操控的软件包安装过程是在一个沙箱（Sandbox）中进行的。这一过程结束后，emerge 脚本需要将沙箱中的成果转移到真实世界，即 / 目录。\nSLOT SLOT, 即「槽」, 和具体某个包相关的概念, 是Gentoo实现多版本共存的基础。\n0 是默认的slot名, 表示没有使用slot;\nslot名是空字符串表示彻底禁止使用slot;\n带有slot的包, 包名后面会有:冒号分隔, 并带上slot, 如:\ndev-python/dnspython-1.12.0-r200:py2 dev-python/dnspython-1.12.0-r300:py3 表示dnspython这个包分别有py2和py3两个slot。\n相关的一些命令:\neix 可以直接查看包的所有slot:\n$ eix dnspython * dev-python/dnspython Available versions: (py2) 1.12.0-r200 (py3) 1.12.0-r300 {examples test PYTHON_TARGETS=\u0026quot;python2_7 python3_3 python3_4\u0026quot;} Homepage: http://www.dnspython.org/ https://pypi.python.org/pypi/dnspython Description: DNS toolkit for Python equery list -p:\n$ equery l -po dnspython * Searching for dnspython ... [-P-] [ ] dev-python/dnspython-1.12.0-r200:py2 [-P-] [ ] dev-python/dnspython-1.12.0-r300:py3 [-P-] [ ~] dev-python/dnspython-1.12.0-r301:py3 equery keywords:\n$ equery keywords dnspython Keywords for dev-python/dnspython: | | u | | a a a n p r s | n | | l m r h i m m i p i s p | u s | r | p d a m p a 6 i o p c s 3 a x | s l | e | h 6 r 6 p 6 8 p s p 6 c 9 s r 8 | e o | p | a 4 m 4 a 4 k s 2 c 4 v 0 h c 6 | d t | o ------------+---------------------------------+-------+------- 1.12.0-r200 | + + + ~ + + o o o + + o ~ ~ + + | o py2 | gentoo ------------+---------------------------------+-------+------- 1.12.0-r300 | + + + ~ + + o o o + + o ~ ~ + + | o py3 | gentoo 1.12.0-r301 | ~ ~ ~ ~ ~ ~ o o o ~ ~ o ~ ~ ~ ~ | o | gentoo 真实的 Hello World！ 在一个遥远的地方，真的存在着 hello-world 的源码包。我们只要通过 ebuild 文件将这个源码包的位置告诉 ebuild.sh 脚本，ebuild.sh 便会不远万里将其擒来。所以，我们需要在 hello-world-1.0.ebuild 文件中添加以下内容：\nSRC_URI=\u0026#34;https://gitlab.com/alogim/gentoo-basic-ebuild/-/raw/master/update1/hello-world-1.0.tar.gz?inline=false\u0026#34; SRC_URI 这个变量便是存储源码包的下载地址的。\n在重新生成 Manifest 时，ebuild.sh 便会自动将源码包下载到 /var/cache/distfiles/ 目录，并为这个源码包也生成一个数字签名存储在 Manifest 文件中。\n既然有了 hello-world 的源码包，那么下一步就该思考如何在 ebuild 文件中定义这个源码包的编译过程了。不过，解开刚才下载的 hello-world-1.0.tar.gz 包看一下，发现包里只有一份 Bash 脚本 hello-world，其内容为：\n#!/bin/sh  echo \u0026#34;Hello world!\u0026#34; 所以，这个源码包就没必要编译了，直接安装到系统中即可。从而，我们在 ebuild 文件中获得了第一次编写 ebuild 函数的机会。在现有的 hello-world-1.0.ebuile 的文件中继续添加以下内容：\nsrc_install() { dobin hello-world } src_install 是 ebuild.sh 脚本能够识别并执行的函数名。也就是说，从 ebuild.sh 脚本的角度来看，你若想让我替你将软件包安装至系统中，那么你必须得按照我的习惯来。我的习惯就是在你提供给我的 ebuild 文件中寻找 src_install 这个函数，如果有这个函数，我就执行它，否则我就什么也不做。这就是 ebuild.sh 与 ebuild 文件之间达成的一个约定。\n现在我们在 ebuild 文件中向 ebuild.sh 提供了 src_install 这个函数。这个函数只包含一条命令：dobin hello-world 。这个命令的意思是为 hello-world 这个脚本设置可执行权限，然后将其安装至系统默认的可执行文件目录中，即 /usr/bin 目录。\nsrc_install 只是 ebuild.sh 与 ebuild 文件之间众多约定函数中的一个而已，并且这些约定函数是顺次被 ebuild.sh 执行的，如下图所示：\n这里存在一个问题，hello-world 这个 Bash 脚本是包含在 hello-world-1.0.tar.gz 这个包内的，而我们只在 hello-world-1.0.ebuild 文件中定义了 src_install 函数，那么 hello-world-1.0.tar.gz 何时被解包的呢？这个问题的答案是，Portage 管理系统中已经为这些约定的函数定义了默认行为。比如，用于为源码包解包的 src_unpack 函数，其默认的定义是：\nsrc_unpack() { if [ \u0026#34;${A}\u0026#34; != \u0026#34;\u0026#34; ]; then unpack ${A} fi } 如果在 ebuild 文件中没有重新定义 src_unpack 函数，那么 ebuild.sh 便会按照上面图示的管线调用默认的 src_unpack 函数。所以 hello-world 脚本得以从 hello-world-1.0.tar.gz 中解出。\n对现在的 hello-world-1.0.ebuild 再次生成 Manifest，然后就可以用它将 hello-world 脚本安装至 /usr/bin 目录中了。\n这就是我们用自己写的 ebuild 安装的第一个『软件包』。\nebuild repository An ebuild repository, colloquially known as an overlay, is a structure of directories and files used to add and extend software packages for a Gentoo-based system.\nEbuild repositories contain ebuilds, eclasses, and other types of descriptive metadata files. These files inform the package manager of software available for installation, news items, and profile targets. An ebuild repository should conform to one or more Ebuild APIs as detailed in Gentoo\u0026rsquo;s Package Manager Specification.\nThe Gentoo ebuild repository, as Gentoo\u0026rsquo;s primary and \u0026ldquo;official\u0026rdquo; repository, is the source for all the information needed to build and install Gentoo packages, contained in ebuilds.\nAdministrators of Gentoo systems can add additional ebuild repositories by using various utilities and methods described below.\nThe Gentoo ebuild repository The Gentoo ebuild repository will sometimes be called by shorter, or even colloquial, names, such as the Gentoo repository, the Gentoo repo, ::gentoo, gentoo.git, or occasionally just the \u0026ldquo;repo\u0026rdquo;. It was historically known within the Gentoo community as the Portage tree, rsync tree, or sometimes just \u0026ldquo;the tree\u0026rdquo;.\nRepositories in general Repositories are handled through /etc/portage/repos.conf (which, like many other Portage configuration locations, can be a file or a directory), and the eselect repository is is a tool to manage this configuration.\nRepository definitions inside /etc/portage/repos.conf also inform Portage if and how the repository can be updated. With it, calling emaint sync \u0026ndash;auto will automatically update the enabled repositories as well.\nA deprecated, yet still supported method is to use the PORTDIR_OVERLAY variable inside /etc/portage/make.conf. This variable can point to one or more additional locations on the file system where additional repositories are available. The use of the /etc/portage/repos.conf/ directory is highly preferred.\nFor more information, see /etc/portage/repos.conf and the Portage/Sync article.\nPriorities Ebuilds from repositories with higher priority numbers (for example 60) will take precedence over ebuilds from repositories with lower priorities (such as 50).\nThe list of ebuild repositories with their priorities can be obtained through the output of the following commands (look for the \u0026ldquo;Repositories\u0026rdquo; string):\n# emerge --info --verbose # portageq repos_config / The Gentoo ebuild repository will have a priority of -1000 which means that all other repositories generally take precedence if they are assigned a higher priority. This is the default behaviour, because ebuild repositories are designed to \u0026ldquo;lay over\u0026rdquo; or \u0026ldquo;on top\u0026rdquo; of the Gentoo repository. To set the priority of other repositories, manually edit the relevant repos.conf section and set priority = to the desired value. For example:\n# nano -w /etc/portage/repos.conf/eselect-repo.conf [guru] location = /var/db/repos/guru sync-type = git sync-uri = https://github.com/gentoo-mirror/guru.git priority = 100 Repositories that do not have a priority set default to 0.\nRepository synchronization Repository synchronization is generally managed with the emaint sync command. See the Portage sync article, and man emaint for information on how to use the portage synchronization commands.\nThe emerge \u0026ndash;sync command is now only a compatibility command, calling the emaint module. eix-sync is a wrapper using emerge \u0026ndash;sync, followed by eix-update. For further details see the Eix article and man eix.\nThe emerge-webrsync tool can be used to download and install the daily Gentoo Repository snapshot. This may help with firewall restrictions.\nRepository management tools eselect-repository eselect repository maintains /etc/portage/repos.conf entries for Portage to access and synchronize.\nLayman eselect repository supersedes layman for most uses.\nUsage Emerging a duplicate package When working with ebuild repositories it is possible to encounter a situation where multiple versions of the same package are available from different ebuild repositories. Instruct Portage to install a specific package from a specific ebuild repository with the :: version specifier:\n# emerge --ask category/atom::repository-name The same notation can be used for different emerge instructions, including uninstalling a package through --depclean.\nBest practices Cache generation When large ebuild repositories are installed, Portage may take a long time to perform operations like dependency resolution. This is because ebuild repositories do not usually contain a metadata cache.\nGenerate a local metadata cache by running emerge \u0026ndash;regen after syncing the ebuild repositories:\n# emaint sync --allrepos # ( ulimit -n 4096 \u0026amp;\u0026amp; emerge --regen ) Be careful, because emerge \u0026ndash;regen takes a lot of time and it\u0026rsquo;s not recommended for rsync users as rsync updates the cache using server-side caches (most of users of portage are rsync users). Rsync users should simply run emerge \u0026ndash;sync (or eix-sync) to regenerate the cache. It\u0026rsquo;s probably only users of very large ebuild repositories should try emerge \u0026ndash;regen.\nMasking enabled ebuild repositories When using large ebuild repositories or those with unknown/low quality code, it is best practice to hard mask the whole ebuild repository and only accept specific ebuilds on a case-by-case basis. For example, for an overlay named \u0026ldquo;repository-foobar\u0026rdquo;:\n# nano -w /etc/portage/package.mask/repository-foobar */*::repository-foobar Then add the specific package(s) from the repository-foobar overlay so that they will be available visible to Portage for installation:\n# nano -w /etc/portage/package.unmask/bar foo-category/bar::repository-name After the above unmask the package named \u0026ldquo;foo-category/bar\u0026rdquo; should be available and none of the other packages from the repository-foobar overlay will be available, which is by design.\nGentoo on ZFS 备份 初始化硬盘 这里的初始化硬盘是为了将原来的数据全部清除并且重新建立LUKS和文件系统。出于安全的考虑，备份不应该直接在硬盘上分区创建文件系统后备份在上面，应该做一层加密再去创建文件系统和备份。\n将硬盘插入需要备份的电脑上\n查看新增的设备\n$ fdisk -l Disk /dev/sda: 232.9 GiB, 250055122432 bytes, 488388911 sectors Disk model: 00AAJS-00B4A0 Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0x80f01a9c Device Boot Start End Sectors Size Id Type /dev/sda1 2048 488388910 488386863 232.9G 83 Linux 这里可以看到新添加的磁盘，上面是有以前的东西，这里为了安全起见用随机数据覆盖掉这个分区。 这里会清除可能存在的任何没有加密的旧数据，如果遭受攻击这会让攻击者更难确定数据位置，这一步会很慢（取决于你的接口速度和硬盘速率）。\n$ sudo dd if=/dev/urandom of=/dev/sda bs=1M status=progress \u0026amp;\u0026amp; sync 完成之后，我们需要重新对这个硬盘进行分区\n$ sudo fdisk /dev/sda Welcome to fdisk (util-linux 2.35.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): n Partition type p primary (0 primary, 0 extended, 4 free) e extended (container for logical partitions) Select (default p): Using default response p. Partition number (1-4, default 1): First sector (2048-488388910, default 2048): Last sector, +/-sectors or +/-size{K,M,G,T,P} (2048-488388910, default 488388910): Created a new partition 1 of type \u0026#39;Linux\u0026#39; and of size 232.9 GiB. Command (m for help): w The partition table has been altered. Calling ioctl() to re-read partition table. Syncing disks. 这样就创建了一个分区，接下来我们要在这个分区上创建LUKS\n创建 LUKS 我们这里可以使用cryptsetup这个命令来初始化我们的LUKS分区\n如果你没有这个命令可以运行这条命令进行安装：\n$ emerge -av cryptsetup 然后初始化分区\n$ sudo cryptsetup luksFormat /dev/sda1 WARNING! ======== This will overwrite data on /dev/sda1 irrevocably. Are you sure? (Type \u0026#39;yes\u0026#39; in capital letters): YES Enter passphrase for /dev/sda1: Verify passphrase: 这里会提示这个操作将会将这个分区里面的内容全部删掉，输入大写的YES确认，然后输入两次密码，注意密码是没有回显的。\n打开 LUKS 和创建文件系统 现在是LUKS已经做好了，但是我们还需要在上面格式化分区才能够挂载使用，我们首先要打开LUKS分区：\n$ sudo cryptsetup luksOpen /dev/sda1 backup Password: Enter passphrase for /dev/sda1: 我这里是想打开这个LUKS卷，为了区分和其他的我给这个名字叫做backup，然后会提示你输入LUKS的密码，正确输入之后就可以在/dev/mappaer下面看到一个backup的设备了\n现在对这个分区进行格式化，这次用的是ext4的分区\n$ sudo mkfs.ext4 -v /dev/mapper/backup 创建挂载点和挂载 在完成了分区初始化之后我们还需要创建一个挂载点用于挂载这个备份的分区:\n$ sudo mkdir -pv /backup 挂载分区:\n$ sudo mount -v /dev/mapper/backup /backup 备份系统 下载就可以备份系统了，这次使用的是rsync工具来进行备份系统：\n$ sudo rsync -aAXv --exclude={\u0026#34;/dev/*\u0026#34;,\u0026#34;/proc/*\u0026#34;,\u0026#34;/sys/*\u0026#34;,\u0026#34;/tmp/*\u0026#34;,\u0026#34;/run/*\u0026#34;,\u0026#34;/mnt/*\u0026#34;,\u0026#34;/media/*\u0026#34;,\u0026#34;/lost+found\u0026#34;,\u0026#34;/backup/*\u0026#34;,\u0026#34;/swapfile\u0026#34;} / /backup 这里使用的-aAXv选项的意思是：文件将会以归档模式传输，保留符号设备，文件权限，修改时间，ACL和扩展属性，并且将备份的过程打印在屏幕上。\n--exclude就是排除特定的文件类似于/dev、/proc之类的，/backup是我们的备份分区不需要再去搞一份防止出现奇奇怪怪的后果。\n这会耗费很多时间可以休息一下做其他的事情。\n等待这个备份完成之后我们就可以卸载这块硬盘进行保存了。\n卸载挂载点\n$ umount /backup 关闭LUKS分区\n$ cryptsetup luksClose backup 迁移到 ZFS 分区 首先我需要把之前的分区全部干掉，然后创建如下表的分区：\n   分区 文件系统 大小     /dev/nvme0n1p1 fat32 128M   /dev/nvme0n1p2 swap 64G   /dev/nvme0n1p3 ZFS ALL    直接在系统里面丢swapfile是不合理的，最好是有个单独的分区给swap。\n初始化分区 创建完成分区之后我们还需要对分区进行初始化：\n$ mkfs.vfat -F32 /dev/nvme0n1p1 $ mkswap /dev/nvme0n1p2 创建 pool 这里需要注意一点是像是我们之前分区的/dev/nvme0n这种设备或者是/dev/sda这样的，如果插拔U盘之类的可能盘序会发生变化，但是ZFS池是不会意识到这个变化的，这样就会产生zfs池不可用的问题，我们需要一些方法来获取到磁盘的id并以此来创建我们的zfs池。\n$ ls -l /dev/disk/by-id lrwxrwxrwx 1 root root 13 Feb 13 12:29 nvme-KXG50PNV2T04_KIOXIA_Y9IS103FTHDM -\u0026gt; ../../nvme0n1 lrwxrwxrwx 1 root root 15 Feb 13 12:32 nvme-KXG50PNV2T04_KIOXIA_Y9IS103FTHDM-part1 -\u0026gt; ../../nvme0n1p1 lrwxrwxrwx 1 root root 15 Feb 13 12:29 nvme-KXG50PNV2T04_KIOXIA_Y9IS103FTHDM-part2 -\u0026gt; ../../nvme0n1p2 KXG50PNV2T04_KIOXIA_Y9IS103FTHDM-part3 -\u0026gt; ../../nvme0n1p3 ... 这里的KXG50PNV2T04_KIOXIA_Y9IS103FTHDM就是我们的硬盘，nvme-KXG50PNV2T04_KIOXIA_Y9IS103FTHDM-part1就是我们创建作为未来的/boot分区。\n当我们创建zfs池的时候尽可能选择用这种id的方式去创建。现在我们创建一个加密的zpool：\n$ zpool create -f -o ashift=12 -o cachefile=/etc/zfs/zpool.cache -O compression=lz4 -O xattr=sa -O relatime=on -O acltype=posixacl -O dedup=off -O encryption=on -O keyformat=passphrase -m none -R /mnt/gentoo rock /dev/disk/by-id/nvme-eui.000000000000001000080d0200600f01-part3 zpoolprops\n ashift=ashift: Pool sector size exponent, to the power of 2 (internally referred to as ashift). The typical case for setting this property is when performance is important and the underlying disks use 4KiB sectors but report 512B sectors to the OS (for compatibility reasons); in that case, set ashift=12 (which is 1\u0026laquo;12 = 4096). cachefile=path|none: Controls the location of where the pool configuration is cached. Setting this property caches the pool configuration in a different location that can later be imported with zpool import -c.  根据提示输入密码（注意密码不会有回显，并不是键盘坏了）。\n这条命令创建了一个名为 rock的zfs池 使用的压缩算法为lz4。\n如果说你想创建一个不带加密的zpool可以去掉-O encryption=on -O keyformat=passphrase这两个选项。\n创建 datasets 接下来我们要创建自己的rootfs，并且在上面打开加密功能：\n$ zfs create -o mountpoint=none -o canmount=off rock/os $ zfs create -o mountpoint=/ rock/os/gentoo 安装系统 这次安装系统的话，是打算直接从硬盘恢复的，首先插上备份好的硬盘：\n$ fdisk -l ........ Disk /dev/sdc: 232.88 GiB, 250055122432 bytes, 488388911 sectors Disk model: 00AAJS-00B4A0 Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 4096 bytes / 33553920 bytes Disklabel type: dos Disk identifier: 0x80f01a9c Device Boot Start End Sectors Size Id Type /dev/sdc1 2048 488388910 488386863 232.9G 83 Linux 这里看到我们的备份硬盘。我们要创建一个目录用来挂载这个分区：\n$ mkdir -pv /backup 打开LUKS分区：\n$ cryptsetup luksOpen /dev/sdc1 backup Enter passphrase for /dev/sdc1: 输入之前设置的密码。挂载分区：\n$ mount -v /dev/mapper/backup /backup 还有一个分区我们要注意一下就是/boot分区，创建boot分区的挂载点：\n$ mkdir -pv /mnt/gentoo/boot 挂载分区：\n$ mount -v /dev/nvme0n1p1 /mnt/gentoo/boot 将所有文件同步到zfs的dataset里面：\n$ rsync -aAXv --exclude={\u0026#34;/dev/*\u0026#34;,\u0026#34;/proc/*\u0026#34;,\u0026#34;/sys/*\u0026#34;,\u0026#34;/tmp/*\u0026#34;,\u0026#34;/run/*\u0026#34;,\u0026#34;/mnt/*\u0026#34;,\u0026#34;/media/*\u0026#34;,\u0026#34;/lost+found\u0026#34;,\u0026#34;/backup/*\u0026#34;,\u0026#34;/swapfile\u0026#34;} /backup/ /mnt/gentoo 这个复制需要一定的时间，耐心等待完成，期间不要断开硬盘或者是拔掉电源。\nchroot 等到复制原来的系统完成之后我们就需要进入chroot环境，然后完成其他的必要配置了。\n拷贝ZFS池缓存文件：\n$ mkdir -pv /mnt/gentoo/etc/zfs $ cp -v /etc/zfs/zpool.cache /mnt/gentoo/etc/zfs 拷贝网络的DNS：\n$ cp --dereference /etc/resolv.conf /mnt/gentoo/etc/ 挂载必要的文件系统：\n$ mount --types proc /proc /mnt/gentoo/proc $ mount --rbind /sys /mnt/gentoo/sys $ mount --make-rslave /mnt/gentoo/sys $ mount --rbind /dev /mnt/gentoo/dev $ mount --make-rslave /mnt/gentoo/dev 我们不是在官方的Livecd下面还需要执行：\n$ test -L /dev/shm \u0026amp;\u0026amp; rm /dev/shm \u0026amp;\u0026amp; mkdir /dev/shm $ mount --types tmpfs --options nosuid,nodev,noexec shm /dev/shm $ chmod 1777 /dev/shm 进入chroot：\n$ chroot /mnt/gentoo /bin/bash $ source /etc/profile $ export PS1=\u0026#34;(chroot) $PS1\u0026#34; ZFS 安装和配置 首先是要给原来的系统安装上ZFS的支持，确保内核打开了Zlib的支持：\nGeneral Architecture Dependent Options ---\u0026gt; GCC plug ins ---\u0026gt; [ ] Randomize layout of sensitive kernel structures Cryptographic API ---\u0026gt; \u0026lt;*\u0026gt; Deflate compression algorithm Security options ---\u0026gt; [ ] Harden common str/mem functions against buffer overflows 我们还需要调整portage让ZFS包接收测试分支的包：\n$ echo \u0026#34;sys-fs/zfs-kmod ~amd64\u0026#34; \u0026gt;\u0026gt; /etc/portage/package.accept_keywords/zfs-kmod $ echo \u0026#34;sys-fs/zfs ~amd64\u0026#34; \u0026gt;\u0026gt; /etc/portage/package.accept_keywords/zfs 如果你想要使用实时的包可以:\n$ echo \u0026#34;=sys-fs/zfs-kmod-9999 **\u0026#34; \u0026gt;\u0026gt; /etc/portage/package.accept_keywords/zfs-kmod $ echo \u0026#34;=sys-fs/zfs-9999 **\u0026#34; \u0026gt;\u0026gt; /etc/portage/package.accept_keywords/zfs 但是不推荐用最新的，要到处找patch。\n安装ZFS：\n$ emerge -av zfs 有一个很重要的点，每次更新内核或者是编译内核之后最好是重新构建一下模块，否则有可能遇到zpool无法正常初始化的问题：\n$ emerge -va @module-rebuild 将zfs加入到开机启动项和对应的启动级别：\n$ systemctl enable zfs.target $ systemctl enable zfs-import-cache $ systemctl enable zfs-mount $ systemctl enable zfs-import.target 生成和验证zfs hostid文件，这个文件是用于genkernel生成initramfs和zfs导入池的时候验证完整性时候需要的：\n$ zgenhostid $ file /etc/hostid Bootload fstab and Initramfs GRUB 修改grub的配置文件，内容如下：\nGRUB_CMDLINE_LINUX=\u0026#34;dozfs root=ZFS=rock/os/gentoo\u0026#34; 安装bootload：\n$ grub-install --target=x86_64-efi --efi-directory=/boot --bootloader-id=Gentoo 生成配置文件：\n$ grub-mkconfig -o /boot/grub/grub.cfg fstab 挂载的工作这次交给zfs来去完成，我们这里还需要修改一下fstab\n首先查看分区的id：\n$ blkid /dev/nvme0n1p1: UUID=\u0026#34;129F-3405\u0026#34; BLOCK_SIZE=\u0026#34;512\u0026#34; TYPE=\u0026#34;vfat\u0026#34; PARTUUID=\u0026#34;537bd932-cc1f-5643-a297-feebaeb6a5ea\u0026#34; /dev/nvme0n1p2: LABEL=\u0026#34;rock\u0026#34; UUID=\u0026#34;7999529021869478878\u0026#34; UUID_SUB=\u0026#34;11607083434113154920\u0026#34; BLOCK_SIZE=\u0026#34;4096\u0026#34; TYPE=\u0026#34;zfs_member\u0026#34; PARTUUID=\u0026#34;d68d6b86-a407-4141-a1a7-1379cbe1e049\u0026#34; 可以看到我们的/boot分分区UUID是129F-3405，现在可以修改/etc/fstab\n$ nano -w /etc/fstab 内容如下\n# /dev/nvme0n1p1 /dev/nvme0n1p1 /boot vfat rw,relatime,fmask=0022,dmask=0022,codepage=437,iocharset=iso8859-1,shortname=mixed,errors=remount-ro\t0 2 initramfs 重新生成initramfs，之前的initramfs没有zfs的支持这次要加上，为了保证工作正常还需要将genkrenel切换到testing分支\n$ echo \u0026#34;=sys-kernel/genkernel-9999 **\u0026#34; \u0026gt; /etc/portage/package.accept_keywords/genkernel 更新genkernel\n$ emerge -av genkernel 重新生成initramfs文件\n$ genkernel initramfs --zfs --compress-initramfs 重启 在重启验证之前我们需要先做一些清理工作\n首先退出chroot环境\n$ exit 卸载备份分区\n$ umount -R /backup 关闭backup卷\n$ cryptsetup luksClose backup 然后就可以重启啦\n$ reboot 重启之后第一次可能还是没办法正常进入系统，需要进入到shell里面导入一下zpool\n$ zpool import -f rock 设置一下分区挂载点\n$ zfs set mountpoint=/ rock/os/gentoo 然后再重启一下就可以正常进入系统了。\n使用ZFS备份 创建备份ZFS池 首先进入livecd，查看设备：\n$ fdisk -l Disk /dev/nvme0n1: 1.86 TiB, 2048408248320 bytes, 4000797360 sectors ... Disk /dev/sda: 233.76 GiB, 251000193024 bytes, 490234752 sectors ... Disk /dev/sdc: 57.81 GiB, 62075699200 bytes, 121241600 sectors ... 这里的设备分别为：\n   物理位置 说明     /dev/nvme0n1 系统盘   /dev/sda 备份盘   /dev/sdc 启动盘    首先在备份盘上创建一个分区（分配所有空间到这个分区上）：\n$ fdisk /dev/sda Welcome to fdisk (util-linux 2.36). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Device does not contain a recognized partition table. Created a new DOS disklabel with disk identifier 0x108318f9. Command (m for help): n Partition type p primary (0 primary, 0 extended, 4 free) e extended (container for logical partitions) Select (default p): Using default response p. Partition number (1-4, default 1): First sector (2048-490234751, default 2048): Last sector, +/-sectors or +/-size{K,M,G,T,P} (2048-490234751, default 490234751): Created a new partition 1 of type \u0026#39;Linux\u0026#39; and of size 233.8 GiB. Command (m for help): w The partition table has been altered. Calling ioctl() to re-read partition table. Syncing disks. 查看硬盘ID\n$ ls -l /dev/disk/by-id ... lrwxrwxrwx 1 root root 10 Feb 27 14:53 usb-ACASIS_MAC3E_000000000001-0:0-part1 -\u0026gt; ../../sda1 ... usb-ACASIS_MAC3E_000000000001-0:0-part1这里就是我们所需要的硬盘ID，我们使用这个来创建备份池子：\n$ zpool create -f -o ashift=12 -o cachefile=/etc/zfs/zpool.cache -O compression=lz4 -O xattr=sa -O relatime=on -O acltype=posixacl -O dedup=off -m none -R /mnt/backup backup /dev/disk/by-id/usb-ACASIS_MAC3E_000000000001-0:0-part1 备份池也可以加密。\n创建快照 首先导入原来的zpool\n$ zpool import -f rock 给之前的系统创建一个快照：\n$ sudo zfs snapshot rock/os/gentoo@2021-02-27-0000-01-install 查看\n$ zfs list -r -t snapshot -o name,creation rock/os/gentoo rock/os/gentoo@2021-02-27-0000-01-install Sat Feb 27 14:16 2021 发送快照 我们需要打开原来的rock/os/gentoo数据集\n但是首先要设置一下挂载点：\n$ zfs set mountpoint=/mnt/gentoo rock/os/gentoo 打开rock/os/gentoo数据集\n$ zfs mount -l -a 发送快照到backup/os/gentoo\n$ zfs send rock/os/gentoo@2021-02-27-0000-01-install | zfs recv backup/2021-02-27-0000-01-backup 这个会花很长的时间，取决于你使用的接口速度，可以通过这条命令查看io情况：\n$ zpool iostat 2 这条命令是查看所有的zpoolio情况，2秒刷新一次。\n备份/boot分区 设置挂载点\n$ zfs set mountpoint=/mnt/backup backup/2021-02-27-0000-01-backup 备份\n$ mkdir -pv /mnt/boot $ mount -v /dev/nvme0n1p1 /mnt/boot $ cp -rv /mnt/boot/* /mnt/backup/boot/ 恢复快照 卸除挂载：\n$ zfs umount backup/2021-02-27-0000-01-backup 现在就可以恢复快照了：\n$ zfs send backup/2021-02-27-0000-01-backup | zfs recv -F -x encryption rock/os/gentoo 定期备份 在Gentoo的Portage Tree中提供了一个sys-fs/zfs-auto-snapshot的包，这个包可以帮我们创建一个定时任务周期性的备份我们的ZFS\n$ sudo emerge -av sys-fs/zfs-auto-snapshot 可以根据需要配置备份的周期：\n$ sudo zfs set com.sun:auto-snapshot:daily=true rock/os/gentoo $ sudo zfs set com.sun:auto-snapshot:weekly=true rock/os/gentoo 问题排查 grub 救援 grub rescue\u0026gt; set prefix=(hd0,1)/boot/grub grub rescue\u0026gt; set root=(hd0,1) grub rescue\u0026gt; insmod normal grub rescue\u0026gt; normal grub rescue\u0026gt; insmod linux grub rescue\u0026gt; linux /boot/vmlinuz-3.13.0-29-generic dozfs root=ZFS=rock/os/gentoo grub rescue\u0026gt; initrd /boot/initrd.img-3.13.0-29-generic grub rescue\u0026gt; boot 通过 livecd 修复 导入 zpool\n$ zpool import -f rock $ zfs set mountpoint=/mnt/gentoo rock/os/gentoo 挂载 dataset\n$ zfs mount -la 挂载 boot 分区\n$ mount /dev/nvme0n1p1 /mnt/gentoo/boot/ 挂载必要的文件系统\n$ mount --types proc /proc /mnt/gentoo/proc $ mount --rbind /sys /mnt/gentoo/sys $ mount --make-rslave /mnt/gentoo/sys $ mount --rbind /dev /mnt/gentoo/dev $ mount --make-rslave /mnt/gentoo/dev # 我们不是在官方的Livecd下面还需要执行： $ test -L /dev/shm \u0026amp;\u0026amp; rm /dev/shm \u0026amp;\u0026amp; mkdir /dev/shm $ mount --types tmpfs --options nosuid,nodev,noexec shm /dev/shm $ chmod 1777 /dev/shm 进入 chroot\n$ chroot /mnt/gentoo /bin/bash $ source /etc/profile $ export PS1=\u0026#34;(chroot) $PS1\u0026#34; 退出 chroot\n$ exit 卸除挂载\n$ umount -R /mnt/gentoo 改回 rootfs 挂载点\n$ zfs set mountpoint=/ rock/os/gentoo 重启\n$ reboot LUKS 数据的安全，保密性在现在的生活中显得越来越重要。随着数字化的时代的来临，越来越多的数据被数字化，特别是更多有关于我们隐私的数据在不断生成，甚至还有我们需要离线保存的密钥等。而且通常我们使用磁盘，USB 闪存，SD 卡等存储介质进行存储，即便我们已经离线存储，仍然不能保证该存储介质不会丢失，如果丢失那么对于我们来说有可能是灾难性的事件。因此对这些离线存储的重要数据，再次进行进行加密是非常有必要的，本文将告诉你如何加密你的移动存储介质。\n在此之前先介绍一下 LUKS：\n LUKS （Linux Unified Key Setup）是 Linux 硬盘加密的标准。 通过提供标准的磁盘格式，它不仅可以促进发行版之间的兼容性，还可以提供对多个用户密码的安全管理。 与现有解决方案相比，LUKS 将所有必要的设置信息存储在分区信息首部中，使用户能够无缝传输或迁移其数据。\n 内核配置（可选） 通常来说，大部分发行版的内核都已经配置了相关的加密部分，因此非 gentoo 用户可以跳过此部分。\n配置 device mapper 和 crypt target：\n[*] Enable loadable module support Device Drivers ---\u0026gt; [*] Multiple devices driver support (RAID and LVM) ---\u0026gt; \u0026lt;*\u0026gt; Device mapper support \u0026lt;*\u0026gt; Crypt target support 配置加密 API：\n[*] Cryptographic API ---\u0026gt; \u0026lt;*\u0026gt; XTS support \u0026lt;*\u0026gt; SHA224 and SHA256 digest algorithm \u0026lt;*\u0026gt; AES cipher algorithms \u0026lt;*\u0026gt; AES cipher algorithms (x86_64) \u0026lt;*\u0026gt; User-space interface for hash algorithms \u0026lt;*\u0026gt; User-space interface for symmetric key cipher algorithms 编译新内核并配置应用，然后重启：\n# make -j9 \u0026amp;\u0026amp; make modules_install \u0026amp;\u0026amp; make install 安装软件 通常的发行版已经预装了该软件包，可以直接使用，下面是 Gentoo 的安装方法\n# emerge --ask sys-fs/cryptsetup 创建加密分区 注意，该操作会清空你选择分区或设备上的所有数据，请谨慎操作，输入大写的 YES 确认\n# cryptsetup -s 512 luksFormat /dev/sdd WARNING! ======== This will overwrite data on /dev/sdd irrevocably. Are you sure? (Type uppercase yes): YES Enter passphrase: Verify passphrase: 利用密钥文件加密分区 除了密码之外，还可以选择使用密钥文件解密你的硬盘，也就是相当于一个密钥，当然可以也可以只使用密钥文件或者同时使用密码与密钥文件。\n生成随机密钥文件 # dd if=/dev/urandom of=/root/enc.key bs=1 count=4096 添加密钥文件作为密码之一 # cryptsetup luksAddKey /dev/sdd /root/enc.key Enter any existing passphrase: 移除解密密码 移除普通密码：\n# cryptsetup luksRemoveKey /dev/sdd Enter LUKS passphrase to be deleted: ... 移除 key file 密码：\n# cryptsetup luksRemoveKey -d /root/enc.key /dev/sdd 注意：千万不要将所有密码移除，至少需要留有一个密码访问设备，移除操作不可撤销\n解密与挂载 密码解密 # cryptsetup luksOpen /dev/sdd myusb Enter passphrase for /dev/sdd: key file 解密 # cryptsetup luksOpen -d /root/enc.key /dev/sdd myusb 创建文件系统 在挂载使用之前，我们仍然需要对设备创建文件系统才可以使用，可以选择任何你喜欢的文件系统，例如 btrfs，ext4，vfat，ntfs 等\n# mkfs.ext4 /dev/mapper/myusb mke2fs 1.43.6 (29-Aug-2017) Creating filesystem with 488448 4k blocks and 122160 inodes Filesystem UUID: 995e172a-2bc6-432c-a60f-2d4d7093e748 Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912 Allocating group tables: done Writing inode tables: done Creating journal (8192 blocks): done Writing superblocks and filesystem accounting information: done 挂载 现在可以像正常分区一样挂载我们的加密分区设备了\n# mount /dev/mapper/myusb /mnt/ # df -h /dev/mapper/myusb 1.9G 5.7M 1.7G 1% /mnt 卸载挂载点并关闭加密分区 # umount /mnt # cryptsetup luksClose myusb 总结 在完成整个步骤以后，您现在需要做的就是妥善保管您的加密存储，可采用同样的方式加密多个设备进行备份，因为谁也不能保证这移动设备会不会在什么时候丢掉。\n双显卡笔记本独显直通 介绍 双显卡笔记本中直通独显（dGPU）到 win10 虚拟机。\n环境：\n 联想 Legion R7000P 2020 笔记本 RTX2060 笔记本显卡 libvirt+qemu Host: Gentoo Linux Guest: Windows 10 LTSC 2019  MUXed MUXed 结构的笔记本才容易实现独立显卡直通，Legion R7000P 应该就是 MUXed 的。关于什么是 MUXed 的，可以看下图的解释。\n关于如何检测笔记本是否是 MUXed 的，目前没有什么好的办法。有一种说法是运行 lspci，查找有关 Intel HD Graphics/AMD GPU 和 NVIDIA 的设备：\n 如果独显设备名以 3D Controller 开头，那你的电脑就是第二种 MUXless（核显直连显示器）。 如果独显设备名以 VGA Controller 开头，并且有一个 HD Graphics/AMD GPU 核显，那你的电脑是第三种 MUXed（核显、独显切换）。  启用 IOMMU 和 vfio 模块 IOMMU  intel CPU：添加内核参数 intel_iommu=on iommu=pt ，BIOS 开启 VT-d amd CPU：添加内核参数 iommu=pt ，BIOS 开启 AMD-Vi  vfio 添加模块 vfio_pci vfio vfio_iommu_type1 vfio_virqfd 到 initramfs 中。如果是像我一样使用 dracut 生成 initramfs，则在 /etc/dracut.conf 中添加配置 add_drivers+=\u0026quot; vfio_pci vfio vfio_iommu_type1 vfio_virqfd \u0026quot; ，之后重新生成 initramfs。\n隔离 GPU #!/bin/bash shopt -s nullglob for g in `find /sys/kernel/iommu_groups/* -maxdepth 0 -type d | sort -V`; do echo \u0026#34;IOMMU Group ${g###*/}:\u0026#34; for d in $g/devices/*; do echo -e \u0026#34;\\t$(lspci -nns ${d###*/})\u0026#34; done; done; 运行上述脚本，查看显卡所在的 IOMMU Group，并得到显卡相关设备的 device id。\nIOMMU Group 10: 01:00.0 VGA compatible controller [0300]: NVIDIA Corporation TU106M [GeForce RTX 2060 Mobile] [10de:1f15] (rev a1) 01:00.1 Audio device [0403]: NVIDIA Corporation TU106 High Definition Audio Controller [10de:10f9] (rev a1) 01:00.2 USB controller [0c03]: NVIDIA Corporation TU106 USB 3.1 Host Controller [10de:1ada] (rev a1) 01:00.3 Serial bus controller [0c80]: NVIDIA Corporation TU106 USB Type-C UCSI Controller [10de:1adb] (rev a1) 如上所见，device id 分别为 10de:1f15 、 10de:10f9 、 10de:1ada 、 10de:1adb 。再将以上 deivce id 作为参数添加到内核参数或 /etc/modprobe.d/vfio.conf 中。\n 内核参数：vfio-pci.ids=10de:1f15,10de:10f9,10de:1ada,10de:1adb /etc/modprobe.d/vfio.conf ：options vfio-pci ids=10de:1f15,10de:10f9,10de:1ada,10de:1adb  dracut 必须将 device id 添加到内核参数中，并且添加参数 rd.driver.pre=vfio_pci 。\n最后重启电脑。开机后通过命令 lspci -k 确认上述 device id 对应的设备在使用 vfio-pci 驱动。如果有各别设备没有使用 vfio-pci 驱动，则可以通过手动 unbind 和 bind 驱动的方式加载 vfio-pci 驱动。比如如果 0000:01:00.2 仍在使用 xhci_hcd 驱动，则：\n# run as root echo -n \u0026#34;0000:01:00.2\u0026#34; \u0026gt; /sys/bus/pci/drivers/xhci_hcd/unbind echo -n \u0026#34;0000:01:00.2\u0026#34; \u0026gt; /sys/bus/pci/drivers/vfio-pci/bind 创建虚拟机 首先使用 libvirt 创建一个非显卡直通的虚拟机，如果你有多余的显示器和键鼠，也可以直接创建显卡直通的虚拟机。这里我们假设没有多余的设备，并且之后使用 RDP 连接虚拟机。\n首先下载windows 10 LTSC 2019和 virtio windows驱动镜像。\n创建虚拟机：\n Overview ：Firmware 选择 UEFI x86_64:/usr/share/edk2-ovmf/OVMF_CODE.fd CPUs ：选择 Topology，Manually set CPU topology，Sockets 设为 1，Cores 按需要来，我设为 4，Threads 设置为 2。这样一共就分配了 4 核 8 线程的 CPU Memory ：内存我设置为 32G SATA Disk ：Disk Bus 选择 Virtio，可以最小化磁盘性能损耗 NIC ：Device model 也选择 virtio 之后再添加一个 Stroage ，选择 Select custom storage 并选中之前下载的 virtio windows 驱动镜像，然后 Device type 选择 CDROM device 最后在 Boot Options 中选中需要启动的设备  开始安装，在 windows 安装进行到选择硬盘的时候，通过之前加载的 virtio win 驱动的 CDROM，安装 virtio 的磁盘和网络驱动。具体参考可见视频 https://www.bilibili.com/video/BV1dQ4y1o78R 的 29 分 35 秒。安装完毕进入 windows，开启远程桌面并记下 IP，之后通过 RDP 连接虚拟机。\n配置和优化 RemoteFX 配置 RemoteFX  通过 Win+R 运行 gpedit.msc 定位到 计算机配置 -\u0026gt; 管理模板 -\u0026gt; Windows组件 -\u0026gt; 远程桌面服务 -\u0026gt; 远程桌面会话主机 -\u0026gt; 远程会话环境  开启 对 RemoteApp 使用高级 RemoteFX 图形 （可选）开启 配置 RemoteFX 自适应图形的图像质量 ，设置为高 开启 为专门针对 Windows Server 2008 R2 SP1 设计的 RemoteFX 客户端启动 RemoteFX 编码 开启 配置 RemoteFX 数据的压缩 ，并设置为不需使用 RDP 压缩算法  连接压缩会导致编码和解码时产生额外的延迟     定位到 计算机配置 -\u0026gt; 管理模板 -\u0026gt; Windows组件 -\u0026gt; 远程桌面服务 -\u0026gt; 远程桌面会话主机 -\u0026gt; 远程会话环境 -\u0026gt; RemoteFX for Windows Server 2008 R2  开启 配置RemoteFX （可选）开启 使用RemoteFX时优化视觉体验 ，并都设置为最高    解除 30-ish fps 限制  启动注册表编辑器 定位并单击以下注册表子键： HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\WinStations 在 编辑 菜单中选择 新建 ，然后再选择 DWORD（32位）值 输入 DWMFRAMEINTERVAL 并回车 右键 DWMFRAMEINTERVAL ，选择 修改 选择十进制，并输入 15。该设置将最大帧率设置为每秒 60 帧 (FPS)。  显卡直通 先关闭虚拟机。首先我们需要确认 host 和 guest 中的 GPU 硬件 ID 一致的，然而 Legion R7000P 中两者不一致，准确的来说是其中的 Sub ID 部分不一致，所以需要手动修改一下。首先通过命令 lspci -nnk | egrep -A3 \u0026quot;VGA|3D\u0026quot; 查看显卡的 Vendor ID 和 Device ID。\n$ lspci -nnk | egrep -A3 \u0026#34;VGA|3D\u0026#34; 01:00.0 VGA compatible controller [0300]: NVIDIA Corporation TU106M [GeForce RTX 2060 Mobile] [10de:1f15] (rev a1) Subsystem: Lenovo TU106M [GeForce RTX 2060 Mobile] [17aa:3a43] Kernel driver in use: vfio-pci Kernel modules: nouveau -- 06:00.0 VGA compatible controller [0300]: Advanced Micro Devices, Inc. [AMD/ATI] Renoir [1002:1636] (rev c6) Subsystem: Lenovo Renoir [17aa:3a47] Kernel driver in use: amdgpu Kernel modules: amdgpu 其中 NVIDIA 独显的 Vendor ID 为 10de，Device ID 为 1f15。再用命令 grep \u0026quot;PCI_SUBSYS_ID=\u0026quot; /sys/bus/pci/devices/0000:01:00.0/uevent 查看 Sub Vendor ID 和 Sub Device ID。\n$ grep \u0026#34;PCI_SUBSYS_ID=\u0026#34; /sys/bus/pci/devices/0000:01:00.0/uevent PCI_SUBSYS_ID=17AA:3A47 其中 Sub Vendor ID 为 17AA，Sub Device ID 为 3A47。将 17AA 和 3A47 转换为十进制 6058 和 14919，并在虚拟机的 XML 中添加配置：\n\u0026lt;domain xmlns:qemu=\u0026#34;http://libvirt.org/schemas/domain/qemu/1.0\u0026#34; type=\u0026#34;kvm\u0026#34;\u0026gt; ... \u0026lt;qemu:commandline\u0026gt; \u0026lt;qemu:arg value=\u0026#39;-set\u0026#39;/\u0026gt; \u0026lt;qemu:arg value=\u0026#39;device.hostdev0.x-pci-sub-vendor-id=6058\u0026#39;/\u0026gt; \u0026lt;qemu:arg value=\u0026#39;-set\u0026#39;/\u0026gt; \u0026lt;qemu:arg value=\u0026#39;device.hostdev0.x-pci-sub-device-id=14919\u0026#39;/\u0026gt; \u0026lt;/qemu:commandline\u0026gt; \u0026lt;/domain\u0026gt; 注意 XML 的第一行一定要添加 xmlns:qemu=\u0026quot;http://libvirt.org/schemas/domain/qemu/1.0\u0026quot; ，否则后面的配置无法成功添加。\n在 libvirt 中添加硬件，选择 PCI Host Device，然后将 0000:01:00.0 NVIDIA Corporation GeForce RTX 2060 Mobile 和 0000:01:00.1 NVIDIA Corporation High Definition Audio Controller 等都添加进去。\n最后再在 libvirt 中删除虚拟机的 Display Spice 和 Video QXL ，在 CPUs 中取消 Copy host CPU configuration 并将 Model 选择为 host passthrough。如果你需要直通鼠标和键盘，也可以在这个时候添加。\n创建网桥 有线网卡的网桥创建起来较为简单，这里就不详细介绍了，有需要的可以查看我上一篇软路由虚拟机的 BLOG。因为是笔记本，所以这里主要介绍无线网卡的桥接方法。\n先开启 proxy_arp 和 ip_forward，修改配置文件 /etc/sysctl.conf ，添加下述配置：\nnet.ipv4.ip_forward = 1 net.ipv4.conf.all.proxy_arp = 1 再点击 libvirt 菜单栏上的 Edit -\u0026gt; Connection Details ，假设 host 的 ip 为 192.168.3.12，无线网卡为 wlp4s0，新建一个 Network， Name 设置为 proxyArp， Mode 选择 Routed， Forward to 选择 Physical device， Device 设置为 wlp4s0， IPv4 的 Network 设置为 192.168.3.100/28，完成创建。\n然后修改 win10 虚拟机的 NIC 配置，将 Network source 改为 Virtual network \u0026lsquo;proxyArp\u0026rsquo;: Route to wlp4s0，最后重新启动虚拟机与物理机。\n远程连接 重新启动虚拟机后，使用 RDP 连接到虚拟机中。到 nvidia 官网下载驱动，并进行安装。如果安装过程中并未出现问题，则至此显卡直通配置完成。另外如果不外接显示器的话，windows 的分辨率似乎会被限制在 640x480，不知道会不会对游戏有影响，所以有条件还是买一个 HDMI 欺骗器接到独显连接的显示接口上。\n远程连接方式一共有三种，分别可以适用于不同的情况。\nRDP 简单使用方法：\n 确保使用 FreeRDP 2.0 获取 windows 虚拟机 IP，比如 192.168.3.108 xfreerdp /v:192.168.3.108:3389 /w:1600 /h:900 /bpp:32 +clipboard +fonts /gdi:hw /rfx /rfx-mode:video /sound:sys:pulse +menu-anims +window-drag  对于使用 xfreedp 的 RemoteFX 连接的一些问题：\n 只有窗口化的游戏可以运行，全屏将会触发 d3d11 0x087A0001 不能设置分辨率等问题。媒体播放器不受其影响。  作为解决方案，使用无边框模式游戏，或其他等效方案 windows 客户端似乎没有该问题   由于 RDSH/RDVH 连接不支持“相对”鼠标，鼠标会乱跑  重定向 XBOX 手柄或 USB 摇杆可能会解决这个问题？ 使用 Synergy (v1) 并启用相对鼠标模式 通过 RDP RemoteFX 运行 3D 游戏鼠标不稳定    Looking glass Looking glass 的优点是低延迟，其并不是通过网络与虚拟机通信，而是直接使用一块共享内存。缺点是只能本地连接，而且似乎需要外接一个显示设备（或 HDMI 欺骗器）才能让键盘、鼠标正常工作，并且似乎不能使用 spice 套娃远程操作 looking glass。\n安装 client 首先在 host 系统上安装 looking glass client，在 gentoo 上可以通过如下步骤直接安装我打包的 looking glass。\n$ sudo eselect repository enable gig $ sudo emerge --sync gig $ sudo emerge -avt looking-glass 计算内存大小 通过以下公式，根据你期望的最大分辨率来计算内存大小。\nwidth x height x 4 x 2 = total bytes total bytes / 1024 / 1024 = total megabytes + 10 比如，我想要最大使用 4K 分辨率（3840x2160）：\n3840 x 2160 x 4 x 2 = 66355200 bytes 66355200 / 1024 / 1024 = 63.28 MB + 10 = 73.28 最后要注意内存的大小要上向取整到最接近的 2 的幂，在上面的例子中则应为 128。\n配置 libvirt ... \u0026lt;devices\u0026gt; ... \u0026lt;shmem name=\u0026#39;looking-glass\u0026#39;\u0026gt; \u0026lt;model type=\u0026#39;ivshmem-plain\u0026#39;/\u0026gt; \u0026lt;size unit=\u0026#39;M\u0026#39;\u0026gt;128\u0026lt;/size\u0026gt; \u0026lt;/shmem\u0026gt; \u0026lt;/devices\u0026gt; ... 将以上内容添加到虚拟机的 XML 配置中，其中 128 即为上面计算出来的大小。\n如果想要通过 spice 实现键盘和鼠标输入与剪贴板共享，则必须添加 spice 设备。\n  在 libvirt 中，选择 Add Hardware ，然后再选择 Graphics ，使用默认的 spice 配置即可，最后完成添加\n  选择 Video 设备，然后在 Model 栏中输入 none，注意必须要完成这一步，否则可能会造成虚拟机不使用直通的显卡渲染\n  如果有 tablet 设备，则删除\n  如果没有 Mouse 设备，则添加一个\n  如果没有 Keyboard 设备，则添加一个\n 这里使用 Virtio 的键盘可以更好的提高性能，然而 PS/2 的键盘没办法删掉，不知道被哪个设备依赖了，所以就使用 PS/2 的键盘了    还有如果使用 Virtio 的键盘，则需要通过上面加载的 virtio windows 驱动 的 CDROM，以安装驱动\n  创建共享内存文件 新建文件 /etc/tmpfiles.d/10-looking-glass.conf ，其内容为：\n#Type Path Mode UID GID Age Argument f /dev/shm/looking-glass 0660 user kvm - 将其中的 user，改为你自己的用户名。最后使用命令 systemd-tmpfiles --create /etc/tmpfiles.d/10-looking-glass.conf 创建共享内存文件，无需等待下次重启。\n安装 host 首先需要在 windows 中安装 IVSHMEM 驱动，windows 不会自己安装 IVSHMEM 设备，相反它只会为该设备安装一个假驱动。先下载需要安装的驱动程序，https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/upstream-virtio/ ，注意必须下载 0.1.161 或更高的版本，最后将其解压。\n安装 IVSHMEM 驱动需要打开 设备管理器 ，然后在 系统设备 下，找到 PCI标准内存控制器 ，然后选择 更新驱动程序 ，再选择手动更新，选择我们之前下载并解压好的驱动目录，然后安装驱动即可。\nhost 需要在 windows 虚拟机中安装，先下载与 client 版本对应的 host 安装文件：https://looking-glass.io/downloads 。下载完成后解压、安装即可，完成后重启虚拟机，然后通过 log 文件查看其是否正常启动，log 在开始菜单里就有。\n最后再安装一下 spice guest tools， https://www.spice-space.org/download.html#windows-binaries ，以更好的支持鼠标与剪贴板共享。\n配置 client 我使用的配置如下，将配置文件放在 ~/.looking-glass-client.ini 或 /etc/looking-glass-client.ini ：\n[app] renderer=egl shmFile=/dev/shm/looking-glass [win] borderless=yes fullScreen=yes size=1920x1080 [input] grabKeyboard=yes escapeKey=97 [spice] captureOnStart=yes 由于我的笔记本没有 ScrLk 按键，所以将 escape 键设置为了 右 Ctrl 按键。\n至此 looking glass 配置完成，运行命令 looking-glass-client 连接到虚拟机。\n配置 Scream 由于 looking glass 不支持传递音频，所以我们还需要使用 Scream 将 VM 的音频传递给 host。\n首先，编辑 windows 虚拟机的 XML，添加以下部分：\n... \u0026lt;devices\u0026gt; ... \u0026lt;shmem name=\u0026#39;scream-ivshmem\u0026#39;\u0026gt; \u0026lt;model type=\u0026#39;ivshmem-plain\u0026#39;/\u0026gt; \u0026lt;size unit=\u0026#39;M\u0026#39;\u0026gt;2\u0026lt;/size\u0026gt; \u0026lt;/shmem\u0026gt; \u0026lt;/devices\u0026gt; ... 然后再如 looking glass 一样，添加配置文件 /etc/tmpfiles.d/11-scream-ivshmem.conf ，并运行命令 systemd-tmpfiles --create /etc/tmpfiles.d/11-scream-ivshmem.conf 。\nf /dev/shm/scream-ivshmem 0660 user kvm - 如果没有安装 IVSHMEM 驱动，则需要安装一下，跟上面一样。然后下载 scream 的 windows 驱动，地址： https://github.com/duncanthrax/scream/releases ，解压并进行安装。\n再以管理员权限在 CMD 中运行 REG ADD HKLM\\SYSTEM\\CurrentControlSet\\Services\\Scream\\Options /v UseIVSHMEM /t REG_DWORD /d 2 。\n在 Linux 物理机中安装 scream，然后创建配置文件 ~/.config/systemd/user/scream-ivshmem-pulse.service ：\n[Unit] Description=Scream IVSHMEM pulse receiver After=pulseaudio.service Wants=pulseaudio.service [Service] Type=simple ExecStartPre=/usr/bin/truncate -s 0 /dev/shm/scream-ivshmem ExecStartPre=/bin/dd if=/dev/zero of=/dev/shm/scream-ivshmem bs=1M count=2 ExecStart=/usr/bin/scream -m /dev/shm/scream-ivshmem [Install] WantedBy=default.target 最后运行以下命令即可：\n$ sudo systemctl start --user scream-ivshmem-pulse $ sudo systemctl enable --user scream-ivshmem-pulse 这样就配置完成了，在 looing glass 里就可以听到声音了。\nsteam 远程畅玩（流式传输） 因为 RDP 的限制，像 steam 家庭串流或 Geforce Experience 的方式对游戏来说更为推荐。\n如果不想每次串流游戏都输入密码解锁屏幕，则可以通过 RDP 以管理员权限运行 cmd，然后运行以下命令，也可以将其保存为脚本，方便以后使用。注意运行完该命令会立马断开 RDP。\n@powershell -NoProfile -ExecutionPolicy unrestricted -Command \u0026#34;$sessionid=((quser $env:USERNAME | select -Skip 1) -split \u0026#39;\\s+\u0026#39;)[2]; tscon $sessionid /dest:console\u0026#34; 2\u0026gt; UnlockErrors.log benchmark 简单运行了一下 3dmark 的 Time Spy，做虚拟机的图形性能测试。测试了以下几种情况：\n win10 + 物理机直接运行，3dmark 得分 6900 win10 + 虚拟机显卡直通 + 外接显示器，3dmark 得分 6000 win10 + 虚拟机显卡直通 + steam 串流，3dmark 得分 5600 win10 + 虚拟机显卡直通 + looking glass，3dmark 得分 5000，并且在加载的时候，画面延迟近 10 秒  由此可见，想要玩游戏，还是最好外接显示器，或者起码使用 steam 串流吧，个人感觉 looking glass 的性能甚至可能没有 RDP 高，但 RDP 无法运行 3dmark，所以无法比较测试。另外这几种情况中，CPU 得分的差距更大，但一般游戏也不会占用过多 CPU 资源，所以这里并没有记录。\nPS：win10 + 虚拟机显卡直通 + looking glass + HDMI 欺骗器，3dmark 得分也是 5600，looking glass 的性能有待进一步测试。\n参考链接  PCI passthrough via OVMF https://wiki.archlinux.org/title/PCI_passthrough_via_OVMF [GUIDE] Optimus laptop dGPU passthrough https://gist.github.com/Misairu-G/616f7b2756c488148b7309addc940b28 Vendor ID \u0026amp; Device ID https://github.com/marcosscriven/ovmf-with-vbios-patch/issues/2 笔记本 Optimus MUXless 下的 Intel 和 NVIDIA 虚拟机显卡直通 https://lantian.pub/article/modify-computer/laptop-intel-nvidia-optimus-passthrough.lantian/ ledis 的单显卡直通教程 https://github.com/ledisthebest/LEDs-single-gpu-passthrough/blob/main/README-cn.md Looking glass Installation https://looking-glass.io/docs/676/install Bridging Network Connections with Proxy ARP https://wiki.debian.org/BridgeNetworkConnectionsProxyArp setup kvm on a wireless interface on a laptop machine https://unix.stackexchange.com/questions/159191/setup-kvm-on-a-wireless-interface-on-a-laptop-machine 桥接无线网卡 https://blog.lilydjwg.me/2020/5/19/bridged-wireless-network.215330.html  附录：XML 配置 最后附上我的虚拟机的 XML 配置。\n\u0026lt;domain type=\u0026#39;kvm\u0026#39; id=\u0026#39;1\u0026#39; xmlns:qemu=\u0026#39;http://libvirt.org/schemas/domain/qemu/1.0\u0026#39;\u0026gt; \u0026lt;name\u0026gt;win10\u0026lt;/name\u0026gt; \u0026lt;uuid\u0026gt;d5da831a-c1eb-4668-a864-0731557d80a0\u0026lt;/uuid\u0026gt; \u0026lt;metadata\u0026gt; \u0026lt;libosinfo:libosinfo xmlns:libosinfo=\u0026#34;http://libosinfo.org/xmlns/libvirt/domain/1.0\u0026#34;\u0026gt; \u0026lt;libosinfo:os id=\u0026#34;http://microsoft.com/win/10\u0026#34;/\u0026gt; \u0026lt;/libosinfo:libosinfo\u0026gt; \u0026lt;/metadata\u0026gt; \u0026lt;memory unit=\u0026#39;KiB\u0026#39;\u0026gt;33554432\u0026lt;/memory\u0026gt; \u0026lt;currentMemory unit=\u0026#39;KiB\u0026#39;\u0026gt;33554432\u0026lt;/currentMemory\u0026gt; \u0026lt;vcpu placement=\u0026#39;static\u0026#39;\u0026gt;8\u0026lt;/vcpu\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;partition\u0026gt;/machine\u0026lt;/partition\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;os\u0026gt; \u0026lt;type arch=\u0026#39;x86_64\u0026#39; machine=\u0026#39;pc-q35-6.0\u0026#39;\u0026gt;hvm\u0026lt;/type\u0026gt; \u0026lt;loader readonly=\u0026#39;yes\u0026#39; type=\u0026#39;pflash\u0026#39;\u0026gt;/usr/share/edk2-ovmf/OVMF_CODE.fd\u0026lt;/loader\u0026gt; \u0026lt;nvram\u0026gt;/var/lib/libvirt/qemu/nvram/win10_VARS.fd\u0026lt;/nvram\u0026gt; \u0026lt;bootmenu enable=\u0026#39;no\u0026#39;/\u0026gt; \u0026lt;/os\u0026gt; \u0026lt;features\u0026gt; \u0026lt;acpi/\u0026gt; \u0026lt;apic/\u0026gt; \u0026lt;hyperv\u0026gt; \u0026lt;relaxed state=\u0026#39;on\u0026#39;/\u0026gt; \u0026lt;vapic state=\u0026#39;on\u0026#39;/\u0026gt; \u0026lt;spinlocks state=\u0026#39;on\u0026#39; retries=\u0026#39;8191\u0026#39;/\u0026gt; \u0026lt;/hyperv\u0026gt; \u0026lt;vmport state=\u0026#39;off\u0026#39;/\u0026gt; \u0026lt;/features\u0026gt; \u0026lt;cpu mode=\u0026#39;host-passthrough\u0026#39; check=\u0026#39;partial\u0026#39; migratable=\u0026#39;on\u0026#39;\u0026gt; \u0026lt;topology sockets=\u0026#39;1\u0026#39; dies=\u0026#39;1\u0026#39; cores=\u0026#39;4\u0026#39; threads=\u0026#39;2\u0026#39;/\u0026gt; \u0026lt;/cpu\u0026gt; \u0026lt;clock offset=\u0026#39;localtime\u0026#39;\u0026gt; \u0026lt;timer name=\u0026#39;rtc\u0026#39; tickpolicy=\u0026#39;catchup\u0026#39;/\u0026gt; \u0026lt;timer name=\u0026#39;pit\u0026#39; tickpolicy=\u0026#39;delay\u0026#39;/\u0026gt; \u0026lt;timer name=\u0026#39;hpet\u0026#39; present=\u0026#39;no\u0026#39;/\u0026gt; \u0026lt;timer name=\u0026#39;hypervclock\u0026#39; present=\u0026#39;yes\u0026#39;/\u0026gt; \u0026lt;/clock\u0026gt; \u0026lt;on_poweroff\u0026gt;destroy\u0026lt;/on_poweroff\u0026gt; \u0026lt;on_reboot\u0026gt;restart\u0026lt;/on_reboot\u0026gt; \u0026lt;on_crash\u0026gt;destroy\u0026lt;/on_crash\u0026gt; \u0026lt;pm\u0026gt; \u0026lt;suspend-to-mem enabled=\u0026#39;no\u0026#39;/\u0026gt; \u0026lt;suspend-to-disk enabled=\u0026#39;no\u0026#39;/\u0026gt; \u0026lt;/pm\u0026gt; \u0026lt;devices\u0026gt; \u0026lt;emulator\u0026gt;/usr/bin/qemu-system-x86_64\u0026lt;/emulator\u0026gt; \u0026lt;disk type=\u0026#39;file\u0026#39; device=\u0026#39;disk\u0026#39;\u0026gt; \u0026lt;driver name=\u0026#39;qemu\u0026#39; type=\u0026#39;qcow2\u0026#39;/\u0026gt; \u0026lt;source file=\u0026#39;/var/lib/libvirt/images/win10.qcow2\u0026#39; index=\u0026#39;3\u0026#39;/\u0026gt; \u0026lt;backingStore/\u0026gt; \u0026lt;target dev=\u0026#39;vda\u0026#39; bus=\u0026#39;virtio\u0026#39;/\u0026gt; \u0026lt;boot order=\u0026#39;1\u0026#39;/\u0026gt; \u0026lt;alias name=\u0026#39;virtio-disk0\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x04\u0026#39; slot=\u0026#39;0x00\u0026#39; function=\u0026#39;0x0\u0026#39;/\u0026gt; \u0026lt;/disk\u0026gt; \u0026lt;disk type=\u0026#39;file\u0026#39; device=\u0026#39;cdrom\u0026#39;\u0026gt; \u0026lt;driver name=\u0026#39;qemu\u0026#39; type=\u0026#39;raw\u0026#39;/\u0026gt; \u0026lt;source file=\u0026#39;/home/petrus/Downloads/iso/cn_windows_10_enterprise_ltsc_2019_x64_dvd_9c09ff24.iso\u0026#39; index=\u0026#39;2\u0026#39;/\u0026gt; \u0026lt;backingStore/\u0026gt; \u0026lt;target dev=\u0026#39;sdb\u0026#39; bus=\u0026#39;sata\u0026#39;/\u0026gt; \u0026lt;readonly/\u0026gt; \u0026lt;boot order=\u0026#39;2\u0026#39;/\u0026gt; \u0026lt;alias name=\u0026#39;sata0-0-1\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;drive\u0026#39; controller=\u0026#39;0\u0026#39; bus=\u0026#39;0\u0026#39; target=\u0026#39;0\u0026#39; unit=\u0026#39;1\u0026#39;/\u0026gt; \u0026lt;/disk\u0026gt; \u0026lt;disk type=\u0026#39;file\u0026#39; device=\u0026#39;cdrom\u0026#39;\u0026gt; \u0026lt;driver name=\u0026#39;qemu\u0026#39; type=\u0026#39;raw\u0026#39;/\u0026gt; \u0026lt;source file=\u0026#39;/home/petrus/Downloads/iso/virtio-win-0.1.185.iso\u0026#39; index=\u0026#39;1\u0026#39;/\u0026gt; \u0026lt;backingStore/\u0026gt; \u0026lt;target dev=\u0026#39;sdc\u0026#39; bus=\u0026#39;sata\u0026#39;/\u0026gt; \u0026lt;readonly/\u0026gt; \u0026lt;alias name=\u0026#39;sata0-0-2\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;drive\u0026#39; controller=\u0026#39;0\u0026#39; bus=\u0026#39;0\u0026#39; target=\u0026#39;0\u0026#39; unit=\u0026#39;2\u0026#39;/\u0026gt; \u0026lt;/disk\u0026gt; \u0026lt;controller type=\u0026#39;usb\u0026#39; index=\u0026#39;0\u0026#39; model=\u0026#39;qemu-xhci\u0026#39; ports=\u0026#39;15\u0026#39;\u0026gt; \u0026lt;alias name=\u0026#39;usb\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x02\u0026#39; slot=\u0026#39;0x00\u0026#39; function=\u0026#39;0x0\u0026#39;/\u0026gt; \u0026lt;/controller\u0026gt; \u0026lt;controller type=\u0026#39;sata\u0026#39; index=\u0026#39;0\u0026#39;\u0026gt; \u0026lt;alias name=\u0026#39;ide\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x00\u0026#39; slot=\u0026#39;0x1f\u0026#39; function=\u0026#39;0x2\u0026#39;/\u0026gt; \u0026lt;/controller\u0026gt; \u0026lt;controller type=\u0026#39;pci\u0026#39; index=\u0026#39;0\u0026#39; model=\u0026#39;pcie-root\u0026#39;\u0026gt; \u0026lt;alias name=\u0026#39;pcie.0\u0026#39;/\u0026gt; \u0026lt;/controller\u0026gt; \u0026lt;controller type=\u0026#39;pci\u0026#39; index=\u0026#39;1\u0026#39; model=\u0026#39;pcie-root-port\u0026#39;\u0026gt; \u0026lt;model name=\u0026#39;pcie-root-port\u0026#39;/\u0026gt; \u0026lt;target chassis=\u0026#39;1\u0026#39; port=\u0026#39;0x10\u0026#39;/\u0026gt; \u0026lt;alias name=\u0026#39;pci.1\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x00\u0026#39; slot=\u0026#39;0x02\u0026#39; function=\u0026#39;0x0\u0026#39; multifunction=\u0026#39;on\u0026#39;/\u0026gt; \u0026lt;/controller\u0026gt; \u0026lt;controller type=\u0026#39;pci\u0026#39; index=\u0026#39;2\u0026#39; model=\u0026#39;pcie-root-port\u0026#39;\u0026gt; \u0026lt;model name=\u0026#39;pcie-root-port\u0026#39;/\u0026gt; \u0026lt;target chassis=\u0026#39;2\u0026#39; port=\u0026#39;0x11\u0026#39;/\u0026gt; \u0026lt;alias name=\u0026#39;pci.2\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x00\u0026#39; slot=\u0026#39;0x02\u0026#39; function=\u0026#39;0x1\u0026#39;/\u0026gt; \u0026lt;/controller\u0026gt; \u0026lt;controller type=\u0026#39;pci\u0026#39; index=\u0026#39;3\u0026#39; model=\u0026#39;pcie-root-port\u0026#39;\u0026gt; \u0026lt;model name=\u0026#39;pcie-root-port\u0026#39;/\u0026gt; \u0026lt;target chassis=\u0026#39;3\u0026#39; port=\u0026#39;0x12\u0026#39;/\u0026gt; \u0026lt;alias name=\u0026#39;pci.3\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x00\u0026#39; slot=\u0026#39;0x02\u0026#39; function=\u0026#39;0x2\u0026#39;/\u0026gt; \u0026lt;/controller\u0026gt; \u0026lt;controller type=\u0026#39;pci\u0026#39; index=\u0026#39;4\u0026#39; model=\u0026#39;pcie-root-port\u0026#39;\u0026gt; \u0026lt;model name=\u0026#39;pcie-root-port\u0026#39;/\u0026gt; \u0026lt;target chassis=\u0026#39;4\u0026#39; port=\u0026#39;0x13\u0026#39;/\u0026gt; \u0026lt;alias name=\u0026#39;pci.4\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x00\u0026#39; slot=\u0026#39;0x02\u0026#39; function=\u0026#39;0x3\u0026#39;/\u0026gt; \u0026lt;/controller\u0026gt; \u0026lt;controller type=\u0026#39;pci\u0026#39; index=\u0026#39;5\u0026#39; model=\u0026#39;pcie-root-port\u0026#39;\u0026gt; \u0026lt;model name=\u0026#39;pcie-root-port\u0026#39;/\u0026gt; \u0026lt;target chassis=\u0026#39;5\u0026#39; port=\u0026#39;0x14\u0026#39;/\u0026gt; \u0026lt;alias name=\u0026#39;pci.5\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x00\u0026#39; slot=\u0026#39;0x02\u0026#39; function=\u0026#39;0x4\u0026#39;/\u0026gt; \u0026lt;/controller\u0026gt; \u0026lt;controller type=\u0026#39;pci\u0026#39; index=\u0026#39;6\u0026#39; model=\u0026#39;pcie-root-port\u0026#39;\u0026gt; \u0026lt;model name=\u0026#39;pcie-root-port\u0026#39;/\u0026gt; \u0026lt;target chassis=\u0026#39;6\u0026#39; port=\u0026#39;0x15\u0026#39;/\u0026gt; \u0026lt;alias name=\u0026#39;pci.6\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x00\u0026#39; slot=\u0026#39;0x02\u0026#39; function=\u0026#39;0x5\u0026#39;/\u0026gt; \u0026lt;/controller\u0026gt; \u0026lt;controller type=\u0026#39;pci\u0026#39; index=\u0026#39;7\u0026#39; model=\u0026#39;pcie-root-port\u0026#39;\u0026gt; \u0026lt;model name=\u0026#39;pcie-root-port\u0026#39;/\u0026gt; \u0026lt;target chassis=\u0026#39;7\u0026#39; port=\u0026#39;0x8\u0026#39;/\u0026gt; \u0026lt;alias name=\u0026#39;pci.7\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x00\u0026#39; slot=\u0026#39;0x01\u0026#39; function=\u0026#39;0x0\u0026#39; multifunction=\u0026#39;on\u0026#39;/\u0026gt; \u0026lt;/controller\u0026gt; \u0026lt;controller type=\u0026#39;pci\u0026#39; index=\u0026#39;8\u0026#39; model=\u0026#39;pcie-root-port\u0026#39;\u0026gt; \u0026lt;model name=\u0026#39;pcie-root-port\u0026#39;/\u0026gt; \u0026lt;target chassis=\u0026#39;8\u0026#39; port=\u0026#39;0x9\u0026#39;/\u0026gt; \u0026lt;alias name=\u0026#39;pci.8\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x00\u0026#39; slot=\u0026#39;0x01\u0026#39; function=\u0026#39;0x1\u0026#39;/\u0026gt; \u0026lt;/controller\u0026gt; \u0026lt;controller type=\u0026#39;pci\u0026#39; index=\u0026#39;9\u0026#39; model=\u0026#39;pcie-root-port\u0026#39;\u0026gt; \u0026lt;model name=\u0026#39;pcie-root-port\u0026#39;/\u0026gt; \u0026lt;target chassis=\u0026#39;9\u0026#39; port=\u0026#39;0xa\u0026#39;/\u0026gt; \u0026lt;alias name=\u0026#39;pci.9\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x00\u0026#39; slot=\u0026#39;0x01\u0026#39; function=\u0026#39;0x2\u0026#39;/\u0026gt; \u0026lt;/controller\u0026gt; \u0026lt;controller type=\u0026#39;pci\u0026#39; index=\u0026#39;10\u0026#39; model=\u0026#39;pcie-root-port\u0026#39;\u0026gt; \u0026lt;model name=\u0026#39;pcie-root-port\u0026#39;/\u0026gt; \u0026lt;target chassis=\u0026#39;10\u0026#39; port=\u0026#39;0xb\u0026#39;/\u0026gt; \u0026lt;alias name=\u0026#39;pci.10\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x00\u0026#39; slot=\u0026#39;0x01\u0026#39; function=\u0026#39;0x3\u0026#39;/\u0026gt; \u0026lt;/controller\u0026gt; \u0026lt;controller type=\u0026#39;pci\u0026#39; index=\u0026#39;11\u0026#39; model=\u0026#39;pcie-to-pci-bridge\u0026#39;\u0026gt; \u0026lt;model name=\u0026#39;pcie-pci-bridge\u0026#39;/\u0026gt; \u0026lt;alias name=\u0026#39;pci.11\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x0a\u0026#39; slot=\u0026#39;0x00\u0026#39; function=\u0026#39;0x0\u0026#39;/\u0026gt; \u0026lt;/controller\u0026gt; \u0026lt;controller type=\u0026#39;pci\u0026#39; index=\u0026#39;12\u0026#39; model=\u0026#39;pcie-root-port\u0026#39;\u0026gt; \u0026lt;model name=\u0026#39;pcie-root-port\u0026#39;/\u0026gt; \u0026lt;target chassis=\u0026#39;12\u0026#39; port=\u0026#39;0xc\u0026#39;/\u0026gt; \u0026lt;alias name=\u0026#39;pci.12\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x00\u0026#39; slot=\u0026#39;0x01\u0026#39; function=\u0026#39;0x4\u0026#39;/\u0026gt; \u0026lt;/controller\u0026gt; \u0026lt;controller type=\u0026#39;virtio-serial\u0026#39; index=\u0026#39;0\u0026#39;\u0026gt; \u0026lt;alias name=\u0026#39;virtio-serial0\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x03\u0026#39; slot=\u0026#39;0x00\u0026#39; function=\u0026#39;0x0\u0026#39;/\u0026gt; \u0026lt;/controller\u0026gt; \u0026lt;interface type=\u0026#39;network\u0026#39;\u0026gt; \u0026lt;mac address=\u0026#39;52:54:00:9c:b1:61\u0026#39;/\u0026gt; \u0026lt;source network=\u0026#39;proxyArp\u0026#39; portid=\u0026#39;dea4d995-d8d9-408d-ac30-ac45bfd5627e\u0026#39; bridge=\u0026#39;virbr1\u0026#39;/\u0026gt; \u0026lt;target dev=\u0026#39;vnet0\u0026#39;/\u0026gt; \u0026lt;model type=\u0026#39;virtio\u0026#39;/\u0026gt; \u0026lt;alias name=\u0026#39;net0\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x01\u0026#39; slot=\u0026#39;0x00\u0026#39; function=\u0026#39;0x0\u0026#39;/\u0026gt; \u0026lt;/interface\u0026gt; \u0026lt;serial type=\u0026#39;pty\u0026#39;\u0026gt; \u0026lt;source path=\u0026#39;/dev/pts/0\u0026#39;/\u0026gt; \u0026lt;target type=\u0026#39;isa-serial\u0026#39; port=\u0026#39;0\u0026#39;\u0026gt; \u0026lt;model name=\u0026#39;isa-serial\u0026#39;/\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;alias name=\u0026#39;serial0\u0026#39;/\u0026gt; \u0026lt;/serial\u0026gt; \u0026lt;console type=\u0026#39;pty\u0026#39; tty=\u0026#39;/dev/pts/0\u0026#39;\u0026gt; \u0026lt;source path=\u0026#39;/dev/pts/0\u0026#39;/\u0026gt; \u0026lt;target type=\u0026#39;serial\u0026#39; port=\u0026#39;0\u0026#39;/\u0026gt; \u0026lt;alias name=\u0026#39;serial0\u0026#39;/\u0026gt; \u0026lt;/console\u0026gt; \u0026lt;channel type=\u0026#39;spicevmc\u0026#39;\u0026gt; \u0026lt;target type=\u0026#39;virtio\u0026#39; name=\u0026#39;com.redhat.spice.0\u0026#39; state=\u0026#39;connected\u0026#39;/\u0026gt; \u0026lt;alias name=\u0026#39;channel0\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;virtio-serial\u0026#39; controller=\u0026#39;0\u0026#39; bus=\u0026#39;0\u0026#39; port=\u0026#39;1\u0026#39;/\u0026gt; \u0026lt;/channel\u0026gt; \u0026lt;input type=\u0026#39;mouse\u0026#39; bus=\u0026#39;ps2\u0026#39;\u0026gt; \u0026lt;alias name=\u0026#39;input0\u0026#39;/\u0026gt; \u0026lt;/input\u0026gt; \u0026lt;input type=\u0026#39;keyboard\u0026#39; bus=\u0026#39;ps2\u0026#39;\u0026gt; \u0026lt;alias name=\u0026#39;input1\u0026#39;/\u0026gt; \u0026lt;/input\u0026gt; \u0026lt;graphics type=\u0026#39;spice\u0026#39; port=\u0026#39;5900\u0026#39; autoport=\u0026#39;yes\u0026#39; listen=\u0026#39;127.0.0.1\u0026#39;\u0026gt; \u0026lt;listen type=\u0026#39;address\u0026#39; address=\u0026#39;127.0.0.1\u0026#39;/\u0026gt; \u0026lt;image compression=\u0026#39;off\u0026#39;/\u0026gt; \u0026lt;gl enable=\u0026#39;no\u0026#39;/\u0026gt; \u0026lt;/graphics\u0026gt; \u0026lt;sound model=\u0026#39;ich9\u0026#39;\u0026gt; \u0026lt;alias name=\u0026#39;sound0\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x00\u0026#39; slot=\u0026#39;0x1b\u0026#39; function=\u0026#39;0x0\u0026#39;/\u0026gt; \u0026lt;/sound\u0026gt; \u0026lt;audio id=\u0026#39;1\u0026#39; type=\u0026#39;spice\u0026#39;/\u0026gt; \u0026lt;video\u0026gt; \u0026lt;model type=\u0026#39;none\u0026#39;/\u0026gt; \u0026lt;alias name=\u0026#39;video0\u0026#39;/\u0026gt; \u0026lt;/video\u0026gt; \u0026lt;hostdev mode=\u0026#39;subsystem\u0026#39; type=\u0026#39;pci\u0026#39; managed=\u0026#39;yes\u0026#39;\u0026gt; \u0026lt;driver name=\u0026#39;vfio\u0026#39;/\u0026gt; \u0026lt;source\u0026gt; \u0026lt;address domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x01\u0026#39; slot=\u0026#39;0x00\u0026#39; function=\u0026#39;0x0\u0026#39;/\u0026gt; \u0026lt;/source\u0026gt; \u0026lt;alias name=\u0026#39;hostdev0\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x06\u0026#39; slot=\u0026#39;0x00\u0026#39; function=\u0026#39;0x0\u0026#39;/\u0026gt; \u0026lt;/hostdev\u0026gt; \u0026lt;hostdev mode=\u0026#39;subsystem\u0026#39; type=\u0026#39;pci\u0026#39; managed=\u0026#39;yes\u0026#39;\u0026gt; \u0026lt;driver name=\u0026#39;vfio\u0026#39;/\u0026gt; \u0026lt;source\u0026gt; \u0026lt;address domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x01\u0026#39; slot=\u0026#39;0x00\u0026#39; function=\u0026#39;0x1\u0026#39;/\u0026gt; \u0026lt;/source\u0026gt; \u0026lt;alias name=\u0026#39;hostdev1\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x07\u0026#39; slot=\u0026#39;0x00\u0026#39; function=\u0026#39;0x0\u0026#39;/\u0026gt; \u0026lt;/hostdev\u0026gt; \u0026lt;hostdev mode=\u0026#39;subsystem\u0026#39; type=\u0026#39;pci\u0026#39; managed=\u0026#39;yes\u0026#39;\u0026gt; \u0026lt;driver name=\u0026#39;vfio\u0026#39;/\u0026gt; \u0026lt;source\u0026gt; \u0026lt;address domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x01\u0026#39; slot=\u0026#39;0x00\u0026#39; function=\u0026#39;0x2\u0026#39;/\u0026gt; \u0026lt;/source\u0026gt; \u0026lt;alias name=\u0026#39;hostdev2\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x08\u0026#39; slot=\u0026#39;0x00\u0026#39; function=\u0026#39;0x0\u0026#39;/\u0026gt; \u0026lt;/hostdev\u0026gt; \u0026lt;hostdev mode=\u0026#39;subsystem\u0026#39; type=\u0026#39;pci\u0026#39; managed=\u0026#39;yes\u0026#39;\u0026gt; \u0026lt;driver name=\u0026#39;vfio\u0026#39;/\u0026gt; \u0026lt;source\u0026gt; \u0026lt;address domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x01\u0026#39; slot=\u0026#39;0x00\u0026#39; function=\u0026#39;0x3\u0026#39;/\u0026gt; \u0026lt;/source\u0026gt; \u0026lt;alias name=\u0026#39;hostdev3\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x09\u0026#39; slot=\u0026#39;0x00\u0026#39; function=\u0026#39;0x0\u0026#39;/\u0026gt; \u0026lt;/hostdev\u0026gt; \u0026lt;redirdev bus=\u0026#39;usb\u0026#39; type=\u0026#39;spicevmc\u0026#39;\u0026gt; \u0026lt;alias name=\u0026#39;redir0\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;usb\u0026#39; bus=\u0026#39;0\u0026#39; port=\u0026#39;2\u0026#39;/\u0026gt; \u0026lt;/redirdev\u0026gt; \u0026lt;redirdev bus=\u0026#39;usb\u0026#39; type=\u0026#39;spicevmc\u0026#39;\u0026gt; \u0026lt;alias name=\u0026#39;redir1\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;usb\u0026#39; bus=\u0026#39;0\u0026#39; port=\u0026#39;3\u0026#39;/\u0026gt; \u0026lt;/redirdev\u0026gt; \u0026lt;memballoon model=\u0026#39;virtio\u0026#39;\u0026gt; \u0026lt;alias name=\u0026#39;balloon0\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x05\u0026#39; slot=\u0026#39;0x00\u0026#39; function=\u0026#39;0x0\u0026#39;/\u0026gt; \u0026lt;/memballoon\u0026gt; \u0026lt;shmem name=\u0026#39;looking-glass\u0026#39;\u0026gt; \u0026lt;model type=\u0026#39;ivshmem-plain\u0026#39;/\u0026gt; \u0026lt;size unit=\u0026#39;M\u0026#39;\u0026gt;128\u0026lt;/size\u0026gt; \u0026lt;alias name=\u0026#39;shmem0\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x0b\u0026#39; slot=\u0026#39;0x01\u0026#39; function=\u0026#39;0x0\u0026#39;/\u0026gt; \u0026lt;/shmem\u0026gt; \u0026lt;shmem name=\u0026#39;scream-ivshmem\u0026#39;\u0026gt; \u0026lt;model type=\u0026#39;ivshmem-plain\u0026#39;/\u0026gt; \u0026lt;size unit=\u0026#39;M\u0026#39;\u0026gt;2\u0026lt;/size\u0026gt; \u0026lt;alias name=\u0026#39;shmem1\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x0b\u0026#39; slot=\u0026#39;0x02\u0026#39; function=\u0026#39;0x0\u0026#39;/\u0026gt; \u0026lt;/shmem\u0026gt; \u0026lt;/devices\u0026gt; \u0026lt;seclabel type=\u0026#39;dynamic\u0026#39; model=\u0026#39;dac\u0026#39; relabel=\u0026#39;yes\u0026#39;\u0026gt; \u0026lt;label\u0026gt;+77:+77\u0026lt;/label\u0026gt; \u0026lt;imagelabel\u0026gt;+77:+77\u0026lt;/imagelabel\u0026gt; \u0026lt;/seclabel\u0026gt; \u0026lt;qemu:commandline\u0026gt; \u0026lt;qemu:arg value=\u0026#39;-set\u0026#39;/\u0026gt; \u0026lt;qemu:arg value=\u0026#39;device.hostdev0.x-pci-sub-vendor-id=6058\u0026#39;/\u0026gt; \u0026lt;qemu:arg value=\u0026#39;-set\u0026#39;/\u0026gt; \u0026lt;qemu:arg value=\u0026#39;device.hostdev0.x-pci-sub-device-id=14919\u0026#39;/\u0026gt; \u0026lt;/qemu:commandline\u0026gt; \u0026lt;/domain\u0026gt; Apps 中文字体 在应用之前，最好先安装好中文字体和 emojis\n# emerge media-fonts/noto-cjk media-fonts/noto-emoji # eselect fontconfig list # eselect fontconfig enable 70-noto-cjk.conf 要在系统范围内（对所有用户有效）安装字体，请将文件夹移动到 /usr/share/fonts/ 目录。这些文件需要对每个用户而言都是可读的，使用 chmod 来设置合理的权限 (比如，文件至少为 0444 ，而目录至少为 0555)。要为单个用户安装字体，请使用 ~/.local/share/fonts (~/.fonts/ 现在已经过时了)。\n然后更新 fontconfig 的字体缓存：\n$ fc-cache -vf 改善字体渲染效果   安装字体：改成Sarasa效果和Noto差别很小，倒是换成文泉驿倒是真的字体平滑了许多，模糊边缘也少了点点，但还是有，kde的字体渲染做的真不咋样哦，还是ubuntu的gnome字体渲染最舒服。\n  下载更纱黑体(Sarasa Gothic)\nTUNA (CN): https://mirrors.tuna.tsinghua.edu.cn/github-release/be5invis/Sarasa-Gothic\nNJU (CN): https://mirror.nju.edu.cn/github-release/be5invis/Sarasa-Gothic\n  文泉驿正黑/文泉驿微米黑：开源的文泉驿正黑矢量字体是不错的选择，当然现在流行的是微米黑\n    调整系统字体：系统设置 -\u0026gt; 字体\n在系统字体设置那将那些默认的noto sans字体改为更纱黑体即可，前三个最好相应调大一个等级。等距字体可以使用等距更纱黑体，也可以使用你喜欢的等距字体。\n  调整系统缩放：系统设置 -\u0026gt; 显示和监控 -\u0026gt; 显示配置 -\u0026gt; 缩放显示\n默认是100%，可以调整到110～120之间，具体数值根据自己效果设定\n  调整字体DPI：系统设置 -\u0026gt; 字体 -\u0026gt; 勾选“固定字体DPI”并调整DPI的值\n默认是96，同样也可以调整到110~120之间，具体数值根据自己效果设定\n  调整字体展示优先级\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE fontconfig SYSTEM \u0026#34;fonts.dtd\u0026#34;\u0026gt; \u0026lt;fontconfig\u0026gt; \u0026lt;alias\u0026gt; \u0026lt;family\u0026gt;sans-serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sarasa Gothic SC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Sarasa Gothic TC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Sarasa Gothic J\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Sarasa Gothic K\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias\u0026gt; \u0026lt;family\u0026gt;monospace\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Sarasa Mono SC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Sarasa Mono TC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Sarasa Mono J\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Sarasa Mono K\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;/fontconfig\u0026gt; 将上述内容保存为：~/.fonts.conf文件\n  调整完之后注销重新登入\n输入法 作为中文用户，肯定需要款输入法，我推荐使用 fcitx （还有一款叫 ibus）。目前稳定维护的 fcitx 版本是 5 ，但是官方仓库 ::gentoo 目前只有 4 （也能用，就是不怎么维护了）。\n官方仓库 fcitx4 重要：先配置下 fcitx4 开启对 gtk2 的支持以避免有些程序无法使用（gtk3 默认开启了）\n# echo \u0026#39;app-i18n/fcitx gtk2\u0026#39; \u0026gt;\u0026gt; /etc/portage/package.use/fcitx 然后安装\n# emerge app-i18n/fcitx:4 app-i18n/fcitx-configtool:4 app-i18n/fcitx-qt5:4 app-i18n/fcitx-libpinyin:4 其中：\n app-i18n/fcitx 是 fcitx 的主程序 app-i18n/fcitx-configtool 是它的配置工具 app-i18n/fcitx-qt5 用于支持在 qt 程序上使用它 app-i18n/fcitx-libpinyin 是一个输入法  额外仓库 fcitx5 为使用最新的 fcitx5，这里需要使用额外的仓库 ，因为官方仓库目前（2021-11-23）没有。提供 fcitx5 的 Gentoo 仓库（Overlay）推荐 gentoo-zh 。具体方法为：\n  先安装添加额外的仓库必要的工具\n# emerge app-eselect/eselect-repository   然后启用仓库，启用过程中，可能会因为网络原因导致比较慢，请耐心等待\n# eselect repository enable gentoo-zh   更新以获取下仓库内容。\n# emerge dev-vcs/git # emerge --sync gentoo-zh 如果一直卡在这里，那说明当前网络访问 github.com 不流畅。这时候有一种方法是：访问 https://fastgit.org （我不对该网站做任何保证），　修改 /etc/portage/repos.conf/eselect-repo.conf 文件，替换对应链接的域名为上述网站内指定值，并再次同步。\n  添加 portage 配置用于安装\n# mkdir -p /etc/portage/package.mask/ # nano /etc/portage/package.mask/gentoo-zh */*::gentoo-zh # mkdir -p /etc/portage/package.unmask/ # nano /etc/portage/package.unmask/fcitx5 app-i18n/fcitx5-meta::gentoo-zh app-i18n/fcitx5::gentoo-zh app-i18n/fcitx5-configtool::gentoo-zh app-i18n/fcitx5-chinese-addons::gentoo-zh app-i18n/fcitx5-gtk::gentoo-zh app-i18n/fcitx5-qt::gentoo-zh app-i18n/libime::gentoo-zh x11-libs/xcb-imdkit::gentoo-zh # mkdir -p /etc/portage/package.accept_keywords # nano /etc/portage/package.accept_keywords/fcitx5 app-i18n/fcitx5-meta ~amd64 app-i18n/fcitx5 ~amd64 app-i18n/fcitx5-configtool ~amd64 app-i18n/fcitx5-chinese-addons ~amd64 app-i18n/fcitx5-gtk ~amd64 app-i18n/fcitx5-qt ~amd64 app-i18n/libime ~amd64 x11-libs/xcb-imdkit ~amd64   之后安装\n# emerge app-i18n/fcitx5-meta 或者\n# EGIT_OVERRIDE_REPO_FCITX_LIBIME=https://hub.fastgit.org/fcitx/libime.git EGIT_OVERRIDE_REPO_KPU_KENLM=https://hub.fastgit.org/kpu/kenlm.git emerge app-i18n/fcitx5-meta 这里安装了 fcitx 的元包，它会自动依赖安装 fcitx5 主体、 RIME 输入法、配置工具等，这个仓库也会默认安装上 fcitx5-chinese-addons ，里面包含有中文输入法。\n如果安装的时候长时间停止在校验 manifest，尝试用 eclean 清除 distfiles 和 packages。可能原因是混合使用了 gentoo（官方） 和 gentoo-zh（overlay）。\n  最后安装肥猫百万大词库：\nDownload latest version of \u0026ldquo;zhwiki.dict\u0026rdquo; from https://github.com/felixonmars/fcitx5-pinyin-zhwiki/releases\nCopy into ~/.local/share/fcitx5/pinyin/dictionaries/ (create the folder if it does not exist)\n  提示：\n  当使用非官方的 Fcitx5 时，因为没有镜像收录，所以源码需从 Github 下载，这时可能遇到因网络问题导致无法下载的情况（可以从 /var/log/emerge-fetch.log 文件查看源码包下载情况），如果遇到这种情况那么请自行通过各种途径下载好对应的 .tar.gz 格式（或类似）软件包，然后移动到 /var/cache/distfiles/ 目录下。\n  软件包需更名为对应的包名加完整的版本号（执行上述 emerge \u0026lt;包名\u0026gt; 命令后可以看到完整的版本号），比如当显示的包名为 app-i18n/fcitx-gtk-5.0.8:5::gentoo-zh 那么就更名下载的源码包为 fcitx-gtk-5.0.8.tar.gz （ / 符号后以及 : 符号前的内容），以此类推。\n  或者，在 emerge-fetch.log 可以看到下载链接和类似如下的行\nSaving to: ‘/var/cache/distfiles/fcitx5-lm_sc.3gm.arpa-20140820.tar.bz2.__download__’ 通过下载链接下载文件后，改名为删除 .__download__ 剩余部分，如 fcitx5-lm_sc.3gm.arpa-20140820.tar.bz2，然后删除对应的 /var/cache/distfiles/fcitx5-lm_sc.3gm.arpa-20140820.tar.bz2.__download__ 缓存文件，并把重命名的文件移动到 /var/cache/distfiles/。\n  拥抱Fcitx5 起因\n2015年12月，计科杀手 csslayer 创建了fcitx/fcitx5代码库，独自开始了对 Fcitx5 的开发。\n如今五年过去了，Fcitx5 也日渐成熟。（个人感觉算法上相当不错\n今年年初，我从 fcitx-rime 换到 fcitx5-rime ，感觉并不明显 （毕竟对于 Rime 用户来说从4到5最大的变化是界面\n然后，在 Arch Linux CN 众多群友的诱惑下, 我决定尝试一下 Fcitx5 自带的拼音输入法。\n首次使用的体验是相当的棒的，Fcitx5 在默认配置下表现良好，云拼音也有百度，Google，Google CN 三种可选尽管我不怎么用云拼音，整句输入也是相当的棒，还有输入预测功能。\n但这并不是让我抛弃我在 Rime 积攒下的词库投靠老K输入法Fcitx5自带拼音的理由……真正的原因是最近发生的几件事……\n  首先是非常好的反馈体验，开发者老K对待用户非常友好，而且生产力十足\n  然后是 Felix 爬了维基百科制作了肥猫百万大词库，随后大佬 outloudvi 制作了萌娘百科词库，Fcitx5 的日用词库基本满足（AUR 上皆有打包，且在 Arch CN 源有打包\n  肥猫大词库中的一个讨论促使Fcitx5引入了一项新功能——根据前缀生成候选项，效果如图：\n这个功能我觉得对于长词输入是很棒的\n  添加了类似搜狗U模式的拆字模式，效果如图：\n  还有一件事是 Fcitx5 可以使用 fcitx, fcitx5, ibus 的输入法模块（感觉黑科技\n  我从 rime 移植过来一份符号表，这样输入就方便了很多\n  优势\n 上述几条个人认为皆为优势 fcitx5-rime 支持加载动态库形式的 Rime 插件，在设置中填写插件名称即可使用，注意 octagram 插件名称与文件名并不一样（fcitx-rime 无此支持，ibus-rime 有此支持但是似乎配置文件有点问题（喜讯：Arch 官方仓库中的 librime 已经打包了 lua 和 octagram（即语料库）插件 自带一套 LaTeX 简易输入表（虽然只能输入一小部分特殊字符 笔画过滤: 参见 Fcitx5_使用笔画过滤 以词定字 查看选中文字的 Unicode 编码：选中文字，然后使用快捷键 ctrl + alt + shift + u 可以查看选中文字的编码 更好的支持（Fcitx4 已经停止支持  关于设置\n推荐以下设置：\n 预测看个人喜好 启用颜文字 云拼音根据需要来，但是不推荐 Google 后端，原因显然 preedit 也就是单行显示自己选择 安装肥猫百万大词库（墙裂推荐 Lua 插件！！！自带日期和时间，另外推荐几个，内含进制转换、简易计算器和密码生成器  主题美化\n有以下几种选择：\n  kimpanel(KDE)/gnome-shell-extension-kimpanel(Gnome) （同时这也应该是目前 Wayland 下唯一的方案）\n  Material Color 主题，有多种颜色以及单行双行两种模式，Arch 官方源有打包\n  黑色透明主题\n  黑色主题\n  Materia EXP 主题，系统使用暗色主题的用户请谨慎使用\n  Simple Blue 主题\n  Adwaita-dark，推荐 Gnome 用户使用\n  经典的Material 主题，这个主题同时支持4和5 我都没注意这个主题更新了 fcitx5 支持（fcitx5 版本有人在 AUR 上打了包，包名：fcitx5-skin-material\n  base16 material darker 主题\n  自制主题 （顺便写份主题文档吧\n  以上主题在 AUR 皆有打包(似乎目前已有主题在 AUR 上都有打包了\nfcitx5皮肤制作 这次是 fcitx5 是用搜狗皮肤（无法实现动态）！\n下载仓库\n$ git clone https://github.com/fkxxyz/ssfconv.git $ cd ssfconv 下载皮肤\n先从搜狗输入法的皮肤官网下载自己喜欢的皮肤，得到ssf格式的文件，例如 【雨欣】蒲公英的思念.ssf\n转换皮肤\n$ ./ssfconv -t fcitx5 【雨欣】蒲公英的思念.ssf 【雨欣】蒲公英的思念 复制到用户皮肤目录\n$ mkdir -p ~/.local/share/fcitx5/themes/ $ cp -r 【雨欣】蒲公英的思念 ~/.local/share/fcitx5/themes/ 使用该皮肤\n用下面这条命令可以看到该皮肤的名称：\n$ grep Name ~/.local/share/fcitx5/themes/【雨欣】蒲公英的思念/theme.conf 直接修改配置文件 ~/.config/fcitx5/conf/classicui.conf，将 Theme 的值改成这个皮肤的名称即可。\nfcitx(5)+rime的畅快体验   下载词库转换工具：imewlconverter\n  安装 dotnet-runtime\n  寻找词库文件\n 比如从搜狗词库中寻找：搜狗细胞词库词库下载词典_输入法字典 或者从qq词库中寻找：QQ输入法-词库平台    转换词库文件：以“网络工程词库.scel”为例\n$ dotnet ImeWlConverterCmd.dll -ct:pinyin -os:linux -i:scel ./网络工程词库.scel -o:rime ./network.txt  -i:scel对应搜狗的词库文件后缀，如果你要转换qq的词库文件把这里改成qcel -o:rime ./network.txt表示按照rime输入法词库文件格式转换，转换出的文件在当前目录下，且名字为network.txt    转换完成之后将这个文件拷贝到你的用户资料目录下：\n fcitx4: ~/.config/fcitx/rime fcitx5:~/.local/share/fcixt5/rime  文件以luna_pinyin.xxx.dict.yaml的格式命名，如luna_pinyin.network.dict.yaml，之后重启fcitx(5)即可\n  dict.7z 是我的词库文件，拿去解压到你的用户资料目录下即可使用。\n环境配置 无论选择哪个版本、哪个仓库，安装完成后，均执行此配置，这里另开一个终端，以普通用户编辑 ~/.pam_environment 文件（这里为普通用户的家目录下，不存在则创建一个），然后添加以下内容：\nGTK_IM_MODULE DEFAULT=fcitx QT_IM_MODULE DEFAULT=fcitx XMODIFIERS DEFAULT=\\@im=fcitx SDL_IM_MODULE DEFAULT=fcitx 之后，登出 KDE Plasma，后重新登陆，此时只需做最后的配置，以安装的为 fcitx:5 为例，\n 右击托盘区输入法图标，选择 Configure 点击右下角 Add Input Method search 框下输入 Pinyin 选中 Pinyin 后点击右下角的 Add Apply 后退出界面 右击托盘区输入法图标，选择 Restart  Rime 安装 rime 输入法引擎\n# fcitx4 $ sudo emerge app-i18n/fcitx-rime # fcitx5 $ sudo emerge app-i18n/fcitx5-rime 下载 rime-cloverpinyin 最新版本（如clover.schema-build-1.1.4.zip）输入方案（配置方案），解压到用户资料夹：\n fcitx：~/.config/fcitx/rime fcitx5：~/.local/share/fcitx5/rime  在用户资料夹下创建 default.custom.yaml ，内容为\npatch: \u0026#34;menu/page_size\u0026#34;: 8 schema_list: - schema: clover 其中 8 表示打字的时候输入面板的每一页的候选词数目，可以设置成 1~9 任意数字。\n写好该文件之后，点击右下角托盘图标右键菜单，点“重新部署”，然后再点右键，在方案列表里面应该就有“ 🍀️四叶草拼音输入法”的选项了。\n更多访问 Rime 官网。\nKDE System Settings Appearance\n Global Theme: Breeze  Workspace Behavior\n General Behavior  Clicking files or folders: Selects them   Screen Locking  Lock screen automatically: 10 minutes    Startup and Shutdown\n Login Screen  Breeze    Regional Settings\n Date \u0026amp; Time  Set date and time automatically    Connections\n IPv4  Method: Automatic (Only addresses) DNS Servers: 114.114.114.114    Settings\n Proxy  Use manually specified proxy configuration    Display Configuration\n  Night Color\n  Activate Night Color\n  Sunset to sunrise at manual location\nBeijin: 39.90403 116.40753\n    Bluetooth 蓝牙默认是无法使用的\n# systemctl enable bluetooth 首选编辑器 Gentoo Linux 默认安装的编辑器为 nano ，这是一个初始设置下就很适合新手的编辑器，如果你有其它的要求，比如想使用 vim 或者 emacs ，可以先安装\n# emerge -vj app-editors/vim # emerge -vj app-editors/emacs 列出当前存在的编辑器\n# eselect editor list 根据所需要的编辑器对应的序号，设置默认\n# eselect editor set 「序号」 # . /etc/profile mutt # emerge net-mail/fetchmail mail-filter/procmail mail-client/mutt mail-mta/msmtp mpv # emerge media-video/mpv spotify # emerge media-sound/spotify youtube-dl # emerge dev-python/pip ... aria2 # echo \u0026#39;net-misc/aria2 bittorrent\u0026#39; \u0026gt; /etc/portage/package.use/aria2 # emerge net-misc/aria2 Typora # echo \u0026#39;=app-editors/typora-0.11.18::gentoo-zh=\u0026#39; \u0026gt; /etc/portage/package.unmask/typora # echo \u0026#39;=app-editors/typora-0.11.18::gentoo-zh ~amd64\u0026#39; \u0026gt; /etc/portage/package.accept_keywords/typora # cp -av /opt/typora/share/icons/hicolor/* /usr/share/icons/hicolor/ zsh # emerge app-shells/zsh $ chsh Password: Changing the login shell for kurome Enter the new value, or press ENTER for the default Login Shell [/bin/bash]: /bin/zsh Clash clash 需要 root 执行，编写一个 service 就可以了。\ncfw 无法设置 port，总是重置为 0。\nBrowsers 关于浏览器的选择有很多，比如\n www-client/google-chrome （chrome 的官方二进制包） www-client/google-chrome-beta （chrome 的官方二进制包， beta 分支） www-client/chromium （chromium 源码包，需编译，时间很久很久） www-client/firefox-bin （火狐官方二进制包，国际版） www-client/firefox （火狐源码包，需编译，时间很久） www-client/microsoft-edge-beta （Edge 官方二进制包， beta 分支） 等  可以自行选择安装。命令依旧是 emerge \u0026lt;包名\u0026gt; 。安装个别浏览器时，可能会因为许可问题导致无法安装，如何解决看下文的 软件的许可 一节。\n其它的应用自行发掘。这里有推荐应用列表：\n https://wiki.gentoo.org/wiki/Recommended_applications https://wiki.archlinux.org/title/List_of_applications  至此，桌面配置告一段落。\nkio-extras (only for kde)\nMTP (Media Transfer Protocol) is a protocol to allow the transfer of files to external devices. It is provided by several programs, most of them depending on FUSE.\n# echo \u0026#39;kde-apps/kio-extras mtp\u0026#39; \u0026gt; /etc/portage/package.use/kio-extras # emerge --ask kde-apps/kio-extras Gwenview KDE app，看图。\n# emerge kde-apps/gwenview Okular KDE app，PDF 阅读。\n# emerge kde-apps/okular KTimer KDE app，类似于 cronie，只不过是GUI。\n# emerge kde-apps/ktimer KClock KDE app，一个时钟。\n# eselect repository enable guru # emerge --sync guru # echo \u0026#39;*/*::guru\u0026#39; \u0026gt; /etc/portage/package.mask/guru # echo \u0026#39;=kde-apps/kclock-21.12::guru\u0026#39; \u0026gt; /etc/portage/package.unmask/kclock # echo \u0026#39;=kde-apps/kclock-21.12::guru ~amd64\u0026#39; \u0026gt; /etc/portage/package.accept_keywords/kclock # echo \u0026#39;=kde-frameworks/kirigami-addons-0.2::guru\u0026#39; \u0026gt;\u0026gt; /etc/portage/package.unmask/kclock # echo \u0026#39;=kde-frameworks/kirigami-addons-0.2::guru ~amd64\u0026#39; \u0026gt;\u0026gt; /etc/portage/package.accept_keywords/kcloc # emerge kde-apps/kclock RSIBreak 番茄钟\nLibreOffice # emerge app-office/libreoffice-bin Flameshot 很棒的截图软件\n$ sudo emerge media-gfx/flameshot Spectacle KDE app，用的不是很习惯。\n# emerge kde-apps/spectacle KeePassXC # emerge app-admin/keepassxc PPSSPP # echo \u0026#34;games-emulation/ppsspp ~amd64\u0026#34; \u0026gt;\u0026gt; /etc/portage/package.accept_keywords/ppsspp # emerge games-emulation/ppsspp papirus-icon-theme $ sudo emerge -a papirus-icon-theme Vulkan # emerge --ask media-libs/vulkan-loader tree # emerge app-text/tree qemu # echo \u0026#39;QEMU_SOFTMMU_TARGETS=\u0026#34;x86_64\u0026#34;\u0026#39; \u0026gt;\u0026gt; /etc/portage/make.conf # echo \u0026#39;QEMU_USER_TARGETS=\u0026#34;x86_64\u0026#34;\u0026#39; \u0026gt;\u0026gt; /etc/portage/make.conf # emerge app-emulation/qemu net-fs/samba # gpasswd -a kurome kvm Could not access KVM kernel module: Permission denied\nDocker # emerge --ask --verbose app-emulation/docker # systemctl enable docker.service # systemctl start docker.service # usermod -aG docker \u0026lt;username\u0026gt; # docker run --rm hello-world lsusb # emerge --ask sys-apps/usbutils p7zip # emerge app-arch/p7zip Important: The 7-zip archive format does not store standard Unix file permissions such as owner/group or extended file attributes. Those who desire to use 7-zip as a long-term backup or archiving solution should wrap files in a tar archive before compressing with 7z. Use the following command to archive directories of files, preserving Unix file permissions:\n$ tar cf - \u0026lt;directory\u0026gt; | 7za a -si \u0026lt;directory\u0026gt;.tar.7z To extract:\n$ 7za x -so \u0026lt;directory\u0026gt;.tar.7z | tar xf - zip # emerge app-arch/zip Ark File archiver by KDE\n# emerge kde-apps/ark ADB and Fastboot Fastboot is included with ADB inside the dev-util/android-tools package::\n# emerge --ask dev-util/android-tools To run adb without root privileges then the unprivileged user account must be added to the plugdev group:\n# groupmod -a plugdev -U kurome no permissions (missing udev rules? user is in the plugdev group)\nEach Android device has a USB vendor/product ID. An example for HTC Evo is:\nvendor id: 0bb4 product id: 0c8d Plug in your device and execute:\n$ lsusb It should come up something like this:\nBus 002 Device 006: ID 0bb4:0c8d High Tech Computer Corp. 需添加 udev 规则：使用下面的模板，并用你的 [VENDOR ID] 和 [PRODUCT ID] 替换里面的值；确保你是 adbusers 用户组的成员，以访问 adb 设备。 然后把这些规则复制到 /etc/udev/rules.d/51-android.rules：\nSUBSYSTEM==\u0026#34;usb\u0026#34;, ATTR{idVendor}==\u0026#34;[VENDOR ID]\u0026#34;, MODE=\u0026#34;0666\u0026#34;, GROUP=\u0026#34;adbusers\u0026#34; SUBSYSTEM==\u0026#34;usb\u0026#34;,ATTR{idVendor}==\u0026#34;[VENDOR ID]\u0026#34;,ATTR{idProduct}==\u0026#34;[PRODUCT ID]\u0026#34;,SYMLINK+=\u0026#34;android_adb\u0026#34; SUBSYSTEM==\u0026#34;usb\u0026#34;,ATTR{idVendor}==\u0026#34;[VENDOR ID]\u0026#34;,ATTR{idProduct}==\u0026#34;[PRODUCT ID]\u0026#34;,SYMLINK+=\u0026#34;android_fastboot\u0026#34; 再加载刚定义的规则，运行：\n# udevadm control --reload-rules If adb still does not detect the device after plugging your device back in, kill and restart the adb server as root and check devices again:\n# adb kill-server # adb start-server $ adb devices adb: device unauthorized.\n请打开手机同意 USB 调试。\nFile transfer Push a file\n$ adb push mypicture.png /sdcard/on/device Push a folder\n$ adb push myfolder /sdcard/on/device Push all files in a folder\n$ adb push myfolder/ /sdcard/on/device Pull a file\n$ adb pull /sdcard/on/device/mypicture.png Pull a folder\n$ adb pull /sdcard/on/device /home/̩$(whoami)/android-folder/ Flatpak # cat \u0026gt;\u0026gt; /etc/portage/package.accept_keywords/flatpak sys-apps/flatpak ~amd64 acct-user/flatpak ~amd64 acct-group/flatpak ~amd64 dev-util/ostree ~amd64 # emerge sys-apps/flatpak # flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo # flatpak remote-modify flathub --url=https://mirror.sjtu.edu.cn/flathub neofetch $ sudo emerge app-misc/neofetch 使用自定义图像 默认情况下，Neofetch 将显示你的操作系统 logo 以及系统信息。当然，你可以根据需要更改图像。\n要显示图像，Linux 系统应该安装以下依赖项：\n w3m-img（用于显示图像。w3m-img 有时与 w3m 包捆绑在一起）， Imagemagick（用于创建缩略图），  大多数 Linux 发行版的默认仓库中都提供了 w3m-img 和 ImageMagick 包。因此，你可以使用你的发行版的默认包管理器来安装它们。\n现在，运行以下命令以使用自定义图像显示系统信息：\n$ neofetch --w3m /home/sk/Pictures/image.png 或者，\n$ neofetch --w3m --source /home/sk/Pictures/image.png 或者，你可以指向包含以下图像的目录。\n$ neofetch --w3m \u0026lt;path-to-directory\u0026gt; 配置 Neofetch 当我们第一次运行 Neofetch 时，它默认会为每个用户在 $HOME/.config/neofetch/config.conf 中创建一个配置文件。你可以调整此文件来告诉 neofetch 该显示、删除和/或修改哪些详细信息。\n还可以在不同版本中保留此配置文件。这意味着你只需根据自己的喜好自定义一次，并在升级到更新版本后使用相同的设置。你甚至可以将此文件共享给你的朋友和同事，使他拥有与你相同的设置。\nflaggie 安装flaggie来更加方便的管理单个包的USE变量\n$ sudo emerge app-portage/flaggie 用法：比如添加a包的b特性\n# flaggie a +b 去掉c包的d特性\n# flaggie c -d Crossover 注意：安装很麻烦，我转用其他方案了。\n# nano /etc/portage/package.accept_keywords/crossover app-emulation/crossover-bin ~amd64 # nano /etc/portage/package.use/crossover sys-libs/ncurses -gpm # USE=\u0026#34;abi_x86_32 abi_x86_64\u0026#34; emerge app-emulation/crossover-bin 作为环境变量的USE设定特点是，本次安装的所有软件都启用该 USE，区别在 make.conf 中使整个系统都启用该 USE 和在 package.use 中为一个一个的包设置同一个 USE（这种情况每次运行只会提示一个包，特别麻烦）。\nUsing ABI_X86 in Gentoo\nABI_X86 is a USE_EXPAND variable; setting ABI_X86=\u0026quot;32 64\u0026quot; or USE=\u0026quot;abi_x86_32 abi_x86_64\u0026quot; are equivalent.\nBottles $ sudo flatpak install flathub com.usebottles.bottleses deja-dup $ sudo nano /etc/portage/package.accept_keywords/deja-dup app-backup/deja-dup ~amd64 $ sudo nano /etc/portage/package.use/deja-dup gnome-base/gvfs fuse $ sudo app-backup/deja-dup dotfiles General-purpose dotfiles utilities These are programs that help with managing, syncing, and/or installing your dotfiles.\n chezmoi (6282 stars) makes it easy to manage your dotfiles across multiple machines, securely. chezmoi is easy to install, quick to start with, and is very powerful. You can install chezmoi and your dotfiles with a single command, without needing Python installed, or even git. Read how chezmoi compares to other dotfile managers. Dotbot (5173 stars) is a lightweight standalone tool to bootstrap dotfiles, making it easy to have a “one click” installation/upgrade process for your dotfiles. yadm (3239 stars) is a dotfile management tool which supports system-specific alternate files/templating, encryption of private data, custom bootstrap actions, and integration with other git-aware tools like vim-fugitive, tig, git-crypt, etc. rcm (2742 stars) is a set of well-documented shell scripts that help manage your dotfiles. It is easily installable on macOS with the homebrew package manager, but works on all Unix operating systems. Home Manager (2696 stars) by Robert Helgesson is a system built for managing NixOS user environments using the Nix package manager and the Nixpkgs libraries. Homesick (2342 stars) by Josh Nichols. Homesick makes it easy to symlink and clone dotfiles repos. vcsh (1947 stars) by Richard “RichiH” Hartmann. vcsh manages all your dotfiles in Git without the need for symlinks. Any number of Git repositories will co-exist in parallel in your $HOME without interfering with each other. Advanced use cases with different branches for different systems are supported by default. An extensive hook system lets you customize your repositories. vcsh includes batch push, pull, and status commands which operate on all your repositories at once. Homeshick (1827 stars) by Anders Ingemann is like Homesick but written in bash. Great to combine with myrepos. fresh (1079 stars) is a tool to source dotfiles from others into your own. It supports shell configuration (aliases, functions, etc.) as well as config files (e.g. ackrc and gitconfig). Think of it as Bundler for your dotfiles. dotdrop (1069 stars) makes the management of dotfiles between different hosts easy. It allows to store your dotfiles on git and automagically deploy different versions on different setups. shallow-backup (870 stars) lets you easily create lightweight backups of installed packages, applications, fonts and dotfiles, and automatically push them to a remote Git repository. dotfiles (539 stars) Dotfile management made easy. Written in Python (available on PyPI) by Jon Bernard. Ellipsis (336 stars) is a package manager for dotfiles. dotter (325 stars) A dotfile manager and templater written in Rust, with Windows/Linux/Mac support. Dotsync (284 stars) utility for syncing dotfiles between multiple machines from a Git repo or push using rsync. Ghar (268 stars) by Brandon Philip. Ghar is a standalone Python script for managing Git repos symlinked into your home. Homemaker (223 stars) by Alex Yatskov. Homemaker is a standalone tool written in Golang to manage both common and machine-specific dotfile settings. Homemaker can be configured in TOML, YAML or JSON. dotfiler (223 stars) is inspired by homesick and Zach Holman’s dotfiles, made using principle of KISS. Pearl (186 stars) is a brand new revolutionary package manager that allows to automatically activate dotfiles whenever shells or editors start via a smart hook mechanism. Dotfiles are treated as packages that coexist together seamlessly and can be fully controlled and synced across different systems. There is a wide range of packages already available in the Official Pearl Hub. comtrya (155 stars) configuration Management for Localhost / dotfiles. dotgit (148 stars) by Kobus van Schoor. A comprehensive and versatile dotfiles manager which helps to synchronize your dotfiles between multiple computers and devices. kody (130 stars) is a dotfiles runner/manager written with node inspired by Zach Holman’s popular dotfiles. dfm (113 stars) is a utility to manage your dotfiles, lightweight and simple. GNU Stow is a symlink farm manager, useful for automatically (and safely) linking your dotfiles folder into your home directory.  使用 GNU stow 管理你的點文件 我昨天偶然間發現一些我覺得值得分享的經驗，就是那種「爲毛我沒有早點知道這個？」那一類的。 我將在這篇文章中介紹如何使用 GNU Stow 管理你的 GNU/Linux 系統中位於用戶家目錄裏的各種配置文件 （通常又叫「點文件(dotfiles)」比如 .bashrc）。\n這件事的困難之處在於，如果能用版本管理系統(VCS, Version Control System)比如 Git, Mercurial(hg), Bazaar(bzr) 管理點文件的話會非常方便，但是這些點文件大部分都位於家目錄的頂級目錄下， 在這個位置不太適合初始化一個版本管理倉庫。這些年下來我試過很多程序，設計目的在於解決這個問題， 幫你把這些配置文件安置在某個下級目錄中，然後安裝或者鏈接這些文件到它們應該在的位置。 嘗試下來這些程序沒有一個真正能打動我。它們要麼有很多依賴（比如 Ruby 和一大坨庫）， 要麼需要我記住如何用它，考慮到同步配置這種不算經常使用的場合，要記住用法真的挺難。\n最近我在用 GNU Stow 來管理我從源代碼在本地編譯安裝到 /usr/local/中的一些程序。 基本上說，在這種常見用法下，是你把這些本地編譯的包配置安裝到 /usr/local/stow/${PKGNAME}-{PKGVERSION} 這樣的位置，然後在 /usr/local/stow/目錄中執行 # stow ${PKGNAME}-${PKGVERSION} ，然後它就會爲程序所有的文件創建符號鏈接放在 /usr/local 中合適的地方。然後當你想用 Stow 卸載這個程序的時候，就不必再考慮會留下什麼垃圾文件， 或者找不到安裝時用的 Makefile 了。這種安裝方式下也可以非常容易地切換一個程序的不同版本 （比如我想嘗試不同配置選項下的 dwm 或者 st 的時候）。\n前段時間在我掃郵件列表的時候，看到某個帖子中某人在說使用 Stow 管理安裝他的點文件。 當時我沒特別在意這個帖子，但是大概我大腦潛意識把它歸檔保存爲今後閱讀了。 昨天我想起來試試這種用法，試過後我不得不說，這比那些專門設計用來做這任務的點文件管理器要方便太多了， 雖然表面上看起來這種用法沒那麼顯而易見。\n方法很簡單。我建了個 ${HOME}/dotfiles 文件夾，然後在裏面爲我想管理的每個程序配置都 創建一個子文件夾。然後我把這些程序的配置從原本的家目錄移動到這每一個對應的子文件夾中， 並保持它們在家目錄中的文件夾結構。比如，如果某個文件原本應該位於家目錄的頂層文件夾裏， 那它現在應該放在這個程序名子目錄的頂層文件夾。如果某個配置文件通常應該位於默認的 ${XDG_CONFIG_HOME}/${PKGNAME} 位置 ( ${HOME}/.config/${PKGNAME} )， 那麼現在它應該放在 ${HOME}/dotfiles/${PKGNAME}/.config/${PKGNAME} ，如此類推。然後在那個 dotfiles 文件夾裏面，直接運行 $ stow $PKGNAME 命令， Stow 就會爲你自動創建這些配置文件的符號鏈接到合適的位置。接下來就很容易爲這個 dotfiles 目錄初始化版本管理倉庫，從而記錄你對這些配置文件做的修改（並且這也可以極度簡化在不同電腦之間 共享配置，這也是我想要這麼做的主要原因）。\n舉個例子，比如說你想管理 Bash, VIM, Uzbl 這三個程序的配置文件。Bash 會在家目錄的頂層文件夾 放幾個文件； VIM 通常會有在頂層文件夾的 .vimrc 文件和 .vim 目錄；然後 Uzbl 的配置位於 ${XDG_CONFIG_HOME}/uzbl 以及 ${XDG_DATA_HOME}/uzbl 。於是在遷移配置前，你的家目錄的文件夾結構應該看起來像這樣：\nhome/ brandon/ .config/ uzbl/ [...some files] .local/ share/ uzbl/ [...some files] .vim/ [...some files] .bashrc .bash_profile .bash_logout .vimrc 然後遷移配置的方式是，應該建一個 dotfiles 子目錄，然後像這樣移動所有配置文件：\nhome/ /brandon/ .config/ .local/ .share/ dotfiles/ bash/ .bashrc .bash_profile .bash_logout uzbl/ .config/ uzbl/ [...some files] .local/ share/ uzbl/ [...some files] vim/ .vim/ [...some files] .vimrc 然後執行以下命令：\n$ cd ~/dotfiles $ stow bash $ stow uzbl $ stow vim 然後，瞬間，所有你的配置文件（的符號鏈接）就安安穩穩地放入了它們該在的地方，無論原本這些目錄結構 有多麼錯綜複雜，這樣安排之後的 dotfiles 文件夾內的目錄結構立刻整理得有條有理， 並且可以很容易地轉換成版本控制倉庫。非常有用的一點是，如果你有多臺電腦，可能這些電腦並沒有 安裝完全一樣的軟件集，那麼你可以手選一些你需要的軟件配置來安裝。在你的 dotfiles 文件夾中總是 可以找到所有的配置文件，但是如果你不需要某個程序的某份配置，那你就不對它執行 stow 命令，它就不會擾亂你的家目錄。\n嗯，以上就是整個用法介紹。希望能有別人覺得這個用法有用！我知道對我來說這個非常有幫助。\nChezmoi 020-04-14 18:36\n在 Linux 中，点文件是隐藏的文本文件，从 Bash、Git 到 i3 或 VSCode 等更复杂的许多应用程序，都用它存储配置设置。\n这些文件大多数都放在 ~/.config 目录中或用户主目录中。编辑这些文件使你可以自定义也许没有提供设置菜单的应用程序，并且它们可以跨设备甚至是跨其它 Linux 发行版移植。但是，整个 Linux 发烧友社区的讨论焦点是如何管理这些点文件以及如何共享它们。\n我们将展示一个名为 Chezmoi 的工具，该工具与其它工具略有不同。\n点文件管理的历史 如果你在 GitHub 上搜索“dotfiles”，那么你将看到有超过 10 万个存储库在解决一个目标：将人们的点文件存储在可共享且可重复的领地中。但是，除了都在使用 Git 之外，它们存储文件的方式各有不同。\n虽然 Git 解决了代码管理问题，也将其转换为配置文件管理，但它并没有解决如何区分发行版、角色（例如家用计算机与工作计算机）、机密信息管理以及按设备配置的问题。\n因此，许多用户决定制定自己的解决方案，多年来，社区已经做出了许多成果。本文将简要介绍已有的一些解决方案。\n安装问题 如果将点文件存储在 Git 存储库中，你肯定希望可以让更改轻松地自动应用到主目录之中，乍一看，最简单的方法是使用符号链接，例如 ln -s ~/.dotfies/bashrc ~/.bashrc。这可以使你的更改在更新存储库时立即就绪。\n符号链接的问题在于管理符号链接可能很麻烦。Stow 和 RCM 可以帮助你管理这些，但是这些并不是非常舒服的解决方案。下载后，需要对私有文件进行适当的修改和设置访问模式。如果你在一个系统上修改了点文件，然后将存储库下载到另一个系统，则可能会发生冲突并需要进行故障排除。\n解决此问题的另一种方法是编写自己的安装脚本。这是最灵活的选项，但要权衡花费更多时间来构建自定义解决方案是否值得。\n机密信息问题 Git 旨在跟踪更改。如果你在 Git 存储库中存储密码或 API 密钥之类的机密信息，则会比较麻烦，并且需要重写 Git 历史记录以删除该机密信息。如果你的存储库是公开的，那么如果其他人下载了你的存储库，你的机密信息将不再保密。仅这个问题就会阻止许多人与公共世界共享其点文件。\n多设备配置问题 问题不在于如何将配置拉到多个设备，而是当你有多个需要不同配置的设备的问题。大多数人通过使用不同的文件夹或使用不同的复刻fork来处理此问题。这使得难以在不同设备和角色集之间共享配置。\nChezmoi 是如何干的 Chezmoi 是一种考虑了以上问题的用于管理点文件的工具，它不会盲目地从存储库复制或符号链接文件。 Chezmoi 更像是模板引擎，可以根据系统变量、模板、机密信息管理器和 Chezmoi 自己的配置文件来生成你的点文件。\nChezmoi 入门 你可以使用以下命令下载 Chezmoi 的当前版本。\n$ curl -sfL https://git.io/chezmoi | sh 让我们继续使用以下方法创建你的存储库：\n$ chezmoi init 它将在 ~/.local/share/chezmoi/ 中创建你的新存储库。你可以使用以下命令轻松地切换到该目录：\n$ chezmoi cd 让我们添加第一个文件：\nchezmoi add ~/.bashrc 这将你的 .bashrc 文件添加到 chezmoi 存储库。\n注意：如果你的 .bashrc 文件实际上是一个符号链接，则需要添加 -f 标志以跟随它来读取实际文件的内容。\n现在，你可以使用以下命令编辑该文件：\n$ chezmoi edit ~/.bashrc 现在让我们添加一个私有文件，这是一个具有 600 或类似权限的文件。我在 .ssh/config 中有一个文件，我想通过使用如下命令添加它：\n$ chezmoi add ~/.ssh/config Chezmoi 使用特殊的前缀来跟踪隐藏文件和私有文件，以解决 Git 的限制。运行以下命令以查看它：\n$ chezmoi cd 你可以使用以下方法应用任何更改：\n$ chezmoi apply 并使用如下命令检查有什么不同：\n$ chezmoi diff 使用变量和模板 要导出 Chezmoi 可以收集的所有数据，请运行：\n$ chezmoi data 其中大多数是有关用户名、架构、主机名、操作系统类型和操作系统名称的信息。但是你也可以添加我们自己的变量。\n继续，运行：\n$ chezmoi edit-config 然后输入以下内容：\n[data] email = \u0026quot;fedorauser@example.com\u0026quot; name = \u0026quot;Fedora Mcdora\u0026quot; 保存文件，然后再次运行 chezmoi data。你将在底部看到你的电子邮件和姓名已经添加成功。现在，你可以将这些与 Chezmoi 的模板一起使用。运行：\n$ chezmoi add -T --autotemplate ~/.gitconfig 来将你的 .gitconfig 作为模板添加到 Chezmoi 中。如果 Chezmoi 成功地正确推断了模板，你将获得以下信息：\n[user] email = \u0026quot;{{ .email }}\u0026quot; name = \u0026quot;{{ .name }}\u0026quot; 如果没有，则可以将文件更改为这样。\n使用以下方法检查文件：\n$ chezmoi edit ~/.gitconfig 然后使用：\n$ chezmoi cat ~/.gitconfig 来查看 Chezmoi 为此文件生成什么。我生成的示例如下：\n[root@a6e273a8d010 ~]# chezmoi cat ~/.gitconfig [user] email = \u0026quot;fedorauser@example.com\u0026quot; name = \u0026quot;Fedora Mcdora\u0026quot; [root@a6e273a8d010 ~]# 它将在我们的 Chezmoi 配置中生成一个充满变量的文件。你也可以使用变量执行简单的逻辑语句。一个例子是：\n{{- if eq .chezmoi.hostname \u0026quot;fsteel\u0026quot; }} # 如果主机名为 \u0026quot;fsteel\u0026quot; 才包括此部分 {{- end }} 请注意，要使其正常工作，该文件必须是模板。你可以通过查看文件是否在 chezmoi cd 中的文件名后附加 .tmpl 或使用 -T 选项读取文件来进行检查。\n让机密信息保持机密 要对设置进行故障排除，请使用以下命令。\n$ chezmoi doctor 这里重要的是它还向你显示了所支持的密码管理器。\n[root@a6e273a8d010 ~]# chezmoi doctor warning: version dev ok: runtime.GOOS linux, runtime.GOARCH amd64 ok: /root/.local/share/chezmoi (source directory, perm 700) ok: /root (destination directory, perm 550) ok: /root/.config/chezmoi/chezmoi.toml (configuration file) ok: /bin/bash (shell) ok: /usr/bin/vi (editor) warning: vimdiff (merge command, not found) ok: /usr/bin/git (source VCS command, version 2.25.1) ok: /usr/bin/gpg (GnuPG, version 2.2.18) warning: op (1Password CLI, not found) warning: bw (Bitwarden CLI, not found) warning: gopass (gopass CLI, not found) warning: keepassxc-cli (KeePassXC CLI, not found) warning: lpass (LastPass CLI, not found) warning: pass (pass CLI, not found) warning: vault (Vault CLI, not found) [root@a6e273a8d010 ~]# 你可以使用这些客户端，也可以使用通用客户端，也可以使用系统的密钥环。\n对于 GPG，你需要使用以下命令将以下内容添加到配置中：\n$ chezmoi edit-config [gpg] recipient = \u0026quot;\u0026lt;Your GPG keys Recipient\u0026gt;\u0026quot; 你可以使用：\n$ chezmoi add --encrypt 来添加任何文件，这些文件将在你的源存储库中加密，并且不会以纯文本格式公开。Chezmoi 会在应用时自动将其解密。\n我们也可以在模板中使用它们。例如，存储在 Pass 中的机密令牌。继续，生成你的机密信息。\n在此示例中，它称为 githubtoken：\nrwaltr@fsteel:~] $ pass ls Password Store └── githubtoken [rwaltr@fsteel:~] $ 接下来，编辑你的模板，例如我们之前创建的 .gitconfig 并添加以下行。\ntoken = {{ pass \u0026quot;githubtoken\u0026quot; }} 然后让我们使用检查：\n[rwaltr@fsteel:~] $ chezmoi cat ~/.gitconfig This is Git's per-user configuration file. [user] name = Ryan Walter email = rwalt@pm.me token = mysecrettoken [rwaltr@fsteel:~] $ 现在，你的机密信息已在密码管理器中妥善保护，你的配置可以公开共享而没有任何风险！\nTips Petrus.Z Portage command #!/bin/bash euse -E use-flags\t#设置允许use flag（修改/etc/make.conf中的USE） euse -D use-flags\t#设置禁止use flag（修改/etc/make.conf中的USE） euse -i use-flag\t#查询use flag描述 eix RegExp\t#搜索软件包 eix -I\t#列出系统中已安装的软件包 eix --installed-with-use `use`\t#显示哪些已安装的包有`use` flag equery files `PackageName`\t#列出已安装包的文件 equery belongs `FileName`\t#查询已安装的指定文件属于哪个包 equery hasuse `use`\t#查询哪些已安装的包有use flag equery uses `PackageName`\t#显示packege有哪些use ebuild xxx.ebuild digest\t#生成摘要文件 ebuild /var/db/pkg/xxx/xxx.ebuild config\t#初始化配置 equery d package\t#查看依赖package的软件 equery g package\t#查看package的依赖 qdepends package\t# 查询package的依赖 qdepends -rv package\t#输出类似ebuild中或与shell兼容并格式化的依赖 qdepends -Q package\t# 查询哪些包依赖package qlist package\t# 查看package的所有文件列表 qfile file\t# 查看file被哪个package拥有 qcheck package\t# 检查package完整性 qgrep -l package\t# 查找提及package名称的ebuild qgrep -JN package\t# -J限制仅查找已安装的包，-N将打印atom而不是文件名 qlop -um # 查看merge和unmerge log qlop -rt # 查看那当前emerge还有运行了多长时间 qmanifest qtegrity genlop -c #查看当前正在merge的package的编译时间 genlop -t package\t#查看package的编译时间 genlop -u #查看安装与删除的package历史 e-file eread elogv eclean epkginfo apply patches #!/bin/bash  #1.create dir for patches mkdir -p /etc/portage/patches/\u0026lt;package_class\u0026gt;/\u0026lt;package_name\u0026gt;-\u0026lt;package_version\u0026gt; #2.put patches at dir which just created above #3.test patches cd $(portageq get_repo_path / gentoo)/\u0026lt;package_class\u0026gt;/\u0026lt;package_name\u0026gt; ebuild \u0026lt;package_name\u0026gt;-\u0026lt;package_version\u0026gt;.ebuild clean prepare #4.With the message \u0026#34;User patches applied.\u0026#34; all is good and the package needs to be re-emerged as normally. Kernel #!/bin/bash  #1.select the kernel will use eselect kernel list eselect kernel set \u0026lt;No.\u0026gt; #2.configure the kernel with old config (and diff with previous config) zcat /proc/config.gz \u0026gt; /usr/src/linux/.config diff .config ../linux-x.xx.x-gentoo/.config make silentoldconfig/syncconfig/oldconfig #3.compile\u0026amp;install kernel/modules make -j9 make install # compile\u0026amp;install out-of-tree module(s) make modules_prepare emerge --ask @module-rebuild # install initramfs genkernel --install initramfs #4.clean up old kernel files eclean-kernel grub-mkconfig -o /boot/grub/grub.cfg UpgradeGentoo How to upgrade gentoo #!/bin/bash  #1.sync portage tree to lastest emerge-websync emerge --sync #2.upgrade the system emerge -avutDN --with-bdeps=y @world # -a = --ask, -v = --vebose, -u = --update, -t == --tree, -D = --deep, -N = --newuse emerge -a @smart-live-rebuild #3.may be need to update the new config file dispatch-conf # or etc-update #4.clean the unused package emerge -ac # -c = --depclean #5.rebuild dependency library emerge @preserved-rebuild revdep-rebuild emerge -a @module-rebuild #6.clean old distfiles eclean -d distfiles # or eclean-dist -d How to upgrade python local package # 通过脚本维护local-python-world列表 # 安装或删除\u0026lt;package\u0026gt; pip_user install \u0026lt;package\u0026gt; pip_user uninstall \u0026lt;package\u0026gt; # 将所有local python package升级 pip_upgrade Freeing disk space How to Change \u0026amp; Set the Default crontab Editor $ EDITOR=nano crontab -e How to update dolphin file manager in real time The way in order to refresh Dolphin is to press F5. However, this would be manual.\nIn order to continuously refresh, an automatic solution, create a bash script that runs on boot. This bash script should press F5 every five seconds if Dolphin is open. Create a file named dolphin-update in /usr/local/bin with the following contents:\n#!/bin/bash while true; do PID=$(pgrep \u0026quot;dolphin\u0026quot;) if [ \u0026quot;$?\u0026quot; -ne \u0026quot;0\u0026quot; ]; then xdotool key 'F5' fi sleep 5 done You may need to first create it as root and then change the owner to your user:\nsudo chown username:username /usr/local/bin/dolphin-update Ensure that it has executable permissions:\nchmod +x /usr/local/bin/dolphin-update Now we need that to run on boot. To do that run sudo crontab -e and add the following line to the end of the file:\n@reboot /usr/local/bin/dolphin-update This script will run on boot.\nYou should now have a continuously refreshing Dolphin!\nThere are some caveats to this script.\n If you open Dolphin, go to another application where F5 triggers something, (eg Chromium refreshes the page), the script will still run and be a constant annoyance. Solution: Close Dolphin when not actively using it. As a cron job is used, if your computer crashes, the script will not run on boot. However this is a problem with cron not the script.  What the script means, line by line:\n #!/bin/bash - shebang to run with bash while true; do - run continuously PID=$(pgrep \u0026quot;dolphin\u0026quot;) - find the process ID of a dolphin instance. This is purely there to check whether there is even a instance of Dolphin running. if [ \u0026quot;$?\u0026quot; -ne \u0026quot;0\u0026quot; ]; then - check the result of whether there is a Dolphin instance running. If there is, then \u0026hellip; xdotool key 'F5' - press F5 fi - end the if block sleep 5 - wait 5 seconds before repeating the process done - end the while block  How do I convert a .PNG into a .ICO? $ ffmpeg -i img.png img.ico $ ffmpeg -i img.png -vf scale=32:32 img.ico Crop a photo to fit a circle using ffmpeg $ ffmpeg -i avatar.png -i mask.png -filter_complex \u0026#34;[0]scale=400:400[ava];[1]alphaextract[alfa];[ava][alfa]alphamerge\u0026#34; output.png scale=400:400 是 mask.png 的大小。\nmask.png is just a circle, example:\nPath to KDE Picture of the Day $ cd $HOME/.cache/plasma_engine_potd $ file * apod: JPEG image data, JFIF standard 1.01, resolution (DPI), density 96x96, segment length 16, comment: \u0026#34;Description: Adobe ImageReady\u0026#34;, baseline, precision 8, 960x634, components 3 bing: JPEG image data, JFIF standard 1.01, resolution (DPI), density 96x96, segment length 16, baseline, precision 8, 1920x1080, components 3 unsplash:1065976: JPEG image data, JFIF standard 1.01, resolution (DPI), density 72x72, segment length 16, baseline, precision 8, 3840x2160, components 3 Baloo Baloo is the file indexing and file search framework for KDE Plasma, with a focus on providing a very small memory footprint along with with extremely fast searching.\nIndexing limitations\nBaloo uses the file metadata extractors in KFileMetadata to get information about each file it indexes. This means for a file\u0026rsquo;s content to be indexed\n the file must have a recognizable MIME type KDE must have an extractor for that MIME type  Other limitations:\n Baloo doesn\u0026rsquo;t index text files (those whose MIME type is detected as \u0026ldquo;text/something\u0026quot;) over 10 MB (source). The KFileMetadata extractor for text attempts to convert text to Unicode. If the file uses another encoding, such as iso-8859-1, any file contents after the first character that is invalid in Unicode will not be indexed. You may find the -i option to the file command-line utility useful; it tries to infer the character set of a file, e.g. file -i path/to/myfile.txt.  Using Baloo\nBaloo is not an application, but a daemon to index files. Applications can use the Baloo framework to provide file search results. For example, Dolphin\u0026rsquo;s Content search can use Baloo.\nKDE System Settings \u0026gt; File Search provides an intentionally limited number of settings. You can make additional adjustments in Baloo\u0026rsquo;s configuration file.\nbalooctl\nbalooctl is a CLI command to perform certain operations on Baloo. Enter balooctl --help in a terminal app such as userbase:Konsole to list its available subcommands.\nBaloo File Extractor Crashes on every boot I find Baloo fragile and a nuisance. Sometimes it works OK on my amd64 and ~amd64 machines, other times not. If you are not interested in file indexing, you can disable it:\n$ balooctl disable 这个不好用，菊苣（巨巨、大佬）们都推荐关闭。\nKDE Baloo 崩溃问题与调整 Baloo 是 KDE Plasma 的文件索引和文件搜索框架，专注于提供非常小的内存占用以及极快的搜索。KDE 的 Dolphin 和 KRunner 都会调用 Baloo 进行文件搜索。 但是在一些用户的电脑上 Baloo 会崩溃，究其原因，是 Baloo 尝试索引一些奇奇怪怪的文件夹与文件内容所致。解决这个问题也很简单，方法有三。\n 其一是只让 Baloo 索引指定的文件夹，比如 ~/文档 或 ~/音乐 ，索引整个家目录是完全不科学的。在 KDE 的搜索页面即可修改。“未索引”即代表不会索引，“已索引”就是在索引范围内。 其二是只索引文件名称，把“同时索引文件内容”给取消勾选。 其三就是直接关闭 Baloo 的索引功能，把“启用文件搜索”给取消勾选（只是取消索引）。  前两种措施采取一个应该就可以解决崩溃问题。 不推荐用户强行卸载 Baloo 相关包，或者直接砍掉相关服务，因为 Dolphin 的 KDE 的搜索都会依赖 Baloo，直接砍掉的话这些功能会异常。\n更多相关信息参见 KDE 社区维基：Baloo\n内核升级一般步骤 升级内核 建议在make.conf中添加USE='symlink'，然后更新系统。\n$ sudo emerge --ask --verbose --update --deep --newuse @world Configuration $ sudo make menuconfig Build $ sudo make -j4 Install $ sudo make modules_install $ sudo make install BootLoader $ sudo grub-mkconfig -o /boot/grub/grub.cfg 重启以应用新的内核。\nClean $ sudo eclean-kernel -n 1 仅保留当前内核。\nQuestions Problem with transparencies and windowing ghosting out Anyhow, I now applied the \u0026ldquo;force smoothest animations\u0026rdquo; in the KDE compositor settings and it seems to have done the trick!Telegram not launching from the browser xdg-open\nTelegram not launching from the browser xdg-open I am receiving the following message:\nUnable to create io-slave. klauncher said: Unknown protocol 'tg'. Hey! So it’s easy to solve\n Open the folder \\~/.local/share/applications find some files about telegram desktop, like an example, my is userapp-Telegram Desktop-FXJ6T0.desktop Add the line at the end of file MimeType=application/x-xdg-protocol-tg;x-scheme-handler/tg; Reload your browser (maybe do not need…) Enjoy!  我的该目录下有两个与telegram相关的desktop文件，都改了之后就行了。\nHow to reset KDE / display settings after a move to a new machine I had to remove .local/share/kscreen on plasma5\nHow can I reset my display settings through terminal? Removing ~/.config/monitors.xml should do it:\ncfw 在gentoo下用不了，设置端口总为0；\nclash 在gentoo下需要root权限，最好用 systemd service 运行。\n","permalink":"https://sakamotokurome.github.io/posts/gentoousage/","summary":"Portage介绍 欢迎使用 Portage Portage 系统是 Gentoo 在软件管理方面最显著的创新之一。由于 Portage 的高度灵活性和数量庞大的特性，它时常被誉为 Linux 下最好的软件管理工具","title":"Gentoo Usage"},{"content":"Gentoo-zh 群推荐安装教程：\n https://bitbili.net/gentoo-linux-installation-and-usage-tutorial.html https://www.yafa.moe/post/install-gentoo-on-mac/ https://litterhougelangley.life/blog/2021/05/21/gentoo/ https://blog.bugsur.xyz/gentoo-handbook-installation/  群内如果要贴长文本，可以使用网络粘贴板：\n\u0026lt;输出命令\u0026gt; | curl -F \u0026#34;c=@-\u0026#34; \u0026#34;https://fars.ee/\u0026#34; 并且将输出里的 url: http://far.se/xxxx 这行贴出来。使用的时候可以 curl http://far.se/xxxx | less 查看\nQEMU/Linux guest Configuration Host To create a disk image for the virtual machine, run:\n$ qemu-img create -f qcow2 Gentoo-VM.img 30G Download a minimal Gentoo LiveCD from here.\nSince QEMU requires a lot of options, it would be a good idea to put them into a shell script, e.g.:\n$ vim start_Gentoo_VM.sh #!/bin/bash DISKIMG=$HOME/VirtualMachine/Gentoo-VM.img exec qemu-system-x86_64 -enable-kvm \\  -bios /usr/share/edk2-ovmf/OVMF_CODE.fd \\  -cpu host \\  -drive file=${DISKIMG},if=virtio \\  -netdev user,id=vmnic,hostname=Gentoo-VM,hostfwd=tcp::10022-:22 \\  -device virtio-net,netdev=vmnic \\  -device virtio-rng-pci \\  -m 4G \\  -smp 2 \\  -monitor stdio \\  -vga std \\  -audiodev pa,id=snd0 -device ich9-intel-hda -device hda-output,audiodev=snd0 \\  -name \u0026#34;Gentoo VM\u0026#34; \\  $@ $ chmod u+x start_Gentoo_VM.sh Change the path to your disk image Gentoo-VM.img in the script. You can add more options when calling the script. To boot the disk image, run:\n$ ./start_Gentoo_VM.sh -boot d -cdrom $HOME/Downloads/install-amd64-minimal-20211107T170547Z.iso Install the guest per the Gentoo Handbook. See the guest section for optimum support. After the installation start the script without the additional options.\nUsing UEFI with QEMU UEFI for x86 QEMU/KVM VMs is called OVMF (Open Virtual Machine Firmware). It comes from EDK2 (EFI Development Kit), which is the UEFI reference implementation.\n$ sudo emerge sys-firmware/edk2-ovmf 检查是否安装，命令为：\n$ equery f sys-firmware/edk2-ovmf | grep OVMF /usr/share/edk2-ovmf/OVMF_CODE.fd /usr/share/edk2-ovmf/OVMF_CODE.secboot.fd /usr/share/edk2-ovmf/OVMF_VARS.fd 要在虚拟机中运行操作系统的映像文件，添加 -bios /usr/share/ovmf/OVMF.fd。该代码调用名为 OVMF.fd 的文件，该文件是 Qemu 的 UEFI 固件。\nqemu-system-x86_64 -bios /usr/share/edk2-ovmf/OVMF_CODE.fd -cdrom ubuntu-21.04-desktop-amd64.iso 这个名为ovmf的包其实就是名为TianoCore的程序。该名称本身代表开放虚拟机固件)。\nQuestions \u0026ldquo;BdsDxe: failed to load Boot0001\u0026rdquo;\nsolution: Try hitting F2 to enter the OVMF settings during guest boot and manually pick a new boot drive option.\n介绍 欢迎 首先，欢迎使用Gentoo！您将会进入一个选择自由和性能至上的世界。Gentoo的一切都是为了自由选择。在安装Gentoo时就数次明确表明了这一特点——用户可以自己选择想要编译的一切内容、选择安装Gentoo的方式、选择想用的系统日志程序等等。\nGentoo 是一个快速、现代化的元发行版，它的设计简洁、灵活。Gentoo 围绕自由软件建立，它不会对它的用户隐瞒“引擎盖下的细节”。Gentoo 所使用的软件包维护系统 Portage 是用 Python 编写的，这意味着用户可以轻松地查看和修改它的源代码。 Gentoo 的软件包管理系统使用源代码包（虽然也支持预编译软件包），并通过标准的文本文件配置Gentoo。换句话说，开放无处不在。\n“自由选择”是 Gentoo 运行的关键，这点很重要，大家要理解。我们尽量不强迫用户去做任何他们不喜欢的事情。\n安装步骤 Gentoo的安装可以被分成10个步骤，分别对应后续的章节。执行完每个步骤，都会让系统进入某种确定的状态：\n   步骤 结果     1 用户处于一个准备好安装 Gentoo 的工作环境中。   2 用于安装 Gentoo 的互联网连接已经准备完毕。   3 硬盘已经为 Gentoo 的安装初始化完毕。   4 安装环境已经准备好，用户准备 chroot 到新环境中去。   5 那些在所有Gentoo安装中都相同的核心软件包已经安装完毕。   6 Linux内核已经安装完毕。   7 用户已经创建好大部分的 Gentoo 系统配置文件。   8 必要的系统工具已经安装完毕。   9 合适的启动引导程序 (Bootloader) 已经安装配置完毕。   10 登录系统，你就可以在已经全新安装完毕的 Gentoo Linux 系统中尽情探索了！    选择正确的安装媒介 硬件需求 在开始之前，我们先列出在一台 amd64 的主机上成功安装Gentoo所必须的硬件需求。\n    Minimal CD     CPU Any x86-64 CPU, both AMD64 and Intel 64   Memory 2 GB   Disk space 8 GB (excluding swap space)   Swap space At least 2 GB    使用Gentoo Linux安装光盘 最小化安装CD Gentoo最小化安装CD是一张可引导镜像：包含有完整Gentoo环境的。它允许用户从CD或其它安装媒介引导进入Linux。在引导过程中将检测硬件并加载适当的驱动。这个镜像由Gentoo开发人员维护，能让任何有Internet连接的人来安装Gentoo。\n最小化安装CD叫做 install-amd64-minimal-\u0026lt;release\u0026gt;.iso。\nstage又是什么？ stage3压缩包是一个包含有最小化Gentoo环境的文件，可用来按照本手册介绍继续安装Gentoo。以前的Gentoo手册描述了使用三个 stage tarballs 的其中一个来进行安装。现在Gentoo仍然提供stage1和stage2的压缩包，但是官方安装方法只使用stage3压缩包。如果你对使用stage1或stage2压缩包安装Gentoo感兴趣，请阅读 Gentoo 常见问题中的如何使用stage1或stage2 tarball安装Gentoo?\nStage 文件可以在任意一个Gentoo官方镜像站 的 releases/amd64/autobuilds/ 路径下下载，中国可选择Tsinghua University。\n下载 获得安装媒介 Gentoo Linux使用最小化安装CD做为默认安装媒介，它带有一个非常小的可引导的Gentoo Linux环境。此环境包含所有正确的安装工具。 CD镜像本身可以从官方下载页（推荐）或任意一个镜像站下载。\n在这些镜像站上，最小化安装CD可以通过以下方式找到：\n 进入 releases/ 目录 选择相应的架构, 如 amd64/ 选择 autobuilds/ 目录 对于 amd64 和 x86 平台的用户，请选择 current-install-amd64-minimal/ 目录。  在这个位置，安装媒体文件是那些带有.iso扩展名的文件。比如下面的清单：\n[DIR] hardened/ 05-Dec-2014 01:42 - [ ] install-amd64-minimal-20141204.iso 04-Dec-2014 21:04 208M [ ] install-amd64-minimal-20141204.iso.CONTENTS 04-Dec-2014 21:04 3.0K [ ] install-amd64-minimal-20141204.iso.DIGESTS 04-Dec-2014 21:04 740 [TXT] install-amd64-minimal-20141204.iso.DIGESTS.asc 05-Dec-2014 01:42 1.6K [ ] stage3-amd64-20141204.tar.bz2 04-Dec-2014 21:04 198M [ ] stage3-amd64-20141204.tar.bz2.CONTENTS 04-Dec-2014 21:04 4.6M [ ] stage3-amd64-20141204.tar.bz2.DIGESTS 04-Dec-2014 21:04 720 [TXT] stage3-amd64-20141204.tar.bz2.DIGESTS.asc 05-Dec-2014 01:42 1.5K 在上面的例子中， install-amd64-minimal-20141204.iso文件是最小化安装CD。但可以看到,还有其他相关文件存在:\n .CONTENTS 文件是一个文本文件，它列出了安装媒介中的所有文件。这个文件可用于在下载前确认安装媒介是否包含特定的固件和驱动程序。 .DIGESTS 文件包含了ISO文件的Hash值，有不同的Hash格式／算法。这个文件可以用来验证已下载的ISO文件有没有损坏。 .DIGESTS.asc 文件不仅包含了ISO文件的Hash值（和 .DIGESTS 文件一样），还包含了它的加密签名。这个文件即可用于验证已下载的ISO文件是否损坏，也可验证文件确实是由Gentoo发行工程组（Gentoo Release Engineering Team）发布而没有被篡改。  现在可以先忽略当前位置的其他文件——它们在安装的后续步骤中会被提到。下载 .ISO，另外如果想要验证下载的文件，同时下载ISO文件对应的 .DIGESTS.asc。 .CONTENTS 文件不需要下载，因为安装指南后续不会用到这个文件。 .DIGESTS 这个文件和.DIGESTS.asc 文件包含相同的信息，除此以外后者还包含有上面文件的数字签名。\n校验下载的文件 注：这是一个可选步骤，并不是安装 Gentoo Linux 所必须的。但是，我们仍然推荐这么做，以此来确保下载的文件没有损坏，以及确保下载文件确实由 Gentoo Infrastructure Team提供。\n通过 .DIGESTS 和 .DIGESTS.asc 文件，可以使用合适的工具来校验 ISO 文件的有效性。校验通常有两个步骤：　 首先，验证加密签名，确保安装文件是由Gentoo发行工程组（ Gentoo Release Engineering team ） 提供 如果加密签名是有效的，就验证它的文件校验值 （比如 SHA512,WHIRLPOOL），以此来确认下载的文件没有损坏。  在 Linux 系统上,最常用的验证加密签名的方法就是使用 app-crypt/gnupg 这个软件。安装了这个程序,就可以使用以下命令来验证 .DIGESTS.asc 文件中的数字（GPG）签名。\n首先，下载 数字签名页 中正确的密匙：\n$ gpg --keyserver hkps://keys.gentoo.org --recv-keys 0xBB572E0E2D182910 gpg: requesting key 0xBB572E0E2D182910 from hkp server pool.sks-keyservers.net gpg: key 0xBB572E0E2D182910: \u0026#34;Gentoo Linux Release Engineering (Automated Weekly Release Key) \u0026lt;releng@gentoo.org\u0026gt;\u0026#34; 1 new signature gpg: 3 marginal(s) needed, 1 complete(s) needed, classic trust model gpg: depth: 0 valid: 3 signed: 20 trust: 0-, 0q, 0n, 0m, 0f, 3u gpg: depth: 1 valid: 20 signed: 12 trust: 9-, 0q, 0n, 9m, 2f, 0u gpg: next trustdb check due at 2018-09-15 gpg: Total number processed: 1 gpg: new signatures: 1 下一步验证 .DIGESTS.asc 文件的数字（GPG）签名：\n$ gpg --verify install-amd64-minimal-20141204.iso.DIGESTS.asc gpg: Signature made Fri 05 Dec 2014 02:42:44 AM CET gpg: using RSA key 0xBB572E0E2D182910 gpg: Good signature from \u0026#34;Gentoo Linux Release Engineering (Automated Weekly Release Key) \u0026lt;releng@gentoo.org\u0026gt;\u0026#34; [unknown] gpg: WARNING: This key is not certified with a trusted signature! gpg: There is no indication that the signature belongs to the owner. Primary key fingerprint: 13EB BDBE DE7A 1277 5DFD B1BA BB57 2E0E 2D18 2910 确认数字签名有效后，接下来就是验证校验值，以确保下载的ISO文件没有损坏。 .DIGESTS.asc 文件包含了多个哈希算法，所以验证正确校验和的方法之一是先找到登记在文件 .DIGESTS.asc 中的相应的校验值。例如，获取 SHA512 的校验值：\n$ grep -A 1 -i sha512 install-amd64-minimal-20141204.iso.DIGESTS.asc # SHA512 HASH 364d32c4f8420605f8a9fa3a0fc55864d5b0d1af11aa62b7a4d4699a427e5144b2d918225dfb7c5dec8d3f0fe2cddb7cc306da6f0cef4f01abec33eec74f3024 install-amd64-minimal-20141204.iso -- # SHA512 HASH 0719a8954dc7432750de2e3076c8b843a2c79f5e60defe43fcca8c32ab26681dfb9898b102e211174a895ff4c8c41ddd9e9a00ad6434d36c68d74bd02f19b57f install-amd64-minimal-20141204.iso.CONTENTS 在上面的输出中，显示了两个SHA512校验和：一个用于文件：install-amd64-minimal-20141204.iso，一个用于与之对应的 .CONTENTS 文件。只有第一个校验值有用，因为要用它来和下面计算出来的 SHA512 的校验值进行比较：\n$ sha512sum install-amd64-minimal-20141204.iso 364d32c4f8420605f8a9fa3a0fc55864d5b0d1af11aa62b7a4d4699a427e5144b2d918225dfb7c5dec8d3f0fe2cddb7cc306da6f0cef4f01abec33eec74f3024 install-amd64-minimal-20141204.iso 如果两个校验值匹配，那么表明文件没有损坏，安装可以继续进行。损坏的文件会导致安装出现问题，请重新下载。\n刻录光盘 当然,只是下载一个 ISO 文件是无法开始 Gentoo Linux 的安装的。需要将这个ISO文件刻录成一张用来启动的 CD 光盘，是要将 ISO 文件里的内容而不是 ISO 文件本身刻录到CD光盘上。下面介绍了一些常见的方式——这里可以找到其他更复杂的方式：如何刻录ISO文件。\n在 Linux 系统上，可以通过 cdrecord 命令将ISO文件刻录到CD光盘上，这个命令由 app-cdr/cdrtools 软件包提供。\n将ISO文件刻录到 /dev/sr0 设备的 CD 光碟上（这是系统上的第一个 CD 设备-在必要时将其替换为正确的设备）:\n$ cdrecord dev=/dev/sr0 install-amd64-minimal-20141204.iso 喜欢使用图形化界面的用户可以使用 K3B ，它由 kde-app/k3b 软件包提供。在 K3B 软件中，选择“工具”（Tools）菜单，然后选择“刻录CD镜像”（Burn CD Image）。\n启动 启动安装媒介 安装媒介准备就绪后，就可以启动了。 将安装媒介插入系统中，重启，然后进入主板的固件用户界面。 通常是在开机自检（POST）过程中通过在键盘上按DEL, F1, F10, 或 ESC 进入，“触发”键取决于系统和主板。 如果使用主板的型号作为关键字在互联网搜索引擎进行搜索， 结果应该很容易确定。进入主板的固件菜单后，更改引导顺序，以便在内部磁盘设备之前尝试外部可启动媒介（CD / DVD盘或USB驱动器）。 否则，系统很可能会重新启动到内部磁盘设备，从而忽略外部启动媒介。\n重要：如果想安装使用 UEFI 引导的 Gentoo ，建议立即使用UEFI启动。如果不用 UEFI 来启动，可能就要在最后完成 Gentoo Linux 的安装之前制作一个可以启动的 UEFI U盘（或其他介质）。\n如果启动没有成功，请确保将安装媒介插入系统，然后重新启动。这是会显示一个启动提示符。 此时按Enter键将使用默认的启动选项启动。如果要使用自定义引导选项引导安装媒介，请按照启动选项指定一个内核，然后按Enter键。\n附注：在大多数情况下，默认的Gentoo内核可以像之前提到的那样可以在没有任何指定参数的情况下正常工作，有关启动故障排除和专家选项，请继续执行此部分。否则，只需按Enter并跳转至其他硬件配置.\n在启动提示符下，用户可以按 F1 键显示可用的内核，按 F2 按键显示可用的启动选项。如果在15秒内没做任何选择（既不显示信息，也不选择内核）安装媒介将会从硬盘启动。这样不用将 CD 光盘从光盘驱动器里拿出来，也可以在安装过程中重启和尝试已安装好的环境（这有时在远程安装的时候很有用）。\n提到了指定一个内核。 在最小安装介质上，只提供了两个预定义的内核启动选项。 默认选项叫gentoo。 另一个是“-nofb”变量; 这会禁用内核帧缓冲区支持。\n内核选择\n  gentoo\n默认内核，支持K8 CPU（包括NUMA支持）和EM64T CPU。\n  gentoo-nofb\n与“gentoo”相同，但没有framebuffer支持。\n  memtest86\n测试本地RAM的错误。\n  引导选项可以配合内核进一步调整引导过程的行为。\n硬件选择\n  acpi=on\n这个选项载入对 ACPI 的支持，同时也会让 CD 光盘在启动时运行 acpid 守护进程。在系统需要 ACPI 才能正常工作的情况下才需要设置此选项。超线程（Hyperthreading）的支持不需要此选项。\n  acpi=off\n彻底禁用 ACPI。这个选项在一些较老的系统上比较有用，同样也是使用 APM 功能的必需项。这个选项也会禁用处理器的超线程支持。\n  console=X\n这会启用对一些终端的访问许可。它的第一个参数是设备，默认是 ttyS0， 之后的其它选项请使用逗号分割。默认参数是 9600,8,n,1 。\n  dmraid=X\n这会传递参数给 device-mapper RAID 子系统。需要在参数两端加上括号。\n  doapm\n这会加载对 APM 驱动的支持。这同时需要 acpi=off.\n  dopcmcia\n这会加载对 PCMCIA 和 Cardbus 硬件的支持，并且会使 pcmcia cardmgr 在 CD 启动时被启用. 这只有在从 PCMCIA/Cardbus 设备启动时才需要。\n  doscsi\n这会加载对大部分 SCSI 控制器的支持。当从使用 SCSI 内核子系统的 USB 设备启动时需要这个参数。\n  sda=stroke\n这会允许用户对整块硬盘进行分区，即使是 BIOS 无法控制的大容量硬盘。这个选项只有在使用老的 BIOS 的机器上才需要。注意，请把 “sda” 替换为需要这么做的设备。\n  ide=nodma\n这会强制内核禁用 DMA ，一些 IDE 芯片组和一些 CDROM 的驱动需要这么做才能工作。如果系统无法正常读取 IDE 的 CDROM，可以试试这个选项。这同时也会禁止默认的 hdpram 设置被执行。\n  noapic\n这会禁用一些新主板上的高级程序中断控制器（Advanced Programmable Interrupt Controller，APIC），因为这可能会造成一些旧的硬件无法正常工作。\n  nodetect\n这会禁止 CD 的全部自动检测功能，包括对硬件的检测和 DHCP 探测。 这有助于对启动失败的 CD 或驱动器进行查错。\n  nodhcp\n这会禁用在被发现的网卡上进行 DHCP 探测。这在需要使用固定 IP 的时候很有用。\n  nodmraid\n禁用对 device-mapper RAID 的支持，比如板载的IDE/SATA RAID控制器。\n  nofirewire\n这禁用了对 “火线”（ Firewire ） 模块的加载。该选项只在“火线”（Firewire）造成 CD 无法正常启动时才需要。\n  nogpm\n这禁用对 gpm 控制台的鼠标（gpm console mouse）的支持。\n  nohotplug\n这会禁止在启动时加载对热插拔和冷插拔的脚本。这有助于对启动失败的 CD 或驱动器进行查错。\n  nokeymap\n这会禁用选择键盘映射（只有不是 US 键盘时才需要进行对键盘映射的设置）。\n  nolapic\n这会在单处理器内核里禁用本地APIC。\n  nosata\n这会禁止加载 Serial ATA 模块. 这在 SATA 子系统出错时才需要。\n  nosmp\n这会在支持 SMP 的内核上禁用 SMP（Symmetric Multiprocessing）。这在为排查与 SMP 相关的驱动或内核错误时很有用。\n  nosound\n这会禁止对音频的支持和音量控制。这在音频系统造成问题时很有用。\n  nousb\n这会禁止自动加载的 USB 模块。这在 USB 出现问题时很有用。\n  slowusb\n这会为慢速的USB CDROM 在启动时添加更多额外的中断，就像 IBM BladeCenter 那样。\n  逻辑卷／设备管理\n  dolvm\n这会启用 Linux 的逻辑分区管理器（Logical Volume Management）。\n  其他选项\n  debug\n启用调试代码。这可能会显得乱糟糟的，因为这会向输出大量的数据。\n  docache\n这会把整个 CD 运行环境缓存到内存中，这会使用户可以卸载 /mnt/cdrom 并挂载另外一个 CDROM 。这个选项需要至少两倍于 CD 大小的内存空间。\n  doload=X\n这会使启动时内存盘（initial ramdisk，initrd）加载这之后列出来的模块和它们的依赖。把“X”替换为模块名称，当需要加载多个模块时请用逗号分割。\n  dosshd\n在启动时启用 sshd 服务，这在无人值守安装时很有用。\n  passwd=foo\n这会将等号后的字符设置为 root 用户的密码，当使用“dosshd”参数时需要这么做因为默认的 root 密码是留空的。\n  noload=X\n这会使启动时内存盘（initial ramdisk，initrd）跳过对某些会造成问题的特定模块的加载。使用方法和“doload”相同。\n  nonfs\n禁止在启动时启用 portmap/nfsmount 。\n  nox\n这会使启用X的 LiveCD 不自动启动X，而是使用命令行。\n  scandelay\n这会使 CD 在启动过程中等待十秒来使一些初始化很慢的设备完成初始化。\n  scandelay=X\n这允许用户指定 CD 在启动过程中等待一些初始化很慢的设备完成初始化所需的延迟的时间。把X替换为所需要等待的时间（以秒为单位，只需要填写数字）。\n  附注：启动媒介将先检查no*选项，再检查do*选项，所以那些选项可以按照这个顺序覆盖。\n现在启动安装媒介，选择一个内核（如果默认的 gentoo 的内核不能满足）和引导选项。作为示例，我们引导 gentoo 内核启动，并带有dopcmcia作为内核参数：\nboot: gentoo dopcmcia 接下来迎接用户的是一个引导屏幕和进度条。如果用来安装系统的是一个非US键盘，确保马上按Alt + F1来切换到详细模式并遵照提示。如果在10秒钟内什么都没有选，则接受默认（US键盘）并继续引导过程。一旦引导过程完成，用户将自动以root超级用户身份登录到“Live”Gentoo Linux环境。当前控制台将显示一个root提示符，并且可以通过按Alt + F2、Alt + F3和Alt + F4切换到其他控制台。按Alt + F1返回到启动时的那个。\n额外的硬件配置 当安装媒介启动时，它会尝试检测所有的硬件设备并加载合适的内核模块来支持硬件。在绝大多数的情况下，它工作得很好。然而，在某些情况下它可能没有自动加载系统所需的内核模块。如果 PCI 自动检测错过了一些系统硬件，相应的内核模块就必须手动加载了。\n下面例子手工加载了 8139too 模块（它提供对某些类型的网卡的支持）：\n# modprobe 8139too 推荐：用户账号 如果其他人需要访问安装环境，或者需要以非 root 用户的身份在安装媒介上运行命令（例如出于安全原因使用没有 root 特权的 irssi 聊天），这时就需要创建额外的用户帐户，并将 root 用户密码设为强密码。\n使用 passwd 命令来修改 root 用户密码：\n# passwd New password: (Enter the new password) Re-enter password: (Re-enter the password) 要创建一个用户账户，先输入他们的信息，然后设置密码。用 useradd 和 passwd 命令来完成这些操作。\n在下面的例子中，创建了一个名为“john”的用户。\n# useradd -m -G users john # passwd john New password: (Enter john\u0026#39;s password) Re-enter password: (Re-enter john\u0026#39;s password) 使用 su 命令可以从 root 用户（当前用户）切换到新建的用户：\n# su - john 在安装时查看文档 TTYs\n要在安装期间查看 Gentoo 安装手册，首先要按照上面的方法创建一个新的用户帐户。然后按 Alt+F2 进入一个新的终端。\n在安装期间， 可以用 links 命令来浏览 Gentoo 安装手册 - 当然，只有在互联网连接可用的时候才行。\n$ links https://wiki.gentoo.org/wiki/Handbook:AMD64/zh-cn 要回到原来的终端，请按 Alt+F1 。\nGNU Screen\nScreen是官方Gentoo安装介质中默认安装的实用程序。对于经验丰富的Linux爱好者来说，使用 screen 分割窗口查看安装说明，而不是上面提到的多个TTY的方法， 这可能更高效。\n推荐：启动SSH服务 如果你通过的是虚拟机安装，或者同一网络下有其它电脑可以使用，那么使用 ssh 连接上本机，通过复制粘贴命令来操作会更加方便，而 LiveCD 环境下的 sshd 配置为，执行，\n# nano /etc/ssh/sshd_config 打开 sshd 配置文件，确保如下两个选项\nPermitRootLogin yes PasswordAuthentication yes 前面都没有注释符 # ，后面的值都为 yes ，后按下 Ctrl + X ， y ， Enter 保存退出。之后执行，\n# rc-service sshd start 启用 sshd 服务后，为 LiveCD 环境的 root 用户设置一个密码，如果不想设置复杂密码，可以编辑 /etc/security/passwdqc.conf 文件，将 enforce=everyone 改成 enforce=none 保存后再设置\n# passwd root 之后就可以通过其它电脑/主机连接到此 LiveCD 环境了。\n附注：如果用户登录到系统，他们将看到一个本系统主机密钥需要确认的信息（也就是我们说的密匙指纹）。此行为是典型的并且可以像预期一样与SSH服务器进行初始连接。但是，以后当系统设置好，并有人登录到新安装的系统时，SSH客户端会警告主机密钥已被更改。这是因为现在用户登录 - 对于SSH来讲 - 是一个不同的服务器（即新安装的Gentoo系统，而不是现在正在使用的安装系统环境）。请按照屏幕上的指示，去替换用户端的主机密钥\n网络需要能正常工作，sshd 才能使用。请参照 配置网络 的内容继续安装。\n配置网络 自动网络检测 它能够自动检测到么？\n如果系统接入到一个有DHCP服务器的以太网络，网络配置非常可能会自动设置。这样的话，安装CD所包含的很多网络命令，比如ssh、scp、ping、irssi、wget、links，以及其他的一些, 都可以立即工作。\n识别接口名称 ifconfig命令\nifconfig命令 如果网络已配置，ifconfig命令应该会列出一个或多个网络接口（围绕着lo）。在下面的示例中显示为eth0：\n# ifconfig eth0 Link encap:Ethernet HWaddr 00:50:BA:8F:61:7A inet addr:192.168.0.2 Bcast:192.168.0.255 Mask:255.255.255.0 inet6 addr: fe80::50:ba8f:617a/10 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:1498792 errors:0 dropped:0 overruns:0 frame:0 TX packets:1284980 errors:0 dropped:0 overruns:0 carrier:0 collisions:1984 txqueuelen:100 RX bytes:485691215 (463.1 Mb) TX bytes:123951388 (118.2 Mb) Interrupt:11 Base address:0xe800 作为预测的网络接口名称控制的结果, 系统的接口名称可以和旧的eth0命名规则很不一样。近期的安装媒介可能显示常规网络接口名字像是eno0、ens1或enp5s0。查看ifconfig输出中找到有你本地网络相关的IP地址的接口。\nTip：如果使用标准的ifconfig命令没有显示出接口，尝试使用带有-a选项的相同的命令。这个选项强制这个工具去显示系统检测到的所有的网络接口，不管他们是up或down状态。如果ifconfig -a没有提供结果，则硬件有错误或者接口驱动没有加载到内核中。这些情况都超过本手册的范围。联系 #gentoo (webchat) 需求支持。\nip命令\n作为ifconfig的一个备选，ip命令可以用来识别接口名称。下面的示例展示了ip addr（由于是另外一个系统，所以显示的信息不同于前一个示例）的输出:\n# ip addr 2: eno1: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether e8:40:f2:ac:25:7a brd ff:ff:ff:ff:ff:ff inet 10.0.20.77/22 brd 10.0.23.255 scope global eno1 valid_lft forever preferred_lft forever inet6 fe80::ea40:f2ff:feac:257a/64 scope link valid_lft forever preferred_lft forever 上面的输出读起来可能比另外的更乱一点。在上面的示例中，接口名称直接跟在数字后面；它是eno1。\n在本文档的其余部分，手册中假设要操作的网络接口叫作eth0。\n测试网络 尝试ping你的ISP的DNS服务器（可在/etc/resolv.conf中找到）和选择一个网站。这可确信网络正常工作并且网络包可以到达网络，DNS名称解析能正常工作等等。\necho \u0026#39;nameserver 114.114.114.114\u0026#39; \u0026gt;/etc/resolv.conf ping -c 3 www.gentoo.org 如果这些都工作，则本章节中其余的部分可跳过，直接跳到安装介绍的下一步骤（准备磁盘）。\n自动网络配置 如果网络没有立即工作，一些安装媒介允许用户使用net-setup（针对常规或无线网络），pppoe-setup（针对ADSL用户）或 pptp（针对PPTP用户）。\n如果安装媒介没有包含这些工具，继续手动配置网络。\n 常规以太网用户应该继续默认：使用net-setup ADSL用户应该继续备选：使用PPP PPTP用户应该继续备选：使用PPTP  默认：使用net-setup 如果网络没有自动配置，最简单的方式是运行net-setup脚本来设置：\n# net-setup eth0 net-setup将会询问关于网络环境的一些问题。当所有这些完成后，网络连接就应该工作。以前面的方式测试网络连接。如果测试通过，恭喜！跳过本章节剩余部分并继续准备磁盘。\n如果网络还是不能工作，继续手动配置网络。\n可选：使用PPP 假设需要使用PPPoE连接到互联网，安装CD（任何版本）包含ppp来使这件事变得容易。使用提供的pppoe-setup脚本来配置连接。设置过程中将询问已连接到你的ADSL调制解调器的以太网设备、用户名和密码、DNS服务器的IP地址，以及是否需要一个简单的防火墙。\n# pppoe-setup # pppoe-start 如果还是有什么错误，再次在etc/ppp/pap-secrets或/etc/ppp/chap-secrets中检查用户名和密码都是正确的，并且确保使用了正确的以太网设备。如果以太网设备不存在，则需要加载合适的网络模块。如果是那样，继续手动网络配置将解释如何加载合适的网络模块。\n如果所有事都还，继续准备磁盘。\n可选：使用PPTP 如果需要PPTP支持，使用安装CD提供的pptpclient。但是首先确保配置是正确的。编辑/etc/ppp/pap-secrets或/etc/ppp/chap-secrets让它包含正确的用户名/密码组合：\n# nano -w /etc/ppp/chap-secrets 如果需要，继续调整/etc/ppp/options.pptp：\n# nano -w /etc/ppp/options.pptp 当所有事都已完成，运行pptp（带着一些options.pptp无法设定的选项）来连接到服务器：\n# pptp \u0026lt;server ipv4 address\u0026gt; 现在继续准备磁盘。\n手动配置网络 加载适当的网络模块 安装光盘在启动时，会尝试检测所有硬件设备并加载适当的内核模块（驱动程序）以支持你的硬件。绝大多数情况下，它都做得非常好。尽管如此，在某些情况下它可能还是无法自动载入你所需要的内核模块。\n如果net-setup或pppoe-setup都失败，则可能是网络没有立即被找到。也就是说用户可能需要手动加载合适的内核模块。\n要找出什么内核模块提供网络，使用ls命令：\n# ls /lib/modules/`uname -r`/kernel/drivers/net 如果找到一个针对网络设备的驱动，使用modprobe来加载内核模块。比如，要加载pcnet32模块：\n# modprobe pcnet32 要检查网卡现在是否检测到，使用ifconfig。一个检测到的网卡应该在结果中像这样（再一次，这里的eth0只是一个示例）：\n# ifconfig eth0 eth0 Link encap:Ethernet HWaddr FE:FD:00:00:00:00 BROADCAST NOARP MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 b) TX bytes:0 (0.0 b) 不过如果你得到如下错误信息，说明没有检测到网卡：\n# ifconfig eth0 eth0: error fetching interface information: Device not found 系统中可用网络接口命名可以通过/sys文件系统列出。\n# ls /sys/class/net dummy0 eth0 lo sit0 tap0 wlan0 在上面的示例中，找到了6个接口。eth0是最像（有线）以太网络适配器，而wlan0 是无线的。\n假设现在网络已经检测到了，重新尝试net-setup或pppoe-setup（现在应该工作了），但是对于铁杆的人，我们还是要解释如何手动配置网络。\n基于你的网络从下面的章节中选择一个进行设置：\n 使用DHCP 针对自动获取IP 准备无线访问 如果使用无线网络 了解网络术语 解释了关于网络的基础 使用ifconfig和route 解释了如何手动设置网络  使用DHCP DHCP（动态主机配置协议）使自动接受网络信息（IP地址、掩码、广播地址、网关、名称服务器等）变得容易。这只在网络中有DHCP服务器（或者如果ISP提供商提供一个DHCP服务）时有用。要使一个网络接口自动接受信息，使用dhcpcd：\n# dhcpcd eth0 一些网络管理员要求你使用DHCP服务器所提供的主机名和域名。 这种情况下请用：\n# dhcpcd -HD eth0 如果这个工作的话（试着ping一些Internet服务器，像Google的8.8.8.8 或者 Cloudflare的 1.1.1.1 译者注：中国的114.114.114.114），则所有事情都设置好了并可以继续。跳过剩下的章节并继续到准备磁盘。\n准备无线网络链接 附注：可能只有特定的架构支持iw命令。如果这个命令不可用，检查net-wireless/iw包是否可用于当前架构。除非安装net-wireless/iw包，否则iw命令将一直不可用。\n当使用一块无线（802.11）网卡，在继续之前需要先配置无线设置。要查看当前无线网卡的设置，你可以使用iw。运行iw可能会显示如下：\n# iw dev wlp9s0 info Interface wlp9s0 ifindex 3 wdev 0x1 addr 00:00:00:00:00:00 type managed wiphy 0 channel 11 (2462 MHz), width: 20 MHz (no HT), center1: 2462 MHz txpower 30.00 dBm 检查当前连接：\n# iw dev wlp9s0 link Not connected. 或\n# iw dev wlp9s0 link Connected to 00:00:00:00:00:00 (on wlp9s0) SSID: GentooNode freq: 2462 RX: 3279 bytes (25 packets) TX: 1049 bytes (7 packets) signal: -23 dBm tx bitrate: 1.0 MBit/s 附注：一些无线网卡的设备名可能是wlan0或ra0而不是wlp9s0。运行ip link 来识别正确的设备名称。\n对于大多数用户，只需要两个设置来连接，即ESSID（也称无线网络名称）和可选的WEP密钥。\n 首先，确保接口处于活动状态：  # ip link set dev wlp9s0 up  连接到名为“GentooNode”的开放网络：  # iw dev wlp9s0 connect -w GentooNode  设置一个WEP密钥：使用d:前缀：  # iw dev wlp9s0 connect -w GentooNode key 0:d:1234123412341234abcd  用ASCII WEP密钥连接：  # iw dev wlp9s0 connect -w GentooNode key 0:some-password 附注：如果无线网络配置为WPA或WPA2，则需要使用wpa_supplicant。关于为Gentoo Linux配置无线网络的更多信息，请阅读Gentoo手册中的无线网络章节。\n使用iw dev wlp9s0 link确认无线设置。如果无线已经工作，继续按下一章节（了解网络术语）配置IP级别的网络选项或者使用前面描述的net-setup工具。\n网络术语解读 如果以上所做的全部失败，你将不得不手动配置你的网络。这其实一点也不难。不过，你需要熟悉一些网络术语，才能配置好网络令自己满意。读完本节之后，你将了解到什么是网关，子网掩码是作什么用的，广播地址是如何形成的，以及为什么需要名称服务器。\n在网络中，主机通过它们的IP地址（互联网协议地址）来标识。这个地址被看为是由四个0到255的数字来组成。很好，至少在使用IPv4（IP版本4）时。实事上，这样的一个IPv4地址包括32个位（1和0）。让我们来看一个示例：\nIP地址（数字）： 192.168.0.2 IP地址（位）： 11000000 10101000 00000000 00000010 -------- -------- -------- -------- 192 168 0 2 附注：比IPv4更成功的IPv6使用128位（1和0）。在这章节中，我们只关注IPv4地址。\n在所有可访问到的网络里，这样的IP地址跟主机是一一对应的（比如你能够连接到的每台主机必须拥有一个唯一的IP地址）。为了区别一个网络内部和外部的主机，IP地址被分为两个部分：网络部分和主机部分。\n由一堆1后面跟着一堆0的掩码写出了网络的分离。IP映射到1的部分是网络部分，剩下的是主机部分。通常，掩码可以写成IP地址。\nIP地址： 192 168 0 2 11000000 10101000 00000000 00000010 掩码： 11111111 11111111 11111111 00000000 255 255 255 0 +--------------------------+--------+ 网络 主机 换句话说，192.168.0.14是示例网络的一部分，但192.168.1.2不是。\n广播地址是一个拥有相同网络部分，但是主机部分全是1的IP地址。网络上的每一个主机都监听这个IP地址。它的真正用途是用来广播包。\nIP地址： 192 168 0 2 11000000 10101000 00000000 00000010 广播： 11000000 10101000 00000000 11111111 192 168 0 255 +--------------------------+--------+ 网络 主机 了能在互联网上冲浪，网络中的每个主机必须知道哪个主机共享着互联网连接。这个主机叫作网关。它同样是一台常规主机，它有一个常规IP地址（比如192.168.0.1）。\n之前我们说每台主机都有它自己的IP地址。要通过名称来到达这台主机（代替一个IP地址）我们需要一个服务去翻译一个名称（比如dev.gentoo.org）到一个IP地址（64.5.62.82）。这样的服务叫做名称服务。要使用这样的服务，需要在/etc/resolv.conf中定义所需的名称服务器。\n有些情况下，网关同时也是名称服务器。不然的话，需要在这个文件中添加ISP提供的名称服务器。\n总结一下，在继续之前需要下面的信息：\n   网络项目 示例     系统IP地址 192.168.0.2   掩码 255.255.255.0   广播 192.168.0.255   网关 192.168.0.1   名称服务器 195.130.130.5, 195.130.130.133    使用ifconfig和route 设置网络由三步组成：\n 使用ifconfig指派一个IP地址 使用route设置到网关的路由 通过/etc/resolv.conf设置名称服务器的IP完成  要指派一个IP地址，需要IP地址、广播地址和掩码。运行下面的命令，替换${IP_ADDR}为正确的IP地址、${BROADCAST}为正确的广播地址以及${NETMASK}为正确的掩码：\n# ifconfig eth0 ${IP_ADDR} broadcast ${BROADCAST} netmask ${NETMASK} up 用route设置路由。替换${GATEWAY}为正确的网络IP地址：\n# route add default gw ${GATEWAY} 现在打开/etc/resolv.conf：\n# nano -w /etc/resolv.conf 使用下面的模板填入名称服务器。确保替换${NAMESERVER1}和${NAMESERVER2}为合适的名称服务器地址：\nnameserver ${NAMESERVER1} nameserver ${NAMESERVER2} 就是这样。现在通过ping一些互联网服务器（像Google的8.8.8.8 或者 Cloudflare的 1.1.1.1 译者注：中国的114.114.114.114）来测试网络。如果这个工作的话，再次恭喜。继续到准备磁盘。\n准备磁盘 块设备简介 块设备 让我们来好好看看Gentoo Linux以及普通Linux中有关磁盘方面的知识，包括块设备、分区和Linux文件系统。一旦磁盘的来龙去脉都了解了，我们将设置分区和文件系统以进行安装。\n首先，让我们来看看块设备。最著名的块设备可能是代表Linux系统第一块磁盘的/dev/sda。SCSI和SATA磁盘全标为/dev/sd*；甚至IDE磁盘在libata内核框架下也标为/dev/sd*。当使用老设备框架时，第一个IDE磁盘是/dev/hda。\n下表将帮助读者确定系统上找到某种类型的块设备的位置：\n   Type of device Default device handle Editorial notes and considerations     SATA, SAS, SCSI, or USB flash /dev/sda Found on hardware from roughly 2007 until the present, this device handle is perhaps the most commonly used in Linux. These types of devices can be connected via the SATA bus, SCSI, USB bus as block storage. As example, the first partition on the first SATA device is called /dev/sda1.   NVM Express (NVMe) /dev/nvme0n1 The latest in solid state technology, NVMe drives are connected to the PCI Express bus and have the fastest transfer block speeds on the market. Systems from around 2014 and newer may have support for NVMe hardware. The first partition on the first NVMe device is called /dev/nvme0n1p1.   MMC, eMMC, and SD /dev/mmcblk0 embedded MMC devices, SD cards, and other types of memory cards can be useful for data storage. That said, many systems may not permit booting from these types of devices. It is suggested to not use these devices for active Linux installations; rather consider using them to transfer files, which is their design goal. Alternatively they could be useful for short-term backups.    上面的块设备代表磁盘的抽象接口。用户程序可以使用这些块设备来与你的磁盘进行交互，而无需担心驱动器到底是 SATA，SCSI 还是其他什么东西。该程序可以把磁盘当作一系列连续的，可随机访问的 4096 字节块（4K）的存储。\n分区表 虽然理论上可以用一整块磁盘来安装一个Linux系统（比如当创建一个 btrfs RAID时），但是实践中几乎从不这样做。实际上，一块磁盘可以被分成小一些的、更容易管理的块设备。在 amd64 系统里，这被称为分区。有两个标准的分区技术可以被使用：MBR（有时也称为 DOS 磁盘标签）和GPT；这些与两种引导过程类型相关：传统 BIOS 引导和 UEFI 引导。\nGUID 分区表 (GPT)\nGUID 分区表 (GPT)设置（也称为 GPT 磁盘标签）对分区使用 64 位标识符。它用来存储分区信息的空间也远比 MBR 分区表（DOS 磁盘标签）的512字节要大，GPT磁盘它也不对分区的数量作限制。分区的大小限制可以达到 8 ZiB（zebibytes）。\n译者注：\n 1ZiB = 1,024 EiB 1EiB = 1024 PiB 1PiB = 1024 TiB 1TiB = 1024 GiB 1GiB = 1024 MiB 1MiB = 1024 KiB 1KiB = 1024 B  当操作系统和系统固件之间的软件接口是UEFI (相对于BIOS)时，GPT几乎是必选的，因为这里 DOS 磁盘标签会引起很多兼容性问题。\nGPT还利用校验和和冗余。 它携带CRC32校验和以检测报头和分区表中的错误，并在磁盘的末尾有一个备份GPT。 此备份表可用于恢复磁盘开头附近主GPT的损坏。\nImportant：关于 GPT 有一些注意事项：\n 在基于 BIOS 的计算机上使用 GPT 是可行的，但不能与 Microsoft Windows 操作系统进行双重引导。原因是如果 Microsoft Windows 检测到 GPT 分区标签，它将以 UEFI 模式启动。 一些配置为以 BIOS/CSM/legacy 模式启动的有问题的（旧）主板固件在从 GPT 标记的磁盘启动时也可能存在问题。  主引导记录 (MBR) 或 DOS 引导扇区\n主引导记录引导扇区（也称为 DOS 引导扇区或 DOS 磁盘标签）于 1983 年首次在 PC DOS 2.x 中引入。 MBR 使用 32 位标识符作为分区的起始扇区和长度，并支持三种分区类型：主分区、扩展分区和逻辑分区。主分区的信息存储在主引导记录本身——磁盘最开始的一个非常小的（通常是 512 字节）位置。由于空间很小，因此仅支持四个主分区（例如，/dev/sda1 到 /dev/sda4）。\n为了支持更多的分区，可以将 MBR 中的主分区之一标记为扩展分区。然后，该分区可以包含其它逻辑分区（分区内的分区）。\n重要：虽然大多数主板制造商仍然支持，但 MBR 引导扇区及其相关的分区限制被认为是传统的分区方式。除非使用 2010 之前的硬件，否则最好使用 GUID 分区表 对磁盘进行分区。必须继续进行设置类型的读者应了解以下信息：\n 大多数 2010 年后的主板都有接受用 MBR 引导扇区作为传统（受支持但不理想的）引导模式。 由于使用 32 位标识符，MBR 中的分区表无法处理大于 2 TiB 的存储空间。 除非创建扩展分区，否则 MBR 最多支持四个分区。 此设置不提供备份引导扇区，因此如果某些内容覆盖分区表，所有分区信息将丢失。  也就是说，在 AWS 等虚拟化云环境中仍经常使用 MBR 和 BIOS 启动。\n手册作者建议读者安装Gentoo时尽可能使用 [GPT](#使用 GPT for UEFI 对磁盘进行分区) 。\n高级存储 amd64 安装 CD 提供了对逻辑卷管理器 (LVM) 的支持。 LVM 通过增加分区设置提供的灵活性。它允许将分区和磁盘组合到卷组中，并在快速的固态硬盘上为慢速的机械硬盘定义 RAID 组或缓存。下面的安装说明将侧重于\u0026quot;常规\u0026quot;分区，如果强烈需要 LVM，请访问 LVM 文章了解更多详情。新手请注意：LVM虽然完全支持 ，但不在本指南的范围内。\n默认分区方案 在本手册的其余部分，我们将讨论和解释两种情况：1) GPT 分区表和 UEFI 引导，以及 2) MBR 分区表和传统 BIOS 引导。虽然可以混合搭配，但这超出了本手册的范围。如上所述，现代设备应该使用 GPT 分区表和 UEFI 引导；作为此规则的一个例外，MBR 和 BIOS 引导依然经常用于虚拟化（云）环境。\n以下分区方案将用作一个简单的示例布局：\n   Partition Filesystem Size Description     /dev/sda1 fat32 (UEFI) or ext4 (BIOS) 256M Boot/EFI system partition   /dev/sda2 (swap) RAM size * 2 Swap partition   /dev/sda3 ext4 Rest of the disk Root partition    如果这些信息已经足够，高级读者可以直接跳转到实际分区操作。\nfdisk 和 parted 都是分区实用程序。 fdisk 是众所周知的，稳定的，推荐用于 MBR 分区布局分区工具。 parted 是最早支持 GPT 分区的 Linux 块设备管理的分区工具之一，并提供了替代方案。此处使用 fdisk 是因为它具有更好的基于文本的用户界面。\n在进行创建分区的指导之前，关于分区方案和常见陷阱我们会先介绍更多的细节。\n设计一个分区方案 多少个分区以及多大？ 分区数量高度依赖于环境。比如，如果有很多个用户，则建议有一个独立的 /home/，以增强安全性及便于备份。如果安装 Gentoo 来做邮件服务器，则 /var/ 应该独立，因为所有的邮件都储存于 /var/。选择一个正确的文件系统将会获得最大化的性能。游戏服务器应该有一个独立的 /opt/，因为大多数游戏服务器都安装在那里。原因也和 /home/ 目录一样：安全和备份。在大多数场景下，应该保持 /usr/ 大一些：不仅是因为它包含多数的应用程序，还因为它通常还托管着 Gentoo ebuild 存储库（默认情况下位于 /var/db/repos/gentoo ），占用大约 650 MiB 的空间。这个磁盘空间的估计值默认不包括 /var/cache/ 下的 binpkgs/ 和 distfiles/ 目录。\n在Gentoo的大多数情况下，/usr和/var应该保持相对较大的容量。/usr 包含系统上的大多数应用程序和Linux内核源（/usr/src 下）。默认情况下，/var 包含 gentoo ebuild存储库（位于/var/db/repos/gentoo），通常会消耗大约650 MiB（这取决于文件系统）的磁盘空间。此空间估计不包括/var/cache/distfiles（source files）和/var/cache/binpkgs（binary packages）目录。\n分区的数量和大小取决于权衡利弊后根据实际情况选择最佳选项。单独的分区或卷具有以下优点：\n 为每个分区或者卷选择性能最好的文件系统。 当一个失控的工具持续向一个分区或卷写文件时，也不至于让整个系统由于无可用空间而无法运行。 如果有必要，可以简化文件系统检查，多个检查可以并行的完成（尽管使用多个磁盘比使用多个分区更多地实现了这一优势）。 可以通过在挂载一些分区或卷时使用只读、nosuid（忽略setuid属性）、noexec（忽略可执行属性）等来增加安全性。  但是，多个分区也有一些缺点：\n 如果配置不正确，系统可能在一个分区上有很多可用空间，而在另一个分区上可用空间很少。 /usr/ 的单独分区可能需要管理员使用 initramfs 引导，以便在其他引导脚本启动之前挂载该分区。由于 initramfs 的生成和维护超出了本手册的范围，我们建议新手不要为 /usr/ 使用单独的分区。 SCSI 和 SATA 也有 15 个分区的限制，除非磁盘使用 GPT 标签。  附注：如果你打算使用 Systemd，/usr/ 必须在启动时可用，作为根文件系统的一部分或通过 initramfs 挂载。\n那么swap空间呢？ 对于swap空间，没有一个完美值。swap空间的目的是当内存（RAM）有压力时为内核提供磁盘存储。一个swap空间允许内核将看过来稍后不会被访问的内存页面移动到磁盘（swap或者page-out）、施放内存。当然，如果那块内存突然要使用到，需要花一些时间（相比较内存，硬盘是非常慢的）将这些页面需要放回到内存中（page-in）。\n如果系统不运行很需要内存的应用程序或系统有足够多的可能内存，则不需要太多的swap空间。不过，swap空间还用来在休眠时储存整个内存。如果一个系统需要休眠，则必须需要大一点的swap空间，通常至少为系统安装的内存数量。\n作为一般规则，建议交换空间大小为内部存储器 (RAM) 的两倍。对于具有多个硬盘的系统，明智的做法是在每个磁盘上创建一个交换分区，以便它们可以用于并行读/写操作。当必须访问交换空间中的数据时，磁盘交换的速度越快，系统运行的速度就越快。在机械和固态磁盘之间进行选择时，最好将交换放在 SSD 上以提高性能。此外，交换文件可以用作交换分区的替代方案；这对于磁盘空间非常有限的系统来说非常有趣。\n什么是 EFI 系统分区 (ESP)？ 在使用由 UEFI 引导（而不是 BIOS）的操作系统上安装 Gentoo 时，创建 EFI 系统分区 (ESP) 很重要。下面的说明包含正确处理此操作所需的关键点。 在 BIOS/Legacy 模式下启动时不需要 EFI 系统分区。\nESP 必须是 FAT 变体（有时在 Linux 系统上显示为 vfat）。官方 [UEFI 规范](http://www.uefi.org/sites/default/files/resources/UEFI 2_5.pdf) 表示 UEFI 固件将识别 FAT12、16 或 32 文件系统，但建议使用 FAT32。分区后，相应地格式化 ESP：\n# mkfs.fat -F 32 /dev/sda1 警告：如果 ESP 没有使用 FAT 变体进行格式化，那么系统的 UEFI 固件将找不到引导加载程序（或 Linux 内核）并且很可能无法引导系统！\n什么是BIOS引导分区？ 只有在 BIOS/Legacy 模式下将 GPT 分区布局与 GRUB2 结合时，才需要 BIOS 引导分区。 **在 EFI/UEFI 模式下引导时不需要它，使用 MBR 表时也不需要它。**它是一个非常小的分区（1 到 2 MB），像 GRUB2 这样的可以在其中放置超出容量的引导加载程序。本指南中不会使用它。\n使用 GPT for UEFI 对磁盘进行分区 以下部分解释了如何使用 fdisk 为 GPT/UEFI 引导安装创建示例分区布局。范例分区布局我们在前面已经提到过了。\n   Partition Description     /dev/sda1 EFI system (and boot) partition   /dev/sda2 Swap partition   /dev/sda3 Root partition    请您根据自己的实际需要来调整您的分区布局。\n查看当前分区布局 fdisk是一个流行的和强大的分区工具。用fdisk向磁盘开火吧！（在我们的例子里，我们使用/dev/sda）:\n# fdisk /dev/sda 使用 p 键来显示磁盘当前的分区配置。\nCommand (m for help):p Disk /dev/sda: 28.89 GiB, 31001149440 bytes, 60549120 sectors Disk model: DataTraveler 2.0 Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: gpt Disk identifier: 21AAD8CF-DB67-0F43-9374-416C7A4E31EA Device Start End Sectors Size Type /dev/sda1 2048 526335 524288 256M EFI System /dev/sda2 526336 2623487 2097152 1G Linux swap /dev/sda3 2623488 19400703 16777216 8G Linux filesystem /dev/sda4 19400704 60549086 41148383 19.6G Linux filesystem 这块特定的磁盘被配置为容纳 2 个 Linux 文件系统（每个都有一个相应的分区列为“Linux”）以及一个交换分区（列为“Linux swap”）。\n创建一个新的磁盘标签/删除所有分区 输入 g 在磁盘上创建一个新的 GPT 磁盘标签；这将删除所有现有分区。\nCommand (m for help):g Created a new GPT disklabel (GUID: 87EA4497-2722-DF43-A954-368E46AE5C5F). 对于现有的 GPT 磁盘标签（参见上面 p 的输出），或者考虑从磁盘中一一删除现有分区。输入 d 来删除一个分区。例如，要删除现有的 /dev/sda1：\nCommand (m for help):d Partition number (1-4): 1 这个分区已经计划被删除了，当您用p键打印分区清单时它将不会被显示了，但此时它还未被实际删除，直到改变被真正保存。这将允许用户在操作错误后中止——此时，输入q并按Enter可以立即防止分区被删除。\n重复敲击 p来打印分区清单，然后敲击 d键和分区号码来删除它。最终，分区表将变得空空如也。\nCommand (m for help):p Disk /dev/sda: 28.89 GiB, 31001149440 bytes, 60549120 sectors Disk model: DataTraveler 2.0 Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: gpt Disk identifier: 87EA4497-2722-DF43-A954-368E46AE5C5F 现在在内存中的分区表已经空了，我们是时候来创建分区了。\n创建 EFI 系统分区 (ESP) 首先创建一个小的 EFI 系统分区，该分区也将挂载为 /boot。输入 n 创建一个新分区，然后输入 1 选择第一个分区。当提示输入第一个扇区时，确保它从 2048（引导加载程序可能需要）开始并输入 Enter。当提示输入最后一个扇区时，输入 +256M 创建一个大小为 256 MB 的分区：\nCommand (m for help):n Partition number (1-128, default 1): 1 First sector (2048-60549086, default 2048): Last sector, +/-sectors or +/-size{K,M,G,T,P} (2048-60549086, default 60549086): +256M Created a new partition 1 of type 'Linux filesystem' and of size 256 MiB. 将分区标记为 EFI 系统分区：\nCommand (m for help):t Selected partition 1 Partition type (type L to list all types): 1 Changed type of partition 'Linux filesystem' to 'EFI System'. 创建swap分区 接下来，要创建交换分区，请输入 n 创建一个新分区，然后输入 2 创建第二个分区 /dev/sda2。当提示输入第一个扇区时，输入 Enter。当提示输入最后一个扇区时，输入 +4G（或交换空间所需的任何其他大小）以创建大小为 4GB 的分区。\nCommand (m for help):n Partition number (2-128, default 2): First sector (526336-60549086, default 526336): Last sector, +/-sectors or +/-size{K,M,G,T,P} (526336-60549086, default 60549086): +4G Created a new partition 2 of type 'Linux filesystem' and of size 4 GiB. 完成后，输入t设置分区类型，2选择刚刚创建的分区，然后输入 19 设置分区类型为 \u0026ldquo;Linux Swap\u0026rdquo;。\nCommand (m for help):t Partition number (1,2, default 2): 2 Partition type (type L to list all types): 19 Changed type of partition 'Linux filesystem' to 'Linux swap'. 创建根分区 最后，要创建根分区，请输入 n 以创建新分区。然后输入 3 创建第三个分区，/dev/sda3。当提示输入第一个扇区时，按 Enter。当提示输入最后一个扇区时，按 Enter 以创建一个分区，该分区占用磁盘上的其余剩余空间。完成这些步骤后，输入 p 应该会显示一个类似于以下内容的分区表：\nCommand (m for help):p Disk /dev/sda: 28.89 GiB, 31001149440 bytes, 60549120 sectors Disk model: DataTraveler 2.0 Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: gpt Disk identifier: 87EA4497-2722-DF43-A954-368E46AE5C5F Device Start End Sectors Size Type /dev/sda1 2048 526335 524288 256M EFI System /dev/sda2 526336 8914943 8388608 4G Linux swap /dev/sda3 8914944 60549086 51634143 24.6G Linux filesystem 保存分区布局 要保存分区布局并退出 fdisk，请敲击 w。\nCommand (m for help):w 当分区创建完成后，就该在其上部署文件系统了。\n使用 MBR 对磁盘进行分区以用于 BIOS/legacy 启动 下面解释了如何为 MBR/BIOS 传统引导安装创建示例分区布局。前面提到的示例分区布局现在是：\n   Partition Description     /dev/sda1 Boot partition   /dev/sda2 Swap partition   /dev/sda3 Root partition    可以根据个人喜好更改分区布局。\n查看当前分区布局 针对磁盘启动 fdisk（在我们的示例中，我们使用 /dev/sda）：\n# fdisk /dev/sda 输入p显示磁盘的当前分区配置：\nCommand (m for help):p Disk /dev/sda: 28.89 GiB, 31001149440 bytes, 60549120 sectors Disk model: DataTraveler 2.0 Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: gpt Disk identifier: 21AAD8CF-DB67-0F43-9374-416C7A4E31EA Device Start End Sectors Size Type /dev/sda1 2048 526335 524288 256M EFI System /dev/sda2 526336 2623487 2097152 1G Linux swap /dev/sda3 2623488 19400703 16777216 8G Linux filesystem /dev/sda4 19400704 60549086 41148383 19.6G Linux filesystem 直到现在，这个特定的磁盘被配置为使用 GPT 表容纳两个 Linux 文件系统（每个都有一个相应的分区列为 \u0026ldquo;Linux\u0026rdquo;）以及一个交换分区（列为 \u0026ldquo;Linux swap\u0026rdquo;）。\n创建一个新的磁盘标签/删除所有分区 输入 o 在磁盘上创建一个新的 MBR 磁盘标签（这里也称为 DOS 磁盘标签）；这将删除所有现有分区。\nCommand (m for help):o Created a new DOS disklabel with disk identifier 0xe04e67c4. The device contains 'gpt' signature and it will be removed by a write command. See fdisk(8) man page and --wipe option for more details. 对于现有的 DOS 磁盘标签（参见上面 p 的输出），或者考虑从磁盘中一一删除现有分区。输入 d 删除分区。例如，要删除现有的 /dev/sda1：\nCommand (m for help):d Partition number (1-4): 1 该分区现已计划删除。打印分区列表时将不再显示 (p，但在保存更改之前它不会被删除。如果发生错误，用户可以中止操作 —— 在这种情况下, 立即输入 q 并按 Enter 不会删除分区。\n重复输入 p 打印出一个分区列表，然后输入 d 和分区号来删除它。最终，分区表将为空：\nCommand (m for help):p Disk /dev/sda: 28.89 GiB, 31001149440 bytes, 60549120 sectors Disk model: DataTraveler 2.0 Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0xe04e67c4 现在我们已准备好创建分区。\n创建引导分区 首先，创建一个将挂载到 /boot 的小分区。输入 n 创建一个新分区，然后输入 p 作为主分区，输入 1 选择第一个主分区。当提示输入第一个扇区时，确保它从 2048（引导加载程序可能需要）开始并按 Enter。当提示输入最后一个扇区时，输入 +256M 创建一个大小为 256 MB 的分区：\nCommand (m for help):n Partition type p primary (0 primary, 0 extended, 4 free) e extended (container for logical partitions) Select (default p): p Partition number (1-4, default 1): 1 First sector (2048-60549119, default 2048): Last sector, +/-sectors or +/-size{K,M,G,T,P} (2048-60549119, default 60549119): +256M Created a new partition 1 of type 'Linux' and of size 256 MiB. 创建 swap 分区 接下来，要创建交换分区，输入 n 创建一个新分区，然后输入 p，然后输入 2 创建第二个主分区，/dev/sda2。当提示输入第一个扇区时，按 Enter。当提示输入最后一个扇区时，输入 +4G（或交换空间所需的任何其他大小）以创建大小为 4GB 的分区。\nCommand (m for help):n Partition type p primary (1 primary, 0 extended, 3 free) e extended (container for logical partitions) Select (default p): p Partition number (2-4, default 2): 2 First sector (526336-60549119, default 526336): Last sector, +/-sectors or +/-size{K,M,G,T,P} (526336-60549119, default 60549119): +4G Created a new partition 2 of type 'Linux' and of size 4 GiB. 完成后，输入t设置分区类型，输入2选择刚刚创建的分区，然后输入 82 设置分区类型为 \u0026ldquo;Linux Swap\u0026rdquo;。\nCommand (m for help):t Partition number (1,2, default 2): 2 Hex code (type L to list all codes): 82 \u0026lt;!--T:179--\u0026gt; Changed type of partition 'Linux' to 'Linux swap / Solaris'. 创建根分区 最后，要创建根分区，请输入 n 以创建新分区。然后输入 p 和 3 以创建第三个主分区 /dev/sda3。当提示输入第一个扇区时，按 Enter。当提示输入最后一个扇区时，按 Enter 以创建一个分区，该分区占用磁盘上的剩余空间。完成这些步骤后，输入 p 应该会显示一个类似于以下内容的分区表：\nCommand (m for help):p Disk /dev/sda: 28.89 GiB, 31001149440 bytes, 60549120 sectors Disk model: DataTraveler 2.0 Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0xe04e67c4 Device Boot Start End Sectors Size Id Type /dev/sda1 2048 526335 524288 256M 83 Linux /dev/sda2 526336 8914943 8388608 4G 82 Linux swap / Solaris /dev/sda3 8914944 60549119 51634176 24.6G 83 Linux 保存分区布局 要保存分区布局并退出 fdisk，输入 w。\nCommand (m for help):w 现在是时候将文件系统应用在分区上了。\n创建文件系统 介绍 现在分区已经创建，该在上面设置文件系统了。下一章节中描述了 Linux 所支持的众多文件系统。知道使用哪一个文件系统的读者可以继续阅读为分区应用文件系统。剩下的人应该学习可用的文件系统……\n文件系统 有一些可以使用的文件系统。有些在amd64架构上稳定——建议在选择为一个重要分区实验性的选择文件系统前继续阅读。\n  btrfs\n是下一代文件系统，提供了许多高级功能，如快照，通过校验和自我修复、 透明压缩、 子卷和集成 RAID。几个发行版已经开始将它作为一个默认的选项,但它还未为生产工作做好准备。文件系统报告崩溃是常见的。其开发人员敦促人们运行最新的内核版本来解决安全问题,以及老的问题。 这种情况已经很多年了,现在使用它还为时过早。如果出现变更，以及发生了变化，解决错误问题，都很少往旧内核注入补丁。请谨慎使用这个文件系统!\n  ext2\n是经考验证明可靠的Linux文件系统，但是没有元数据日志，这意味这在启动系统时的ext2文件系统的日常检查相当耗时。现在相当一部分的新一代的日志文件系统都可以非常迅速检查一致性，因此比那些非日志文件系统更受欢迎。当你启动系统碰巧遇到文件系统状态不一致时，日志文件系统不会在那里耽搁很长时间。\n  ext3\n是ext2文件系统的带日志版本，提供了元数据日志模式以快速恢复数据。此外还提供了其他增强的日志模式，如完整数据日志模式和有序数据日志模式。它使用了HTree索引，在几乎所有的情况下都能保持高性能。简而言之，ext3是非常好及可靠的文件系统。\n  ext4\n最初创建为ext3的一个分支，EXT4带来了新的功能，性能改进和去除中度更改磁盘格式大小限制。它可以跨越体积高达1的EB并用16 TB最大文件大小。取而代之的是经典的ext2/3位块分配的ext4的使用范围，这对提高大文件的性能，并减少碎片。的Ext4还提供了更为复杂的块分配算法（延迟分配和多嵌段分配）给文件系统驱动更多的方式来优化数据的布局在磁盘上。 EXT4是推荐的通用所有平台的文件系统。\n  f2fs\n这个文件系统最初由三星创建用于NAND闪存，是一种闪存文件系统 从直到2016年第二季度起，这个文件系统仍然被认为不成熟。把Gentoo安装到microSD卡，USB驱动器或其他基于闪存的存储设备时使用它是一个不错的选择。\n  JFS\n是IBM的高性能日志文件系统。JFS是一个轻量级的、快速的和稳定的基于B+树的文件系统，在很多情况下都有很好的表现。\n  ReiserFS\n是基于B+树的文件系统，它有着非常全面的性能，特别时在处理很多小文件的时候，虽然会占用多一点CPU。ReiserFS相比其他文件系统显得受维护的不够。\n  XFS\n是一种带元数据日志的文件系统，它有一个健壮的特性集，并且对可伸缩性进行了优化。XFS似乎对各种各样的硬件问题显得不够宽容。\n  vfat\n也称为FAT32，被支持Linux，但不支持任何权限设置。它主要用于互操作性与其他操作系统（主要是微软的Windows），但也是很有必要的一些系统固件（如UEFI）的支持。\n  NTFS\n这个“新技术”的文件系统是Microsoft Windows的旗舰文件系统。 与上面的vfat类似，它不存储BSD或Linux正常工作所需的权限设置或扩展属性，因此它不能用作根文件系统。 它应该\u0026rsquo;只\u0026rsquo;用于与Microsoft Windows系统的互操作性（注意只强调）。\n  为分区应用文件系统 在一个分区或卷上创建一个文件系统，这里有用于每一个可能的分区的工具。 单击下表中的文件系统名称，了解每个文件系统的更多信息：\n   Filesystem Creation command On minimal CD? Package     btrfs mkfs.btrfs Yes sys-fs/btrfs-progs   ext4 mkfs.ext4 Yes sys-fs/e2fsprogs   f2fs mkfs.f2fs Yes sys-fs/f2fs-tools   jfs mkfs.jfs Yes sys-fs/jfsutils   reiserfs mkfs.reiserfs Yes sys-fs/reiserfsprogs   xfs mkfs.xfs Yes sys-fs/xfsprogs   vfat mkfs.vfat Yes sys-fs/dosfstools   NTFS mkfs.ntfs Yes sys-fs/ntfs3g    例如，要将 EFI 系统分区 (/dev/sda1) 设为 FAT32，将根分区 (/dev/sda3) 设为 ext4，如示例分区结构中所用，将使用以下命令：\n# mkfs.vfat -F 32 /dev/sda1 # mkfs.ext4 /dev/sda3 当在一个小的分区（少于8 GiB）上使用 ext2、ext3 或 ext4，则创建文件系统时必须带适当的选项以保留足够的 inode。mke2fs（mkfs.ext2）应用程序使用“字节每inode”设置来计算一个文件系统 inode 的数量。在小分区，建议增加计算出的 inode 数量。\n# mkfs.ext4 -T small /dev/\u0026lt;device\u0026gt; 这一般将是对于给定的文件系统inode数量的四倍，它的“字节每inode”从16kB每个减少到4kB每个。这个可以在将来通过提供比例进行调整：\n现在在新创建的分区（或逻辑卷）上创建文件系统。\n激活swap分区 mkswap是用来初始化swap分区的命令：\n# mkswap /dev/sda2 要激活swap分区，使用swapon：\n# swapon /dev/sda2 使用上面提到的命令创建和激活swap。\n可选：使用 swapfile $ fallocate -l 15G /swapfile $ chmod 600 /swapfile $ mkswap /swapfile $ swapon /swapfile $ swapon -s 挂载 root 分区 现在分区都已初始化并有文件系统，接下来该挂载那些分区了。使用mount命令，但是不要忘记为每一个创建的分区创建需要的挂载目录。比如示例中我们挂载根分区:\n# mount /dev/sda3 /mnt/gentoo 附注：如果/tmp/需要放在一个独立分区，确保在挂载后变更它的权限：\n# chmod 1777 /mnt/gentoo/tmp 这同样适用于/var/tmp。\n后面的介绍中将挂载proc文件系统（一个内核的虚拟接口）和其它内核伪文件系统。不过我们首先安装Gentoo安装文件。\n安装Gentoo安装文件 安装stage包 设置日期和时间 在安装Gentoo之前，最好确保日期和时间设置正确。 错误配置的时间可能会导致奇怪的结果：基本系统文件应设置精确的时间戳。 事实上，由于几个网站和服务使用加密通信（SSL / TLS），如果系统时间差的离谱，可能无法下载安装文件！\n验证当前时间使用命令date:\n# date Mon Oct 3 13:16:22 PDT 2021 如果显示的日期/时间不正确，请使用下列方法之一进行更新。\n附注：不包括实时时钟（RTC）的主板应配置为自动将系统时钟与时间服务器同步。 这也适用于包含RTC但具有故障电池的系统。\n自动\nGentoo 的官方安装光盘包含 ntpd 命令 (属于包 net-misc/ntp package)。官方光盘包括指向ntp.org时间服务器的配置文件。它可以用于使用时间服务器，使得系统时钟自动同步到UTC时间。使用方法见配置网络 但在某些架构的光盘上可能不可用。\n警告：自动时间同步需要付出一个代价。它将向时间服务器显示系统的IP地址和相关网络信息（在下面的示例中为ntp.org）。有隐私问题的用户应该注意这个“之前”使用下面的方法设置系统时钟。\n# ntpd -q -g 手动\n也可以用date 命令来对系统时钟执行手动设置。使用 MMDDhhmmYYYY 语法 (月, 日, 小时, 分钟 和 年)。\n建议所有Linux系统使用UTC时间。 稍后在安装期间将定义时区。 这将修改时钟的显示为本地时间。\n比如，设置时间到2016年10月3日的13:16：\n# date 100313162021 选择一个stage包 multilib（32和64位）\n选择一个基础压缩包的系统可以在稍后的安装过程节省大量的时间，特别是当它是一次选择正确的配置文件。一个stage包的选择将直接影响未来的系统配置，可以在以后省的头痛。该压缩包 multilib 尽可能使用64位的库，只必要时对32位版本兼容。这对于大多数安装一个很好的选择，因为它在未来的定制提供了极大的灵活性量。那些谁希望自己的系统，能够容易地切换配置,应该下载根据各自的处理器架构 multilib的压缩包选项。\n大多数用户应该不需要使用“高级”tar包选项；它们用于特定的软件或硬件配置。\nno-multilib（纯64位）\n选择一个no-multilib压缩包:no-multilib是在系统的基础上提供了一个完整的64位操作系统环境。这有效地使得切换到multilib的profile是不可能的(不是完全不可能)。这些刚刚开始使用Gentoo的新手不应该选择一个 no-multilib 压缩包，除非\u0026quot;绝对必要\u0026quot;。而且应该有很好的理由并做出负责任的选择。\n警告：注意，把一个系统从no-multilib迁移到multilib需要极其丰富的使用Gentoo的知识并熟悉底层的工具链。这一做法甚至可能导致Toolchain developers 这令人不寒而栗。不适合内心柔弱之人,而且也超出了本指南的范围。\n其他 profile 属性说明\n openrc: 带此单词表示，其默认的初始化程序为 openrc systemd: 带此单词表示，其默认的初始化程序为 systemd，而不带该单词所有 profile ，默认初始化程序都是 openrc （即 Gentoo Linux 官方默认） selinux: 带此单词表示，其默认包含 SELinux 相关配置，启用 SELinux hardened: 带此单词表示，其默认包含强化安全性相关的配置  正常使用情况下，推荐如下两个 stage3 进行下载：\n current-stage3-amd64-openrc current-stage3-amd64-systemd  openrc 是 Gentoo Linux 官方维护且默认的初始化程序，而 systemd 则是如今大多数发行版使用的初始化程序，各有优劣，二者均可，自行选择。\n下载stage压缩包 前往挂载根文件系统的 Gentoo 挂载点（类似于 /mnt/gentoo）：\n# cd /mnt/gentoo 根据不同的安装媒介，下载stage压缩包所需的唯一工具是网络浏览器。\n图形化浏览器\n那些使用图形化网页浏览器从主网站下载小节复制stage文件URL也没有问题。 只需选择适当的选项卡，右键单击stage文件的链接，然后复制链接地址（Firefox）或复制链接位置（Chromium）将链接复制到剪贴板，然后 将链接粘贴到命令行中的 wget程序以下载stage tarball：\n# wget \u0026lt;PASTED_STAGE_URL\u0026gt; 例如\n# wget https://mirrors.bfsu.edu.cn/gentoo/releases/amd64/autobuilds/current-stage3-amd64-systemd/stage3-amd64-systemd-20220315T091810Z.tar.xz # wget https://mirrors.bfsu.edu.cn/gentoo/releases/amd64/autobuilds/current-stage3-amd64-systemd/stage3-amd64-systemd-20220315T091810Z.tar.xz.DIGESTS # cat stage3-amd64-systemd-20220315T091810Z.tar.xz # sha512sum stage3-amd64-systemd-20220315T091810Z.tar.xz 命令行浏览器\n更多传统的读者或是 Gentoo 的“老前辈”，只能命令行工作，可能更喜欢使用非图形化菜单驱动的浏览器 links。 要下载一个 stage，请像下面这样访问Gentoo镜像列表：\n# links https://www.gentoo.org/downloads/mirrors/ 要设置links使用一个HTTP代理，在传入URL上加一个-http-proxy选项：\n# links -http-proxy proxy.server.com:8080 https://www.gentoo.org/downloads/mirrors/ links之外还有一个lynx浏览器。和links类似，它也是一个非图形化的浏览器，但不是自带的。\n# lynx https://www.gentoo.org/downloads/mirrors/ 如果需要定义一个代理，设置http_proxy和/或ftp_proxy变量：\n# export http_proxy=\u0026#34;http://proxy.server.com:port\u0026#34; # export ftp_proxy=\u0026#34;http://proxy.server.com:port\u0026#34; 在镜像列表中，选择一个附近镜像站。通常HTTP镜像站就足够了，但其他网络协议是可用的。请访问releases/amd64/autobuilds/ 。 那里将显示所有可用stage文件 （可能他们个别小组架构在命名的子目录中存储）。选择一个，然后按 d 下载。\nstage 文件下载完成后，可以验证 stage tarball 的完整性并验证其内容。\n对验证stage文件不感兴趣的用户可以通过按 q 来关闭命令行浏览器，并且可以直接移步到 解压stage压缩包 部分。\n验证\n附注：一些 tarballs 是通过XZ压缩的。在下载以 .tar.xz 结尾的 tarball 时，请确保在下面的命令中调整tarball文件名的 .tar.bz2 。\n与最小安装CD一样，可以使用额外的下载来验证stage文件。 虽然这些步骤可以被跳过，但这些文件是为那些关心他们刚刚下载的文件合法性的用户提供的。\n A .CONTENTS 文件包含stage压缩包内的所有文件的列表。 A .DIGESTS 文件，其中包含用不同的算法校验的stage文件。 A .DIGESTS.asc 像.DIGESTS文件一样, 包含不同的stage文件的校验和，但也加密签名，以确保它是由Gentoo项目提供的。  使用 openssl 并比较,提供的校验输出与.DIGESTS或者.DIGESTS.asc 文件的内容是否一致。\n比如，要验证SHA512校验值：\n# openssl dgst -r -sha512 stage3-amd64-\u0026lt;release\u0026gt;-\u0026lt;init\u0026gt;.tar.?(bz2|xz) 使用sha512sum命令的另外一种方式：\n# sha512sum stage3-amd64-\u0026lt;release\u0026gt;-\u0026lt;init\u0026gt;.tar.?(bz2|xz) 要验证Whirlpool校验值：\n# openssl dgst -r -whirlpool stage3-amd64-\u0026lt;release\u0026gt;-\u0026lt;init\u0026gt;.tar.?(bz2|xz) 该值需要匹配，否则下载的文件可能已损坏（或摘要文件）。比较这些命令的输出与.DIGESTS(.asc)中的值。该值需要匹配，否则下载的文件可能已损坏（或digests文件）。\n就像在ISO文件中，它也可以来验证加密签名的.DIGESTS.asc。使用 gpg 以确保DIGESTS.asc文件校验和未被篡改:\n# gpg --verify stage3-amd64-\u0026lt;release\u0026gt;-\u0026lt;init\u0026gt;.tar.?(bz2|xz){.DIGESTS.asc,} 解压stage压缩包 现在，解压下载的stage到系统。我们使用 tar来进行：\n# tar xpvf stage3-*.tar.xz --xattrs-include=\u0026#39;*.*\u0026#39; --numeric-owner 确保你使用了同样的参数 ( xpf 和 --xattrs-include='*.*')。 x表示解开（Extract），v表示详细信息（Verbose）可以用来查看解压缩时发生了什么（可选参数）， p 表示保留权限（Preserve permissions），还有f 表示我们要解开一个文件，而不是标准输入。最后，--numeric-owner 被用于确保从tarball中提取的文件的用户和组ID与Gentoo发布工程团队预期的保持一致，即使大胆的用户使用的不是Gentoo官方安装媒介。\n现在stage文件已经解压好了，下面我们继续配置编译选项。\n配置编译选项 介绍 为了优化Gentoo，可以设置一些影响Portage的变量，Gentoo官方支持包管理器。 所有这些变量可以设置为环境变量（使用export），但这不是永久的。 为了保留设置，Portage读入/etc/portage/make.conf文件 ，一个用于Portage的配置文件，它有一个预配置好的模板文件在 /usr/share/portage/config/make.globals ，而 make.conf 下的配置会覆盖该模板下对应变量。\n附注：所有可能的变量的注释列表可以在 /mnt/gentoo/usr/share/portage/config/make.conf.example中找到。要成功安装Gentoo，只需要设置下面提到的变量。\n启动编辑器（在本指南中，我们使用 nano）来更改我们将在下面讨论的优化变量。\n# nano -w /mnt/gentoo/etc/portage/make.conf 从make.conf.example文件中可以明显看出文件的结构：注释行以 #开头，其他行使用 VARIABLE=\u0026quot;value\u0026quot; 语法定义变量。 接下来选取其中的几个进行讨论。\nCFLAGS 和 CXXFLAGS CFLAGS 和 CXXFLAGS 变量分别定义了GCC C和C ++编译器的优化标志。 尽管这些标志一般在这里默认被定义过，但为了性能最大化，需要分别优化每个程序的这些配置。 原因是因为每个程序都不同。 但是，这是不可管理的，因此这些标志在 make.conf 文件中定义。\n应该在make.conf中定义优化标志，这将使系统的响应速度最快。 不要在此变量中放置实验性的设置; 太多的优化可能会使程序表现不佳（崩溃，甚至更糟，故障）。\n我们不会解释所有可能的优化选项。 要了解它们，请阅读GNU在线手册或gcc信息页面 (info gcc-只适用于可用的Linux系统)。make.conf.example 文件本身也包含了很多例子和信息; 不要忘了读它。\n第一个设置是标志 -march= 和 -mtune= ，指定目标体系结构的名称。 可能用到的选项在make.conf.example文件中有描述（作为注释）。 一个常用的值是“native”，它告诉编译器选择当前系统体系结构（用户正在安装Gentoo时的系统）。(如果你知道自己处理器的代号，就用自己的处理器代号替换这里的native 比如我的是skylake，如果不确定就使用native。一个得到处理器代号的简单办法：使用 CPU-Z 检测）。\n第二个是标志 -O（即大写的字母O，而不是数字零），它指定了gcc优化级别标志。 可能用到级别的是s（对于大小最优化），0（零 - 无优化），1,2或甚至3等更多的优化选项（每个级别具有与前面相同的标志，加上一些额外选项）。 -O2是建议的默认值。 -O3在整个系统范围内使用时会导致问题，因此我们建议您坚持使用-O2。\n另一个普遍使用的优化标记是-pipe（不同编译阶段通信使用管道而不是临时文件）。它对产生的代码没有任何影响，但是会使用更多的内存。在内存不多的系统里，gcc可能会被杀掉。如果是那样的话，就不要用这个标记。\n使用 -fomit-frame-pointer（它将不在寄存器里为不需要帧指针的函数保存帧指针）可能会在调试程序的时候造成严重后果！\n在你定义 CFLAGS和CXXFLAGS的时候，你需要把这些优化标记都合并起来。stage3文件里包含的你解压缩出来的默认值已经足够好了。下面这个例子仅仅是个例子：\n# Compiler flags to set for all languages COMMON_FLAGS=\u0026#34;-march=native -O2 -pipe\u0026#34; # Use the same settings for both variables CFLAGS=\u0026#34;${COMMON_FLAGS}\u0026#34; CXXFLAGS=\u0026#34;${COMMON_FLAGS}\u0026#34; Tip：通过GCC 优化指导这篇文章获取有更多的信息，比如这些优化变量如何影响你的系统，Safe CFLAGS也许是对初学者开始优化系统更实用的一篇文章\nMAKEOPTS 通过使用MAKEOPTS 你可以定义在安装软件的时候同时可以产生并行编译的数目。官方推荐取「内存大小/2G」（free -h）与「CPU 线程数」（nproc）中的较小者。\n警告：使用大量job会显着影响内存消耗。良好的建议是为指定的每项工作至少有2 GiB的RAM（例如，-j6需要至少12个GiB）。要避免内存不足，请降低作业数量以适应可用内存。\n提示：使用并行emerges （--jobs）时，运行的有效作业数量可以呈指数增长（最高使工作数乘以emerge作业数）。通过运行仅限localhost-only distcc配置，可以根据仅限于每个主机的编译器实例的数量来解决此问题。\nMAKEOPTS=\u0026#34;-j5\u0026#34; 如果变量未进行设置，那么 portage 会根据当前 CPU 的线程数自动赋予一个值，该自动值等于当前 CPU 线程数。\nmake.conf Template # These settings were set by the catalyst build script that automatically # built this stage. # Please consult /usr/share/portage/config/make.conf.example for a more # detailed example. COMMON_FLAGS=\u0026#34;-march=native -O2 -pipe\u0026#34; CFLAGS=\u0026#34;${COMMON_FLAGS}\u0026#34; CXXFLAGS=\u0026#34;${COMMON_FLAGS}\u0026#34; FCFLAGS=\u0026#34;${COMMON_FLAGS}\u0026#34; FFLAGS=\u0026#34;${COMMON_FLAGS}\u0026#34; #直接填写即可 CHOST=\u0026#34;x86_64-pc-linux-gnu\u0026#34; # CPU指令集，按照自己CPU的实际情况填写，后文会提到 CPU_FLAGS_X86=\u0026#34;aes avx avx2 f16c fma3 mmx mmxext pclmul popcnt rdrand sse sse2 sse3 sse4_1 sse4_2 ssse3\u0026#34; # 同时编译的线程数 MAKEOPTS=\u0026#34;-j5\u0026#34; # NOTE: This stage was built with the bindist Use flag enabled PORTDIR=\u0026#34;/var/db/repos/gentoo\u0026#34; DISTDIR=\u0026#34;/var/cache/distfiles\u0026#34; PKGDIR=\u0026#34;/var/cache/binpkgs\u0026#34; # This sets the language of build output to English. # Please keep this setting intact when reporting bugs. LC_MESSAGES=C # Emerge Default Option EMERGE_DEFAULT_OPTS=\u0026#34;--binpkg-changed-deps=y --binpkg-respect-use=y --getbinpkg=y --autounmask --autounmask-keep-masks --autounmask-write=n --keep-going -v -a\u0026#34; #每次安装完包之后自动清理 AUTO_CLEAN=\u0026#34;yes\u0026#34; # Accept # 如果你更喜欢最新而非稳定那这里用~amd64 ACCEPT_KEYWORDS=\u0026#34;amd64\u0026#34; # 接受所有许可证的软件 ACCEPT_LICENSE=\u0026#34;*\u0026#34; # Lang # 语言设置照抄即可 L10N=\u0026#34;en-US zh-CN en zh\u0026#34; # Harkware # intel集成显卡和nvidia显卡（不使用novueau） VIDEO_CARDS=\u0026#34;intel i965 iris nvidia\u0026#34; # intel声卡 ALSA_CARDS=\u0026#34;hda_intel\u0026#34; # 输入设备 非笔记本去除后面的synaptics INPUT_DEVICES=\u0026#34;libinput synaptics\u0026#34; #Grub # 设置GRUB版本 照抄即可 GRUB_PLATFORMS=\u0026#34;efi-64\u0026#34; # Ccache # 使用ccache来大大提高重新编译时的速度，等后面安装并设置ccache之后取消注释 # FEATURES=\u0026#34;parallel-fetch ccache\u0026#34;  # ccache使用的目录 # CCACHE_DIR=\u0026#34;/var/cache/ccache\u0026#34;  # Aria2  # 使用aria2提高下载速度（不设置也无大碍，设置的话一定要注意指令拼写正确） #FETCHCOMMAND=\u0026#34;/usr/bin/aria2c -d \\${DISTDIR} -o \\${FILE} --allow-overwrite=true --max-tries=5 --max-file-not-found=2 --max-concurrent-downloads=5 --connect-timeout=5 --timeout=5 --split=5 --min-split-size=2M --lowest-speed-limit=20K --max-connection-per-server=9 --uri-selector=feedback \\${URI}\u0026#34; #RESUMECOMMAND=\u0026#34;${FETCHCOMMAND}\u0026#34; # USE  # USE变量是Gentoo最有威力的变量 也是Gentoo吸引我的原因之一 #FUCKDE=\u0026#34;-gnome -gnome-shell -gnome-keyring -nautilus -kde\u0026#34; # 不打算安装gnome和kde及其相关组件 #FUCKSV=\u0026#34;-bindist -mdev elogind -dhcpcd -oss -grub -plymouth -systemd -consolekit\u0026#34; # 不使用systemd plymouth consolekit 只使用elogind（旧教程会使用consolekit，事实上elogind是consolekit未来的替代品） #SOFTWARE=\u0026#34;sudo -icu client git chromium openmp minizip udev blkid efi hwdb smack acpi ccache dbus policykit udisks\u0026#34; # 需要用到的特性 照抄即可 #AUDIO=\u0026#34;alsa jack pulseaudio\u0026#34; # 对于音频相关软件使用pulseaudio alsa jack特性 #NET=\u0026#34;network networkmanager connection-sharing wifi http2\u0026#34; # 网络相关 照抄即可 #VIDEO=\u0026#34;X vulkan layers glamor nvidia gallium\u0026#34; # 图形相关 照抄即可 #ELSE=\u0026#34;cjk emoji\u0026#34; # 照抄 # 定义需要的USE变量 #USE=\u0026#34;${FUCKDE} ${FUCKSV} ${SOFTWARE} ${AUDIO} ${NET} ${VIDEO} ${ELSE}\u0026#34; # Mirrors # 设置镜像站为北外镜像站（清华镜像站的影分身，压力小，速度快） GENTOO_MIRRORS=\u0026#34;https://mirrors.bfsu.edu.cn/gentoo\u0026#34; # Proxy # emerge时用到的代理 需要代理时候自行设置 勿照抄 下同 #http_proxy=\u0026#34;http://127.0.0.1:8889\u0026#34;  #https_proxy=\u0026#34;http://127.0.0.1:8889\u0026#34;   make.conf\n  CHOST\n  CPU_FLAGS_X86\n检测cpu指令集\n$ sudo emerge app-portage/cpuid2cpuflags $ sudo cpuid2cpuflags 安装完成之后使用该指令并将输出值作为CPU_FLAGS_X86的值输入到make.conf中\n  AUTO_CLEAN: man make.conf wrote\nAUTOCLEAN = [\u0026quot;yes\u0026quot; | \u0026quot;no\u0026quot;] Automatically cleans the system by removing outdated packages which will not remove functionalities or prevent your system from working. On major ABI changes this may need to be set to off to ensure that the system can be rebuilt using the new libs before the old ones are removed. Downgrading with this option turned off may result in missing symlinks and an inoperable system. Defaults to yes.   ALSA_CARDS:\nALSA_CARDS is used by sys-firmware/alsa-firmware and media-sound/alsa-tools (result of eix -U ALSA_CARDS).\nIf you have an intel hda(according to your lspci output), you don\u0026rsquo;t need to bother with ALSA_CARDS, because that card doesn\u0026rsquo;t require anything special. If you still want to set it for the sake of completeness, use ALSA_CARDS=\u0026ldquo;hda-intel\u0026rdquo;.\n  INPUT_DEVICES\n  ccache: 配置ccache\nemerge --ask dev-util/ccache # 创建ccache的目录 mkdir -p /var/cache/ccache # 修改owner为portage组的用户 chown -R root:portage /var/cache/ccache # 修改权限 chmod -R 777 /var/cache/ccache # 完成配置之后去掉make.conf中ccache的注释 # 之后安装别的包可能会在ccache这出现问题，需要重新给权限   就位，预备，出发 ！ 根据你的喜好更新并保存/mnt/gentoo/etc/portage/make.conf（nano用户可以敲 Ctrl+X）。\n让我们继续 安装Gentoo 基本系统.\n安装Gentoo基础系统 Chrooting 可选：选择镜像站点 分发文件 为了能更快的下载源代码，这里推荐选择一个快的镜像。Portage 将会在make.conf文件中查找GENTOO_MIRRORS变量，并使用其中所列的镜像。可以通过浏览 Gentoo 镜像列表搜索一个（或一组）最接近系统物理位置（往往那是最快的）的镜像。另外，我们提供一个叫作mirrorselect的好工具，它为用户选择所需镜像提供了一个很好的交换。只需要移动光标选择镜像并按Spacebar选择一个或多个镜像。\n# mirrorselect -i -o \u0026gt;\u0026gt; /mnt/gentoo/etc/portage/make.conf 如果因为连接国外网络不畅的原因，导致获取列表失败，这时候也可以直接手动指定一个镜像：\necho \u0026#39;GENTOO_MIRRORS=\u0026#34;https://mirrors.tuna.tsinghua.edu.cn/gentoo\u0026#34;\u0026#39; \u0026gt;\u0026gt; /mnt/gentoo/etc/portage/make.conf 官方 ebuild 软件仓库 选择镜像的第二个重要步骤是通过/etc/portage/repos.conf/gentoo.conf文件来配置 Gentoo的 ebuild 软件仓库。这个文件包含了更新 Portage 数据库（包含 Portage 需要下载和安装软件包所需要的信息的一个 ebuild 和相关文件的集合）所需要的同步信息。\n通过几个简单的步骤就可以完成软件仓库的配置。首先，如果它不存在，则创建repos.conf目录：\n# mkdir --parents /mnt/gentoo/etc/portage/repos.conf 接下来，复制 Portage 提供的 Gentoo 仓库配置文件到这个（新创建的）目录：\n# cp /mnt/gentoo/usr/share/portage/config/repos.conf /mnt/gentoo/etc/portage/repos.conf/gentoo.conf 使用一个文件编辑器或通过使用 cat 命令来看一眼。文件里的内容应该是.ini格式并且看起来像是这样：\n# cat /mnt/gentoo/etc/portage/repos.conf/gentoo.conf [DEFAULT] main-repo = gentoo [gentoo] location = /var/db/repos/gentoo sync-type = rsync sync-uri = rsync://rsync.gentoo.org/gentoo-portage auto-sync = yes sync-rsync-verify-jobs = 1 sync-rsync-verify-metamanifest = yes sync-rsync-verify-max-age = 24 sync-openpgp-key-path = /usr/share/openpgp-keys/gentoo-release.asc sync-openpgp-key-refresh-retry-count = 40 sync-openpgp-key-refresh-retry-overall-timeout = 1200 sync-openpgp-key-refresh-retry-delay-exp-base = 2 sync-openpgp-key-refresh-retry-delay-max = 60 sync-openpgp-key-refresh-retry-delay-mult = 4 上面列出的默认的sync-uri变量值将决定一个基于轮询的镜像位置。这将缓解Gentoo基础设施上带宽的压力并能提供一个由于特定镜像离线的故障安全。除非使用本地私有Portage镜像，否则建议保留默认URI。\nTip：对那些有兴趣的话，可以在Portage项目的同步主题中找到关于Portage的同步API插件的官方规范。\n自定义 ebuild 软件仓库 同步方式：\n rsync 方式可以使用命令校验本地改动，但本地同步时速度较慢；镜像站同步上游频率正常 git 方式可以使用命令结合人工介入判断以校验本地改动，本地同步时速度快；官方镜像点与原始仓库同步最及时，但国内镜像站同步上游频率低  目前推荐使用 git 方式。为了使得更新更迅速，建议自定义一个靠近自己的镜像站点。方法为先创建一个自定义配置文件 /etc/portage/repos.conf/gentoo.conf ，后根据同步类型进行操作：\n  自定义 rsync 方式同步配置\n[gentoo] location = /var/db/repos/gentoo auto-sync = yes sync-type = rsync sync-uri = rsync://mirrors.bfsu.edu.cn/gentoo-portage # 国内我这里建议可以使用北外的镜像站，其负载小，带宽大，更新迅速。 # 其它国内的镜像站我所知的还有： # TUNA： rsync://mirrors.tuna.tsinghua.edu.cn/gentoo-portage # 163： rsync://mirrors.163.com/gentoo-portage # 中科大： rsync://rsync.mirrors.ustc.edu.cn/gentoo-portage/ Gentoo Linux 官方有一份较为完整的 rsync 镜像列表 。\n  自定义 git 方式同步配置\n[gentoo] location = /var/db/repos/gentoo auto-sync = yes sync-type = git sync-depth = 1 sync-uri = https://mirrors.bfsu.edu.cn/git/gentoo-portage.git # 国内我找到的 git 方式同步镜像只有北外和 TUNA 两家 # TUNA 的地址： https://mirrors.tuna.tsinghua.edu.cn/git/gentoo-portage.git # 但它们的同步上游的频率都很低（截至发文时确认为 11 小时一次） # 所以若使用 git 方式同步，在网络流畅的情况，个人更建议直接同步官方镜像： # https://github.com/gentoo-mirror/gentoo.git sync-git-verify-commit-signature = yes # 设置校验最上层 commit 的签名，默认是不校验的 之后执行：\nemerge -vj dev-vcs/git # 以安装 git 工具，它并不是系统自带的 rm -rf /var/db/repos/gentoo # 删除原有的不支持 git 方式的数据库 emerge --sync # 初始化同步一次数据库   如果你比较疑惑为何在 mirrorselect 时添加了一个镜像地址，此时又添加了，那么在此说明：\n安装 Gentoo Linux 时往 /etc/portage/make.conf 写入的镜像地址，是 distfiles 镜像地址，用于下载安装软件时的软件本体（源代码或者二进制包），也包括了很多其它内容，比如 Portage 数据库的快照（但此快照不适用于日常更新）。\n而此时配置的镜像是用于同步 Portage 系统的数据库，其包含了基础的系统配置文件，安装软件所需的描述文件等等很多基础内容。\n复制DNS信息 在进行新环境之前，还有一件要做的事情就是复制/etc/resolv.conf中的DNS信息。需要完成这个来确保即使进入到新环境后网络仍然可以使用。/etc/resolv.conf包含着当前网络中的DNS服务器。\n要复制这个信息，建议通过cp命令的 --dereference 选项。这可以保障如果/etc/resolv.conf是一个符号链接的话，复制的是那个目标文件而不是这个符号文件自己。否则在新环境中，符号文件将指向一个不存在的文件（因为链接目标非常可能不会在新环境中）。\n# cp --dereference /etc/resolv.conf /mnt/gentoo/etc/ 或者\n# echo \u0026#39;nameserver 114.114.114.114\u0026#39; \u0026gt; /mnt/gentoo/etc/resolv.conf 挂载必要的文件系统 稍等片刻，Linux 的根目录将变更到新的位置。为了确保新环境正常工作，需要确保一些文件系统可以正常使用。\n需要提供的文件系统是：\n /proc/ 一个pseudo文件系统（看起来像是常规文件，事实上却是实时生成的），由Linux内核暴露的一些环境信息 /sys/ 一个pseudo文件系统，像要被取代的/proc/一样，比/proc/更加有结构 /dev/ 是一个包含全部设备文件的常规文件系统，一部分由Linux设备管理器（通常是udev）管理  /proc/位置将要挂载到/mnt/gentoo/proc/，而其它的两个都是绑定挂载。字面上的意思是，例如/mnt/gentoo/sys/事实上就是/sys/（它只是同一个文件系统的第二个条目点），而/mnt/gentoo/proc/是（可以说是）文件系统的一个新的挂载。\n# mount --types proc /proc /mnt/gentoo/proc # mount --rbind /sys /mnt/gentoo/sys # mount --make-rslave /mnt/gentoo/sys # mount --rbind /dev /mnt/gentoo/dev # mount --make-rslave /mnt/gentoo/dev # mount --bind /run /mnt/gentoo/run # mount --make-slave /mnt/gentoo/run 附注：--make-rslave操作是稍后安装systemd支持时所需要的。\n警告：当使用非Gentoo安装媒介时，比如 Ubuntu，这时可能还不算完。一些发行版将/dev/shm符号链接到/run/shm/，在chroot后将变得不可用。为了让/dev/shm/是一个正常挂载的tmpfs，可以这样修复：\n# test -L /dev/shm \u0026amp;\u0026amp; rm /dev/shm \u0026amp;\u0026amp; mkdir /dev/shm # mount --types tmpfs --options nosuid,nodev,noexec shm /dev/shm 同时确保设置了权限为1777：\n# chmod 1777 /dev/shm  ArchФэ: genfstab 确实方便很多，再来个gentoochroot就更舒服了 min: 可以，做完前面的步骤，再 systemd-nspawn -b -D /mnt 这样比之chroot还可以用hostnamectl啥的\n 进入新环境 现在所有的分区已经初始化，并且基础环境已经安装，是时候进入到新的安装环境了。这意思着会话将把根目录（能访问到最顶层的位置）从当前的安装环境（安装CD或其他安装媒介）变为安装系统（叫做初始化分区）。因此叫作 change root 或 chroot。\n完成chroot有三个步骤：\n 使用 chroot 将根目录的位置从 /（在安装媒介里）更改成 /mnt/gentoo/ （在分区里） 使用 source 命令将一些设置（那些在 /etc/profile 中的）重新载入到内存中 更改主提示符来帮助我们记住当前会话在一个 chroot 环境里面。  # chroot /mnt/gentoo /bin/bash # source /etc/profile # export PS1=\u0026#34;(chroot) ${PS1}\u0026#34; 从现在开始，所有的动作将立即在新Gentoo Linux环境里生效。当然这离完成还很远，因为安装还剩下很多章节 ！\nTip：如果安装Gentoo时在这一步之后的任何地方中断，那么“应该”可以从这一步“继续”安装。不必再重新给磁盘分区！只需要[挂载 root 分区](#挂载 root 分区) 并运行上述步骤，然后通过复制 DNS 信息 重新进入工作环境。 这也对修复引导程序问题很有用。 更多的信息可以在 chroot 这篇文章中找到。\n挂载 boot 分区 现在已经进入新的环境，必须创建并挂载 boot 分区。 当编译内核并安装引导加载程序时，这将非常重要：\n# mount /dev/sda1 /boot 可以挂载到 /boot/efi/ 分区\n# mkdir -p /boot/efi # mount /dev/sda1 /boot/efi/ 配置Portage 从网站安装 Gentoo ebuild 数据库快照 接下来，是安装 Gentoo ebuild 数据库。这个快照包含一组文件，包括通知 Portage 中有关可用软件的标题（用于安装），系统管理员可以选择哪些配置文件，软件包或 profile 特定新闻 (news) 项目等。\n建议那些使用限制性防火墙的用户使用 emerge-webrsync 命令（它使用 HTTP / FTP 协议下载快照）节省网络带宽。 没有网络或带宽限制的读者可以愉快地跳到下一节。\n这将从Gentoo的一个镜像中获取最新的快照（每天发布）并将其安装到系统上：\n# emerge-webrsync 附注：在这个操作中，emerge-webrsync可能会报找不到 /var/db/repos/gentoo/ 位置。这是预期内的并且不用担心——这个工具将会创建这个位置。\n从现在开始，Portage 可能会提示建议运行某些更新。这是因为在安装了一个新的repository 快照后，Portage 发现了 stage 文件中已经安装的某些软件包有更新的版本。现在可以安全的忽略包的更新；可以延迟到 Gentoo 安装完成之后更新。\n可选：更新Portage ebuild 数据库 注：如果不配置代理的话，这个真的非常慢，非常耗时。\nGentoo 数据库可以更新到最新版本。前面的emerge-webrsync命令将安装一个最近的快照（通常是24小时以内），所以这一步是可选的。\n假设需要最新更新的软件包（1小时以内），可以使用emerge \u0026ndash;sync。这个命令将使用rsync协议来更新 Gentoo ebuild 数据库（之前通过emerge-webrsync获得的）到最新状态。\n# emerge --sync 在慢速的终端上，比如一些framebuffer或者串口控制台，建议使用--quiet选项来加速这个进程：\n# emerge --sync --quiet 阅读新闻条目 当同步Portage ebuild 数据库时，Portage 可能会输出类似于下面的信息：\n* IMPORTANT: 2 news items need reading for repository \u0026#39;gentoo\u0026#39;. * Use eselect news to read news items. 创建新闻条目是为了提供一个通信媒介，通过 Gentoo ebuild 数据库来给用户推送重要的消息。可以使用 eselect news 管理新闻条目。eselect 应用程序是一个Gentoo 特有的应用程序，它允许使用通用管理接口来管理系统。在这里，要用到 eselect 的 news 模块。\n对于news模块，最常用的有三个操作：\n 使用list显示一个可用新闻条目的预览。 使用read来阅读新闻条目。 使用purge将在新闻条目阅读后删除，并且不能再次阅读。  # eselect news list # eselect news read # eselect news read --quiet 可以通过新闻阅读器手册页查看更多关于新闻阅读器的信息：\n# man news.eselect 选择正确的配置文件 配置文件是任何一个Gentoo系统的积木。它不仅指定USE、CFLAGS和其它重要变量的默认值，还会锁定系统的包版本范围。这些设定全是由Gentoo的Portage开发者们来维护。\n使用eselect，你能看到当前系统正在使用什么配置文件，现在来使用profile模块：\n# eselect profile list ... [1] default/linux/amd64/17.1 (stable) [2] default/linux/amd64/17.1/selinux (stable) [3] default/linux/amd64/17.1/hardened (stable) [4] default/linux/amd64/17.1/hardened/selinux (stable) [5] default/linux/amd64/17.1/desktop (stable) [6] default/linux/amd64/17.1/desktop/gnome (stable) [7] default/linux/amd64/17.1/desktop/gnome/systemd (stable) [8] default/linux/amd64/17.1/desktop/plasma (stable) [9] default/linux/amd64/17.1/desktop/plasma/systemd (stable) ... 附注：命令的这个输出只是一个示例，并会随时间演变。\n可以看到，一些架构还会有桌面的子配置文件。\nWarning：升级 profile 不能掉以轻心。 选择初始 profile 时，请确保使用与最初使用的 stage3 “相同的版本”（例如 17.1 ）。 每个新的 profile 版本都通过新闻项目公布，新闻项目中包含了迁移说明。 在切换到较新的 profile 之前，请务必阅读并遵循这些内容。\n在看完框架的可用配置文件amd64之后，用户可以键入以下命令为系统选择一个不同的配置文件，比如选择 plasma/systemd：\n# eselect profile set 9 No-multilib\n若要选择没有 32 位应用和类库的纯 64 位环境，请使用一个 no-multilib 的配置文件：\n# eselect profile list Available profile symlink targets: [1] default/linux/amd64/17.1 * [2] default/linux/default/linux/amd64/17.1/desktop [3] default/linux/default/linux/amd64/17.1/desktop/gnome [4] default/linux/default/linux/amd64/17.1/desktop/kde [5] default/linux/default/linux/amd64/17.1/no-multilib 接下来选择no-multilib配置文件：\n# eselect profile set 5 # eselect profile list Available profile symlink targets: [1] default/linux/default/linux/amd64/17.1 [2] default/linux/default/linux/amd64/17.1/desktop [3] default/linux/default/linux/amd64/17.1/desktop/gnome [4] default/linux/default/linux/amd64/17.1/desktop/kde [5] default/linux/default/linux/amd64/17.1/no-multilib * 附注：developer 子配置文件是专用于Gentoo Linux开发，也就是说不是用于普通用户。\n推荐：安装二进制包 对于虚拟机或其他情况，可以选择是否安装二进制包而不是自己从源码开始编译。\n二进制包的提供是目前 Gentoo 的一种实验性质的方案，它的存在能显著缩短整体安装时间，降低机器负载，但目前对二进制包是不存在文件校验的，所以使用它有些许潜在风险。同时，使用二进制包表示将不会对本机有编译优化。（其它的也有可能导致一些需要编译的包出现编译问题）\n另外，如果本地一些包的 [USE标记](# USE标记) 有变动或者一些包的依赖有了变动，那么对于该包， Portage 目前默认会回退到自行编译安装的状态（也推荐这样），在尽可能安装二进制包的同时，也完全不影响正常的使用。\n如果你决定启用这个尚处于实验状态的方案，那么需创建一个文件：\n$ cat \u0026gt; /etc/portage/binrepos.conf [binhost] priority = 9999 sync-uri = https://mirrors.tuna.tsinghua.edu.cn/gentoo/experimental/amd64/binpkg/default/linux/17.1/x86-64/ sync-uri 可以配置成任意所选镜像地址\n再编辑 /etc/portage/make.conf 文件，设置：\nEMERGE_DEFAULT_OPTS=\u0026#34;--binpkg-changed-deps=y --binpkg-respect-use=y --getbinpkg=y\u0026#34; 最终，我的配置为：\n# echo \u0026#39;EMERGE_DEFAULT_OPTS=\u0026#34;--binpkg-changed-deps=y --binpkg-respect-use=y --getbinpkg=y --autounmask --autounmask-keep-masks --autounmask-write=n --keep-going -v -a\u0026#34;\u0026#39; \u0026gt;\u0026gt; /etc/portage/make.conf 配置USE变量 USE是Gentoo为用户提供的最具威力的变量之一。很多程序通过它可以选择编译或者不编译某些可选的支持。例如，一些程序可以在编译时加入对 GTK+或是对Qt的支持。其它的程序可以在编译时加入或不加入对于SLL的支持。有些程序甚至可以在编译时加入对framebuffer的支持（svgalib）以取代X11（X服务器）。\n大多数的发行版会使用尽可能多的支持特性编译它们的软件包，这既增加了软件的大小也减慢了启动时间，而这些还没有算上可能会涉及到的大量依赖性问题。Gentoo可以让你自己定义软件编译的选项，而这正是USE要做的事。\n在USE变量里你可以定义关键字，它被用来对应相应的编译选项。例如，ssl将会把SSL支持编译到程序中以支持它。-X会移除其对于X服务器的支持（注意前面的减号）。gnome gtk -kde -qt4 -qt5将会以支持GNOME（和GTK+）但不支持KDE（和Qt）的方式编译软件，使系统为GNOME做完全调整（如果架构支持）。\n默认的USE设置全放在了系统所使用的Gentoo配置文件的make.defaults文件中。Gentoo对它的配置文件们使用了一个（复杂的）继承系统，在这个阶段我们不去深入。最简单的检查当前活动的USE标记的办法是运行emerge \u0026ndash;info并选择以USE开头的那一行：\n# emerge --info | grep ^USE USE=\u0026#34;X acl alsa amd64 berkdb bindist bzip2 cli cracklib crypt cxx dri ...\u0026#34; 附注：上面的示例被截断了，实际上的USE列表值是非常非常多的。\n可以在系统的 /var/db/repos/gentoo/profiles/use.desc 中找到可用的USE标记的完整描述。\n# less /var/db/repos/gentoo/profiles/use.desc 在less命令中，可以通过使用↑和↓键来滚动，并且可以按q退出。\n作为示例，我们展示一个支持DVD、ALSA,以及CD录制的基于KDE系统的USE设置：\n# nano -w /etc/portage/make.conf USE=\u0026#34;-gtk -gnome qt5 kde dvd alsa cdr\u0026#34; 当USE在/etc/portage/make.conf中定义，会从那个默认列表中添加（或者移除，如果USE标记以-号开头的话）。用户想忽略所有默认的USE设置并完全由自己管理的话，应该在make.conf中定义USE以-*开头：\nUSE=\u0026#34;-* X acl alsa \u0026#34; 警告：由于仔细选择 USE 标志默认值可能会对某些软件包防止冲突和其它错误，所以尽管可以设置 -*（如上例所示），但不鼓励这样做。\n推荐： 配置 ACCEPT_LICENSE 变量 Gentoo 对所有的软件包都使用包所属的许可证进行标记。这允许用户在安装软件之前根据特定的许可证或许可证组来选择软件。\nImportant：ebuild 中 的 LICENSE 变量仅是为 Gentoo 开发人员和用户准备的一份指南。它既不是法律声明，也不保证其真实性。因此不要过度依赖它，您需要深入检查软件包的本身，以及您使用的所有文件。\nPortage 使用 ACCEPT_LICENSE 变量决定那些包允许对之前接受的许可证不提示用户。同样，也可以在 /etc/portage/package.license 中每个包中设置例外。\n在 Gentoo 仓库中定义的许可证组，由 Gentoo Licenses project 项目管理，有：\n   Group Name Description     @GPL-COMPATIBLE GPL compatible licenses approved by the Free Software Foundation   @FSF-APPROVED Free software licenses approved by the FSF (includes @GPL-COMPATIBLE)   @OSI-APPROVED Licenses approved by the Open Source Initiative   @MISC-FREE Misc licenses that are probably free software, i.e. follow the Free Software Definition but are not approved by either FSF or OSI   @FREE-SOFTWARE Combines @FSF-APPROVED, @OSI-APPROVED and @MISC-FREE   @FSF-APPROVED-OTHER FSF-approved licenses for \u0026ldquo;free documentation\u0026rdquo; and \u0026ldquo;works of practical use besides software and documentation\u0026rdquo; (including fonts)   @MISC-FREE-DOCS Misc licenses for free documents and other works (including fonts) that follow the free definition but are NOT listed in @FSF-APPROVED-OTHER   @FREE-DOCUMENTS Combines @FSF-APPROVED-OTHER and @MISC-FREE-DOCS   @FREE Metaset of all licenses with the freedom to use, share, modify and share modifications. Combines @FREE-SOFTWARE and @FREE-DOCUMENTS   @BINARY-REDISTRIBUTABLE Licenses that at least permit free redistribution of the software in binary form. Includes @FREE   @EULA License agreements that try to take away your rights. These are more restrictive than \u0026ldquo;all-rights-reserved\u0026rdquo; or require explicit approval    Gentoo 在配置文件中提供了有预定义的值，默认接受由自由软件基金会明确批准的许可，开源项目或者遵循自由软件定义，例如：\n# portageq envvar ACCEPT_LICENSE @FREE 可以通过更改 /etc/portage/make.conf 来自定义整个系统，使之接受所有许可：\n# echo \u0026#39;ACCEPT_LICENSE=\u0026#34;*\u0026#34;\u0026#39; \u0026gt;\u0026gt; /etc/portage/make.conf 还可以根据需要添加每个软件包的覆盖：\n# nano -w /etc/portage/package.license/kernel app-arch/unrar unRAR sys-kernel/linux-firmware @BINARY-REDISTRIBUTABLE sys-firmware/intel-microcode intel-ucode 更新@world集合 程序的原子指的是由完整类别组成的名称，没有版本和其他的限定符号比如说 net-vpn/openvpn。什么时候会用到原子呢？比如说你要引用一个基于SQLite的数据库 dev-python/axiom 但是这个是和sci-mathematics/axiom 是一个软件包名字这个时候原子就派上用场了。\n可以将多个原子分为一组，从而可以针对整个组来进行操作（比如说重建某个组）。对于这个组有个名字：集合，集合以@作为前缀，其中一些是在Portage里由预先定义的比如说 @system集合包括主要的系统软件包。像是我们安装一个软件包（原子）这个就会记录在 /var/lib/portage/world中 (@world集合包含了@system集合，如果有需要还可以自己定义集合)。将 world 文件复制到其它运行 Gentoo 的电脑上，就可以还原原机器上安装的软件和环境。\n明智的做法是更新系统的 @world set ，以便可以构建系统。\n当系统应用了任何升级，或从 任何profile 构建了stage3 后，应用了变化的 use 标记时，下一步是“必要”的。\n# emerge --ask --verbose --update --deep --newuse @world Tip：如果选择了桌面环境配置文件，则此过程可能大大增加安装过程所需的时间量。 时间紧迫的人可以通过这个“经验法则”工作： 配置文件名称越短，系统的特定属性越少，@world设置的特定性越低，系统将需要的软件包越少。 换一种说法：\n 选择 default/linux/amd64/17.1 将只有很少的包被重装或更新 选择 default/linux/amd64/17.1/desktop/gnome/systemd 将需要安装许多软件包，因为init系统要更改为systemd，并且将安装GNOME桌面环境框架。  可选：使用 OpenRC 作为 init 系统 **本文的后续部分专注于 Systemd 作为默认的 init 系统。**如果读者要安装 GNOME 3.8 及之后版本则必须使用 Systemd。如果需要使用 OpenRC （传统的 Gentoo init 系统），可以阅读官方文档。\n时区 为系统选择时区。在/usr/share/zoneinfo/中查找可用的时区。\n# ls /usr/share/zoneinfo 假设选择的时区是 Asia/Shanghai，生成一个符号链接：\n# ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 稍后，当系统运行时，我们可以使用timedatectl命令配置时区和相关设置。\n配置 locale Locale 生成 大多数用户只想在他们的系统上使用一或两个地区。对于 root 用户而言，一般使用默认的配置即可。但这里需要添加上自己所需其它语言设置以供普通用户使用。\nLocale 不只是指定用户应该使用与系统进行交互的语言，同时也指定了字符串排序，日期和时间的显示等规则。Locale 是 \u0026ldquo;区分大小写\u0026rdquo; 的，必须完全按照描述的方式表示。完整的 locale 可用列表可以在 /usr/share/i18n/SUPPORTED 文件中找到。\n系统支持的 locale 必须在 /etc/locale.gen 文件中定义。\n# \u0026lt;语言\u0026gt;_\u0026lt;国家代码\u0026gt;[@可选的变体].\u0026lt;编码\u0026gt; \u0026lt;编码\u0026gt; 下面的地区是一个示例，展示了同时使用英语（美国）和汉语（中国）及附加字符格式（如UTF-8）。\n# cat \u0026gt;\u0026gt; /etc/locale.gen en_US.UTF-8 UTF-8 zh_CN.UTF-8 UTF-8 警告：我们\u0026quot;强烈\u0026quot;建议添加至少一个UTF-8格式的地区设置，因为许多应用程序也许需要这样才能正确构建。\n下一步是运行 locale-gen 命令。此命令会生成 /etc/locale.gen 文件中所有指定的地区。\n# locale-gen 要验证当前所选择的 locale 可用，可以运行 locale -a。\nLocale 选择 等完成后，我们就来设定系统级别的 locale 设置。我们又一次使用 eselect 来做这件事，现在使用 locale 模块。\n通过 eselect locale list 可显示可用的目标：\n# eselect locale list Available targets for the LANG variable: [1] C [2] C.utf8 [3] POSIX [4] en_US.utf8 [5] zh_CN.utf8 [6] C.UTF8 * [ ] (free form) 可以使用 eselect locale set \u0026lt;NUMBER\u0026gt; 选择正确的 locale：\n# eselect locale set 4 这个还可以通过手动编辑 /etc/env.d/02locale 文件来完成：\nLANG=\u0026#34;zh_CN.UTF-8\u0026#34; LC_COLLATE=\u0026#34;C\u0026#34; 设定 locale 可以避免在后面安装中，内核和软件汇编时的警告和错误。\n现在重新加载环境：\n# env-update \u0026amp;\u0026amp; source /etc/profile \u0026amp;\u0026amp; export PS1=\u0026#34;(chroot) ${PS1}\u0026#34; 完整的本地化指南提供了有关 locale 选择过程的其他指导。另一个有意思的文章是为系统启用 UTF-8 的具体信息的 UTF-8 指南。\n配置Linux内核 安装源码 Linux内核是所有发行版的核心。它位于用户程序和系统硬件之间。Gentoo提供给用户一些可选的内核源码。完整的带描述的列表在内核概述页面。\nGentoo Linux 所提供的可用内核源码包都在 sys-kernel 类下。而其中以下两个个版本更通用：\n  sys-kernel/gentoo-sources\n这是最高到内核主线版本的内核源码包，需要自行配置后，再自行编译后安装\n  sys-kernel/gentoo-kernel\n这是最高到内核主线版本的内核源码包，但同时包含了通用的内核配置，可自动编译后安装\n  针对基于amd64 系统的Gentoo，建议使用包sys-kernel/gentoo-sources。\n选择一个合适的内核并使用emerge来安装它。\n# emerge --ask sys-kernel/gentoo-sources 这将在/usr/src/中安装Linux内核源码。如果在选择的内核源代码包上没有启用USE=symlink，它将不会自己创建一个符号链接。\n通常需要维护/usr/src/linux符号链接，这样它就指向与当前运行的内核相对应的源代码。但是，默认情况下不会创建这个符号链接。创建符号链接的一个简单方法是利用eselect的内核模块。\n关于符号链接的目的以及如何管理它的更多信息，请参阅 Kernel/Upgrade。\n首先，列出所有已安装的内核:\n# eselect kernel list Available kernel symlink targets: [1] linux-4.9.16-gentoo 要创建一个名为linux的符号链接，请使用:\n# eselect kernel set 1 # ls -l /usr/src/linux lrwxrwxrwx 1 root root 12 Oct 13 11:04 /usr/src/linux -\u0026gt; linux-4.9.16-gentoo 现在是时候来配置和编译内核源代码了。有两种方法：\n 手动配置并生成内核。 一个叫作genkernel的工具用来自动化生成并安装Linux内核。  我们在这里解释做为默认选择的手动配置，它是优化环境的最好方式。\n默认：手动配置 介绍 手动配置内核经常被Linux用户认为是最困难的步骤。事实并非如此——但是当您手动配置几次内核之后，你就不会再觉得它有多么难了：）\n无论如何，有一件事是真实的：当手动配置内核时，了解（硬件）系统是至关重要的。大多数信息可以通过安装包含lspci命令的sys-apps/pciutils来收集：\n# emerge --ask sys-apps/pciutils 附注：在chroot中，可以安全的忽略任何lspci可能抛出的关于pcilib的警告（比如pcilib: cannot open /sys/bus/pci/devices）。\n另一个系统信息来源是运行lsmod来查看安装CD使用什么内核模块，它可能对启用什么提供了一个好的暗示。\n现在进入内核源码目录并执行make menuconfig。这将启动一个菜单驱动的配置屏幕。\n# cd /usr/src/linux # make menuconfig Linux内核配置有很多很多的章节。我们先列出一些必须激活的选项（否则Gentoo将无法工作，或者离开附加的调整将无法正常工作）。我们同时在Gentoo维基上有一个Gentoo内核配置指南可能会在将来有帮助。\n激活必要的选项 如果您使用的是 sys-kernel/gentoo-sources，我们强烈建议您启用Gentoo的配置选项。这些确保可以使用适当的功能所需的最低内核功能：\nGentoo Linux ---\u0026gt; Generic Driver Options ---\u0026gt; [*] Gentoo Linux support [*] Linux dynamic and persistent device naming (userspace devfs) support [*] Select options required by Portage features Support for init systems, system and service managers ---\u0026gt; [*] OpenRC, runit and other script based systems and managers [*] systemd 当然，您在最后两行中的选择取决于您的Init系统（OpenRC与Systemd）的选择。\n如果您使用的是 sys-kernel/vanilla-sources, ，您必须自己找到所需的选项。\n确保引导系统的每一个至关重要的驱动（比如SCSI控制器,等等）是编译进内核而不是作为一个模块，否则系统将无法完全引导。\n接下来选择最正确的CPU类型。同时建议启用MCE功能（如果可用）能在硬件出现问题时通知用户。在一些架构（比如x86_64），这些错误不会打印到 dmesg，但是会到/dev/mcelog。这需要app-admin/mcelog包。\n同时选择Maintain a devtmpfs file system to mount at /dev来让重要的设备文件在引导过程的早期就已就绪(CONFIG_DEVTMPFS and CONFIG_DEVTMPFS_MOUNT):\nDevice Drivers ---\u0026gt; Generic Driver Options ---\u0026gt; [*] Maintain a devtmpfs filesystem to mount at /dev [*] Automount devtmpfs at /dev, after the kernel mounted the rootfs 验证 SCSI 磁盘支持是否已激活(CONFIG_BLK_DEV_SD):\nDevice Drivers ---\u0026gt; SCSI device support ---\u0026gt; \u0026lt;*\u0026gt; SCSI disk support 现在进入File Systems并选择你使用的文件系统。不要作为模块来编译根文件系统所使用的文件系统，否则Gentoo系统将不能挂载这个分区。同时选择Virtual memory和*/proc file system*根据系统的需要选择一个或多个以下选项(CONFIG_EXT2_FS, CONFIG_EXT3_FS, CONFIG_EXT4_FS, CONFIG_MSDOS_FS, CONFIG_VFAT_FS, CONFIG_PROC_FS, and CONFIG_TMPFS):\nFile systems ---\u0026gt; \u0026lt;*\u0026gt; Second extended fs support \u0026lt;*\u0026gt; The Extended 3 (ext3) filesystem \u0026lt;*\u0026gt; The Extended 4 (ext4) filesystem \u0026lt;*\u0026gt; Reiserfs support \u0026lt;*\u0026gt; JFS filesystem support \u0026lt;*\u0026gt; XFS filesystem support \u0026lt;*\u0026gt; Btrfs filesystem support DOS/FAT/NT Filesystems ---\u0026gt; \u0026lt;*\u0026gt; MSDOS fs support \u0026lt;*\u0026gt; VFAT (Windows-95) fs support Pseudo Filesystems ---\u0026gt; [*] /proc file system support [*] Tmpfs virtual memory file system support (former shm fs) 如果使用PPPoE连接到互联网，或者是拨号调制解调器，则启用下面的选项(CONFIG_PPP, CONFIG_PPP_ASYNC, and CONFIG_PPP_SYNC_TTY)：\nDevice Drivers ---\u0026gt; Network device support ---\u0026gt; \u0026lt;*\u0026gt; PPP (point-to-point protocol) support \u0026lt;*\u0026gt; PPP support for async serial ports \u0026lt;*\u0026gt; PPP support for sync tty ports 这两个压缩选项将是无害的，但是它们一定是不需要的，包括基于以太网的PPP选项也是一样，只有在配置内核模式PPPoE时才会需要。\n不要忘记在内核中包括网（以太网或无线）卡。\n大多数系统会有多核心处理，所以激活“Symmetric multi-processing support”是重要的' (CONFIG_SMP)：\nProcessor type and features ---\u0026gt; [*] Symmetric multi-processing support 附注：在多核心系统中，每一个核心计作一个处理器。\n如果使用USB输入设备（比如键盘和鼠标）或其他USB设备，不要忘记启用那些(CONFIG_HID_GENERIC and CONFIG_USB_HID, CONFIG_USB_SUPPORT, CONFIG_USB_XHCI_HCD, CONFIG_USB_EHCI_HCD, CONFIG_USB_OHCI_HCD):：\nDevice Drivers ---\u0026gt; HID support ---\u0026gt; -*- HID bus support \u0026lt;*\u0026gt; Generic HID driver [*] Battery level reporting for HID devices USB HID support ---\u0026gt; \u0026lt;*\u0026gt; USB HID transport layer [*] USB support ---\u0026gt; \u0026lt;*\u0026gt; xHCI HCD (USB 3.0) support \u0026lt;*\u0026gt; EHCI HCD (USB 2.0) support \u0026lt;*\u0026gt; OHCI HCD (USB 1.1) support 架构特有的内核配置 如果要支持32位程序，请确保选择IA32 Emulation(CONFIG_IA32_EMULATION)。Gentoo 默认会安装一个multilib 系统（混合 32 位/ 64 位计算），所以除非使用了一个 no-multilib 配置文件，否则这个选项是必需的。\nProcessor type and features ---\u0026gt; [ ] Machine Check / overheating reporting [ ] Intel MCE Features [ ] AMD MCE Features Processor family (AMD-Opteron/Athlon64) ---\u0026gt; ( ) Opteron/Athlon64/Hammer/K8 ( ) Intel P4 / older Netburst based Xeon ( ) Core 2/newer Xeon ( ) Intel Atom ( ) Generic-x86-64 Executable file formats / Emulations ---\u0026gt; [*] IA32 Emulation 如果在分区时使用GPT分区标签，则启用对它的支持 (CONFIG_PARTITION_ADVANCED and CONFIG_EFI_PARTITION)：\n-*- Enable the block layer ---\u0026gt; Partition Types ---\u0026gt; [*] Advanced partition selection [*] EFI GUID Partition support 如果使用UEFI来引导系统，则在内核中启用EFI桩支持和EFI变量 (CONFIG_EFI, CONFIG_EFI_STUB, CONFIG_EFI_MIXED, and CONFIG_EFI_VARS)：\nProcessor type and features ---\u0026gt; [*] EFI runtime service support [*] EFI stub support [*] EFI mixed-mode support Firmware Drivers ---\u0026gt; EFI (Extensible Firmware Interface) Support ---\u0026gt; \u0026lt;*\u0026gt; EFI Variable Support via sysfs 编译和安装 当配置完成，是时间来编译和安装内核了。退出配置并开始编译过程：\n# make \u0026amp;\u0026amp; make modules_install 附注：还可以启用并行生成使用make -jX，X是一个生成过程中所允许运行的并行任务的整数。这类似于早期有关/etc/portage/make.conf的中关于MAKEOPTS变量的介绍。\n当内核完成编译，复制内核镜像到/boot/。这由make install命令来处理：\n# make install 这将复制内核镜像到/boot/，一起的还有System.map文件和内核配置文件。\n可选：生成一个initramfs 在某些情况中需要建立一个initramfs (initial ram file system) ——一个基于内存的初始化文件系统，它用于解决如何在真正初始化系统运行前执行用户空间程序。类似的方案还有一种叫 initrd ，两者功能基本一致，实现方式有差异。\n它代表着一种方案，也代表着一个文件。它在一些基础情况下并不是必须的。\n在说明它存在的意义前，先简单说明下 Linux 系统的基本启动流程：\n PC 加电，BIOS/UEFI 自检后载入系统引导程序 引导程序载入内核 内核挂载根目录所对应的分区 内核执行根目录下系统的初始化（init）命令 自此来到了用户空间下  这个基本的流程里面会出现问题，看步骤 3\n 问题一、如果这个根目录的分区无法直接挂载怎么办（被加密了、使用了 RAID、它是一个 NFS，等情况） 问题二、如果这个根目录的分区下的 /usr 又单独分区了，里面没所需文件怎么办（这个文件夹包含了系统的库文件等）  如果上述两种情况都未出现，那么只要把根目录分区所对应的文件系统驱动被编译进内核（而非模块的形式），就可以省略掉 initramfs ；如果出现了任意一种情况，这个时候就需要 initramfs 的参与。\n正如前文所说， initramfs 提供了在真正系统初始化前提前进入用户空间的功能，它其实就是一个简略版的完整系统，通过它，可以把该解密的分区解密，该挂载的内核无法直接挂载的分区（包括模块未加载，额外的分区，需要联网等情况）都挂载好，之后再由根目录下真正的系统初始化程序接管。\n如果没有initramfs的，存在着巨大的风险，系统将无法正常开机，因为这是负责安装的文件系统工具需要驻留在这些文件系统的信息。 initramfs中的一个将在必要的文件拉进它的内核启动之后使用的档案，但控制被移交前转移到初始化工具。在initramfs的脚本，然后将确保分区正确地安装在系统继续启动之前。\nGentoo Linux 提供了一个工具叫 sys-kernel/genkernel 可用于创建 initramfs，其配置文件位于 /etc/genkernel.conf ，里面对每个变量的设置都有详细的说明。 有别于其它的 initramfs 创建工具， genkernel 会单独编译一个独立的 initramfs 环境（而非直接使用当前系统环境），并打包压缩。这会使得其相对于其它的工具（比如 dracut）创建过程更慢。\n# emerge --ask sys-kernel/genkernel # genkernel --install --kernel-config=/path/to/used/kernel.config initramfs 为了在initramfs中启用特定的支持，比如LVM或RAID，要为genkernel添加一个合适的选项。查看genkernel \u0026ndash;help以获得更多信息。在下面的示例中，我们启用LVM和软件RAID (mdadm) 的支持：\n# genkernel --lvm --mdadm --install --kernel-config=/path/to/used/kernel.config initramfs initramfs将存储在/boot/。结果文件可以简单的通过列出以initramfs开头的文件来找到：\n# ls /boot/initramfs* 现在继续到内核模块。\n备选：localmodconfig 内核是否真的需要自定义配置？这个问题因人而异，有人想要一份精简的内核，有人只要功能完善即可。我个人建议则是，非嵌入式环境下，对内核体积没要求情况下量力而行即可。内核的配置系统太过庞与复杂，理解所有的配置很难。而纯粹使用通用的配置则会导致模块目录太大，无用的模块太多，也不妥。\nmake localmodconfig 生成了一份完整的内核配置文件。此命令的含义是，以当前系统环境为参考，禁用没有被加载的模块配置。可在纯模块加载的系统环境下，接上你有的设备，开启你需要用到的所有服务，然后执行它。一般用于首次配置内核，使得后续配置更轻松。\n而进一步的配置可以在内核目录下使用 make menuconfig 命令打开一个界面化的配置菜单，根据界面内提示进行。也可以执行 make help 显示帮助信息，以方便根据需要自行选择。\n自定义配置时，建议给该配置文件设定一个自定义版本，以便于区分，配置路径位于:\nGeneral setup ---\u0026gt; (-examplename) Local version - append to kernel release 其它的项目本文不会说明，建议查阅 官方内核配置文档 ，其它可查阅的资料有：\n 在界面化的配置菜单界面，选中选项按下 h 后显示的说明 查询硬件设备对应驱动的 Linux-Hardware 站点（英文）： https://linux-hardware.org/index.php?view=search cateee.net 的 Linux 内核驱动数据库（英文）： https://cateee.net/lkddb/web-lkddb/ 金步国针对旧版本内核的配置说明（中文）： http://www.jinbuguo.com/kernel/longterm-linux-kernel-options.html  备选：使用genkernel 如果手动配置看起来太恐怖，建议使用genkernel。它将自动配置并编译内核。\ngenkernel配置内核的工作原理几乎和安装CD配置的内核完全一致。也就是说当使用genkernel建立内核，系统通常将在引导时检测全部硬件，就像安装CD所做的。因为genkernel不需要任何手动内核配置，它对于那些不能轻松的编译他们自动内核的用户来说是一个理想的解决方案。\n现在，我们来看看如何使用genkernel。首先emerge sys-kernel/genkernel这个ebuild：\n# emerge --ask sys-kernel/genkernel 接下来，编辑/etc/fstab文件来使包含有第二个值为/boot/的那条的第一个值指向到正确的设备。如果是按照本手册的分区示例，则这个设备非常像使用ext4文件系统的/dev/sda1。这将使文件中的这一条目看起来像是：\n# nano -w /etc/fstab /dev/sda1\t/boot\text4\tdefaults\t0 2 附注：在Gentoo将来的安装中，还要再配置一次/etc/fstab。现在只需要正确设置/boot来让genkernel应用程序读到相应的配置。\n现在，运行genkernel all来编译内核源码。值得注意的是，使用genkernel编译一个内核将支持几乎全部的硬件，这将使编译过程需要一阵子来完成！\n附注：如果引导分区不是使用ext4作为文件系统，它可能需要使用genkernel \u0026ndash;menuconfig all来手动配置内核，并在内核中添加对这个具体文件系统的支持（比如：不是作为一个模块）。LVM2用户可能要作为参数来添加--lvm。\n# genkernel all 一旦genkernel完成，将创建一个内核、全部的模块和初始化内存文件（initramfs）。我们将在文档后面配置引导器的时候使用这个内核和initrd。记下内核和initrd名字作为编辑引导器配置文件的信息。initrd将在后执行硬件检测之后、“真实”系统启动之前立即启动。\n# ls /boot/kernel* /boot/initramfs* 推荐：二进制 因为内核的配置非常复杂，需根据每台机器的环境而定，为了简单与节约时间，可以选择预编译好的，适用范围最广的二进制内核。\n# emerge --ask sys-kernel/gentoo-kernel-bin sys-kernel/gentoo-kernel-bin 是最高到内核主线版本的内核二进制包，其使用的是最通用的内核配置。\n内核模块 配置模块 附注：硬件模块手动列出是可选的。在大多数情况下，udev通常将加载所有被检测为已连接的硬件模块。然而，列出自动检测到的模块是没有什么不良影响的。有时，一些奇特硬件需要帮助来加载其驱动程序。\n在 /etc/modules-load.d/.conf 中各个模块的每一行列出需要自动加载的模块。如果有必要的话，可以在 /etc/modprobe.d/.conf 文件中，为模块设置添加附加选项。\n要查看所有可用模块，运行下面的find命令。不要忘记替换“\u0026lt;kernel version\u0026gt;”为刚刚编译的内核版本：\n# find /lib/modules/\u0026lt;kernel version\u0026gt;/ -type f -iname \u0026#39;*.o\u0026#39; -or -iname \u0026#39;*.ko\u0026#39; | less 比如，要自动加载3c59x.ko模块（3Com网卡家族的特定驱动），编辑/etc/modules-load.d/network.conf文件并在里面输入模块名字。实际的文件名对 loader 来说无关紧要。\n# mkdir -p /etc/modules-load.d # nano -w /etc/modules-load.d/network.conf 继续到配置系统来安装。\n推荐：安装固件 一些驱动需要先在系统上安装附加的固件才能工作。经常网络接口上会使用，特别是无线网络接口。此外，来自 AMD 、 NVidia 和 Intel 等供应商的现代视频芯片在使用开源驱动程序时，通常也需要外部固件文件。大多数固件都打包在 sys-kernel/linux-firmware 里：\n# emerge --ask sys-kernel/linux-firmware 配置系统 文件系统信息 关于 fstab 在Linux系统下，系统所用到的所有分区都必须在 /etc/fstab文件中指明。这个文件包含了这些分区的挂载点（在系统目录树中的位置）、挂载方法和特殊挂载选项（是否自动挂载，是否某个用户可以挂载它等）。\n创建/etc/fstab文件 /etc/fstab文件使用一种特殊语法格式。每行都包含六个字段。这些字段之间由空白键（空格键，tab键，或者两者混合使用）分隔。每个字段都有自己的含意：\n 第一个字段显示要挂载的特殊 block 设备或远程文件系统。 有几种设备标识符可用于特殊块设备节点，包括设备文件路径，文件系统标签，UUID以及分区标签。 第二个字段是分区挂载点，也就是分区应该挂载到的地方 第三个字段给出分区所用的文件系统 第四个字段给出的是挂载分区时mount命令所用的挂载选项。由于每个文件系统都有自己的挂载选项，我们建议你阅读mount手册（man mount）以获得所有挂载选项的列表。多个挂载选项之间是用逗号分隔的。 第五个字段是给dump使用的，用以决定这个分区是否需要dump。一般情况下，你可以把该字段设为0（零）。 第六个字段是给fsck使用的，用以决定系统非正常关机之后文件系统的检查顺序。根文件系统应该为1，而其它的应该为2（如果不需要文件系统自检的话可以设为0）。  重要：Gentoo 默认提供的 /etc/fstab 不是有效的fstab 文件，它只是提供了几个模板。\n# nano -w /etc/fstab 在文本的其余部分，我们使用默认的块设备 /dev/sd* 文件作为分区。\n分区表和UUIDs\nMBR（BIOS）和GPT都支持“文件系统”标签和“文件系统”的UUID。 这些属性可以在尝试查找和挂载块设备时使用，作为 mount 命令的替代方法，在 /etc/fstab 中定义。文件系统标签和 UUID 由 LABEL 和 UUID 前缀标识，可以使用 blkid 命令查看：\n# blkid 警告：如果分区中的文件系统被擦除，则文件系统标签和UUID值将随后被更改或删除。\n出于唯一性，建议使用 MBR 分区表的读者使用UUID来定义/etc/fstab 中的可挂载卷。\n分区卷标和 UUIDs\n已经使用 GPT 磁盘的用户有一些更稳定的选项可用于在 /etc/fstab 中定义分区。分区卷标和分区 UUID 可以用来标识块设备的单独分区，而不管为分区本身选择了什么文件系统。分区卷标和 UUID 分别由 PARTLABEL 和 PARTUUID 前缀标识，可以通过运行 blkid 命令在终端中很好地查看分区标签：\n# blkid 虽然对于分区表不总是正确的，但使用UUID来标识fstab 中的分区，即使将来文件系统更改，也可以保证在寻找某个卷时引导加载程序不会被混淆。对于经常重新启动并定期添加和删除SATA设备时，在 fstab 中定义分区，使用旧的默认分区文件 (/dev/sd*N非常危险) 。\n块设备文件的命名取决于许多因素，包括磁盘如何以及以什么顺序加载到系统。它们也可能以不同的顺序显示，具体情况取决于在早期启动过程中内核首先检测到哪些设备。 有了这个说明，除非有人打算不断地解决磁盘排序问题，使用默认块设备文件是一个简单和直接的方法。\n让我们来看看如何写下/boot/分区的选项。 这只是一个示例，应根据安装时的具体情况进行修改。 在amd64分区示例中， /boot/ 通常是/dev/sda1 ext4作为文件系统。 它需要在启动期间进行检查，所以我们写下：\n/dev/sda1 /boot ext4 defaults 0 2 有些用户不希望/boot/分区自动挂载，以提高系统的安全性。 他们应该用noauto.代替 defaults。这意味着这些用户将需要在每次他们想要使用它时手动挂载这个分区。\n增加符合你分区方案的规则，为你的光驱（当然，如果你有其他分区或者驱动器，也为它们加上）添加挂载规则。\n下面是/etc/fstab文件的例子（for MBR）：\n/dev/sda1 /boot ext4 defaults,noatime 0 2 /dev/sda2 none swap sw 0 0 /dev/sda3 / ext4 noatime 0 1 /dev/cdrom /mnt/cdrom auto noauto,user 0 0 auto选项可以使mount 猜测文件系统（推荐对于可移动设备采用这个选项，因为它们可能采用很多不同的文件系统），而 user选项使得非root用户可以挂载光驱。\n为了提高性能，大多数用户想要添加 noatime mount选项，这将拥有更快的系统，因为访问时间没有注册（一般不需要这些）。 这也推荐用于固态硬盘（SSD）用户，他们还应该启用discard 安装选项（现在只支持ext4和btrfs），这使得 TRIM命令有效。\n下面是/etc/fstab文件的例子（for GPT）\n# EFI 分区 UUID=\u0026#34;XXXX-XXXX\u0026#34; /boot vfat rw,noatime,errors=remount-ro 0 2 # 交换分区 UUID=\u0026#34;XXXXXXXX-...XXXX\u0026#34; none swap sw 0 0 # 根分区 UUID=\u0026#34;XXXXXXXX-...XXXX\u0026#34; / ext4 defaults,noatime 0 1 仔细检查/etc/fstab文件，保存并退出以继续。\n推荐：genfstab # emerge -av genfstab # genfstab -U / \u0026gt;\u0026gt; /etc/fstab 网络信息 主机名 要设置主机名称，创建/编辑 /etc/hostname ，然后直接输入所需的主机名。\n# echo \u0026#39;SAKAMOTO\u0026#39; \u0026gt; /etc/hostname 当使用 systemd 引导时，存在一个名为hostnamectl的工具，用于编辑/etc/hostname和/etc/machine-info：\n# hostnamectl set-hostname \u0026lt;HOSTNAME\u0026gt; 参考 man hostnamectl 来获得更多选项。\n配置网络 在Gentoo Linux安装时，网络已经配置。然而，这是安装的安装光盘本身的配置，并不是新的系统环境的网络配置。现在你所要设置的是Gentoo系统的永久网络配置。\n附注：更多关于网络配置的详细信息，包括网卡绑定、网桥、802.1Q VLANs和无线网络在内的高级配置会在Gentoo网络配置这一部分介绍。\n使用 systemd-networkd systemd-networkd 在有线网络接口的简单配置上是很有用的。它在默认情况下是禁用的。\n要配置systemd-networkd，在/etc/systemd/network路径下创建一个文件。network请参考systemd.network(5)， 一个简单的DHCP配置如下:\n# nano -w /etc/systemd/network/50-dhcp.network [Match] Name=en* [Network] DHCP=yes 在启动时自动启用网络连接\n# systemctl enable systemd-networkd.service # systemctl start systemd-networkd.service 注意systemd-networkd 默认不会自动更新 resolv.conf ，要 systemd 管理 DNS 设置，替换 resolv.conf 为一个符号连接并启动 systemd-resolved。\n# ln -snf /run/systemd/resolve/resolv.conf /etc/resolv.conf # systemctl enable systemd-resolved.service # systemctl start systemd-resolved.service 推荐：使用 NetworkManager # emerge --ask net-misc/networkmanager # systemctl enable NetworkManager 使用 nmtui 设置：在 IPv4 CONFIGURATION 设置 DNS-servers 为 114.114.114.114，并开启 Ignore automatically obtained DNS parameters。因为它会把路由器ip（192.168.0.1）放在/etc/resolv.conf 第一个，导致ping不通。\nThe hosts file Next inform Linux about the network environment. This is defined in /etc/hosts and helps in resolving host names to IP addresses for hosts that aren\u0026rsquo;t resolved by the nameserver.\n# This defines the current system and must be set 127.0.0.1 tux.homenetwork tux localhost # Optional definition of extra systems on the network 192.168.0.5 jenny.homenetwork jenny 192.168.0.6 benny.homenetwork benny Save and exit the editor to continue.\nRoot 密码 使用passwd命令设置root密码。\n# passwd root帐户是一个功能强大的帐户，因此请选择一个强密码。 稍后将为日常操作创建其他常规用户帐户。\nReset lost root password\n Append the init=/bin/bash kernel parameter to your boot loader\u0026rsquo;s boot entry. Your root file system is mounted as read-only now, so remount it as read/write: mount -n -o remount,rw /. Use the passwd command to create a new password for the root user. Reboot by typing reboot -f and do not lose your password again!  Read-only file system\n# mount -o remount,rw / 安装系统工具 系统日志工具 因为有一些工具提供给用户的功能比较类似，它们就没有包含在stage3当中。现在就是你选择安装哪一个的时候了。\n你首先需要决定的就是系统日志工具。Unix和Linux在日志记录功能方面有良好的传统——如果你愿意的话你可以把系统发生的所有事件都记录到日志文件中。这些功能就是通过系统日志工具来完成的。\nsystemd 提供了自己的日志记录工具，名字叫“ journal”。在运行systemd的系统上，可以选择性的地安装单独的 syslog 程序，并且可能需要进行其他配置才能使syslog 守护进程从日志中读取消息。\nGentoo提供了多种系统日志工具可供选择。包括：\n app-admin/sysklogd -提供传统的系统日志记录守护程序。默认日志配置容易学习，这个包是初学者的好选择。 app-admin/syslog-ng -高级系统记录器。 需要额外配置很多东西， 更高级的用户可以根据它的日志潜力选择这个包; 注意额外的配置是任何种类的智能日志记录的必要条件。 app-admin/metalog -一个可以灵活配置的系统日志工具。  Portage内或许还有其他的系统日志工具——我们的可用软件包数量是以天为单位在增加的。\nTip：如果你打算使用sysklogd或者syslog-ng你很可能会随后希望安装并且配置 logrotate ，因为这些系统日志工具并没有提供系统日志文件的滚动功能。\n可选：Cron守护进程 接下来你可以选择cron守护进程。尽管这是可选的并且不是系统所必须的，但是最好能够安装一个。\ncron守护程序执行计划中的命令。 如果某些命令需要定期执行（例如每天，每周或每月），这是非常方便的。\nGentoo提供了几个可选的cron守护进程： sys-process/bcron, sys-process/dcron, sys-process/fcron, and sys-process/cronie。安装这其中一个的方法和安装一个系统日志工具的方法类似。下面的例子使用sys-process/cronie。\n# emerge --ask sys-process/cronie # systemctl enable cronie 如果使用 dcron，则需要执行额外的初始化命令：\n# crontab /etc/crontab 如果使用 fcron，则需要额外的 emerge 步骤：\n# emerge --config sys-process/fcron 可选：文件索引 如果你想索引你的系统文件使得你能够使用locate工具很快定位它们，你需要安装sys-apps/mlocate。\n# emerge --ask sys-apps/mlocate 可选：远程访问 为了能够在安装后远程访问系统，必须将sshd配置为在启动时启动。\n$ systemctl enable sshd 如果需要串行控制台访问(这在远程服务器的情况下是可能的)，则必须配置agetty。\n$ systemctl enable getty@tty1.service 文件系统工具 根据你所使用的文件系统的不同，你需要安装必须的文件系统工具（用于检查文件系统完整性、创建额外的文件系统等）。请注意管理ext2，ext3和ext4文件系统的工具 (sys-fs/e2fsprogs)已经做为系统的一部分被安装了。\n以下的表格列出了特定文件系统所需要安装的工具。\n   Filesystem Package     Ext 4 sys-fs/e2fsprogs   XFS sys-fs/xfsprogs   ReiserFS sys-fs/reiserfsprogs   JFS sys-fs/jfsutils   VFAT (FAT32, \u0026hellip;) sys-fs/dosfstools   Btrfs sys-fs/btrfs-progs   ZFS sys-fs/zfs    Tip：获取更多关于Gentoo上文件系统的信息请看filesystem article。\n网络工具 如果不需要任何其它网络工具，请立即继续 配置引导程序。\n安装DHCP客户端 重要：虽然可选，但大多数用户会发现他们需要一个DHCP客户端，用来连接到他们网络上的DHCP服务器。 请借此机会安装DHCP客户端。如果忘记此步骤，则系统可能无法访问网络，从而使之后无法下载DHCP客户端。\n为了使系统能够使用netifrc脚本自动获取一个或多个IP地址，需要安装DHCP客户端。 我们建议使用net-misc/dhcpcd，虽然许多其他DHCP客户端可通过Gentoo数据库下载：\n# emerge --ask net-misc/dhcpcd 关于 dhcpcd 的更多信息可以通过 dhcpcd 文章查询。\n可选：安装PPPoE客户端 如果你需要ppp来连接网络，你需要安装它 net-dialup/ppp 。\n# emerge --ask net-dialup/ppp 推荐：安装无线网络工具 如果系统将连接无线网络,请为开放网络或 WEP 网络安装 net-wireless/iw 包，为 WPA 或 WPA2 网络安装 net-wireless/wpa_supplicant 包。iw 也是一个有用的无线网络扫描的基本诊断工具\n# emerge --ask net-wireless/iw net-wireless/wpa_supplicant 现在继续配置引导启动程序。\n配置引导加载程序 选择引导器 完成配置Linux内核、安装系统工具和编辑配置文件之后，现在是时候去安装Linux安装的最后一个重要的部分：引导器。\n引导器负责在引导过程中启动内核——若没有引导器，系统将不知道按下电源键后将如何进行。\n针对amd64，我们编写了如果在基于BIOS的系统上配置GRUB2或LILO，以及针对UEFI系统的GRUB2或efibootmgr。\n在本手册的这一部分中，描述了 \u0026ldquo;emerging\u0026rdquo; 引导加载程序包和 \u0026ldquo;installing\u0026rdquo; 引导加载程序到系统磁盘之间的区别。 这里，术语 \u0026ldquo;emerging\u0026rdquo; 将用于请求 Portage 使软件包安装于系统。 术语 \u0026ldquo;installing\u0026rdquo; 将表示引导加载程序复制文件或物理地修改系统的磁盘驱动器的适当部分，以便在下一次开机时使引导加载程序“激活并准备好操作”。\n默认：GRUB2 默认情况下，Gentoo系统现在主要依赖于GRUB（在sys-boot/grub 包中），它是GRUB Legacy的继任者。无需额外配置，GRUB2就能支持旧的BIOS(\u0026ldquo;pc\u0026rdquo;) 系统。 在安装之前加上少量的配置，Grub2可以支持超过一半的平台。 有关详细信息，请参阅位于GRUB2的先决条件。\nEmerge 当使用只支持MBR分区表的旧版BIOS系统时，无需进行其他配置即可安装GRUB：\n# emerge --ask --verbose sys-boot/grub UEFI用户注意：运行上述命令将在出现之前输出启用的GRUB_PLATFORMS 值。 当使用支持UEFI的系统时，用户需要确保启用 GRUB_PLATFORMS=\u0026quot;efi-64\u0026quot; 参数（默认情况下是这样）。 如果设置不是这样，则需要在安装GRUB2之前将 GRUB_PLATFORMS=\u0026quot;efi-64\u0026quot;添加到/etc/portage/make.conf：\n# echo \u0026#39;GRUB_PLATFORMS=\u0026#34;efi-64\u0026#34;\u0026#39; \u0026gt;\u0026gt; /etc/portage/make.conf # emerge --ask sys-boot/grub 如果GRUB2在未先添加GRUB_PLATFORMS=\u0026quot;efi-64\u0026quot;到make.conf时就已经emerge过，可以添加这一行（像上面显示那样）然后通过--update --newuse options to emerge:选项来重新计算 world package set ：\n# emerge --ask --update --newuse --verbose sys-boot/grub GRUB2现在已经安装到系统中了，但是还没有激活。\n安装 接下来，通过grub-install命令安装GRUB2所需的文件到/boot/grub/目录。假设第一块磁盘（引导系统的那块）是/dev/sda，将使用下面的一条命令：\n使用BIOS时\n# grub-install /dev/sda 使用UEFI时\n重要：确保EFI系统分区在运行grub-install“之前”已经挂载。它可能会使grub-install安装的GRUB EFI文件（grubx64.efi（到一个错误的目录“并且不会”提供“任何”辨识使用错误目录的信息。\n# grub-install --target=x86_64-efi --efi-directory=/boot 附注：当/boot分区没有格式化成vfat时，必须修改 --efi-directory选项到EFI系统分区。如\n# grub-install --target=x86_64-efi --efi-directory=/boot/efi 重要：如果 grub_install 返回了一个错误，类似 Could not prepare Boot variable: Read-only file system，那么为了成功安装，可能必须需要将 efivars 重新挂载为读写：\n# mount -o remount,rw /sys/firmware/efi/efivars 一些主板制造商（包括虚拟机）似乎只支持EFI系统分区（ESP）中.EFI文件的 /efi/boot/目录。 GRUB安装程序可以使用 --removable选项自动执行此操作。 在运行以下命令之前验证是否已安装ESP。 假设ESP安装在/boot（如前所述），执行：\n# grub-install --target=x86_64-efi --efi-directory=/boot --removable 这将创建UEFI规范定义的默认目录，然后将 grubx64.efi 文件复制到由同一规范定义的“默认”EFI文件位置。\n配置 接下来，基于用户在/etc/default/grub文件和/etc/grub.d中特别配置的脚本文件来生成GRUB2。在大多数场景中，不需要由用户来配置，GRUB2就可以自动检测出哪个内核用于引导（位于/boot/中最高的那一个）以及根文件系统是什么。也可以使用GRUB_CMDLINE_LINUX 变量在/etc/default/grub中附加内核参数。\n要生成最终的GRUB2配置，运行grub-mkconfig命令：\n# grub-mkconfig -o /boot/grub/grub.cfg Generating grub.cfg ... Found linux image: /boot/vmlinuz-4.9.16-gentoo Found initrd image: /boot/initramfs-genkernel-amd64-4.9.16-gentoo done 需要注意至少找到一个Linux镜像在命令的输出中，它们是用来引导系统的。如果使用一个initramfs或用genkernel建立内核，同样会检测到正确的initrd 镜像。如果不是这样，进入到/boot/并使用ls命令检查内容。如果文件确实不存在，回到内核配置和安装的介绍。\nTip：os-prober实用程序可与GRUB2配合使用，以检测所连接驱动器上的其他操作系统。可检测到Windows 7, 8.1, 10,和其他Linux发行版。 那些希望双引导系统的应该出现sys-boot/os-prober包，然后重新运行 grub-mkconfig命令（如上所示）。 如果遇到问题，请务必先阅读GRUB2 文章，然后再向Gentoo社区请求支持。\n使用救急控制台 set 用来修改变量，insmod 用来载入模组以添加功能。\n如果 /boot 在单独分区上（例如在用 UEFI 的时候），适当地进行修改：\n注意： 因为 boot 是一个单独的分区而不是根分区的一部分，你得手动把它的地址写清楚，格式和前面的 prefix 一样。\nset root=(hd0,5) linux (hdX,Y)/vmlinuz-linux root=/dev/sda6 initrd (hdX,Y)/initramfs-linux.img boot 可选：启用休眠唤醒 如果之前有分配交换分区，在这里可以执行如下命令以启用其休眠后唤醒的功能\n# sed -Ei \u0026#34;/GRUB_CMDLINE_LINUX_DEFAULT/s/^#*(GRUB.*DEFAULT=).*$/\\1\\\u0026#34;resume=UUID=$(blkid -o value /dev/sdX4 | head -1)\\\u0026#34;/\u0026#34; /etc/default/grub 也可以手动修改，打开 /etc/default/grub 文件：\n 找到 GRUB_CMDLINE_LINUX_DEFAULT 变量 去掉其注释标记 (#) 在其双引号内添加上 resume=UUID=\u0026lt;UUID 值\u0026gt;，　此 \u0026lt;UUID 值\u0026gt; 可由命令 blkid -o value /dev/sdX4 | head -1 显示  最后创建配置 ：\n# grub-mkconfig -o /boot/grub/grub.cfg 可选：多系统 如果电脑存在多系统，可以执行如下步骤添加其它系统的引导菜单选项：\n  给 grub 添加 mount 这个 USE 以满足 os-prober 的依赖\n# echo \u0026#39;sys-boot/grub mount\u0026#39; \u0026gt;/etc/portage/package.use/grub   安装 os-prober 工具\n# emerge -vj os-prober 如果你上面进行了启用休眠唤醒可选操作，更新了 grub 配置文件，那么安装完成后可能会有一个关于 Grub 的配置文件更新提示 IMPORTANT: config file '/etc/default/grub' needs updating. 这个暂时不用理会，也可「更新配置文件」\n  配置 grub 以启用 os-prober 功能\n# echo \u0026#39;GRUB_DISABLE_OS_PROBER=false\u0026#39; \u0026gt;\u0026gt;/etc/default/grub   之后再次运行一次上述的 grub-mkconfig 命令，该命令会自动识别同一机器上其它的系统，并做成引导菜单选项：\n# grub-mkconfig -o /boot/grub/grub.cfg   备选1：LILO Emerge LILO (the LInuxLOader,) 是Linux引导程序的久经考验的主力。但是它缺少GRUB所拥有的一些特性。LILO仍旧在一些系统上被使用的原因是GRUB无法使用但LILO却可以。当然还因为一些人是先认识了LILO而且对它忠心不二。不管怎样，Gentoo可以支持它们两个启动器。\n安装LILO是一件轻而易举的事，使用emerge就可以了。\n# emerge --ask sys-boot/lilo 配置 要配置LILO，首先要创建 /etc/lilo.conf:\n# nano -w /etc/lilo.conf 在配置文件中，小节（sections）被用于指向可引导的内核。请确保内核文件（与内核版本号一起）和initramfs文件都可以被知晓，因为它们都需要被这个配置文件所引用。\nNote：如果根文件系统是JFS，请在每一个引导条目之后增加 append=\u0026quot;ro\u0026quot;因为JFS在它被挂载为可读写之前需要重放它的日志。\nboot=/dev/sda # Install LILO in the MBR prompt # Give the user the chance to select another section timeout=50 # Wait 5 (five) seconds before booting the default section default=gentoo # When the timeout has passed, boot the \u0026quot;gentoo\u0026quot; section compact # This drastically reduces load time and keeps the map file smaller; may fail on some systems image=/boot/vmlinuz-4.9.16-gentoo label=gentoo # Name we give to this section read-only # Start with a read-only root. Do not alter! root=/dev/sda3 # Location of the root filesystem image=/boot/vmlinuz-4.9.16-gentoo label=gentoo.rescue # Name we give to this section read-only # Start with a read-only root. Do not alter! root=/dev/sda3 # Location of the root filesystem append=\u0026quot;init=/bin/bb\u0026quot; # Launch the Gentoo static rescue shell # The next two lines are for dual booting with a Windows system. # In this example, Windows is hosted on /dev/sda6. other=/dev/sda6 label=windows 附注：如果您使用不同的分区方案或内核文件，请根据需要进行调整。\n如果initramfs是必须的，那么就更改配置文件以便引用这个initramfs文件，并且告诉initramfs根设备的所在位置。\nimage=/boot/vmlinuz-4.9.16-gentoo label=gentoo read-only append=\u0026quot;root=/dev/sda3\u0026quot; initrd=/boot/initramfs-genkernel-amd64-4.9.16-gentoo 如果额外的选项需要被传递到内核，使用append语句。例如增加 video 语句来使能framebuffer：\nimage=/boot/vmlinuz-4.9.16-gentoo label=gentoo read-only root=/dev/sda3 append=\u0026quot;video=uvesafb:mtrr,ywrap,1024x768-32@85\u0026quot; 使用 genkernel的用户应该了解他们的内核使用与安装CD相同的引导选项。例如，如果对SCSI设备的支持需要被使能，就增加 doscsi到内核选项中。\n现在保存这个文件并退出。\n安装 为了彻底完成，运行 /sbin/lilo，这样 LILO 就会把 /etc/lilo.conf 中的设置应用到系统中（也就是说安装它自己到磁盘上）。要记住每一次一个新内核被安装或者 lilo.conf 文件被改变后，/sbin/lilo 都需要执行一次，以确保在内核文件名发生改变后系统仍然能够被引导起来。\n# /sbin/lilo 备选2：efibootmgr 在基于UEFI的系统上，系统上的UEFI固件（换句话说，主引导加载程序）可以直接操作以查找UEFI引导条目。 这样的系统不需要具有额外的（也称为辅助）引导加载器，如GRUB2，以帮助引导系统。 据说，基于EFI的引导加载程序（如GRUB2）存在的原因是在引导过程中“扩展”UEFI系统的功能。 使用efibootmgr是真正的那些想要采取一个极简主义（虽然更僵硬的）方法来启动他们的系统; 使用GRUB2（见上文）对于大多数用户更容易，因为它在引导UEFI系统时提供了灵活的方法。\n记住sys-boot/efibootmgr应用程序不是一个引导器，它是一个和UEFI固件相互作用并更新它的设置，因为之前安装的Linux内核可以通过额外的选项（如果需要）来引导，或允许多重引导条目。可以通过EFI变量（需要支持EFI变量的内核）来完成这个相互作用。\n一定要阅读通过 EFI stub内核文章“\u0026lsquo;再继续。 内核必须具有能够被系统的UEFI固件直接引导的特定选项。 可能需要重新编译内核。 看看**efibootmgr** 文章，这也是一个好主意。\n附注：要重申，efibootmgr 不是引导UEFI系统的要求。Linux内核本身就可以启动即引导，其他内核命令行选项可以内置到Linux内核（有一个内核配置选项）允许用户指定启动参数作为命令行选项，甚至initramfs 可以“内置”到内核。\n那些决定采取这种方法的人必须安装软件：\n# emerge --ask sys-boot/efibootmgr 接下来，创建 /boot/efi/boot/，并复制内核文件到这个位置，并叫作bootx64.efi：\n# mkdir -p /boot/efi/boot # cp /boot/vmlinuz-* /boot/efi/boot/bootx64.efi 接下来，告诉UEFI固件创建一个叫作“Gentoo”的引导条目，它拥有全新编译的EFI stub内核：\n# efibootmgr --create --disk /dev/sda --part 2 --label \u0026#34;Gentoo\u0026#34; --loader \u0026#34;\\efi\\boot\\bootx64.efi\u0026#34; 如果使用一个内存文件系统（initramfs），为它添加相应的引导选项：\n# efibootmgr -c -d /dev/sda -p 2 -L \u0026#34;Gentoo\u0026#34; -l \u0026#34;\\efi\\boot\\bootx64.efi\u0026#34; initrd=\u0026#39;\\initramfs-genkernel-amd64-4.9.16-gentoo\u0026#39; 附注：UEFI定义强制要求使用\\作为目录分割符。\n完成这些变更后，当系统重新启动时，会有一个叫作“Gentoo”的引导条目。\n备选3: Syslinux Syslinux是 amd64架构的另一种引导加载程序替代方案。 它不仅支持MBR，从版本6.00开始，它开始支持EFI启动。 还支持PXE（网络）引导和鲜为人知的选项。 尽管Syslinux是许多流行的引导加载程序，但它并没有得到手册的支持。 读者可以在Syslinux文章中找到有关新兴然后安装此引导加载程序的信息。\n备选4：systemd-boot systemd-boot, formerly called gummiboot, is a simple UEFI boot manager capable of booting Linux and Windows in EFI mode.\nNote: As of systemd 220, systemd-boot has been included with systemd (accessible via the bootctl command). If sys-apps/systemd has been installed on the system, then sys-boot/systemd-boot does not need to be installed.\nUEFI boot manager The systemd-boot application makes the installation, which only needs to be performed once (unless a new version of systemd-boot needs to be installed), fairly simple. Verify the following:\n  The system is booted with EFI to start with (either from a EFI compatible media, or through any other UEFI boot manager) as it will otherwise fail to install.\n  The EFI variable file system (efivars) is mounted read/write:\n# mount -t efivarfs efivarfs /sys/firmware/efi/efivars   Then perform the install itself:\n# bootctl --path /boot/efi install The installation will install the proper EFI files so that the EFI-capable system will boot the systemd-boot bootloader.\n重启系统 退出chroot环境并unmount全部已持载分区。然后敲入一条有魔力的命令来初始化最终的、真实的测试：reboot。\n# exit # cd # umount -l /mnt/gentoo/dev{/shm,/pts,} # umount -R /mnt/gentoo # reboot 当然，别忘了移除可引导CD，否则可能再次从CD启动，而不是新的Gentoo系统。\n当重启进全新安装的Gentoo环境，继续完成结束Gentoo安装。\n收尾安装工作 用户管理 添加一个日常使用的用户 在Unix/Linux系统中，用root进行工作是一件危险的事情，应该尽量避免。因此我们强烈推荐您为日常使用添加一个普通用户。\n用户所属的组定义了其可以执行的活动。下表中列出了许多您可能希望使用的重要组：\n   Group Description     audio Be able to access the audio devices.   cdrom Be able to directly access optical devices.   floppy Be able to directly access floppy devices.   games Be able to play games.   portage Be able to access portage restricted resources.   usb Be able to access USB devices.   video Be able to access video capturing hardware and doing hardware acceleration.   wheel Be able to use su.    比如，创建一个叫作larry的wheel、users和audio组的成员用户，首先作为root登录（只有root能创建用户）并运行useradd：\nLogin: root Password: (输入root 密码) # useradd -m -G users,wheel,audio -s /bin/bash larry # passwd larry Password: (输入larry的密码) Re-enter password: (重复输入密码) 如果一个用户仍需要以root身份做一些任务，他们可以使用**su -**来临时得到root权限。另一种方式是使用sudo包，如果配置正确的话，非常安全。\nsudo sudo 使普通用户可以以超级权限执行命令\n# emerge app-admin/sudo 打开配置文件，找到 #%wheel 开头的几行设置，根据说明去掉所需配置行的注释符号\n# visudo 磁盘清理 删除tar包 当Gentoo安装完毕并且系统已经重启过，如果所有事情都完成好了，我们现在要从硬盘上删除下载的stage3的tar包。记住它们下载在/目录。\n# rm /stage3-*.tar.xz 下一步该做什么？ 文档 不知道接下来该做什么？现在有许多途径可以探索…Getoo 为用户提供了大量的可能性，因此也已经在 wiki 和其他与 Gentoo 相关的子域名上提供大量的文档（少量没有），可以通过这些文档来进行探索（参见下面的 [Gentoo 在线](#Gentoo 在线)章节）。\n读者一定要看一下 Gentoo 手册的下一章节使用 Gentoo，讲述了如何保障软件是最新的、如何安装额外的软件包、USE 标记的更多细节、OpenRC init 系统，以及与 Gentoo 系统安装后，管理相关的各种其他信息话题。\n除了这本手册，也鼓励读者去探索Gentoo维基的其他角落来寻找更多的、社区提供的文档。Gentoo wiki 组同时提供一个文档概述，其中按照类别列出了一系列的维基文档。比如，它指向的本地化指南能使系统更有家的感觉（特别适用于以英语为第二语言的用户）。\nGentoo 在线 重要：读者应注意，所有在线的 Gentoo 官方网站均受Gentoo的 行为准则约束。活跃于 Gentoo 社区是一种特权，而不是一种权利，用户应该知道行为准则的存在是有原因的。\n除了 Freenode 托管的因特网中继聊天（ internet relay chat IRC）网络和邮件列表之外，大多数Gentoo 网站要求每个站点都有一个帐户，以便提问、展开讨论或上报 Bug。\n论坛 和 IRC\n欢迎每个用户来我们的 Gentoo 论坛 或我们的 Gentoo 的 因特网中继聊天（ internet relay chat IRC）频道。有很多以前发现的新 Gentoo 安装遇到的问题，在获得一些反馈后得以解决，这些问题的经验可以在论坛中轻松地搜索查看。其他用户第一次使用 Gentoo 遇到安装问题的可能性非常令人惊讶。建议用户在 Gentoo 支持频道寻求帮助之前搜索论坛和 wiki。\n邮件列表\n这些是提供给社区成员的一些邮件列表，他们更愿意通过电子邮件请求支持或反馈，而不是在论坛或IRC上创建用户帐户。用户需要按照说明进行操作，以便订阅特定的邮件列表。\nBugs\n有时，在查看 wiki、搜索论坛、在IRC频道或邮件列表中寻求支持之后，并没有问题已知的解决方案。一般来说，这是在 Gentoo 的 Bugzilla 网站 上报告 bug 的信号。\n开发指南\n希望了解更多有关开发 Gentoo 的读者可以查看开发指南。该指南提供了有关编写 ebuild、使用 eclass 的说明，并提供了 Gentoo 开发中许多基本概念的定义。\n结语 Gentoo 是一个健壮、灵活、维护良好的发行版。开发者社区很高兴听到关于如何使Gentoo 成为一个“更好的”发行版的反馈。\n在此提醒，任何关于 “本手册”的反馈应该按照如何改进手册？章节中开头的详细准则。\n我们期待看到我们的用户将如何选择使用Gentoo！\n显卡驱动 在之前安装 Gentoo Linux 的过程中，二进制内核本身已自带了大多数显卡的内核驱动部分，该部分负责接收用户空间发送的指令及数据，进行处理后传递给显卡。\nmake.conf 对于 X 而言，这里以现代化的 N 卡为例，编辑 /etc/portage/make.conf 文件，双显卡 Intel+NVIDIA 添加以下内容：\n# echo \u0026#39;VIDEO_CARDS=\u0026#34;intel i965 iris nvidia\u0026#34;\u0026#39; \u0026gt;\u0026gt; /etc/portage/make.conf  Intel 的一般设为 intel i965 iris， 详细查阅： https://wiki.gentoo.org/wiki/Intel。 N 卡开源驱动一般设为 nouveau， 详细查阅： https://wiki.gentoo.org/wiki/Nouveau。如若你的显卡是较新的 N 卡，开源驱动还未支持，请安装闭源驱动。 N 卡闭源驱动一般设为 nvidia， 详细查阅： https://wiki.gentoo.org/wiki/NVIDIA/nvidia-drivers。 amdgpu 用于给 X 开启 2D 驱动（X 下必须），radeonsi 用于给 OpenGL 的实现 mesa 开启对内核下 amdgpu 驱动的支持（无论 X 还是 Wayland 均需配置），如果 A 卡比较老，则额外添加 radeon 值，详细查阅： https://wiki.gentoo.org/wiki/AMDGPU。 虚拟机下的驱动设置得具体看，比如现在的 VirtualBox 和 VMWare 都用 vmware 驱动，那么就设置值为 vmware，再比如 QEMU 可选使用 virgl 驱动，那么就设置为 virgl。  在这里，还需将之前配置的普通用户 kurome 添加到 video 组下以使用硬件加速功能。执行\n# gpasswd -a kurome video # or # groupmod -a video -U kurome 驱动 Intel # emerge -av xorg-server xf86-video-intel nvidia # emerge -av nvidia-drivers xrandr 禁用 nouveau：\n# cat \u0026gt;\u0026gt; /etc/modprobe.d/blacklist.conf blacklist nouveau blacklist lbm-nouveau options nouveau modeset=0 要起作用，需要重启。\nNVIDIA/Optimus 注意：请安装完成桌面环境后再来看这部分。\n一般情况下，intel + nvidia 用混合模式。\nxorg.conf For a laptop with Intel integrated graphics and Nvidia discrete graphics, the following xorg.conf should be sufficient:\n# mkdir -p /etc/X11/xorg.conf.d/ # nano /etc/X11/xorg.conf.d/10-nvidia.conf Section \u0026#34;ServerLayout\u0026#34; Identifier \u0026#34;layout\u0026#34; Screen 0 \u0026#34;nvidia\u0026#34; Inactive \u0026#34;intel\u0026#34; EndSection Section \u0026#34;Device\u0026#34; Identifier \u0026#34;nvidia\u0026#34; Driver \u0026#34;nvidia\u0026#34; BusID \u0026#34;01:00:0\u0026#34; Option \u0026#34;RegistryDwords\u0026#34; \u0026#34;EnableBrightnessControl=1\u0026#34; EndSection Section \u0026#34;Screen\u0026#34; Identifier \u0026#34;nvidia\u0026#34; Device \u0026#34;nvidia\u0026#34; Option \u0026#34;AllowEmptyInitialConfiguration\u0026#34; EndSection Section \u0026#34;Device\u0026#34; Identifier \u0026#34;intel\u0026#34; Driver \u0026#34;modesetting\u0026#34; EndSection Section \u0026#34;Screen\u0026#34; Identifier \u0026#34;intel\u0026#34; Device \u0026#34;intel\u0026#34; EndSection 有朋友会问，BusID 是否需要根据自己的改一改，我觉得可能不用，我用过 intel + nvidia 的3台笔记本，这个 BusID 都没有变过，还来自不同厂家，小米，Thinkpad，雷蛇。\n也可以通过如下命令确认一下：\n$ lspci | grep -i --color \u0026#39;vga\\|3d\\|2d\u0026#39; 00:02.0 VGA compatible controller: Intel Corporation UHD Graphics 620 (rev 07) 01:00.0 3D controller: NVIDIA Corporation GM108M [GeForce 930MX] (rev a2) gdm 编辑/usr/share/gdm/greeter/autostart/optimus.desktop 和 /etc/xdg/autostart/optimus.desktop 文件。写入的内容均一样：\n[Desktop Entry] Type=Application Name=Optimus Exec=sh -c \u0026#34;xrandr --setprovideroutputsource modesetting NVIDIA-0; xrandr --auto\u0026#34; NoDisplay=true X-GNOME-Autostart-Phase=DisplayServer sddm 编辑 /etc/sddm.conf 文件，内容如下：\n[X11] DisplayCommand=/etc/sddm/scripts/Xsetup 下面创建一个脚本目录：\n# mkdir -p /etc/sddm/scripts 创建启动脚本，cat \u0026gt; /etc/sddm/scripts/Xsetup ，内容如下：\n#!/bin/sh xrandr --setprovideroutputsource modesetting NVIDIA-0 xrandr --auto 最后赋予权限：\n$ chmod u+x /etc/sddm/scripts/Xsetup 无显示管理器 修改 ~/.xinitrc：\n#!/bin/bash xrandr --setprovideroutputsource modesetting NVIDIA-0 xrandr --auto xrdb -merge ~/.Xresources [ -f ~/.xprofile ] \u0026amp;\u0026amp; source ~/.xprofile exec dbus-launch --exit-with-session startplasma-x11 前两行为必填，后两行为启动X11时同时加载这两个文件。\n编写一个简单脚本：假设名字为 sx.sh\n#!/bin/bash sudo modprobe nvidia_drm nvidia_modeset nvidia \u0026amp;\u0026amp; startx 授权启动\n$ chmod u+x sx.sh $ ./sx.sh KDE KDE 是一个自由软件社区，其提供了一组应用程序，包括流行的 Plasma 桌面环境。\nGentoo对KDE项目的支持非常好，包括对KDE Frameworks 5，Plasma 5和Applications的全面支持，以及其他各种各样基于KDE的软件。\nProfile 在安装心仪的 DE/WM 之前，建议切换到的 desktop profile 下，执行\n# eselect profile list 以列出所有的 profiles，然后进行选择。例如：\nopenrc 下，可以选择\n amd64/17.1/desktop amd64/17.1/desktop/gnome amd64/17.1/desktop/plasma  systemd 下，可以选择\n amd64/17.1/desktop/systemd amd64/17.1/desktop/gnome/systemd amd64/17.1/desktop/plasma/systemd  如若只想安装轻量级的窗口管理器，那么可以选择类似 amd64/17.1/desktop 一样的纯 desktop profile。\n根据本文上下文环境，这里我选择 amd64/17.1/desktop/plasma 以准备好 KDE Plasma 的前期环境\n# eselect profile set 9 虽然 desktop profile 下已经配置启动了基本的 ALSA 声音接口功能，但个人建议再启用 PulseAudio 声音服务器以获得更多功能。只需编辑 /etc/portage/make.conf 文件，设置\necho \u0026#39;USE=\u0026#34;pulseaudio\u0026#34;\u0026#39; \u0026gt;\u0026gt; /etc/portage/make.conf 切换到 desktop profile 并不是一个必须的操作，也可以在基础的 profile 或者其它的 profile 下进行，但如果这样的话，则需要再自行额外配置，会相对复杂一点，此处不多做说明。\nPlasma Plasma 5 是 KDE 正在发展的一代桌面环境，基于 Qt 5 和 KDE Framework 5 。\n安装 kde-plasma/plasma-meta 包提供完整的 Plasma 5 桌面，执行此命令将 plasma-meta 这个元包添加到 world set 中：\n# emerge --ask kde-plasma/plasma-meta 你也可以选择安装 kde-plasma/plasma-desktop，它提供了一个非常基本的桌面，让用户可以自由安装他们需要的额外软件包 - 或者更确切地说，让他们自己找出并补全缺少的功能。\n警告：请注意，仅安装kde-plasma/plasma-desktop会丢失重要的软件包，例如kde-plasma/powerdevil（电源管理，挂起和休眠选项），kde-plasma/systemsettings等等，在这种情况下都不会被支持。\n小工具\nkde-plasma/kdeplasma-addons 提供了很多有用的小工具 (早就被 kde-plasma/plasma-meta作为依赖安装了)：\n# emerge --ask kde-plasma/kdeplasma-addons 显示管理器\nSDDM （Simple Desktop Display Manager） 是被推荐的登录管理器并且它默认会通过 kde-plasma/plasma-meta 被自动安装。 另外你也可以选择使用 LightDM ,这需要为 kde-plasma/plasma-meta 设置 -sddm 的 USE 旗标， 同时还要修改 /etc/conf.d/xdm 中的设置。 同时在发生错误时请阅读 SDDM 页面。\n如果是其它的 DM 也是启用对应的服务即可。\n# systemctl enable sddm.service 无显示管理器\nPlasma 可以用startx以老式方式启动，但需要格外小心以确保它获得有效的会话。创建 ~/.xinitrc 文件：\n#!/bin/sh exec dbus-launch --exit-with-session startplasma-x11 这也可以写入~/.profile文件中，该文件将在登录时执行。\ndbus-launch --exit-with-session startplasma-wayland 系统托盘 Plasma 5 对系统托盘图标使用StatusNotifier规范。由于并非所有应用程序都已移植到新系统，因此需要一些应变方法，并且 Plasma 5 也具有将旧的基于xembed的系统托盘图标转换为StatusNotifier图标的方法。\n通过激活kde-plasma/plasma-meta的 legacy-systray 来启用传统支持，这将引入kde-plasma/xembed-sni-proxy。编辑 /etc/portage/package.use/kde-plasma-settings\n# xembed system tray support for legacy applications kde-plasma/plasma-meta legacy-systray Pidgin net-im/pidgin 需要 x11-plugins/pidgin-indicator。安装完成后，在 工具|插件 下可以找到 Ubuntu 指示器 插件。\nKWallet 在登录桌面后添加一个（无线）网络连接或者在kde-apps/kmail中添加一个电子邮箱账户时，许多用户被推荐使用 kde-frameworks/kwallet —— Plasma桌面的加密密码存储器。\n有个软件包kde-apps/kwalletmanager，可用于管理KWallets，导入及导出密码：\n# emerge --ask kde-apps/kwalletmanager KWallet 自动解锁\nkde-plasma/kwallet-pam 提供了一种机制，可以避免在登录后即被要求访问kwallet。\n# emerge --ask kde-plasma/kwallet-pam 需要如下的配置：\n 为了KWallet的安全性，请使用比较传统的blowfish加密，而不是GPG 在kwallet和用户使用相同的密码 让登录管理器支持PAM特性 - x11-misc/sddm 和 x11-misc/lightdm 都支持  通过SDDM解锁KWallet PAM的配置行，编辑 /etc/pam.d/sddm：\n-auth optional pam_kwallet5.so -session optional pam_kwallet5.so auto_start 附注：对于LightDM， 需要自己编辑/etc/pam.d/lightdm\n附注：如果在登录时，存有你的用户的KWallet文件的文件系统已经被pam_mount挂载，你可能需要将~/.local/share/kwalletd/kdewallet.salt复制到你的根文件系统的相同路径下。否则，PAM会在主目录可用之前尝试解锁KWallet并失败。实际包含加密的KWallet密码的文件~/.local/share/kwalletd/kdewallet.kwl不需要复制。\n禁用 KWallet\n要完全禁用KWallet子系统，请编辑 ~/.config/kwalletrc：\n[Wallet] Enabled=false SSH/GPG 密钥启动/关闭脚本 ssh-agent 脚本位于 /etc/xdg/plasma-workspace/env 和 /etc/xdg/plasma-workspace/shutdown。关闭脚本需要设置可执行位，因为它们不是源。Keychain 提供了更多信息\nUsing keychain with Plasma 5 Keychain is a frontend to ssh-agent and ssh-add, allowing long running sessions and letting the user enter passphases just once. It can also be used to allow scripts access to SSH connections.\n# emerge --ask net-misc/keychain Plasma 5 users, instead of using ~/.bash_profile, can let Plasma manage ssh-agent for them. In order to do so, edit /etc/xdg/plasma-workspace/env/10-agent-startup.sh, which is read during Plasma\u0026rsquo;s startup, and /etc/xdg/plasma-workspace/shutdown/10-agent-shutdown.sh, which is executed during its shutdown.\nHere is how one could edit those files:\nEditing /etc/xdg/plasma-workspace/env/10-agent-startup.sh for Plasma 5\nSSH_AGENT=true Editing /etc/xdg/plasma-workspace/shutdown/10-agent-shutdown.sh for Plasma 5\nif [ -n \u0026#34;${SSH_AGENT_PID}\u0026#34; ]; then eval \u0026#34;$(ssh-agent -k)\u0026#34; fi Now, all that has to be done is launch a terminal of choice, like kde-apps/konsole, and load the right set of keys to use. For example:\n$ keychain ~/.ssh/id_rsa The keys will be remembered until the end of the Plasma session (or until the ssh-agent process is killed manually).\n使用root权限运行 GUI 应用 警告：使用root权限启动 GUI 应用可能是一个 非常 坏的主意。相比之下，更好的办法是将常规用户添加到相应的组或者只是无提权地运行命令。只有在绝对必要时才使用 kdesu 。\nKDE Plasma有一个实用程序，用于以root权限启动图形应用。它由kde-plasma/kde-cli-tools提供 - 要使用 USE 标志kdesu构建。这将会安装kde-frameworks/kdesu的一个图形前端。这依赖Xorg，并且仅在X内有效。编辑 /etc/portage/package.use/kde-plasma-settings\n# Build graphical frontend for kde-frameworks/kdesu (requires X) kde-plasma/kde-cli-tools kdesu X 记得要重建软件包以获取更改：\n# emerge -1 kde-cli-tools 可以通过从KRunner或终端仿真器调用kdesu来使用它：\n# kdesu \u0026lt;program-name\u0026gt; 将显示一个消息对话框，提示输入root密码。\n附注：出于安全原因，某些应用（如kwrite、dolphin等）拒绝使用kdesu打开。\n应用程序 发行版本包含很多基于 Qt 5/KDE Frameworks 5 的应用程序和支持库。\n安装 kde-apps/kde-apps-meta 包提供完整的应用程序集合，但是可替代地，可以挑选其中一个或多个较小的元包。\n个人建议没必要使用默认设置来安装 kde-apps/kde-apps-meta 包，因为会引入太多不常用的应用，建议根据 USE 来管理（下文 USE 标记一节有说明），选择性安装，即\n# echo \u0026#39;kde-apps/kde-apps-meta -*\u0026#39; \u0026gt; /etc/portage/package.use/kdeapps 同时取消 kdecore-meta 的 webengine 依赖，以减少当下的编译时间\n# echo \u0026#39;kde-apps/kdecore-meta -webengine\u0026#39; \u0026gt;\u0026gt; /etc/portage/package.use/kdeapps 安装最核心的 KDE 应用，其它 KDE 应用根据需要安装即可\n# emerge --ask kde-apps/kde-apps-meta 本地化 Plasma-5 和应用程序的每个包都提供了本地化文件。可以在系统设置中启用本地化。\nKDE PIM KDE PIM 是一整套用于管理个人信息的应用程序，包括邮件，日历，联系人等。它有几个可选的运行时依赖来扩展其功能：\n 病毒检测：app-antivirus/clamav 垃圾邮件过滤：mail-filter/bogofilter 或 mail-filter/spamassassin  框架 KDE Frameworks 5 是一套运行库和软件框架的合集，为KDE Plasma 5 和 KDE 应用提供基础，但是可能会受到一些 Qt 程序的影响。\nKDE 框架大部分是运行库，只提供少量的面对用户的功能。它不需要被手动安装 —— 需要的软件包会被作为别的软件包的依赖自动安装。\n更多KDE软件 最主要的 KDE 应用程序在 Porage 树的 kde-apps 和kde-misc 分类中。\nGNOME GNOME 是一个流行的能够启动 Xorg 和 Wayland 会话的 桌面环境 。本指南 尝试描述 GNOME 的所有方面，包括安装、配置和使用。\n从 3.30 版本开始，Gentoo 上的 GNOME 能够再次在 OpenRC 上运行。详情参见 Mart Raudsepp (leio) 的 blog post。\n什么是 GNOME? 项目 GNOME 项目是一个自由的软件组织，它致力于 GNOME 的发展，Unix/Linux 桌面套件和开发平台。 GNOME 基金会协调发展 GNOME 项目的其他方面。\n软件 GNOME 是一个桌面环境和一个开发平台。这款自由软件是包括 Canonical (Ubuntu) 和 Red Hat（Red Hat Linux、Fedora、Centos）在内的多个行业领导者的首选桌面。\n准备 从历史上看，Xorg 显示服务器是 Linux 上所有桌面环境的标准显示基础。对于 GNOME 3 及更高版本，已经开始转向更新的 Wayland 显示服务器协议。NVIDIA 以外的系统在 Wayland 上运行 GNOME 会话没有问题。\n也就是说，退一步讲，最好先阅读并按照 Xorg 指南 中设置 X 环境的说明。\n根据 GNOME 上游的说法，GNOME 3 是用 systemd 初始化系统编写的。因此，systemd 用户最好从 systemd 文章中阅读并遵守所有必要的内核设置。\n安装 在安装 GNOME 套件之前，编辑系统的 USE 变量是个好主意。 Gentoo 开发人员提供了一个 GNOME 特定配置文件，以帮助对 GNOME 软件堆栈进行系统范围的调整。在安装 GNOME 之前选择最新且稳定的 GNOME 特定配置文件。\n使用 logind 的 OpenRC 用户可以选择此特定配置文件：\n# eselect profile set default/linux/amd64/17.1/desktop/gnome systemd 用户将会选择以下 profile：\n# eselect profile set default/linux/amd64/17.1/desktop/gnome/systemd 确保 X、gtk 和 gnome 位于 /etc/portage/make.conf 中的 USE 变量中。 建议启用对 D-Bus 系统范围的支持。 systemd 包括这个系统消息总线。 也将 systemd 添加到 USE 变量（D-Bus 是 GNOME 广泛使用的系统消息总线）。 如果不需要 KDE 支持，请从 USE 中删除 qt5 和 kde。 可以通过在它们前面添加减号 (-) 来删除 USE 标志。 有关正确使用的减号，请参见下面的示例。\nUSE=\u0026quot;-qt5 -kde X gtk gnome systemd\u0026quot; 附注：当使用 desktop/gnome profile, 这些 USE flags将为你设置。\n一旦完成,就由emerge GNOME来安装GNOME，安装一个完整的GNOME，它提供了所有你可能需要的额外的软件包：\n# emerge --ask gnome-base/gnome “最小化”GNOME安装，该选项提供了一个轻量级的GNOME安装没有额外的工具\n# emerge --ask gnome-base/gnome-light 这将需要一段时间，所以要开始阅读我们 wiki 中的其他部分。准备好了么？很好，现在更新环境变量：\n# env-update \u0026amp;\u0026amp; source /etc/profile 接下来剩余的服务和用户组将被清除。\n验证 plugdev 组是否存在。如果是，建议让每个 GNOME 用户成为该组的成员，但这是可选的（该组不再常见）。\n# getent group plugdev plugdev❌104: 取代 \u0026lt;username\u0026gt; 为GNOME用户的用户名:\n# gpasswd -a \u0026lt;username\u0026gt; plugdev 第一印象 现在是时候看看什么是刚刚构建的。退出root 终端并以普通用户身份登录。下一步骤是配置会话管理器，使用GNOMEstartx 命令来调用(请看using startx 在Xorg guide的更多信息)。\n启用 GDM 注：有关 GDM 故障排除的帮助可以在 GNOME/GDM 文章中找到。\nsystemd\n在引导时启动 GDM：\n# systemctl enable gdm.service 要立即启动 GDM，运行：\n# systemctl start gdm.service Tip：以下命令同时启用并立即启动 GDM：\n# systemctl enable --now gdm.service 另一个建议是激活 Network Manager，以防没有其他网络管理服务被激活。\n使用 startx 退出 root shell 并以普通用户身份登录。 下一步是配置会话管理器以在调用 startx 命令时运行 GNOME（有关更多信息，请参阅 Xorg 指南中的使用 startx）。\n# echo \u0026#34;exec gnome-session\u0026#34; \u0026gt; ~/.xinitrc 从 gnome-base/gnome-session-2.26.2 开始，当使用 ~/.xinitrc 方法启动桌面时，用户需要预先添加 XDG_MENU_PREFIX 变量以获取 GNOME 菜单。如果 ~/.xinitrc 没有被使用，它将被自动处理；无需额外的配置。\n# sed -i \u0026#39;1i\\export XDG_MENU_PREFIX=gnome-\u0026#39; ~/.xinitrc 现在开始运行安装的图形环境startx:\n# startx 如果一切顺利GNOME，我们高兴的问候您。祝贺你成功设置GNOME!\n移除 完全删除 GNOME 安装的一种可能方法是明确卸载 gnome-base/gnome 包，然后清除该包的依赖项。\n为了做到这一点，请确保主 ebuild 存储库已同步：\n# emerge --sync 接下来，运行全局更新使系统是全新的：\n# emerge --ask --update --newuse --deep --with-bdeps=y @world 卸载 GNOME 基础包：\n# emerge --ask --depclean gnome-base/gnome 最后，清理系统：\n# emerge --ask --depclean GNOME 现已删除。\nAwesome 简介 awesome 是眾多衍生自 dwm 的 window manager 的其中之一，是一種 tiling window manager。第一次接觸到 tiling wm 是 ion，但是因為設定不容易且用不習慣，一下就放棄了。幾個月前發現時常有人在 Debian Planet 上 awesome, awesome 的嚷嚷，花了點時間才搜尋到這個 wm 的首頁，稍微試用一下卻馬上就被吸引住了！目前的 stable 版本也就是我第一次使用的是 awesome 2.3 版，主打的是簡單的設定檔，良好的 EWMH 支持，XRandr/Xinerama 支持等，還有就是比 virtual desktop 更方便的 tag 用法，動態的 layout 等。噢，還有一個一定要提的就是 widget 的支援，awesome 提供基礎的顯示元件如 text, graph, image 等，可以利用 script 把資訊更新到 widget 上，可以輕鬆的自製 widget。\n2.3 版用的還挺習慣的，widget 雖然需要用 script 去更新資料，但是也有許多人寫好許多模組利用 ruby, perl 或是獨立程式去更新資料。可是在我還在適應期，還沒開始自訂我的環境時，jd 宣佈開始 awesome 3 的開發，要全面使用 XCB 並引入 Lua 作為設定/程式介面。心養養的我就開始使用 git 版的 awesome，awesome 3 因為引入 XCB 幾乎全面改寫，而 Lua 使得 awesome 大部分的操作都便得動態且可以自訂，如 widget 就可以用 Lua 完成，client 的操作、tag 的切換、快捷鍵的設定，通通都可以透過 Lua 設定卻又維持一定的可讀性。因此，awesome 3 的定位變成了進階使用者為主，高度客製化的 framework window manager。\n使用寬螢幕或是大螢幕時，常要調整視窗大小，不容易完全利用到整個螢幕的空間，compiz 等 3d wm 雖然特效絢麗，但是仍比不上 tiling wm 的方便有效率。awesome 推出沒多久就受到許多人的青睞，在這次的 DebConf8 就有數位 DD 使用 awesome 上台演說呢 XD\nawesome 3 預計下禮拜就要釋出了，Debian 的使用者可以直接從 experimental 安裝 3.0~rc5\n從官網節錄的一些特性：\n 目前唯一使用 XCB 的 window manager 良好的文件 所有工作皆可用鍵盤完成 Multihead 支援，可用 XRandR, Xinerama, Zaphod 實做 Freedesktop 標準：EWMH, XDG Base Directory, XEmbed, System Tray 根據不同 tag 的 policy 自動排列視窗 使用 tag 而不是 workspace，可以根據需要選擇要顯示哪些 tag 內的視窗，可以同時選擇多個 tag 可以使用眾多的 Lua 擴充：dynamic tagging, widget feeding, tabs, … D-Bus 支援  awesome 的客製化可以參考 Wiki 以及 Lua api doc\n","permalink":"https://sakamotokurome.github.io/posts/gentooinstallation/","summary":"Gentoo-zh 群推荐安装教程： https://bitbili.net/gentoo-linux-installation-and-usage-tutorial.html https://www.yafa.moe/post/install-gentoo-on-mac/ https://litterhougelangley.life/blog/2021/05/21/gentoo/ https://blog.bugsur.xyz/gentoo-handbook-installation/ 群内如果要贴长文本，可以使用网络粘贴板： \u0026lt;输出命令\u0026gt; | curl -F \u0026#34;c=@-\u0026#34; \u0026#34;https://fars.ee/\u0026#34; 并且将输出里的 url: http://far.se/xxxx 这行贴出来。使用的时候","title":"Gentoo Installation"},{"content":"/ˌoʊpənˈsuːzə/\nDesktop DVD 方式安装   使用其他方式安装系统需要耗费比其他安装方式更多的时间和精力，除非必要，建议优先使用离线的 DVD 镜像进行安装系统。\n  语言选择 English，因为 Linux 需要经常使用 Terminal，中文家目录并不方便。\n  分区 选择默认的 btrfs 文件系统，有需要选择 Guided setup 和 Expert Partitioner。\n  软件包：\n$ sudo zypper in --no-recommends android-tools aria2 qemu-kvm samba goldendict noto-sans-cjk-fonts noto-sans-mono-fonts translate-shell git unrar proxychains-ng kdeconnect-kde tree   镜像源 国内镜像 我们官方的态度是不鼓励直接使用镜像的。\n因为比起「其它」发行版，我们 openSUSE 的技术力量比较强，开发了两个东西。\n一个叫做 Metalink，意思是这个格式（BT、Megalink 磁力链一样的格式）可以自动从 BT/FTP/HTTP 同时下载。\n另一个叫做 MirrorBrain，意思是我把所有的镜像地址隐藏起来，只暴露出一个中央服务器，所有人只需使用这个中央服务器（download.opensuse.org ），它会根据你的 IP 地理位置为你分配一个离你最近的镜像，但是在你那边显示的依旧是来自 download.opensuse.org。而如何分配是根据镜像管理员和中央服务器管理员当初的协定来确定的，比如镜像每月能够承受的流量、所愿意扮演的角色（是区域中心、地标式的镜像比如北交大、中科大，还是小镜像）等。\n而根据 openSUSE 软件源的构造，所有的 RPM 包都是从镜像获得的，所有的 metadata（元数据）都是从主镜像（位于德国）获得的，所以你源刷新的慢，只能证明你被我们光荣伟大的放火长城拖住了，而不能证明 openSUSE 项目有错，也代表不了你下载 RPM 包时的速度。\n更换镜像 你可以使用由 openSUSE 社区开发的测速工具快速查找合适的镜像站。\n  禁用原有软件源\n$ sudo zypper mr -da   添加镜像源\n$ sudo zypper ar -fcg \u0026#39;https://opentuna.cn/opensuse/tumbleweed/repo/oss/\u0026#39; \u0026#39;OPEN-TUNA:CN:OSS\u0026#39; $ sudo zypper ar -fcg \u0026#39;https://opentuna.cn/opensuse/tumbleweed/repo/non-oss/\u0026#39; \u0026#39;OPEN-TUNA:CN:NON-OSS\u0026#39; 命令中最后一个参数为每一个源指定了一个 alias（别称），可以根据个人喜好更改。\nOpenTUNA 镜像站作为 TUNA 镜像的兄弟站，由清华 TUNA 协会运行维护，提供和 TUNA 镜像站基本一致的镜像内容\n  手动刷新软件源\n$ sudo zypper ref   更新 Tumbleweed 无论怎样，下面的内容将完成升级：\n 退出你的桌面环境，在登录管理器中按 CTRL + ALT + F1 进入内核终端界面。 以 root 的身份登录。 输入命令。sudo zypper dup。 处理好任何冲突，然后同意升级。 当升级完成后，输入命令。sudo reboot  Packman 什么是 Packman ？\nopenSUSE 的 Packman 是 Package man 的缩写。意即指一群打包狂组成的团体。他们在尊重并重视版权的基础上做一些规避专利的事。总之，他们想要自由打包从多媒体到大型软件到游戏到甚至是自己的回收站的所有内容。\nPackman 和 openSUSE 的关系\nPackman 不隶属于任何 openSUSE 官方，是独立于 openSUSE 社区之外的社区，只是基于 openSUSE 打给 openSUSE 用的软件包。注意 openSUSE 社区也是官方，同样有在专利法最为严苛的美国和欧洲注册，这也是为什么 OBS 不能打包专利软件的原因，另一个原因是 OBS 的服务器坐落于德国诺伦堡。\nPackman 的资源来自于成员捐献，不能和 openSUSE 官方有任何的联系，也就是说即使是 SuSE 的捐献，也要放弃一切权利。不能像社区董事会那样，主席要由 SuSE 指定，一般是 SuSE 员工。\nPackman 欢迎大学和社区为它做镜像。\nPackman 收纳什么样的软件 ？\n由于英文的 free 很有迷惑性（大部分外国人喜欢用法语 Libre，也就是自由）：\n 这里的自由，仍然不包括商业和私有软件，版权产品应该尊重他们自有的分发渠道。也就是说，这里仍然不做盗版，也不做免费使用的商业软件。不规避版权，只规避专利。版权同样是保护 Linux 下的开源作品不被盗版的力量，而专利则是大公司用来牟利的工具。 这里只接纳由于或有专利纠纷而不能存在于官方构建服务中的软件。比如 FFMPEG，MPLAYER，MP3, AMULE。和依赖它们的软件。以及可以自由分发的软件，并且愿意允许从源代码编译。  也就是说，大部分时候这里的软件都是 FOSS/LOSS （自由和开源软件），而不是免费软件。而且是存在或有专利纠纷的软件，想想看什么软件最容易发生专利纠纷呢？ 多媒体。于是 Packman 里有那么多多媒体软件也就不奇怪了。\n另外 Packman 还允许两类软件：发行版中长期不更新的软件的最新版，和发行版中没有的软件。但这是 FTP 做源的时代延续下来的。目前这两类软件都建议走 OBS 流程来做，因为 OBS 的服务器比 Packman 的多快好省。\n启用 Packman 源 国内可用的 Packman 镜像列表：Packman/镜像列表，配置方法详见：添加镜像源。\nopenSUSE Tumbleweed 用户：\n$ sudo zypper ar -cfp 90 https://mirrors.ustc.edu.cn/packman/suse/openSUSE_Tumbleweed/ packman $ sudo zypper ref Multimedia Codecs openSUSE 默认是没有部分多媒体编解码器的，包括家喻户晓的 MP3、AVI 等。这是因为它们是受限媒体格式。具体解释见openSUSE 编解码器一键安装、常见编解码器对应软件包/源说明、及版权须知。\n通过 Packman 安装解码器：如果不使用 VLC 可以省略 vlc-codecs。\n$ sudo zypper refresh $ sudo zypper dist-upgrade --from packman --allow-vendor-change $ sudo zypper install --from packman ffmpeg gstreamer-plugins-{good,bad,ugly,libav} libavcodec-full vlc-codecs 或者通过 opi 安装：\n$ sudo zypper in opi \u0026amp;\u0026amp; opi codecs or, In order to install the H264/AVC support on your system, type in:\n$ sudo zypper install x264 libx265-130 libx264-148 软件管理 更新/刷新进程被占用 在 System Tray Setting 里面关闭 Software Updates 的通知。\n如果你不需要自动更新，或者不需要 Packagekit 本身，你首先可以考虑:\n$ sudo systemctl mask packagekit.service #屏蔽 Packagekit 服务 或者卸载该软件：\n$ sudo zypper rm Packagekit 取消推荐的软件包 \u0026amp; 删除模组 打开 YaST ，点击 软件管理 ，再点击左上角的 依赖项 ，取消勾选 安装被推荐的软件包 。这样你的电脑就不会在某次更新后出现一些不是你主动安装的软件包。\n在 软件管理 页面，点击 视图，选择 模组 ，然后你就能看到按模组分类的包。例如你可以在此页面直接用鼠标右键单击 游戏 ，选择 不安装 或 卸载，卸载全部的预装的 KDE/Gnome 游戏包。\nOBS Package Installer 如果你想在终端直接查找来自 OBS 的软件包，你可以先安装 opi\n$ sudo zypper in opi 然后输入你想要查找的软件包的名称，例如你要安装 qbittorrent enhanced edition ，你可以：\n$ opi qbittorrent 中文社区源 openSUSE 中文社区的开发者们为用户构建、打包和收录一些发起自中文 Linux 圈子的软件或中文 Linux 圈子常用的软件。详见：\n openSUSE for Chinese Users Project   输入法 在Yast中安装第二语言，就会自动安装fcitx并添加中文支持，但是这种方案安装的东西很多。\nibus $ sudo zypper in ibus ibus-rime $ vim .bashrc export GTK_IM_MODULE=ibus export XMODIFIERS=@im=ibus export QT_IM_MODULE=ibus $ ibus-daemon -x -d Fcitx5 $ sudo zypper in --recommends fcitx5 fcitx5-chinese-addons 设置主题：Setting -\u0026gt; Location -\u0026gt; input method -\u0026gt; Configure addons -\u0026gt; Classic user interface -\u0026gt; Theme.\n输入法最好使用 \u0026ndash;recommends，否则会遇到很多麻烦，比如要手动安装 kcm_fcitx5，第三方软件（Typora、Chrome）不能使用中文等。一些相关信息如下：\n$ cat /etc/xdg/autostart/org.fcitx.Fcitx5.desktop $ cat /usr/etc/X11/xim.d/fcitx5 #make sure set these vars before dbus-launch export LC_CTYPE=$LANG export XMODIFIERS=\u0026#34;@im=fcitx5\u0026#34; export GTK_IM_MODULE=fcitx5 export QT_IM_SWITCHER=imsw-multi export QT_IM_MODULE=fcitx5 ... 打包信息详见openSUSE:Factory/fcitx5 \n词库 Fcitx 的 Libpinyin 可以直接在线导入搜狗细胞词库。不需要安装sougou输入法。\n需要安装 fcitx-pinyin-tools/fcitx-table-tools 这两个包，以添加处理词库的工具。\n$ sudo zypper in fcitx-pinyin-tools fcitx-table-tools 词库少了的话，也不好用，但是一次只能导入一个细胞词库。网上可以找到比较全的词库包。\n通过 7zr 解压过后将所有 txt 词库拷贝到 ~/.config/fcitx/libpinyin/importdict 即可。\n$ 7zr x txt.7z cloudpinyin 根据文档，可以使用 libpinyin + cloudpinyin，哪怕不用导入词典，依旧很好用。果然，还是云词库的力量强大。\n$ sudo zypper in fcitx-cloudpinyin 默认的云输入引擎是 Google ，国内直接访问很不流畅，你可以打开输入法的配置，点击 Addon Config，找到 Cloud Pinyin ，点击右侧的设置，在弹出的窗口中，将 Google 替换为 Baidu 。\nNVIDIA 有两种为英伟达（NVIDIA）显卡提供的驱动：\n 为 NVIDIA 硬件提供的自由开源的驱动名叫 nouveau。 来自 NVIDIA 厂商自己的驱动名为 nvidia，但由于许可证问题，它不能直接被集成进入 openSUSE 。  如果你没有特别的需求，NVIDIA 的闭源驱动不是必须安装的。持有 NVIDIA 独立显卡之类厂商只提供闭源驱动的硬件的 Tumbleweed 用户请不要过于频繁地更新系统，闭源驱动可能会因为内核版本太新缺乏适配而崩溃。\n安装 将你的系统更新至最新的版本。\n$ sudo zypper dup 添加 Nvdia 软件源\n$ sudo zypper addrepo --refresh https://download.nvidia.com/opensuse/tumbleweed NVIDIA 获取架构信息\n$ sudo hwinfo --gfxcard | grep Model 确定安装的驱动类型\n$ sudo zypper se x11-video-nvidiaG0* $ sudo zypper se -s x11-video-nvidiaG0* 要利用 OpenGL 加速，你必须安装一个附加包，选择与驱动程序对应的包\n$ sudo zypper se nvidia-glG0* 安装：\n$ sudo zypper in x11-video-nvidiaG06 nvidia-glG06 最后，重启电脑确认是否加载\n$ sudo lsmod | grep nvidia 画面撕裂 出现此种情况，你必须打开 “PRIME同步” 功能：\n 创建文件  $ sudo echo \u0026#34;options nvidia_drm modeset=1 \u0026#34; \u0026gt; /etc/modprobe.d/nvidia-drm-nomodeset.conf 执行代码：  $ sudo dracut -f 重启\n注意： 在某些情况下，修改此配置可能会导致图形界面无法进入，若出现此情况，请进入重启后进入恢复模式，执行 sudo rm /etc/modprobe.d/nvidia-drm-nomodeset.conf ，然后执行 dracut -f ，然后重启\nAudacious 一个设计简洁，功能强大，支持多种格式的无损播放器。\n$ sudo zypper in audacious OpenZFS openSUSE Tumbleweed\n$ sudo zypper ar https://download.opensuse.org/repositories/filesystems/openSUSE_Tumbleweed/filesystems.repo $ sudo zypper ref $ sudo zypper in zfs 装入 NTFS 分区   安装 ntfs-3g。\nsudo zypper in ntfs-3g   创建一个要充当安装点的目录，如 ~/mounts/windows。\nmkdir ~/mounts/windows   确定所需的 Windows 分区。\nsudo fdisk -l   以读写模式装入分区。使用相应的 Windows 分区替换占位符 DEVICE：\nntfs-3g /dev/DEVICE MOUNT POINT 要在只读模式下使用 Windows 分区，请追加 -o ro\nntfs-3g /dev/DEVICE MOUNT POINT -o ro ntfs-3g 命令使用当前用户 (UID) 和组 (GID) 装入给定设备。如果要为其他用户设置写权限，请使用命令 id  USER 获取 UID 和 GID 值的输出。设置方式：\nid usernamentfs-3g /dev/DEVICE MOUNT POINT -o uid=1000,gid=100   要卸载资源，请运行 fusermount -u 安装点。\n  ntfs-3g 与 ntfs3 Linux Kernel 5.15 合并了 Paragon 提供的 NTFS3 内核驱动， 拥有更高的性能和更多的特性\n总结：内核驱动开销变低, 读取性能有所提升，写入性能大幅提升，不考虑硬盘速度的话，写入速度接近10x\nSystem Settings 任务栏透明化 Go to System Settings | Window Management | Window Rules. Press New\u0026hellip; button. Give some description to the new rule, Dock Transparency, for example. Then select only Dock (panel) in \u0026ldquo;Window type\u0026rdquo; field.\n之后在 Appearance \u0026amp; Fixes 中调整 opacity。\n使用 24 小时制 点击桌面右侧的时间 =\u0026gt; 点击弹出面板的左上角 Config Digital Clock =\u0026gt; Appearance 的 Time display 设置为 24 小时（但是窗口管理器还是12小时制）。\n主题 不是我喜欢黑暗主题，而是热门的好看的主题都是黑暗主题。所以尝试如下：\n 全局黑暗主题为 Sweet chrome 黑暗主题  系统设置 Theme 使用 GTK+，可以使标题栏，设置菜单栏为黑暗，但是网页、设置页为白色。 Chrome 黑暗模式：在网址栏输入 chrome://flags/#enable-force-dark，启用。可以使设置页面黑暗，网页黑暗，但是进入 segmentfault，你会发现 segment 不见了（即表现不好）。 安装 dark reader 插件。可以使网页黑暗，比 chrome 自带表现要好。但是打开新页面时，还是有短暂的白色。   Firefox 黑暗主题  设置页的颜色会与系统一致，也就是与 chrome 相反。 firefox theme 会改变标题栏、设置菜单栏颜色。    实际上你会发现，无法达到一致的黑暗，反而使得眼睛不舒服，所以我放弃了黑暗主题。\n亮色混合主题：\n Global Theme 为 openSUSE Plasma 为 Edna-light Window Decorations 为 Edna-light Font 为 Source Hans Sans CN 和 Jet Brains Moon Icon 为 Papirus SSDM Theme 为 chili for plasma kconsole 主题为 sweet 开始改为 application dashboard  实际你会发现，混合主题没有一个单独主题搭配的那么协调。\n窗体内容亮色，其他部分为黑暗，即标准主题:\n 全局主题 Sweet Colors 为 Breeze，使得 window 内容为亮色 Window Decorations 为 sweet-dark-transparent，设置标题栏 Icon 为 Papirus SSDM Theme 为 sweet fcitx 为 dartmouth。  感觉可以。\nDesktop Effects：\n Magic Lamp 400ms Wobbly Windows  不如不要。\nKDE Wallet 在每次重装或者配置桌面后kdewallet总是在登陆系统之后提示输入密码，虽然在输入密码后能够继续正常使用，但是每次登陆系统都需要输入一次密码还是很烦人的。\n出现的原因：\n在重新配置桌面或者重装系统之后KDE Wallet所需要的一些必备需要依赖组件未能找到，所以导致不能正确运行KDE Wallet，所以只要安装其所需的组件即可。而其所需的但是未能自动安装的依赖组件正是 pam_kwallet，kwallet-pam 与 GnuPG keys 不兼容，所以 KDE Wallet 必须使用 blowfish 加密方式。\n解决方案 ：\n安装缺失的组件\n$ sudo zypper in pam_kwallet 为了保险起见，查看个人目录下是否存在~/.kde4/share/apps/kwallet文件夹，如果存在则将其删除或者重命名以避免出现冲突，并且还需要确定使用的钱包名为kdewallet并且密码为当前用户的密码。\n如此便可完全正常使用KDE Wallet\n解决方案参考arch wiki的KDE Wallet小节中。\nSwitching desktops Q: Disabling mouse scroll-wheel switching between virtual desktops\nA: Right-click the desktop -\u0026gt; Configure Desktop and Wallpaper\u0026hellip; -\u0026gt; Mouse actions -\u0026gt; \u0026ldquo;vertical scrollwheel: Standard Menu\u0026rdquo;\nQkular: Dark Mode Configure Qkular =\u0026gt; Accessibility =\u0026gt; Color mode =\u0026gt; Invert color\nSpectacle: clipboard Configure =\u0026gt; General =\u0026gt; after taking a screenshot =\u0026gt; Copy image to clipboard\nSystem Btrfs 文件系统似乎是内核中比较稳定的部分，多年来，人们一直使用 ext2/3，ext 文件系统以其卓越的稳定性成为了事实上的 Linux 标准文件系统。近年来 ext2/3 暴露出了一些扩展性问题，于是便催生了 ext4 。在 2008 年发布的 Linux2.6.19 内核中集成了 ext4 的 dev 版本。 2.6.28 内核发布时，ext4 结束了开发版，开始接受用户的使用。似乎 ext 就将成为 Linux 文件系统的代名词。然而当您阅读很多有关 ext4 的文章时，会发现都不约而同地提到了 btrfs，并认为 ext4 将是一个过渡的文件系统。 ext4 的作者 Theodore Tso 也盛赞 btrfs 并认为 btrfs 将成为下一代 Linux 标准文件系统。 Oracle，IBM， Intel 等厂商也对 btrfs 表现出了极大的关注，投入了资金和人力。为什么 btrfs 如此受人瞩目呢。这便是本文首先想探讨的问题。\nKevin Bowling 有一篇介绍各种文件系统的文章，在他看来，ext2/3 等文件系统属于“古典时期”。文件系统的新时代是 2005 年由 Sun 公司的 ZFS 开创的。 ZFS 代表” last word in file system ”，意思是此后再也不需要开发其他的文件系统了。 ZFS 的确带来了很多崭新的观念，对文件系统来讲是一个划时代的作品。\n如果您比较 btrfs 的特性，将会发现 btrfs 和 ZFS 非常类似。也许我们可以认为 btrfs 就是 Linux 社区对 ZFS 所作出的回应。从此往后在 Linux 中也终于有了一个可以和 ZFS 相媲美的文件系统。\nBtrfs 的特性 您可以在 btrfs 的主页上看到 btrfs 的特性列表。我自作主张，将那张列表分成了四大部分。\n首先是扩展性 (scalability) 相关的特性，btrfs 最重要的设计目标是应对大型机器对文件系统的扩展性要求。 Extent，B-Tree 和动态 inode 创建等特性保证了 btrfs 在大型机器上仍有卓越的表现，其整体性能而不会随着系统容量的增加而降低。\n其次是数据一致性 (data integrity) 相关的特性。系统面临不可预料的硬件故障，Btrfs 采用 COW 事务技术来保证文件系统的一致性。 btrfs 还支持 checksum，避免了 silent corrupt 的出现。而传统文件系统则无法做到这一点。\n第三是和多设备管理相关的特性。 Btrfs 支持创建快照 (snapshot)，和克隆 (clone) 。 btrfs 还能够方便的管理多个物理设备，使得传统的卷管理软件变得多余。\n最后是其他难以归类的特性。这些特性都是比较先进的技术，能够显著提高文件系统的时间 / 空间性能，包括延迟分配，小文件的存储优化，目录索引等。\n扩展性相关的特性 B-Tree\nbtrfs 文件系统中所有的 metadata 都由 BTree 管理。使用 BTree 的主要好处在于查找，插入和删除操作都很高效。可以说 BTree 是 btrfs 的核心。\n一味地夸耀 BTree 很好很高效也许并不能让人信服，但假如稍微花费一点儿时间看看 ext2/3 中元数据管理的实现方式，便可以反衬出 BTree 的优点。\n妨碍 ext2/3 扩展性的一个问题来自其目录的组织方式。目录是一种特殊的文件，在 ext2/3 中其内容是一张线性表格。\n图中展示了一个 ext2 目录文件的内容，该目录中包含四个文件。分别是 \u0026ldquo;home1\u0026rdquo;，\u0026ldquo;usr\u0026rdquo;，\u0026ldquo;oldfile\u0026rdquo; 和 \u0026ldquo;sbin\u0026rdquo; 。如果需要在该目录中查找目录 sbin，ext2 将遍历前三项，直至找到 sbin 这个字符串为止。\n这种结构在文件个数有限的情况下是比较直观的设计，但随着目录下文件数的增加，查找文件的时间将线性增长。 2003 年，ext3 设计者开发了目录索引技术，解决了这个问题。目录索引使用的数据结构就是 BTree 。如果同一目录下的文件数超过 2K，inode 中的 i_data 域指向一个特殊的 block 。在该 block 中存储着目录索引 BTree 。 BTree 的查找效率高于线性表，\n但为同一个元数据设计两种数据结构总是不太优雅。在文件系统中还有很多其他的元数据，用统一的 BTree 管理是非常简单而优美的设计。\nBtrfs 内部所有的元数据都采用 BTree 管理，拥有良好的可扩展性。 btrfs 内部不同的元数据由不同的 Tree 管理。在 superblock 中，有指针指向这些 BTree 的根。如图 2 所示：\nFS Tree 管理文件相关的元数据，如 inode，dir 等； Chunk tree 管理设备，每一个磁盘设备都在 Chunk Tree 中有一个 item ； Extent Tree 管理磁盘空间分配，btrfs 每分配一段磁盘空间，便将该磁盘空间的信息插入到 Extent tree 。查询 Extent Tree 将得到空闲的磁盘空间信息； Tree of tree root 保存很多 BTree 的根节点。比如用户每建立一个快照，btrfs 便会创建一个 FS Tree 。为了管理所有的树，btrfs 采用 Tree of tree root 来保存所有树的根节点； checksum Tree 保存数据块的校验和。\n基于 Extent 的文件存储\n现代很多文件系统都采用了 extent 替代 block 来管理磁盘。 Extent 就是一些连续的 block，一个 extent 由起始的 block 加上长度进行定义。\nExtent 能有效地减少元数据开销。为了进一步理解这个问题，我们还是看看 ext2 中的反面例子。\next2/3 以 block 为基本单位，将磁盘划分为多个 block 。为了管理磁盘空间，文件系统需要知道哪些 block 是空闲的。 Ext 使用 bitmap 来达到这个目的。 Bitmap 中的每一个 bit 对应磁盘上的一个 block，当相应 block 被分配后，bitmap 中的相应 bit 被设置为 1 。这是很经典也很清晰的一个设计，但不幸的是当磁盘容量变大时，bitmap 自身所占用的空间也将变大。这就导致了扩展性问题，随着存储设备容量的增加，bitmap 这个元数据所占用的空间也随之增加。而人们希望无论磁盘容量如何增加，元数据不应该随之线形增加，这样的设计才具有可扩展性。\n下图比较了 block 和 extent 的区别：\n在 ext2/3 中，10 个 block 需要 10 个 bit 来表示；在 btrfs 中则只需要一个元数据。对于大文件，extent 表现出了更加优异的管理性能。\nExtent 是 btrfs 管理磁盘空间的最小单位，由 extent tree 管理。 Btrfs 分配 data 或 metadata 都需要查询 extent tree 以便获得空闲空间的信息。\n动态 inode 分配\n为了理解动态 inode 分配，还是需要借助 ext2/3 。下表列举了 ext2 文件系统的限制：\n限制最大文件数量文件系统空间大小 V / 8192\n比如 100G 大小的文件系统中，能创建的文件个数最大为 131072\n下图显示了 ext2 的磁盘布局：\n在 ext2 中 inode 区是被预先固定分配的，且大小固定，比如一个 100G 的分区中，inode table 区中只能存放 131072 个 inode，这就意味着不可能创建超过 131072 个文件，因为每一个文件都必须有一个唯一的 inode 。\n为了解决这个问题，必须动态分配 inode 。每一个 inode 只是 BTree 中的一个节点，用户可以无限制地任意插入新的 inode，其物理存储位置是动态分配的。所以 btrfs 没有对文件个数的限制。\n针对 SSD 的优化支持\nSSD 是固态存储 Solid State Disk 的简称。在过去的几十年中，CPU/RAM 等器件的发展始终遵循着摩尔定律，但硬盘 HDD 的读写速率却始终没有飞跃式的发展。磁盘 IO 始终是系统性能的瓶颈。\nSSD 采用 flash memory 技术，内部没有磁盘磁头等机械装置，读写速率大幅度提升。 flash memory 有一些不同于 HDD 的特性。 flash 在写数据之前必须先执行擦除操作；其次，flash 对擦除操作的次数有一定的限制，在目前的技术水平下，对同一个数据单元最多能进行约 100 万次擦除操作，因此，为了延长 flash 的寿命，应该将写操作平均到整个 flash 上。\nSSD 在硬件内部的微代码中实现了 wear leveling 等分布写操作的技术，因此系统无须再使用特殊的 MTD 驱动和 FTL 层。虽然 SSD 在硬件层面做了很多努力，但毕竟还是有限。文件系统针对 SSD 的特性做优化不仅能提高 SSD 的使用寿命，而且能提高读写性能。 Btrfs 是少数专门对 SSD 进行优化的文件系统。 btrfs 用户可以使用 mount 参数打开对 SSD 的特殊优化处理。\nBtrfs 的 COW 技术从根本上避免了对同一个物理单元的反复写操作。如果用户打开了 SSD 优化选项，btrfs 将在底层的块空间分配策略上进行优化：将多次磁盘空间分配请求聚合成一个大小为 2M 的连续的块。大块连续地址的 IO 能够让固化在 SSD 内部的微代码更好的进行读写优化，从而提高 IO 性能。\n数据一致性相关的特性 COW 事务\n理解 COW 事务，必须首先理解 COW 和事务这两个术语。\n所谓 COW，即每次写磁盘数据时，先将更新数据写入一个新的 block，当新数据写入成功之后，再更新相关的数据结构指向新 block 。\nCOW 只能保证单一数据更新的原子性。但文件系统中很多操作需要更新多个不同的元数据，比如创建文件需要修改以下这些元数据：\n 修改 extent tree，分配一段磁盘空间 创建一个新的 inode，并插入 FS Tree 中 增加一个目录项，插入到 FS Tree 中  任何一个步骤出错，文件便不能创建成功，因此可以定义为一个事务。\n下面将演示一个 COW 事务。\nA 是 FS Tree 的根节点，新的 inode 的信息将被插入节点 C 。首先，btrfs 将 inode 插入一个新分配的 block C ’中，并修改上层节点 B，使其指向新的 block C ’；修改 B 也将引发 COW，以此类推，引发一个连锁反应，直到最顶层的 Root A 。当整个过程结束后，新节点 A ’变成了 FS Tree 的根。但此时事务并未结束，superblock 依然指向 A 。\n接下来，修改目录项（E 节点），同样引发这一过程，从而生成新的根节点 A ’’。\n此时，inode 和目录项都已经写入磁盘，可以认为事务已经结束。 btrfs 修改 superblock，使其指向 A ’’，如下图所示：\nCOW 事务能够保证文件系统的一致性，并且系统 Reboot 之后不需要执行 fsck 。因为 superblock 要么指向新的 A ’’，要么指向 A，无论哪个都是一致的数据。\nChecksum\nChecksum 技术保证了数据的可靠性，避免 silent corruption 现象。由于硬件原因，从磁盘上读出的数据会出错。比如 block A 中存放的数据为 0x55，但读取出来的数据变是 0x54，因为读取操作并未报错，所以这种错误不能被上层软件所察觉。\n解决这个问题的方法是保存数据的校验和，在读取数据后检查校验和。如果不符合，便知道数据出现了错误。\next2/3 没有校验和，对磁盘完全信任。而不幸的是，磁盘的错误始终存在，不仅发生在廉价的 IDE 硬盘上，昂贵的 RAID 也存在 silent corruption 问题。而且随着存储网络的发展，即使数据从磁盘读出正确，也很难确保能够安全地穿越网络设备。\nbtrfs 在读取数据的同时会读取其相应的 checksum 。如果最终从磁盘读取出来的数据和 checksum 不相同，btrfs 会首先尝试读取数据的镜像备份，如果数据没有镜像备份，btrfs 将返回错误。写入磁盘数据之前，btrfs 计算数据的 checksum 。然后将 checksum 和数据同时写入磁盘。\nBtrfs 采用单独的 checksum Tree 来管理数据块的校验和，把 checksum 和 checksum 所保护的数据块分离开，从而提供了更严格的保护。假如在每个数据 block 的 header 中加入一个域保存 checksum，那么这个数据 block 就成为一个自己保护自己的结构。这种结构下有一种错误无法检测出来，比如本来文件系统打算从磁盘上读 block A，但返回了 block B，由于 checksum 在 block 内部，因此 checksum 依旧是正确的。 btrfs 采用 checksum tree 来保存数据块的 checksum，避免了上述问题。\nBtrfs 采用 crc32 算法计算 checksum，在将来的开发中会支持其他类型的校验算法。为了提高效率，btrfs 将写数据和 checksum 的工作分别用不同的内核线程并行执行。\n多设备管理相关的特性 每个 Unix 管理员都曾面临为用户和各种应用分配磁盘空间的任务。多数情况下，人们无法事先准确地估计一个用户或者应用在未来究竟需要多少磁盘空间。磁盘空间被用尽的情况经常发生，此时人们不得不试图增加文件系统空间。传统的 ext2/3 无法应付这种需求。\n很多卷管理软件被设计出来满足用户对多设备管理的需求，比如 LVM 。 Btrfs 集成了卷管理软件的功能，一方面简化了用户命令；另一方面提高了效率。\n多设备管理\nBtrfs 支持动态添加设备。用户在系统中增加新的磁盘之后，可以使用 btrfs 的命令将该设备添加到文件系统中。\n为了灵活利用设备空间，Btrfs 将磁盘空间划分为多个 chunk 。每个 chunk 可以使用不同的磁盘空间分配策略。比如某些 chunk 只存放 metadata，某些 chunk 只存放数据。一些 chunk 可以配置为 mirror，而另一些 chunk 则可以配置为 stripe 。这为用户提供了非常灵活的配置可能性。\nSubvolume\nSubvolume 是很优雅的一个概念。即把文件系统的一部分配置为一个完整的子文件系统，称之为 subvolume 。\n采用 subvolume，一个大的文件系统可以被划分为多个子文件系统，这些子文件系统共享底层的设备空间，在需要磁盘空间时便从底层设备中分配，类似应用程序调用 malloc() 分配内存一样。可以称之为存储池。这种模型有很多优点，比如可以充分利用 disk 的带宽，可以简化磁盘空间的管理等。\n所谓充分利用 disk 的带宽，指文件系统可以并行读写底层的多个 disk，这是因为每个文件系统都可以访问所有的 disk 。传统的文件系统不能共享底层的 disk 设备，无论是物理的还是逻辑的，因此无法做到并行读写。\n所谓简化管理，是相对于 LVM 等卷管理软件而言。采用存储池模型，每个文件系统的大小都可以自动调节。而使用 LVM，如果一个文件系统的空间不够了，该文件系统并不能自动使用其他磁盘设备上的空闲空间，而必须使用 LVM 的管理命令手动调节。\nSubvolume 可以作为根目录挂载到任意 mount 点。 subvolume 是非常有趣的一个特性，有很多应用。\n假如管理员只希望某些用户访问文件系统的一部分，比如希望用户只能访问 /var/test/ 下面的所有内容，而不能访问 /var/ 下面其他的内容。那么便可以将 /var/test 做成一个 subvolume 。 /var/test 这个 subvolume 便是一个完整的文件系统，可以用 mount 命令挂载。比如挂载到 /test 目录下，给用户访问 /test 的权限，那么用户便只能访问 /var/test 下面的内容了。\n快照和克隆\n快照是对文件系统某一时刻的完全备份。建立快照之后，对文件系统的修改不会影响快照中的内容。这是非常有用的一种技术。\n比如数据库备份。假如在时间点 T1，管理员决定对数据库进行备份，那么他必须先停止数据库。备份文件是非常耗时的操作，假如在备份过程中某个应用程序修改了数据库的内容，那么将无法得到一个一致性的备份。因此在备份过程中数据库服务必须停止，对于某些关键应用这是不能允许的。\n利用快照，管理员可以在时间点 T1 将数据库停止，对系统建立一个快照。这个过程一般只需要几秒钟，然后就可以立即重新恢复数据库服务。此后在任何时候，管理员都可以对快照的内容进行备份操作，而此时用户对数据库的修改不会影响快照中的内容。当备份完成，管理员便可以删除快照，释放磁盘空间。\n快照一般是只读的，当系统支持可写快照，那么这种可写快照便被称为克隆。克隆技术也有很多应用。比如在一个系统中安装好基本的软件，然后为不同的用户做不同的克隆，每个用户使用自己的克隆而不会影响其他用户的磁盘空间。非常类似于虚拟机。\nBtrfs 支持 snapshot 和 clone 。这个特性极大地增加了 btrfs 的使用范围，用户不需要购买和安装昂贵并且使用复杂的卷管理软件。下面简要介绍一下 btrfs 实现快照的基本原理。\n如前所述 Btrfs 采用 COW 事务技术，从图 COW transaction 3 可以看到，COW 事务结束后，如果不删除原来的节点 A,C,E，那么 A,C,E,D,F 依然完整的表示着事务开始之前的文件系统。这就是 snapshot 实现的基本原理。\nBtrfs 采用引用计数决定是否在事务 commit 之后删除原有节点。对每一个节点，btrfs 维护一个引用计数。当该节点被别的节点引用时，该计数加一，当该节点不再被别的节点引用时，该计数减一。当引用计数归零时，该节点被删除。对于普通的 Tree Root, 引用计数在创建时被加一，因为 Superblock 会引用这个 Root block 。很明显，初始情况下这棵树中的所有其他节点的引用计数都为一。当 COW 事务 commit 时，superblock 被修改指向新的 Root A ’’，原来 Root block A 的引用计数被减一，变为零，因此 A 节点被删除。 A 节点的删除会引发其子孙节点的引用计数也减一，图 COW transaction 3 中的 B，C 节点的引用计数因此也变成了 0，从而被删除。 D,E 节点在 COW 时，因为被 A ’’所引用，计数器加一，因此计数器这时并未归零，从而没有被删除。\n创建 Snapshot 时，btrfs 将的 Root A 节点复制到 sA，并将 sA 的引用计数设置为 2 。在事务 commit 的时候，sA 节点的引用计数不会归零，从而不会被删除，因此用户可以继续通过 Root sA 访问 snapshot 中的文件。\n软件 RAID\nRAID 技术有很多非常吸引人的特性，比如用户可以将多个廉价的 IDE 磁盘组合为 RAID0 阵列，从而变成了一个大容量的磁盘； RAID1 和更高级的 RAID 配置还提供了数据冗余保护，从而使得存储在磁盘中的数据更加安全。\nBtrfs 很好的支持了软件 RAID，RAID 种类包括 RAID0,RAID1 和 RAID10.\nBtrfs 缺省情况下对 metadata 进行 RAID1 保护。前面已经提及 btrfs 将设备空间划分为 chunk，一些 chunk 被配置为 metadata，即只存储 metadata 。对于这类 chunk，btrfs 将 chunk 分成两个条带，写 metadata 的时候，会同时写入两个条带内，从而实现对 metadata 的保护。\n其他特性 Btrfs 主页上罗列的其他特性不容易分类，这些特性都是现代文件系统中比较先进的技术，能够提高文件系统的时间或空间效率。\nDelay allocation\n延迟分配技术能够减少磁盘碎片。在 Linux 内核中，为了提高效率，很多操作都会延迟。\n在文件系统中，小块空间频繁的分配和释放会造成碎片。延迟分配是这样一种技术，当用户需要磁盘空间时，先将数据保存在内存中。并将磁盘分配需求发送给磁盘空间分配器，磁盘空间分配器并不立即分配真正的磁盘空间。只是记录下这个请求便返回。\n磁盘空间分配请求可能很频繁，所以在延迟分配的一段时间内，磁盘分配器可以收到很多的分配请求，一些请求也许可以合并，一些请求在这段延迟期间甚至可能被取消。通过这样的“等待”，往往能够减少不必要的分配，也有可能将多个小的分配请求合并为一个大的请求，从而提高 IO 效率。\nInline file\n系统中往往存在大量的小文件，比如几百个字节或者更小。如果为其分配单独的数据 block，便会引起内部碎片，浪费磁盘空间。 btrfs 将小文件的内容保存在元数据中，不再额外分配存放文件数据的磁盘块。改善了内部碎片问题，也增加了文件的访问效率。\n上图显示了一个 BTree 的叶子节点。叶子中有两个 extent data item 元数据，分别用来表示文件 file1 和 file2 所使用的磁盘空间。\n假设 file1 的大小仅为 15 个字节； file2 的大小为 1M 。如图所示，file2 采用普通的 extent 表示方法：extent2 元数据指向一段 extent，大小为 1M，其内容便是 file2 文件的内容。\n而对于 file1， btrfs 会把其文件内容内嵌到元数据 extent1 中。如果不采用 inline file 技术。如虚线所示，extent1 指向一个最小的 extent，即一个 block，但 file1 有 15 个字节，其余的空间便成为了碎片空间。\n采用 inline 技术，读取 file1 时只需要读取元数据 block，而无需先读取 extent1 这个元数据，再读取真正存放文件内容的 block，从而减少了磁盘 IO 。\n得益于 inline file 技术，btrfs 处理小文件的效率非常高，也避免了磁盘碎片问题。\nDirectory index\n当一个目录下的文件数目巨大时，目录索引可以显著提高文件搜索时间。 Btrfs 本身采用 BTree 存储目录项，所以在给定目录下搜索文件的效率是非常高的。\n然而，btrfs 使用 BTree 管理目录项的方式无法同时满足 readdir 的需求。 readdir 是 POSIX 标准 API，它要求返回指定目录下的所有文件，并且特别的，这些文件要按照 inode number 排序。而 btrfs 目录项插入 BTree 时的 Key 并不是 Inode number，而是根据文件名计算的一个 hash 值。这种方式在查找一个特定文件时非常高效，但却不适于 readdir 。为此，btrfs 在每次创建新的文件时，除了插入以 hash 值为 Key 的目录项外，还同时插入另外一种目录项索引，该目录项索引的 KEY 以 sequence number 作为 BTree 的键值。这个 sequence number 在每次创建新文件时线性增加。因为 Inode number 也是每次创建新文件时增加的，所以 sequence number 和 inode number 的顺序相同。以这种 sequence number 作为 KEY 在 BTree 中查找便可以方便的得到一个以 inode number 排序的文件列表。\n另外以 sequence number 排序的文件往往在磁盘上的位置也是相邻的，所以以 sequence number 为序访问大量文件会获得更好的 IO 效率。\n压缩\n大家都曾使用过 zip，winrar 等压缩软件，将一个大文件进行压缩可以有效节约磁盘空间。 Btrfs 内置了压缩功能。\n通常人们认为将数据写入磁盘之前进行压缩会占用很多的 CPU 计算时间，必然降低文件系统的读写效率。但随着硬件技术的发展，CPU 处理时间和磁盘 IO 时间的差距不断加大。在某些情况下，花费一定的 CPU 时间和一些内存，但却能大大节约磁盘 IO 的数量，这反而能够增加整体的效率。\n比如一个文件不经过压缩的情况下需要 100 次磁盘 IO 。但花费少量 CPU 时间进行压缩后，只需要 10 次磁盘 IO 就可以将压缩后的文件写入磁盘。在这种情况下，IO 效率反而提高了。当然，这取决于压缩率。目前 btrfs 采用 zlib 提供的 DEFALTE/INFLATE 算法进行压缩和解压。在将来，btrfs 应该可以支持更多的压缩算法，满足不同用户的不同需求。\n目前 btrfs 的压缩特性还存在一些不足，当压缩使能后，整个文件系统下的所有文件都将被压缩，但用户可能需要更细粒度的控制，比如针对不同的目录采用不同的压缩算法，或者禁止压缩。我相信，btrfs 开发团队将在今后的版本中解决这个问题。\n对于某些类型的文件，比如 jpeg 文件，已经无法再进行压缩。尝试对其压缩将纯粹浪费 CPU 。为此，当对某文件的若干个 block 压缩后发现压缩率不佳，btrfs 将不会再对文件的其余部分进行压缩操作。这个特性在某种程度上提高了文件系统的 IO 效率。\n预分配\n很多应用程序有预先分配磁盘空间的需要。他们可以通过 posix_fallocate 接口告诉文件系统在磁盘上预留一部分空间，但暂时并不写入数据。如果底层文件系统不支持 fallocate，那么应用程序只有使用 write 预先写一些无用信息以便为自己预留足够的磁盘空间。\n由文件系统来支持预留空间更加有效，而且能够减少磁盘碎片，因为所有的空间都是一次分配，因而更有可能使用连续的空间。 Btrfs 支持 posix_fallocate 。\n总结 至此，我们对 btrfs 的很多特性进行了较为详细的探讨，但 btrfs 能提供的特性却并不止这些。 btrfs 正处于试验开发阶段，还将有更多的特性。\nBtrfs 也有一个重要的缺点，当 BTree 中某个节点出现错误时，文件系统将失去该节点之下的所有的文件信息。而 ext2/3 却避免了这种被称为”错误扩散”的问题。\n但无论怎样，希望您和我一样，开始认同 btrfs 将是 Linux 未来最有希望的文件系统。\nBtrfs 使用 了解了 btrfs 的特性，想必您一定想亲身体验一下 btrfs 的使用。本章将简要介绍如何使用 btrfs 。\n要使用一些用户空间工具的话，需要 安装 基础操作必须的 btrfs-progs 软件包。\n停用写时复制 (CoW) chattr +C /dir/file会为这个文件的单个引用停用写时复制,如果这个文件不只有一个引用(例如通过 cp 生成或者在文件系统快照中)，写时复制依然生效。\n可以用下面的方法为已存在的文件或目录停用写时复制:\n$ mv /path/to/dir /path/to/dir_old $ mkdir /path/to/dir $ chattr +C /path/to/dir $ cp -a --reflink=never /path/to/dir_old/. /path/to/dir $ rm -rf /path/to/dir_old 创建文件系统 单一设备上的文件系统\n要在分区 /dev/partition 上创建一个 Btrfs 文件系统，执行：\n# mkfs.btrfs -L mylabel /dev/partition Btrfs 用于元数据的默认节点大小 (nodesize) 为 16KB，而用于数据的默认扇区大小 (sectorsize) 等于页面大小 (page size) 并会自动检测。 要对元数据使用较大的节点大小 (必须为扇区大小的倍数，最大允许 64KB)，请通过 -n 开关为 nodesize 指定一个值。如下例所示，使用 32KB 块大小：\n# mkfs.btrfs -L mylabel -n 32k /dev/partition 注意： 根据 mkfs.btrfs(8) § OPTIONS 手册页内容：“较小的节点大小会增加碎片，但也会让 B-trees 更高，进而使得锁定争用（locking contention）更少。较高的节点大小则能有更好的打包（packing）和更少的碎片，但代价是，更新元数据块时会使用更多的内存”。\n多设备文件系统 RAID\n多个设备可以用来创建一组 RAID。支持的 RAID 级别有 RAID 0、RAID 1、RAID 10、RAID 5 和 RAID 6。从 5.5 版本内核开始，新增对 RAID1c3 和 RAID1c4 的支持，分别是 3 份冗余和 4 份冗余的 RAID 1。可以使用 -d 和 -m 参数分别为数据和元数据配置 RAID 等级。默认情况下，数据有一份副本（single），元数据则被镜像（RAID1）。\n# mkfs.btrfs -d single -m raid1 /dev/part1 /dev/part2 ... subvolume 创建子卷\n要创建一个子卷:\n# btrfs subvolume create /path/to/subvolume 列出子卷列表\n要列出当前路径 (path) 下的子卷和它们的 ID:\n# btrfs subvolume list -p path 删除子卷\n要删除一个子卷:\n# btrfs subvolume delete /path/to/subvolume 自 Linux 4.18 起, 用户可以像移除常规目录一样删除一个子卷 (用 rm -r, rmdir 命令)。\n挂载子卷\n可以使用 subvol=*/path/to/subvolume* 或 subvolid=*objectid* 挂载标志来安装子卷，就像文件系统分区一样。\n$ sudo mount /dev/sdb1 -o subvol=projects /tmp/projects$ sudo mount /dev/sdb1 -o subvolid=261 /tmp/projects 使用 Btrfs 快照进行增量备份 *快照(snapshot)*是 Btrfs 的一个有趣的功能。快照是一个子卷的副本。生成快照是立即的。然而，生成快照与执行 rsync 或 cp 不同，快照并不是一创建就会占用空间。\n 编者注：来自 BTRFS Wiki：快照简单的来说就是一个子卷，它使用 Btrfs 的 COW 功能与其他子卷共享其数据（和元数据）。\n 占用的空间将随着原始子卷或快照本身（如果它是可写的）的数据变化而增加。子卷中已添加/修改的文件和已删除的文件仍然存在于快照中。这是一种方便的备份方式。\n使用快照进行备份\n快照驻留在子卷所在的同一磁盘上。你可以像浏览普通目录一样浏览它，并按照生成快照时的状态恢复文件的副本。顺便说一下，在快照子卷的同一磁盘上生成快照并不是一个理想的备份策略：如果硬盘坏了，快照也会丢失。快照的一个有趣的功能是可以将快照发送到另一个位置。快照可以被发送到外部硬盘或通过 SSH 发送到远程系统（目标文件系统也需要格式化为 Btrfs）。要实现这个，需要使用命令 btrfs send 和 btrfs receive。\n生成快照\n要使用 btrfs send 和 btrfs receive 命令，重要的是要将快照创建为只读，而快照默认是可写的。\n要创建一个快照:\n# btrfs subvolume snapshot source [dest/]name source为要创建快照的对象，[dest/]name为快照安放路径。\n下面的命令将对 /home 子卷进行快照。请注意 -r 标志代表只读。\nsudo btrfs subvolume snapshot -r /home /.snapshots/home-day1 快照的名称可以是当前日期，而不是 day1，比如 home-$(date +%Y%m%d)。快照看起来像普通的子目录。你可以把它们放在任何你喜欢的地方。目录 /.snapshots 可能是一个不错的选择，以保持它们的整洁和避免混淆。\n 编者注：快照不会对自己进行递归快照。如果你创建了一个子卷的快照，子卷所包含的每一个子卷或快照都会被映射到快照里面的一个同名的空目录。\n 使用 btrfs send 进行备份\n在本例中，U 盘中的目标 Btrfs 卷被挂载为 /run/media/user/mydisk/bk。发送快照到目标卷的命令是：\nsudo btrfs send /.snapshots/home-day1 | sudo btrfs receive /run/media/user/mydisk/bk 这被称为初始启动，它相当于一个完整的备份。这个任务需要一些时间，取决于 /home 目录的大小。显然，后续的增量发送只需要更短的时间。\n增量备份\n快照的另一个有用的功能是能够以增量的方式执行发送任务。让我们再来生成一个快照。\nsudo btrfs subvolume snapshot -r /home /.snapshots/home-day2 为了执行增量发送任务，需要指定上一个快照作为基础，并且这个快照必须存在于源文件和目标文件中。请注意 -p 选项。\nsudo btrfs send -p /.snapshot/home-day1 /.snapshot/home-day2 | sudo btrfs receive /run/media/user/mydisk/bk 再来一次（一天之后）：\nsudo btrfs subvolume snapshot -r /home /.snapshots/home-day3sudo btrfs send -p /.snapshot/home-day2 /.snapshot/home-day3 | sudo btrfs receive /run/media/user/mydisk/bk 清理\n操作完成后，你可以保留快照。但如果你每天都执行这些操作，你可能最终会有很多快照。这可能会导致混乱，并可能会在你的磁盘上使用大量的空间。因此，如果你认为你不再需要一些快照，删除它们是一个很好的建议。\n请记住，为了执行增量发送，你至少需要最后一个快照。这个快照必须存在于源文件和目标文件中。\nsudo btrfs subvolume delete /.snapshot/home-day1sudo btrfs subvolume delete /.snapshot/home-day2sudo btrfs subvolume delete /run/media/user/mydisk/bk/home-day1sudo btrfs subvolume delete /run/media/user/mydisk/bk/home-day2 注意：第 3 天的快照被保存在源文件和目标文件中。这样，明天（第 4 天），你就可以执行新的增量 btrfs send。\n最后的建议是，如果 U 盘的空间很大，可以考虑在目标盘中保留多个快照，而在源盘中只保留最后一个快照。\n压缩 给现存文件启用压缩，可使用 btrfs filesystem defragment -c alg 命令，alg 处可选填为 zlib，lzo 或 zstd。举例来说，要用 zstd 方式给整个文件系统重新压缩，执行下列命令：\n# btrfs filesystem defragment -r -v -c zstd / 要在新的 Btrfs 分区上安装 Arch Linux 时就启用压缩功能 (充分利用压缩特性)，请在 挂载 文件系统时使用 compress 选项：mount -o compress=zstd /dev/sd*xY* /mnt/。在配置过程中，请在 fstab 中把 compress=zstd 添加到根目录文件系统的挂载选项里。\n提示： 通过执行 chattr +c，也可以在不使用 compress 选项的情况下为每个单文件启用压缩属性。对目录执行会使这个目录下新文件自动被压缩。\nBtrfs 和 LVM-ext4 两者的共性 尽管两个文件系统之间存在核心差异，但 Btrfs 和 LVM-ext4 实际上有很多共同之处。两者都是成熟且经过充分测试的存储技术。从 Fedora Core 的早期开始，就一直在使用 LVM，而 ext4 在 2009 年成为 Fedora 11 的默认设置。Btrfs 在 2009 年并入 Linux 主线内核，并且 Facebook 广泛使用了该文件系统。SUSE Linux Enterprise 12 在 2014 年使其成为默认文件系统。因此，它在生产环境中也有着长久的运行时间。\n这两个系统都能很好地防止因意外停电而导致的文件系统损坏，尽管它们的实现方式不同。它们支持的配置包括使用单盘设置和跨越多个设备，并且这两种配置都能够创建近乎即时的快照。有各种工具可以帮助管理这两种系统，包括命令行和图形界面。这两种解决方案在家用台式机和高端服务器上都同样有效。\nLVM-ext4 的优势 ext4 文件系统 专注于高性能和可伸缩性，没有太多额外的花哨之处。它能有效地防止长时间后的碎片化，并当碎片化出现后提供了 很好的工具。ext4 之所以坚如磐石，是因为它构建在前代的 ext3 文件系统之上，带来了多年的系统内测试和错误修复。\nLVM-ext4 环境中的大多数高级功能都来自 LVM 本身。LVM 位于文件系统的“下方”，这意味着它支持任何文件系统。逻辑卷Logical volume（LV）是通用的块设备，因此 虚拟机可以直接使用它们。这种灵活性使得每个逻辑卷都可以使用合适的文件系统，用合适的选项应对各种情况。这种分层方法还遵循了“小工具协同工作”的 Unix 哲学。\n从硬件抽象出来的卷组volume group（VG）允许 LVM 创建灵活的逻辑卷。每个逻辑卷都提取自同一个存储池，但具有自己的设置。调整卷的大小比调整物理分区的大小容易得多，因为没有数据有序放置的限制。LVM 物理卷physical volume（PV）可以是任意数量的分区，甚至可以在系统运行时在设备之间移动。\nLVM 支持只读和读写的 快照，这使得从活动系统创建一致的备份变得很容易。每个快照都有一个定义的大小，更改源卷或快照卷将占用其中的空间。又或者，逻辑卷也可以是稀疏配置池thinly provisioned pool的一部分。这允许快照自动使用池中的数据，而不是使用在创建卷时定义的固定大小的块。\n有多个磁盘驱动器的 LVM\n当有多个设备时，LVM 才真正大放异彩。它原生支持大多数 RAID 级别，每个逻辑卷可以具有不同的 RAID 级别。LVM 将自动为 RAID 配置选择适当的物理设备，或者用户可以直接指定它。基本的 RAID 支持包括用于性能的数据条带化（RAID0）和用于冗余的镜像（RAID1）。逻辑卷也可以使用 RAID5、RAID6 和 RAID10 等高级设置。LVM RAID 支持已经成熟，因为 LVM 在底层使用的 设备映射器（dm） 和 多设备（md） 内核支持， 与 mdadm 使用的一样。\n对于具有快速和慢速驱动器的系统，逻辑卷也可以是 缓存卷。经典示例是 SSD 和传统磁盘驱动器的组合。缓存卷使用较快的驱动器来存储更频繁访问的数据（或用作写缓存），而慢速的驱动器则用于处理大量数据。\nLVM 中大量稳定的功能以及 ext4 的可靠性在既往的使用中早已被证明了。当然，功能越多就越复杂。在配置 LVM 时，要找到合适的功能选项是很有挑战性的。对于单驱动器的台式机系统，LVM 的功能（例如 RAID 和缓存卷）不适用。但是，逻辑卷比物理分区更灵活，快照也很有用。对于正常的桌面使用，LVM 的复杂性会成为典型的用户可能遇到的问题恢复的障碍。\nBtrfs 的优势 从前几代文件系统中学到的经验指导了构建到 Btrfs 的功能设计。与 ext4 不同，它可以直接跨越多个设备，因此它具有通常仅在卷管理器中才能找到的功能。它还具有 Linux 文件系统空间中独有的功能（ZFS 具有相似的功能集，但不要指望它在 Linux 内核中出现）。\nBtrfs 的主要功能\n也许最重要的功能是对所有数据进行校验和checksumming。校验和与写时复制copy-on-write（COW）一起，提供了在意外断电后确保文件系统完整性的 关键方法。更独特的是，校验和可以检测数据本身中的错误。悄然的数据损坏（有时也称为 bitrot）比大多数人意识到的更常见。如果没有主动验证，损坏最终可能会传播到所有可用的备份中。这使得用户没有有效的副本。通过透明地校验所有数据，Btrfs 能够立即检测到任何此类损坏。启用正确的 dup 或 raid 选项，文件系统也可以透明地修复损坏。\n写时复制也是 Btrfs 的基本功能，因为它在提供文件系统完整性和即时子卷快照方面至关重要。从公共子卷创建快照后，快照会自动共享底层数据。另外，事后的重复数据删除deduplication 使用相同的技术来消除相同的数据块。单个文件可以通过使用 cp 的 reflink 选项 来使用 COW 功能。reflink 副本对于复制大型文件（例如虚拟机镜像）特别有用，这些文件往往随着时间的推移具有大部分相同的数据。\nBtrfs 支持跨越多个设备，而无需卷管理器。多设备支持可提供数据镜像功能以实现冗余和条带化以提高性能。此外，还实验性地支持更高级的 RAID 级别，例如 RAID 5 和 RAID 6。与标准 RAID 设置不同，Btrfs 的 RAID1 实际上允许奇数个设备。例如，它可以使用 3 个设备，即使它们的大小不同。\n所有 RAID 和 dup 选项都是在文件系统级别指定的。因此，各个子卷不能使用不同的选项。请注意，使用多设备的 RAID1 选项意味着即使一个设备发生故障，卷中的所有数据都是可用的，并且校验功能可以保持数据本身的完整性。这超出了当前典型的 RAID 设置所能提供的范围。\n附加功能\nBtrfs 还支持快速简便的远程备份。子卷快照可以 发送到远程系统 进行存储。通过利用文件系统中固有的 COW 元数据，这些传输通过仅发送先前发送的快照中的增量更改而非常有效。诸如 snapper 之类的用户应用程序使管理这些快照变得容易。\n另外，Btrfs 卷可以具有 透明压缩 功能，并且 chattr +c 可以标记进行压缩的单个文件或目录。压缩不仅可以减少数据消耗的空间，还可以通过减少写入操作量来帮助延长 SSD 的寿命。压缩当然会带来额外的 CPU 开销，但是有很多选项就可以权衡取舍。\nBtrfs 集成了文件系统和卷管理器功能，这意味着总体维护比 LVM-ext4 更简单。当然，这种集成的灵活性较低，但是对于大多数台式机甚至服务器而言，设置已足够。\nLVM 上使用 Btrfs Btrfs 可以 就地转换 ext3/ext4 文件系统。就地转换意味着无需将数据复制出来然后再复制回去。数据块本身甚至都不需要修改。因此，对于现有的 LVM-ext4 系统，一种选择是将 LVM 保留在原处，然后简单地将 ext4 转换为 Btrfs。虽然可行且受支持，但有一些原因使它不是最佳选择。\nBtrfs 的吸引力之一是与卷管理器集成的文件系统所带来的更轻松的管理。要是在 LVM 之上运行，对于系统维护，仍然要对额外的卷管理器进行一些设置。同样，LVM 设置通常具有多个固定大小的逻辑卷，并具有独立文件系统。虽然 Btrfs 支持给定的计算机上的多个卷，但是许多不错的功能都需要单一卷具有多个子卷。如果每个 LVM 卷都有一个独立的 Btrfs 卷，则用户仍然需要手动管理固定大小的 LVM 卷。虽然能够收缩挂载的 Btrfs 文件系统的能力确实使处理固定大小的卷的工作变得更轻松。通过在线收缩功能，就无需启动 实时镜像 了。\n在使用 Btrfs 的多设备支持时，必须仔细考虑逻辑卷的物理位置。对于 Btrfs 而言，每个逻辑卷都是一个单独的物理设备，如果实际情况并非如此，则某些数据可用性功能可能会做出错误的决定。例如，如果单个驱动器发生故障，对数据使用 RAID1 通常可以提供保护。如果实际逻辑卷在同一物理设备上，则没有冗余。\n如果强烈需要某些特定的 LVM 功能，例如原始块设备或高速缓存的逻辑卷，则在 LVM 之上运行 Btrfs 是有意义的。在这种配置下，Btrfs 仍然提供其大多数优点，例如校验和和易于发送的增量快照。尽管使用 LVM 会产生一些操作开销，但 Btrfs 的这种开销并不比任何其他文件系统大。\n总结 当尝试在 Btrfs 和 LVM-ext4 之间进行选择时，没有一个正确的答案。每个用户都有独特的要求，并且同一用户可能拥有具有不同需求的不同系统。看一下每个配置的功能集，并确定是否有令人心动的功能。如果没有，坚持默认值没有错。选择这两种设置都有很好的理由。\nSnapper Snapper 是 openSUSE 下用于创建和管理文件系统快照（以下简称快照）的工具。快照保存了文件系统在某个时间点的状态，从而可以轻松实现系统回滚或数据备份。\nSnapper 可以在 Btrfs 文件系统（推荐）及采用 XFS 或 Ext4 文件系统的 LVM 精简配置卷上使用，本文主要介绍在 Btrfs 文件系统上使用 Snapper 的方法。\n快照类型 Snapper 快照可分为两大类型：\n 快照对：由一对快照组成，在进行某项操作前拍摄一个“前快照”（pre），操作后再拍摄一个“后快照”（post），从而可以比较两个快照对差异而撤销该操作。快照对是一一对应的，如果删除了某一快照，则对应的快照也会被删除。 单一快照（single）：由一个单独的快照组成，与其他快照没有特殊联系。可用于备份或回滚整个系统等操作。  快照对和单一快照既可以手动创建，也可以根据配置自动创建。自动创建的快照又可分为三种类型：\n 时间线快照：每小时自动创建的单一快照。 安装快照：在安装软件包前后自动创建的一对快照对。可用于撤销软件包更改。 管理快照：在使用 YaST 管理系统前后自动创建的一堆快照对。可用于撤销配置更改。  这三种自动创建的快照均可单独启用和配置，从而提供了极大的灵活性。\n默认配置 要在分区或 Btrfs 子卷启用快照，需要创建配置文件。Snapper 的配置文件存储在 /etc/snapper/configs 中。\n如果你的根分区大于 16 GB，并且在安装 openSUSE 时使用默认分区配置，则根分区的配置文件应已被自动创建。默认配置启用了安装快照和管理快照，并排除了部分目录，可以满足大多数需求。以下列表显示了排除的所有目录：\n  /boot/grub2/i386-pc、/boot/grub2/x86_64-efi、/boot/grub2/powerpc-ieee1275、/boot/grub2/s390x-emu\n不能回滚引导加载程序配置。上面列出的目录是架构专属目录。前两个目录位于 AMD64/Intel 64 计算机上，后两个目录分别位于 IBM POWER 和 IBM Z 上。\n  /home\n如果独立的分区中没有 /home，便会将该目录排除以免在回滚时发生数据丢失。\n  /opt、/var/opt\n第三方产品通常安装到 /opt 下。排除此目录是为了防止在回滚时卸装这些应用程序。\n  /srv\n包含 Web 和 FTP 服务器的数据。排除此目录是为了防止在回滚时发生数据丢失。\n  /tmp、/var/tmp、/var/cache、/var/crash\n包含临时文件和超速缓存的所有目录都会排除在快照范围之外。\n  /usr/local\n在手动安装软件时会用到此目录。系统会将该目录排除以免在回滚时卸载这些安装的软件。\n  /var/lib/libvirt/images\n使用 libvirt 管理的虚拟机映像的默认位置。为确保回滚期间虚拟机映像不会替换为旧版本而被排除。默认情况下，此子卷是使用写入时不复制选项创建的。\n  /var/lib/mailman、/var/spool\n包含邮件或邮件队列的目录会排除，以免在回滚后造成邮件丢失。\n  /var/lib/bind\n包含 DNS 服务器的区域数据。排除该目录是为了确保回滚后名称服务器仍能运作。\n  /var/lib/mariadb、/var/lib/mysql、/var/lib/pgqsl\n这些目录包含数据库数据。默认情况下，这些子卷是使用写入时不复制选项创建的。\n  /var/log\n日志文件所在的位置。排除该目录是为了在对受损的系统进行回滚后能够对日志文件进行分析。\n  如果你希望使用 openSUSE 的默认配置，但在安装 openSUSE 时未开启快照功能，可以使用以下命令创建根分区的默认配置文件：\n注意： 要使用该默认配置文件，请确保根分区大小至少为 16 GB，并使用 openSUSE 安装程序建议的包含子卷的 Btrfs 根文件系统（安装程序默认分区设置）\nsnapper -c root create-config / 确保 snapper-zypp-plugin 软件包已安装以启用安装快照：\nzypper install snapper-zypp-plugin 手动配置 创建和装入新子卷 系统支持在 / 层次下创建新的子卷，并永久性装入该卷。此类子卷将从快照中排除。切勿在现有快照中创建此类子卷，因为在回滚之后，您将无法再删除快照。\nSUSE Linux Enterprise Server 上配置了 /@/ 子卷，该子卷充当永久性子卷（例如 /opt、/srv、/home 等）的独立根目录。您创建和永久装入的任何新子卷都需要在这个初始根文件系统中创建。\n为此，请运行以下命令。在此示例中，从 /dev/sda2 创建了一个新子卷 /usr/important。\nsudo mount /dev/sda2 -o subvol=@ /mntsudo btrfs subvolume create /mnt/usr/importantsudo umount /mnt /etc/fstab 中的相应项需类似于：\n/dev/sda2 /usr/important btrfs subvol=@/usr/important 0 0 提示：子卷可能包含经常更改的文件，例如虚拟化的磁盘映像、数据库文件或日志文件。如果是这样，可考虑对此卷禁用写入时复制功能，以免复制磁盘块。可在 /etc/fstab 中使用 nodatacow 装入选项来实现此目的：\n/dev/sda2 /usr/important btrfs nodatacow,subvol=@/usr/important 0 0 或者，要为单个文件或目录禁用写入时复制功能，请使用命令 chattr +C 路径。\n创建配置文件 希望在特定分区或子卷启用快照，可以以下命令创建相应的配置文件：\nsnapper -c 配置文件名 create-config 分区或子卷的挂载点 这将根据 /etc/snapper/config-templates/default 提供的默认值创建配置文件。\n注意： 在创建配置文件前请确保目标分区或子卷已被创建。不能为同一分区或子卷创建多个配置文件。\n例如，为防止回滚时数据丢失，默认的根分区配置排除了 /home 目录，可以使用上述命令为 /home 创建配置文件：\nsnapper -c home create-config /home 该命令会使用 /etc/snapper/config-templates/default 提供的默认值创建 /etc/snapper/configs/home 文件。\n可以使用\nsnapper list-configs 查看现有配置文件。\n启用/禁用自动快照 你可以选择性地启用/禁用自动创建的快照类型：\n启用时间线快照\nsnapper -c 配置文件名 set-config \u0026quot;TIMELINE_CREATE=yes\u0026quot; 禁用时间线快照\nsnapper -c 配置文件名 set-config \u0026quot;TIMELINE_CREATE=no\u0026quot; 时间线快照默认会启用，但根分区除外。\n注意： 以下两种快照包含的内容由安装的软件包或修改的配置而定，与特定分区或子卷无关。默认为启用状态。\n启用安装快照\nzypper install snapper-zypp-plugin 禁用安装快照\nzypper remove snapper-zypp-plugin 使用 YaST 或 Zypper 安装包时所创建的快照会由 snapper-zypp-plugin 进行处理。何时创建快照由 XML 配置文件 /etc/snapper/zypp-plugin.conf 定义。\n启用管理快照\n在 /etc/sysconfig/yast2 中将 USE_SNAPPER 设置为 yes 禁用管理快照\n在 /etc/sysconfig/yast2 中将 USE_SNAPPER 设置为 no 配置文件参数 Snapper 的行为由配置文件参数定义，除了直接使用文本编辑器编辑配置文件外，还可以使用\nsnapper -c 配置文件名称 set-config \u0026quot;参数名称=参数\u0026quot; 修改配置文件参数。\n以下对几个常用配置案例进行说明，完整的参数说明可参阅 snapper-configs(5) ：\nman snapper-configs 允许普通用户管理快照\n默认情况下仅 root 用户可以管理快照，要允许普通用户或组管理快照，可运行：\nsnapper -c 配置文件名称 set-config \u0026quot;ALLOW_USERS=用户名\u0026quot; \u0026quot;ALLOW_GROUPS=组名\u0026quot; \u0026quot;SYNC_ACL=yes\u0026quot; 必须配置“SYNC_ACL=yes”以允许普通用户访问快照所在目录。\n自动清理旧快照\n为防止快照占据全部磁盘空间，Snapper 提供了几种自动清理旧快照的机制，可通过一系列参数配置自动清理过程：\n   清理机制 说明 启用选项 配置参数 含义 备注     编号 根据快照编号进行清理 NUMBER_CLEANUP=yes NUMBER_LIMIT=数字或范围 定义要保留的快照数量。 如果启用了定额支持，应使用范围。如果未启用定额支持，应使用单个数字。   NUMBER_LIMIT_IMPORTANT=数字或范围 定义要保留的含 important 标签的快照数量，内核更新等的安装快照自带该标签。       NUMBER_MIN_AGE=秒 定义满足上述条件的快照被清理前最少应保留的时间。0 表示无限制。       时间线 根据快照创建时间进行清理 TIMELINE_CLEANUP=yes TIMELINE_LIMIT_HOURLY=数字或范围 定义要保留的每小时首张快照的数量。 如果启用了定额支持，应使用范围。如果未启用定额支持，应使用单个数字。   TIMELINE_LIMIT_DAILY=数字或范围 定义要保留的每日首张快照的数量。       TIMELINE_LIMIT_WEEKLY=数字或范围 定义要保留的每周首张快照的数量，此处的周由星期一开始。       TIMELINE_LIMIT_MONTHLY=数字或范围 定义要保留的每月首张快照的数量。       TIMELINE_LIMIT_YEARLY=数字或范围 定义要保留的每年首张快照的数量。       TIMELINE_MIN_AGE=秒 定义满足上述条件的快照被清理前最少应保留的时间。0 表示无限制。       无差异快照对 清理没有差异的快照对。如运行 Yast2 后未作任何修改，则自动清理创建的管理快照。 EMPTY_PRE_POST_CLEANUP=yes EMPTY_PRE_POST_CLEANUP=秒 定义无差异快照对被清理前最少应保留的时间。0 表示无限制。    磁盘定额 定义快照可占用空间的百分比 运行snapper setup-quota SPACE_LIMIT=表示百分比的小数 定义快照可占用空间的百分比 仅支持 Btrfs 文件系统需至少启用编号或时间线清理算法中的一个启用定额支持后，编号和时间线清理算法的部分参数应当使用范围值。清理算法会清理快照至上限值，如果未满足定额配置则在下限值范围内尽量清理快照以满足定额。    管理配置文件 可以使用 snapper 命令快速管理配置文件：\n列出配置文件\nsnapper list-configs 显示特定的配置文件\nsnapper -c 配置文件名称 get-config 删除配置文件\nsnapper -c 配置文件名称 delete-config 快照管理 可以使用 snapper 工具或 Yast2 模块进行查看、创建、比较快照等操作。\nsnapper 工具提供了一系列子命令，可以在文本界面进行快照管理。本节介绍了一些常用命令和参数，更多信息可参阅 snapper(8)：\nman snapper 注意： 管理快照时可使用 “-c 配置文件名” 指定配置文件，如未指定则默认使用 root 配置文件，下述示例均未指定配置文件。\n查看快照\nsnapper list 将列出 root 配置的所有快照。\n可以使用 “-t” 参数列出特定类型的快照。\n例如，列出 root 配置下的所有快照对：\nsnapper list -t pre-post 列出 home 配置下的所有单一快照：\nsnapper -c home list -t single 你还可以使用\nsnapper list -a 列出所有配置下的快照。\n创建快照\nsnapper create 将使用 root 配置文件创建一个单一快照。\n可以使用“-t”参数指定快照类型（默认值为 single），使用“-d”参数添加描述。手动创建的快照默认不会自动被清理，使用“\u0026ndash;cleanup-algorithm”参数指定自动清理算法。还可以使用“\u0026ndash;userdata”参数定义自定义数据（如 important 标记）。\n例如，创建当前系统的单一快照，标记为重要，并指定时间线清理算法：\nsnapper create -t single --description \u0026quot;系统快照\u0026quot; --userdata \u0026quot;important=yes\u0026quot; --cleanup-algorithm timeline 要创建一个快照对，首先创建一个前快照，使用“\u0026ndash;print-number”选项以列出快照编号：\nsnapper create -t pre --print-number --description \u0026quot;Before\u0026quot; 假设列出的快照编号为 30，将其作为“\u0026ndash;pre-number”参数的值创建后快照：\nsnapper create -t post --pre-number 30 --description \u0026quot;After\u0026quot; 你也可以使用\nsnapper create --command \u0026quot;要运行的命令\u0026quot; 以自动创建运行命令前后的快照对。\n比较快照\n有两种比较方法：\nsnapper status \u0026lt;第一个快照编号\u0026gt;..\u0026lt;第二个快照编号\u0026gt; //第一个快照的创建时间要早于第二个 将显示您在两个快照时间内修改的全部文件的路径和文件名。\n例如，下述命令可以比较当前系统状态与 161 号快照的差异：\nsnapper status 161..0 //0 表示当前系统，它不是快照，但你可以认为是比所有快照都新的一个快照。 第二种：\nsnapper diff \u0026lt;第一个快照编号\u0026gt;..\u0026lt;第二个快照编号\u0026gt; 文件名 将以 diff 的格式显示指定文件的差异，如果未指定文件名，将显示所有文件的差异。\n撤销修改\nsnapper undochange \u0026lt;修改前的快照编号\u0026gt;..\u0026lt;修改后的快照编号\u0026gt; \u0026lt;文件名\u0026gt; 比如你误删除了某个文件，可以使用：\nsnapper undochange \u0026lt;删除文件前的快照编号\u0026gt;..0 文件名 //0 表示当前系统，它不是快照，但你可以认为是比所有快照都新的一个快照。 来撤销。\n删除快照\nsnapper delete 快照编号或范围 例如，要删除 16 号快照：\nsnapper delete 16 要删除 10 号到 15 号快照：\nsnapper delete 10-15 可以结合“-s”参数以在删除快照后立刻释放可用空间而不必等待 Btrfs 进程回收。\n回滚整个系统\nSUSE Linux Enterprise Server 上包含的 GRUB 2 版本可以从 Btrfs 快照进行引导。与 Snapper 的回滚功能相结合，就能恢复配置错误的系统。只有针对默认 Snapper 配置（根）创建的快照才可引导。\n注意： 要回滚整个系统，请确保根文件系统为 openSUSE 安装程序默认的带子卷的 Btrfs 文件系统。从 SUSE Linux Enterprise Server 15 开始，只有在根分区的默认子卷配置未更改过的情况下，才支持系统回滚。\n如果因为更新或病毒等原因导致系统出现重大错误，并保留了错误前的快照，则可以回滚整个系统到错误前的状态。\nsnapper rollback 要回滚的快照编号 该命令将创建当前系统状态的只读快照 A 及指定编号快照的可读写快照 B，并使用快照 B 替换根分区的默认子卷，重新启动系统后即可实现回滚。\n你还可以在引导系统时选择Start bootloader from a read-only snapshot，以引导想要回滚的快照，在检查无误后在引导的快照中执行：\nsnapper rollback 不指定快照编号时，将创建根分区默认子卷（即原系统）的只读快照 A 和当前系统（即目前引导的快照）的可读写快照 B，并使用快照 B 替换根分区的默认子卷，重新启动系统后选择默认引导项即可实现回滚。\nsudo 许多命令和系统实用程序都需要以 root 身份运行才能执行。为了确保安全和避免发生意外运行危险命令，通常建议不要直接以 root 身份登录。建议的做法是以非特权的普通用户身份工作，并使用 sudo 命令来运行需要较高特权的命令。\n在 SUSE Linux Enterprise Server 上，sudo 默认配置与 su 的工作方式类似。但是，sudo 可让用户以高度可配置的方式使用任何其他用户的特权来运行命令。这样，便可为某些用户和组指派具有特定特权的角色。举例来说，可以允许组 users 的成员使用 wilber 的特权运行命令。通过禁止指定任何命令选项，可以进一步限制对命令的权限。虽然 su 始终需要 root 口令才能使用 PAM 进行身份验证，但是您可以将 sudo 配置为使用您自己的身份凭证进行身份验证。这样就不需要共享 root 口令，从而提高了安全性。\nsudo 基本用法 虽然 sudo 简单易用，功能却十分强大。\n运行单个命令 以普通用户身份登录后，您可以在命令前加上 sudo 以 root 身份运行任何命令。按照提示输入口令后，如果身份验证成功，您便能以 root 身份运行命令：\n# id -un 命令会打印当前用户的登录名 $ id -un tux # 在输入过程中不会显示口令，无论是明文还是密文均不显示。  $ sudo id -un root\u0026#39;s password: root # 只有以 sudo 开头的命令才会使用较高的特权运行。如果是不带 sudo 前缀的相同命令，仍会使用当前用户的特权运行。  $ id -un tux # 在限定时间内，您无需再次输入 root 口令。  $ sudo id -un root I/O 重定向的工作方式与您预期的可能不同：\n$ sudo echo s \u0026gt; /proc/sysrq-trigger bash: /proc/sysrq-trigger: Permission denied $ sudo cat \u0026lt; /proc/1/maps bash: /proc/1/maps: Permission denied 只有 echo/cat 二进制会使用较高特权运行，重定向则由用户外壳使用用户特权执行。您可以按启动外壳中所述启动外壳，也可以使用 dd 实用程序来启动：\n$ echo s | sudo dd of=/proc/sysrq-trigger $ sudo dd if=/proc/1/maps | cat 启动外壳 必须在每条命令前加上 sudo 可能很繁琐。虽然可以将外壳指定为命令 sudo bash，但还是建议您使用以下其中一种内置机制来启动外壳：\n  sudo -s (\u0026lt;命令\u0026gt;)\n启动 SHELL 环境变量所指定的外壳或目标用户的默认外壳。如果给定了命令，则会将该命令传递给外壳（使用 -c 选项），否则外壳会以交互模式运行。\n$ sudo -s root's password: $ exit   sudo -i (\u0026lt;命令\u0026gt;)\n  与 -s 类似，但是会将外壳启动为登录外壳。也就是说，系统会对外壳的启动文件（.profile 等）进行处理，并会将当前的工作目录设置为目标用户的主目录。\n$ sudo -i root's password: $ exit   环境变量 默认情况下，sudo 不会传播环境变量：\n$ ENVVAR=test env | grep ENVVAR ENVVAR=test $ ENVVAR=test sudo env | grep ENVVAR root's password: $ 输出为空即表明在使用 sudo 运行的命令的环境中不存在环境变量 ENVVAR。\n此行为可通过 env_reset 选项进行更改，请参见下文有用的标志和选项。\n配置 sudo sudo 是一个非常灵活的工具，提供各种配置选项。\n注意：如果您不小心将自己锁定在 sudo 之外，则可以使用 su - 及 root 口令来获取 root 外壳。要修复该错误，请运行 visudo。\n编辑配置文件 sudo 的主要策略配置文件为 /etc/sudoers。如果此文件中存在错误，您可能便会无法进入系统，因此强烈建议您使用 visudo 来编辑配置文件。此举可防止同时更改打开的文件，并会在保存修改之前检查语法错误。\n您还可以通过设置 EDITOR 环境变量来使用除 vi 以外的编辑器（不论名字如何），例如：\n$ sudo EDITOR=/usr/bin/nano visudo 不过，/etc/sudoers 文件本身是由系统包提供的，更新时这些修改可能会取消。因此，建议您将自定义配置放到 /etc/sudoers.d/ 目录下的文件中。该目录下的任何文件都会自动纳入系统中。要在该子目录下创建或编辑文件，请运行：\nsudo visudo -f /etc/sudoers.d/NAME 或者，使用其他编辑器（例如 nano）：\nsudo EDITOR=/usr/bin/nano visudo -f /etc/sudoers.d/NAME 注意：/etc/sudoers 中的 #includedir 命令（用于 /etc/sudoers.d）会忽略以 ~（波浪号）结尾或包含 .（点）的文件。\n关于 visudo 命令的详细信息，请运行 man 8 visudo。\nsudoers 基本配置语法 在 sudoers 配置文件中，有两种类型的选项：字符串和标志。字符串可以包含任何值，而标志则只能在“ON”或“OFF”之间切换。sudoers 配置文件最重要的语法构造为：\n# Everything on a line after a # gets ignored, Defaults !insults # Disable the insults flag Defaults env_keep += \u0026quot;DISPLAY HOME\u0026quot; # Add DISPLAY and HOME to env_keep tux ALL = NOPASSWD: /usr/bin/frobnicate, PASSWD: /usr/bin/journalctl  #include 和 #includedir 这两个普通命令例外。其后跟数字，用于指定 UID。 去除 ! 可将指定的标志设置为“ON”。  有用的标志和选项\n   选项名称 说明 示例     targetpw 此标志控制调用用户是需要输入目标用户（例如 root）的口令 (ON) 还是需要输入调用用户的口令 (OFF)。 Defaults targetpw # Turn targetpw flag ON   rootpw 如果设置了该选项，sudo 会提示输入 root 口令，而非目标用户或调用者的口令。默认值为“OFF”。 Defaults !rootpw # Turn rootpw flag OFF   env_reset 如果设置了该选项，sudo 会构造一个仅包含 TERM、PATH、HOME、MAIL、SHELL、LOGNAME、USER、USERNAME 和 SUDO_* 集的最小环境。此外，会从调用环境导入 env_keep 中列出的变量。默认值为“ON”。 Defaults env_reset # Turn env_reset flag ON   env_keep env_reset 标志设为“ON”时要保留的环境变量列表。 # Set env_keep to contain EDITOR and PROMPT Defaults env_keep = \u0026quot;EDITOR PROMPT\u0026quot; Defaults env_keep += \u0026quot;JRE_HOME\u0026quot; # Add JRE_HOME Defaults env_keep -= \u0026quot;JRE_HOME\u0026quot; # Remove JRE_HOME   env_delete env_reset 标志设为“OFF”时要去除的环境变量列表。 # Set env_delete to contain EDITOR and PROMPT Defaults env_delete = \u0026quot;EDITOR PROMPT\u0026quot; Defaults env_delete += \u0026quot;JRE_HOME\u0026quot; # Add JRE_HOME Defaults env_delete -= \u0026quot;JRE_HOME\u0026quot; # Remove JRE_HOME    还可以使用 Defaults 令牌为用户、主机和命令集合创建别名。并且，可以仅将选项应用到特定用户集。\n关于 /etc/sudoers 配置文件的详细信息，请参见 man 5 sudoers。\nsudoers 中的规则 sudoers 配置中的规则可能会非常复杂，因此本节仅涉及基本内容。每个规则都遵循基本模式（[] 标记的是可选部分）：\n#Who Where As whom Tag What User_List Host_List = [(User_List)] [NOPASSWD:|PASSWD:] Cmnd_List   User_List\n一个或多个（用 , 分隔）标识符：用户名、格式为 %GROUPNAME 的组或格式为 #UID 的用户 ID。可以使用 ! 前缀来取反。\n  Host_List\n一个或多个（用 , 分隔）标识符：（完全限定的）主机名或 IP 地址。可以使用 ! 前缀来取反。Host_List 的惯常选项为 ALL。\n  NOPASSWD:|PASSWD:\n如果用户在 NOPASSWD: 后面运行的命令与 CMDSPEC 匹配，系统不会提示用户输入口令。\nPASSWD 为默认选项，仅当两个选项位于同一行时才需要指定它：\ntux ALL = PASSWD: /usr/bin/foo, NOPASSWD: /usr/bin/bar   Cmnd_List\n一个或多个（用 , 分隔）区分符：可执行文件的路径，后跟允许使用的自变量或什么也不跟。\n/usr/bin/foo # Anything allowed /usr/bin/foo bar # Only \u0026quot;/usr/bin/foo bar\u0026quot; allowed /usr/bin/foo \u0026quot;\u0026quot; # No arguments allowed   ALL 可以用作 User_List、Host_List 和 Cmnd_List。\n允许 tux 在无需输入口令的情况下以 root 身份运行所有命令的规则：\ntux ALL = NOPASSWD: ALL 允许 tux 运行 systemctl restart apache2 的规则：\ntux ALL = /usr/bin/systemctl restart apache2 允许 tux 在不带自变量的情况下以 admin 身份运行 wall 的规则：\ntux ALL = (admin) /usr/bin/wall \u0026quot;\u0026quot; 警告：以下类型的构造\nALL ALL = ALL 在没有 Defaults targetpw 的情况下切勿使用，否则任何人都能以 root 身份运行命令。\n常见使用情况 尽管默认配置对于简单的设置和桌面环境通常已经够用，但是自定义配置非常有用。\n在无需 root 口令的情况下使用 sudo 在具有特殊限制（“用户 X 只能以 root” 身份运行命令 Y）的情况下，无法实现此目的。在其他情况下，还是建议进行某种分隔。按照惯例，组 wheel 的成员能以 root 身份运行所有带有 sudo 的命令。\n  将自己添加到 wheel 组\n如果您自己的用户帐户尚不是 wheel 组的成员，请添加该帐户，具体做法是运行 sudo usermod -a -G wheel 用户名然后注销并再次登录。运行 groups 用户名以确认更改是否成功。\n  将使用调用用户的口令进行身份验证的选项设为默认设置。\n使用 visudo 创建文件 /etc/sudoers.d/userpw并添加：\nDefaults !targetpw   选择新默认规则。\n根据是否想要用户重新输入口令，取消对 /etc/sudoers 中特定行的注释，并将默认规则注释掉。\n## Uncomment to allow members of group wheel to execute any command # %wheel ALL=(ALL) ALL ## Same thing without a password # %wheel ALL=(ALL) NOPASSWD: ALL   提高默认规则的限制性\n将 /etc/sudoers 中允许一切操作的规则注释掉或去除：\nALL ALL=(ALL) ALL # WARNING! Only use this together with \u0026#39;Defaults targetpw\u0026#39;!   警告：切勿漏掉这一步，否则任何用户都能以 root 身份执行任何命令。\n  测试配置\n尝试以 wheel 的成员和非成员身份运行 sudo。\n# user tux $ groups users wheel $ sudo id -un tux\u0026#39;s password: root # use wilber $ groups users $ sudo id -un wilber is not in the sudoers file. This incident will be reported.   对 X.Org 应用程序使用 sudo 在使用 sudo 启动图形应用程序时，可能会出现以下错误：\n$ sudo xterm xterm: Xt error: Can\u0026#39;t open display: %s xterm: DISPLAY is not set YaST 会选择 ncurses 界面而非图形界面。\n要在通过 sudo 启动的应用程序中使用 X.Org，需要传播环境变量 DISPLAY 和 XAUTHORITY。要进行此项配置，请创建文件 /etc/sudoers.d/xorg并添加下面一行：\nDefaults env_keep += \u0026#34;DISPLAY XAUTHORITY\u0026#34; 如尚未设置 XAUTHORITY 变量，请按如下方式设置：\nexport XAUTHORITY=~/.Xauthority 现在，X.Org 应用程序便可正常运行：\n$ sudo yast2 Zypper Zypper 是用于安装、更新和去除包的命令行包管理器。它还可管理储存库。这一点对于完成远程软件管理任务或从外壳脚本管理软件尤其有用。\n一般使用 Zypper 的常用语法为：\nzypper [--global-options] COMMAND [--command-options] [arguments] 有关常规选项和所有命令的列表，请参见 zypper help。要获取有关特定命令的帮助，请键入 zypper help 命令。\n  Zypper 命令\n执行 Zypper 最简单的方式是，键入其名称后跟一个命令。例如，要将所有需要的增补程序应用于系统，请使用：\n$ sudo zypper patch   全局选项\n此外，您还可以选择使用一个或多个全局选项，只需在命令前面键入它们即可：\n$ sudo zypper --non-interactive patch 在上面的示例中，选项 --non-interactive 表示在不询问任何问题的情况下运行命令（自动应用默认回答）。\n  命令特定的选项\n要使用特定于某个命令的选项，请紧接在该命令后面键入这些选项：\n$ sudo zypper patch --auto-agree-with-licenses 在上面的示例中，--auto-agree-with-licenses 用于将所有需要的增补程序应用于系统，不要求您确认任何许可条款，而是自动接受许可条款。\n  自变量\n某些命令需要一个或多个自变量。例如，使用 install 命令时，需要指定您要安装的一个或多个包：\n$ sudo zypper install mplayer 某些选项还需要单个自变量。用以下命令可列出所有已知模式：\n$ zypper search -t pattern   您可以组合上述所有模式。例如，下面的命令在冗长模式下运行时将安装 mc and vim 包（来自 factory 储存库）：\n$ sudo zypper -v install --from factory mc vim --from 选项确保了在从指定储存库请求包时保留所有储存库的启用状态（用于解析任何依赖项）。\n多数 Zypper 命令都有 dry-run 选项，它模拟给定的命令。它可用于测试。\n$ sudo zypper remove --dry-run MozillaFirefox Zypper 支持 --userdata 字符串全局选项。您可以使用此选项指定一个将会写入 Zypper 的日志文件和插件（例如 Btrfs 插件）的字符串。它可以用于标记和标识日志文件中的事务。\n$ sudo zypper --userdata STRING patch 使用 Zypper 安装和删除软件 要安装或去除包，请使用以下命令：\n$ sudo zypper install PACKAGE_NAME$ sudo zypper remove PACKAGE_NAME 警告：不要去除必需的系统包，例如 glibc 、zypper、kernel。如果去除这些包，系统可能会变得不稳定，或完全停止工作。\n选择要安装或去除的包 可以使用 zypper install 和 zypper remove 命令通过多种方法来找到包。\n  按确切的包名称\n$ sudo zypper install MozillaFirefox   按确切的包名称和版本号\n$ sudo zypper install MozillaFirefox-52.2   按储存库别名和包名称\n$ sudo zypper install mozilla:MozillaFirefox 其中 mozilla 是用于安装的储存库别名。\n  使用通配符按包名称\n您可以选择名称以特定字符串开头或结尾的所有包。使用通配符要小心，特别是去除包的时候。以下命令将安装名称以“Moz”开头的所有包：\n$ sudo zypper install 'Moz*' 提示：在调试问题时，您有时需要临时安装大量的 -debuginfo 包，以获取有关正在运行的进程的详细信息。在调试会话完成后，如果您需要清理环境，请运行以下命令：\n$ sudo zypper remove '*-debuginfo'   按功能\n例如，要安装不知道名称的包，这些功能就很有用。下面的命令将安装包 MozillaFirefox：\n$ sudo zypper install firefox   按功能、硬件体系结构或版本\n  所需硬件体系结构的名称需要追加在功能的后面，两者以句点分隔。例如，要指定 AMD64/Intel 64 体系结构（在 Zypper 中命名为 x86_64），请使用：\n$ sudo zypper install 'firefox.x86_64'   版本必须追加到字符串的末尾，并且前面必须带有一个运算符：\u0026lt;（小于）、\u0026lt;=（小于等于）、=（等于）、\u0026gt;=（大于等于）或 \u0026gt;（大于）。\n$ sudo zypper install 'firefox\u0026gt;=52.2'   还可以指定硬件体系结构与版本组合要求：\n$ sudo zypper install 'firefox.x86_64\u0026gt;=52.2'     按 RPM 文件的路径\n您还可以指定包的本地或远程路径：\n$ sudo zypper install /tmp/install/MozillaFirefox.rpm$ sudo zypper install http://download.example.com/MozillaFirefox.rpm   同时安装和去除包 要同时安装和去除包，请使用 +/- 修饰符。要安装 emacs 并同时去除 vim ，请使用：\n$ sudo zypper install emacs -vim 要去除 emacs 并同时安装 vim ，请使用：\n$ sudo zypper remove emacs +vim 为避免 - 开头的包名称被解释为命令行选项，要始终把它用作第二个自变量。如果做不到这点，在它之前加上 --：\n$ sudo zypper install -emacs +vim # Wrong$ sudo zypper install vim -emacs # Correct$ sudo zypper install -- -emacs +vim # Correct$ sudo zypper remove emacs +vim # Correct 清理已去除包的依赖项 如果您想将在指定的包去除后不再需要的所有包（随指定的包）自动去除，请使用 --clean-deps 选项：\n$ sudo zypper rm PACKAGE_NAME --clean-deps 在脚本中使用 Zypper 默认情况下，在安装或删除选定包之前发生问题时，Zypper 会要求确认。您可以使用 --non-interactive 选项覆盖此行为。必须在实际命令（install、remove 和 patch）的前面指定此选项，如下所示：\n$ sudo zypper --non-interactive install PACKAGE_NAME 该选项允许在脚本和 cron 任务中使用 Zypper。\n安装或下载源包 要安装某个包的对应源代码包，请使用：\n$ zypper source-install PACKAGE_NAME 以 root 身份执行时，源包的默认安装位置为 /usr/src/packages/；以用户身份运行时，则为 ~/rpmbuild。可以在本地 rpm 配置中更改这些值。\n使用此命令还会安装指定包的版本依赖项。如果不想执行此操作，请添加开关 -D：\n$ sudo zypper source-install -D PACKAGE_NAME 要只安装版本依赖项，请使用 -d。\n$ sudo zypper source-install -d PACKAGE_NAME 当然，只有当储存库列表中启用了含有源包的储存库时，才能这样做（默认添加但不启用它）。\n可使用以下方法来获取储存库中所有源包的列表：\n$ zypper search -t srcpackage 您也可以将所有已安装软件包的源包下载到本地目录。要下载源包，请使用：\n$ zypper source-download 默认的下载目录是 /var/cache/zypper/source-download。您可以使用 --directory 选项更改下载目录。若只想显示缺失或多余的包而不进行下载或删除任何内容，请使用 --status 选项。要删除多余的源包，请使用 --delete 选项。要禁用删除，请使用 --no-delete 选项。\n从禁用的储存库安装包 通常，您只能安装或刷新来自启用的储存库的包。--plus-content 标记选项可帮助您指定要刷新的、要在当前 Zypper 会话期间暂时启用的，以及要在会话完成后禁用的储存库。\n例如，要启用可以提供其他 -debuginfo 或 -debugsource 包的储存库，请使用 --plus-content debug。可以多次指定此选项。\n要暂时启用此类“调试”储存库以安装特定的 -debuginfo 包，请按如下所示使用该选项：\n$ sudo zypper --plus-content debug \\ install \u0026quot;debuginfo(build-id)=eb844a5c20c70a59fc693cd1061f851fb7d046f4\u0026quot; 对于缺少的 debuginfo 包，gdb 将会报告 build-id 字符串。\n实用程序 要校验所有依赖项是否仍然满足，并修复缺少的依赖项，请使用：\n$ zypper verify 除了依赖项必须满足外，某些包还“推荐”其他包。只有在实际可用并可安装时才会安装这些推荐包。如果推荐的包在推荐它们的包已安装（通过添加其他包或硬件）之后才可用，请使用以下命令：\n$ sudo zypper install-new-recommends 此命令在插入网络摄像头或 Wi-Fi 设备后非常有用。如果可用，它将安装设备驱动程序和相关软件。只有在满足特定硬件依赖项后，才可安装驱动程序和相关软件。\n使用 Zypper 更新软件 用 Zypper 更新软件有三种方式：安装包、安装包的新版本或更新整个分发包。最后一种方式可通过 zypper dist-upgrade 来实现。\n安装全部所需的增补程序 要安装所有适用于您系统的正式发布的增补程序，请运行：\n$ sudo zypper patch 系统将会检查您计算机上配置的储存库中提供的所有增补程序是否与您的安装相关。如果相关（未分为可选或功能类别），则会立即安装这些增补程序。\n如果即将安装的增补程序所包含的更改要求重引导系统，您会在重引导前收到警告。\n单纯使用 zypper patch 命令不会应用来自第三方储存库的包。要同时更新第三方储存库，请使用 with-update 命令选项，如下所示：\n$ sudo zypper patch --with update 要额外安装可选增补程序，请使用：\n$ sudo zypper patch --with-optional 要安装与特定 Bugzilla 问题相关的所有增补程序，请使用：\n$ sudo zypper patch --bugzilla=NUMBER 要安装与特定 CVE 数据库项相关的所有增补程序，请使用：\n$ sudo zypper patch --cve=NUMBER 例如，要安装 CVE 编号为 CVE-2010-2713 的安全增补程序，请执行：\n$ sudo zypper patch --cve=CVE-2010-2713 如果只想安装影响 Zypper 和包管理本身的增补程序，请使用：\n$ sudo zypper patch --updatestack-only 请记住，如果您使用了 updatestack-only 命令选项，将会丢弃原本还会更新其他储存库的其他命令选项。\n列出增补程序 为了让您确定增补程序是否可用，Zypper 允许您查看以下信息：\n  所需增补程序的数目\n要列出所需增补程序（适用于您的系统但尚未安装的增补程序）的数目，请使用 patch-check：\n$ zypper patch-checkLoading repository data...Reading installed packages...5 patches needed (1 security patch) 可以结合 --updatestack-only 选项使用此命令，以便仅列出影响 Zypper 和包管理本身的增补程序。\n  所需增补程序的列表\n要列出全部所需的增补程序（适用于您的系统但尚未安装的增补程序），请使用 list-patches：\n$ zypper list-patchesLoading repository data...Reading installed packages...Repository | Name | Version | Category | Status | Summary---------------+-------------+---------+----------+---------+---------SLES12-Updates | SUSE-2014-8 | 1 | security | needed | openssl: Update for OpenSSL   所有增补程序的列表\n要列出可用的所有增补程序，而不管它们是否已安装或适用于您的安装，请使用 zypper patches。\n还可以列出并安装与特定问题相关的增补程序。要列出特定的增补程序，请使用带以下选项的 zypper list-patches 命令：\n  按 Bugzilla 问题\n要列出与 Bugzilla 问题相关的全部所需增补程序，请使用 --bugzilla 选项。\n要列出针对特定 Bug 的增补程序，您也可以指定 Bug 编号：--bugzilla=编号。要搜索与多个 Bugzilla 问题相关的增补程序，请在 bug 编号之间添加逗号，例如：\n$ zypper list-patches --bugzilla=972197,956917   按 CVE 编号\n要列出与 CVE（公共漏洞和披露）数据库中某个项相关的全部所需增补程序，请使用 --cve 选项。\n要列出针对特定 CVE 数据库项的增补程序，您也可以指定 CVE 编号：--cve=*编号*。要搜索与多个 CVE 数据库项相关的增补程序，请在 CVE 编号之间添加逗号，例如：\n$ zypper list-patches --bugzilla=CVE-2016-2315,CVE-2016-2324     要列出所有增补程序而不管是否需要安装它们，请另外使用 --all 选项。例如，要列出指派有 CVE 编号的所有增补程序，请使用：\n$ zypper list-patches --all --cveIssue | No. | Patch | Category | Severity | Status------+---------------+-------------------+-------------+-----------+----------cve | CVE-2015-0287 | SUSE-SLE-Module.. | recommended | moderate | neededcve | CVE-2014-3566 | SUSE-SLE-SERVER.. | recommended | moderate | not needed[...] 安装新的包版本 如果某个安装源只包含新包，但未提供增补程序，则 zypper patch 不会产生任何作用。要使用可用的较新版本更新所有已安装的包（同时还要保持系统完整性），请使用︰\n$ sudo zypper update 要更新个别包，请用更新或安装命令指定包：\n$ sudo zypper update PACKAGE_NAME$ sudo zypper install PACKAGE_NAME 可使用此命令来获取所有新的可安装包的列表：\n$ zypper list-updates 请注意，此命令只会列出符合以下准则的包︰\n 与已安装的包拥有相同的供应商， 由至少与已安装包拥有相同优先级的储存库提供， 可安装（满足所有依赖项）。  所有新的可用包（无论是否可安装）的列表可通过以下方式获取：\n$ sudo zypper list-updates --all 要找出新包无法安装的原因，请使用上面所述的 zypper install 或 zypper update 命令。\n识别孤立的包 每当您从 Zypper 中去除某个储存库或者升级系统时，某些包可能会进入“孤立”状态。这些孤立的包不再属于任何活动储存库。以下命令可以列出这些包：\n$ sudo zypper packages --orphaned 借助此列表，您可以确定是否仍然需要某个包，或者是否可以安全去除某个包。\n识别使用已删除文件的进程和服务 在增补、更新或去除包时，系统上可能有一些正在运行的进程会继续使用更新或去除后已被删除的文件。运行 zypper ps 可以列出使用已删除文件的进程。如果此类进程属于某个已知的服务，则会列出服务名称，方便您重启动该服务。默认情况下，zypper ps 会显示一个表：\nPID | PPID | UID | User | Command | Service | Files------+------+-----+-------+--------------+--------------+-------------------814 | 1 | 481 | avahi | avahi-daemon | avahi-daemon | /lib64/ld-2.19.s-\u0026gt; | | | | | | /lib64/libdl-2.1-\u0026gt; | | | | | | /lib64/libpthrea-\u0026gt; | | | | | | /lib64/libc-2.19-\u0026gt;[...]  PID：进程的 ID PPID：父进程的 ID UID：运行进程的用户的 ID User：运行进程的用户的登录名 Command：用于执行进程的命令 Service：服务名称（仅当命令与系统服务关联时才显示） Files：已删除文件的列表  通过如下方式可控制 zypper ps 的输出格式：\n  zypper ps -s\n创建一份简短表格，其中不会显示已删除的文件。\nPID | PPID | UID | User | Command | Service------+------+------+---------+--------------+--------------814 | 1 | 481 | avahi | avahi-daemon | avahi-daemon817 | 1 | 0 | root | irqbalance | irqbalance1567 | 1 | 0 | root | sshd | sshd1761 | 1 | 0 | root | master | postfix1764 | 1761 | 51 | postfix | pickup | postfix1765 | 1761 | 51 | postfix | qmgr | postfix2031 | 2027 | 1000 | tux | bash |   zypper ps -ss\n仅显示与系统服务关联的进程。\nPID | PPID | UID | User | Command | Service------+------+------+---------+--------------+--------------814 | 1 | 481 | avahi | avahi-daemon | avahi-daemon817 | 1 | 0 | root | irqbalance | irqbalance1567 | 1 | 0 | root | sshd | sshd1761 | 1 | 0 | root | master | postfix1764 | 1761 | 51 | postfix | pickup | postfix1765 | 1761 | 51 | postfix | qmgr | postfix   zypper ps -sss\n仅显示使用已删除文件的系统服务。\navahi-daemonirqbalancepostfixsshd   zypper ps --print \u0026quot;systemctl status %s\u0026quot;\n显示用于检索可能需要重启动的服务状态信息的命令。\nsystemctl status avahi-daemonsystemctl status irqbalancesystemctl status postfixsystemctl status sshd   用 Zypper 管理安装源 Zypper 的所有安装或增补程序命令均基于已知安装源列表。要列出系统已知的所有储存库，请使用命令：\n$ zypper repos 结果将类似于与以下输出：\n# | Alias | Name | Enabled | Refresh--+--------------+---------------+---------+--------1 | SLEHA-12-GEO | SLEHA-12-GEO | Yes | No2 | SLEHA-12 | SLEHA-12 | Yes | No3 | SLES12 | SLES12 | Yes | No 当在各个命令中指定储存库时，可以使用别名、URI 或 zypper repos 命令输出中的储存库编号。储存库别名是用于储存库处理命令中的储存库名称的简短版本。请注意，在修改储存库列表后，储存库编号可能会更改。别名本身不会更改。\n默认情况下不显示储存库的 URI 或优先级之类的细节。用以下命令可以列出所有细节：\n$ zypper repos -d 添加安装源 要添加安装源，请运行\n$ sudo zypper addrepo URI ALIAS URI 可以是因特网储存库、网络资源、目录、CD 或 DVD。ALIAS 是储存库的唯一简写标识符。您可以随意选择别名，前提是它必须唯一。如果指定的别名已在使用，Zypper 将发出警告。\n刷新储存库 zypper 可让您从配置的储存库中提取包的更改。要提取更改，请运行：\n$ sudo zypper refresh 注意：有些命令默认会自动执行 refresh，因此您不需要明确运行该命令。\n使用 refresh 命令时搭配 --plus-content 选项还可查看已禁用储存库中的更改：\n$ sudo zypper --plus-content refresh 该选项虽然会提取储存库中的更改，但会使禁用储存库的状态保持不变，即仍为禁用。\n删除储存库 要从列表中去除某个储存库，请将命令 zypper removerepo 与要删除的储存库的别名或编号结合使用。例如\n$ sudo zypper removerepo 1$ sudo zypper removerepo \u0026quot;SLEHA-12-GEO\u0026quot; 修改储存库 用 zypper modifyrepo 启用或禁用储存库。您还可以用该命令更改储存库的属性（例如刷新行为、名称或优先级）。以下命令将会启用名为 updates 的储存库、打开自动刷新并将其优先级设置为 20：\n$ sudo zypper modifyrepo -er -p 20 'updates' 修改储存库并不局限于单个储存库 —— 您也可以对组执行该操作︰\n -a：所有储存库 -l：本地储存库 -t：远程储存库 -m 类型：特定类型的储存库（其中类型可以是以下之一：http、https、ftp、cd、dvd、dir、file、cifs、smb、nfs、hd 和 iso）  要重命名安装源别名，请使用 renamerepo 命令。以下示例将别名从 Mozilla Firefox 更改为 firefox：\n$ sudo zypper renamerepo 'Mozilla Firefox' firefox 用 Zypper 查询储存库和包 Zypper 提供各种查询储存库或包的方式。要获取所有可用的产品、模式、包或增补程序的列表，请使用以下命令：\n$ zypper products$ zypper patterns$ zypper packages$ zypper patches 要查询特定包的所有储存库，请使用 search。要获得有关特定包的信息，请使用 info 命令。\n搜索软件 zypper search 命令可对包名或（视情况）对包摘要和说明执行搜索。括在 / 中的字符串会解译为正则表达式。默认情况下搜索不区分大小写。\n  执行简单搜索来查找包含 fire 的包名称\n$ zypper search \u0026quot;fire\u0026quot;   执行简单搜索来查找确切的包 MozillaFirefox\n$ zypper search --match-exact \u0026quot;MozillaFirefox\u0026quot;   同时在包描述和摘要中搜索\n$ zypper search -d fire   仅显示尚未安装的包\n$ zypper search -u fire   显示包含字符串 fir 且该字符串后面不是 e 的包\n$ zypper se \u0026quot;/fir[^e]/\u0026quot;   搜索特定功能 要搜索提供特殊功能的包，请使用命令 what-provides。例如，如果您想知道哪个包提供 Perl 模块 SVN::Core，请使用以下命令：\n$ zypper what-provides 'perl(SVN::Core)' what-provides 包名 与 rpm -q --whatprovides 包名 类似，不过 RPM 只能查询 RPM 数据库（即所有已安装的包的数据库）。另一方面，Zypper 将告诉您任意储存库的功能的提供商，而非仅已安装的储存库功能的提供商。\n显示包信息 要查询个别包，请使用 info 命令，并用完整包名称作为自变量。这会显示有关某个包的详细信息。如果包名与储存库中的所有包名都不匹配，该命令会输出非包匹配项的详细信息。如果您请求特定类型（通过使用 -t 选项），但该类型不存在，该命令会输出其他可用的匹配项，但不提供详细信息。\n如果您指定源包，该命令会显示基于该源包构建的二进制包。如果您指定二进制包，该命令会输出用来构建该二进制包的源包。\n如果还要显示该包必需/推荐的包，则使用选项 --requires 和 --recommends：\nzypper info --requires MozillaFirefox 显示生命周期信息 要检查您的产品和所支持包的生命周期，请如下所示使用 zypper lifecycle 命令：\n$ zypper lifecycleProduct end of supportCodestream: SUSE Linux Enterprise Server 15 2028-04-23 SUSE Linux Enterprise Server 15 n/a*Module end of supportBasesystem Module 2021-07-31No packages with end of support different from product.*) See https://www.suse.com/lifecycle for latest information 配置 Zypper Zypper 现在随附配置文件，允许您永久更改 Zypper 的行为（系统范围或用户特定）。要进行系统范围更改，请编辑 /etc/zypp/zypper.conf。要进行用户特定的更改，请编辑 ~/.zypper.conf。如果 ~/.zypper.conf 尚不存在，您可以使用 /etc/zypp/zypper.conf 作为模板：将其复制到 ~/.zypper.conf 并根据您的喜好进行调整。请参见文件中的注释，获取有关可用选项的帮助。\n查错 如果您在访问配置的储存库中的包时遇到问题（例如，尽管您知道某个包在某个储存库中，但 Zypper 找不到该包），刷新储存库或许可以解决问题：\nsudo zypper refresh 如果不起作用，则尝试\nsudo zypper refresh -fdb 这会强制完全刷新和重构建数据库，包括强制下载原始元数据。\nBtrfs 文件系统上的 Zypper 回滚功能 如果根分区上使用的是 Btrfs 文件系统，且系统中安装了 snapper，当 Zypper 提交对文件系统所做的更改以创建相应的文件系统快照时，会自动调用 snapper。这些快照可用于还原 Zypper 进行的任何更改。\nzypper autoremove zypper 提供了 subcommand 子命令的功能，可以将自定义脚本当作 zypper 命令来执行。所以可以编写这样一个脚本：\n$ sudo vi /usr/lib/zypper/commands/zypper-autoremove #!/bin/sh packages=$(zypper -tqn --no-refresh packages --unneeded | grep \u0026#39;^i |\u0026#39; | awk -F \u0026#34;|\u0026#34; \u0026#39;{print $3}\u0026#39;) if [[ -n \u0026#34;$packages\u0026#34; ]]; then echo $packages | xargs zypper remove --clean-deps else echo \u0026#34;No unneeded package found.\u0026#34; fi $ sudo chmod u+x /usr/lib/zypper/commands/zypper-autoremove 命名为 zypper-autoremove，放在你的 $PATH 下或者 /usr/lib/zypper/commands 里面，就可以通过\n$ sudo zypper autoremove 命令来实现清理无用包的功能了。\nzypper auto-refreshes Zypper auto-refreshes the repos when you run it. Disable it.\n$ sudo zypper modifyrepo -a -R -R is legacy. -F should also work. If no name is specified, the action is done on all repos.\nRPM RPM（RPM 程序包管理器）用于管理软件包。其主要程命令为 rpm 和 rpmbuild。用户、系统管理员和包构建人员可以查询强大的 RPM 数据库以获得有关已安装软件的详细信息。\nrpm 有五种模式：安装、卸装（或更新）软件包、重构建 RPM 数据库、查询 RPM 库或独立 RPM 存档、对包执行完整性检查以及对包签名。rpmbuild 可用于从原始源构建可安装的包。\n用特殊的二进制格式对可安装 RPM 存档进行打包。这些存档由要安装的程序文件和某些元信息组成，这些元信息供 rpm 在安装过程中配置软件包使用或者储存在 RPM 数据库中进行存档。RPM 存档通常具有扩展名 .rpm。\n对于一些包，软件开发所需的组件（库、报头、包含文件等）已纳入独立的包中。只有当您要自己编译软件时才需要这些开发包（例如最新的 GNOME 包）。可以通过扩展名 -devel 确定这些开发包，例如包 alsa-devel 和 gimp-devel。\n校验包真实性 RPM 包具有 GPG 签名。要校验 RPM 包的签名，请使用 rpm --checksig PACKAGE-1.2.3.rpm 命令确定该包是来自 SUSE 还是另一个可信机构。特别建议对来自因特网的更新包使用此命令。\n修复操作系统中的问题时，您可能需要将问题临时修复 (PTF) 安装到生产系统中。SUSE 提供的包已使用特殊的 PTF 密钥签名。要手动导入该密钥，请使用以下命令：\nsudo rpm --import \\/usr/share/doc/packages/suse-build-key/suse_ptf_key.asc 导入该密钥后，您可以在系统上安装 PTF 包。\n管理包：安装、更新和卸装 安装 RPM 存档的步骤通常十分简单，执行运行：rpm -i PACKAGE.rpm。使用此命令可以安装包，但前提是满足其依赖关系并且不与其他包冲突。如果出现错误消息，rpm 将请求那些需要安装的包以满足依赖关系要求。在后台，RPM 数据库确保不出现冲突 － 一个特定文件只能属于一个包。通过选择不同的选项，您可以强制 rpm 忽略这些默认设置，但这只供专家用户使用。否则，将影响系统的完整性并可能使系统无法更新。\n选项 -U 或 --upgrade 以及 -F 或 --freshen 可用于更新包（例如，rpm -F PACKAGE.rpm）。此命令将删除旧版本的文件并立即安装新文件。两个版本之间的差别是：-U 安装系统中以前不存在的包，而 -F 只更新以前安装的包。更新时，rpm 使用以下策略小心更新配置文件：\n 如果配置文件未被系统管理员更改，则 rpm 将安装适当文件的新版本。系统管理员无需执行任何操作。 如果配置文件在更新前曾被系统管理员更改，则 rpm 会以扩展名 .rpmorig 或 .rpmsave（备份文件）保存更改的文件，并安装新包中的版本。仅当原先安装的文件和较新的版本不同时，才执行此操作。如果是这种情况，则将备份文件（.rpmorig 或 .rpmsave）与新安装的文件进行比较，并在新文件中再次进行更改。之后，请删除所有 .rpmorig 和 .rpmsave 文件，以免以后的更新出现问题。 如果配置文件已存在并且 .spec 文件中指定了 noreplace 标签，则出现 .rpmnew 文件。  更新后，在使用 .rpmsave 和 .rpmnew 文件进行比较后应将它们删除，从而防止它们阻碍以后的更新。如果 RPM 数据库以前未能识别文件，则将为其指派扩展名 .rpmorig。 否则，将使用 .rpmsave。换句话说，.rpmorig 是从异系统格式更新为 RPM 的结果。而 .rpmsave 是从较早的 RPM 更新为较新的 RPM 的结果。.rpmnew 不提供任何有关系统管理员是否对配置文件进行过任何更改的信息。/var/adm/rpmconfigcheck 中提供这些文件的列表。不覆盖某些配置文件（如 /etc/httpd/httpd.conf）以允许继续进行操作。\n-U 开关的作用并不完全等同于使用 -e 选项进行卸载以及使用 -i 选项进行安装，它还有其他作用。只要可能，就可以使用 -U。\n要去除包，请输入 rpm -e PACKAGE。仅当不存在未解决的依赖项问题时，此命令才会删除包。例如，只要有其他程序需要 Tcl/Tk，理论上就不能删除它。即使是在这种情况下，RPM 也会向数据库寻求帮助。如果出于任何原因无法进行此删除操作（即使不存在其他依赖项），则最好使用选项 --rebuilddb 重构建 RPM 数据库。\n增量 RPM 包 增量 RPM 包包含旧版本和新版本的 RPM 包之间的差别。在旧 RPM 上应用增量 RPM 将得到全新的 RPM。不需要旧 RPM 的副本，因为增量 RPM 也可以与已安装的 RPM 一起工作。增量 RPM 包的大小甚至比增补程序 RPM 小，这有利于通过因特网传送更新包。缺点是，涉及增量 RPM 的更新操作与使用纯粹 RPM 或增补程序 RPM 进行更新的情况相比，占用的 CPU 周期要长得多。\nmakedeltarpm 和 applydelta 二进制文件是增量 RPM 套件（包 deltarpm）的一部分，可帮助您创建和应用增量 RPM 包。使用以下命令可以创建名为 new.delta.rpm 的增量 RPM。以下命令假设 old.rpm 和 new.rpm 是存在的：\nsudo makedeltarpm old.rpm new.rpm new.delta.rpm 如果旧包已经安装，则使用 applydeltarpm 可以从文件系统重新构建新的 RPM：\nsudo applydeltarpm new.delta.rpm new.rpm 如果不访问文件系统而从旧 RPM 得到它，请使用 -r 选项：\nsudo applydeltarpm -r old.rpm new.delta.rpm new.rpm RPM 查询 带 -q 选项的 rpm 将启动查询，如此用户便可查看 RPM 存档（通过添加选项 -p）并查询已安装包的 RPM 数据库。可以使用多个开关指定所需信息的类型。\n   选项 含义     -i 包信息   -l 文件列表   -f FILE 查询包含文件 FILE 的包（必须使用 FILE 指定完整路径）   -s 带有状态信息的文件列表（间接指定 -l）   -d 仅列出文档文件（间接指定 -l）   -c 仅列出配置文件（间接指定 -l）   --dump 带有完整详细信息的文件列表（将用于 -l、-c 或 -d）   --provides 列出包中可被另一个包通过 --requires 请求的功能   --requires, -R 包需要的功能   --scripts 安装脚本（预安装、后安装、卸载）    例如，命令 rpm -q -i wget 显示\nName : wgetVersion : 1.14Release : 17.1Architecture: x86_64Install Date: Mon 30 Jan 2017 14:01:29 CETGroup : Productivity/Networking/Web/UtilitiesSize : 2046483License : GPL-3.0+Signature : RSA/SHA256, Thu 08 Dec 2016 07:48:44 CET, Key ID 70af9e8139db7c82Source RPM : wget-1.14-17.1.src.rpmBuild Date : Thu 08 Dec 2016 07:48:34 CETBuild Host : sheep09Relocations : (not relocatable)Packager : https://www.suse.com/Vendor : SUSE LLC \u0026lt;https://www.suse.com/\u0026gt;URL : http://www.gnu.org/software/wget/Summary : A Tool for Mirroring FTP and HTTP ServersDescription :Wget enables you to retrieve WWW documents or FTP files from a server.This can be done in script files or via the command line.Distribution: SUSE Linux Enterprise 12 只有当您指定带有完整路径的完整文件名时，选项 -f 才起作用。根据需要提供任意多个文件名。例如：\nrpm -q -f /bin/rpm /usr/bin/wgetrpm-4.11.2-15.1.x86_64wget-1.14-17.1.x86_64 如果只知道部分文件名，则可以使用外壳脚本。当运行所显示的脚本时，将部分文件名以参数的形式传递给脚本。\n#! /bin/shfor i in $(rpm -q -a -l | grep $1); do echo \u0026quot;\\\u0026quot;$i\\\u0026quot; is in package:\u0026quot; rpm -q -f $i echo \u0026quot;\u0026quot;done rpm -q --changelog PACKAGE 命令会按日期排序显示有关特定包的详细更改信息列表。\n借助已安装的 RPM 数据库，可以进行校验检查。使用 -V 或 --verify 启动这些检查。使用此选项，rpm 显示安装后已被更改的包中的所有文件。rpm 使用 8 个字符符号给出有关以下更改的一些提示：\n   符号 含义     5 MD5 校验和   S 文件大小   L 符号链接   T 修改时间   D 主要和次要设备编号   U 拥有者   G 组   M 方式（权限和文件类型）    对于配置文件，将输出字母 c。例如，对于 /etc/wgetrc（wget 包）的更改：\nrpm -V wgetS.5....T c /etc/wgetrc RPM 数据库的文件被放置在 /var/lib/rpm 中。如果分区 /usr 的大小为 1 GB，则此数据库可能会占用将近 30 MB，特别是在完全更新之后。如果数据库比预期大得多，则最好使用选项 --rebuilddb 重构建数据库。在执行此操作之前，制作旧数据库的备份。cron 脚本 cron.daily 每天制作数据库的副本（用 gzip 打包）并将这些副本储存在 /var/adm/backup/rpmdb 中。副本的数目是由 /etc/sysconfig/backup 中的变量 MAX_RPMDB_BACKUPS（默认值为 5）控制的。对于 1 GB 的 /usr，单个备份的大小大约为 1 MB。\n安装和编译源包 所有源包都带有 .src.rpm 扩展名（源 RPM）。\n源包可以从安装媒体复制到硬盘并使用 YaST 解压缩。但是，在包管理器中它们不会被标记为已安装 ([i])。这是因为源包不是在 RPM 数据库中输入的。只有已安装的操作系统软件列在 RPM 数据库中。安装源包时，只将源代码添加到系统中。\n以下目录必须可用于 /usr/src/packages 中的 rpm 和 rpmbuild（除非在诸如 /etc/rpmrc 这样的文件中指定自定义设置）：\n  SOURCES\n代表原始源（.tar.bz2 或 .tar.gz 文件等）和特定于发布版本的调整（多为 .diff 或 .patch 文件）\n  SPECS\n代表 .spec 文件，类似于元 Makefile，该文件控制构建进程\n  BUILD\n在此目录中解压缩、增补和编译所有源\n  RPMS\n储存完整的二进制包的位置\n  SRPMS\n这里是源 RPM\n  使用 YaST 安装源包时，将在 /usr/src/packages 中安装所有需要的组件：源和调整在 SOURCES 中，相关的 .spec 文件在 SPECS 中。\n警告：不要对系统组件（glibc、rpm 等）进行试验，因为这样做会影响系统的稳定性。\n下面的示例使用 wget.src.rpm 包。安装源包后，应具有类似以下列表中的文件：\n/usr/src/packages/SOURCES/wget-1.11.4.tar.bz2/usr/src/packages/SOURCES/wgetrc.patch/usr/src/packages/SPECS/wget.spec rpmbuild -bX /usr/src/packages/SPECS/wget.spec 会启动编译。X 是通配符，代表构建进程的不同阶段。以下简要描述：\n  -bp\n在 /usr/src/packages/BUILD 中准备源：解压和打增补程序。\n  -bc\n执行与 -bp 相同的操作，但还进行编译。\n  -bi\n执行与 -bp 相同的操作，但还安装生成的软件。注意：如果包不支持 BuildRoot 功能，则可能会重写配置文件。\n  -bb\n执行与 -bi 相同的操作，但还创建二进制包。如果编译成功，二进制包应该在 /usr/src/packages/RPMS 中。\n  -ba\n执行与 -bb 相同的操作，但还创建源 RPM。如果编译成功，二进制包应该在 /usr/src/packages/SRPMS 中。\n  --short-circuit\n跳过某些步骤。\n  现在可以使用 rpm -i 或最好使用 rpm -U 来安装创建的二进制 RPM。使用 rpm 进行安装使它显示在 RPM 数据库中。\n使用 build 编译 RPM 包 许多包存在的风险是构建进程中会将许多不需要的文件添加到正在运行的系统中。为防止发生这种情况，请使用 build，它将创建构建包的已定义环境。要建立这一 chroot 环境，build 脚本必须和完整的包树结构一起提供。可以通过 NFS 或从 DVD 使用硬盘上的此树。使用 build --rpms DIRECTORY 设置位置。与 rpm 不同，build 命令在源目录中查找 .spec 文件。要用系统中 /media/dvd 下装入的 DVD 构建 wget（如上例所示），请以 root 用户身份使用以下命令：\ncd /usr/src/packages/SOURCES/mv ../SPECS/wget.spec .build --rpms /media/dvd/suse/ wget.spec 随后，将在 /var/tmp/build-root 建立一个最小的环境。在此环境中构建包。完成后，生成的包位于 /var/tmp/build-root/usr/src/packages/RPMS 中。\nbuild 脚本提供多个其他选项。例如，使脚本优先选择您自己的 RPM、忽略构建环境的初始化或者将 rpm 命令限制在上述阶段之一。\n用于 RPM 存档和 RPM 数据库的工具 Midnight Commander (mc) 可以显示 RPM 存档的内容并复制部分内容。它将存档表示为虚拟文件系统，提供 Midnight Commander 所有常用的菜单选项。使用 F3 键显示 HEADER。使用光标键和 Enter 键查看存档结构。使用 F5 键复制部分存档。\n拥有全部功能的包管理器将作为 YaST 模块提供。\nFirewall-cmd Firewall-cmd 是 Firewalld 的命令行工具。\nfirewall-cmd(firewalld command line client) 是 firewalld 的主要命令行工具。它可以用来获取 firewalld 的状态信息，获取运行时和永久环境的防火墙配置，也可以用来修改这些配置。根据所选择的策略，你需要通过 Root 认证才能访问或更改 firewalld 的配置。它只有在 firewalld 运行的情况下才能使用。firewall-cmd 充当 nftables/iptables 的前端。\n该文主要描述 firewall-cmd 的简易使用方法，更多内容详见：Firewalld Documentation\n准备工作 openSUSE 已经默认安装并激活了 firewalld ，但你可以使用下列方法安装 firewalld ：\n$ sudo zypper ref $ sudo zypper update $ sudo zypper install firewalld Firewalld 的基本概念 区域（zone） firewalld 将所有的网络数据流量划分为多个区域，再根据数据包的源IP地址或传入网络接口等条件，将数据流量转入相应区域的防火墙规则中。\n你可以通过运行以下 ls 命令查看所有的区域：\n$ ls -l /usr/lib/firewalld/zones/ 使用 cat 指令查阅某个区域的详细内容\n$ cat /usr/lib/firewalld/zones/*.xml * 的可以替换成：\n block：拒绝所有传入的网络连接。只有从系统内部发起的网络连接才可能有效； dmz：隔离区域也称为非军事化区域 (Demilitarized zone) ，为您的局域网提供有限的访问权限，并且只允许选定的传入端口； drop：终止所有传入链接，只允许传出的链接； external：对路由器类型的连接很有用。你需要局域网和广域网的接口来进行伪装（NAT）才能正常工作。 home：适用于家庭电脑，如局域网内的笔记本电脑和台式机，您可以信任其他电脑。只允许选定的 TCP/IP 端口； internal：用于内部网络，当你几乎信任局域网内的其他服务器或计算机时； public（系统默认值）：适用于始终处于公共区域的云服务器或托管在您处的服务器。您不信任网络上的任何其他计算机和服务器。您只允许使用所需的端口和服务； trusted：允许任何的网络链接； work：适用于您信任您的同事和其他服务器的工作场所。  查看所有区域：\n$ sudo firewall-cmd --get-zones 查看默认区域：\n$ sudo firewall-cmd --get-default-zone #### OR $ sudo grep -i DefaultZone /etc/firewalld/firewalld.conf openSUSE 默认的区域是 public ，默认启用的服务是 ssh 和 dhcpv6-client 。 查看网络接口名称：\n$ ip link show 当 NetworkManager 添加新的接口连接（如 eth0 或 ens3）时，它们将被连接到默认的区域。通过运行以下命令进行验证：\n$ firewall-cmd --get-active-zones 服务（services） 服务是一个包含了本地端口、协议、源端口、目的地和防火墙帮助模块 (firewall helper modules) 的列表。\n查询与 public 相关的防火墙规则或服务：\n$ sudo firewall-cmd --list-all --zone=public public (active) target: default icmp-block-inversion: no interfaces: wlan0 sources: services: dhcpv6-client ports: protocols: masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: 在该查询结果中，默认区域是 public ，允许的服务是 dhcpv6-client 。假设你需要删除 dhcpv6-client ，那么你应该运行如下指令：\n$ sudo firewall-cmd --remove-service=dhcpv6-client --permanent --zone=public $ sudo firewall-cmd --reload #### 重载防火墙 $ sudo firewall-cmd --list-services #### 列出所有服务 运行下列指令查询特定区域允许的服务列表：\n$ sudo firewall-cmd --list-services #### 查询当前区域允许的服务 $ sudo firewall-cmd --list-services --zone=* #### 将 * 替换成你所需要查询服务的区域 $ sudo firewall-cmd --list-all-zones #### 查询全部区域的服务或防火墙规则 启动、检查和关闭 firewalld 服务 启动（Start）并激活（Enable）防火墙：\n$ sudo systemctl start firewalld $ sudo systemctl enable firewalld 检查防火墙服务状态：\n$ sudo systemctl status firewalld 检查防火墙状态：\n$ sudo firewall-cmd --state 检查 firewalld 是否开机启动：\n$ sudo systemctl is-enabled firewalld 更改规则后，重启防火墙让规则生效：\n$ sudo firewall-cmd --reload 暂停（Stop）和关闭（Disable）防火墙：\n$ sudo systemctl stop firewalld $ sudo systemctl disable firewalld 运行时和永久规则 运行时的 firewalld 配置更改是临时性的，当你重新启动 openSUSE 或 firewalld 时，它们就会消失。永久规则则不受影响。 例如\n$ sudo firewall-cmd --zone=public --add-service=kdeconnect #### 运行时规则 $ sudo firewall-cmd --zone=public --add-service=kdeconnect --permanent #### 永久规则 添加永久性规则\n$ sudo firewall-cmd --zone=* --add-service=** --permanent #### 将 * 替换成区域，将 ** 替换成服务名称，如 https. $ sudo firewall-cmd --reload #### 重启防火墙让规则生效。 确认规则是否生效：\n$ sudo firewall-cmd --list-services $ sudo firewall-cmd --list-services --permanent 查询 firewalld 支持的服务列表\n$ sudo firewall-cmd --get-services $ sudo firewall-cmd --get-services | grep kdeconnect $ ls -l /usr/lib/firewalld/services/ $ cat /usr/lib/firewalld/services/kdeconnect.xml Firewall-cmd 规则集样例 添加 DNS 服务（TCP/UDP 端口：53，区域为 public，永久性规则）：\n$ sudo firewall-cmd --zone=public --add-service=dns --permanent 删除某个服务（例如 VNC 服务器服务，TCP 端口：5900-5903，区域为 public，永久性规则）：\n$ sudo firewall-cmd --zone=public --remove-service=vnc-server --permanent 开放特定的端口（TCP/UDP），例如开放 TCP/UDP 端口：55527：\n$ sudo firewall-cmd --zone=public --add-port=55527/tcp --permanent $ sudo firewall-cmd --zone=public --add-port=55527/udp --permanent 查看已开放的端口：\n$ sudo firewall-cmd --zone=public --list-ports $ sudo firewall-cmd --zone=public --list-ports --permanent 拒绝/禁用特定端口：\n$ sudo firewall-cmd --zone=public --remove-port=23/tcp --permanent 注意，当 firewalld 的区域是 public 的时候，绝大多数端口是默认禁用的。\n编写端口转发 Firewalld 规则 将同一服务器上的 TCP 端口 443 转发到 8080：\n$ sudo firewall-cmd --zone=public --add-forward-port=port=80:proto=tcp:toport=8080 --permanent 要删除上述端口转发，请运行下列指令：\n$ sudo firewall-cmd --zone=public --remove-forward-port=port=80:proto=tcp:toport=8080 如果您需要将流量 (端口 443) 转发到 192.168.2.42 端口 443 的 lxd 服务器/容器，请开启伪装功能：\n$ sudo firewall-cmd --zone=public --add-masquerade $ sudo firewall-cmd --zone=public --add-forward-port=port=443:proto=tcp:toport=443:toaddr=192.168.2.42 --permanent 要删除上述伪装规则，请运行下列指令：\n$ sudo firewall-cmd --zone=public --remove-masquerade $ sudo firewall-cmd --zone=public --remove-forward-port=port=443:proto=tcp:toport=443:toaddr=192.168.2.42 --permanent 列出规则：\n$ sudo firewall-cmd --zone=public --list-all --permanent Rich rule 示例 假设你想只允许从 192.168.0.0 子网的 IP 地址访问 KDE Connect 的端口，运行下列指令：\n$ sudo firewall-cmd --permanent --zone=public --add-rich-rule=\u0026#39;rule family=\u0026#34;ipv4\u0026#34; source address=\u0026#34;192.168.2.0/24\u0026#34; port protocol=\u0026#34;tcp\u0026#34; port=\u0026#34;1714-1764\u0026#34; accept\u0026#39; $ sudo firewall-cmd --permanent --zone=public --add-rich-rule=\u0026#39;rule family=\u0026#34;ipv4\u0026#34; source address=\u0026#34;192.168.2.0/24\u0026#34; port protocol=\u0026#34;udp\u0026#34; port=\u0026#34;1714-1764\u0026#34; accept\u0026#39; 要验证新规则，请运行下列指令：\n$ sudo firewall-cmd --list-rich-rules --permanent 您可以通过以下方式删除富规则：\n$ sudo firewall-cmd --permanent --zone=public --remove-rich-rule \u0026#39;rule family=\u0026#34;ipv4\u0026#34; source address=\u0026#34;192.168.0.0/24\u0026#34; port protocol=\u0026#34;udp\u0026#34; port=\u0026#34;1714-1764\u0026#34; accept\u0026#39; 其他 如果你更青睐于GUI，那么你可以考虑使用Yast自带的防火墙，或者使用 firewall-config:\n$ sudo zypper install firewall-config Tips 为什么选择 openSUSE Free and Open Source 确定你心目中的贡献者们是什么样的，从而聚拢到这样的人。\n狭义的自由开源概念 狭义的自由开源概念是：自由地开放源代码。即：软件作者把源代码公开发布，给予你修改并二次发布的权利。就这样，没别的了。\n测试、调试、故障受理与修复、接受新功能请求、接受代码合并请求、接受别人的帮助、用户社区建立、互动、整个自由开源生态的维护，统统都是完全没有，谁愿意干谁干，跟我没有关系。或者这么说：“写完拉倒”，哪怕洪水滔天。这从 GPL 许可证的“无保声明”中可以看出端倪。\n广义的自由开源概念 实际上如果你看过操作系统革命你就会明白：开放源代码其实并不是这一运动想要实现的全部，它的最终目的是普及自由精神，建立自由社区。\n目前这一精神在自由开源软件上的表现有：\n 源代码开源。 来自软件所有者的开发门槛为零。 不重新发明轮子。如果有已有实现并可以扩展，那么扩展它。 文档开源。使用维基等。 组织并形成用户互助社区。积极帮助用户（在不影响开发的前提下）。同时在开发上尽量面向用户，把用户的反应纳入到重大修改的考量因素当中去，积极采纳合理意见。 积极回应故障汇报并提供修复。 积极回应新功能请求。能做的做，不能做的解释原因寻求理解。 形成良性的贡献者添加内容和用户反馈渠道。 重视并维护由类似软件共同组成的生态的和谐稳定。（简单说就是：我开发 KDE 是因为 GNOME 满足不了我的需求，而不是为了搞死 GNOME。）  现在您可以拿来同狭义的自由开源概念做比较，发现如果说狭义的自由开源概念只是指某种行为，那么广义的自由开源概念已经是指一种氛围了。\nopenSUSE 秉持的自由开源概念 openSUSE 项目是完全做到“广义的自由开源概念”的社区。\n同时我们一直持有的相关理念还有：\n 积极的与上游合作。不“内化”补丁或修改，除非上游出于种种原因不收。 积极的为整个生态着想。 不搞歧视或二等公民。 尊重许可证、版权甚至是专利  如果你认同这些，那么您适合这个社区。\n常用软件 Remove a file using inode number 用 7zip 解压出一个乱码文件，删除不了，因此考虑用 inode 删除。\n  Use -i flag to get the inode number of any file (First column is your inode)\n$ ls -li   In find command, use -inum flag with inode number and ls at the end to list a file\n$ find . -inum \u0026lt;inode number\u0026gt; -ls   In find command, use -inum flag with inode number and pass the rm using exec arugment to delete a file\n$ find . -inum \u0026lt;inode number\u0026gt; -exec rm {} \\;   unzip 乱码 openSUSE 中文论坛讨论：大家都用什么 gui 压缩软件？\n问题描述 ZIP文件在不同平台压缩时，对于文件名会有不同的编码，主要分为下面两类：\n Windows平台，默认的中文编码为GBK，因此压缩后的文件名编码格式为GBK。 Linux/MacOS平台，默认的中文编码为UTF8，因此压缩后的文件名编码格式为UTF8。  这样就存在一个问题，在Windows上压缩的文件放到MacOS上解压，或者将Windows上压缩的文件上传到服务器上解压后处理，里面的文件名都会出现乱码情况。出现这个问题，主要是因为ZIP标准公布于1989年1月，那时还没有Unicode标准。在当前ZIP标准中，Info-ZIP Unicode Path Extra Field(0x7075)会记录UTF8的编码名。\n但是，这个字段不是强制字段，允许为空，Linux/Mac OS在压缩时都不会记录这个标识，因此，无法识别出zip包采用的编码方式，导致解压时会出现乱码。\n解决 系统还未编译安装Unzip 更改源码解决乱码\n调试发现问题出现在 MultiByteToWideChar 方法里，如 MultiByteToWideChar(CP_ACP,0,fn,-1,tfn,MAX_PATH); 到这里时 fn 中的 name 属性值还是正常的，在这个方法内部执行完 tfn 就乱了。\n解决方法：\n打开 unzip.cpp 源文件，找到函数\nZRESULT TUnzip::Get(int index,ZIPENTRY *ze) { // ......  // ...... } 这个函数里有\n#ifdef UNICODE  MultiByteToWideChar(CP_UTF8,0,fn,-1,tfn,MAX_PATH); #else  strcpy(tfn,fn); #endif 把 CP_UTF8 改为 CP_ACP（CP_ACP 指示要使用当前设置的 API 默认 Windows ANSI 代码页）\n重新编译后\n这样就解决了解压中文文件名称乱码的问题\n编译时解决源码问题（无需更改源码）\n上面的情况，我们我观察到unzip源代码这段开始的地方有判断\n#ifndef Ext_ASCII_TO_Native 这样问题似乎更简单了，不用改源代码，只需在 make 时定义 Ext_ASCII_TO_Native 即可，这样 Ext_ASCII_TO_Native 实际为一个空的宏，不进行任何转换操作。\n比如，使用下面的方法编译\n$ make -DExt_ASCII_TO_Native 或者在 bash 执行下面两行\n$ export LOCAL_UNZIP=-DExt_ASCII_TO_Native $ make unzip 解压缩含中文文件名 zip 包是出现乱码的问题解决！\n如果您的系统已经安装了 unzip unzip 行命令解压，指定字符集\n通过 unzip 行命令解压，指定字符集\n$ unzip -O CP936 xxx.zip # 用GBK, GB18030 也可以 有的发行版并没有如 Ubuntu 那样安装了 unzip-iconv 补丁，因此需要安装该补丁以启用“指定字符集”功能。\n注意：unzip-natspec 是较新的方案，gbkunzip 是依云的一个Python脚本解决方案。\n在环境变量中，指定 unzip 参数\n在环境变量中，指定 unzip 参数，总是以指定的字符集显示和解压文件 /etc/environment 中加入 2 行\nUNZIP=\u0026#34;-O CP936\u0026#34; ZIPINFO=\u0026#34;-O CP936\u0026#34; 利用 python 来处理\n复制以下内容（Python）保存为 myuzip.py 文件脚本，并修改运行权限为可运行（chmod +x uzip）\n#!/usr/bin/env python # -*- coding: utf-8 -*- # uzip.py import os import sys import zipfile print \u0026#34;Processing File \u0026#34; + sys.argv[1] file=zipfile.ZipFile(sys.argv[1],\u0026#34;r\u0026#34;); for name in file.namelist(): utf8name=name.decode(\u0026#39;gbk\u0026#39;) print \u0026#34;Extracting \u0026#34; + utf8name pathname = os.path.dirname(utf8name) if not os.path.exists(pathname) and pathname!= \u0026#34;\u0026#34;: os.makedirs(pathname) data = file.read(name) if not os.path.exists(utf8name): fo = open(utf8name, \u0026#34;w\u0026#34;) fo.write(data) fo.close file.close() 这样以后我们解压缩时只需要运行此文件即可\n$ ./myuzip.py xxxx.zip 乱码问题 Unicode 中文乱码速查表\n   xxxxxx 示例 特点 产生原因     古文码 鐢辨湀瑕佸ソ濂藉涔犲ぉ澶╁悜涓? 大都为不认识的古文，并加杂日韩文 以 GBK 方式读取 UTF-8 编码的中文   口字码 ����Ҫ�¨2�ѧϰ������ 大部分字符为小方块 以 UTF-8 的方式读取 GBK 编码的中文   符号码 ç”±æœˆè|�å￥½å￥½å-|ä1 å¤©å¤©å�‘ä¸Š 大部分字符为各种符号 以 ISO8859-1 方式读取 UTF-8 编码的中文   拼音码 óéÔÂòaoÃoÃÑ§Ï°ììììÏòéÏ 大部分字符为头顶带有各种类似声调符号的字母 以 ISO8859-1 方式读取 GBK 编码的中文   问句码 由月要好好学习天天向?? 字符串长度为偶数时正确，长度为奇数时最后的字符变为问号 以 GBK 方式读取 UTF-8 编码的中文，然后又用 UTF-8 的格式再次读取   锟拷码 锟斤拷锟斤拷要锟矫猴拷学习锟斤拷锟斤拷锟斤拷 全中文字符，且大部分字符为“锟斤拷”这几个字符 以 UTF-8 方式读取 GBK 编码的中文，然后又用 GBK 的格式再次读取   烫烫烫 烫烫烫烫烫烫烫烫烫烫烫烫烫烫烫烫烫烫 字符显示为“烫烫烫”这几个字符 VC Debug 模式下，栈内存未初始化   屯屯屯 屯屯屯屯屯屯屯屯屯屯屯屯屯屯屯屯屯屯 字符显示为“屯屯屯”这几个字符 VC Debug 模式下，堆内存未初始化    避免乱码基本原则：使用 utf-8 代替 gbk/gb2312。\n文件名乱码 安装 convmv，使用 convmv 命令转换编码格式。示例：\n$ convmv -f GBK -t UTF-8 --notest --nosmart file -f 指定原始编码，-t 指定输出编码。使用 convmv --list 可查询所有支持的编码。 --notest 表示非测试而是要进行转码（如果不使用该参数只会打印出转换结果而不会实际转码），--smart 表示如果已经是 UTF-8 则忽略。\n文件内容乱码 使用 iconv 命令转换格式。示例：\n$ iconv -f GBK -t UTF-8 -o new-file origin-file -f 指定原始编码，-t 指定输出编码。使用 iconv -l 可查询所有支持的编码。-o 指定输出文件。\nzip 压缩包乱码 避免方法：非 utf8 编码环境下（一般 windows 下的中文环境即是）不使用 zip 进行压缩（建议使用 7z)。 解决方案：安装使用 unzip-iconv [package not found] 或者 unzip-natspec 取代原版的 unzip 来解压缩，示例：\n$ unzip -O gbk file.zip file.zip 是压缩文件，gbk 是该文件的编码格式，以 -O 指定（原版 unzip 无 -O 选项）。\nKDE Tips trash-cli rm -rf 文件会彻底消失掉。为了避免误操作,有人写了一个替代品 trash-cli ，从命令行里面删除的时候移动到回收站，也就是 trash:/\n不过 trash-cli 有点臃肿和重复，kde 的 kioclient5 可以做一样的事情\nkioclient5 move \u0026lt;filename\u0026gt; trash:/ # 这里可以用文件通配符: 删除所有 .jpg 文件 kioclient5 move *.jpg trash:/ 可以在 .bashrc 里面加入这个命令来放心地删除文件\nfunction krm(){ kioclient5 move \u0026#34;$@\u0026#34; trash:/ } liberate Super Key 为了避免快捷键冲突，我给所有软件 (比如 Emacs) 添加自定义快捷键都会用 SuperKey（Microsoft 叫 WinKey，Appple 叫 CommandKey）来弄。这时候就需要禁用 SuperKey 启动开始菜单来防止误操作。\nkwriteconfig5 --file kwinrc --group ModifierOnlyShortcuts --key Meta \u0026#34;\u0026#34; # 重载配置 qdbus org.kde.KWin /KWin reconfigure kwriteconfig5 那条命令的实际作用是在~/.config/kwinrc 里面修改了这部分\n[ModifierOnlyShortcuts] Meta= 如果你想迁移你的 KDE 设置，可以把所用自定义的设置都用脚本来表示，比如说禁用键盘上的锁屏键\n# 修改 ~/.config/kglobalshortcutsrc 里面 [ksmserver] 中 Lock Session= 的值为 \u0026#34;,,Lock Session\u0026#34; kwriteconfig5 --file kglobalshortcutsrc --group ksmserver --key \u0026#34;Lock Session\u0026#34; \u0026#34;,,Lock Session\u0026#34; Custom Context Menu KDE 可以添加自定义的右键菜单，比如说我自用的通过 Inkscape 把 .svg 转换成 .eps（ LaTeX 插入 .eps 方便一些）\n把如下的内容丢进 ~/.local/share/kservices5/ServiceMenus/svg2eps.desktop 即可。\n[Desktop Entry] Type=Service ServiceTypes=KonqPopupMenu/Plugin MimeType=image/svg+xml Actions=svg2eps Icon=view-refresh [Desktop Action svg2eps] Name=convert svg to eps Icon=view-refresh Exec=inkscape -D \u0026#34;%f\u0026#34; --export-type=eps 唯一重点的一行是 Exec=。\n原始的命令是 inkscape -D \u0026lt;filename\u0026gt; --export-type=eps，然后把 \u0026lt;filename\u0026gt;换成 %f, Dolphin 就会在从右键使用的时候自动传入目标文件。(大写的版本%F会传入一组文件)。\n具体的写法在 Freedesktop Desktop Entry Specification-\u0026gt; The Exec key 里面。\nMimeType= 是匹配文件格式，可以用 file --mime-type -b \u0026lt;filename\u0026gt; 来获取，或者从 freedesktop/xdg-shared-mime-info 里面查\n你可能注意到，右键菜单里面的格式，用的和 launcher(开始菜单）用的是用样的格式 .desktop\n如果仔细考虑一下，他们本质上是没有区别的，只不过一个从 launcher 里面打开，另一个从右键呼出。不过通过右键打开的，可以获取一些文件和目录的信息。\n详细的教程 https://develop.kde.org/docs/extend/dolphin/service-menus/\n长命令通知 如果一个命令需要运行的特别特别久，可以在命令后面加上 \u0026amp;\u0026amp; notify-send \u0026lt;message\u0026gt;\u0026quot;\n比如 ls \u0026amp;\u0026amp; notify-send \u0026quot;finished at $(date +%c)\u0026quot;\n不过这个通知一会就会消失，可以在设置里面，把 low priority 的通知设置成 show in history\n这个同时还可以插入图片，想知道可以搜以下 KNotify/Knotifications 的 API…\nCommand Palette 自从某一个版本以后，用 KDE 框架写的软件都” 自动 “地获得了一个命令面板功能 Ctrl+Alt+i，正式的名称应该是 KCommandBar。\n这里有两个好玩的：\n  okular ” 自动 “地获得搜索最近打开文件的能力\n  Kate 可以更加方便地调用外部程序（类似于 Kakoune 那种几乎完全借助外部程序处理文档编辑的操作）。\n需要做的就是从菜单栏的 Tools -\u0026gt; External Tools -\u0026gt; Configure 里面添加新的外部程序，比如 google 搜索选定的文本。\n也可以这样操作来安装这个 google 搜索：\necho \u0026#34;[General] actionName=externaltool_GoogleSearch arguments=https://www.google.com/search?q=%{Document:Selection:Text} executable=/usr/bin/xdg-open icon=plasma-search name=GoogleSearch output=Ignore reload=false save=None\u0026#34; \u0026gt; ~/.config/kate/externaltools/googlesearch 然后这样搜索一段选定的文本了\n  openQA 大致的原理就是开一个虚拟机，然后模拟用户活动：https://openqa.opensuse.org\n而且测试的项目也很多，除了安装，重启，安装桌面环境之类常规的测试。还有一些很特别的，比如说从 GNOME 桌面启动 Firefox，然后在关于界面一定会在某个坐标出现 Firefox 的 logo。打开 Dophin 然后右键菜单，新建文件的地方一定可以有那个文本文件。\n另外还有两个项目也在使用来自 SUSE 的 openQA:\n Debian: https://openqa.debian.net https://wiki.debian.org/Outreachy/Round15/Projects/TestingDebianWithOpenQA Fedora https://openqa.stg.fedoraproject.org https://fedoraproject.org/wiki/OpenQA  SDB 支持资料库。\n Support Database (SDB) articles are written as solutions for technical problems with openSUSE.\n 给 pdf 电子书加目录 对许多人来说 pdf 格式的电子书最头疼的两件事：\n 每页都是没经过 OCR 处理过的图片 没有目录(ABBYY)  以下这个批量加目录的方法我用好久了，见过我这么操作过的都想学一下，这里详细地记录以下，也方便以后有人再问的时候 :)\n用到的软件是 pdftk pdftk-java / pdftk-java · GitLab 。linux 发行版一般都有这个这个软件可以直接安装。\npdftk 的用法就是：输出 (dump_data) pdf 的元信息 (data.txt)，编辑以后，重新倒入 (update_info) 到 pdf 文件里面\n主要是这两条命令:\npdftk [my.pdf] dump_data \u0026gt; [data.txt] pdftk [my.pdf] update_info [data.txt] output my2.pdf 在第一条命令输出的 data.txt 里面加入如下的内容，然后通过第二条命令就可以创建新的目录条目\nBookmarkBegin BookmarkTitle: name BookmarkLevel: level BookmarkPageNumber: page number 另外电子书的第一页通常是封面，紧接着的是其它的东西。但是书里面标注的页码的第一页往往后面的某页。\nPDF 支持把页码标注成其它的格式 (page_labels)，第一页标注成 cover，第二到第十页标注成罗马数字，然后从第十一页标注成 1,2,3,4,5,6…\n# 把第一页标注成名字为 cover 的非数字 (NoNumber) PageLabelBegin PageLabelNewIndex: 1 PageLabelStart: 1 PageLabelPrefix: cover PageLabelNumStyle: NoNumber # 从第二页 (PageLabelNewIndex) 开始标注成小写罗马数字 (LowercaseRomanNumerals) PageLabelBegin PageLabelNewIndex: 2 PageLabelStart: 1 # 从数字 1 开始数，如果这里变成 3 =\u0026gt; 起始的罗马数字会是 iii PageLabelNumStyle: LowercaseRomanNumerals # 从 {true start page} 开始用普通的数字标注 PageLabelBegin PageLabelNewIndex: {true start page} PageLabelStart: 1 PageLabelNumStyle: DecimalArabicNumerals 对于一本书，这种手动添加的方法会很慢，下面是一个小脚本来半自动化。\n由于电子书 100% 可以搜索到这种格式的目录 编号 标题 页码。如果搜索不到，也可以直接从书里面复制。\n复制粘贴一下，调整成这种格式\n14 I: Reduction Semantics\t1 1 Semantics via Syntax\t5 2 Analyzing Syntactic Semantics\t13 3 The λ-Calculus\t23 4 ISWIM\t45 II: PLT Redex\t201 11 The Basics\t205 12 Variables and Meta-functions\t217 13 Layered Development\t227 14 Testing\t237 ...... 第一行是对于人类，而非 pdf 格式来说真正的第一页\n后面根据行首 tab 的数量来决定目录的层级\n每行后面的数字是页码\n然后用这个小脚本 toc-gen.py\n#!/usr/bin/env python3 # # Usage # toc-gen.py \u0026lt; edited-toc.txt # def make_offset(off: int): if off \u0026gt; 1: print(\u0026#34;\u0026#34;\u0026#34;PageLabelBegin PageLabelNewIndex: 1 PageLabelStart: 1 PageLabelPrefix: cover PageLabelNumStyle: NoNumber\u0026#34;\u0026#34;\u0026#34;) if off \u0026gt; 2: print(\u0026#34;\u0026#34;\u0026#34;PageLabelBegin PageLabelNewIndex: 2 PageLabelStart: 1 PageLabelNumStyle: LowercaseRomanNumerals\u0026#34;\u0026#34;\u0026#34;) print(f\u0026#34;\u0026#34;\u0026#34;PageLabelBegin PageLabelNewIndex: {off}PageLabelStart: 1 PageLabelNumStyle: DecimalArabicNumerals\u0026#34;\u0026#34;\u0026#34;) def make_bookmark(t: str, l: int, p: int): print(f\u0026#34;\u0026#34;\u0026#34;BookmarkBegin BookmarkTitle: {t}BookmarkLevel: {l}BookmarkPageNumber: {p}\u0026#34;\u0026#34;\u0026#34;) if __name__ == \u0026#39;__main__\u0026#39;: offset = int(input()) make_offset(offset) while True: try: line = input() if not line.strip(): break except EOFError: break title = \u0026#34; \u0026#34;.join(line.split()[0:-1]) n_of_tabs = len(line) - len(line.lstrip()) page = int(line.split()[-1]) make_bookmark(t=title, l=n_of_tabs + 1, p=page + offset) 来获取这些内容，把这些内容粘贴到 [data.txt] 后面，然后再用 pdftk 的第二条命令\nPageLabelBegin PageLabelNewIndex: 1 PageLabelStart: 1 PageLabelPrefix: cover PageLabelNumStyle: NoNumber PageLabelBegin PageLabelNewIndex: 2 PageLabelStart: 1 PageLabelNumStyle: LowercaseRomanNumerals PageLabelBegin PageLabelNewIndex: 14 PageLabelStart: 1 PageLabelNumStyle: DecimalArabicNumerals BookmarkBegin BookmarkTitle: Reduction Semantics BookmarkLevel: 1 BookmarkPageNumber: 15 BookmarkBegin BookmarkTitle: Semantics via Syntax BookmarkLevel: 2 BookmarkPageNumber: 19 BookmarkBegin BookmarkTitle: Analyzing Syntactic Semantics BookmarkLevel: 2 BookmarkPageNumber: 27 BookmarkBegin BookmarkTitle: The λ-Calculus BookmarkLevel: 2 BookmarkPageNumber: 37 BookmarkBegin BookmarkTitle: ISWIM BookmarkLevel: 2 BookmarkPageNumber: 59 BookmarkBegin BookmarkTitle: An Abstract Syntax Machine BookmarkLevel: 2 BookmarkPageNumber: 79 BookmarkBegin BookmarkTitle: Abstract Register Machines BookmarkLevel: 2 BookmarkPageNumber: 103 BookmarkBegin BookmarkTitle: Tail Calls and More Space Savings BookmarkLevel: 2 BookmarkPageNumber: 121 BookmarkBegin BookmarkTitle: Control: Errors, Exceptions, and Continuations BookmarkLevel: 2 BookmarkPageNumber: 129 BookmarkBegin BookmarkTitle: State: Imperative Assignment .............. Bingo! 这下舒服了 :)\nKDE PIM 使用指北 Questions 无法读取 exfat 、 .7z 和 .rar $ sudo zypper in fuse-exfat exfat-utils $ sudo zypper in p7zip-full $ sudo zypper in unrar vscode keychain issues for KDE $ sudo zypper in gnome-keyring 提示添加密码的时候为空就行了，否则每次启动 vscode 都需要输入一次密码。\nTypora 字体问题 如果 Typora 字体如上面那样，每个字大小不一样：   整个应用的语言设置为英语\n  在 conf.user.json 指定字体\n{ \u0026#34;defaultFontFamily\u0026#34;: { \u0026#34;standard\u0026#34;: \u0026#34;Source Han Sans CN\u0026#34;, //String - Defaults to \u0026#34;Times New Roman\u0026#34;.  \u0026#34;serif\u0026#34;: \u0026#34;Source Han Sans CN\u0026#34;, // String - Defaults to \u0026#34;Times New Roman\u0026#34;.  \u0026#34;sansSerif\u0026#34;: \u0026#34;Source Han Sans CN\u0026#34;, // String - Defaults to \u0026#34;Arial\u0026#34;.  \u0026#34;monospace\u0026#34;: \u0026#34;JetBrains Mono\u0026#34; // String - Defaults to \u0026#34;Courier New\u0026#34;.  } }   flatpak run: Invalid MIT-MAGIC-COOKIE-1 key rm .Xauthority nothing provides \u0026lsquo;libuuid\u0026rsquo; needed by the to be installed xmind BearChild, [7/21/22 10:14 PM] 强行装即可 libuuid 的依赖对于大多数 opensuse 安装来讲，都可以忽略，打包的问题\nHigh cpu usage of Goldendict full-text search 在 openSUSE 中是默认开启的，Disable full-text search: Preferences =\u0026gt; Full-text search\nSet a different input method for each app window System Settings =\u0026gt; Input Devices =\u0026gt; Keyboard =\u0026gt; Layouts =\u0026gt; Switching Policy =\u0026gt; Application\n安装软件碰到碰到冲突，应该如何选择解决方式? 出现这种情况大体可以有以下几个原则：\n 不要变更操作系统架构，比如把原来的 x86_64 变成 i586，（命令行执行 uname -m 可以让你知道你的系统架构，或者说 openSUSE 版本是 32 位还是 64 位），你也知道 32 位和 64 位不是一个东西。 1.1 这里有一个特例是 x86_64 -\u0026gt; noarch 这种，比如有些 python 的软件包是存在的。 能不卸载就不卸载。比如安装一个软件包让你卸载掉 700 多个软件包。 除非你知道你在做什么，比如我自己就是打包匠，我知道我的包可能 specfile 有一个地方写错了，否则不要用忽略依赖关系强制安装的选项。因为这么选了之后 YaST 再无可能查出故障。 变更软件包的厂商（制作人）的原则： 4.1 除非你知道你在做什么，否则官方源优于所有其它源。比如 xxx -\u0026gt; openSUSE 这种变更是允许的。某种程度上，在你不是很了解 openSUSE 包管理体系的时候它能够有效地无形中纠正你做出的一些错误选择。比如你切换了一个系统软件包到不稳定的版本，它能给改过来。但是如果你知道你在做什么就不必了，比如你通过 KDE:Current 把 KDE 升级为 4.13.2，而官方源中是 4.11，这种情况就不必降级。 4.2 除非你知道你在做什么，否则官方开发源优于除了官方源以外的所有其它源。比如 home:xxx -\u0026gt; devel:xxx 这种由 home 切换到非 home 的变更是允许的。因为 home 源谁都可以申请，软件包的质量参差不齐，开发源是官方认可的打包者为发行版开发软件包的地方，相对质量有所保证。但是如果你知道你在做什么就不必了，比如我可能知道 13.1 的 glew 有 bug，于是我会在我的 home 源里制作一个修复版本。这时肯定要安装我自己的。 4.3 只从 home 源中取自己需要的、且官方没有提供的软件包。比如我的 home 里可能有一个你需要的 hime 输入法，但同时也有一个非常老的 gtk2（会导致你后续基本上所有 gtk 相关的软件包都会弹出冲突解决对话框），你只装 hime 是不会带上我的 gtk 的，除非是你操作失误，选择切换系统软件包到该源。从图中看你肯定有这样的失误了。这是个一步错，步步都可能错的问题。 能不降级就不降级。比如 3.10 版本降级到 3.9 版本，这是没有必要的。  如果这 5 条军规之间产生冲突，编号越小的作用力越大。比如，开发源中的版本是 3.9, 而 home 源中的版本是 3.10，那么提示的时候，版本规律要服从软件源优先级规律，所以要选择把 3.10 版本降级为开发源中的 3.9。\nSpotify: \u0026ldquo;Ding\u0026rdquo; notification for each played song  Hanjingxue, [9/29/22 8:17 AM] 你可以去 spotify flatpak 对应的 GitHub 仓库的 issue 列表看看有没有人遇到过相同的问题\nBearChild, [9/29/22 8:17 AM] openSUSE 自己是不会给你“咚”的声音的\n 总结：除了使用 Google 外，还可以到 Github Issue 查找（而且优先级更高）。\n具体就是关闭 Spotify 的 Settings =\u0026gt; Display =\u0026gt; show desktop notifications\u0026hellip;\n","permalink":"https://sakamotokurome.github.io/posts/opensuse/","summary":"/ˌoʊpənˈsuːzə/ Desktop DVD 方式安装 使用其他方式安装系统需要耗费比其他安装方式更多的时间和精力，除非必要，建议优先使用离线的 DVD 镜像进行安","title":"OpenSUSE"},{"content":"[fəˈdɔrə] 费多拉\nFedora Linux 版本 Fedora 官方版本  Fedora 工作站是可以安装在笔记本电脑和台式电脑上的 Linux。 此版本附带 GNOME 作为默认桌面环境和各种标准应用程序，以便 Fedora Linux 已准备好用于日常使用。 Fedora 服务器专门用于服务器计算机用途，提供邮件服务器、DNS 等的安装。 Fedora 物联网，用于物联网和设备边缘生态系统。 Fedora CoreOS 是一种自动更新的操作系统，旨在安全、大规模地运行容器化工作负载。 Fedora Silverblue 是一个不可变的桌面操作系统，旨在支持以容器为中心的工作流。  Fedora Spins Fedora 的默认桌面环境是 GNOME，但是如果您喜欢其他的桌面环境，比如 KDE Plasma Desktop 或 Xfce，您可以下载一个您喜欢的桌面环境的 spin，然后用它来安装 Fedora，为您选择的桌面环境进行预配置。\nFedora Labs Fedora 实验室是一个由 Fedora 社区成员策划和维护的目的明确的软件和内容的精选捆绑包。这些软件可以作为独立的Fedora完整版安装，也可以作为现有的Fedora安装的附加组件安装。\nFedora Alternative Downloads 这些Fedora下载要么是特殊用途的——用于测试，用于特定的架构；要么是其他格式的Fedora标准版本，如网络安装程序格式或用于torrent下载的格式。\n本页旨在作为查找Fedora替代版本的单一中央资源。\nFedora Usage Mirrors Of Fedora SJTU Mirror 托管于华东教育网骨干节点上海交通大学。\n$ sudo sed -e \u0026#39;s/^metalink=/#metalink=/g\u0026#39; -e \u0026#39;s|^#baseurl=http://download.example/pub/|baseurl=https://mirror.sjtu.edu.cn/|g\u0026#39; -i.bak /etc/yum.repos.d/{fedora,fedora-updates,fedora-modular,fedora-updates-modular}.repo $ sudo dnf makecache #生成缓存 RPMFusion 第一步下载基础包(开源和闭源)， 这里我们使用bfsu来下载，以避免网络问题，终端输入:\n$ sudo dnf install --nogpgcheck https://mirror.sjtu.edu.cn/rpmfusion/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm https://mirror.sjtu.edu.cn/rpmfusion/nonfree/fedora/rpmfusion-nonfree-release-$(rpm -E %fedora).noarch.rpm -y 第二步，使用SJTU Mirror\nsudo sed -e \u0026#39;s|^metalink=|#metalink=|g\u0026#39; -e \u0026#39;s|^#baseurl=http://download1.rpmfusion.org/|baseurl=https://mirror.sjtu.edu.cn/rpmfusion/|g\u0026#39; -i.bak /etc/yum.repos.d/rpmfusion-* FlatHub Mirror 改为使用 sjtu 镜像：\n$ sudo flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo $ sudo flatpak remote-modify --enable flathub $ sudo flatpak remote-modify flathub --url=https://mirror.sjtu.edu.cn/flathub $ sudo flatpak remotes --show-details $ cat /var/lib/flatpak/repo/config Copr 类似 Ubuntu 的 PPA\n  You need to have dnf-plugins-core installed for dnf, and you need to have yum-plugin-copr installed for yum\n$ sudo dnf install dnf-plugins-core $ sudo yum install yum-plugin-copr   If you’re using a version of Linux with dnf, or if you have older distribution:\n$ sudo dnf copr enable user/project $ sudo yum copr enable user/project   例如Fedora自带的Copr repo for PyCharm\n$ cat /etc/yum.repos.d/_copr_phracek-PyCharm.repo [phracek-PyCharm] name=Copr repo for PyCharm owned by phracek baseurl=https://copr-be.cloud.fedoraproject.org/results/phracek/PyCharm/fedora-$releasever-$basearch/ skip_if_unavailable=True gpgcheck=1 gpgkey=https://copr-be.cloud.fedoraproject.org/results/phracek/PyCharm/pubkey.gpg enabled=0 Speed Up DNF 尝试更改参数：\n$ sudo vi /etc/dnf/dnf.conf fastestmirror=true #如果启用国内镜像，就不需要设置这个了。 max_parallel_downloads=5 metadata_expire=2d  fastermirror 选择最快的镜像 max_parallel_downloads 一次下载多个包  Gnome $ sudo dnf install gnome-tweaks gnome-extensions-app  gnome-tweaks 里面可以管理 startup apps。 gnome-extensions-app 管理 extensions。 gnome-shell-extension-appindicator gnome-shell-extension-gsconnect  Multiple Git Accounts $ ssh-keygen -t rsa -C \u0026#34;your-email\u0026#34; $ nano ~/.ssh/config Host github-proj1 HostName github.com User git IdentityFile ~/.ssh/id_rsa_github_proj1 Host github-proj2 HostName github.com User git IdentityFile ~/.ssh/id_rsa_github_proj2 Host aws-codecommit-proj3 Hostname git-codecommit.us-east-2.amazonaws.com User TECADMIN0123456789 IdentityFile ~/.ssh/id_rsa_aws_codecommit_proj3 AddKeysToAgent yes $ git clone ssh://github-proj1/user1/repo.git $ git clone ssh://github-proj2/user2/repo.git $ git clone ssh://aws-codecommit-proj3/v1/repos/myrepo 设置 config 后，可能需要重启才能起作用。\nFcitx5 安装\n$ sudo dnf install fcitx5 fcitx5-chinese-addons fcitx5-gtk fcitx5-qt fcitx5-configtool fcitx5-autostart fcitx5-rime $ rpm -ql fcitx5-autostart /etc/profile.d/fcitx5.sh /etc/xdg/autostart/org.fcitx.Fcitx5.desktop $ cat /etc/profile.d/fcitx5.sh if [ ! \u0026#34;$XDG_SESSION_TYPE\u0026#34; = \u0026#34;tty\u0026#34; ] # if this is a gui session (not tty) then # let\u0026#39;s use fcitx instead of fcitx5 to make flatpak happy # this may break behavior for users who have installed both # fcitx and fcitx5, let then change the file on their own export INPUT_METHOD=fcitx export GTK_IM_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=@im=fcitx fi $ cat /etc/xdg/autostart/org.fcitx.Fcitx5.desktop [Desktop Entry] Name[ca]=Fcitx 5 Name[da]=Fcitx 5 Name[de]=Fcitx 5 Name[ja]=Fcitx 5 Name[ko]=Fcitx 5 Name[zh_CN]=Fcitx 5 Name[zh_TW]=Fcitx 5 Name=Fcitx 5 GenericName[ca]=Mètode d\u0026#39;entrada GenericName[da]=Inputmetode GenericName[de]=Eingabemethode GenericName[ja]=入力メソッド GenericName[ko]=입력기 GenericName[ru]=Метод ввода GenericName[zh_CN]=输入法 GenericName[zh_TW]=輸入法 GenericName=Input Method Comment[ca]=Mètode d\u0026#39;entrada estàndard Comment[da]=Start inputmetode Comment[de]=Eingabemethode starten Comment[ja]=入力メソッドを開始 Comment[ko]=입력기 시작 Comment[zh_CN]=启动输入法 Comment=Start Input Method Exec=/usr/bin/fcitx5 Icon=fcitx Terminal=false Type=Application Categories=System;Utility; StartupNotify=false X-GNOME-AutoRestart=false X-GNOME-Autostart-Notify=false X-KDE-autostart-after=panel X-KDE-StartupNotify=false X-KDE-Wayland-VirtualKeyboard=true 在 fcitx5 Configure 中，Input Method 只保留 rime，按组合键 Ctrl+` 选择 ”朙月拼音-简化字“，对应定制文件为 luna_pinyin_simp.custom.yaml。\n扩展：Input Method Panel\nNvidia   Update from the existing repositories\n$ sudo dnf update   Add the RPMFusion repository for NVIDIA drivers\n$ sudo dnf install fedora-workstation-repositories   Update from the newly added repositories\n$ sudo dnf update --refresh   Install the driver and its dependencies\n$ sudo dnf install gcc kernel-headers kernel-devel akmod-nvidia xorg-x11-drv-nvidia xorg-x11-drv-nvidia-libs xorg-x11-drv-nvidia-libs.i686   Wait for the kernel modules to load up\n  Read from the updated kernel modules\n$ sudo akmods --force $ sudo dracut --force   Reboot your system.\n在这里，确定在登录界面选择的是 Gnome on Xorg。\n  Edit the X11 configuration\n$ sudo cp -p /usr/share/X11/xorg.conf.d/nvidia.conf /etc/X11/xorg.conf.d/nvidia.conf $ sudo nano /etc/X11/xorg.conf.d/nvidia.conf Section \u0026#34;OutputClass\u0026#34; Identifier \u0026#34;nvidia\u0026#34; MatchDriver \u0026#34;nvidia-drm\u0026#34; Driver \u0026#34;nvidia\u0026#34; Option \u0026#34;AllowEmptyInitialConfiguration\u0026#34; Option \u0026#34;SLI\u0026#34; \u0026#34;Auto\u0026#34; Option \u0026#34;BaseMosaic\u0026#34; \u0026#34;on\u0026#34; Option \u0026#34;PrimaryGPU\u0026#34; \u0026#34;yes\u0026#34; EndSection Section \u0026#34;ServerLayout\u0026#34; Identifier \u0026#34;layout\u0026#34; Option \u0026#34;AllowNVIDIAGPUScreens\u0026#34; EndSection   Reboot your system\n  Verify the configuration\n$ glxinfo | egrep \u0026#34;OpenGL vendor|OpenGL renderer\u0026#34;   Movies and music In order to install OpenH264, you first need to enable it:\n$ cat /etc/yum.repos.d/fedora-cisco-openh264.repo [fedora-cisco-openh264] name=Fedora $releasever openh264 (From Cisco) - $basearch metalink=https://mirrors.fedoraproject.org/metalink?repo=fedora-cisco-openh264-$releasever\u0026amp;arch=$basearch type=rpm enabled=0 metadata_expire=14d repo_gpgcheck=0 gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-fedora-$releasever-$basearch skip_if_unavailable=True [fedora-cisco-openh264-debuginfo] name=Fedora $releasever openh264 (From Cisco) - $basearch - Debug metalink=https://mirrors.fedoraproject.org/metalink?repo=fedora-cisco-openh264-debug-$releasever\u0026amp;arch=$basearch type=rpm enabled=0 metadata_expire=14d repo_gpgcheck=0 gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-fedora-$releasever-$basearch skip_if_unavailable=True $ sudo dnf config-manager --set-enabled fedora-cisco-openh264 Use the dnf utility to install packages that provide multimedia libraries:\n$ sudo proxychains dnf install gstreamer1-plugins-{bad-\\*,good-\\*,base} gstreamer1-plugin-openh264 gstreamer1-libav --exclude=gstreamer1-plugins-bad-free-devel -y $ sudo proxychains dnf install lame\\* --exclude=lame-devel -y $ sudo proxychains dnf group upgrade --with-optional Multimedia -y $ sudo dnf config-manager --set-disabled fedora-cisco-openh264 and then install the plugins (for firefox, if needed):\n$ sudo dnf install mozilla-openh264 Afterwards you need open Firefox, go to menu → Add-ons → Plugins and enable OpenH264 plugin.\nRhythmbox 无法订阅喜马拉雅的feed，报错为：\nUnable to load the feed. Check your network connection 其实试一下荔枝FM，会发现是可以订阅的。比较一下就会发现，荔枝FM的Feed都是mp3链接，而喜马拉雅的Feed都是m4a链接，下载必须解码器后（ The .m4a files are alac which would be decoded by gstreamer1.0-libav. ），Rhythmbox 确实能播放m4a文件了，但依然无法订阅，因此应该是Prodcast解析feed链接的问题，有兴趣有能力有时间看：Rhythmbox Development Reference Manual（PS：Ubuntu 22.04.1 上并无此问题）\nPodman kali linux\n开代理的话会报错：\nCould not connect to 127.0.0.1:7890 (127.0.0.1). - connect (111: Connection refused) 查看 man podman-run，添加 --http-proxy=false 解决：\n$ podman run --http-proxy=false -it docker.io/kalilinux/kali-rolling:latest /bin/bash 更换 ustc 源\n$ echo \u0026#39;deb http://mirrors.ustc.edu.cn/kali kali-rolling main non-free con trib\u0026#39; \u0026gt; sources.list metapackage\n$ apt update \u0026amp;\u0026amp; apt -y install kali-linux-headless ZFS on Fedora zfs-fuse is a daemon which provides support for the ZFS filesystem, via fuse. Ordinarily this daemon will be invoked from system boot scripts.\n$ sudo dnf install zfs-fuse $ sudo zfs-fuse $ sudo zpool import dpool cannot import \u0026#39;dpool\u0026#39;: pool is formatted using a newer ZFS version OpenZFS on Fedora\n$ sudo rpm -e --nodeps zfs-fuse $ sudo proxychains dnf install -y https://zfsonlinux.org/fedora/zfs-release$(rpm -E %dist).noarch.rpm $ cat /etc/yum.repos.d/zfs.repo [zfs] name=ZFS on Linux for Fedora $releasever baseurl=http://download.zfsonlinux.org/fedora/$releasever/$basearch/ enabled=0 metadata_expire=7d gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-zfsonlinux [zfs-source] name=ZFS on Linux for Fedora $releasever - Source baseurl=http://download.zfsonlinux.org/fedora/$releasever/SRPMS/ enabled=0 gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-zfsonlinux [zfs-testing] name=ZFS on Linux for Fedora $releasever - Testing baseurl=http://download.zfsonlinux.org/fedora-testing/$releasever/$basearch/ enabled=0 metadata_expire=7d gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-zfsonlinux [zfs-testing-source] name=ZFS on Linux for Fedora $releasever - Testing Source baseurl=http://download.zfsonlinux.org/fedora-testing/$releasever/SRPMS/ enabled=0 gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-zfsonlinux $ sudo proxychains dnf install -y kernel-devel $ sudo proxychains dnf install -y zfs $ sudo modprobe zfs $ echo zfs | sudo tee /etc/modules-load.d/zfs.conf # 可选 $ sudo dnf config-manager --set-disabled zfs virt-manager $ sudo dnf install @virtualization $ sudo vi /etc/libvirt/libvirtd.conf unix_sock_group = \u0026#34;libvirt\u0026#34; unix_sock_rw_perms = \u0026#34;0770\u0026#34; $ sudo systemctl restart libvirtd $ sudo usermod -a -G libvirt $(whoami) Now you must log out and log in to apply the changes.\nVSCode Visual Studio Code on Linux\n$ sudo tee -a /etc/yum.repos.d/vscode.repo \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; [code] name=Visual Studio Code baseurl=https://packages.microsoft.com/yumrepos/vscode enabled=1 gpgcheck=1 gpgkey=https://packages.microsoft.com/keys/microsoft.asc EOF $ sudo dnf install code VSCodium\nBinary releases of VS Code without MS branding/telemetry/licensing.\nvscodium-deb-rpm-repo:\n$ sudo tee -a /etc/yum.repos.d/vscodium.repo \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; [gitlab.com_paulcarroty_vscodium_repo] name=gitlab.com_paulcarroty_vscodium_repo baseurl=https://paulcarroty.gitlab.io/vscodium-deb-rpm-repo/rpms/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://gitlab.com/paulcarroty/vscodium-deb-rpm-repo/raw/master/pub.gpg metadata_expire=1h EOF $ dnf install codium Fedora System Package Manager Managing DNF Repository DNF repositories commonly provide their own .repo file. To add such a repository to your system and enable it, run the following command as root:\ndnf config-manager --add-repo repository_url To enable a particular repository or repositories, type the following at a shell prompt as root:\ndnf config-manager --set-enabled repository… To disable a DNF repository, run the following command as root:\ndnf config-manager --set-disabled repository… For example, Google Chrome Repository：\n$ cat /etc/yum.repos.d/google-chrome.repo [google-chrome] name=google-chrome baseurl=https://dl.google.com/linux/chrome/rpm/stable/x86_64 enabled=1 gpgcheck=1 gpgkey=https://dl.google.com/linux/linux_signing_key.pub $ sudo dnf config-manager --set-enabled google-chrome $ sudo dnf install google-chrome-stable DNF System Upgrade $ sudo dnf upgrade --refresh $ sudo reboot $ sudo dnf install dnf-plugin-system-upgrade $ sudo dnf system-upgrade download --releasever=35 $ sudo dnf system-upgrade reboot  Change the --releasever= number if you want to upgrade to a different release. If some of your packages have unsatisfied dependencies, the upgrade will refuse to continue until you run it again with an extra --allowerasing option. This often happens with packages installed from third-party repositories for which an updated repositories hasn’t been yet published. Study the output very carefully and examine which packages are going to be removed. None of them should be essential for system functionality, but some of them might be important for your productivity.  In case of unsatisfied dependencies, you can sometimes see more details if you add --best option to the command line. If you want to remove/install some packages manually before running dnf system-upgrade download again, it is advisable to perform those operations with --setopt=keepcache=1 dnf command line option. Otherwise the whole package cache will be removed after your operation, and you will need to download all the packages once again.   There are other important optional operations here, please read the official documentation.  DNF local plugin An internet search yields two common solutions that eliminate or reduce repeat downloads of the same RPM set – create a private Fedora Linux mirror or set up a caching proxy.\nFedora provides guidance on setting up a [private mirror](https://fedoraproject.org/wiki/ Infrastructure/Mirroring#How_can_someone_make_a_private_mirror). A mirror requires a lot of bandwidth and disk space and significant work to maintain. A full private mirror would be too expensive and it would be overkill for my purposes.\nThe most common solution I found online was to implement a caching proxy using Squid. I had two concerns with this type of solution. First, I would need to edit repository definitions stored in /etc/yum.repo.d on each virtual and physical machine or container to use the same mirror. Second, I would need to use http and not https connections which would introduce a security risk.\nAfter reading Glenn’s 2018 post on the DNF local plugin, I searched for additional information but could not find much of anything besides the sparse documentation for the plugin on the DNF documentation web site. This article is intended to raise awareness of this plugin.\nUse DNS over TLS dnf updateinfo First, check the updates available:\n$ dnf check-update OK, so run your first dnf updateinfo command:\n$ dnf updateinfo Look at the list of updates and which types they belong to:\n$ dnf updateinfo list The next command will list the actual changelog.\n$ dnf updateinfo info install only security and bugfixes updates\n$ dnf check-update --security --bugfix $ sudo dnf update --security --bugfix Install only specific updates\n$ sudo dnf update --advisories=FEDORA-2021-74ebf2f06f,FEDORA-2021-83fdddca0f XFS 檔案系統簡介 CentOS 7 開始，預設的檔案系統已經由原本的 EXT4 變成了 XFS 檔案系統了！為啥 CentOS 要捨棄對 Linux 支援度最完整的 EXT 家族而改用 XFS 呢？ 這是有一些原因存在的。\nEXT 家族當前較傷腦筋的地方：支援度最廣，但格式化超慢！\nExt 檔案系統家族對於檔案格式化的處理方面，採用的是預先規劃出所有的 inode/block/meta data 等資料，未來系統可以直接取用， 不需要再進行動態配置的作法。這個作法在早期磁碟容量還不大的時候還算 OK 沒啥問題，但時至今日，磁碟容量越來越大，連傳統的 MBR 都已經被 GPT 所取代，連我們這些老人家以前聽到的超大 TB 容量也已經不夠看了！現在都已經說到 PB 或 EB 以上容量了呢！那妳可以想像得到，當你的 TB 以上等級的傳統 ext 家族檔案系統在格式化的時候，光是系統要預先分配 inode 與 block 就消耗你好多好多的人類時間了\u0026hellip;\nTips：之前格式化過一個 70 TB 以上的磁碟陣列成為 ext4 檔案系統，按下格式化，去喝了咖啡、吃了便當才回來看做完了沒有\u0026hellip; 所以，後來立刻改成 xfs 檔案系統了。\n另外，由於虛擬化的應用越來越廣泛，而作為虛擬化磁碟來源的巨型檔案 (單一檔案好幾個 GB 以上！) 也就越來越常見了。 這種巨型檔案在處理上需要考慮到效能問題，否則虛擬磁碟的效率就會不太好看。因此，從 CentOS 7.x 開始， 檔案系統已經由預設的 Ext4 變成了 xfs 這一個較適合高容量磁碟與巨型檔案效能較佳的檔案系統了。\nTips：其實鳥哥有幾組虛擬電腦教室伺服器系統，裡面跑的確實是 EXT4 檔案系統，老實說，並不覺得比 xfs 慢！所以，對鳥哥來說， 效能並不是主要改變檔案系統的考量！對於檔案系統的復原速度、建置速度，可能才是鳥哥改換成 xfs 的思考點。\nXFS 檔案系統的配置\n基本上 xfs 就是一個日誌式檔案系統，而 CentOS 7.x 拿它當預設的檔案系統，自然就是因為最早之前，這個 xfs 就是被開發來用於高容量磁碟以及高效能檔案系統之用， 因此，相當適合現在的系統環境。此外，幾乎所有 Ext4 檔案系統有的功能， xfs 都可以具備！也因此在本小節前幾部份談到檔案系統時， 其實大部份的操作依舊是在 xfs 檔案系統環境下介紹給各位的哩！\nxfs 檔案系統在資料的分佈上，主要規劃為三個部份，一個資料區 (data section)、一個檔案系統活動登錄區 (log section)以及一個即時運作區 (realtime section)。 這三個區域的資料內容如下：\n 資料區 (data section)  基本上，資料區就跟我們之前談到的 ext 家族一樣，包括 inode/data block/superblock 等資料，都放置在這個區塊。 這個資料區與 ext 家族的 block group 類似，也是分為多個儲存區群組 (allocation groups) 來分別放置檔案系統所需要的資料。 每個儲存區群組都包含了 (1)整個檔案系統的 superblock、 (2)剩餘空間的管理機制、 (3)inode的分配與追蹤。此外，inode與 block 都是系統需要用到時， 這才動態配置產生，所以格式化動作超級快！\n另外，與 ext 家族不同的是， xfs 的 block 與 inode 有多種不同的容量可供設定，block 容量可由 512bytes ~ 64K 調配，不過，Linux 的環境下， 由於記憶體控制的關係 (分頁檔 pagesize 的容量之故)，因此最高可以使用的 block 大小為 4K 而已！(鳥哥嘗試格式化 block 成為 16K 是沒問題的，不過，Linux 核心不給掛載！ 所以格式化完成後也無法使用啦！) 至於 inode 容量可由 256bytes 到 2M 這麼大！不過，大概還是保留 256bytes 的預設值就很夠用了！\nTips：總之， xfs 的這個資料區的儲存區群組 (allocation groups, AG)，你就將它想成是 ext 家族的 block 群組 (block groups) 就對了！本小節之前講的都可以在這個區塊內使用。 只是 inode 與 block 是動態產生，並非一開始於格式化就完成配置的。\n 檔案系統活動登錄區 (log section)  在登錄區這個區域主要被用來紀錄檔案系統的變化，其實有點像是日誌區啦！檔案的變化會在這裡紀錄下來，直到該變化完整的寫入到資料區後， 該筆紀錄才會被終結。如果檔案系統因為某些緣故 (例如最常見的停電) 而損毀時，系統會拿這個登錄區塊來進行檢驗，看看系統掛掉之前， 檔案系統正在運作些啥動作，藉以快速的修復檔案系統。\n因為系統所有動作的時候都會在這個區塊做個紀錄，因此這個區塊的磁碟活動是相當頻繁的！xfs 設計有點有趣，在這個區域中， 妳可以指定外部的磁碟來作為 xfs 檔案系統的日誌區塊喔！例如，妳可以將 SSD 磁碟作為 xfs 的登錄區，這樣當系統需要進行任何活動時， 就可以更快速的進行工作！相當有趣！\n 即時運作區 (realtime section)  當有檔案要被建立時，xfs 會在這個區段裡面找一個到數個的 extent 區塊，將檔案放置在這個區塊內，等到分配完畢後，再寫入到 data section 的 inode 與 block 去！ 這個 extent 區塊的大小得要在格式化的時候就先指定，最小值是 4K 最大可到 1G。一般非磁碟陣列的磁碟預設為 64K 容量，而具有類似磁碟陣列的 stripe 情況下，則建議 extent 設定為與 stripe 一樣大較佳。這個 extent 最好不要亂動，因為可能會影響到實體磁碟的效能喔。\nXFS 檔案系統的描述資料觀察\n剛剛講了這麼多，完全無法理會耶～有沒有像 EXT 家族的 dumpe2fs 去觀察 superblock 內容的相關指令可以查閱呢？有啦！可以使用 xfs_info 去觀察的！ 詳細的指令作法可以參考如下：\n[root@study ~]# xfs_info 掛載點|裝置檔名 範例一：找出系統 /boot 這個掛載點底下的檔案系統的 superblock 紀錄 [root@study ~]# df -T /boot Filesystem Type 1K-blocks Used Available Use% Mounted on /dev/vda2 xfs 1038336 133704 904632 13% /boot # 沒錯！可以看得出來是 xfs 檔案系統的！來觀察一下內容吧！ [root@study ~]# xfs_info /dev/vda2 1 meta-data=/dev/vda2 isize=256 agcount=4, agsize=65536 blks 2 = sectsz=512 attr=2, projid32bit=1 3 = crc=0 finobt=0 4 data = bsize=4096 blocks=262144, imaxpct=25 5 = sunit=0 swidth=0 blks 6 naming =version 2 bsize=4096 ascii-ci=0 ftype=0 7 log =internal bsize=4096 blocks=2560, version=2 8 = sectsz=512 sunit=0 blks, lazy-count=1 9 realtime =none extsz=4096 blocks=0, rtextents=0 上面的輸出訊息可以這樣解釋：\n 第 1 行裡面的 isize 指的是 inode 的容量，每個有 256bytes 這麼大。至於 agcount 則是前面談到的儲存區群組 (allocation group) 的個數，共有 4 個， agsize 則是指每個儲存區群組具有 65536 個 block 。配合第 4 行的 block 設定為 4K，因此整個檔案系統的容量應該就是 4655364K 這麼大！ 第 2 行裡面 sectsz 指的是邏輯磁區 (sector) 的容量設定為 512bytes 這麼大的意思。 第 4 行裡面的 bsize 指的是 block 的容量，每個 block 為 4K 的意思，共有 262144 個 block 在這個檔案系統內。 第 5 行裡面的 sunit 與 swidth 與磁碟陣列的 stripe 相關性較高。這部份我們底下格式化的時候會舉一個例子來說明。 第 7 行裡面的 internal 指的是這個登錄區的位置在檔案系統內，而不是外部設備的意思。且佔用了 4K * 2560 個 block，總共約 10M 的容量。 第 9 行裡面的 realtime 區域，裡面的 extent 容量為 4K。不過目前沒有使用。  由於我們並沒有使用磁碟陣列，因此上頭這個裝置裡頭的 sunit 與 extent 就沒有額外的指定特別的值。根據 xfs(5) 的說明，這兩個值會影響到你的檔案系統性能， 所以格式化的時候要特別留意喔！上面的說明大致上看看即可，比較重要的部份已經用特殊字體圈起來，你可以瞧一瞧先！\nRosetta 由于我主要使用 ubuntu，为学习而使用 fedora，只是短时期使用过其他发行版，因此截取部分如下。\nBasic operations    Action Red Hat/Fedora Debian/Ubuntu     Search for package(s) by searching the expression in name, description, short description. What exact fields are being searched by default varies in each tool. Mostly options bring tools on par. dnf search apt search   Install a package(s) by name dnf install apt install   Upgrade Packages - Install packages which have an older version already installed dnf upgrade apt update and then apt upgrade   Upgrade Packages - Another form of the update command, which can perform more complex updates \u0026ndash; like distribution upgrades. When the usual update command will omit package updates, which include changes in dependencies, this command can perform those updates. dnf distro-sync apt update and then apt dist-upgrade   Remove a package(s) and all dependencies by name dnf remove apt autoremove   Remove a package(s) and its configuration files ? apt purge   Remove a package(s) and all dependencies and configuration files ? apt autoremove --purge   Remove dependencies that are no longer needed (orphans), because e.g. the package which needed the dependencies was removed. dnf autoremove apt autoremove   Remove packages no longer included in any repositories. dnf repoquery --extras aptitude purge '~o'   Mark a package previously installed as a dependency as explicitly required. dnf mark install apt-mark manual   Install package(s) as dependency / without marking as explicitly required. dnf install and then dnf mark remove apt-mark auto   Only downloads the given package(s) without unpacking or installing them dnf download apt install --download-only (into the package cache) or apt download (bypass the package cache)   Clean up all local caches. Options might limit what is actually cleaned. dnf clean all apt autoclean removes only unneeded, obsolete information or apt clean   Start a shell to enter multiple commands in one session dnf shell    Show a log of actions taken by the software management. dnf history read /var/log/dpkg.log   Get a dump of the whole system information - Prints, Saves or similar the current state of the package management system. Preferred output is text or XML. (Note: Why either-or here? No tool offers the option to choose the output format.) see /var/lib/rpm/Packages apt-cache stats   e-mail delivery of package changes  apt install apt-listchanges    Querying specific packages    Action Red Hat/Fedora Debian/Ubuntu     Show all or most information about a package. The tools' verbosity for the default command vary. But with options, the tools are on par with each other. dnf list or dnf info apt show or apt-cache policy   Display local package information: Name, version, description, etc. rpm -qi / dnf info installed dpkg -s or aptitude show   Display remote package information: Name, version, description, etc. dnf info apt-cache show or aptitude show   Display files provided by local package rpm -ql dpkg -L   Display files provided by a remote package dnf repoquery -l or repoquery -l (from package yum-utils) apt-file list   Query the package which provides FILE rpm -qf (installed only) or dnf provides (everything) or repoquery -f (from package yum-utils) dpkg -S or dlocate   List the files that the package holds. Again, this functionality can be mimicked by other more complex commands. dnf repoquery -l dpkg-query -L   Displays packages which provide the given exp. aka reverse provides. Mainly a shortcut to search a specific field. Other tools might offer this functionality through the search command. dnf provides apt-file search   Search all packages to find the one which holds the specified file. dnf provides apt-file search or auto-apt is using this functionality.   Show the changelog of a package dnf changelog apt-get changelog    Querying package lists    Action Red Hat/Fedora Debian/Ubuntu     Search for package(s) by searching the expression in name, description, short description. What exact fields are being searched by default varies in each tool. Mostly options bring tools on par. dnf search apt search   Lists packages which have an update available. Note: Some provide special commands to limit the output to certain installation sources, others use options. dnf list updates or dnf check-update apt list --upgradable   Display a list of all packages in all installation sources that are handled by the packages management. Some tools provide options or additional commands to limit the output to a specific installation source. dnf list available apt-cache dumpavail or apt-cache dump (Cache only) or apt-cache pkgnames   Generates a list of installed packages dnf list installed `dpkg \u0026ndash;list   List packages that are installed but are not available in any installation source (anymore). dnf list extras `apt \u0026ndash;installed list   List packages that were recently added to one of the installation sources, i.e. which are new to it. dnf list recent aptitude search '~N' or aptitude forget-new   List installed local packages along with version rpm -qa dpkg -l or apt list --installed   Search locally installed package for names or descriptions rpm -qa '*\u0026lt;str\u0026gt;*' `aptitude search \u0026lsquo;~i(~n $name   List packages not required by any other package dnf leaves or package-cleanup --leaves --all deborphan -anp1   List packages installed explicitly (not as dependencies) dnf history userinstalled apt-mark showmanual   List packages installed automatically (as dependencies) grep -E \u0026lsquo;^i[^+]\u0026rsquo; (workaround) apt-mark showauto    Querying package dependencies    Action Red Hat/Fedora Debian/Ubuntu     Display packages which require X to be installed, aka show reverse dependencies. dnf repoquery --alldeps --whatrequires or repoquery --whatrequires apt-cache rdepends or aptitude search ~D$pattern   Display packages which conflict with given expression (often package). Search can be used as well to mimic this function. dnf repoquery --conflicts aptitude search '~C$pattern'   List all packages which are required for the given package, aka show dependencies. dnf repoquery --requires or repoquery -R apt-cache depends or apt-cache show   List what the current package provides dnf repoquery --provides dpkg -s or aptitude show   List all packages that require a particular package dnf repoquery --installed --alldeps --whatrequires aptitude search ~D{depends,recommends,suggests}:$pattern or aptitude why   Display all packages that the specified packages obsoletes. dnf list obsoletes apt-cache show   Generates an output suitable for processing with dotty for the given package(s).  apt-cache dotty    Installation sources management    Action Red Hat/Fedora Debian/Ubuntu     Installation sources management edit /etc/yum.repos.d/${REPO}.repo edit /etc/apt/sources.list   Add an installation source to the system. Some tools provide additional commands for certain sources, others allow all types of source URI for the add command. Again others, like apt and dnf force editing a sources list. apt-cdrom is a special command, which offers special options design for CDs/DVDs as source. /etc/yum.repos.d/*.repo apt-cdrom add   Refresh the information about the specified installation source(s) or all installation sources. dnf clean expire-cache and then dnf check-update apt-get update   Prints a list of all installation sources including important information like URI, alias etc. cat /etc/yum.repos.d/* apt-cache policy   List all packages from a certain repo     Disable an installation source for an operation dnf --disablerepo=    Download packages from a different version of the distribution than the one installed. dnf --releasever= apt-get install -t release package or apt-get install package/release (dependencies not covered)    Overrides    Action Red Hat/Fedora Debian/Ubuntu     Add a package lock rule to keep its current state from being changed edit dnf.conf adding/amending the exclude option apt-mark hold pkg   Delete a package lock rule  apt-mark unhold pkg   Show a listing of all lock rules  /etc/apt/preferences   Set the priority of the given package to avoid upgrade, force downgrade or to overwrite any default behavior. Can also be used to prefer a package version from a certain installation source.  /etc/apt/preferences, apt-cache policy   Remove a previously set priority  /etc/apt/preferences   Show a list of set priorities  apt-cache policy or /etc/apt/preferences   Ignore problems that priorities may trigger.      Verification and repair    Action Red Hat/Fedora Debian/Ubuntu     Verify single package rpm -V debsums   Verify all packages rpm -Va debsums   Reinstall given package; this will reinstall the given package without dependency hassle dnf reinstall apt install --reinstall   Verify dependencies of the complete system; used if installation process was forcefully killed dnf repoquery --requires apt-get check   Use some magic to fix broken dependencies in a system dnf repoquery --unsatisfied apt-get --fix-broken and then aptitude install   Add a checkpoint to the package system for later rollback (unnecessary, it is done on every transaction)    Remove a checkpoint from the system n/a    Provide a list of all system checkpoints dnf history list    Rolls entire packages back to a certain date or checkpoint dnf history rollback    Undo a single specified transaction dnf history undo     Using package files and building packages    Action Red Hat/Fedora Debian/Ubuntu     Query a package supplied on the command line rather than an entry in the package management database rpm -qp dpkg -I   List the contents of a package file rpmls rpm -qpl dpkg -c   Install local package file, e.g. app.rpm and uses the installation sources to resolve dependencies dnf install apt install   Updates package(s) with local packages and uses the installation sources to resolve dependencies dnf upgrade debi   Add a local package to the local package cache mostly for debugging purposes.  apt-cache add *package-filename*   Extract a package `rpm2cpio cpio -vid`   Install/Remove packages to satisfy build-dependencies. Uses information in the source package dnf builddep apt-get build-dep   Display the source package to the given package name(s) dnf repoquery -s apt-cache showsrc   Download the corresponding source package(s) to the given package name(s) dnf download --source apt-get source or debcheckout   Build a package rpmbuild -ba (normal) or mock (in chroot) debuild   Check for possible packaging issues rpmlint lintian    Fedora Tips kill kill 是向进程发送信号的命令。\n   代号 名称 内容     1 SIGHUP 启动被终止的程序，可让该进程重新读取自己的配置文件，类似重新启动。   2 SIGINT 相当于用键盘输入 [ctrl]-c 来中断一个程序的进行。   9 SIGKILL 代表强制中断一个程序的进行，如果该程序进行到一半，那么尚未完成的部分可能会有“半产品”产生，类似 vim会有 .filename.swp 保留下来。   15 SIGTERM 以正常的方式来终止该程序。由于是正常的终止，所以后续的动作会将他完成。不过，如果该程序已经发生问题，就是无法使用正常的方法终止时，输入这个 signal 也是没有用的。   19 SIGSTOP 相当于用键盘输入 [ctrl]-z 来暂停一个程序的进行。    Shell freezes In the event of a shell freeze (which might be caused by certain appearance tweaks, malfunctioning extensions or perhaps a lack of available memory), restarting the shell by pressing Alt+F2 and then entering r may not be possible.\nIn this case, try switching to another TTY (Ctrl+Alt+F2) and entering the following command: pkill -HUP gnome-shell. It may take a few seconds before the shell successfully restarts. On X11, restarting the shell in this fashion should not log the user out, but it is a good idea to try and ensure that all work is saved anyway; on Wayland (currently the default), restarting the shell kills the whole session, so everything will be lost.\nIf this fails, the Xorg server will need to be restarted either by pkill X for console logins or by restarting gdm.service for GDM logins. Bear in mind that restarting the Xorg server will log the user out, so try to ensure that all work is saved before attempting this.\nfix a frozen Gnome desktop session 在较旧的 Gnome（即 Gnome 3.28 之前）中，您可以使用此命令重新启动 GNome shell。\n$ glxinfo | grep display name of display: :1 display: :1 screen: 0 $ touch gnome-restart $ echo \u0026#39;#!/bin/bash\u0026#39; \u0026gt; gnome-restart $ echo \u0026#39;DISPLAY=:1 gnome-shell --replace \u0026amp;\u0026#39; \u0026gt;\u0026gt; gnome-restart $ sudo chmod +x gnome-restart $ ./gnome-restart 重启 Gnome Shell 可以使用 busctl --user call org.gnome.Shell /org/gnome/Shell org.gnome.Shell Eval s 'Meta.restart(\u0026quot;Restarting…\u0026quot;)' 命令行执行 ALT + F2 r 相同的操作。\n亦可：\n$ sudo systemctl restart systemd-logind Gaming on Fedora  Nvidia Drivers Steam(ProtonDB)/Lutris/Q4Wine Discord OBS GOverlay  Fedora 33 百度网盘Linux版 那个 rpm 包压根不是对标最新的Fedora的，而是给那些基于RHEL的同样使用rpm包管理的古董国产操作系统使用的。\n下载 baidunetdisk_3.5.0_amd64.deb，并解压出实际的程序。\n首先我们跑一下，看看bt 吧：\nThread 1 \u0026#34;baidunetdisk\u0026#34; received signal SIGSEGV, Segmentation fault. 0x00007ffff5096179 in EVP_MD_CTX_clear_flags () from /lib64/libcrypto.so.1.1 (gdb) bt 目测翻车在libcrypto.so.1.1, 而且是跟sqlite加密有关.\n我们把baidunetdisk动态链接到相关的加密库都找出来:\n$ ldd baidunetdisk | grep -i -E \u0026#39;ssl|crypt\u0026#39; libgcrypt.so.20 =\u0026gt; /lib64/libgcrypt.so.20 (0x00007fa18d693000) libk5crypto.so.3 =\u0026gt; /lib64/libk5crypto.so.3 (0x00007fa18d3cd000) libcrypto.so.1.1 =\u0026gt; /lib64/libcrypto.so.1.1 (0x00007fa18d0c0000) 经验告诉我，这个baidunetdisk挂的原因是， Fedora 33上面的包都比较新，尤其是 openssl 库. 因此，解决办法是，去下载老版本的 Ubuntu 18.04 的包，然后把so文件取出来，强制baidunetdisk使用这些旧版本的库即可.\nldd 一下很容易找出依赖关系: libkrb5.so.3 -\u0026gt; libk5crypto.so.3 -\u0026gt; libcrypto.so.1.1\n下载以下包:\nhttps://ubuntu.pkgs.org/18.04/ubuntu-main-amd64/libkrb5support0_1.16-2build1_amd64.deb.html https://ubuntu.pkgs.org/18.04/ubuntu-main-amd64/libk5crypto3_1.16-2build1_amd64.deb.html https://ubuntu.pkgs.org/18.04/ubuntu-main-amd64/libkrb5-3_1.16-2build1_amd64.deb.html https://ubuntu.pkgs.org/18.04/ubuntu-main-amd64/libgssapi-krb5-2_1.16-2build1_amd64.deb.html http://archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.0g-2ubuntu4_amd64.deb 编辑 /usr/share/applications/baidunetdisk.desktop, 将Exec=/opt/baidunetdisk/baidunetdisk --no-sandbox %U 修改成：\nExec=/bin/env LD_LIBRARY_PATH=/home/ttys3/Apps/baidunetdisk /home/ttys3/Apps/baidunetdisk/baidunetdisk --no-sandbox %U ldd 查看程序依赖库 作用：用来查看程式运行所需的共享库,常用来解决程式因缺少某个库文件而不能运行的一些问题。\n示例：查看test程序运行所依赖的库:\n/opt/app/todeav1/test$ ldd test libstdc++.so.6 =\u0026gt; /usr/lib64/libstdc++.so.6 (0x00000039a7e00000) libm.so.6 =\u0026gt; /lib64/libm.so.6 (0x0000003996400000) libgcc_s.so.1 =\u0026gt; /lib64/libgcc_s.so.1 (0x00000039a5600000) libc.so.6 =\u0026gt; /lib64/libc.so.6 (0x0000003995800000) /lib64/ld-linux-x86-64.so.2 (0x0000003995400000) /opt/app/todeav1/test$ ldd libc.so.6 ...  第一列：程序需要依赖什么库 第二列: 系统提供的与程序需要的库所对应的库 第三列：库加载的开始地址  通过上面的信息，我们可以得到以下几个信息：\n 通过对比第一列和第二列，我们可以分析程序需要依赖的库和系统实际提供的，是否相匹配 通过观察第三列，我们可以知道在当前的库中的符号在对应的进程的地址空间中的开始位置  如果依赖的某个库找不到，通过这个命令可以迅速定位问题所在。\n原理： ldd不是个可执行程式，而只是个shell脚本； ldd显示可执行模块的dependency的工作原理，其实质是通过ld-linux.so（elf动态库的装载器）来实现的。ld-linux.so模块会先于executable模块程式工作，并获得控制权，因此当上述的那些环境变量被设置时，ld-linux.so选择了显示可执行模块的dependency。\nadb and fastboot $ sudo dnf install android-tools OneDrive 加速 OneDrive 的下载速度，明白的都明白，不懂得也就算了 。\nPC 端（手机端应该也可以）有一个可能有效的提速方法是：\n 前往：https://tools.ipip.net/traceroute.php 左侧 ipv6 或 ipv4 选择离自己最近的运营商，右侧 ICMP 填入sharepoint.com 搜索之后将延时最短的非局域网 ip 填入在hosts文件中 保存，使之生效，可以在控制台ping sharepoint.com查看是否成功解析到新的 ip  Recover a root password   Boot the Live installation media and choose Try Fedora.\n  From the desktop, open a terminal and switch to root using su (the system will not ask for a password).\n  To view your hard drive device nodes, enter df -H into the terminal. For this example we will use /dev/sda1 for the /boot partition and /dev/sda2 for the root / partition.\nIf you are using LVM partitions, type: sudo lvscan and note the /dev path of your root partition. For this example we will use /dev/fedora/root.\n  Create a directory for the mount point (use the -p option to create subdirectories):\nmkdir -p /mnt/sysimage/boot   Mount the / (root) partition (be sure to use the actual device node or LVM path of your root / partition):\nTo mount root on a standard partition scheme enter:\nmount /dev/sda2 /mnt/sysimage To mount root on an LVM partition scheme enter:\nmount /dev/fedora/root /mnt/sysimage   Continue the process by mounting /boot, proc, /dev, and /run with:\nmount /dev/sda1 /mnt/sysimage/boot mount -t proc none /mnt/sysimage/proc mount -o bind /dev /mnt/sysimage/dev mount -o bind /run /mnt/sysimage/run   chroot to the mounted root partition with:\nchroot /mnt/sysimage /bin/bash   Change the root password:\npasswd   Exit out of chroot with:\nexit and exit out of the terminal.\n  Reboot your system and boot from the hard drive.\n  Congratulations, your root password has been successfully changed.\nSamba Server Install and Configure Samba\nTo get started with samba, you need to install the samba core packages and samba-client package as shown:\n# dnf install samba samba-common samba-client  After all the samba is installed, you need to configure the samba share directory with proper permissions and ownership, so that it is going to be shared with all client machines in the same local network.\n# mkdir -p /srv/tecmint/data # chmod -R 755 /srv/tecmint/data # chown -R nobody:nobody /srv/tecmint/data # chcon -t samba_share_t /srv/tecmint/data Next, we are going to configure the Samba share directory in the smb.conf file, which is the main configuration file for Samba.\n# mv /etc/samba/smb.conf /etc/samba/smb.conf.bak # vim /etc/samba/smb.conf Add the following configuration lines, which define the policies on who can access the samba share on the network.\n[global] workgroup = WORKGROUP server string = Samba Server %v netbios name = rocky-8 security = user map to guest = bad user dns proxy = no ntlm auth = true [Public] path = /srv/tecmint/data browsable =yes writable = yes guest ok = yes read only = no Save and exit the configuration file.\nNext, verify the samba configuration for errors.\n# testparm If everything looks okay, make sure to start, enable and verify the status of the Samba daemons.\n# systemctl start smb # systemctl enable smb # systemctl start nmb # systemctl enable nmb # systemctl status smb # systemctl status nmb Accessing Samba Share from Windows\nTo access Samba share from the Windows machine, press the Windows logo key + R to launch the Run dialog and enter the IP address of the samba server\nSecure Samba Share Directory\nTo secure our Samba share, we need to create a new samba user.\n# useradd smbuser # smbpasswd -a smbuser Next, create a new group and add the new samba user to this group.\n# sudo groupadd smb_group # sudo usermod -g smb_group smbuser Thereafter, create another secure samba share directory for accessing files securely by samba users.\n# mkdir -p /srv/tecmint/private # chmod -R 770 /srv/tecmint/private # chcon -t samba_share_t /srv/tecmint/private # chown -R root:smb_group /srv/tecmint/private Once again, access the Samba configuration file.\n# vi /etc/samba/smb.conf Add these lines to define to secure samba share.\n[Private] path = /srv/tecmint/private valid users = @smb_group guest ok = no writable = no browsable = yes Save the changes and exit.\nFinally, restart all the samba daemons as shown.\n$ sudo systemctl restart smb $ sudo systemctl restart nmb Now try to access the Samba share, this time you will see an additional ‘Private‘ directory. To access this directory, you will be required to authenticate with the Samba user’s credentials\n[MIT/GNU Scheme](MIT/GNU Scheme) 9.2 是最后支持 windows 的版本，之前的版本我在fedora上编译失败了。\n$ wget https://ftp.gnu.org/gnu/mit-scheme/stable.pkg/9.2/mit-scheme-9.2-x86-64.tar.gz $ sudo dnf install gcc make m4 ncurses-devel libX11-devel $ tar xzf mit-scheme-VERSION-i386.tar.gz $ cd mit-scheme-VERSION/src $ sudo ./configure --prefix=/opt/mit-scheme $ sudo make $ sudo make install WAV、FLAC、APE 区别 同一个音乐文件而言，WAV、FLAC、APE三种音乐格式的音质是完全一样的。\n意思是说，从CD碟上抓轨出来后，得到的WAV和APE、FLAC音质完全相同，实际上是不同形式的同一个文件。但与CD碟是否完全一样，除了抓轨操作问题，基本上都是电脑设备技术所限。（你不能要求电脑器材技术同灌制唱片的专业器材一致，电脑只是个均衡性技术器材组合体。）\n所以，从收藏角度来说，三种格式可以，一样。但播放效果上，上万元的专业设备和神经质般的金耳朵是能听出些许差别来的，这主要是因为不同格式间因编码不同导致解码速度不同所致；如果转换为同一种格式，正常听是没有区别的。\n那么，APE、FLAC、WAV三种格式区别在哪里呢？（这些区别并不是说音乐文件本身品质有优劣）\n  编码不同，导致解码速度WAV \u0026gt; FLAC \u0026gt; APE，直接影响到播放听感流畅性上：WAV \u0026gt; FLAC \u0026gt; APE\nWAV波形文件是音响设备和很多软件可以直接读取的波形文件，基本上不存在编解码问题。flac和ape都对WAV进行了编码，故能换取较小的体积，但同时造成解码播放时，因播放器材解析力很敏感（或者说技术所限），会因出现一定的jitter抖动（解析复杂编码所致）而导致播放效果不够饱满和流畅。这点你可以通过统一转换为WAV格式来试听解决。\n  编码不同，导致所占空间大小 APE \u0026lt; FLAC \u0026lt; WAV。\n由于flac和ape都对WAV进行了更高技术的编码，所以换取了较小的体积，这也是这两种格式之所以出现的根本原因。由于二者都是无损压缩，如果你是为了收藏，同时你的空间比较吃紧，无疑收藏较小体积的APE是最佳选择。至于以后会不会出现更小体积的无损压缩格式，但目前来说，APE 是最优选择。\n  编码不同，解码速度不一，导致占用CPU和耗电量不同。\n编码越复杂，解码越麻烦，自然占用内存率越高，耗电量自然越大。那些伤不起的播放机们感触最深，同样的电量，三种格式播放时长依次为由长到短：WAV \u0026gt; FLAC \u0026gt; APE，所以，如果你的P5播放机比较脆弱，自然选择WAV可以享受更长时间的音乐。\n  开源性不同，导致纠错效果不同。\n这一点各取所需吧！很多flac粉们对APE的防纠错和容错性大为诟病，指责其一报错就无法继续播放，等于整轨作废，同时嫌技术不开放（难道你自己要编程？搞不懂这个意见也这么大）。而flac用静音处理方式他们就认为很好。\n个人认为，如果播放的话，因为一个错误就整轨不能播放，等于白下载，的确很烦人，而flac静音处理得以继续播放下面的曲目，的确人性；但从收藏的角度而言，静音处理错误是不是有点瞒天过海、自欺欺人？发烧者和收藏癖们对人耳觉察不到的细微差别都耿耿于怀，怎么会放过这么大的差错？反正，如果有错误音轨，我是肯定不要收藏的，而APE，正好给我了检验好坏质量的途径。\n  开源性不同，导致支持软件多寡不均。\n编码软件的支持上，大家都说支持flac的软件比ape多。这点没问题。但并不等于支持Ape格式的播放软件就少。实际上，现在已经有很多软件支持ape了。而且，支持flac的软件虽然多，也有很多不支持flac的，但wav就不一样了，还没有不支持WAV格式的播放器呢！这样说来，是不是也要把flac淘汰掉？！其实，听的时候就那么几首歌，转一下格式能够让你的播放器支持不就好啦。\n  从收藏角度讲，APE、FLAC、WAV三种格式一样，文件音质相同；从播放来讲，格式不同，专业设备下，效果可能会有人耳察觉不同的区别（楼主没感觉出来）。\n扩展知识 无损音乐音质也分“三六九等”\n同一个文件的各个无损格式是一样的音质，如果不是同一个文件，即使是同一首歌，音质也分三六九等。举个例子，彭丽媛的曲目《在希望的田野上》 ，收录于《非同凡响》、《沂蒙山小调》、《演唱中国民歌》、《珠穆朗玛》等多个音乐专辑，这些专辑分别由不同的唱片公司于不同的时间出版，音质就会参差不齐。同时，由于时代不同，技术上受历史局限。也会导致音质有别。\n为什么无损音乐和CD比较，听觉上会有细微差别？\n无损音乐与CD碟片数据信息完全一样，那为什么音效不一样呢？嗯，这里我用的“音效”这个词非常好。CD碟和原声一样吗？肯定不一样。主要是技术上根本做不到完全还原原声。而且，为了音乐效果，一般还会加进各种特效。CD播放机和电脑，更是两个功用完全不同的设备。音效当然不可能一致。\n其实，就算CD播放机，也不可能找到两台播放效果完全一样的。有句话，大意是世界上不可能找到两把相同的二胡，也是这个意思。\n假无损是怎么回事？\n到这里，我就给大家提炼出一个观点：【“无损音乐”不等于“无损音质”】\n除了碟片录制设备技术问题（早期碟片音质都不好；不同唱片公司录制技术层次不同；国内碟相对国外顶级技术也不好），也有假无损，即不是由正版CD碟片抓轨得到，而是通过盗版碟片抓轨、磁带（卡带）翻录甚至是有损音乐（MP3等）转换而得到。这些APE、FLAC、WAV等格式的所谓的“无损音乐”，其音质就很差很差。\n除了第一个原因我们无奈选择外，其他的发烧友都应该剔除。对于磁带翻录，如果是稀有资源，建议大家保留，因为如果找不到无损，有总比无好。\n我的音乐听起来音质不好，是无损吗？\n前面说了，【“无损音乐”不等于“无损音质”】，无损音乐严格来说，是指wav波形文件从音乐CD碟片的无损数字记录和APE、FLAC、WavPack、WMALossless等则是对WAV波形文件进行无损压缩。wav是无损音乐文件，APE、FLAC等则是无损压缩音乐文件。绝对意义上讲，他们都不能完全替代CD碟。WAV波形文件在媒体播放器里直接播放，而APE等其他压缩格式则需要经过解压（解码）还原成WAV再进行播放。\n如果你的无损音乐听感比较差，这你就要注意了\n⒈ 是真无损，多见于早期碟片。由于上世纪CD碟片刚起步，技术水平有限，故灌制效果相对今天的碟片来说欠佳。此外，即使今天，不同唱片公司出品的碟片，音质也有差别。在没有替代品的情况下，建议保留。\n⒉ 是真无损，音质不好可能由抓轨操作失误造成“爆音”等数据信息残缺，建议更换。\n⒊ 显示真无损，音质极差。这多由磁带/卡带转录而来。早期歌手只有磁带作品留世，虽然音质不好，但是唯一的纪念品。将其转录为数据，是为了更好地保存。在没有替代品的情况下，建议保留。\n⒋ 假无损。即由有损格式MP3、WMA、OGG等格式转换而来，有些凭耳听，甚至难与真无损辨别，只有软件能检测出。有损转无损，丢失的信息不会转回来。虽然体积增大了，音质还是有损的音质。\n如何鉴别无损音乐？\n如何鉴别？主要是一靠听、二靠看、三靠软件检测。\n注意软件检测也会出错，只是作为参考。毕竟，音乐最主要的用途是欣赏，而不是科学精密研究。建议大家首先听。比如磁带转录的，一般一听就听出来。但软件检测未必检测出。这是因为软件作用只是检测哪些是由有损低劣的音乐转换成的伪劣假冒无损。\n  【一听】\n听第一感觉，如果音质不好，甚至有爆音，即使是真无损，也是音质较差的低劣无损。\n  【二看】看占用空间大小和播放码率\n看占用空间大小，一定要在相同格式的前提下，否则用APE和FLAC比较，是无意义的。一般，两个时长、内容一致的同名文件，占用空间越大者原则上包含信息越丰富、音质越好；看播放码率。\n  【三检测】用无损检验软件检测，和看频谱。\n  篇外篇 长期来，很多人对MP3印象不好，更多人认为WMA的最佳音质要好过MP3，这种说法是不正确的，在中高码率下，编码得当的MP3要比WMA优秀很多，可以非常接近CD音质，在不太好的硬件设备支持下，没有多少人可以区分两者的差异，这不是神话故事，尽管你以前盲听就可以很轻松区分MP3和CD，但现在你难保证你可以分辨正确。因为MP3也是优秀的编码，以前被埋没了。\n大家都谈说音质好，一种是指还原度好，就是说和录制的时候差别越小越好；一种是指悦耳，就是好听。就mp3来说，mp3是一种压缩格式，码率越高，通常来说就代表压缩小，损失的细节比较少，也就是说，码率越高听起来越接近原声。但是音质还和你的输出设备有关，比如说一部好的mp3，一对好耳机，这都对你的听音音质有帮助！因此，如果想改善音质，不妨从以上几个角度出发，不要过分强调其中哪一方面。\n视频编码码率控制 背景知识：\n视频编码过程中，有一个重要步骤：量化，量化属于有损压缩过程。量化基本决定了视频的码率，视频的码率又从一定程度上决定了视频的质量。量化值QP越大则量化的粒度越高，压缩率越大，码率更小，视频质量越低，呈现出来就是马赛克比较大，画面不细腻，画面比较模糊。反之，压缩率低，码率大，质量高，画面细腻，细节丰富。\n所以选择一个适合场景的视频码控方案很重要，调整视频输出码率其实就是在视频编码速度、网络带宽以及视频质量之间做一个平衡。有时网络带宽很受限，就要优先考虑码率大小优先的码控方案，有些对视频质量要求很高，要高清视频，那就要选择质量优先的模型。\n整体来说选择视频编码码率控制方案，可以通过下面五个因素权衡得出：\n  视觉质量稳定性，利于视觉主观质量，比如清晰度，流畅度，细节等，这点和人眼的视觉原理有关，选择人眼主动质量感受最高的模型；\n  即时输出码率，相当于每帧编码输出比特数，要考虑网络带宽因素，随着移动互联网发展，也需要考虑wifi和无线网这块的影响；\n  输出视频文件大小可控，利于传输，存储，要看系统的空间大小；\n  编码速度，不同的码控模型也影响了编码速度，对于低延时、实时场景要考虑，因为不同的码控方案，计算的复杂度不同，带来的编码延时也有影响；\n  对于移动设备还需要不同编码方式耗电量要求，因为不同模型会影响编码和解码复杂度，进而在移动设备编码和播放需要的耗电量不同；\n  CBR 恒定码率（Constant Bit Rate），一定时间范围内比特率基本保持的恒定，属于码率优先模型。\n**适用场景：**一般也不建议使用这种方式，虽然输出的码率总是处于一个稳定值，但是质量不稳定，不能充分有效利用网络带宽，因为这种模型不考虑视频内容的复杂性，把所有视频帧的内容统一对待。但是有些编码软件只支持固定质量或者固定码率方式，有时不得不用。用的时候在允许的带宽范围内尽可能把带宽设置大点，以防止复杂运动场景下视频质量很低，如果设置的不合理，在运动场景下直接就糊的看不成了。\n特点：\n 码率稳定，但是质量不稳定，带宽有效利用率不高，特别当该值设置不合理，在复杂运动场景下，画面非常模糊，非常影响观看体验； 但是输出视频码率基本稳定，便于计算视频体积大小；  VBR 可变码率（Variable Bit Rate），简单场景分配比较大的QP，压缩率小，质量高。复杂场景分配较小QP。得到基本稳定的视觉质量，因为人眼人眼本来就对复杂场景不敏感，缺点在于输出码率大小不可控。\n有两种调控模式：质量优先模式和2PASS二次编码模式。\n质量优先模式：\n不考虑输出视频文件的大小，完全按照视频的内容复杂程度来分配码率，这样视频的播放效果质量最好。\n二次编码方式2PASS：\n第一次编码检测视频内容的简单和复杂部分，同时确定简单和复杂的比例。第二遍编码会让视频的平均码率不变，复杂的地方分配多bit,简单地方分配少bit。这种编码虽然很好，但是速度会跟不上。\n**适用场景：**VBR适用于那些对带宽和编码速度不太限制，但是对质量有很高要求的场景。特别是在运动的复杂场景下也可以保持比较高的清晰度且输出质量比较稳定，适合对延时不敏感的点播，录播或者存储系统。\n特点：\n 码率不稳定，质量基本稳定且非常高； 编码速度一般比较慢，点播、下载和存储系统可以优先使用，不适合低延时、直播系统； 这种模型完全不考虑输出的视频带宽，为了质量，需要多少码率就占用多少，也不太考虑编码速度；  ABR 恒定平均目标码率(Average Bit Rate），简单场景分配较低bit,复杂场景分配足够bit，使得有限的bit数能够在不同场景下合理分配，这类似VBR。同时一定时间内，平均码率又接近设置的目标码率，这样可以控制输出文件的大小，这又类似CBR。可以认为是CBR和VBR的折中方案，这是大多人的选择。特别在对质量和视频带宽都有要求的情况下，可以优先选择该模式，一般速度是VBR的两倍到三倍，相同体积的视频文件质量却比CBR好很多。\n**适用场景：**ABR在直播和低延时系统用的比较多，因为只编码了一次，所以速度快，同时兼顾了视频质量和带宽,对于转码速度有要求的情况下也可以选择该模式。B站的大部分视频就选择了该模式。\n特点：\n 视频质量整体可控，同时兼顾了视频码率和速度，是一个折中方案，实际用的比较多； 使用过程一般要让调用方设置，最低码率、最高码率和平均码率，这些值要尽可能设置合理点；  总结 不懂的話沒關係，反正普遍情況是這樣的：\n  音質：CBR \u0026gt; VBR \u0026gt; ABR\n192 kbps以下的CBR，與後兩者無明顯差異，但檔案容量差很多，建議有心要壓CBR就直接衝高流量！\n  檔案大小：CBR \u0026gt; VBR \u0026amp; ABR\n後兩者隨參數設定而有差別，大致上差不了多少\n  DFF、DSF、DST  DSD是SACD采用的信号调制方式，相当于CDDA（普通CD）采用的PCM调制方式。 DSF、DFF是SACD碟片中数据的未压缩编码格式，DSF用于Sony，DFF用于Philips，相当于CDDA碟片中的WAV文件。 DST是一种对SACD中DSF、DFF数据进行无损压缩的编码格式，相当于FLAC、APE是对CDDA中WAV数据的无损压缩。  RPM 搜索与下载网站  pkgs.org：最好的 rpm.pbone.net：比较全面但是下载速度有点慢 rpmfind.net：速度还可以就是没有上面的全 crpm.cn  误删了 /usr/share/icons 目录   从他们的官方网站下载您的操作系统的完整 ISO 并将其加载到驱动器中，然后将 /usr/share/applications 从 ISO 复制到您的系统。\n  reinstall\n$ sudo dnf reinstall \u0026#34;$(rpm -qa)\u0026#34;   Flatpak 的亚洲字体问题 如果你遇到了游戏中无法显示亚洲字体的问题，这是因为 org.freedesktop.Platform 并没有包含合适的字体文件进去。首先尝试挂载你的本地字体：\n$ flatpak run --filesystem=~/.local/share/fonts --filesystem=~/.config/fontconfig com.valvesoftware.Steam 如果上述命令不起作用，考虑动手 hack 一下：直接将字体文件复制进 org.freedesktop.Platform 的目录下以启用字体，例如\n# replace ? with your version and hash /var/lib/flatpak/runtime/org.freedesktop.Platform/x86_64/?/?/files/etc/fonts/conf.avail /var/lib/flatpak/runtime/org.freedesktop.Platform/x86_64/?/?/files/etc/fonts/conf.d /var/lib/flatpak/runtime/org.freedesktop.Platform/x86_64/?/?/files/share/fonts SELinux policy for a systemd service Check that the script is properly labeled as bin_t\n$ sudo chcon -v -t bin_t /home/kurome/.opt/clash/clash_premium FILTER RULES ~/.opt/rsync/backup-home:\n+ /.config/ + /.config/autostart/*** + /.config/fontconfig/*** + /.config/google-chrome/*** + /.config/ibus/*** + /.config/obsidian/*** + /.config/Typora/*** + /Documents/*** + /.goldendict/*** + /.local/ + /.local/bin/*** + /.local/share + /.local/share/applications/*** + /.local/share/icons/*** + /.local/share/TelegramDesktop/*** + /Music/*** + /.opt/*** + /.ssh/*** + /Templates/*** - /**   Using Rsync filter to include/exclude files\nthis won\u0026rsquo;t work:\n+ /some/path/this-file-will-not-be-found + /file-is-included - * this set of rules works fine:\n+ /some/ + /some/path/ + /some/path/this-file-is-found + /file-also-included - *   exclude all directories except a few\n$ cat filter.txt + /include_this_dir/ + /include_this_dir/** + /include_that_dir/ + /include_that_dir/** - /** $ rsync -av --dry-run --filter=\u0026#34;merge filter.txt\u0026#34; source_dir/ dest_dir/ You can reduce it further with three \u0026ldquo;*\u0026rdquo;, like + /include_this_dir/***, which means + /include_this_dir/ + /include_this_dir/**\n  ~/.local/bin/backup-home:\n#!/bin/bash  set -o errexit set -o nounset set -o pipefail readonly SOURCE_DIR=/home/kurome/ readonly BACKUP_DIR=\u0026#34;$(findmnt -nr -o target -S /dev/mapper/luks-5277e33d-604f-4c1e-bc8c-40c14544614e)/Backup/HomeData\u0026#34; readonly DATETIME=\u0026#34;$(date \u0026#39;+%Y-%m-%d_%H:%M:%S\u0026#39;)\u0026#34; readonly BACKUP_PATH=\u0026#34;${BACKUP_DIR}/${DATETIME}\u0026#34; readonly LATEST_LINK=\u0026#34;${BACKUP_DIR}/latest\u0026#34; rsync -av \\ \t--delete \u0026#34;${SOURCE_DIR}/\u0026#34; \\ \t--link-dest \u0026#34;${LATEST_LINK}\u0026#34; \\ \t--filter=\u0026#34;merge /home/kurome/.opt/rsync/backup-home\u0026#34; \\ \t\u0026#34;${BACKUP_PATH}\u0026#34; rm -rf \u0026#34;${LATEST_LINK}\u0026#34; ln -s \u0026#34;${BACKUP_PATH}\u0026#34; \u0026#34;${LATEST_LINK}\u0026#34; Fedora Questions Cannot open acess to console, the root account is locked\u0026hellip; 先是添加一个 LV 到 /etc/fstab，结果开机报错，原因是写错了：\nTime out ...Dependency failed for ... 结束后就 Cannot open acess to console, the root account is locked，什么也干不了，只能强制关机。\n解决方案是重启进入 Fedora Live CD，挂载 root，修改 /etc/fstab。但是无法挂载，挂载的是 Fedora Live CD 的 root，我 TM 佛了，原因应该是这两个名一模一样，Live CD 覆盖了 root。最后是用 Ubntu Live CD 解决。\n这告诉我们，不要只有一个 Live CD。这还告诉我们，先找自己的原因才能有耐心去解决问题。\ndmesg-x86/cpu: SGX disabled by BIOS SGX技术的分析和研究\nsnd_hda_codec_hdmi hdaudioC0D2: Monitor plugged-in, Failed to power up codec ret=[-13] set Kernel parameters，要使改变在重启后仍生效，您可以手动编辑 /boot/grub/grub.cfg。对于初学者，建议编辑 /etc/default/grub 并将您的内核选项添加至 GRUB_CMDLINE_LINUX_DEFAULT 行：\nGRUB_CMDLINE_LINUX_DEFAULT=\u0026quot;snd_hda_codec_hdmi.enable_silent_stream=0\u0026quot; 然后重新生成 grub.cfg 文件：\n# grub2grub-mkconfig2 -o /boot/grub2/grub.cfg 为什么 Linus Torvalds 用 Fedora  2008：linus对发行版的要求是\u0026quot;易安装，比较贴近上游\u0026quot;即可（滚动+少折腾”）。 2010年的时候，他指出了Fedora 14的一个bug。 2011年Fedora 15换Gnome3作为默认DE了，Linus直言\u0026quot;unholy mess\u0026quot; ，然后转投XFCE。 2011年末，Linus提出并修补了openSUSE中Xorg的一个严重bug。 2013年5月：Linus尝试将自己手头的MacBook Air装上Linux，把几个大的发行版全部都试了一遍。发现只有Fedora能正常工作。 之后的所有消息就是各种fedora了  代理后为什么 ping 不通 问题：\n设置了http_proxy和https_proxy在.bashrc文件里，firefox可以上网了。ping外网能够解析域名，但ping不通\n解答：\n首先提一个问题，为什么我们要用代理服务器上网？\n那是因为如果不用代理服务器，我们访问的website 被blocked，最简单的方式就是在一个大型防火墙上执行： deny website IP。\n而使用代理服务器，无非是用代理服务器的IP作为目的IP，把用户的HTTP、HTTPS封装在TCP上，这样途径防火墙时，由于目的IP不在blocked IP 之列，所以被放行，这样我们就可以浏览一些被blocked 的网页。\n但是一般代理服务器并不为UDP/ICMP服务，最多为TCP服务，所以你ping website 时，代理服务器并没有介入，因为Ping是ICMP报文，那就意味着你的ping包的目的IP就是被blocked IP地址，很显然无法正常通过，全被丢了。\nFedora安装Chrome后显示“您的浏览器由所属组织管理” I finally got a chance to look into this today, and I don\u0026rsquo;t think it\u0026rsquo;s as alarming as this BZ makes it sound. Yes, Chrome (over-)states that it is \u0026ldquo;Managed by your organization\u0026rdquo;. Clicking on that links to https://support.google.com/chrome/answer/9281740 which lists the things a managed system can do. However, if you read just a few sentences further, it tells you how to view exactly which settings your administrator has enabled, which in turn has links to the descriptions of what those features are. As clearly linked there, the only settings we\u0026rsquo;ve enabled is \u0026ldquo;This browser can negotiate authentication with *.fedoraproject.org\u0026rdquo;.\nSo, I\u0026rsquo;m inclined to say that while the initial reading page might lead a user to be slightly concerned, I don\u0026rsquo;t feel that the situation is particularly dire. They can always just read content in the links.\nIn the worst case, if someone really doesn\u0026rsquo;t want to have that message appear, they can just dnf remove fedora-chromium-config.\nfedora-chromium-config\nThis package is used to install customizations for Chromium/Chrome that are recommended by Fedora, including a user-agent string identifying the system as Fedora.\nIt includes a GSSAPI configuration that enables access to many Fedora Project services. To add support for other domains, replace the symlink /etc/chromium/policies/managed/00_gssapi.json with your own content. (upstream)\ndifference between docker attach and docker exec There was a commit PR which added to the doc:\n Note: This command (attach) is not for running a new process in a container. See: docker exec.\n The answer to \u0026ldquo;Docker. How to get bash\\ssh inside runned container (run -d)?\u0026rdquo; illustrates the difference:\n (docker \u0026gt;= 1.3) If we use docker attach, we can use only one instance of shell. So if we want to open new terminal with new instance of container\u0026rsquo;s shell, we just need to run docker exec\nif the docker container was started using /bin/bash command, you can access it using attach, if not then you need to execute the command to create a bash instance inside the container using exec.\n As mentioned in this issue:\n  Attach isn\u0026rsquo;t for running an extra thing in a container, it\u0026rsquo;s for attaching to the running process. \u0026ldquo;docker exec\u0026rdquo; is specifically for running new things in a already started container, be it a shell or some other process.   The same issue adds:\n While attach is not well named, particularly because of the LXC command lxc-attach (which is more akin docker exec \u0026lt;container\u0026gt; /bin/sh, but LXC specific), it does have a specific purpose of literally attaching you to the process Docker started. Depending on what the process is the behavior may be different, for instance attaching to /bin/bash will give you a shell, but attaching to redis-server will be like you\u0026rsquo;d just started redis directly without daemonizing.\n Error syncing passwords  Error: MergeDataAndStartSyncing@../../components/password_manager/core/browser/sync/password_syncable_service.cc:190, datatype error was encountered: Failed to get passwords from store.\n The problem was solved by deleting \u0026lsquo;Login Data\u0026rsquo; and \u0026lsquo;Login Data-journal\u0026rsquo; in the profile.\n$ rm -rf ~/.config/google-chrome/Default/Login\\ Data* The \u0026lt;profile\u0026gt; part can be found in the Profile Path on the chrome://version page.\nGnome Boxes with ssh GNOME Boxes does not expose guests to SSH into. You are expected to have SPICE guest additions installed on the guest to be able:\n to copy and paste text with a shared clipboard between the host and the guest and to drag and drop files into the guest.  This approach is supposed to be intuitively comprehensible for unsophisticated users.\nWhere do packages installed with DNF get stored? With APT (Ubuntu), downloaded packages are stored at: /var/cache/apt/archives\nDNF stores downloaded packages and metadata in /var/cache/dnf, in various per-repository subdirectories.\nHow do I scan for viruses with ClamAV? RHEL RHEL Developer Subscription Need to log in to download RHEL.\n下载的时候会断，有时候甚至下载到 99% 都会断，所以最好是用专门的、支持断点续传的软件（如 aria2）下载。同时最好不要关闭浏览器，特别是保留redhat官网登录状态，如果关闭了就需要重新登录，根本没有保存登录状态选项。\n怎样使用 Red Hat Subscription Manager (RHSM) 将系统注册到红帽客户门户网站？\n# subscription-manager register --username \u0026lt;username\u0026gt; --password \u0026lt;password\u0026gt; --auto-attach 注意！是用户名而不是邮箱！\n配置 Red Hat Enterprise Linux 8 中基本系统设置的指南\nEPEL \u0026amp; RPMFusion EPEL的全称叫 Extra Packages for Enterprise Linux 。EPEL是由 Fedora 社区打造，为 RHEL 及衍生发行版如 CentOS、Scientific Linux 等提供高质量软件包的项目。装上了 EPEL之后，就相当于添加了一个第三方源。\n# subscription-manager repos --enable codeready-builder-for-rhel-9-$(arch)-rpms # dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm 如果你知道rpmfusion.org的话，拿 rpmfusion 做比较还是很恰当的，rpmfusion 主要为桌面发行版提供大量rpm包（只有开源驱动才能进官方源，想要闭源驱动装rpmfusion），而EPEL则为服务器版本提供大量的rpm包，而且大多数rpm包在官方 repository 中是找不到的。\n继上面安装 epel 后安装 RPMFusion：\n# dnf install --nogpgcheck https://mirrors.rpmfusion.org/free/el/rpmfusion-free-release-$(rpm -E %rhel).noarch.rpm https://mirrors.rpmfusion.org/nonfree/el/rpmfusion-nonfree-release-$(rpm -E %rhel).noarch.rpm 使用 BFSU MIRROR\n$ sudo dnf install --nogpgcheck https://mirrors.bfsu.edu.cn/rpmfusion/free/el/rpmfusion-free-release-$(rpm -E %rhel).noarch.rpm https://mirrors.bfsu.edu.cn/rpmfusion/nonfree/el/rpmfusion-nonfree-release-$(rpm -E %rhel).noarch.rpm -y 注意：RHEL、CentOS 及替代（Rocky、AlmaLinux、OracleLinux）等服务器版本，很多常见桌面应用是没有在源里面提供的（不论时官方源还是额外的第三方源），因此需要手动管理了。\nRemi\u0026rsquo;s RPM repository 这个存储库的目标是什么？\n 向Fedora和Enterprise Linux（RHEL、CentOS、Oracle、Scientific Linux，\u0026hellip;）用户提供 最新版本的**PHP**堆栈、全功能和一些其他软件。它主要包含：\n 我也在 Fedora 中维护的包 Fedora 开发版中可用的软件包的反向移植 一些与 Fedora 政策不兼容的软件包 在提交到 Fedora 存储库之前正在处理的一些包 （几乎）香草版本  这与 Enterprise Linux的向后移植修复策略相去甚远。\n GetPageSpeed RHEL Packages Repository We have by far the largest RPM repository with dynamic stable NGINX modules and VMODs for Varnish 4.1 and 6.0 LTS. If you want to install nginx, Varnish and lots of useful modules for them, this is your one stop repository to get all performance related software.\nELRepo Project The ELRepo Project focuses on hardware related packages to enhance your experience with Enterprise Linux. This includes filesystem drivers, graphics drivers, network drivers, sound drivers, webcam and video drivers.\nHTML5/MP4 videos Install EPEL and RPMFusion.\nThen yum install ffmpeg and you should be all set. The way Firefox works with this is it links to the avcodec/avformat (one of those two) libraries at launch, and those are provided by the ffmpeg project. ffmpeg in turn will grab the necessary codecs’ libraries it was compiled with (x264, vp9, x265, etc) and install them on your system.\nKdump Kdump是一种基于kexec的Linux内核崩溃捕获机制，简单来说系统启动时会预留一块内存，当系统崩溃调用命令kexec(kdump kernel)在预留的内存中启动kdump内核，该内核会将此时内存中的所有运行状态和数据信息收集到一个coredump文件中以便后续分析调试。\nQemu on rhel The main QEMU executable is now /usr/libexec/qemu-kvm\nVNC applications Some Free/Libre software supporting VNC/RFB protocol or Remote Desktop Protocol (RDP):\n noVNC (GitHub) is a browser-based app supporting many VNC features but no RDP. rdesktop (GitHub) FreeRDP (GitHub) Fork of rdesktop to clean the code, support Seamless Windows (RDP6)\u0026hellip; Remmina (GitHub) Based on FreeRDP replaced tsclient as Ubuntu\u0026rsquo;s default RD client (2011) Vinagre Default GNOME VNC client supporting RDP since 2012 Ulteo Open Virtual Desktop (guide to get source code)  VirtualBox has a built-in vRDP protocol that can be used to access GNU/Linux remote desktops (Linux distro usually lacks a RDP server). The vRDP protocol is compatible with all RDP clients. However, the proprietary VirtualBox Extension Pack is required.\nSee also this good comparison of remote desktop software (Wikipedia).\nTechRadar has also published an interesting article on this purpose:\n Best Linux remote desktop clients: Top 5 RDC in 2018 By Mayank Sharma, January 2018 We cover all the ins-and-outs of remote viewing\nRemote control features\n TigerVNC 3/5 RealVNC 4/5 Top Remmina 4/5 Top Vinagre 3/5 TightVNC 3/5  Multimedia performance\n TigerVNC 4/5 Top RealVNC 4/5 Top Remmina 3/5 Vinagre 4/5 Top TightVNC 2/5  Interface and usability\n TigerVNC 3/5 RealVNC 3/5 Remmina 3/5 Vinagre 3/5 TightVNC 3/5  Documentation and support\n TigerVNC 2/5 RealVNC 5/5 Top Remmina 3/5 Vinagre 2/5 TightVNC 2/5  Server and protocol support\n TigerVNC 2/5 RealVNC 4/5 Top Remmina 3/5 Vinagre 3/5 TightVNC 1/5  Configurable parameters\n TigerVNC 2/5 RealVNC 4/5 Top Remmina 3/5 Vinagre 2/5 TightVNC 2/5  Connection flexibility\n TigerVNC 4/5 Top RealVNC 3/5 Remmina 4/5 Top Vinagre 2/5 TightVNC 4/5 Top  Final verdict\n TigerVNC 5/5 Open source credentials and performance RealVNC 4/5 Remote desktop access on the Raspberry Pi Remmina 3/5 Multi-protocol remote desktop client Vinagre 3/5 Lacks the control offered by its peers TightVNC 2/5 Focus on Windows platforms   Rocky NJU Mirror $ sed -e \u0026#39;s|^mirrorlist=|#mirrorlist=|g\u0026#39; \\  -e \u0026#39;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.nju.edu.cn/rocky|g\u0026#39; \\  -i.bak \\  /etc/yum.repos.d/Rocky-*.repo $ dnf makecache EPEL 首先从CentOS Extras这个源（本镜像站也有镜像）里安装epel-release：\nyum install epel-release 修改/etc/yum.repos.d/epel.repo，将mirrorlist和metalink开头的行注释掉。\n接下来，取消注释这个文件里baseurl开头的行，并将其中的http://download.fedoraproject.org/pub替换成https://mirrors.bfsu.edu.cn。\n可以用如下命令自动替换：（来自 https://github.com/tuna/issues/issues/687）\n$ sed -e \u0026#39;s!^metalink=!#metalink=!g\u0026#39; \\  -e \u0026#39;s!^#baseurl=!baseurl=!g\u0026#39; \\  -e \u0026#39;s!//download\\.fedoraproject\\.org/pub!//mirrors.bfsu.edu.cn!g\u0026#39; \\  -e \u0026#39;s!//download\\.example/pub!//mirrors.bfsu.edu.cn!g\u0026#39; \\  -e \u0026#39;s!http://mirrors!https://mirrors!g\u0026#39; \\  -i /etc/yum.repos.d/epel*.repo CentOS 关于多线程 概述 每个正在系统上运行的程序都是一个进程。每个进程包含一到N个线程。进程也可能是整个程序或者是部分程序的动态执行。线程是一组指令的集合，或者是程序的特殊段，它可以在程序里独立执行。也可以把它理解为代码运行的上下文。所以线程基本上是轻量级的进程，它负责在单个程序里执行多任务。通常由操作系统负责多个线程的调度和执行。线程是程序中一个单一的顺序控制流程。在单个程序中同时运行多个线程完成不同的工作,称为多线程。\n线程和进程的区别在于,子进程和父进程有不同的代码和数据空间,而多个线程则共享数据空间,每个线程有自己的执行堆栈和程序计数器为其执行上下文.多线程主要是为了节约CPU时间,发挥利用,根据具体情况而定. 线程的运行中需要使用计算机的内存资源和CPU。\n同步多线程（SMT）是一种在一个CPU 的时钟周期内能够执行来自多个线程的指令的硬件多线程技术。本质上，同步多线程是一种将线程级并行处理（多CPU）转化为指令级并行处理（同一CPU）的方法。 同步多线程是单个物理处理器从多个硬件线程上下文同时分派指令的能力。同步多线程用于在商用环境中及为周期/指令（CPI）计数较高的工作负载创造性能优势。 处理器采用超标量结构，最适于以并行方式读取及运行指令。同步多线程使您可在同一处理器上同时调度两个应用程序，从而利用处理器的超标量结构性质。\n超线程（HT, Hyper-Threading）是英特尔研发的一种技术，于2002年发布。通过此技术，英特尔实现在一个实体CPU中，提供两个逻辑线程。\n其实可以将SMT和HT理解为一个技术。\n Hyper-threading (officially called Hyper- ThreadingTechnology or HT Technology, and abbreviated as HTT orHT) is Intel’s proprietary simultaneous multithreading (SMT) implementation used to improve parallelization ofcomputations (doing multiple tasks at once) performed onx86 microprocessors.\n来自 https://cn.bing.com/search?q=intel+ht\u0026amp;go=%E6%8F%90%E4%BA%A4\u0026amp;qs=ds\u0026amp;form=QBLHCN\n 与多进程的区别  “进程——资源分配的最小单位，线程——程序执行的最小单位”\n 实际应用中基本上都是“进程+线程”的结合方式，千万不要真的陷入一种非此即彼的误区。\n   对比维度 多进程 多线程 总结     数据共享、同步 数据共享复杂，需要用IPC；数据是分开的，同步简单 因为共享进程数据，数据共享简单，但也是因为这个原因导致同步复杂 各有优势   内存、CPU 占用内存多，切换复杂，CPU利用率低 占用内存少，切换简单，CPU利用率高 线程占优   创建销毁、切换 创建销毁、切换复杂，速度慢 创建销毁、切换简单，速度很快 线程占优   编程、调试 编程简单，调试简单 编程复杂，调试复杂 进程占优   可靠性 进程间不会互相影响 一个线程挂掉将导致整个进程挂掉 进程占优   分布式 适应于多核、多机分布式；如果一台机器不够，扩展到多台机器比较简单 适应于多核分布式 进程占优     需要注意：   1）需要频繁创建销毁的优先用线程\n2）需要进行大量计算的优先使用线程\n3）强相关的处理用线程，弱相关的处理用进程\n一般的Server需要完成如下任务：消息收发、消息处理。“消息收发”和“消息处理”就是弱相关的任务，而“消息处理”里面可能又分为“消息解码”、“业务处理”，这两个任务相对来说相关性就要强多了。因此“消息收发”和“消息处理”可以分进程设计，“消息解码”、“业务处理”可以分线程设计。当然这种划分方式不是一成不变的，也可以根据实际情况进行调整。\n4）可能要扩展到多机分布的用进程，多核分布的用线程\n5）都满足需求的情况下，用你最熟悉、最拿手的方式\n来自 https://blog.csdn.net/lishenglong666/article/details/8557215\n 如何使用？ 需要CPU、BIOS、操作系统、应用软件都支持多线程技术才可以。\n支持多线程的CPU Power CPU 支持的SMT技术：\n Simultaneous multithreading (SMT) is a processor technology that allows multiple instruction streams (threads) to run concurrently on the same physical processor, improving overall throughput. To the operating system, each hardware thread is treated as an independent logical processor. Single-threaded (ST) execution mode is also supported.\n来自 https://www.ibm.com/support/knowledgecenter/SSFHY8_6.2/reference/am5gr_f0106.html?view=embed\n Intel CPU 支持的HT技术：\n Intel® Hyper-Threading Technology (Intel® HT Technology) uses processor resources more efficiently, enabling multiple threads to run on each core. As a performance feature, it also increases processor throughput, improving overall performance on threaded software. Intel® HT Technology is available on the latest Intel® Core™ vPro™ processors, the Intel® Core™ processor family, the Intel® Core™ M processor family, and the Intel® Xeon® processor family. By combining one of these Intel® processors and chipsets with an operating system and BIOS supporting Intel® HT Technology.\n来自 https://www.intel.com/content/www/us/en/architecture-and-technology/hyper-threading/hyper-threading-technology.html\n SMT/HT支持情况  Intel CPU : 2 Thread/Core Power9 CPU： 8 Thread /Core Sparc: 8 Thread /Core  RHEL7/CentOS7 \u0026amp; Intel CPU BIOS 中修改SMT/HT 的设置，使用这种方式Enable或者Disable后，将永久生效，需要重启。\nHyper-Threading Technology BIOS Setup Options For Intel® Desktop/Server Boards setup option location is the main menu of the BIOS setup program. • Located on the same menu screen that already had Processor Type, Processor Speed, System Bus Speed, and other related processor fields. • Setup Option Text ○ The field is called Hyper-Threading Technology. • Setup Option Values ○ The setup option values are Enabled and Disabled. • Setup Option Help Text 来自 \u0026lt;https://www.intel.com/content/www/us/en/support/articles/000007645/boards-and-kits/desktop-boards.html\u0026gt; RHEL/CentOS操作系统中查看多线程情况：（更多信息：https://access.redhat.com/solutions/rhel-smt）\n# lscpu | grep -e Socket -e Core -e Thread Thread(s) per core: 2 # 线程数 Core(s) per socket: 6 # core 数量 Socket(s): 2 或者\n# grep -H . /sys/devices/system/cpu/cpu*/topology/thread_siblings_list | sort -n -t ':' -k 2 -u # 显示 /sys/devices/system/cpu/cpu0/topology/thread_siblings_list:0 # 表示HT关闭 # 显示 /sys/devices/system/cpu/cpu0/topology/thread_siblings_list:0-1 # 表示 HT 启用 操作系统层关闭多线程有几种办法：\n 方法一：使用nosmt启动参数，需要新的x86 CPU，需要重启  # grubby --args=nosmt --update-kernel=DEFAULT # grub2-mkconfig -o /boot/grub/grub.conf # 创建新的grub.conf # reboot #重启  方法二：临时关闭，重启后失效  # echo off \u0026gt; /sys/devices/system/cpu/smt/control /sys/devices/system/cpu/smt/control: This file allows to read out the SMT control state and provides the ability to disable or (re)enable SMT. The possible states are: ============== =================================================== on SMT is supported by the CPU and enabled. All logical CPUs can be onlined and offlined without restrictions. off SMT is supported by the CPU and disabled. Only the so called primary SMT threads can be onlined and offlined without restrictions. An attempt to online a non-primary sibling is rejected forceoff Same as 'off' but the state cannot be controlled. Attempts to write to the control file are rejected. notsupported The processor does not support SMT. It's therefore not affected by the SMT implications of L1TF. Attempts to write to the control file are rejected. ============== =================================================== The possible states which can be written into this file to control SMT state are: - on - off - forceoff /sys/devices/system/cpu/smt/active: This file reports whether SMT is enabled and active, i.e. if on any physical core two or more sibling threads are online. AIX \u0026amp; Power Power9 CPU默认支持8线程，使用smtctl命令可以查看和修改 smt级别。更多内容查看https://www.ibm.com/support/knowledgecenter/ssw_aix_72/com.ibm.aix.cmds5/smtctl.htm\n 查看 SMT level  smtctl  临时修改 SMT level, # 可以是 1, 2, 4 or 8，重启后将恢复原来的smt level  smtctl -t 2 -w now  修改 SMT level永久生效，# 可以是 1, 2, 4 or 8，完成后需要使用bosboot创建启动设备   smtctl -t 4 -w boot bosboot -a # Creates complete boot image and device. RHEL7 \u0026amp; Power OpenPower CPU 默认支持4线程，安装RHEL后可以使用开源的工具 ppc64_cpu进行查看和修改多线程（更多查看 https://github.com/ibm-power-utilities/powerpc-utils）。\nppc64_cpu --------- This allows users to set the smt state, smt-snooze-delay and other settings on ppc64 processors. It also allows users to control the number of processor cores which are online (not in the sleep state). 来自 \u0026lt;https://github.com/ibm-power-utilities/powerpc-utils\u0026gt; 1，查看 SMT level\nppc64_cpu --smt 2，修改 SMT 级别， # is 1, 2, 4 or on\nppc64_cpu --smt=# 3， 关闭 smt支持\nppc64_cpu --smt=off 其他 oracle数据库 Oracle Database 在12c之前windows平台下支持多线程，Unix和Linux只支持多进程模式。在Oracle Database 12c中，Oracle引入了多线程模式，允许在Windows平台之外的Unix、Linux系统使用多线程模式，结合多进程与多线程模式，Oracle可以改进进程管理与性能。\n通过设置初始化参数threaded_execution，可以启用或关闭多线程模式，该参数缺省值为False，设置为TRUE启用12c的这个新特性：\nSQL\u0026gt; show parameter threaded_exec NAME TYPE VALUE --- threaded_execution boolean FALSE SQL\u0026gt; alter system set threaded_execution=true scope=spfile; System altered. 该参数重新启动数据库后生效，但是注意，多线程模式，不支持操作系统认证，不能直接启动数据库，需要提供SYS的密码认证后方能启动数据库：\nSQL\u0026gt; shutdown immediate; SQL\u0026gt; startup ORA-01017: invalid username/password; logon denied # 需要通过用户名和密码登录数据库。 用ps -ef 检查一下进程/线程：\n[oracle@enmocoredb dbs]$ ps -ef|grep ora_ oracle 27404 1 0 17:00 ? 00:00:00 ora_pmon_core oracle 27406 1 0 17:00 ? 00:00:00 ora_psp0_core oracle 27408 1 3 17:00 ? 00:00:05 ora_vktm_core oracle 27412 1 0 17:00 ? 00:00:00 ora_u004_core oracle 27418 1 0 17:00 ? 00:00:00 ora_u005_core oracle 27424 1 0 17:00 ? 00:00:00 ora_dbw0_core 其中U\u0026lt;NNN\u0026gt;进程是共享线程的\u0026quot;容器进程\u0026quot;，每个进程可以容纳100个线程。 来自 https://www.eygle.com/archives/2013/07/oracle_database_12c_multithreaded_model.html 连接热点   打开WIFI\nifconfig interface up   查看所有可用的无线网络信号\niw wlp2s0 scan | grep SSID   连接无线网\nwpa_supplicant -B -i wlp2s0 -c \u0026lt;(wpa_passphrase \u0026#34;SSID\u0026#34; \u0026#34;passwd\u0026#34;)   分配IP地址\ndhclient interface   查看无线网卡地址信息，有ip地址表示网络连接成功\nifconfig interface   PPPOE （ADSL）拨号上网   安装拨号软件\ndnf install rp-pppoe* ppp*   设定\npppoe-setup   拨号上网\npppoe-stoppppoe-start   安装中文输入法   安装 fcitx\ndnf install fcitx-im fcitx-configtool fcitx-googlepinyin   配置\n$ nano ~/.xprofile # or ~/.bashrc export GTK_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=\u0026#34;@im=fcitx\u0026#34;   fcitx 没图标：重装fcitx，在fcitx配置里关掉Kimpanel\n  关闭触摸板 $ dnf install xorg-x11-apps synclient TouchpadOff=1 # 关闭 synclient TouchpadOff=0 # 开启 用 MTP 挂载手机   安装jmtpfs\ndnf install jmtpfs   查看手机 “busnum”和“devnum”\njmptfs -l   建立挂载点\nmkdir /media/dir   挂载手机\njmtpfs -device=busnum,devnum /media/dir/   查找依赖 $ yum whatprovide package $ dnf provides package 默认字体 CentOS 默认字体目录 /lib/kbd/consolefonts\n纯命令行是不能使用系统之外的字体的。\nCentOS Minimal + Xfce base 源与 epel 源，使用用阿里镜像: https://developer.aliyun.com/mirror/\n  安装Xfce4，先安装 Xfce 可以保证不安装多余的包\ndnf group listdnf groupinstall Xfce   安装 X Window system\ndnf groupinstall \u0026#34;X Window system\u0026#34;   验证\nsystemctl isolate graphical.target   设置\n# 设置成命令模式systemctl set-default multi-user.target # 设置成图形模式systemctl set-default graphical.target    安装中文字体和中文输入法楷体字体\ndnf install cjkuni-ukai-fonts   输入法需要安装如下包：\n ibus， 这个包里有ibus-daemon这个平台服务器程序和ibus这个配置助手。 ibus-libpinyin， 这个是ibus平台下具体的拼音输入法。 im-chooser,这个是输入法平台选择助手程序。 执行im-chooser，选择输入法平台和输入法。重新登录系统。    xfce 主题\n 网站：xfce-look.org 主题目录： /usr/share/themes 或 ~/.themes 图标鼠标目录： /usr/share/icons 或 ~/.icons 壁纸： /usr/share/background , /usr/share/wallpapers Plank    SELinux SELinux 初探 從進入了 CentOS 5.x 之後的 CentOS 版本中 (當然包括 CentOS 7)，SELinux 已經是個非常完備的核心模組了！尤其 CentOS 提供了很多管理 SELinux 的指令與機制， 因此在整體架構上面是單純且容易操作管理的！所以，在沒有自行開發網路服務軟體以及使用其他第三方協力軟體的情況下， 也就是全部使用 CentOS 官方提供的軟體來使用我們伺服器的情況下，建議大家不要關閉 SELinux 了喔！ 讓我們來仔細的玩玩這傢伙吧！\n什麼是 SELinux 什麼是 SELinux 呢？其實他是『 Security Enhanced Linux 』的縮寫，字面上的意義就是安全強化的 Linux 之意！那麼所謂的『安全強化』是強化哪個部分？ 是網路資安還是權限管理？底下就讓我們來談談吧！\n當初設計的目標：避免資源的誤用 SELinux 是由美國國家安全局 (NSA) 開發的，當初開發這玩意兒的目的是因為很多企業界發現， 通常系統出現問題的原因大部分都在於『內部員工的資源誤用』所導致的，實際由外部發動的攻擊反而沒有這麼嚴重。 那麼什麼是『員工資源誤用』呢？舉例來說，如果有個不是很懂系統的系統管理員為了自己設定的方便，將網頁所在目錄 /var/www/html/ 的權限設定為 drwxrwxrwx 時，你覺得會有什麼事情發生？\n現在我們知道所有的系統資源都是透過程序來進行存取的，那麼 /var/www/html/ 如果設定為 777 ， 代表所有程序均可對該目錄存取，萬一你真的有啟動 WWW 伺服器軟體，那麼該軟體所觸發的程序將可以寫入該目錄， 而該程序卻是對整個 Internet 提供服務的！只要有心人接觸到這支程序，而且該程序剛好又有提供使用者進行寫入的功能， 那麼外部的人很可能就會對你的系統寫入些莫名其妙的東西！那可真是不得了！一個小小的 777 問題可是大大的！\n為了控管這方面的權限與程序的問題，所以美國國家安全局就著手處理作業系統這方面的控管。 由於 Linux 是自由軟體，程式碼都是公開的，因此她們便使用 Linux 來作為研究的目標， 最後更將研究的結果整合到 Linux 核心裡面去，那就是 SELinux 啦！所以說， SELinux 是整合到核心的一個模組喔！ 更多的 SELinux 相關說明可以參考：http://www.nsa.gov/research/selinux/\n這也就是說：其實 SELinux 是在進行程序、檔案等細部權限設定依據的一個核心模組！ 由於啟動網路服務的也是程序，因此剛好也能夠控制網路服務能否存取系統資源的一道關卡！ 所以，在講到 SELinux 對系統的存取控制之前，我們得先來回顧一下之前談到的系統檔案權限與使用者之間的關係。 因為先談完這個你才會知道為何需要 SELinux 的啦！\n傳統的檔案權限與帳號關係：自主式存取控制, DAC 我們通过Linux 帳號管理與 ACL 權限設定的內容，知道系統的帳號主要分為系統管理員 (root) 與一般用戶，而這兩種身份能否使用系統上面的檔案資源則與 rwx 的權限設定有關。 不過你要注意的是，各種權限設定對 root 是無效的。因此，當某個程序想要對檔案進行存取時， 系統就會根據該程序的擁有者/群組，並比對檔案的權限，若通過權限檢查，就可以存取該檔案了。\n這種存取檔案系統的方式被稱為『自主式存取控制 (Discretionary Access Control, DAC)』，基本上，就是依據程序的擁有者與檔案資源的 rwx 權限來決定有無存取的能力。 不過這種 DAC 的存取控制有幾個困擾，那就是：\n root 具有最高的權限：如果不小心某支程序被有心人士取得， 且該程序屬於 root 的權限，那麼這支程序就可以在系統上進行任何資源的存取！真是要命！ 使用者可以取得程序來變更檔案資源的存取權限：如果你不小心將某個目錄的權限設定為 777 ，由於對任何人的權限會變成 rwx ，因此該目錄就會被任何人所任意存取！  這些問題是非常嚴重的！尤其是當你的系統是被某些漫不經心的系統管理員所掌控時！他們甚至覺得目錄權限調為 777 也沒有什麼了不起的危險哩\u0026hellip;\n以政策規則訂定特定程序讀取特定檔案：委任式存取控制, MAC 現在我們知道 DAC 的困擾就是當使用者取得程序後，他可以藉由這支程序與自己預設的權限來處理他自己的檔案資源。 萬一這個使用者對 Linux 系統不熟，那就很可能會有資源誤用的問題產生。為了避免 DAC 容易發生的問題，因此 SELinux 導入了委任式存取控制 (Mandatory Access Control, MAC) 的方法！\n委任式存取控制 (MAC) 有趣啦！他可以針對特定的程序與特定的檔案資源來進行權限的控管！ 也就是說，即使你是 root ，那麼在使用不同的程序時，你所能取得的權限並不一定是 root ， 而得要看當時該程序的設定而定。如此一來，我們針對控制的『主體』變成了『程序』而不是使用者喔！ 此外，這個主體程序也不能任意使用系統檔案資源，因為每個檔案資源也有針對該主體程序設定可取用的權限！ 如此一來，控制項目就細的多了！但整個系統程序那麼多、檔案那麼多，一項一項控制可就沒完沒了！ 所以 SELinux 也提供一些預設的政策 (Policy) ，並在該政策內提供多個規則 (rule) ，讓你可以選擇是否啟用該控制規則！\n在委任式存取控制的設定下，我們的程序能夠活動的空間就變小了！舉例來說， WWW 伺服器軟體的達成程序為 httpd 這支程式， 而預設情況下， httpd 僅能在 /var/www/ 這個目錄底下存取檔案，如果 httpd 這個程序想要到其他目錄去存取資料時， 除了規則設定要開放外，目標目錄也得要設定成 httpd 可讀取的模式 (type) 才行喔！限制非常多！ 所以，即使不小心 httpd 被 cracker 取得了控制權，他也無權瀏覽 /etc/shadow 等重要的設定檔喔！\n簡單的來說，針對 Apache 這個 WWW 網路服務使用 DAC 或 MAC 的結果來說，兩者間的關係可以使用下圖來說明。 底下這個圖示取自 Red Hat 訓練教材，真的是很不錯～所以被鳥哥借用來說明一下！\n左圖是沒有 SELinux 的 DAC 存取結果，apache 這隻 root 所主導的程序，可以在這三個目錄內作任何檔案的新建與修改～ 相當麻煩～右邊則是加上 SELinux 的 MAC 管理的結果，SELinux 僅會針對 Apache 這個『 process 』放行部份的目錄， 其他的非正規目錄就不會放行給 Apache 使用！因此不管你是誰，就是不能穿透 MAC 的框框！這樣有比較了解乎？\nSELinux 的運作模式 再次的重複說明一下，SELinux 是透過 MAC 的方式來控管程序，他控制的主體是程序， 而目標則是該程序能否讀取的『檔案資源』！所以先來說明一下這些咚咚的相關性啦！\n  主體 (Subject)： SELinux 主要想要管理的就是程序，因此你可以將『主體』跟本章談到的 process 劃上等號；\n  目標 (Object)： 主體程序能否存取的『目標資源』一般就是檔案系統。因此這個目標項目可以等檔案系統劃上等號；\n  政策 (Policy)：\n由於程序與檔案數量龐大，因此 SELinux 會依據某些服務來制訂基本的存取安全性政策。這些政策內還會有詳細的規則 (rule) 來指定不同的服務開放某些資源的存取與否。在目前的 CentOS 7.x 裡面僅有提供三個主要的政策，分別是：\n targeted：針對網路服務限制較多，針對本機限制較少，是預設的政策； minimum：由 target 修訂而來，僅針對選擇的程序來保護！ mls：完整的 SELinux 限制，限制方面較為嚴格。  建議使用預設的 targeted 政策即可。\n  安全性本文 (security context)： 我們剛剛談到了主體、目標與政策面，但是主體能不能存取目標除了政策指定之外，主體與目標的安全性本文必須一致才能夠順利存取。 這個安全性本文 (security context) 有點類似檔案系統的 rwx 啦！安全性本文的內容與設定是非常重要的！ 如果設定錯誤，你的某些服務(主體程序)就無法存取檔案系統(目標資源)，當然就會一直出現『權限不符』的錯誤訊息了！\n  由於 SELinux 重點在保護程序讀取檔案系統的權限，因此我們將上述的幾個說明搭配起來，繪製成底下的流程圖，比較好理解：\n上圖的重點在『主體』如何取得『目標』的資源存取權限！ 由上圖我們可以發現，(1)主體程序必須要通過 SELinux 政策內的規則放行後，就可以與目標資源進行安全性本文的比對， (2)若比對失敗則無法存取目標，若比對成功則可以開始存取目標。問題是，最終能否存取目標還是與檔案系統的 rwx 權限設定有關喔！如此一來，加入了 SELinux 之後，出現權限不符的情況時，你就得要一步一步的分析可能的問題了！\n安全性本文 (Security Context) CentOS 7.x 的 target 政策已經幫我們制訂好非常多的規則了，因此你只要知道如何開啟/關閉某項規則的放行與否即可。 那個安全性本文比較麻煩！因為你可能需要自行設定檔案的安全性本文呢！為何需要自行設定啊？ 舉例來說，你不也常常進行檔案的 rwx 的重新設定嗎？這個安全性本文你就將他想成 SELinux 內必備的 rwx 就是了！這樣比較好理解啦。\n安全性本文存在於主體程序中與目標檔案資源中。程序在記憶體內，所以安全性本文可以存入是沒問題。 那檔案的安全性本文是記錄在哪裡呢？事實上，安全性本文是放置到檔案的 inode 內的，因此主體程序想要讀取目標檔案資源時，同樣需要讀取 inode ， 在 inode 內就可以比對安全性本文以及 rwx 等權限值是否正確，而給予適當的讀取權限依據。\n那麼安全性本文到底是什麼樣的存在呢？我們先來看看 /root 底下的檔案的安全性本文好了。 觀察安全性本文可使用『 ls -Z 』去觀察如下：(注意：你必須已經啟動了 SELinux 才行！若尚未啟動，這部份請稍微看過一遍即可。底下會介紹如何啟動 SELinux 喔！)\n# 先來觀察一下 root 家目錄底下的『檔案的 SELinux 相關資訊』 [root@study ~]# ls -Z -rw-------. root root system_u:object_r:admin_home_t:s0 anaconda-ks.cfg -rw-r--r--. root root system_u:object_r:admin_home_t:s0 initial-setup-ks.cfg -rw-r--r--. root root unconfined_u:object_r:admin_home_t:s0 regular_express.txt # 上述特殊字體的部分，就是安全性本文的內容！鳥哥僅列出數個預設的檔案而已， # 本書學習過程中所寫下的檔案則沒有列在上頭喔！ 如上所示，安全性本文主要用冒號分為三個欄位，這三個欄位的意義為：\nIdentify:role:type 身份識別:角色:類型 這三個欄位的意義仔細的說明一下吧：\n  身份識別 (Identify)：\n相當於帳號方面的身份識別！主要的身份識別常見有底下幾種常見的類型：\n  unconfined_u：不受限的用戶，也就是說，該檔案來自於不受限的程序所產生的！一般來說，我們使用可登入帳號來取得 bash 之後， 預設的 bash 環境是不受 SELinux 管制的～因為 bash 並不是什麼特別的網路服務！因此，在這個不受 SELinux 所限制的 bash 程序所產生的檔案， 其身份識別大多就是 unconfined_u 這個『不受限』用戶囉！\n  system_u：系統用戶，大部分就是系統自己產生的檔案囉！\n  基本上，如果是系統或軟體本身所提供的檔案，大多就是 system_u 這個身份名稱，而如果是我們用戶透過 bash 自己建立的檔案，大多則是不受限的 unconfined_u 身份～如果是網路服務所產生的檔案，或者是系統服務運作過程產生的檔案，則大部分的識別就會是 system_u 囉！\n因為鳥哥這邊教大家使用文字界面來產生許多的資料，因此你看上面的三個檔案中，系統安裝主動產生的 anaconda-ks.cfs 及 initial-setup-ks.cfg 就會是 system_u，而我們自己從網路上面抓下來的 regular_express.txt 就會是 unconfined_u 這個識別啊！\n  角色 (Role)：\n透過角色欄位，我們可以知道這個資料是屬於程序、檔案資源還是代表使用者。一般的角色有：\n  object_r：代表的是檔案或目錄等檔案資源，這應該是最常見的囉；\n  system_r：代表的就是程序啦！不過，一般使用者也會被指定成為 system_r 喔！\n  你也會發現角色的欄位最後面使用『 _r 』來結尾！因為是 role 的意思嘛！\n  類型 (Type) (最重要！)：\n在預設的 targeted 政策中， Identify 與 Role 欄位基本上是不重要的！重要的在於這個類型 (type) 欄位！ 基本上，一個主體程序能不能讀取到這個檔案資源，與類型欄位有關！而類型欄位在檔案與程序的定義不太相同，分別是：\n  type：在檔案資源 (Object) 上面稱為類型 (Type)；\n  domain：在主體程序 (Subject) 則稱為領域 (domain) 了！\n  domain 需要與 type 搭配，則該程序才能夠順利的讀取檔案資源啦！\n  程序與檔案 SELinux type 欄位的相關性 那麼這三個欄位如何利用呢？首先我們來瞧瞧主體程序在這三個欄位的意義為何！透過身份識別與角色欄位的定義， 我們可以約略知道某個程序所代表的意義喔！先來動手瞧一瞧目前系統中的程序在 SELinux 底下的安全本文為何？\n# 再來觀察一下系統『程序的 SELinux 相關資訊』 [root@study ~]# ps -eZ LABEL PID TTY TIME CMD system_u:system_r:init_t:s0 1 ? 00:00:03 systemd system_u:system_r:kernel_t:s0 2 ? 00:00:00 kthreadd system_u:system_r:kernel_t:s0 3 ? 00:00:00 ksoftirqd/0 .....(中間省略)..... unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 31513 ? 00:00:00 sshd unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 31535 pts/0 00:00:00 bash # 基本上程序主要就分為兩大類，一種是系統有受限的 system_u:system_r，另一種則可能是用戶自己的， # 比較不受限的程序 (通常是本機用戶自己執行的程式)，亦即是 unconfined_u:unconfined_r 這兩種！ 基本上，這些對應資料在 targeted 政策下的對應如下：\n   身份識別 角色 該對應在 targeted 的意義     unconfined_u unconfined_r 一般可登入使用者的程序囉！比較沒有受限的程序之意！大多數都是用戶已經順利登入系統 (不論是網路還是本機登入來取得可用的 shell) 後， 所用來操作系統的程序！如 bash, X window 相關軟體等。   system_u system_r 由於為系統帳號，因此是非交談式的系統運作程序，大多數的系統程序均是這種類型！    但就如上所述，在預設的 target 政策下，其實最重要的欄位是類型欄位 (type)， 主體與目標之間是否具有可以讀寫的權限，與程序的 domain 及檔案的 type 有關！這兩者的關係我們可以使用 crond 以及他的設定檔來說明！ 亦即是 /usr/sbin/crond, /etc/crontab, /etc/cron.d 等檔案來說明。 首先，看看這幾個咚咚的安全性本文內容先：\n# 1. 先看看 crond 這個『程序』的安全本文內容： [root@study ~]# ps -eZ | grep cron system_u:system_r:crond_t:s0-s0:c0.c1023 1338 ? 00:00:01 crond system_u:system_r:crond_t:s0-s0:c0.c1023 1340 ? 00:00:00 atd # 這個安全本文的類型名稱為 crond_t 格式！ # 2. 再來瞧瞧執行檔、設定檔等等的安全本文內容為何！ [root@study ~]# ll -Zd /usr/sbin/crond /etc/crontab /etc/cron.d drwxr-xr-x. root root system_u:object_r:system_cron_spool_t:s0 /etc/cron.d -rw-r--r--. root root system_u:object_r:system_cron_spool_t:s0 /etc/crontab -rwxr-xr-x. root root system_u:object_r:crond_exec_t:s0 /usr/sbin/crond 當我們執行 /usr/sbin/crond 之後，這個程式變成的程序的 domain 類型會是 crond_t 這一個～而這個 crond_t 能夠讀取的設定檔則為 system_cron_spool_t 這種的類型。因此不論 /etc/crontab, /etc/cron.d 以及 /var/spool/cron 都會是相關的 SELinux 類型 (/var/spool/cron 為 user_cron_spool_t)。 文字看起來不太容易了解，我們使用圖示來說明這幾個東西的關係！\n上圖的意義我們可以這樣看的：\n 首先，我們觸發一個可執行的目標檔案，那就是具有 crond_exec_t 這個類型的 /usr/sbin/crond 檔案； 該檔案的類型會讓這個檔案所造成的主體程序 (Subject) 具有 crond 這個領域 (domain)， 我們的政策針對這個領域已經制定了許多規則，其中包括這個領域可以讀取的目標資源類型； 由於 crond domain 被設定為可以讀取 system_cron_spool_t 這個類型的目標檔案 (Object)， 因此你的設定檔放到 /etc/cron.d/ 目錄下，就能夠被 crond 那支程序所讀取了； 但最終能不能讀到正確的資料，還得要看 rwx 是否符合 Linux 權限的規範！  上述的流程告訴我們幾個重點，第一個是政策內需要制訂詳細的 domain/type 相關性；第二個是若檔案的 type 設定錯誤， 那麼即使權限設定為 rwx 全開的 777 ，該主體程序也無法讀取目標檔案資源的啦！不過如此一來， 也就可以避免使用者將他的家目錄設定為 777 時所造成的權限困擾。\n真的是這樣嗎？沒關係～讓我們來做個測試練習吧！就是，萬一你的 crond 設定檔的 SELinux 並不是 system_cron_spool_t 時， 該設定檔真的可以順利的被讀取運作嗎？來看看底下的範例！\n# 1. 先假設你因為不熟的緣故，因此是在『root 家目錄』建立一個如下的 cron 設定： [root@study ~]# vim checktime 10 * * * * root sleep 60s # 2. 檢查後才發現檔案放錯目錄了，又不想要保留副本，因此使用 mv 移動到正確目錄： [root@study ~]# mv checktime /etc/cron.d [root@study ~]# ll /etc/cron.d/checktime -rw-r--r--. 1 root root 27 Aug 7 18:41 /etc/cron.d/checktime # 仔細看喔，權限是 644 ，確定沒有問題！任何程序都能夠讀取喔！ # 3. 強制重新啟動 crond ，然後偷看一下登錄檔，看看有沒有問題發生！ [root@study ~]# systemctl restart crond [root@study ~]# tail /var/log/cron Aug 7 18:46:01 study crond[28174]: ((null)) Unauthorized SELinux context=system_u:system_r: system_cronjob_t:s0-s0:c0.c1023 file_context=unconfined_u:object_r:admin_home_t:s0 (/etc/cron.d/checktime) Aug 7 18:46:01 study crond[28174]: (root) FAILED (loading cron table) # 上面的意思是，有錯誤！因為原本的安全本文與檔案的實際安全本文無法搭配的緣故！ 您瞧瞧～從上面的測試案例來看，我們的設定檔確實沒有辦法被 crond 這個服務所讀取喔！而原因在登錄檔內就有說明， 主要就是來自 SELinux 安全本文 (context) type 的不同所致喔！沒辦法讀就沒辦法讀，先放著～後面再來學怎麼處理這問題吧！\nSELinux 三種模式的啟動、關閉與觀察 並非所有的 Linux distributions 都支援 SELinux 的，所以你必須要先觀察一下你的系統版本為何！ 鳥哥這裡介紹的 CentOS 7.x 本身就有支援 SELinux 啦！所以你不需要自行編譯 SELinux 到你的 Linux 核心中！ 目前 SELinux 依據啟動與否，共有三種模式，分別如下：\n enforcing：強制模式，代表 SELinux 運作中，且已經正確的開始限制 domain/type 了； permissive：寬容模式：代表 SELinux 運作中，不過僅會有警告訊息並不會實際限制 domain/type 的存取。這種模式可以運來作為 SELinux 的 debug 之用； disabled：關閉，SELinux 並沒有實際運作。  我們前面不是談過主體程序需要經過政策規則、安全本文比對之後，加上 rwx 的權限規範， 若一切合理才會讓程序順利的讀取檔案嗎？那麼這個 SELinux 的三種模式與上面談到的政策規則、安全本文的關係為何呢？我們還是使用圖示加上流程來讓大家理解一下：\n就如上圖所示，首先，你得要知道，並不是所有的程序都會被 SELinux 所管制，因此最左邊會出現一個所謂的『有受限的程序主體』！那如何觀察有沒有受限 (confined )呢？ 很簡單啊！就透過 ps -eZ 去擷取！舉例來說，我們來找一找 crond 與 bash 這兩隻程序是否有被限制吧？\n[root@study ~]# ps -eZ | grep -E \u0026#39;cron|bash\u0026#39; system_u:system_r:crond_t:s0-s0:c0.c1023 1340 ? 00:00:00 atd unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 13888 tty2 00:00:00 bash unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 28054 pts/0 00:00:00 bash unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 28094 pts/0 00:00:00 bash system_u:system_r:crond_t:s0-s0:c0.c1023 28174 ? 00:00:00 crond 如前所述，因為在目前 target 這個政策底下，只有第三個類型 (type) 欄位會有影響，因此我們上表僅列出第三個欄位的資料而已。 我們可以看到， crond 確實是有受限的主體程序，而 bash 因為是本機程序，因此就是不受限 (unconfined_t) 的類型！也就是說， bash 是不需要經過上圖的流程，而是直接去判斷 rwx 而已～。\n了解了受限的主體程序的意義之後，再來了解一下，三種模式的運作吧！首先，如果是 Disabled 的模式，那麼 SELinux 將不會運作，當然受限的程序也不會經過 SELinux ， 也是直接去判斷 rwx 而已。那如果是寬容 (permissive) 模式呢？這種模式也是不會將主體程序抵擋 (所以箭頭是可以直接穿透的喔！)，不過萬一沒有通過政策規則，或者是安全本文的比對時， 那麼該讀寫動作將會被紀錄起來 (log)，可作為未來檢查問題的判斷依據。\n至於最終那個 Enforcing 模式，就是實際將受限主體進入規則比對、安全本文比對的流程，若失敗，就直接抵擋主體程序的讀寫行為，並且將他記錄下來。 如果通通沒問題，這才進入到 rwx 權限的判斷喔！這樣可以理解三種模式的行為了嗎？\n那你怎麼知道目前的 SELinux 模式呢？就透過 getenforce 吧！\n[root@study ~]# getenforce Enforcing \u0026lt;==諾！就顯示出目前的模式為 Enforcing 囉！ 另外，我們又如何知道 SELinux 的政策 (Policy) 為何呢？這時可以使用 sestatus 來觀察：\n[root@study ~]# sestatus [-vb] 選項與參數： -v ：檢查列於 /etc/sestatus.conf 內的檔案與程序的安全性本文內容； -b ：將目前政策的規則布林值列出，亦即某些規則 (rule) 是否要啟動 (0/1) 之意； 範例一：列出目前的 SELinux 使用哪個政策 (Policy)？ [root@study ~]# sestatus SELinux status: enabled \u0026lt;==是否啟動 SELinux SELinuxfs mount: /sys/fs/selinux \u0026lt;==SELinux 的相關檔案資料掛載點 SELinux root directory: /etc/selinux \u0026lt;==SELinux 的根目錄所在 Loaded policy name: targeted \u0026lt;==目前的政策為何？ Current mode: enforcing \u0026lt;==目前的模式 Mode from config file: enforcing \u0026lt;==目前設定檔內規範的 SELinux 模式 Policy MLS status: enabled \u0026lt;==是否含有 MLS 的模式機制 Policy deny_unknown status: allowed \u0026lt;==是否預設抵擋未知的主體程序 Max kernel policy version: 28 如上所示，目前是啟動的，而且是 Enforcing 模式，而由設定檔查詢得知亦為 Enforcing 模式。 此外，目前的預設政策為 targeted 這一個。你應該要有疑問的是， SELinux 的設定檔是哪個檔案啊？ 其實就是 /etc/selinux/config 這個檔案喔！我們來看看內容：\n[root@study ~]# vim /etc/selinux/config SELINUX=enforcing \u0026lt;==調整 enforcing|disabled|permissive SELINUXTYPE=targeted \u0026lt;==目前僅有 targeted, mls, minimum 三種政策 若有需要修改預設政策的話，就直接改 SELINUX=enforcing 那一行即可喔！\nSELinux 的啟動與關閉 上面是預設的政策與啟動的模式！你要注意的是，如果改變了政策則需要重新開機；如果由 enforcing 或 permissive 改成 disabled ，或由 disabled 改成其他兩個，那也必須要重新開機。這是因為 SELinux 是整合到核心裡面去的， 你只可以在 SELinux 運作下切換成為強制 (enforcing) 或寬容 (permissive) 模式，不能夠直接關閉 SELinux 的！ 如果剛剛你發現 getenforce 出現 disabled 時，請到上述檔案修改成為 enforcing 然後重新開機吧！\n不過你要注意的是，如果從 disable 轉到啟動 SELinux 的模式時， 由於系統必須要針對檔案寫入安全性本文的資訊，因此開機過程會花費不少時間在等待重新寫入 SELinux 安全性本文 (有時也稱為 SELinux Label) ，而且在寫完之後還得要再次的重新開機一次喔！你必須要等待粉長一段時間！ 等到下次開機成功後，再使用 getenforce 或 sestatus 來觀察看看有否成功的啟動到 Enforcing 的模式囉！\n如果你已經在 Enforcing 的模式，但是可能由於一些設定的問題導致 SELinux 讓某些服務無法正常的運作， 此時你可以將 Enforcing 的模式改為寬容 (permissive) 的模式，讓 SELinux 只會警告無法順利連線的訊息， 而不是直接抵擋主體程序的讀取權限。讓 SELinux 模式在 enforcing 與 permissive 之間切換的方法為：\n[root@study ~]# setenforce [0|1] 選項與參數： 0 ：轉成 permissive 寬容模式； 1 ：轉成 Enforcing 強制模式 範例一：將 SELinux 在 Enforcing 與 permissive 之間切換與觀察 [root@study ~]# setenforce 0 [root@study ~]# getenforce Permissive [root@study ~]# setenforce 1 [root@study ~]# getenforce Enforcing 不過請注意， setenforce 無法在 Disabled 的模式底下進行模式的切換喔！\nTips：在某些特殊的情況底下，你從 Disabled 切換成 Enforcing 之後，竟然有一堆服務無法順利啟動，都會跟你說在 /lib/xxx 裡面的資料沒有權限讀取，所以啟動失敗。這大多是由於在重新寫入 SELinux type (Relabel) 出錯之故，使用 Permissive 就沒有這個錯誤。那如何處理呢？最簡單的方法就是在 Permissive 的狀態下，使用『 restorecon -Rv / 』重新還原所有 SELinux 的類型，就能夠處理這個錯誤！\nSELinux 政策內的規則管理 我們知道 SELinux 的三種模式是會影響到主體程序的放行與否。 如果是進入 Enforcing 模式，那麼接著下來會影響到主體程序的，當然就是第二關：『 target 政策內的各項規則 (rules) 』了！ 好了，那麼我們怎麼知道目前這個政策裡面到底有多少會影響到主體程序的規則呢？很簡單，就透過 getsebool 來瞧一瞧即可。\n SELinux 各個規則的布林值查詢 getsebool  如果想要查詢系統上面全部規則的啟動與否 (on/off，亦即布林值)，很簡單的透過 sestatus -b 或 getsebool -a 均可！\n[root@study ~]# getsebool [-a] [規則的名稱] 選項與參數： -a ：列出目前系統上面的所有 SELinux 規則的布林值為開啟或關閉值 範例一：查詢本系統內所有的布林值設定狀況 [root@study ~]# getsebool -a abrt_anon_write --\u0026gt; off abrt_handle_event --\u0026gt; off ....(中間省略).... cron_can_relabel --\u0026gt; off # 這個跟 cornd 比較有關！ cron_userdomain_transition --\u0026gt; on ....(中間省略).... httpd_enable_homedirs --\u0026gt; off # 這當然就是跟網頁，亦即 http 有關的囉！ ....(底下省略).... # 這麼多的 SELinux 規則喔！每個規則後面都列出現在是允許放行還是不許放行的布林值喔！  SELinux 各個規則規範的主體程序能夠讀取的檔案 SELinux type 查詢 seinfo, sesearch  我們現在知道有這麼多的 SELinux 規則，但是每個規則內到底是在限制什麼東西？如果你想要知道的話，那就得要使用 seinfo 等工具！ 這些工具並沒有在我們安裝時就安裝了，因此請拿出原版光碟，放到光碟機，鳥哥假設你將原版光碟掛載到 /mnt 底下，那麼接下來這麼作， 先安裝好我們所需要的軟體才行！\n[root@study ~]# yum install /mnt/Packages/setools-console-* 很快的安裝完畢之後，我們就可以來使用 seinfo, sesearch 等指令了！\n[root@study ~]# seinfo [-trub] 選項與參數： --all ：列出 SELinux 的狀態、規則布林值、身份識別、角色、類別等所有資訊 -u ：列出 SELinux 的所有身份識別 (user) 種類 -r ：列出 SELinux 的所有角色 (role) 種類 -t ：列出 SELinux 的所有類別 (type) 種類 -b ：列出所有規則的種類 (布林值) 範例一：列出 SELinux 在此政策下的統計狀態 [root@study ~]# seinfo Statistics for policy file: /sys/fs/selinux/policy Policy Version \u0026amp; Type: v.28 (binary, mls) Classes: 83 Permissions: 255 Sensitivities: 1 Categories: 1024 Types: 4620 Attributes: 357 Users: 8 Roles: 14 Booleans: 295 Cond. Expr.: 346 Allow: 102249 Neverallow: 0 Auditallow: 160 Dontaudit: 8413 Type_trans: 16863 Type_change: 74 Type_member: 35 Role allow: 30 Role_trans: 412 Range_trans: 5439 ....(底下省略).... # 從上面我們可以看到這個政策是 targeted ，此政策的安全本文類別有 4620 個； # 而各種 SELinux 的規則 (Booleans) 共制訂了 295 條！ 我們前面簡單的談到了幾個身份識別 (user) 以及角色 (role) 而已，如果你想要查詢目前所有的身份識別與角色，就使用『 seinfo -u 』及『 seinfo -r 』就可以知道了！至於簡單的統計資料，就直接輸入 seinfo 即可！但是上面還是沒有談到規則相關的東西耶～ 沒關係～一個一個來～我們在 16.5.1 的最後面談到 /etc/cron.d/checktime 的 SELinux type 類型不太對～那我們也知道 crond 這個程序的 type 是 crond_t ， 能不能找一下 crond_t 能夠讀取的檔案 SELinux type 有哪些呢？\n[root@study ~]# sesearch [-A] [-s 主體類別] [-t 目標類別] [-b 布林值] 選項與參數： -A ：列出後面資料中，允許『讀取或放行』的相關資料 -t ：後面還要接類別，例如 -t httpd_t -b ：後面還要接SELinux的規則，例如 -b httpd_enable_ftp_server 範例一：找出 crond_t 這個主體程序能夠讀取的檔案 SELinux type [root@study ~]# sesearch -A -s crond_t | grep spool allow crond_t system_cron_spool_t : file { ioctl read write create getattr .. allow crond_t system_cron_spool_t : dir { ioctl read getattr lock search op.. allow crond_t user_cron_spool_t : file { ioctl read write create getattr se.. allow crond_t user_cron_spool_t : dir { ioctl read write getattr lock add_n.. allow crond_t user_cron_spool_t : lnk_file { read getattr } ; # allow 後面接主體程序以及檔案的 SELinux type，上面的資料是擷取出來的， # 意思是說，crond_t 可以讀取 system_cron_spool_t 的檔案/目錄類型～等等！ 範例二：找出 crond_t 是否能夠讀取 /etc/cron.d/checktime 這個我們自訂的設定檔？ [root@study ~]# ll -Z /etc/cron.d/checktime -rw-r--r--. root root unconfined_u:object_r:admin_home_t:s0 /etc/cron.d/checktime # 兩個重點，一個是 SELinux type 為 admin_home_t，一個是檔案 (file) [root@study ~]# sesearch -A -s crond_t | grep admin_home_t allow domain admin_home_t : dir { getattr search open } ; allow domain admin_home_t : lnk_file { read getattr } ; allow crond_t admin_home_t : dir { ioctl read getattr lock search open } ; allow crond_t admin_home_t : lnk_file { read getattr } ; # 仔細看！看仔細～雖然有 crond_t admin_home_t 存在，但是這是總體的資訊， # 並沒有針對某些規則的尋找～所以還是不確定 checktime 能否被讀取。但是，基本上就是 SELinux # type 出問題～因此才會無法讀取的！ 所以，現在我們知道 /etc/cron.d/checktime 這個我們自己複製過去的檔案會沒有辦法被讀取的原因，就是因為 SELinux type 錯誤啦！ 根本就無法被讀取～好～那現在我們來查一查，那 getsebool -a 裡面看到的 httpd_enable_homedirs 到底是什麼？又是規範了哪些主體程序能夠讀取的 SELinux type 呢？\n[root@study ~]# semanage boolean -l | grep httpd_enable_homedirs SELinux boolean State Default Description httpd_enable_homedirs (off , off) Allow httpd to enable homedirs # httpd_enable_homedirs 的功能是允許 httpd 程序去讀取使用者家目錄的意思～ [root@study ~]# sesearch -A -b httpd_enable_homedirs 範例三：列出 httpd_enable_homedirs 這個規則當中，主體程序能夠讀取的檔案 SELinux type Found 43 semantic av rules: allow httpd_t home_root_t : dir { ioctl read getattr lock search open } ; allow httpd_t home_root_t : lnk_file { read getattr } ; allow httpd_t user_home_type : dir { getattr search open } ; allow httpd_t user_home_type : lnk_file { read getattr } ; ....(後面省略).... # 從上面的資料才可以理解，在這個規則中，主要是放行 httpd_t 能否讀取使用者家目錄的檔案！ # 所以，如果這個規則沒有啟動，基本上， httpd_t 這種程序就無法讀取使用者家目錄下的檔案！  修改 SELinux 規則的布林值 setsebool  那麼如果查詢到某個 SELinux rule，並且以 sesearch 知道該規則的用途後，想要關閉或啟動他，又該如何處置？\n[root@study ~]# setsebool [-P] 『規則名稱』 [0|1] 選項與參數： -P ：直接將設定值寫入設定檔，該設定資料未來會生效的！ 範例一：查詢 httpd_enable_homedirs 這個規則的狀態，並且修改這個規則成為不同的布林值 [root@study ~]# getsebool httpd_enable_homedirs httpd_enable_homedirs --\u0026gt; off \u0026lt;==結果是 off ，依題意給他啟動看看！ [root@study ~]# setsebool -P httpd_enable_homedirs 1 # 會跑很久很久！請耐心等待！ [root@study ~]# getsebool httpd_enable_homedirs httpd_enable_homedirs --\u0026gt; on 這個 setsebool 最好記得一定要加上 -P 的選項！因為這樣才能將此設定寫入設定檔！ 這是非常棒的工具組！你一定要知道如何使用 getsebool 與 setsebool 才行！\nSELinux 安全本文的修改 現在我們知道 SELinux 對受限的主體程序有沒有影響，第一關考慮 SELinux 的三種類型，第二關考慮 SELinux 的政策規則是否放行，第三關則是開始比對 SELinux type 啦！從剛剛我們也知道可以透過 sesearch 來找到主體程序與檔案的 SELinux type 關係！ 好，現在總算要來修改檔案的 SELinux type，以讓主體程序能夠讀到正確的檔案啊！這時就得要幾個重要的小東西了～來瞧瞧～\n使用 chcon 手動修改檔案的 SELinux type [root@study ~]# chcon [-R] [-t type] [-u user] [-r role] 檔案 [root@study ~]# chcon [-R] --reference=範例檔 檔案 選項與參數： -R ：連同該目錄下的次目錄也同時修改； -t ：後面接安全性本文的類型欄位！例如 httpd_sys_content_t ； -u ：後面接身份識別，例如 system_u； (不重要) -r ：後面接角色，例如 system_r； (不重要) -v ：若有變化成功，請將變動的結果列出來 --reference=範例檔：拿某個檔案當範例來修改後續接的檔案的類型！ 範例一：查詢一下 /etc/hosts 的 SELinux type，並將該類型套用到 /etc/cron.d/checktime 上 [root@study ~]# ll -Z /etc/hosts -rw-r--r--. root root system_u:object_r:net_conf_t:s0 /etc/hosts [root@study ~]# chcon -v -t net_conf_t /etc/cron.d/checktime changing security context of ‘/etc/cron.d/checktime’ [root@study ~]# ll -Z /etc/cron.d/checktime -rw-r--r--. root root unconfined_u:object_r:net_conf_t:s0 /etc/cron.d/checktime 範例二：直接以 /etc/shadow SELinux type 套用到 /etc/cron.d/checktime 上！ [root@study ~]# chcon -v --reference=/etc/shadow /etc/cron.d/checktime [root@study ~]# ll -Z /etc/shadow /etc/cron.d/checktime -rw-r--r--. root root system_u:object_r:shadow_t:s0 /etc/cron.d/checktime ----------. root root system_u:object_r:shadow_t:s0 /etc/shadow 上面的練習『都沒有正確的解答！』因為正確的 SELinux type 應該就是要以 /etc/cron.d/ 底下的檔案為標準來處理才對啊～ 好了～既然如此～能不能讓 SELinux 自己解決預設目錄下的 SELinux type 呢？可以！就用 restorecon 吧！\n使用 restorecon 讓檔案恢復正確的 SELinux type [root@study ~]# restorecon [-Rv] 檔案或目錄 選項與參數： -R ：連同次目錄一起修改； -v ：將過程顯示到螢幕上 範例三：將 /etc/cron.d/ 底下的檔案通通恢復成預設的 SELinux type！ [root@study ~]# restorecon -Rv /etc/cron.d restorecon reset /etc/cron.d/checktime context system_u:object_r:shadow_t:s0-\u0026gt; system_u:object_r:system_cron_spool_t:s0 # 上面這兩行其實是同一行喔！表示將 checktime 由 shadow_t 改為 system_cron_spool_t 範例四：重新啟動 crond 看看有沒有正確啟動 checktime 囉！？ [root@study ~]# systemctl restart crond [root@study ~]# tail /var/log/cron # 再去瞧瞧這個 /var/log/cron 的內容，應該就沒有錯誤訊息了 其實，鳥哥幾乎已經忘了 chcon 這個指令了！因為 restorecon 主動的回復預設的 SELinux type 要簡單很多！而且可以一口氣恢復整個目錄下的檔案！ 所以，鳥哥建議你幾乎只要記得 restorecon 搭配 -Rv 同時加上某個目錄這樣的指令串即可～修改 SELinux 的 type 就變得非常的輕鬆囉！\nsemanage 預設目錄的安全性本文查詢與修改 你應該要覺得奇怪，為什麼 restorecon 可以『恢復』原本的 SELinux type 呢？那肯定就是有個地方在紀錄每個檔案/目錄的 SELinux 預設類型囉？ 沒錯！是這樣～那要如何 (1)查詢預設的 SELinux type 以及 (2)如何增加/修改/刪除預設的 SELinux type 呢？很簡單～透過 semanage 即可！他是這樣使用的：\n[root@study ~]# semanage {login|user|port|interface|fcontext|translation} -l [root@study ~]# semanage fcontext -{a|d|m} [-frst] file_spec 選項與參數： fcontext ：主要用在安全性本文方面的用途， -l 為查詢的意思； -a ：增加的意思，你可以增加一些目錄的預設安全性本文類型設定； -m ：修改的意思； -d ：刪除的意思。 範例一：查詢一下 /etc /etc/cron.d 的預設 SELinux type 為何？ [root@study ~]# semanage fcontext -l | grep -E \u0026#39;^/etc |^/etc/cron\u0026#39; SELinux fcontext type Context /etc all files system_u:object_r:etc_t:s0 /etc/cron\\.d(/.*)? all files system_u:object_r:system_cron_spool_t:s0 看到上面輸出的最後一行，那也是為啥我們直接使用 vim 去 /etc/cron.d 底下建立新檔案時，預設的 SELinux type 就是正確的！ 同時，我們也會知道使用 restorecon 回復正確的 SELinux type 時，系統會去判斷預設的類型為何的依據。現在讓我們來想一想， 如果 (當然是假的！不可能這麼幹) 我們要建立一個 /srv/mycron 的目錄，這個目錄預設也是需要變成 system_cron_spool_t 時， 我們應該要如何處理呢？基本上可以這樣作：\n# 1. 先建立 /srv/mycron 同時在內部放入設定檔，同時觀察 SELinux type [root@study ~]# mkdir /srv/mycron [root@study ~]# cp /etc/cron.d/checktime /srv/mycron [root@study ~]# ll -dZ /srv/mycron /srv/mycron/checktime drwxr-xr-x. root root unconfined_u:object_r:var_t:s0 /srv/mycron -rw-r--r--. root root unconfined_u:object_r:var_t:s0 /srv/mycron/checktime # 2. 觀察一下上層 /srv 的 SELinux type [root@study ~]# semanage fcontext -l | grep \u0026#39;^/srv\u0026#39; SELinux fcontext type Context /srv all files system_u:object_r:var_t:s0 # 怪不得 mycron 會是 var_t 囉！ # 3. 將 mycron 預設值改為 system_cron_spool_t 囉！ [root@study ~]# semanage fcontext -a -t system_cron_spool_t \u0026#34;/srv/mycron(/.*)?\u0026#34; [root@study ~]# semanage fcontext -l | grep \u0026#39;^/srv/mycron\u0026#39; SELinux fcontext type Context /srv/mycron(/.*)? all files system_u:object_r:system_cron_spool_t:s0 # 4. 恢復 /srv/mycron 以及子目錄相關的 SELinux type 喔！ [root@study ~]# restorecon -Rv /srv/mycron [root@study ~]# ll -dZ /srv/mycron /srv/mycron/* drwxr-xr-x. root root unconfined_u:object_r:system_cron_spool_t:s0 /srv/mycron -rw-r--r--. root root unconfined_u:object_r:system_cron_spool_t:s0 /srv/mycron/checktime # 有了預設值，未來就不會不小心被亂改了！這樣比較妥當些～ semanage 的功能很多，不過鳥哥主要用到的僅有 fcontext 這個項目的動作而已。如上所示， 你可以使用 semanage 來查詢所有的目錄預設值，也能夠使用他來增加預設值的設定！如果您學會這些基礎的工具， 那麼 SELinux 對你來說，也不是什麼太難的咚咚囉！\n一個網路服務案例及登錄檔協助 本章在 SELinux 小節當中談到的各個指令中，尤其是 setsebool, chcon, restorecon 等，都是為了當你的某些網路服務無法正常提供相關功能時， 才需要進行修改的一些指令動作。但是，我們怎麼知道哪個時候才需要進行這些指令的修改啊？我們怎麼知道系統因為 SELinux 的問題導致網路服務不對勁啊？如果都要靠用戶端連線失敗才來哭訴，那也太沒有效率了！所以，我們的 CentOS 7.x 有提供幾支偵測的服務在登錄 SELinux 產生的錯誤喔！那就是 auditd 與 setroubleshootd。\n setroubleshoot \u0026ndash;\u0026gt; 錯誤訊息寫入 /var/log/messages  幾乎所有 SELinux 相關的程式都會以 se 為開頭，這個服務也是以 se 為開頭！而 troubleshoot 大家都知道是錯誤克服，因此這個 setroubleshoot 自然就得要啟動他啦！這個服務會將關於 SELinux 的錯誤訊息與克服方法記錄到 /var/log/messages 與 /var/log/setroubleshoot/* 裡頭，所以你一定得要啟動這個服務才好。啟動這個服務之前當然就是得要安裝它啦！ 這玩意兒總共需要兩個軟體，分別是 setroublshoot 與 setroubleshoot-server，如果你沒有安裝，請自行使用 yum 安裝吧！\n此外，原本的 SELinux 資訊本來是以兩個服務來記錄的，分別是 auditd 與 setroubleshootd。既然是同樣的資訊，因此 CentOS 6.x (含 7.x) 以後將兩者整合在 auditd 當中啦！所以，並沒有 setroubleshootd 的服務存在了喔！因此，當你安裝好了 setroubleshoot-server 之後，請記得要重新啟動 auditd，否則 setroubleshootd 的功能不會被啟動的。\nTips：事實上，CentOS 7.x 對 setroubleshootd 的運作方式是： (1)先由 auditd 去呼叫 audispd 服務， (2)然後 audispd 服務去啟動 sedispatch 程式， (3)sedispatch 再將原本的 auditd 訊息轉成 setroubleshootd 的訊息，進一步儲存下來的！\n[root@study ~]# rpm -qa | grep setroubleshoot setroubleshoot-plugins-3.0.59-1.el7.noarch setroubleshoot-3.2.17-3.el7.x86_64 setroubleshoot-server-3.2.17-3.el7.x86_64 在預設的情況下，這個 setroubleshoot 應該都是會安裝的！是否正確安裝可以使用上述的表格指令去查詢。萬一沒有安裝，請使用 yum install 去安裝吧！ 再說一遍，安裝完畢最好重新啟動 auditd 這個服務喔！不過，剛剛裝好且順利啟動後， setroubleshoot 還是不會有作用，為啥？ 因為我們並沒有任何受限的網路服務主體程序在運作啊！所以，底下我們將使用一個簡單的 FTP 伺服器軟體為例，讓你了解到我們上頭講到的許多重點的應用！\n 實例狀況說明：透過 vsftpd 這個 FTP 伺服器來存取系統上的檔案  現在的年輕小伙子們傳資料都用 line, FB, dropbox, google 雲端磁碟等等，不過在網路早期傳送大容量的檔案，還是以 FTP 這個協定為主！ 現在為了速度，經常有 p2p 的軟體提供大容量檔案的傳輸，但以鳥哥這個老人家來說，可能 FTP 傳送資料還是比較有保障\u0026hellip; 在 CentOS 7.x 的環境下，達成 FTP 的預設伺服器軟體主要是 vsftpd 這一支喔！\n詳細的 FTP 協定我們在伺服器篇再來談，這裡只是簡單的利用 vsftpd 這個軟體與 FTP 的協定來講解 SELinux 的問題與錯誤克服而已。 不過既然要使用到 FTP 協定，一些簡單的知識還是得要存在才好！否則等一下我們沒有辦法了解為啥要這麼做！ 首先，你得要知道，用戶端需要使用『FTP 帳號登入 FTP 伺服器』才行！而有一個稱為『匿名 (anonymous) 』的帳號可以登入系統！ 但是這個匿名的帳號登入後，只能存取某一個特定的目錄，而無法脫離該目錄～！\n在 vsftpd 中，一般用戶與匿名者的家目錄說明如下：\n 匿名者：如果使用瀏覽器來連線到 FTP 伺服器的話，那預設就是使用匿名者登入系統。而匿名者的家目錄預設是在 /var/ftp 當中！ 同時，匿名者在家目錄下只能下載資料，不能上傳資料到 FTP 伺服器。同時，匿名者無法離開 FTP 伺服器的 /var/ftp 目錄喔！ 一般 FTP 帳號：在預設的情況下，所有 UID 大於 1000 的帳號，都可以使用 FTP 來登入系統！ 而登入系統之後，所有的帳號都能夠取得自己家目錄底下的檔案資料！當然預設是可以上傳、下載檔案的！  為了避免跟之前章節的用戶產生誤解的情況，這裡我們先建立一個名為 ftptest 的帳號，且帳號密碼為 myftp123， 先來建立一下吧！\n[root@study ~]# useradd -s /sbin/nologin ftptest [root@study ~]# echo \u0026#34;myftp123\u0026#34; | passwd --stdin ftptest 接下來當然就是安裝 vsftpd 這隻伺服器軟體，同時啟動這隻服務，另外，我們也希望未來開機都能夠啟動這隻服務！ 因此需要這樣做 (鳥哥假設你的 CentOS 7.x 的原版光碟已經掛載於 /mnt 了喔！)：\n[root@study ~]# yum install /mnt/Packages/vsftpd-3* [root@study ~]# systemctl start vsftpd [root@study ~]# systemctl enable vsftpd [root@study ~]# netstat -tlnp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1326/sshd tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 2349/master tcp6 0 0 :::21 :::* LISTEN 6256/vsftpd tcp6 0 0 :::22 :::* LISTEN 1326/sshd tcp6 0 0 ::1:25 :::* LISTEN 2349/master # 要注意看，上面的特殊字體那行有出現，才代表 vsftpd 這隻服務有啟動喔！！  匿名者無法下載的問題  現在讓我們來模擬一些 FTP 的常用狀態！假設你想要將 /etc/securetty 以及主要的 /etc/sysctl.conf 放置給所有人下載， 那麼你可能會這樣做！\n[root@study ~]# cp -a /etc/securetty /etc/sysctl.conf /var/ftp/pub [root@study ~]# ll /var/ftp/pub -rw-------. 1 root root 221 Oct 29 2014 securetty # 先假設你沒有看到這個問題！ -rw-r--r--. 1 root root 225 Mar 6 11:05 sysctl.conf 一般來說，預設要給用戶下載的 FTP 檔案會放置到上面表格當中的 /var/ftp/pub 目錄喔！現在讓我們使用簡單的終端機瀏覽器 curl 來觀察看看！ 看你能不能查詢到上述兩個檔案的內容呢？\n# 1. 先看看 FTP 根目錄底下有什麼檔案存在？ [root@study ~]# curl ftp://localhost drwxr-xr-x 2 0 0 40 Aug 08 00:51 pub # 確實有存在一個名為 pub 的檔案喔！那就是在 /var/ftp 底下的 pub 囉！ # 2. 再往下看看，能不能看到 pub 內的檔案呢？ [root@study ~]# curl ftp://localhost/pub/ # 因為是目錄，要加上 / 才好！ -rw------- 1 0 0 221 Oct 29 2014 securetty -rw-r--r-- 1 0 0 225 Mar 06 03:05 sysctl.conf # 3. 承上，繼續看一下 sysctl.conf 的內容好了！ [root@study ~]# curl ftp://localhost/pub/sysctl.conf # System default settings live in /usr/lib/sysctl.d/00-system.conf. # To override those settings, enter new settings here, or in an /etc/sysctl.d/\u0026lt;name\u0026gt;.conf file # # For more information, see sysctl.conf(5) and sysctl.d(5). # 真的有看到這個檔案的內容喔！所以確定是可以讓 vsftpd 讀取到這檔案的！ # 4. 再來瞧瞧 securetty 好了！ [root@study ~]# curl ftp://localhost/pub/securetty curl: (78) RETR response: 550 # 看不到耶！但是，基本的原因應該是權限問題喔！因為 vsftpd 預設放在 /var/ftp/pub 內的資料， # 不論什麼 SELinux type 幾乎都可以被讀取的才對喔！所以要這樣處理！ # 5. 修訂權限之後再一次觀察 securetty 看看！ [root@study ~]# chmod a+r /var/ftp/pub/securetty [root@study ~]# curl ftp://localhost/pub/securetty # 此時你就可以看到實際的檔案內容囉！ # 6. 修訂 SELinux type 的內容 (非必備) [root@study ~]# restorecon -Rv /var/ftp 上面這個例子在告訴你，要先從權限的角度來瞧一瞧，如果無法被讀取，可能就是因為沒有 r 或沒有 rx 囉！並不一定是由 SELinux 引起的！ 了解乎？好～再來瞧瞧如果是一般帳號呢？如何登入？\n 無法從家目錄下載檔案的問題分析與解決  我們前面建立了 ftptest 帳號，那如何使用文字界面來登入呢？就使用如下的方式來處理。同時請注意，因為文字型的 FTP 用戶端軟體， 預設會將用戶丟到根目錄而不是家目錄，因此，你的 URL 可能需要修訂一下如下！\n# 0. 為了讓 curl 這個文字瀏覽器可以傳輸資料，我們先建立一些資料在 ftptest 家目錄 [root@study ~]# echo \u0026#34;testing\u0026#34; \u0026gt; ~ftptest/test.txt [root@study ~]# cp -a /etc/hosts /etc/sysctl.conf ~ftptest/ [root@study ~]# ll ~ftptest/ -rw-r--r--. 1 root root 158 Jun 7 2013 hosts -rw-r--r--. 1 root root 225 Mar 6 11:05 sysctl.conf -rw-r--r--. 1 root root 8 Aug 9 01:05 test.txt # 1. 一般帳號直接登入 FTP 伺服器，同時變換目錄到家目錄去！ [root@study ~]# curl ftp://ftptest:myftp123@localhost/~/ -rw-r--r-- 1 0 0 158 Jun 07 2013 hosts -rw-r--r-- 1 0 0 225 Mar 06 03:05 sysctl.conf -rw-r--r-- 1 0 0 8 Aug 08 17:05 test.txt # 真的有資料～看檔案最左邊的權限也是沒問題，所以，來讀一下 test.txt 的內容看看 # 2. 開始下載 test.txt, sysctl.conf 等有權限可以閱讀的檔案看看！ [root@study ~]# curl ftp://ftptest:myftp123@localhost/~/test.txt curl: (78) RETR response: 550 # 竟然說沒有權限！明明我們的 rwx 是正常沒問題！那是否有可能是 SELinux 造成的？ # 3. 先將 SELinux 從 Enforce 轉成 Permissive 看看情況！同時觀察登錄檔 [root@study ~]# setenforce 0 [root@study ~]# curl ftp://ftptest:myftp123@localhost/~/test.txt testing [root@study ~]# setenforce 1 # 確定問題後，一定要轉成 Enforcing 啊！ # 確定有資料內容！所以，確定就是 SELinux 造成無法讀取的問題～那怎辦？要改規則？還是改 type？ # 因為都不知道，所以，就檢查一下登錄檔看看有沒有相關的資訊可以提供給我們處理！ [root@study ~]# vim /var/log/messages Aug 9 02:55:58 station3-39 setroubleshoot: SELinux is preventing /usr/sbin/vsftpd from lock access on the file /home/ftptest/test.txt. For complete SELinux messages. run sealert -l 3a57aad3-a128-461b-966a-5bb2b0ffa0f9 Aug 9 02:55:58 station3-39 python: SELinux is preventing /usr/sbin/vsftpd from lock access on the file /home/ftptest/test.txt. ***** Plugin catchall_boolean (47.5 confidence) suggests ****************** If you want to allow ftp to home dir Then you must tell SELinux about this by enabling the \u0026#39;ftp_home_dir\u0026#39; boolean. You can read \u0026#39;None\u0026#39; man page for more details. Do setsebool -P ftp_home_dir 1 ***** Plugin catchall_boolean (47.5 confidence) suggests ****************** If you want to allow ftpd to full access Then you must tell SELinux about this by enabling the \u0026#39;ftpd_full_access\u0026#39; boolean. You can read \u0026#39;None\u0026#39; man page for more details. Do setsebool -P ftpd_full_access 1 ***** Plugin catchall (6.38 confidence) suggests ************************** .....(底下省略)..... # 基本上，你會看到有個特殊字體的部份，就是 sealert 那一行。雖然底下已經列出可能的解決方案了， # 就是一堆底線那些東西。至少就有三個解決方案 (最後一個沒列出來)，哪種才是正確的？ # 為了了解正確的解決方案，我們還是還執行一下 sealert 那行吧！看看情況再說！ # 4. 透過 sealert 的解決方案來處理問題 [root@study ~]# sealert -l 3a57aad3-a128-461b-966a-5bb2b0ffa0f9 SELinux is preventing /usr/sbin/vsftpd from lock access on the file /home/ftptest/test.txt. # 底下說有 47.5% 的機率是由於這個原因所發生，並且可以使用 setsebool 去解決的意思！ ***** Plugin catchall_boolean (47.5 confidence) suggests ****************** If you want to allow ftp to home dir Then you must tell SELinux about this by enabling the \u0026#39;ftp_home_dir\u0026#39; boolean. You can read \u0026#39;None\u0026#39; man page for more details. Do setsebool -P ftp_home_dir 1 # 底下說也是有 47.5% 的機率是由此產生的！ ***** Plugin catchall_boolean (47.5 confidence) suggests ****************** If you want to allow ftpd to full access Then you must tell SELinux about this by enabling the \u0026#39;ftpd_full_access\u0026#39; boolean. You can read \u0026#39;None\u0026#39; man page for more details. Do setsebool -P ftpd_full_access 1 # 底下說，僅有 6.38% 的可信度是由這個情況產生的！ ***** Plugin catchall (6.38 confidence) suggests ************************** If you believe that vsftpd should be allowed lock access on the test.txt file by default. Then you should report this as a bug. You can generate a local policy module to allow this access. Do allow this access for now by executing: # grep vsftpd /var/log/audit/audit.log | audit2allow -M mypol # semodule -i mypol.pp # 底下就重要了！是整個問題發生的主因～最好還是稍微瞧一瞧！ Additional Information: Source Context system_u:system_r:ftpd_t:s0-s0:c0.c1023 Target Context unconfined_u:object_r:user_home_t:s0 Target Objects /home/ftptest/test.txt [ file ] Source vsftpd Source Path /usr/sbin/vsftpd Port \u0026lt;Unknown\u0026gt; Host station3-39.gocloud.vm Source RPM Packages vsftpd-3.0.2-9.el7.x86_64 Target RPM Packages Policy RPM selinux-policy-3.13.1-23.el7.noarch Selinux Enabled True Policy Type targeted Enforcing Mode Permissive Host Name station3-39.gocloud.vm Platform Linux station3-39.gocloud.vm 3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 Alert Count 3 First Seen 2015-08-09 01:00:12 CST Last Seen 2015-08-09 02:55:57 CST Local ID 3a57aad3-a128-461b-966a-5bb2b0ffa0f9 Raw Audit Messages type=AVC msg=audit(1439060157.358:635): avc: denied { lock } for pid=5029 comm=\u0026#34;vsftpd\u0026#34; path=\u0026#34;/home/ftptest/test.txt\u0026#34; dev=\u0026#34;dm-2\u0026#34; ino=141 scontext=system_u:system_r:ftpd_t:s0-s0: c0.c1023 tcontext=unconfined_u:object_r:user_home_t:s0 tclass=file type=SYSCALL msg=audit(1439060157.358:635): arch=x86_64 syscall=fcntl success=yes exit=0 a0=4 a1=7 a2=7fffceb8cbb0 a3=0 items=0 ppid=5024 pid=5029 auid=4294967295 uid=1001 gid=1001 euid=1001 suid=1001 fsuid=1001 egid=1001 sgid=1001 fsgid=1001 tty=(none) ses=4294967295 comm=vsftpd exe=/usr/sbin/vsftpd subj=system_u:system_r:ftpd_t:s0-s0:c0.c1023 key=(null) Hash: vsftpd,ftpd_t,user_home_t,file,lock 經過上面的測試，現在我們知道主要的問題發生在 SELinux 的 type 不是 vsftpd_t 所能讀取的原因～ 經過仔細觀察 test.txt 檔案的類型，我們知道他原本就是家目錄，因此是 user_home_t 也沒啥了不起的啊！是正確的～ 因此，分析兩個比較可信 (47.5%) 的解決方案後，可能是與 ftp_home_dir 比較有關啊！所以，我們應該不需要修改 SELinux type， 修改的應該是 SELinux rules 才對！所以，這樣做看看：\n# 1. 先確認一下 SELinux 的模式，然後再瞧一瞧能否下載 test.txt，最終使用處理方式來解決～ [root@study ~]# getenforce Enforcing [root@study ~]# curl ftp://ftptest:myftp123@localhost/~/test.txt curl: (78) RETR response: 550 # 確定還是無法讀取的喔！ [root@study ~]# setsebool -P ftp_home_dir 1 [root@study ~]# curl ftp://ftptest:myftp123@localhost/~/test.txt testing # OK！太讚了！處理完畢！現在使用者可以在自己的家目錄上傳/下載檔案了！ # 2. 開始下載其他檔案試看看囉！ [root@study ~]# curl ftp://ftptest:myftp123@localhost/~/sysctl.conf # System default settings live in /usr/lib/sysctl.d/00-system.conf. # To override those settings, enter new settings here, or in an /etc/sysctl.d/\u0026lt;name\u0026gt;.conf file # # For more information, see sysctl.conf(5) and sysctl.d(5). 沒問題喔！透過修改 SELinux rule 的布林值，現在我們就可以使用一般帳號在 FTP 服務來上傳/下載資料囉！非常愉快吧！ 那萬一我們還有其他的目錄也想要透過 FTP 來提供這個 ftptest 用戶上傳與下載呢？往下瞧瞧～\n 一般帳號用戶從非正規目錄上傳/下載檔案  假設我們還想要提供 /srv/gogogo 這個目錄給 ftptest 用戶使用，那又該如何處理呢？假設我們都沒有考慮 SELinux ， 那就是這樣的情況：\n# 1. 先處理好所需要的目錄資料 [root@study ~]# mkdir /srv/gogogo [root@study ~]# chgrp ftptest /srv/gogogo [root@study ~]# echo \u0026#34;test\u0026#34; \u0026gt; /srv/gogogo/test.txt # 2. 開始直接使用 ftp 觀察一下資料！ [root@study ~]# curl ftp://ftptest:myftp123@localhost//srv/gogogo/test.txt curl: (78) RETR response: 550 # 有問題喔！來瞧瞧登錄檔怎麼說！ [root@study ~]# grep sealert /var/log/messages | tail Aug 9 04:23:12 station3-39 setroubleshoot: SELinux is preventing /usr/sbin/vsftpd from read access on the file test.txt. For complete SELinux messages. run sealert -l 08d3c0a2-5160-49ab-b199-47a51a5fc8dd [root@study ~]# sealert -l 08d3c0a2-5160-49ab-b199-47a51a5fc8dd SELinux is preventing /usr/sbin/vsftpd from read access on the file test.txt. # 雖然這個可信度比較高～不過，因為會全部放行 FTP ，所以不太考慮！ ***** Plugin catchall_boolean (57.6 confidence) suggests ****************** If you want to allow ftpd to full access Then you must tell SELinux about this by enabling the \u0026#39;ftpd_full_access\u0026#39; boolean. You can read \u0026#39;None\u0026#39; man page for more details. Do setsebool -P ftpd_full_access 1 # 因為是非正規目錄的使用，所以這邊加上預設 SELinux type 恐怕會是比較正確的選擇！ ***** Plugin catchall_labels (36.2 confidence) suggests ******************* If you want to allow vsftpd to have read access on the test.txt file Then you need to change the label on test.txt Do # semanage fcontext -a -t FILE_TYPE \u0026#39;test.txt\u0026#39; where FILE_TYPE is one of the following: NetworkManager_tmp_t, abrt_helper_exec_t, abrt_tmp_t, abrt_upload_watch_tmp_t, abrt_var_cache_t, abrt_var_run_t, admin_crontab_tmp_t, afs_cache_t, alsa_home_t, alsa_tmp_t, amanda_tmp_t, antivirus_home_t, antivirus_tmp_t, apcupsd_tmp_t, ... Then execute: restorecon -v \u0026#39;test.txt\u0026#39; ***** Plugin catchall (7.64 confidence) suggests ************************** If you believe that vsftpd should be allowed read access on the test.txt file by default. Then you should report this as a bug. You can generate a local policy module to allow this access. Do allow this access for now by executing: # grep vsftpd /var/log/audit/audit.log | audit2allow -M mypol # semodule -i mypol.pp Additional Information: Source Context system_u:system_r:ftpd_t:s0-s0:c0.c1023 Target Context unconfined_u:object_r:var_t:s0 Target Objects test.txt [ file ] Source vsftpd .....(底下省略)..... 因為是非正規目錄啊，所以感覺上似乎與 semanage 那一行的解決方案比較相關～接下來就是要找到 FTP 的 SELinux type 來解決囉！ 所以，讓我們查一下 FTP 相關的資料囉！\n# 3. 先查看一下 /var/ftp 這個地方的 SELinux type 吧！ [root@study ~]# ll -Zd /var/ftp drwxr-xr-x. root root system_u:object_r:public_content_t:s0 /var/ftp # 4. 以 sealert 建議的方法來處理好 SELinux type 囉！ [root@study ~]# semanage fcontext -a -t public_content_t \u0026#34;/srv/gogogo(/.*)?\u0026#34; [root@study ~]# restorecon -Rv /srv/gogogo [root@study ~]# curl ftp://ftptest:myftp123@localhost//srv/gogogo/test.txt test # 喔耶！終於再次搞定喔！ 在這個範例中，我們是修改了 SELinux type 喔！與前一個修改 SELinux rule 不太一樣！要理解理解喔！\n 無法變更 FTP 連線埠口問題分析與解決  在某些情況下，可能你的伺服器軟體需要開放在非正規的埠口，舉例來說，如果因為某些政策問題，導致 FTP 啟動的正常的 21 號埠口無法使用， 因此你想要啟用在 555 號埠口時，該如何處理呢？基本上，既然 SELinux 的主體程序大多是被受限的網路服務，沒道理不限制放行的埠口啊！ 所以，很可能會出問題～那就得要想想辦法才行！\n# 1. 先處理 vsftpd 的設定檔，加入換 port 的參數才行！ [root@study ~]# vim /etc/vsftpd/vsftpd.conf # 請按下大寫的 G 跑到最後一行，然後新增加底下這行設定！前面不可以留白！ listen_port=555 # 2. 重新啟動 vsftpd 並且觀察登錄檔的變化！ [root@study ~]# systemctl restart vsftpd [root@study ~]# grep sealert /var/log/messages Aug 9 06:34:46 station3-39 setroubleshoot: SELinux is preventing /usr/sbin/vsftpd from name_bind access on the tcp_socket port 555. For complete SELinux messages. run sealert -l 288118e7-c386-4086-9fed-2fe78865c704 [root@study ~]# sealert -l 288118e7-c386-4086-9fed-2fe78865c704 SELinux is preventing /usr/sbin/vsftpd from name_bind access on the tcp_socket port 555. ***** Plugin bind_ports (92.2 confidence) suggests ************************ If you want to allow /usr/sbin/vsftpd to bind to network port 555 Then you need to modify the port type. Do # semanage port -a -t PORT_TYPE -p tcp 555 where PORT_TYPE is one of the following: certmaster_port_t, cluster_port_t, ephemeral_port_t, ftp_data_port_t, ftp_port_t, hadoop_datanode_port_t, hplip_port_t, port_t, postgrey_port_t, unreserved_port_t. .....(後面省略)..... # 看一下信任度，高達 92.2% 耶！幾乎就是這傢伙～因此不必再看～就是他了！比較重要的是， # 解決方案裡面，那個 PORT_TYPE 有很多選擇～但我們是要開啟 FTP 埠口嘛！所以， # 就由後續資料找到 ftp_port_t 那個項目囉！帶入實驗看看！ # 3. 實際帶入 SELinux 埠口修訂後，在重新啟動 vsftpd 看看 [root@study ~]# semanage port -a -t ftp_port_t -p tcp 555 [root@study ~]# systemctl restart vsftpd [root@study ~]# netstat -tlnp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1167/sshd tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1598/master tcp6 0 0 :::555 :::* LISTEN 8436/vsftpd tcp6 0 0 :::22 :::* LISTEN 1167/sshd tcp6 0 0 ::1:25 :::* LISTEN 1598/master # 4. 實驗看看這個 port 能不能用？ [root@study ~]# curl ftp://localhost:555/pub/ -rw-r--r-- 1 0 0 221 Oct 29 2014 securetty -rw-r--r-- 1 0 0 225 Mar 06 03:05 sysctl.conf 透過上面的幾個小練習，你會知道在正規或非正規的環境下，如何處理你的 SELinux 問題哩！仔細研究看看囉！\nSwap 【譯】替 swap 辯護：常見的誤解 這篇翻譯自 Chris Down 的博文 In defence of swap: common misconceptions 。\n翻譯這篇文章是因爲經常看到朋友們（包括有經驗的程序員和 Linux 管理員）對 swap 和 swappiness 有諸多誤解，而這篇文章正好澄清了這些誤解，也講清楚了 Linux 中這兩者的本質。值得一提的是本文討論的 swap 針對 Linux 內核，在別的系統包括 macOS/WinNT 或者 Unix 系統中的交換文件可能有不同一樣的行爲， 需要不同的調優方式。比如在 FreeBSD handbook 中明確建議了 swap 分區通常應該是兩倍物理內存大小，這一點建議對 FreeBSD 系內核的內存管理可能非常合理， 而不一定適合 Linux 內核，FreeBSD 和 Linux 有不同的內存管理方式尤其是 swap 和 page cache 和 buffer cache 的處理方式有諸多不同。\n經常有朋友看到系統卡頓之後看系統內存使用狀況觀察到大量 swap 佔用，於是覺得卡頓是來源於 swap 。就像文中所述，相關不蘊含因果，產生內存顛簸之後的確會造成大量 swap 佔用，也會造成系統卡頓， 但是 swap 不是導致卡頓的原因，關掉 swap 或者調低 swappiness 並不能阻止卡頓，只會將 swap 造成的 I/O 轉化爲加載文件緩存造成的 I/O 。\n以下是原文翻譯：\n 太長不看：\n 對維持系統的正常功能而言，有 swap 是相對挺重要的一部分。沒有它的話會更難做到合理的內存管理。 swap 的目的通常並不是用作緊急內存，它的目的在於讓內存回收能更平等和高效。 事實上把它當作「緊急內存」來用的想法通常是有害的。 禁用 swap 在內存壓力下並不能避免磁盤I/O造成的性能問題，這麼做只是讓磁盤I/O顛簸的範圍從 匿名頁面轉化到文件頁面。這不僅更低效，因爲系統能回收的頁面的選擇範圍更有限了， 而且這種做法還可能是加重了內存壓力的原因之一。 內核 4.0 版本之前的交換進程（swapper）有一些問題，導致很多人對 swap 有負面印象， 因爲它太急於（overeagerness）把頁面交換出去。在 4.0 之後的內核上這種情況已經改善了很多。 在 SSD 上，交換出匿名頁面的開銷和回收文件頁面的開銷基本上在性能/延遲方面沒有區別。 在老式的磁盤上，讀取交換文件因爲屬於隨機訪問讀取所以會更慢，於是設置較低的 vm.swappiness 可能比較合理（繼續讀下面關於 vm.swappiness 的描述）。 禁用 swap 並不能避免在接近 OOM 狀態下最終表現出的症狀，儘管的確有 swap 的情況下這種症狀持續的時間可能會延長。在系統調用 OOM 殺手的時候無論有沒有啓用 swap ，或者更早/更晚開始調用 OOM 殺手，結果都是一樣的：整個系統留在了一種不可預知的狀態下。 有 swap 也不能避免這一點。 可以用 cgroup v2 的 memory.low 相關機制來改善內存壓力下 swap 的行爲並且 避免發生顛簸。  我的工作的一部分是改善內核中內存管理和 cgroup v2 相關，所以我和很多工程師討論過看待內存管理的態度， 尤其是在壓力下應用程序的行爲和操作系統在底層內存管理中用的基於經驗的啓發式決策邏輯。\n在這種討論中經常重複的話題是交換區（swap）。交換區的話題是非常有爭議而且很少被理解的話題，甚至包括那些在 Linux 上工作過多年的人也是如此。很多人覺得它沒什麼用甚至是有害的：它是歷史遺蹟，從內存緊缺而 磁盤讀寫是必要之惡的時代遺留到現在，爲計算機提供在當年很必要的頁面交換功能作爲內存空間。 最近幾年我還經常能以一定頻度看到這種論調，然後我和很多同事、朋友、業界同行們討論過很多次， 幫他們理解爲什麼在現代計算機系統中交換區仍是有用的概念，即便現在的電腦中物理內存已經遠多於過去。\n圍繞交換區的目的還有很多誤解——很多人覺得它只是某種爲了應對緊急情況的「慢速額外內存」， 但是沒能理解在整個操作系統健康運作的時候它也能改善普通負載的性能。\n我們很多人也聽說過描述內存時所用的常見說法： 「 Linux 用了太多內存 」，「 swap 應該設爲物理內存的兩倍大小 」，或者類似的說法。 雖然這些誤解要麼很容易化解，或者關於他們的討論在最近幾年已經逐漸變得瑣碎，但是關於「無用」交換區 的傳言有更深的經驗傳承的根基，而不是一兩個類比就能解釋清楚的，並且要探討這個先得對內存管理有 一些基礎認知。\n本文主要目標是針對那些管理 Linux 系統並且有興趣理解「讓系統運行於低/無交換區狀態」或者「把 vm.swappiness 設爲 0 」這些做法的反論。\n背景 如果沒有基本理解 Linux 內存管理的底層機制是如何運作的，就很難討論爲什麼需要交換區以及交換出頁面 對正常運行的系統爲什麼是件好事，所以我們先確保大家有討論的基礎。\n內存的類型 Linux 中內存分爲好幾種類型，每種都有各自的屬性。想理解爲什麼交換區很重要的關鍵一點在於理解這些的細微區別。\n比如說，有種 頁面（「整塊」的內存，通常 4K） 是用來存放電腦裏每個程序運行時各自的代碼的。 也有頁面用來保存這些程序所需要讀取的文件數據和元數據的緩存，以便加速隨後的文件讀寫。 這些內存頁面構成 頁面緩存（page cache），後文中我稱他們爲文件內存。\n還有一些頁面是在代碼執行過程中做的內存分配得到的，比如說，當代碼調用 malloc 能分配到新內存區，或者使用 mmap 的 MAP_ANONYMOUS 標誌分配的內存。 這些是「匿名(anonymous)」頁面——之所以這麼稱呼它們是因爲他們沒有任何東西作後備—— 後文中我稱他們爲匿名內存。\n還有其它類型的內存——共享內存、slab內存、內核棧內存、文件緩衝區（buffers），這種的—— 但是匿名內存和文件內存是最知名也最好理解的，所以後面的例子裏我會用這兩個說明， 雖然後面的說明也同樣適用於別的這些內存類型。\n可回收/不可回收內存 考慮某種內存的類型時，一個非常基礎的問題是這種內存是否能被回收。 「回收（Reclaim）」在這裏是指系統可以，在不丟失數據的前提下，從物理內存中釋放這種內存的頁面。\n對一些內存類型而言，是否可回收通常可以直接判斷。比如對於那些乾淨（未修改）的頁面緩存內存， 我們只是爲了性能在用它們緩存一些磁盤上現有的數據，所以我們可以直接扔掉這些頁面， 不需要做什麼特殊的操作。\n對有些內存類型而言，回收是可能的，但是不是那麼直接。比如對髒（修改過）的頁面緩存內存， 我們不能直接扔掉這些頁面，因爲磁盤上還沒有寫入我們所做的修改。這種情況下，我們可以選擇拒絕回收， 或者選擇先等待我們的變更寫入磁盤之後才能扔掉這些內存。\n對還有些內存類型而言，是不能回收的。比如前面提到的匿名頁面，它們只存在於內存中，沒有任何後備存儲， 所以它們必須留在內存裏。\n說到交換區的本質 如果你去搜 Linux 上交換區的目的的描述，肯定會找到很多人說交換區只是在緊急時用來擴展物理內存的機制。 比如下面這段是我在 google 中輸入「什麼是 swap」 從前排結果中隨機找到的一篇：\n 交換區本質上是緊急內存；是爲了應對你的系統臨時所需內存多餘你現有物理內存時，專門分出一塊額外空間。 大家覺得交換區「不好」是因爲它又慢又低效，並且如果你的系統一直需要使用交換區那說明它明顯沒有足夠的內存。 ［……］如果你有足夠內存覆蓋所有你需要的情況，而且你覺得肯定不會用滿內存，那麼完全可以不用交換區 安全地運行系統。\n 事先說明，我不想因爲這些文章的內容責怪這些文章的作者——這些內容被很多 Linux 系統管理員認爲是「常識」， 並且很可能你問他們什麼是交換區的時候他們會給你這樣的回答。但是也很不幸的是， 這種認識是使用交換區的目的的一種普遍誤解，尤其在現代系統上。\n前文中我說過回收匿名頁面的內存是「不可能的」，因爲匿名內存的特點，把它們從內存中清除掉之後， 沒有別的存儲區域能作爲他們的備份——因此，要回收它們會造成數據丟失。但是，如果我們爲這種內存頁面創建 一種後備存儲呢？\n嗯，這正是交換區存在的意義。交換區是一塊存儲空間，用來讓這些看起來「不可回收」的內存頁面在需要的時候 可以交換到存儲設備上。這意味着有了交換區之後，這些匿名頁面也和別的那些可回收內存一樣， 可以作爲內存回收的候選，就像乾淨文件頁面，從而允許更有效地使用物理內存。\n交換區主要是爲了平等的回收機制，而不是爲了緊急情況的「額外內存」。使用交換區不會讓你的程序變慢—— 進入內存競爭的狀態才是讓程序變慢的元兇。\n那麼在這種「平等的可回收機遇」的情況下，讓我們選擇回收匿名頁面的行爲在何種場景中更合理呢？ 抽象地說，比如在下述不算罕見的場景中：\n 程序初始化的時候，那些長期運行的程序可能要分配和使用很多頁面。這些頁面可能在最後的關閉/清理的 時候還需要使用，但是在程序「啓動」之後（以具體的程序相關的方式）持續運行的時候不需要訪問。 對後臺服務程序來說，很多後臺程序要初始化不少依賴庫，這種情況很常見。 在程序的正常運行過程中，我們可能分配一些很少使用的內存。對整體系統性能而言可能比起讓這些內存頁 一直留在內存中，只有在用到的時候才按需把它們用 缺頁異常（major fault） 換入內存， 可以空出更多內存留給更重要的東西。  考察有無交換區時會發生什麼 我們來看一些在常見場景中，有無交換區時分別會如何運行。 在我的 關於 cgroup v2 的演講 中探討過「內存競爭」的指標。\n在無/低內存競爭的狀態下  有交换区: 我們可以選擇換出那些只有在進程生存期內很小一部分時間會訪問的匿名內存， 這允許我們空出更多內存空間用來提升緩存命中率，或者做別的優化。 無交換區: 我們不能換出那些很少使用的匿名內存，因爲它們被鎖在了內存中。雖然這通常不會直接表現出問題， 但是在一些工作條件下這可能造成卡頓導致不平凡的性能下降，因爲匿名內存佔着空間不能給 更重要的需求使用。   譯註：關於 內存熱度 和 內存顛簸（thrash）\n討論內核中內存管理的時候經常會說到內存頁的 冷熱 程度。這裏冷熱是指歷史上內存頁被訪問到的頻度， 內存管理的經驗在說，歷史上在近期頻繁訪問的 熱 內存，在未來也可能被頻繁訪問， 從而應該留在物理內存裏；反之歷史上不那麼頻繁訪問的 冷 內存，在未來也可能很少被用到， 從而可以考慮交換到磁盤或者丟棄文件緩存。\n顛簸（thrash） 這個詞在文中出現多次但是似乎沒有詳細介紹，實際計算機科學專業的課程中應該有講過。 一段時間內，讓程序繼續運行所需的熱內存總量被稱作程序的工作集（workset），估算工作集大小， 換句話說判斷進程分配的內存頁中哪些屬於 熱 內存哪些屬於 冷 內存，是內核中 內存管理的最重要的工作。當分配給程序的內存大於工作集的時候，程序可以不需要等待I/O全速運行； 而當分配給程序的內存不足以放下整個工作集的時候，意味着程序每執行一小段就需要等待換頁或者等待 磁盤緩存讀入所需內存頁，產生這種情況的時候，從用戶角度來看可以觀察到程序肉眼可見的「卡頓」。 當系統中所有程序都內存不足的時候，整個系統都處於顛簸的狀態下，響應速度直接降至磁盤I/O的帶寬。 如本文所說，禁用交換區並不能防止顛簸，只是從等待換頁變成了等待文件緩存， 給程序分配超過工作集大小的內存才能防止顛簸。\n 在中/高內存競爭的狀態下  有交换区: 所有內存類型都有平等的被回收的可能性。這意味着我們回收頁面有更高的成功率—— 成功回收的意思是說被回收的那些頁面不會在近期內被缺頁異常換回內存中（顛簸）。 無交換區: 匿名內存因爲無處可去所以被鎖在內存中。長期內存回收的成功率變低了，因爲我們成體上 能回收的頁面總量少了。發生缺頁顛簸的危險性更高了。缺乏經驗的讀者可能覺得這某時也是好事， 因爲這能避免進行磁盤I/O，但是實際上不是如此——我們只是把交換頁面造成的磁盤I/O變成了扔掉熱緩存頁 和扔掉代碼段，這些頁面很可能馬上又要從文件中讀回來。  在臨時內存佔用高峰時  有交换区: 我們對內存使用激增的情況更有抵抗力，但是在嚴重的內存不足的情況下， 從開始發生內存顛簸到 OOM 殺手開始工作的時間會被延長。內存壓力造成的問題更容易觀察到， 從而可能更有效地應對，或者更有機會可控地干預。 無交換區: 因爲匿名內存被鎖在內存中了不能被回收，所以 OOM 殺手會被更早觸發。 發生內存顛簸的可能性更大，但是發生顛簸之後到 OOM 解決問題的時間間隔被縮短了。 基於你的程序，這可能更好或是更糟。比如說，基於隊列的程序可能更希望這種從顛簸到殺進程的轉換更快發生。 即便如此，發生 OOM 的時機通常還是太遲於是沒什麼幫助——只有在系統極度內存緊缺的情況下才會請出 OOM 殺手，如果想依賴這種行爲模式，不如換成更早殺進程的方案，因爲在這之前已經發生內存競爭了。  好吧，所以我需要系統交換區，但是我該怎麼爲每個程序微調它的行爲？ 你肯定想到了我寫這篇文章一定會在哪兒插點 cgroup v2 的安利吧？ ;-)\n顯然，要設計一種對所有情況都有效的啓發算法會非常難，所以給內核提一些指引就很重要。 歷史上我們只能在整個系統層面做這方面微調，通過 vm.swappiness 。這有兩方面問題： vm.swappiness 的行爲很難準確控制，因爲它只是傳遞給一個更大的啓發式算法中的一個小參數； 並且它是一個系統級別的設置，沒法針對一小部分進程微調。\n你可以用 mlock 把頁面鎖在內存裏，但是這要麼必須改程序代碼，或者折騰 LD_PRELOAD ，或者在運行期用調試器做一些魔法操作。對基於虛擬機的語言來說這種方案也不能 很好工作，因爲通常你沒法控制內存分配，最後得用上 mlockall ，而這個沒有辦法精確指定你實際上想鎖住的頁面。\ncgroup v2 提供了一套可以每個 cgroup 微調的 memory.low ，允許我們告訴內核說當使用的內存低於一定閾值之後優先回收別的程序的內存。這可以讓我們不強硬禁止內核 換出程序的一部分內存，但是當發生內存競爭的時候讓內核優先回收別的程序的內存。在正常條件下， 內核的交換邏輯通常還是不錯的，允許它有條件地換出一部分頁面通常可以改善系統性能。在內存競爭的時候 發生交換顛簸雖然不理想，但是這更多地是單純因爲整體內存不夠了，而不是因爲交換進程（swapper）導致的問題。 在這種場景下，你通常希望在內存壓力開始積攢的時候通過自殺一些非關鍵的進程的方式來快速退出（fail fast）。\n你不能依賴 OOM 殺手達成這個。 OOM 殺手只有在非常急迫的情況下纔會出動，那時系統已經處於極度不健康的 狀態了，而且很可能在這種狀態下保持了一陣子了。需要在開始考慮 OOM 殺手之前，積極地自己處理這種情況。\n不過，用傳統的 Linux 內存統計數據還是挺難判斷內存壓力的。我們有一些看起來相關的系統指標，但是都 只是支離破碎的——內存用量、頁面掃描，這些——單純從這些指標很難判斷系統是處於高效的內存利用率還是 在滑向內存競爭狀態。我們在 Facebook 有個團隊，由 Johannes 牽頭，努力開發一些能評價內存壓力的新指標，希望能在今後改善目前的現狀。 如果你對這方面感興趣， 在我的 cgroup v2 的演講中介紹到一個被提議的指標 。\n調優 那麼，我需要多少交換空間？ 通常而言，最優內存管理所需的最小交換空間取決於程序固定在內存中而又很少訪問到的匿名頁面的數量， 以及回收這些匿名頁面換來的價值。後者大體上來說是問哪些頁面不再會因爲要保留這些很少訪問的匿名頁面而 被回收掉騰出空間。\n如果你有足夠大的磁盤空間和比較新的內核版本（4.0+），越大的交換空間基本上總是越好的。 更老的內核上 kswapd ， 內核中負責管理交換區的內核線程，在歷史上傾向於有越多交換空間就 急於交換越多內存出去。在最近一段時間，可用交換空間很大的時候的交換行爲已經改善了很多。 如果在運行 4.0+ 以後的內核，即便有很大的交換區在現代內核上也不會很激進地做交換。因此， 如果你有足夠的容量，現代內核上有個幾個 GB 的交換空間大小能讓你有更多選擇。\n如果你的磁盤空間有限，那麼答案更多取決於你願意做的取捨，以及運行的環境。理想上應該有足夠的交換空間 能高效應對正常負載和高峰（內存）負載。我建議先用 2-3GB 或者更多的交換空間搭個測試環境， 然後監視在不同（內存）負載條件下持續一週左右的情況。只要在那一週裏沒有發生過嚴重的內存不足—— 發生了的話說明測試結果沒什麼用——在測試結束的時候大概會留有多少 MB 交換區佔用。 作爲結果說明你至少應該有那麼多可用的交換空間，再多加一些以應對負載變化。用日誌模式跑 atop 可以在 SWAPSZ 欄顯示程序的頁面被交換出去的情況，所以如果你還沒用它記錄服務器歷史日誌的話 ，這次測試中可以試試在測試機上用它記錄日誌。這也會告訴你什麼時候你的程序開始換出頁面，你可以用這個 對照事件日誌或者別的關鍵數據。\n另一點值得考慮的是交換空間所在存儲設備的媒介。讀取交換區傾向於很隨機，因爲我們不能可靠預測什麼時候 什麼頁面會被再次訪問。在 SSD 上這不是什麼問題，但是在傳統磁盤上，隨機 I/O 操作會很昂貴， 因爲需要物理動作尋道。另一方面，重新加載文件緩存可能不那麼隨機，因爲單一程序在運行期的文件讀操作 一般不會太碎片化。這可能意味着在傳統磁盤上你想更多地回收文件頁面而不是換出匿名頁面，但仍舊， 你需要做測試評估在你的工作負載下如何取得平衡。\n 譯註：關於休眠到磁盤時的交換空間大小\n原文這裏建議交換空間至少是物理內存大小，我覺得實際上不需要。休眠到磁盤的時候內核會寫回並丟棄 所有有文件作後備的可回收頁面，交換區只需要能放下那些沒有文件後備的頁面就可以了。 如果去掉文件緩存頁面之後剩下的已用物理內存總量能完整放入交換區中，就可以正常休眠。 對於桌面瀏覽器這種內存大戶，通常有很多緩存頁可以在休眠的時候丟棄。\n 對筆記本/桌面用戶如果想要休眠到交換區，這也需要考慮——這種情況下你的交換文件應該至少是物理內存大小。\n我的 swappiness 應該如何設置？ 首先很重要的一點是，要理解 vm.swappiness 是做什麼的。 vm.swappiness 是一個 sysctl 用來控制在內存回收的時候，是優先回收匿名頁面， 還是優先回收文件頁面。內存回收的時候用兩個屬性： file_prio （回收文件頁面的傾向） 和 anon_prio （回收匿名頁面的傾向）。 vm.swappiness 控制這兩個值， 因爲它是 anon_prio 的默認值，然後也是默認 200 減去它之後 file_prio 的默認值。 意味着如果我們設置 vm.swappiness = 50 那麼結果是 anon_prio 是 50， file_prio 是 150 （這裏數值本身不是很重要，重要的是兩者之間的權重比）。\n 譯註：關於 SSD 上的 swappiness\n原文這裏說 SSD 上 swap 和 drop page cache 差不多開銷所以 vm.swappiness = 100 。我覺得實際上要考慮 swap out 的時候會產生寫入操作，而 drop page cache 可能不需要寫入（ 要看頁面是否是髒頁）。如果負載本身對I/O帶寬比較敏感，稍微調低 swappiness 可能對性能更好， 內核的默認值 60 是個不錯的默認值。以及桌面用戶可能對性能不那麼關心，反而更關心 SSD 的寫入壽命，雖然說 SSD 寫入壽命一般也足夠桌面用戶，不過調低 swappiness 可能也能減少一部分不必要的寫入（因爲寫回髒頁是必然會發生的，而寫 swap 可以避免）。 當然太低的 swappiness 會對性能有負面影響（因爲太多匿名頁面留在物理內存裏而降低了緩存命中率） ，這裏的權衡也需要根據具體負載做測試。\n另外澄清一點誤解， swap 分區還是 swap 文件對系統運行時的性能而言沒有差別。或許有人會覺得 swap 文件要經過文件系統所以會有性能損失，在譯文之前譯者說過 Linux 的內存管理子系統基本上獨立於文件系統。 實際上 Linux 上的 swapon 在設置 swap 文件作爲交換空間的時候會讀取一次文件系統元數據， 確定 swap 文件在磁盤上的地址範圍，隨後運行的過程中做交換就和文件系統無關了。關於 swap 空間是否連續的影響，因爲 swap 讀寫基本是頁面單位的隨機讀寫，所以即便連續的 swap 空間（swap 分區）也並不能改善 swap 的性能。希疏文件的地址範圍本身不連續，寫入希疏文件的空洞需要 文件系統分配磁盤空間，所以在 Linux 上交換文件不能是希疏文件。只要不是希疏文件， 連續的文件內地址範圍在磁盤上是否連續（是否有文件碎片）基本不影響能否 swapon 或者使用 swap 時的性能。\n 這意味着，通常來說 vm.swappiness 只是一個比例，用來衡量在你的硬件和工作負載下， 回收和換回匿名內存還是文件內存哪種更昂貴 。設定的值越低，你就是在告訴內核說換出那些不常訪問的 匿名頁面在你的硬件上開銷越昂貴；設定的值越高，你就是在告訴內核說在你的硬件上交換匿名頁和 文件緩存的開銷越接近。內存管理子系統仍然還是會根據實際想要回收的內存的訪問熱度嘗試自己決定具體是 交換出文件還是匿名頁面，只不過 swappiness 會在兩種回收方式皆可的時候，在計算開銷權重的過程中左右 是該更多地做交換還是丟棄緩存。在 SSD 上這兩種方式基本上是同等開銷，所以設成 vm.swappiness = 100 （同等比重）可能工作得不錯。在傳統磁盤上，交換頁面可能會更昂貴， 因爲通常需要隨機讀取，所以你可能想要設低一些。\n現實是大部分人對他們的硬件需求沒有什麼感受，所以根據直覺調整這個值可能挺困難的 —— 你需要用不同的值做測試。你也可以花時間評估一下你的系統的內存分配情況和核心應用在大量回收內存的時候的行爲表現。\n討論 vm.swappiness 的時候，一個極爲重要需要考慮的修改是（相對）近期在 2012 年左右 Satoru Moriya 對 vmscan 行爲的修改 ，它顯著改變了代碼對 vm.swappiness = 0 這個值的處理方式。\n基本上來說這個補丁讓我們在 vm.swappiness = 0 的時候會極度避免掃描（進而回收）匿名頁面， 除非我們已經在經歷嚴重的內存搶佔。就如本文前面所屬，這種行爲基本上不會是你想要的， 因爲這種行爲會導致在發生內存搶佔之前無法保證內存回收的公平性，這甚至可能是最初導致發生內存搶佔的原因。 想要避免這個補丁中對掃描匿名頁面的特殊行爲的話， vm.swappiness = 1 是你能設置的最低值。\n內核在這裏設置的默認值是 vm.swappiness = 60 。這個值對大部分工作負載來說都不會太壞， 但是很難有一個默認值能符合所有種類的工作負載。因此，對上面「 那麼，我需要多少交換空間？ 」那段討論的一點重要擴展可以說，在測試系統中可以嘗試使用不同的 vm.swappiness ，然後監視你的程序和系統在重（內存）負載下的性能指標。在未來某天，如果我們在內核中有了合理的 缺頁檢測 ，你也將能通過 cgroup v2 的頁面缺頁 指標來以負載無關的方式決定這個。\nSREcon19 Asia/Pacific - Linux Memory Management at Scale: Under the Hood\n2019年07月更新：內核 4.20+ 中的內存壓力指標 前文中提到的開發中的內存缺頁檢測指標已經進入 4.20+ 以上版本的內核，可以通過 CONFIG_PSI=y 開啓。詳情參見我在 SREcon 大約 25:05 左右的討論。\n結論  交換區是允許公平地回收內存的有用工具，但是它的目的經常被人誤解，導致它在業內這種負面聲譽。如果 你是按照原本的目的使用交換區的話——作爲增加內存回收公平性的方式——你會發現它是很有效的工具而不是阻礙。 禁用交換區並不能在內存競爭的時候防止磁盤I/O的問題，它只不過把匿名頁面的磁盤I/O變成了文件頁面的 磁盤I/O。這不僅更低效，因爲我們回收內存的時候能選擇的頁面範圍更小了，而且它可能是導致高度內存競爭 狀態的元兇。 有交換區會導致系統更慢地使用 OOM 殺手，因爲在缺少內存的情況下它提供了另一種更慢的內存， 會持續地內存顛簸——內核調用 OOM 殺手只是最後手段，會晚於所有事情已經被搞得一團糟之後。 解決方案取決於你的系統：  你可以預先更具每個 cgroup 的或者系統全局的內存壓力改變系統負載。這能防止我們最初進入內存競爭 的狀態，但是 Unix 的歷史中一直缺乏可靠的內存壓力檢測方式。希望不久之後在有了 缺頁檢測 這樣的性能指標之後能改善這一點。 你可以使用 memory.low 讓內核不傾向於回收（進而交換）特定一些 cgroup 中的進程， 允許你在不禁用交換區的前提下保護關鍵後臺服務。    關於 swap 的一些補充 ","permalink":"https://sakamotokurome.github.io/posts/fedora/","summary":"[fəˈdɔrə] 费多拉 Fedora Linux 版本 Fedora 官方版本 Fedora 工作站是可以安装在笔记本电脑和台式电脑上的 Linux。 此版本附带 GNOME 作为默认桌面环境和各种标准应用","title":"Fedora"},{"content":"Backup Your System  Ubuntu Help Arch Wiki  Rsync 备份\n#!/bin/bash  set -o errexit set -o nounset set -o pipefail readonly SOURCE_DIR=/ readonly BACKUP_DIR=\u0026#34;$(findmnt -nr -o target -S /dev/mapper/luks-5277e33d-604f-4c1e-bc8c-40c14544614e)/Ubuntu2204\u0026#34; readonly DATETIME=\u0026#34;$(date \u0026#39;+%Y-%m-%d_%H:%M:%S\u0026#39;)\u0026#34; readonly BACKUP_PATH=\u0026#34;${BACKUP_DIR}/${DATETIME}\u0026#34; readonly LATEST_LINK=\u0026#34;${BACKUP_DIR}/latest\u0026#34; rsync -av \\ \t--delete \u0026#34;${SOURCE_DIR}/\u0026#34; \\ \t--link-dest \u0026#34;${LATEST_LINK}\u0026#34; \\ \t--exclude={\u0026#34;dev/*\u0026#34;,\u0026#34;proc/*\u0026#34;,\u0026#34;sys/*\u0026#34;,\u0026#34;tmp/*\u0026#34;,\u0026#34;run/*\u0026#34;,\u0026#34;mnt/*\u0026#34;,\u0026#34;media/*\u0026#34;,\u0026#34;lost+found/*\u0026#34;,\u0026#34;Trash/*\u0026#34;,\u0026#34;DataBackup/*\u0026#34;,\u0026#34;DataPool/*\u0026#34;,\u0026#34;swapfile\u0026#34;,\u0026#34;cxoffice\u0026#34;,\u0026#34;.cxoffice\u0026#34;,\u0026#34;*.iso\u0026#34;,\u0026#34;*.qcow2\u0026#34;,\u0026#34;.steam\u0026#34;,\u0026#34;Downloads/*\u0026#34;,\u0026#34;*.exe\u0026#34;,\u0026#34;Ventoy\u0026#34;,\u0026#34;Desktop/*\u0026#34;,\u0026#34;Music/*\u0026#34;,\u0026#34;.snapshots\u0026#34;,\u0026#34;Games\u0026#34;,\u0026#34;Pictures/*\u0026#34;,\u0026#34;Videos/*\u0026#34;,\u0026#34;.cache\u0026#34;} \\ \t\u0026#34;${BACKUP_PATH}\u0026#34; rm -rf \u0026#34;${LATEST_LINK}\u0026#34; ln -s \u0026#34;${BACKUP_PATH}\u0026#34; \u0026#34;${LATEST_LINK}\u0026#34; 注意：\n ${SOURCE_DIR}/必须带反斜杠，否则会备份SOURCE_DIR这个目录，而不是这个目录里的内容。 --exclude=\u0026quot;Trash\u0026quot;，Trash被认为为目录，而非文件或文件和目录，并且，它不支持路径~/.local/share/Trash 注意：正因为 --exclude 不是按照路径，所以才特别方便，比如 usb 在不同发行版之间可能会挂载到不同的路径（如 ubuntu 的会在 /media 下，fedora 的会在 /run 下），但是一般以 usb 的 label 比如 DataBackup 作为挂载目录，那么只需要把 DataBackup 放在 --exclude 之中，就可以在备份时排除这个 usb 设备而不需要考虑具体的路径了。  查看备份大小\n$ sudo du -hs /backup/ 16G /backup/ 整个备份为16GB，所花时间 12m。\n通过 crontab 使之每周一12点自动备份：\n$ sudo crontab -e 0 12 * * 1 /path/.backup.sh 还原\n分区、格式化和挂载\n# lsblk -f sda ├─sda1 │ vfat EFI A642-AF58 246.9M 2% /boot/efi └─sda2 ext4 ROOT c83192bb-14f3-45d1-9345-20785a419414 190.1G 8% / # mkdir -p /mnt/ubuntu # mount /dev/sda2 /mnt/ubuntu # mkdir -p /mnt/ubuntu/boot/efi # mount /dev/sda1 /mnt/ubuntu/boot/efi 还原：还原的时候，如果带 --delete，那么就会删除备份时 --exclude= 不包含的内容。还原的时候，同名文件内容会恢复到备份时候的状态。\n# rsync -av 备份目录 源目录 # rsync -av /path/to/backup/latest/ /mnt/ubuntu   chroot\n# mount --types proc /proc /mnt/ubuntu/proc # mount --rbind /sys /mnt/ubuntu/sys # mount --make-rslave /mnt/ubuntu/sys # mount --rbind /dev /mnt/ubuntu/dev # mount --make-rslave /mnt/ubuntu/dev # mount --bind /run /mnt/ubuntu/run # mount --make-slave /mnt/ubuntu/run # chroot /mnt/ubuntu   update /etc/fstab\n# blkid /dev/sda2: LABEL=\u0026#34;ROOT\u0026#34; UUID=\u0026#34;c83192bb-14f3-45d1-9345-20785a419414\u0026#34; TYPE=\u0026#34;ext4\u0026#34; PARTUUID=\u0026#34;4659f9ec-1e96-4d4a-ad0e-e32a69a477ce\u0026#34; /dev/sda1: LABEL_FATBOOT=\u0026#34;EFI\u0026#34; LABEL=\u0026#34;EFI\u0026#34; UUID=\u0026#34;A642-AF58\u0026#34; TYPE=\u0026#34;vfat\u0026#34; PARTUUID=\u0026#34;4bf5d597-b541-e845-8b70-c8ad6374df22\u0026#34; fstab 模版如下\n# ROOT UUID=c83192bb-14f3-45d1-9345-20785a419414 / ext4 errors=remount-ro 0 1 # EFI UUID=A642-AF58 /boot/efi vfat umask=0077 0 1 # SWAP UUID=63c78f3a-91ab-43f2-bf97-6e3348e0fc00 none swap default 0 0 # swapfile /swapfile none swap sw 0 0   reinstall grup\n# grub-install --target=x86_64-efi --efi-directory=/boot/efi # grub-mkconfig -o /boot/grub/grub.cfg 不能带 \u0026ndash;bootloader-id=GRUB，否则建立 /boot/efi/EFI/GRUB 目录。\n  reboot\n# exit # cd # umount -l /mnt/ubuntu/dev{/shm,/pts,} # umount -R /mnt/ubuntu # reboot    TAR Backup\n$ cd / # THIS CD IS IMPORTANT THE FOLLOWING LONG COMMAND IS RUN FROM / $ tar -cvpzf backup.tar.gz \\ --exclude=/backup.tar.gz \\ --exclude=/proc \\ --exclude=/tmp \\ --exclude=/mnt \\ --exclude=/dev \\ --exclude=/sys \\ --exclude=/run \\  --exclude=/media \\  --exclude=/var/log \\ --exclude=/var/cache/apt/archives \\ --exclude=/usr/src/linux-headers* \\  --exclude=/home/*/.gvfs \\ --exclude=/home/*/.cache \\  --exclude=/home/*/.local/share/Trash / deja-dup/Duplicity Simple backup tool for GNOME\nconfig files\nThe deja-dup settings can also be changed with dconf-editor in the dconf-tools apt package. The settings are in org.gnome.DejaDup.\n$ gsettings list-recursively org.gnome.DejaDup $ gsettings set org.gnome.DejaDup include-list \u0026#34;[\u0026#39;/home/kurome/.aria2\u0026#39;, \u0026#39;/home/kurome/.clash\u0026#39;, \u0026#39;/home/kurome/.config/autostart\u0026#39;, \u0026#39;/home/kurome/.config/Typora\u0026#39;, \u0026#39;/home/kurome/.config/variety\u0026#39;, \u0026#39;/home/kurome/.hugo\u0026#39;, \u0026#39;/home/kurome/.local/bin\u0026#39;, \u0026#39;/home/kurome/.local/share/applications\u0026#39;, \u0026#39;/home/kurome/.local/share/TelegramDesktop\u0026#39;, \u0026#39;/home/kurome/.ssh\u0026#39;, \u0026#39;/home/kurome/.telegram\u0026#39;, \u0026#39;/home/kurome/.typora\u0026#39;, \u0026#39;/home/kurome/Documents\u0026#39;, \u0026#39;/home/kurome/Downloads\u0026#39;, \u0026#39;/home/kurome/Templates\u0026#39;, \u0026#39;/home/kurome/Music\u0026#39;, \u0026#39;/home/kurome/.config/containers\u0026#39;, \u0026#39;/home/kurome/.local/share/fcitx5\u0026#39;]\u0026#34; from: launchpad.net: How do I also backup my deja Dup settings?\nThe settings used to be stored there, and the files are still present.\nIn more recent version they are stored in:\n~/.config/dconf Resotre\n$ duplicity file:///home/kurome/DataBackup/Linux/ Restore/ Others Does the UEFI partition either \u0026ldquo;MUST\u0026rdquo; or \u0026ldquo;SHOULD\u0026rdquo; be first for some reason? If so why?\nThe key words \u0026ldquo;SHOULD\u0026rdquo;, \u0026ldquo;MUST\u0026rdquo; and \u0026ldquo;MAY\u0026rdquo; (capitalised) in this answer are to be interpreted as described in RFC 2119.\nAn (U)EFI System Partition (ESP from now on):\n MAY reside at the beginning of the disk and SHOULD be FAT32 because of Windows compatibility.  The only official limit is:\n the ESP MUST reside in the first 2.2 Terabytes of the disk.  So, the ESP MUST reside anywhere in those first 2.2 TB of the disk, but there is absolutely no need for the ESP to be the first partition or reside on the beginning of the disk whatsoever. (It\u0026rsquo;s just that some large company in Redmond, WA advises system integrators differently)\u0026hellip;\nI would put it as the last partition on the disk (if \u0026lt; 2.2TB) as it\u0026rsquo;s only used to load other OSes, but that\u0026rsquo;s just a personal, totally subjective opinion!\nAdd Boot Option Manually\nIn Boot Option Name, type Ubuntu, and in File Name select the file grubx64.efi and then Click on \u0026lsquo;OK\u0026rsquo;.\n13 个开源备份解决方案\n  Cronopete\n  Deja Dup\n  Rclone\n  Rdiff-backup\n  Restic\n  Rsync\n  BorgBackup：带有压缩和加密特性以用具有数据去重功能的备份解决方案。它基于 BSD 许可证，支持 Linux、MacOS 和 BSD。\n  UrBackup：它可以做镜像和文件的完整和增量备份；你可以保存整个分区或单个目录。它有 Windows、Linux、和 MacOS 客户端，并且采用 GNU Affero 公共许可证。\n  LuckyBackup：根据其网站介绍，“它是一个易于使用、快速（只传输变化部分，而不是全部数据）、安全（在做任何数据操作之前，先检查所有需要备份的目录，以确保数据安全）、可靠和完全可定制的备份解决方案。它在 GPL 许可证下发行。\n  Casync ：一个可寻址内容的同步解决方案 —— 它设计用于备份、同步、存储和检索大文件系统的多个相关版本。它使用 GNU Lesser 公共许可证。\n  Syncthing：用于在两台计算机之间同步文件。它基于 Mozilla 公共许可证使用，根据其网站介绍，它是安全和私密的。它可以工作于 MacOS、Windows、Linux、FreeBSD、Solaris 和 OpenBSD。\n  Duplicati：一个可工作于 Windows、MacOS 和 Linux 上的、并且支持多种标准协议（比如 FTP、SSH、WebDAV 和云服务）、免费的备份解决方案。它的特性是强大的加密功能，并且它使用 GPL 许可证。\n  Dirvish ：一个基于磁盘的虚拟镜像备份系统，它使用 OSL-3.0 许可证。它要求必须安装有 Rsync、Perl5、SSH。\n  Bacula：允许系统管理员去管理备份、恢复、和跨网络的不同种类计算机上的多种数据的一套计算机程序，它支持在 Linux、FreeBSD、Windows、MacOS、OpenBSD 和 Solaris 上运行，并且它的大部分源代码都是基于 AGPLv3 许可证的。\n  BackupPC：一个高性能的、企业级的、可以备份 Linux、Windows 和 MacOS 系统的 PC 和笔记本电脑上的数据到服务器磁盘上的备份解决方案。它是基于 GPLv3 许可证的。\n  Amanda ：一个使用 C 和 Perl 写的备份系统，它允许系统管理员去备份整个网络中的客户端到一台服务器上的磁带、磁盘或基于云的系统。它是由马里兰大学于 1991 年开发并拥有版权，并且它有一个 BSD 式的许可证。\n  Back in Time ：一个为 Linux 设计的简单的备份实用程序。它提供了命令行和图形用户界面，它们都是用 Python 写的。去执行一个备份，只需要指定存储快照的位置、需要备份的文件夹，和备份频率即可。它使用的是 GPLv2 许可证。\n  Timeshift ：一个 Linux 上的备份实用程序，它类似于 Windows 上的系统恢复和 MacOS 上的时间胶囊。它的 GitHub 仓库上介绍说：“Timeshift 通过定期递增的文件系统快照来保护你的系统。这些快照可以在日后用于数据恢复，以撤销某些对文件系统的修改。”\n  Kup ：一个能够帮助用户备份它们的文件到 USB 驱动器上的备份解决方案，但它也可以用于执行网络备份。它的 GitHub 仓库上介绍说：”当插入你的外部硬盘时，Kup 将自动启动并复制你的最新的修改。“\n  How to make a disk image and restore from it later?/Moving entire Linux installation to another drive\nIt\u0026rsquo;s Clonezilla(再生龍) Live: http://clonezilla.org/\nThe tutorial for Clonezilla can be found here.\nEasy backup/restore of installed system?\nYes you can use remastersys for that.You can see a complete tutorial here\nrsync+btrfs+dm-crypt 备份整个系统\nReinstall GRUB\n清理系统 删除不再需要的包 $ sudo apt autoremove APT cache # see the size of this cache $ sudo du -sh /var/cache/apt # remove only the outdated packages $ sudo apt-get autoclean # delete apt cache in its entirety $ sudo apt-get clean apt-get 和软件中心下载的软件包一般放在 /var/cache/apt/archives/ 目录，一般都安装在 /usr/\nJournal logs # check the log size $ journalctl --disk-usage # clear the logs that are older than a certain days $ journalctl --vacuum-time=3d Thumbnails cache # check the size of thumbnail cache $ du -sh ~/.cache/thumbnails $ rm -rf ~/.cache/thumbnails/* Duplicate files Find and remove duplicate files：You can use a GUI tool like FSlint or a command line tool like FDUPES for this task\nOld Linux kernels Remove old Linux kernels\n# List all installed Linux kernels $ sudo dpkg --list \u0026#39;linux-image*\u0026#39; $ apt-get remove linux-image-VERSION 清理 Snap 与 snap 有关的系统文件都存放在 /var/lib/snapd 目录下。根据你所安装的 Snap 包的数量，这个目录的大小可能在几 GB。\n$ sudo du -sh /var/lib/snapd 根据设计，Snap 至少会在你的系统上保留一个你所安装的软件包的旧版本。你可以通过使用 Snap 命令看到这种行为：\n$ snap list --all 你应该看到同一个软件包被列了两次，而且版本和修订号都不同。\n为了释放磁盘空间，你可以删除额外的软件包版本。你怎么知道要删除哪一个呢？你可以看到，这些较旧的软件包被标记为“禁用”。\n#!/bin/bash # Removes old revisions of snaps # CLOSE ALL SNAPS BEFORE RUNNING THIS set -eu snap list --all | awk \u0026#39;/disabled/{print $1, $3}\u0026#39; | while read snapname revision; do snap remove \u0026#34;$snapname\u0026#34; --revision=\u0026#34;$revision\u0026#34; done 命令行技巧 Bash 快捷键 编辑命令\n Ctrl + a ：移到命令行首 Ctrl + e ：移到命令行尾 Ctrl + f ：按字符前移（右向） Ctrl + b ：按字符后移（左向） Alt + f ：按单词前移（右向） Alt + b ：按单词后移（左向） Ctrl + xx：在命令行首和光标之间移动 Ctrl + u ：从光标处删除至命令行首 Ctrl + k ：从光标处删除至命令行尾 Ctrl + w ：从光标处删除至字首 Alt + d ：从光标处删除至字尾 Ctrl + d ：删除光标处的字符 Ctrl + h ：删除光标前的字符 Ctrl + y ：粘贴至光标后 Alt + c ：从光标处更改为首字母大写的单词 Alt + u ：从光标处更改为全部大写的单词 Alt + l ：从光标处更改为全部小写的单词 Ctrl + t ：交换光标处和之前的字符 Alt + t ：交换光标处和之前的单词 Alt + Backspace：与 Ctrl + w 类似，分隔符有些差别  重新执行命令\n Ctrl + r：逆向搜索命令历史 Ctrl + g：从历史搜索模式退出 Ctrl + p：历史中的上一条命令 Ctrl + n：历史中的下一条命令 Alt + .：使用上一条命令的最后一个参数  控制命令\n Ctrl + l：清屏 Ctrl + o：执行当前命令，并选择上一条命令 Ctrl + s：阻止屏幕输出 Ctrl + q：允许屏幕输出 Ctrl + c：终止命令 Ctrl + z：挂起命令  Bang (!) 命令\n !!：执行上一条命令 !blah：执行最近的以 blah 开头的命令，如 !ls !blah:p：仅打印输出，而不执行 !$：上一条命令的最后一个参数，与 Alt + . 相同 !$:p：打印输出 !$ 的内容 !*：上一条命令的所有参数 !*:p：打印输出 !* 的内容 ^blah：删除上一条命令中的 blah ^blah^foo：将上一条命令中的 blah 替换为 foo ^blah^foo^：将上一条命令中所有的 blah 都替换为 foo  你可能不知道的SHELL Shell也叫做命令行界面，它是*nix操作系统下用户和计算机的交互界面。Shell这个词是指操作系统中提供访问内核服务的程序。\n这篇文章向大家介绍Shell一些非广为人知、但却实用有趣的知识，权当品尝shell主食后的甜点吧。\n科普\n先科普几个你可能不知道的事实：\n  Shell几乎是和Unix操作系统一起诞生，第一个Unix Shell是肯·汤普逊（Ken Thompson）以Multics上的Shell为模范在1971年改写而成，并命名Thompson sh。即便是后来流行的bash（shell的一种变体），它的年龄实际上比当前流行的所有的Linux kernel都大，可谓在Linux系统上是先有Shell再有Kernel。\n  当前绝大部分*nix和MacOS操作系统里的默认的Shell都是bash，bash由Brian Fox在1987年创造，全称Bourne Again shell ( bash)。\n  你或许听说除了bash之外，还有Bourne shell ( sh)，Korn shell ( ksh)，C shell （包括 csh and tcsh），但是你知道这个星球上一共存在着大约50多种不同的shell么？想了解他们，请参考 http://www.freebsd.org/ports/shells.html。\n  一些强大的命令\n  在命令行前加空格，该命令不会进入history里。\n  ctrl-x e\n快速启动你的默认编辑器（由变量$EDITOR设置）。\n  为什么说 zsh 是 shell 中的极品？ 色彩高亮\n并不是传统基于正则表达式的色彩高亮，而是真的会判断你输入的是啥的色彩高亮。\n比如一个主题白色代表普通命令或者程序，红色代表错误命令，青色的代表内建命令或者 alias （echo 和 ls ），这些都不是正则判断出来的，是真的去检查的。非零的错误码（上一条命令错误），也可以高亮显示。\n命令提示\n注意，命令提示和补全是两个完全不同的系统，很多时候提示比补全更有用。你输入命令，后面就用灰色给你提示命令的参数，而且是随着你动态输入完每一个字母不断修正变化。\n这个命令提示是基于你的历史命令数据库进行分析的，随着你输入的命令越来越多，提示将会越来越准确和顺手。\n如果你觉得它提示的正确，你可以 CTRL+F 表示采纳，后面就会自动帮你一次性全部输入完了。\n智能补全\n缩写路径补全：\n$ cd /v/w/h 敲一个TAB\n$ cd /var/www/html/ 补全目录、命令参数补全连敲两次TAB进入选择模式，除了 tab/shift+tab 可以前后切换外，你还可以使用光标键上下左右移动。回车表示确认选择，用 CTRL+G 表示退出。\n快速跳转\n输入 cd 后面加一个减号后，按一次 tab 马上就列出本次登陆后去过的最近几次路径，接着根据下面的提示输入数字按回车就过去了，比如输入：\n$ cd -5 \u0026lt;回车\u0026gt; 当然你还可以不输入数字，而是再按一次 tab 进入选择模式，上下键或者 ctrl+n/p 来选择，回车确认，ctrl+g 返回。\n自动跳转\n敲入 z 命令，列出了自从我开始用zsh进入过的目录和他们的权重，进入次数越多，权重越大。z 后面加一个关键词就能跳转到所有匹配的历史路径中权重最高的那个了。空格分隔多个关键字，z会先匹配出第一个来，然后再匹配第二个\u0026hellip;\n使用：“z -l foo\u0026quot; 可以列出包含 foo 的所有历史路径。\n# 按下ALT+O 就执行 cd .. 命令 bindkey -s \u0026#39;\\eo\u0026#39; \u0026#39;cd ..\\n\u0026#39; # 按下 ALT+; 就执行 ls -l 命令 bindkey -s \u0026#39;\\e;\u0026#39; \u0026#39;ls -l\\n\u0026#39; 热键绑定\nzsh 里面使用 bindkey 命令可以设置一系列热键，用来运行某一个 zsh 内部命令或者某个 shell 命令。\n应该知道的LINUX技巧 首先，我想告诉大家，在Unix/Linux下，最有效率技巧的不是操作图形界面，而是命令行操作，因为命令行意味着自动化。\n日常\n  请man bash后查找Readline Key Bindings一节来看看bash的默认热键，比如：Alt-. 把上一次命令的最后一个参数打出来，而Alt-* 则列出你可以输入的命令。\n  回到上一次的工作目录： cd – （回到home是 cd ~）\n  pstree -p 可以帮你显示进程树。\n  使用 pgrep 和 pkill 来找到或是kill 某个名字的进程。 (-f 选项很有用).\n  通过 \u0026lt;(some command) 可以把某命令当成一个文件。示例：比较一个本地文件和远程文件 /etc/hosts： diff /etc/hosts \u0026lt;(ssh somehost cat /etc/hosts)\n  在 bash中，使用重定向到标准输出和标准错误。如： some-command \u0026gt;logfile 2\u0026gt;\u0026amp;1。\n  使用 man ascii 来查看 ASCII 表。\n  系统调试\n  如果你想知道磁盘、CPU、或网络状态，你可以使用 iostat, netstat, top (或更好的 htop), 还有 dstat 命令。你可以很快地知道你的系统发生了什么事。关于这方面的命令，还有iftop, iotop等。\n  要了解内存的状态，你可以使用free和vmstat命令。具体来说，你需要注意 “cached” 的值，这个值是Linux内核占用的内存。还有free的值。\n  如果你要找到哪个socket或进程在使用网络带宽，你可以使用 iftop 或 nethogs。\n  如果你要抓网络包的话，试试 wireshark 或 tshark。\n  了解 strace 和 ltrace。这两个命令可以让你查看进程的系统调用，这有助于你分析进程的hang在哪了，怎么crash和failed的。你还可以用其来做性能profile，使用 -c 选项，你可以使用-p选项来attach上任意一个进程。\n  了解用ldd命令来检查相关的动态链接库。注意：ldd的安全问题\n  使用gdb来调试一个正在运行的进程或分析core dump文件。参看我写的《GDB中应该知道的几个调试方法》\n  学会到 /proc 目录中查看信息。这是一个Linux内核运行时记录的整个操作系统的运行统计和信息，比如： /proc/cpuinfo, /proc/xxx/cwd, /proc/xxx/exe, /proc/xxx/fd/, /proc/xxx/smaps.\n  如果你调试某个东西为什么出错时，sar命令会有用。它可以让你看看 CPU, 内存, 网络, 等的统计信息。\n  使用 dmesg 来查看一些硬件或驱动程序的信息或问题。\n  powerline-shell 不想每次都安装 zsh 与 ohmyzsh？\n$ pip install powerline-shell Add the following to your .bashrc file:\nfunction _update_ps1() { PS1=$(powerline-shell $?) } if [[ $TERM != linux \u0026amp;\u0026amp; ! $PROMPT_COMMAND =~ _update_ps1 ]]; then PROMPT_COMMAND=\u0026#34;_update_ps1; $PROMPT_COMMAND\u0026#34; fi 默认的话，路径会完整显示，会很长\ngenerate the default config at this location using:\n$ mkdir -p ~/.config/powerline-shell \u0026amp;\u0026amp; \\ powerline-shell --generate-config \u0026gt; ~/.config/powerline-shell/config.json Segment Configuration\n{ \u0026#34;segments\u0026#34;: [ \u0026#34;virtual_env\u0026#34;, \u0026#34;username\u0026#34;, \u0026#34;hostname\u0026#34;, \u0026#34;ssh\u0026#34;, \u0026#34;cwd\u0026#34;, \u0026#34;git\u0026#34;, \u0026#34;hg\u0026#34;, \u0026#34;jobs\u0026#34;, \u0026#34;root\u0026#34; ], + \u0026#34;cwd\u0026#34;: + { + \u0026#34;max_depth\u0026#34;: 1 + } } 检测硬盘坏道和坏块 硬盘坏道分为物理坏道和逻辑坏道。\n 物理坏道：就是硬盘实体有坏的地方，物理坏道推荐换硬盘，当然也有办法重新分区来隔离坏道，不过可能也用不久，所以不推荐。 逻辑坏道：是磁盘磁道上面的校验信息（ECC）跟磁道的数据对不上号所致。出现这一故障的原因，通常都是因为一些程序的错误操作或是该处扇区的磁介质开始出现不稳定的先兆。物理坏道也是逻辑坏道产生的一种原因。  发现 dmesg：当有硬盘坏道时，通常在dmesg输出的信息中会有 Buffer I/O Error，所以经常检查dmesg的输出可以及时发现是否存在硬盘问题。\n检测 通过fdisk 查看显示所有磁盘或闪存的信息\n$ sudo fdisk -l /dev/sd* 使用 badlocks检查 linux 硬盘上的坏道/坏块\n$ sudo badblocks -s -v /dev/sdb \u0026gt; badsectors.txt 修复 查看上述分区检查出来的坏道信息\n$ tail -f badsectors.txt 先备份数据再修复磁盘。硬盘在使用时不能修复，否则可能存在写并发的问题，所以修复前需要umount对应分区,或使用 Live CD\n$ sudo umount MountPoint umount 分区成功后，修复命令如下，其中-w表示写入修复的，后面是结束（END）和开始（START）块号，注意END在前，START在后。\n$ sudo badblocks -s -w /dev/sdb 205971590 205971595 修复后再次检查\n$ sudo badblocks -s -v /dev/sdb 205971590 205971595 屏蔽 执行e2fsck（针对 ext2/ext3/ext4 文件系统）或fsck命令，命令中还需要用到 badsectors.txt 文件和设备文件。\n# for ext2/ext3/ext4 $ sudo e2fsck -l badsectors.txt /dev/sdb # others $ sudo fsck -l badsectors.txt /dev/sdb 如何探索 從「指令」找到「使用說明」\n找使用說明\n$ man -f ls 閱讀使用說明\n$ man ls $ man 1 ls # 若是「bash」內建的指令，則是可以使用「help」 $ help if 上面的「man 1 ls」，「1」指的是「Manpage Sections」。\n執行下面指令可以看到各個「Section」的簡介。\n$ whatis intro 然後分別執行下面的指令，可以閱讀更詳細的說明\n$ man 1 intro $ man 2 intro $ man 3 intro $ man 4 intro $ man 5 intro $ man 6 intro $ man 7 intro $ man 8 intro 從「指令」找到「所屬套件」\n先透過「whereis」來找到「ls」所在的確切路徑。\n$ whereis ls ls: /bin/ls 然後根據這個結果，再執行下面的指令\n$ rpm -qf /bin/ls $ dpkg -S /bin/ls coreutils-8.32-1.2.x86_64 找「已安裝套件」的「檔案列表」\n$ rpm -ql coreutils $ dpkg -L coreutils 包管理相关 Better output for apt upgrade You can get this better output by asking for more verbose version output (-V, --verbose-versions, see man apt-get).\nfucked up 执行snap list可查看被snap化的应用：\n core18 是 snap 应用的运行环境 snap-store 是 ubuntu snap 应用商店 snapd 自然不用多说，是snap负责管理应用的daemon gtk-common-themes, 只是为了使 snap 化的应用样式保持一致。 gnome-3-34-1804：This snap includes a GNOME 3.28 stack (the base libraries and desktop integration components) and shares it through the content interface.  看看 mount 的结果，你会发现这些应用居然是以squashfs文件系统打包的，然后解包就是一个将squashfs的文件挂载为一个loop设备：\n$ df -t squashfs snap后的程序有两大问题：\n 一是慢，虽然Ubuntu官方宣称 snap 速度已经相比之前提升了几倍，但是，老灯同时在用Fedora 32, 所有程序打开流畅无比。但是 Ubuntu 20.04 下启动或关闭程序一些程序是能感受到明显的卡顿。这个卡顿在1秒以上。 二是体积大。其打包的app体积，相比于AppImage 或 Flatpak, 也是大很多。以Corebird这个应用为例，snap 112MB, deb 2MB, Flatpak 12MB (参考 Snappy Sceptic Files Bug to Ask Why It Even Exists 一文).  Extract a .deb file Download .deb package\n$ apt download nginx Extract .deb package using ar command\nYou can use the ar command to extract .deb file too. The syntax is:\n$ ar x {file.deb} Extract .deb package using dpkg-deb command\nYou can use the dpkg-deb command to extract .deb file too. The syntax is:\n$ dpkg-deb -xv {file.deb} {/path/to/where/extract} Get packages url using apt Not all installed packages will have a URL associated with them, of course. However, you could use apt-get dowload:\n$ apt-get download --print-uris wget \u0026#39;http://archive.ubuntu.com/ubuntu/pool/main/w/wget/wget_1.15-1ubuntu1.14.04.2_amd64.deb\u0026#39; wget_1.15-1ubuntu1.14.04.2_amd64.deb 270522 SHA256:a3f3b049ea373402236a804a5a0952c6ef9b356ba8cc19fbc1f257db6e8f3052 This is the candidate version as shown by apt-cache policy, which might not necessarily be the installed version.\nDebian 档案库基础 对于典型的 HTTP 访问，档案库在 “/etc/apt/sources.list” 文件中像下面那样指定，例如，现在 stable = bullseye 系统。\ndeb http://deb.debian.org/debian/ bullseye main contrib non-free deb-src http://deb.debian.org/debian/ bullseye main contrib non-free 这里，我倾向于使用代号 “bullseye” 来代替套件名 “stable” ，以避免下一个 stable 版本发布时出现意外。\n“/etc/apt/sources.list” 的含义在 sources.list(5) 中进行了描述，下面是一些要点。\n “deb” 的那行定义了二进制软件包。 “deb-src” 的那行定义了源代码软件包。 第一个参数是 Debian 档案库的根 URL 。 第二个参数是发行版名称：可以使用套件名或代号。 第三个和之后的参数是 Debian 档案库的有效档案库范围名称。  Debian 档案库中的那些目录都是干什么用的？\n dists 目录是“distributions”的缩写，它是访问当前可用的 Debian 发布版本（和预发布版本）的正统方式。 pool 目录：软件包位于一个很大的“池（pool）”中，依源码包的名称进行组织。为了便于管理，pool 按照区（“main”、“contrib”和“non-free”）和源码包名的首字母进行分类。这些目录包括一些文件：每个架构的二进制软件包，以及用于生成这些二进制软件包的源码包。  总结\n一个套件的下载链接：\n[根URL]pool/[有效档案库范围名称]/[套件名首字母]/[套件名]/[套件下载档案] 例如 google chrome的仓库定义是\ndeb [arch=amd64] https://dl.google.com/linux/chrome/deb/ stable main 下载链接是\nhttps://dl.google.com/linux/chrome/deb/pool/main/g/google-chrome-stable/google-chrome-stable_104.0.5112.101-1_amd64.deb Find the package that provides a file   use the tool apt-file\n$ sudo apt-get install apt-file $ sudo apt-file update $ apt-file search libstdc++.so.6 $ apt-file find kwallet.h   You can search it in Google directly\n  Use apt search for package name only By default, apt search command looks for the searched term in both the name of the package and its description.\nYou may narrow down the search by instructing the apt command to search for package names only.\n$ apt search --names-only search_term 压缩相关 为什么 Linux 要用 tar.gz，很少用 7Z 或 ZIP？ 因为 7z 和 zip 压缩格式都不能保留 unix 风格的文件权限，比如解压出个可执行文件要重新 chmod chown 才能恢复正常。而 tar 格式可以。而 tar 本身不提供压缩，无非就是把包括所有文件的內容和权限拼成一个文件而己，所以用另外如 gzip 格式压缩。为什么是 gzip，因为几乎所有 linux 都支持而已。\nextract a specific file from a tar archive Yes, just give the full stored path of the file after the tarball name.\nExample: suppose you want file etc/apt/sources.list from etc.tar:\n$ tar -xf etc.tar etc/apt/sources.list 解压zip 如果解压中文乱码：\n$ unzip -O CP936 xxx.zip CP936其实就是GBK，IBM在发明Code Page的时候将GBK放在第936页，所以叫CP936。\n注意：有些名为 *.rar 文件其实是 zip 文件，直接用 nautilus 解压会乱码，可以用 file filename.rar 确认一下，使用 unzip 解压。\n常见国家的编码 韩文编码\n1.EUC_KR：用来储存韩国KSX1001字集(旧称KSC5601)的字符。此规格由KSX2901(旧称KS C 5861)定义。\nKS X 1001字元使用两个字节来表示： “高位字节”使用0xA1-0xFE，“低位字节”使用0xA1-0xFE\n日文编码\n1.Shift_JIS ：是一个日本电脑系统常用的编码表。它能容纳全角及半角拉丁字母、平假名、片假名、符号及日语汉字。它被命名为Shift_JIS的原因，是它在放置全角字符时，要避开原本在0xA1-0xDF放置的半角假名字符。在微软及IBM的日语电脑系统中，即使用了这个编码表。这个编码表称为CP932。\n2.EUC_JP：用来存储日本JISx0208以及JISx0212的字集的字符，但日文文字较多使用ISO-2022-JP或Shift_JIS的方法来表示。\n俄文编码\n1.KOI8-R：KOI-8系列的斯拉夫文字8位元编码，供俄语及保加利亚语使用。\n常见字符编码 ASCII\nASCII是美国(国家)信息交换标准(代)码，一种使用7个或8个二进制位进行编码的方案，最多可以给256(2^80)个字符 (包括字母、数字、标点符号、控制字符及其他符号)分配(或指定)数值。基本的 ASCII 字符集共有 128 个字符，其中有 96 个可打印字符，包括常用的字母、数字、标点符号等，另外还有 32 个控制字符。\n文件中每一个字都是美标形象码或空格码，这类文件称为“美标文本文件”，或略为“文本文件”，通常可在不同电脑系统间直接交换。 文件中含有控制码或非美标码的文件，通常不能在不同电脑系统间直接交换。这类文件有一个通称，叫“二进制文件”\nANSI\n为了扩充ASCII编码，以用于显示本国的语言，不同的国家和地区制定了不同的标准，由此产生了GB2312, BIG5, JIS 等各自的编码标准。这些使用 2 个字节来代表一个字符的各种汉字延伸编码方式，称为 ANSI 编码，又称为MBCS（Muilti-Bytes Charecter Set，多字节字符集）。在简体中文系统下，ANSI 编码代表 GB2312 编码，在日文操作系统下，ANSI 编码代表 JIS 编码，所以在中文 windows下要转码成GB2312,GBK(gb2312的扩展)只需要把文本保存为ANSI 编码即可。 不同 ANSI 编码之间互不兼容，当信息在国际间交流时，无法将属于两种语言的文字，存储在同一段 ANSI 编码的文本中。一个很大的缺点是，同一个编码值，在不同的编码体系里代表着不同的字。这样就容易造成混乱\nGB2312\nGB2312是ANSI编码里的一种，对ANSI编码最初始的ASCII编码进行扩充，为了满足国内在计算机中使用汉字的需要，中国国家标准总局发布了一系列的汉字字符集国家标准编码，统称为GB码，或国标码。其中最有影响的是于1980年发布的《信息交换用汉字编码字符集 基本集》，标准号为GB 2312-1980,因其使用非常普遍，也常被通称为国标码。GB2312编码通行于我国内地；新加坡等地也采用此编码。几乎所有的中文系统和国际化的软件都支持GB2312。 GB2312是一个简体中文字符集，由6763个常用汉字和682个全角的非汉字字符组成\nGBK\nGB 2312的出现，基本满足了汉字的计算机处理需要，但对于人名、古汉语等方面出现的罕用字，GB 2312不能处理，这导致了后来GBK及GB 18030汉字字符集的出现 GBK共收入21886个汉字和图形符号，其中汉字（包括部首和构件）21003个，图形符号883个。GBK编码标准兼容GB2312，共收录汉字21003个、符号883个，并提供1894个造字码位，简、繁体字融于一库。GB2312码是中华人民共和国国家汉字信息交换用编码，全称《信息交换用汉字编码字符集——基本集》，1980年由国家标准总局发布。基本集共收入汉字6763个和非汉字图形字符682个，通行于中国大陆。新加坡等地也使用此编码。GBK是对GB2312-80的扩展.\nBig5\n在台湾、香港与澳门地区，使用的是繁体中文字符集。而1980年发布的GB2312面向简体中文字符集，并不支持繁体汉字。在这些使用繁体中文字符集的地区，一度出现过很多不同厂商提出的字符集编码，这些编码彼此互不兼容，造成了信息交流的困难。为统一繁体字符集编码，1984年，台湾五大厂商宏碁、神通、佳佳、零壹以及大众一同制定了一种繁体中文编码方案，因其来源被称为五大码，英文写作Big5，后来按英文翻译回汉字后，普遍被称为大五码。大五码是一种繁体中文汉字字符集，其中繁体汉字13053个，808个标点符号、希腊字母及特殊符号。\nunicode\n为什么电子邮件和网页都经常会出现乱码，就是因为信息的提供者可能是日文的ANSI编码体系和信息的读取者可能是中文的编码体系，他们对同一个二进制编码值进行显示，采用了不同的编码，导致乱码。这个问题促使了unicode码的诞生。 如果有一种编码，将世界上所有的符号都纳入其中，无论是英文、日文、还是中文等，大家都使用这个编码表，就不会出现编码不匹配现象。每个符号对应一个唯一的编码，乱码问题就不存在了。这就是Unicode编码。\nunicode，中文叫万国码，统一码，是统一码联盟为了世界上大多数文字系统进行整理和编码。 和unicode类似，iso组织也在做同样的事情，iso开展了 ISO/IEC 10646项目，名字叫“ Universal Multiple-Octet Coded Character Set”，简称UCS。 后来，双方意识到时间上不需要2套通用的字符集，所以双方开始进行整合，到unicode2.0时，unicode的编码和ucs的编码都基本一致。 但是又略有不同。\nUnicode深入人心，且UTF-8(Unicode中的一种)大行其道，UCS编码基本被等同于UTF-16，UTF-32了，所以目前UCS基本谈出人们的视野中。\nUTF-8\nUnicode固然统一了编码方式，但是它的效率不高，比如UCS-4(Unicode的标准之一)规定用4个字节存储一个符号，那么每个英文字母前都必然有三个字节是0，这对存储和传输来说都很耗资源。 为了提高Unicode的编码效率，于是就出现了UTF-8编码。UTF-8可以根据不同的符号自动选择编码的长短。比如英文字母可以只用1个字节就够了。\nUTF-16\nUTF-16是Unicode的其中一个使用方式,UTF-16比起UTF-8，好处在于大部分字符都以固定长度的字节 (2字节) 储存，但UTF-16却无法兼容于ASCII编码。\nBase64\n有的电子邮件系统(比如国外信箱)不支持非英文字母(比如汉字)传输，这是历史原因造成的(认为只有美国会使用电子邮件?)。因为一个英文字母使用ASCII编码来存储，占存储器的1个字节(8位)，实际上只用了7位2进制来存储，第一位并没有使用，设置为0，所以，这样的系统认为凡是第一位是1的字节都是错误的。而有的编码方案(比如GB2312)不但使用多个字节编码一个字符，并且第一位经常是1，于是邮件系统就把1换成0，这样收到邮件的人就会发现邮件乱码。\n为了能让邮件系统正常的收发信件，就需要把由其他编码存储的符号转换成ASCII码来传输。比如，在一端发送GB2312编码－\u0026gt;根据Base64规则－\u0026gt;转换成ASCII码，接收端收到ASCII码－\u0026gt;根据Base64规则－\u0026gt;还原到GB2312编码。\nBMP\nUCS-4根据最高位为0的最高字节分成2^7=128个group。每个group再根据次高字节分为256个plane。每个plane根据第3个字节分为256行 (rows)，每行包含256个cells。当然同一行的cells只是最后一个字节不同，其余都相同。 group 0的plane 0被称作Basic Multilingual Plane, 即BMP。或者说UCS-4中，高两个字节为0的码位被称作BMP。 将UCS-4的BMP去掉前面的两个零字节就得到了UCS-2。在UCS-2的两个字节前加上两个零字节，就得到了UCS-4的BMP。而目前的UCS-4规范中还没有任何字符被分配在BMP之外\n硬盘相关 dd 制作U盘启动盘 $ dd bs=4M if=fileName.iso of=/dev/sdx status=progress \u0026amp;\u0026amp; sync Windows 下用 Rufus 且 dd 写入模式\nexFAT 文件系统\n所谓文件系统，就是文件的储存方式。通过文件系统可以准确找到存储在硬盘中的数据。储存设备都需要指定文件系统，计算机才能读写。\nWindows 的文件系统\n  FAT32：是最老的文件系统，所有操作系统都支持，兼容性最好。但是，它是为 32 位计算机设计的，文件不能超过 232 - 1 个字节，也就是不能超过 4GB，分区不能超过 8TB。\n  NTFS：是 Windows 的默认文件系统，用来替换 FAT32。Linux 下有如下方法创建 NTFS 文件系统\n# gparted $ sudo apt-get install gparted # mkntfs $ sudo apt-get install ntfs-3g $ sudo mkntfs --fast --label myUsbDrive /dev/sdb1 # mkfs $ mkfs.ntfs -f -L DiskLabel /dev/sdb1   exFAT：是 FAT32 的 64位升级版，ex 就是 extended 的缩写（表示\u0026quot;扩展的 FAT32\u0026quot;），功能不如 NTFS，但是解决了文件和分区的大小问题，两者最大都可以到 128PB。\n  Linux 的 exFAT 格式化\n$ sudo mkfs.exfat /dev/sdX1 分区表\n所谓硬盘分区，就是指一块硬盘上面，同时存在多个文件系统。每个文件系统管理的区域，就称为一个分区（partition）。\n分区大小、起始位置、结束位置、文件系统等信息，都储存在分区表里面。\n分区表也分成两种格式：MBR 和 GPT。前者是传统格式，兼容性好；后者更现代，功能更强大。\nimg转化成iso IMG是一种文件归档格式（archive format），主要是为了创建磁盘的映像文件（disk image），它可以用来封装存储整个磁盘（通常指软磁盘，Floppy Disk或Diskette）或整片光盘的内容，使用\u0026quot;.IMG\u0026quot;这个扩展名的文件就是利用这种文件格式来创建的。\n.IMG这个文件格式可视为.ISO格式的一种超集合。由于.ISO只能封存使用ISO9660和UDF这两种文件系统的存储介质，意即.ISO只能拿来封存CD或DVD，因此才发展出了.IMG，它是以.ISO格式为基础另外新增可封存使用其它文件系统的存储介质的能力，.IMG可向后兼容于.ISO，如果是拿来封存CD或DVD，则使用.IMG和.ISO这两种格式所产生出来的内容是一样的。\n将img 转化成iso的有 nrg2iso 或 ccd2iso，分别下载如下：\n$ sudo apt-get install nrg2iso $ sudo apt-get install ccd2iso 使用如下：\n$ nrg2iso image.nrg image.iso $ ccd2iso \u0026lt;.img filename\u0026gt; \u0026lt;.iso filename\u0026gt; 启用 TRIM 当我在运行 Linux 的计算机上安装我的第一块固态驱动器（SSD）后，我开始探索如何用好它们。SSD 在操作方式上与传统磁性驱动器不同，并且它们需要在软件上另行处理以达到功能优化。\n在传统磁盘驱动器上，删除时所删除的文件不会从磁盘中完全删除。这就是为什么你可以恢复已删除的文件的原因。基本上，文件系统仅引用磁盘上文件的位置，并且当文件被删除时，该引用被擦除，以允许你在这些空间中写入新数据覆盖原来的数据。然而，对于 SSD，新数据只能写在驱动器上完全新的或已擦除的单元上。因为必须在写入之前清除空间，如果在写入文件时尚未有足够的可用空间，则必须首先擦除该空间。这可能会对性能产生负面影响。\n如果操作系统在写入新数据之前就擦除了未使用的空间，而不是在写入时同时进行擦除，则可以提高文件保存性能。这种做法就是 TRIM。 TRIM 命令本质上允许你的操作系统告诉驱动器哪些区域的数据不再使用，以便擦除它们，加快驱动器将来的写入，可以 SSD 的用户提供更佳的体验。\n在 Linux 中，fstrim 提供此功能，它可以为写入新数据而准备驱动器，并延长驱动器的使用寿命。由于在我使用的 Linux 发行版上 SSD 的 trim 不是自动的，所以必须去调度该操作，否则 SSD 的性能会随着时间的推移而降低。\n为了在驱动器上运行 fstrim，驱动器本身以及其上的文件系统必须支持 TRIM。TRIM SSD 可以在命令行或 cron 任务中手动完成。作为超级用户（使用 su 或 sudo），运行 fstrim / -v 以完成手动 trim，或者设置 cron 任务以在计算机未使用时定期为你运行此命令。对于 fstrim 的完整选项列表请参考它的 man 手册。\n注：可以定期执行fstrim命令，但是不建议在mount / fstab 中使用discard 选项。因为这个选项要求SSD每次删除文件都进行trim操作，比较耗资源，尤其是在文件操作很频繁的时候。所以可以考虑用cron来定期trim。\n硬件支持根据使用的驱动器接口类型如 PCI、ATA、SCSI 还是 SD/MMC 而有所不同。你需要咨询你的 Linux 供应商以了解你的特定发行版是如何支持 TRIM 的。\n例如，红帽提供以下 SSD 磁盘指南。“性能随着所使用的块数接近磁盘容量而降低，性能影响程度因供应商而异，但是所有设备都会遇到一些性能降低。为了解决性能降低问题，主机系统（例如 Linux 内核）使用丢弃请求以通知存储器给定范围的块不再使用。”\nDebian wiki 提供了 SSD 使用的一些基本注意事项：使用 Linux 3.2 或更高版本内核，使用 SSD 的最新固件，使用 EXT4 文件系统，并且“在正常工作负载下有足够的 DRAM 用来操作而不用使用交换空间“。\nreserve 5% of the space By default, ext2/3/4 filesystems reserve 5% of the space to be useable only by root. This is to avoid a normal user completely filling the disk which would then cause system components to fail whenever they next needed to write to the disk.\nYou can see the number of reserved blocks (and lots of other information about the filesystem) by doing:\n$ sudo tune2fs -l /dev/sda8 For a /home partition, it is probably safe to set the reserved fraction to zero:\n$ sudo tune2fs -m 0 /dev/sda8 Which should make an additional ~5GB available.\nChange Partition Label e2label or tune2fs The commands e2label or tune2fs used for changing label of ext2, ext3 and ext4 type partitions.\n# e2label /dev/sda1 ROOT OR # tune2fs –L ROOT_PART /dev/sda1 Here, ROOT and ROOT_PART are the labels to be added to /dev/sda1 which is ext4 formatted partition.\nntfslabel The ntfslabel command used for changing label of NTFS partitions.\n# ntfslabel /dev/sda5 NTFS_DIR mkswap The mkswap command used for changing label of SWAP partition.\nAfter unmounting the filesystem, following command needs to be executed to change the label of swap partition.\n# mkswap -L SWAP_PART /dev/sda5 Where, /dev/sda5 is the SWAP formatted partition.\nexfatlabel The exfatlabel command used for changing the label of exFAT formatted partition.\n# exfatlabel /dev/sda3 EX_PART Disable usb automount $ gsettings get org.gnome.desktop.media-handling automount $ gsettings set org.gnome.desktop.media-handling automount false or use dconf-editor\nCreate an ISO File   Mkisofs\n$ mkisofs -o [filename.iso] [ directory_path] $ mkisofs –o backup.iso /home/tin/Documents/backup   dd\n$ dd if=[source] of=[target.iso] $ sudo dd if= /dev/sdb of= diskimage.iso   Brasero\n$ sudo apt-get install brasero   将du的输出按文件大小排序 sdu () { du -sk $@ | sort -n | awk \u0026#39; BEGIN { split(\u0026#34;K,M,G,T\u0026#34;, Units, \u0026#34;,\u0026#34;); FS=\u0026#34;\\t\u0026#34;; OFS=\u0026#34;\\t\u0026#34;; } { u = 1; while ($1 \u0026gt;= 1024) { $1 = $1 / 1024; u += 1 } $1 = sprintf(\u0026#34;%.1f%s\u0026#34;, $1, Units[u]); sub(/\\.0/, \u0026#34;\u0026#34;, $1); print $0; }\u0026#39; } SSHFS: How to Mount Remote File Systems Over SSH SSHFS (SSH File System) is a client for mounting a file system located on a remote machine onto your local system through an SSH connection. Using the SFTP (SSH file transfer protocol), the SSHFS command-line tool mounts a physical or virtual disk locally, allowing file transfer between a local and remote machine.\nThis article demonstrates the installation and usage of SSHFS to mount a remote folder or file system over SSH.\nInstall SSHFS $ sudo apt install sshfs Mount a Remote File System on Linux Step 1: Create Mount Point\nCreate a mount point directory in the mnt folder where the remote file system will be mounted:\n$ sudo mkdir /mnt/\u0026lt;folder name\u0026gt; Step 2: Mount the Remote File System Using SSHFS\nMount the remote file system to the created mount point using the SSHFS tool:\n$ sudo sshfs [-o \u0026lt;options\u0026gt;] \u0026lt;remote user\u0026gt;@\u0026lt;remote host\u0026gt;:/\u0026lt;path to remote directory\u0026gt; /mnt/\u0026lt;folder name\u0026gt;/ Enter the login password when requested if using password authentication. If the remote server uses SSH key authorization, provide the path of the private key. For example:\n$ sudo sshfs -o allow_other,IdentityFile=/home/kb/.ssh/id_rsa ubuntu@131.153.142.254:/home/ubuntu/ /mnt/test/ The allow_other option allows access to users other than root.\nStep 3: Unmount a Remote File System on Linux\nLastly, when finished with the mount point, unmount the remote file system with:\n$ sudo umount /mnt/\u0026lt;folder name\u0026gt; 交换文件 在桌面环境中，交换分区或文件用来实现休眠(hibernate)的功能，即将当前环境保存在磁盘的交换文件或分区部分。除此之外，某些特定软件需要 swap 才可以正确运行。交换文件与分区性能相同，且交换文件更为灵活，可随时变更大小，增加与删除。\n$ sudo fallocate -l 4G /swapfile # 创建4G的交换空间，大小根据需要自定 $ sudo dd if=/dev/zero of=/swapfile bs=1M count=4096 status=progress # 或者使用 dd $ sudo chmod 600 /swapfile # 设置正确的权限 $ sudo mkswap /swapfile # 格式化swap文件 $ sudo swapon /swapfile # 启用swap文件 最后，向 /etc/fstab 中追加如下内容：\n/swapfile none swap defaults 0 0 KDE 自身提供开箱即用的睡眠功能(suspend)，即将系统挂起到内存，消耗少量的电量。休眠(hibernate)会将系统挂起到交换分区或文件，几乎不消耗电量。\nFile recovery  Ubuntu Help Arch Wiki  Ddrescue GNU ddrescue是一个用于磁盘、CD-ROM与其他数字存储媒体的资料恢复工具。其将原始存储区块（如扇区）从一个设备或文件复制到另一个，同时以智能方式处理读取错误，透过从部分读取的区块中截取尚称良好的扇区来最小化资料损失。\nFile or grep With a bit of chances, sometimes I can recover deleted files with this script or next solution in the answer :\n#!/bin/bash  if [[ ! $1 ]]; then echo -e \u0026#34;Usage:\\n\\n\\t$0\u0026#39;file name\u0026#39;\u0026#34; exit 1 fi f=$(file 2\u0026gt;/dev/null /proc/*/fd/* | awk \u0026#39;$NF == \u0026#34;(deleted)\u0026#34;{print $(NF-1)}\u0026#39;) if [[ $f ]]; then echo \u0026#34;fd $ffound...\u0026#34; cp -v \u0026#34;$f\u0026#34; \u0026#34;$1\u0026#34; else echo \u0026gt;\u0026amp;2 \u0026#34;No fd found...\u0026#34; exit 2 fi  There\u0026rsquo;s another useful trick: if you know a pattern in your deleted files, type alt+sys+resuo to reboot+remount in read-only, then with a live-cd, use grep to search in the hard-drive :\ngrep -a -C 500 \u0026#39;known pattern\u0026#39; /dev/sda | tee /tmp/recover then edit /tmp/recover to keep only what were your file(s) before.\nHey, if with unix philosophy all is files, it\u0026rsquo;s time to take advantage of this, no ?\n I don\u0026rsquo;t understand how the grep solution worked for you, it outputs only binary data. How is that useful? – w00t\nSure, it \u0026ldquo;only\u0026rdquo; spits out binary data. But sometimes that binary data happens to contain the ASCII bits corresponding to the file I\u0026rsquo;m looking for. I guess I don\u0026rsquo;t understand the question? – wchargin\nthe trick is to use a search pattern that is very specific to that file. The grep command will take the 500 lines before and after each matching line, so it will still spit out a lot of irrelevant data, but with a text editor that can cope with that (e.g. Vim), it\u0026rsquo;s easy to sort out the good from the bad stuff. You could also filter out all lines with nonprintable characters by piping it through another grep command: grep -av \u0026quot;[^[:print:]]\u0026quot; – JimmyMcHoover\n Extundelete 安装：\n$ sudo apt install extundelete 查看挂载：\n$ df -lh /dev/sdb1 6.8G 4.1G 2.8G 60% /media/taroballs/taroballs 卸载文件系统：停止对当前分区做任何操作，防止inode被覆盖。inode被覆盖基本就告别恢复了\n$ umount /dev/sdb1 通过inode节点恢复：\n  通过扫描查找删除的文件夹\n$ extundelete /dev/sdb1 --inode 2   恢复单一文件tmppasswd\n$ extundelete /dev/sdb1 --restore-file passwd   恢复目录deletetest\n$ extundelete /dev/sdb1 --restore-directory deletetest   恢复所有\n$ extundelete /dev/sdb1 --restore-all   恢复指定inode\n$ extundelete /dev/sdb1 --restore-inode 14   Commands to see mountpoint On Linux, you can now use the findmnt command from util-linux (since version 2.18):\n$ findmnt -S /dev/VG_SC/home TARGET SOURCE FSTYPE OPTIONS /home /dev/mapper/VG_SC-home ext4 rw,relatime,errors=remount-ro,data=ordered Or lsblk (also from util-linux, since 2.19):\n$ lsblk /dev/VG_SC/home NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT VG_SC-home 254:2 0 200G 0 lvm /home That one is also useful to find all the file system mounted under a specific device (disk or partition\u0026hellip;):\n$ lsblk /dev/sda2 NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda2 8:2 0 59.5G 0 part ├─linux-debian64 (dm-1) 252:1 0 15G 0 lvm └─linux-mint (dm-2) 252:2 0 15G 0 lvm / To get the mountpoint only:\n$ findmnt -nr -o target -S /dev/storage/home /home $ lsblk -o MOUNTPOINT -nr /dev/storage/home /home Above findmnt does return with a failure exit status if the device is not mounted, not lsblk.\nSo:\nif mountpoint=$(findmnt -nr -o target -S \u0026#34;$device\u0026#34;); then printf \u0026#39;\u0026#34;%s\u0026#34; is mounted on \u0026#34;%s\u0026#34;\\n\u0026#39; \u0026#34;$device\u0026#34; \u0026#34;$mountpoint\u0026#34; else printf \u0026#39;\u0026#34;%s\u0026#34; does not appear to be directly mounted\\n\u0026#39; \u0026#34;$device\u0026#34; fi mount an ISO image/file  Create the mount point directory on Linux: sudo mkdir /mnt/iso Mount the ISO file on Linux: sudo mount -o loop /path/to/my-iso-image.iso /mnt/iso Verify it, run: mount OR df -H OR ls -l /mnt/iso/ Unmount the ISO file using: sudo umount /mnt/iso/  桌面环境相关 在中文介面下，如何只用英文目錄名稱？   方案一：先切到英文介面再重新開機，此時 Fedora 會問你要不要將子目錄換為英文名稱（選 Yes），再切回中文介面重新開機，Fedora 會再問你一次要不要更改子目錄為中文名稱（選 No），收工！\n  方案二：\n$ LANG=C xdg-user-dirs-gtk-update # 同意更新 $ xdg-user-dirs-gtk-update # 保留且不再問   方案三：手動修正配置文件~/.config/user-dirs.dirs ,然後在主目錄下創建對應目錄,重啟即可解決.\n  XDG_TEMPLATES_DIR If you drop any files in \u0026ldquo;Templates\u0026rdquo; folder. Then when you right-click and create a new document, you can select any of these files as a basis for the new file.\nIf you have deleted the folder and need to restore this functionality:\n$ gedit ~/.config/user-dirs.dirs Check that there is a line containing the following - if not, add this line.\nXDG_TEMPLATES_DIR=\u0026quot;$HOME/Templates\u0026quot; nmcheck.gnome.org nmcheck.gnome.org is not malware. It is the gnome network manager connectivity check (for captive portals/hotspots). Click the link and you will see a single text file with a text in it. It should be \u0026ldquo;NetworkManager is online\u0026rdquo;.\nCheck /etc/NetworkManager/NetworkManager.conf. There probably is a section with this in it:\n[Connectivity] uri=http://nmcheck.gnome.org/check_network_status.txt on Ubuntu 20.04 no [Connectivity]  line like accepted answer in /etc/NetworkManager/NetworkManager.conf.\nBut you can disable the auto connectivity check by:\n Go to Settings app Go to Privacy menu On Connectivity tab, uncheck Connectivity Checking  Automatic Light / Dark Mode for GNOME, this shell extension exists: Night Theme Switcher\n改善触摸板体验 众所周知，Macbook 的触摸板是体验最好的，很多果粉都吹 Macbook 的触摸板用了之后“就不再想要去用鼠标”。\n有一群人搞了一个项目：「Linux Touchpad like Macbook Update」。顾名思义，就是“把 Linux 的触摸板搞的像 Macbook 一样”。\n这个项目的主要作用就是针对现在 Linux 下对于触摸板管理的相关驱动进行一些修改和优化，以提升触摸的使用体验，尤其是包括“多点触摸”等等等。\n$ sudo add-apt-repository ppa:p12/xorg-gestures $ sudo apt-get update 当然，尽管如此，我们也只是在驱动层面改善了触摸，在应用层面还需要另一个工具的帮忙：touchegg\n安装完毕之后你的三指上滑和三指下滑都可以正常使用了，譬如三指上滑是窗口最大化，三指下滑是窗口最小化。\nMacOS Fonts Fonts on Macintosh\nThe primary system font in OS X El Capitan and above is San Francisco. OS X Yosemite used Helvetica Neue, and preceding versions largely employed Lucida Grande.\nFonts for Apple platforms\n SF Pro SF Compact SF Mono SF Arabic New York  Format Chinese, Japanese, or Korean text in Pages on Mac\nFor best results, use these recommended fonts:\n Simplified Chinese: PingFang SC Traditional Chinese for Taiwan: PingFang TC Traditional Chinese for Hong Kong and Macau: PingFang HK Korean: Apple SD Gothic Neo Japanese: Hiragino Sans (sans serif) or Hiragino Mincho (serif)  Monaco\nWith the August 2009 release of Mac OS X 10.6 \u0026ldquo;Snow Leopard\u0026rdquo;, Menlo was introduced as the default monospaced font instead of Monaco in Terminal and Xcode, However, Monaco remains a part of macOS. Monaco is the default font in the current Python IDLE when used on a Mac running OS X El Capitan.\nDownload\n  Fontshub\nOn FontsHub.pro, you can download fonts for free and use them on your site to design headlines, quotes, paragraphs, lists, or other text elements.\n  PingFang SC\n  fonts\n  config\nedit .config/fontconfig/fonts.conf\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE fontconfig SYSTEM \u0026#34;fonts.dtd\u0026#34;\u0026gt; \u0026lt;fontconfig\u0026gt; \u0026lt;alias\u0026gt; \u0026lt;family\u0026gt;sans-serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;SF Pro Display\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;PingFang SC\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias\u0026gt; \u0026lt;family\u0026gt;serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;SF Pro Display\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;PingFang SC\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias\u0026gt; \u0026lt;family\u0026gt;monospace\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Menlo\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;/fontconfig\u0026gt; FromUbuntuToKubuntu $ sudo apt install kubuntu-desktop 类似的还有\n lubuntu-desktop ubuntu-desktop xubuntu-desktop  修改 User-Agent Chrome  方法一：依次打开 开发者工具 \u0026gt; More tools \u0026gt; Network conditions，在User agent中选择（已有多种范例可以选择）或自定义相应值。 方法二：添加启动参数 \u0026ndash;user-agent=\u0026ldquo;自定义的User-Agent值\u0026rdquo;，可在命令行或快捷方式的“目标”框中使用。 方法三：使用User-Agent Switcher for Chrome之类的扩展程序。  Firefox  方法一：在地址栏输入about:config，回车后打开配置编辑器，输入general.useragent.override创建该首选项，数据类型为字符串，再输入自定义的User-Agent字符串。 方法二：使用User Agent Switcher and Manager之类的组件。  从 Linux 终端发送桌面通知与提醒 从 Linux 终端发送通知 要从 Linux 终端发送通知，请使用 notify-send 命令。运行 which notify-send 命令来查看它是否在于你的系统中。如果没有，请使用包管理器来安装它。\n在基于 Debian 的发行版上，输入：\n$ sudo apt install notify-send 几个简单的通知示例：\n$ notify-send \u0026#34;Dinner ready!\u0026#34; $ notify-send \u0026#34;Tip of the Day\u0026#34; \u0026#34;How about a nap?\u0026#34; 你可以用紧急程度、自定义图标等选项来自定义通知。过 man notify-send 了解更多。你也可以在通知正文中使用一小组 HTML 标记，以使消息有一个棒的视觉感受。最重要的是，URL 被呈现为可点击的。例如：\n$ notify-send -u critical \\  \u0026#34;Build failed!\u0026#34; \\  \u0026#34;There were \u0026lt;b\u0026gt;123\u0026lt;/b\u0026gt; errors. Click here to see the results: http://buildserver/latest\u0026#34; 发送的通知会被桌面环境接收，并像其他通知一样显示。它们将具有相同的外观、交互和行为。\n将 notify-send 与 at 结合使用 计划任务通常被用来定期安排命令。at 命令安排在一个指定的时间执行一条命令。如果你像这样运行它，它会以交互模式启动，你可以在其中输入要在指定时间执行的命令：\n$ at 12:00 这对脚本来说并不有用。幸运的是 at 接受来自标准输入的参数，所以我们可以这样使用它：\n$ echo \u0026#34;npm run build\u0026#34; | at now + 1 minute $ echo \u0026#34;backup-db\u0026#34; | at 13:00 有许多指定时间的方法。 从绝对时间，如 10:00，到相对时间，如 now + 2 hours ，再特殊时间，如noon 或 midnight。我们可以把它和 notify-send 结合起来，在未来的某个时间向自己发送提醒。例如：\n$ echo \u0026#34;notify-send \u0026#39;Stop it and go home now?\u0026#39; \u0026#39;Enough work for today.\u0026#39; -u critical\u0026#34; | at now Desktop file Running a .desktop file in the terminal With any recent Ubuntu that supports gtk-launch just simply go\ngtk-launch \u0026lt;file\u0026gt; Where \u0026lt;file\u0026gt; is the name of the .desktop file with or without the .desktop part. The name must not include the full path.\nSo gtk-launch foo opens /usr/share/applications/foo.desktop (or foo.desktop located in one of the other permitted directories.)\nSet variable in .desktop file Add the setting of the environment variable, via the env command, to the entry \u0026ldquo;Exec\u0026rdquo;:\nExec=env APPMENU_DISPLAY_BOTH=1 digikam -caption \u0026#34;%c\u0026#34; %i How to validate/verify .desktop files? You are looking for the desktop-file-validate tool provided by the desktop-files-utils package in your distribution. It check for syntax, using reserved words/characters, in summary, that it complies with the Desktop Entry specification. Here\u0026rsquo;s a example of a bad .desktop file:\n$ desktop-file-validate asdf.desktop asdf.desktop: error: value \u0026#34;s.0.m.t.h.i.n.g\u0026#34; for key \u0026#34;Version\u0026#34; in group \u0026#34;Desktop Entry\u0026#34; is not a known version Which in good files like caribou-autostart.desktop won\u0026rsquo;t show anything.\nDash to Dock Hide Mounted Drives on the Dock\n$ gsettings set org.gnome.shell.extensions.dash-to-dock show-mounts false How do you disable the window preview in Ubuntu dock (GNOME sidebar)?\nThis will allow you to cycle through the open windows by clicking on the icon:\n$ gsettings set org.gnome.shell.extensions.dash-to-dock click-action \u0026#39;cycle-windows\u0026#39; To revert the action:\n$ gsettings reset org.gnome.shell.extensions.dash-to-dock click-action gsettings or dconf value list for a key\nIf it was a enumeration, you could\ngsettings range ... Example:\n$ gsettings range org.gnome.shell.extensions.dash-to-dock click-action enum \u0026#39;skip\u0026#39; \u0026#39;minimize\u0026#39; \u0026#39;launch\u0026#39; \u0026#39;cycle-windows\u0026#39; \u0026#39;minimize-or-overview\u0026#39; \u0026#39;previews\u0026#39; \u0026#39;minimize-or-previews\u0026#39; \u0026#39;focus-or-previews\u0026#39; \u0026#39;focus-minimize-or-previews\u0026#39; \u0026#39;quit\u0026#39; Preferring Chinese fonts to Japanese ones   Copy the system configuration file /etc/fonts/conf.avail/64-language-selector-prefer.conf to the per-user font configuration folder.\n$ mkdir ~/.config/fontconfig/ $ cp /etc/fonts/conf.avail/64-language-selector-prefer.conf ~/.config/fontconfig/fonts.conf   Move SC and TC adn HK fonts in front of JP and KR ones in the aliases defined in ~/.config/fontconfig/fonts.conf:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE fontconfig SYSTEM \u0026#34;fonts.dtd\u0026#34;\u0026gt; \u0026lt;fontconfig\u0026gt; \u0026lt;alias\u0026gt; \u0026lt;family\u0026gt;sans-serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Ubuntu\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK SC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK TC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK HK\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK JP\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK KR\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Lohit Devanagari\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias\u0026gt; \u0026lt;family\u0026gt;serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Noto Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Serif CJK SC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Serif CJK TC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Serif CJK JP\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Serif CJK KR\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Lohit Devanagari\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias\u0026gt; \u0026lt;family\u0026gt;monospace\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Ubuntu Mono\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans Mono CJK SC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans Mono CJK TC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans Mono CJK HK\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans Mono CJK JP\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans Mono CJK KR\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;/fontconfig\u0026gt;   Restart apps.\n  概览 Linux 音频系统 论 Linux 是如何将音乐文件转换成空气的震动 你很有可能从未仔细研究过 Linux 的音频系统. 在大多数情况下, 在装好图形界面后（或者像 ubuntu 或 openSUSE 这种装好就带桌面环境的发行版里），音频就“自然而然”地能用了。的确，对很多人来说，自带的音频设置已经够好了。\n然而，隐藏在这“够好”下面的是一套颇为复杂的音频系统。如果你好奇心大发，想要了解 Linux 是怎么将你的音乐文件变成空气的震动的，抑或遇到了一点关于声音的问题，想要大概了解一下音频系统的构成以便定位问题来源，这里是一篇简短的介绍。\n俯瞰音频系统 要让你的喇叭或者耳机动起来，我们需要经历以下的步骤：\n首先，我们将音频文件 解码 成未压缩的音频流 (waveform)。现在，为了节省空间，大部分音频文件都是压缩过的，比如无损压缩格式 flac, ape 和有损压缩格式 mp3, aac, ogg 等。只有经过解码这个步骤，才能将这些音频文件变成声卡可以认识的音频流。\n然后，我们将这些音频流输出到一个 音频服务器 (sound server) 里。比如，如果你想一边看视频一边参加一个视频会议，你就需要使用一个音频服务器把这两个音频流混合到一起以便让声卡播放。\n最终，我们将混制好的音频流送到 声卡驱动 那里。由于所有音轨已经被音频服务器汇成一条，驱动仅需将音频流发送给声卡做最终的数模转换即可。\nLinux 下的具体实现 架构已经明晰，那么 Linux 下是哪些部件组成了这一架构的呢？\nALSA: 声卡驱动 为了保证音频被正确播放，发送和接收端需要确定比特率，采样深度等参数。\n严格来说，ALSA 是一套完整的音频处理系统（毕竟它的全名是 高级 Linux 音频架构 ）。但在现在的大多数使用情况下，我们只是将它作为一个声卡驱动用。这里主要介绍实际的使用场景。\nALSA 负责直接与声卡通讯。为了方便应用程序开发，ALSA 提供了一套与硬件无关的 API 以便程序能够轻松地设置输出参数并发送音频流。例如，是否使用声卡提供的硬件混音？还是使用软件混音器？如何调节各应用的响度？等等。\n然而，直接使用 ALSA 有很多不方便。为了使 ALSA 能够同时播放多条音频，用户必须做一些设置 。因此，大部分现代的桌面环境使用音频服务器解决这类问题。\nPulseAudio: 你或许正在用的音频服务器实现 如果你正在使用某种桌面环境的话，你大概已经用过位于托盘上面的音量控制控件。这通常就是控制 PulseAudio 服务器的一个前端。\n为了将多个程序发来的音频流按照指定的音量混音并发往声卡驱动（通常是 ALSA），PulseAudio 拥有一个内置的混音器。PulseAudio 还提供了一套很适合用户界面的 API（例如各大桌面环境的音量控件）。\n然而，由于 PulseAudio 主要针对没什么专业需求的 Linux 桌面用户，它使用一套检测系统来发现系统上可用的音频硬件，并自动决定应该如何配置这些硬件。然而，这些配置在很多情况下并不理想。更糟糕的是，为了省电或节省系统资源，内置的混音器往往不能提供最佳的质量，且会引入相当大的内部处理延迟。\n简单得说，对于懒得操心细化的配置且并不需要多么高的音频质量的普通用户来说，PuseAudio 应该已经足够好了。\nJACK: 创造者与专业用户的音频服务器 PulseAudio 也许对普通用户来说已经够好，那么对于专业用户呢？\n答案是 JACK！从设计角度上来说，JACK 并不是用来当作通用的音频服务器使用的。它是一个 “音频连接工具”（正如它的名字，\u0026ldquo;JACK Audio Connection Kit\u0026rdquo; 所言）。在 JACK 的世界里面，每个音频节点（可能是个音频软件，也有可能是一个抽象硬件，比如一个 MIDI 键盘）都可以拥有多个输入源和输出源。举个例子，你可以将你的 MIDI 的键盘的 MIDI 输出连接到 FluidSynth （一个 MIDI 电子合成器）的输入源上，这样在 FluidSynth 的输出源上就会输出合成好的声音。然后将 FluidSynth 的输出源同时连接到一个录音软件（比如 Audacity）和主音频输出上。这样。你就可以一边监听你的演奏，一边将它们录制到音频文件当中去。\n而且，由于 JACK 是被设计成用作专业音乐制作的，它内置的混音器的质量极佳。因此，有很多 JACK 用户并不用它制作音乐，而是把 JACK 当作一个质量更好且用起来更灵活的音频服务器使用。想让视频会议上的同事们听听你正在听的音乐？没问题！只要将音乐播放器的输出源接到视频会议软件的输入源上即可。\n然而，JACK 没能统治 Linux 桌面是有原因的。相对于 PulseAudio 来说，JACK 需要配置一些参数（例如声卡的比特率，缓冲区大小等等）才能正常工作。如果参数不正确，最终的声音会出现莫名其妙的卡顿和损坏。在此之外，JACK 的灵活性有些时候反而是劣势，毕竟为了达成这种灵活性，JACK 有些情况下需要用户手动配置音频节点的连接方式。\nPipeWire: 新希望 严格来说，PipeWire 不仅仅是一个音频服务器，不过它的音频服务器功能十分卓越。PipeWire 最早的设计用途是视频流处理系统，不过后来扩展为可以处理任意多媒体流（包括我们关心的音频流）。现在 Wayland 上分享桌面就是由 PipeWire 负责中介，实时视频压缩以及鉴权。相比于 PulseAudio，PipeWire 的 CPU 占用更低，混音器质量更好且处理延迟极低。对于桌面用户来说，PipeWire 对蓝牙音频设备的支持也更加可靠。对于专业用户来说，PipeWire 的音频内部处理延迟已经接近 JACK 了，足以支撑专业音频处理。\n更棒的是，PipeWire 完全实现了 PulseAudio 的应用接口。因此，理论上你只需要装上 PipeWire（发行版的包管理器应该会自动卸载 PulseAudio 以防止冲突），所有的程序和控制面板应该都可以完美工作。目前为止（2022年2月，0.3 以上版本）PipeWire 应该已经很稳定了，但是 PipeWire 毕竟是很新的项目，可能还会有一些兼容性问题。\n我应该用什么？ 如果你一般只听听音乐什么的话，PulseAudio 应该足够好了。如果你遇到了任何音质上面的问题，很有可能只是因为 PulseAudio 没有使用最佳的配置选项，或者有可能是因为你的声卡的驱动有 bug。看一看 ArchWiki 上面的 PulseAudio/Troubleshooting，大多数问题应该很好解决。\n如果你想做点音乐的话，JACK 值得一试。你需要一点配置（比如给 JACK 实时权限，找到适合你声卡的配置等等），但配好之后 JACK 的灵活性是无可匹敌的。\n如果你觉得 PipeWire 解决了你的痛点的话，PipeWire 值得一试！PipeWire 已经在我的主力机上跑了一年多了，体感没有什么稳定性问题，而且蓝牙连接过程相对 PulseAudio 更可靠。\n对于某些特殊情况，比如你只需要运行一个播放音频的软件且需要最小的延迟（a.k.a. 音游），那么你可以试着让应用程序直接使用 ALSA，毕竟这样的话音频将被直接发往声卡，省略了所有中间处理的步骤。或者也可以试试 JACK，毕竟在 JACK 里声音延迟是相对较小且可控的。\nDownload a single folder from GitHub Update Apr. 2021: there are a few tools created by the community that can do this for you:\n Download Directory(Credits to fregante)  It has also been integrated into the excellent Refined Github chrome extension as a button in the Github web UI.   GitZip (Credits to Kino - see his answer here) DownGit (Credits to Minhas Kamal - see his answer here)  Note: if you\u0026rsquo;re trying to download a large number of files, you may need to provide a token to these tools to avoid rate limiting.\nOriginal (manual) approach: Checking out an individual directory is not supported by git natively, but Github can do this via SVN. If you checkout your code with subversion, Github will essentially convert the repo from git to subversion on the backend, then serve up the requested directory.\nHere\u0026rsquo;s how you can use this feature to download a specific folder. I\u0026rsquo;ll use the popular javascript library lodash as an example.\n  Navigate to the folder you want to download. Let\u0026rsquo;s download /test from master branch.\n  Modify the URL for subversion. Replace tree/master with trunk.\nhttps://github.com/lodash/lodash/tree/master/test ➜\nhttps://github.com/lodash/lodash/trunk/test\n  Download the folder. Go to the command line and grab the folder with SVN.\nsvn checkout https://github.com/lodash/lodash/trunk/test   You might not see any activity immediately because Github takes up to 30 seconds to convert larger repositories, so be patient.\n Full URL format explanation:\n If you\u0026rsquo;re interested in master branch, use trunk instead. So the full path is trunk/foldername If you\u0026rsquo;re interested in foo branch, use branches/foo instead. The full path looks like branches/foo/foldername Protip: You can use svn ls to see available tags and branches before downloading if you wish   That\u0026rsquo;s all! Github supports more subversion features as well, including support for committing and pushing changes.\nuse Github Contents API\nou can use Github Contents API to get an archive link and tar to retrieve a specified folder.\nCommand line:\ncurl https://codeload.github.com/[owner]/[repo]/tar.gz/master | tar -xz --strip=2 [repo]\\-master/[folder_path]\\ For example: if you want to download examples/with-apollo/ folder from zeit/next.js, you can type this:\n$ curl https://codeload.github.com/zeit/next.js/tar.gz/master | tar -xz --strip=2 next.js-master/examples/with-apollo locale 切換 參考文章  Ubuntu Community Help Wiki / Locale Debian Wiki / Locale  前提 安裝完成後，一開始「/etc/default/locale」的內容如下\n# File generated by update-locale LANG=\u0026#34;en_US.UTF-8\u0026#34; LC_NUMERIC=\u0026#34;en_US.UTF-8\u0026#34; LC_TIME=\u0026#34;en_US.UTF-8\u0026#34; LC_MONETARY=\u0026#34;en_US.UTF-8\u0026#34; LC_PAPER=\u0026#34;en_US.UTF-8\u0026#34; LC_NAME=\u0026#34;en_US.UTF-8\u0026#34; LC_ADDRESS=\u0026#34;en_US.UTF-8\u0026#34; LC_TELEPHONE=\u0026#34;en_US.UTF-8\u0026#34; LC_MEASUREMENT=\u0026#34;en_US.UTF-8\u0026#34; LC_IDENTIFICATION=\u0026#34;en_US.UTF-8\u0026#34; locale-gen 執行下面指令\n$ sudo locale-gen en_US.UTF-8 zh_CN.UTF-8 zh_TW zh_TW.UTF-8 Generating locales (this might take a while)... en_US.UTF-8... done zh_CN.UTF-8... done zh_TW.BIG5... done zh_TW.UTF-8... done Generation complete. 切換成「英文界面」 修改「/etc/default/locale」這個檔案，改成如下的內容\nLANG=\u0026quot;en_US.UTF-8\u0026quot; 或是直接執行下面指令，修改「/etc/default/locale」這個檔案\n$ sudo sh -c \u0026#39;echo \u0026#34;LANG=\\\u0026#34;en_US.UTF-8\\\u0026#34;\u0026#34; \u0026gt; /etc/default/locale\u0026#39; 切換成「中文界面」 修改「/etc/default/locale」這個檔案，改成如下的內容\nLANG=\u0026quot;zh_TW.UTF-8\u0026quot; 或是直接執行下面指令，修改「/etc/default/locale」這個檔案\n$ sudo sh -c \u0026#39;echo \u0026#34;LANG=\\\u0026#34;zh_TW.UTF-8\\\u0026#34;\u0026#34; \u0026gt; /etc/default/locale\u0026#39; 其他方式 或是也可以善用下面的指令來操作。\n$ sudo dpkg-reconfigure locales Locales of SDDM 在使用 KDE 的时候，在设置里将语言改为英文，会发现 SSDM 依旧是中文日期，原因是：The SDDM is following the system locales defined in /etc/default/locale\nUniform look Qt 应用程序，在 Gnome 上的 Appearence 设置就对其无效。参考 Uniform look for Qt and GTK applications 进行设置\n  方案一：安装并使用同时支持 QT 和 GTK 的主题。\n  Breeze 主题：在 KDE 平台下使用 kde-config-gtk-style 设置 GTK 主题。\n$ sudo apt install breeze-gtk-theme kde-config-gtk-style   Adwaita 主题：在 Gnome 平台下使用 QT_STYLE_OVERRIDE 环境变量或 qt5ct 工具\n$ sudo apt install adwaita-qt -y $ echo \u0026#34;export QT_STYLE_OVERRIDE=adwaita-dark\u0026#34; \u0026gt;\u0026gt; ~/.profile     方案二：使用 Kvantum。参考 How to Change Look and Feel of Qt5 Apps in Ubuntu, Debian, Fedora Linux 来设置 QT 程序的黑暗模式：\n$ sudo apt install qt5-style-kvantum qt5-style-kvantum-themes -y $ echo \u0026#34;export QT_STYLE_OVERRIDE=kvantum\u0026#34; \u0026gt;\u0026gt; ~/.profile   离线保存网页  pocket（可离线。要账号。有时会抓取错误） keep（只有文字没有图） evernote（选项多，但阅读，添加和管理无法脱机。要账号。不能保存豆丁、百度文档里面的内容） 打印为pdf（格式有变化，图片可能缺损。不能保存豆丁、百度文档里面的内容） 另存为html（有些网站，比如豆丁文档也可以完整保存，打印为pdf则不能。缺点是一个网页文件一个文件夹，看着难受。）  接下来是我的解决方案：\nchrome插件SingleFile：Single File和SingleFile Core，两个都要装。保存为网页htm格式，一个文件，可以保存豆丁文档，可以脱机。基本完美。安装插件后务必重启浏览器。\n有一点要注意的：如果你查看的豆丁或百度文库有好多页，务必要让所有页都显示过一次，再使用single file，才能完全保存。否则脱机的时候只能看到你看过的页面。已测试。\nSingle File 把样式都内嵌了，图片也是Base64格式内嵌，还把坑爹的脚本都移除了，这样不会出现各种加载错误什么的。\n缺点：无法云同步。\n2016.7更新：刚刚发现在Chrome地址栏中输入chrome://flags，可以看到一些实验功能，其中包含了将网页保存为.mhtml格式开关，开启后重启Chrome，ctrl+s开启的保存窗口中就多出了一种保存为.mhtml的选项，也即将网页保存为单一文件。\n2020年，更新，chrome已经把mhtml加入默认保存方式\nDynamic Workspaces A kwin script that creates and deletes desktops as you move windows on the last one.\n用 JavaScript 写的，可以参考 KWin Scripting Tutorial，还有一个 Plasma Desktop Scripting\nmeta, super, and hyper keys   Meta\nThe Meta key is not found on modern keyboards. Its use is sometimes emulated with AltGr (on some international layouts) or the right Alt key on the others. In addition:\n Sun keyboards have a meta key (◆) as well Emacs calls Esc the Meta key    Super\nThe Super key is equivalent to or the ⌘ (command) key. In Ubuntu, it\u0026rsquo;s just another name for .\n  Hyper\nHyper is the fourth (counting Ctrl) and last modifier on the Space cadet keyboard. In Ubuntu, its function is undefined (I think), but it can be mapped, as in the screen shot above, to , should it be needed.\n  KDE 的 Super、Meta 是 Win 键\n终端相关 個人 bin 資料夾 $ mkdir -p ~/bin $ mkdir -p ~/.local/bin/ 在「~/.profile」這個檔案，有將這兩個路徑加入「PATH」。\n$ cat ~/.profile # ~/.profile: executed by the command interpreter for login shells. # This file is not read by bash(1), if ~/.bash_profile or ~/.bash_login # exists. # see /usr/share/doc/bash/examples/startup-files for examples. # the files are located in the bash-doc package. # the default umask is set in /etc/profile; for setting the umask # for ssh logins, install and configure the libpam-umask package. #umask 022 # if running bash if [ -n \u0026#34;$BASH_VERSION\u0026#34; ]; then # include .bashrc if it exists if [ -f \u0026#34;$HOME/.bashrc\u0026#34; ]; then . \u0026#34;$HOME/.bashrc\u0026#34; fi fi # set PATH so it includes user\u0026#39;s private bin if it exists if [ -d \u0026#34;$HOME/bin\u0026#34; ] ; then PATH=\u0026#34;$HOME/bin:$PATH\u0026#34; fi # set PATH so it includes user\u0026#39;s private bin if it exists if [ -d \u0026#34;$HOME/.local/bin\u0026#34; ] ; then PATH=\u0026#34;$HOME/.local/bin:$PATH\u0026#34; fi 为什么执行自己的程序要在前面加./ shell是如何运行程序的：如果不给出相对路径，或者绝对路径，那么它会经历下面的查找过程。\n alias中查找 内置命令中查找 PATH中查找  $ cd /temp $ ./ls_bak 等同于\n$ /temp/ls_bak shell通常可以执行两种程序，一种是二进制程序，一种是脚本程序。如果是文本程序，且开头没有指定解释程序，则按照shell脚本处理，如果指定了解释程序，则使用解释程序来解释运行；对于二进制程序，则直接创建新的进程即可。\ngood practice to avoid using sudo su It is good practice to avoid performing more actions as root than you need to. sudo facilitates this by allowing you to run individual commands as root without having to log in as root and without needing an interactive root shell for tasks you would otherwise not run a shell to do. But sudo su is not a \u0026ldquo;backdoor,\u0026rdquo; it is simply a somewhat less elegant way to do what sudo is designed to allow you to do with sudo -s. Similarly, sudo -i is the more elegant way to achieve what sudo su - would get you: a simulated initial login shell whose environment is like what you would get if you could log in as root on the command line. See man sudo.\nDefault .bashrc You don\u0026rsquo;t need to trust this random gist on Github. Heck, it\u0026rsquo;s ~10 years old. Don\u0026rsquo;t you want the latest default - or the default that\u0026rsquo;s specific to your version of Ubuntu?\nYou can find the \u0026ldquo;skeleton\u0026rdquo; file used to initialize new users in ls -a /etc/skel.\nTo copy someone else\u0026rsquo;s comment: just run cp /etc/skel/.bashrc ~/ to copy from that \u0026ldquo;skeleton\u0026rdquo; to your current bashrc.\nuse \u0026lsquo;cp\u0026rsquo; to exclude a specific directory $ shopt -s extglob $ echo images/* images/004.bmp images/033.jpg images/1276338351183.jpg images/2252.png $ echo images/!(*.jpg) images/004.bmp images/2252.png 使用wget下载目录下所有文件 $ wget http://your/website/folder/ -c -r -np -nd -k -L -p 根据需要增减参数：\n -c 断点续传 -r 递归下载指定网页目录下（包括子目录）的所有文件 -np 递归下载时不搜索上层目录，否则将下载路径的上一级目录下的其它文件 -nd 递归下载时不逐层创建目录，将所有的文件下载到当前目录 -k 将绝对链接转为相对链接，如需下载整个站点后脱机浏览网页则需加上此参数 -L 递归时不进入其它主机 -p 获得显示HTML页面所需的所有图片等。  在文件夹内进行的全文搜索 这里写了一个讲究小而美和工具之间组合的全文搜索的方法。\n主要用 fzf，一个效率很高对每一行进行模糊搜索的工具。你可以给它喂一堆任意的字符串，然后从中搜索。\n比如用 fd 喂给 fzf 所有目录，然后发送给 cd 来快速跳转目录\n$ sudo apt install fzf fd-find $ vim ~/.bashrc fcd(){ cd $(fd --type directory | fzf) } 如果我想跳转到位置比较深 workbench-scheme 下 racket 目录，只需要输入 很短的 wor rac 然后按回车就够了\n 为了全文搜索，我们需要一个喂给 fzf 所有文件的文件名 + 行号 + 行内容的小脚本 cat-all.py\n#!/usr/bin/env python3 import os,sys, subprocess IGNORE_DIRS=[\u0026#34;.git\u0026#34;,\u0026#34;.vscode\u0026#34;,\u0026#34;build\u0026#34;] pwd=os.getcwd() for (dirpath, dirnames, filenames) in os.walk(pwd): if not any(ig in dirpath for ig in IGNORE_DIRS): for file in filenames: full_path=dirpath+\u0026#34;/\u0026#34;+file relative_path=full_path[len(pwd)+1:] mimetype=subprocess.check_output([\u0026#34;file\u0026#34;,\u0026#34;--dereference\u0026#34;,\u0026#34;--brief\u0026#34;, \u0026#34;--mime-type\u0026#34;, full_path]).decode() if(mimetype.startswith(\u0026#34;text\u0026#34;)): try: with open(full_path,\u0026#34;r\u0026#34;) as f: for ln,line in enumerate(f,start=1): if not line.isspace(): print(relative_path,\u0026#34;|\u0026#34;,ln,\u0026#34;|\u0026#34;,line.strip()) except: print(\u0026#34;[FAILED] \u0026#34;,full_path, file=sys.stderr) 然后就可以这样寻找当前目录下以前写过的所有的 hello, world\n$ cat-all.py | fzf 和 grep \u0026quot;Hello, World\u0026quot; 区别在于一些 hello_world，“Hello to some World”， “World Hello” 之类的也会被匹配到\n如果想按回车直接打开对应的文件，只要把 fzf 输出的内容用 awk 截取第一部分传给 xdg-open 就行了\n$ cat-all.py | fzf | awk \u0026#39;{print $1}\u0026#39; | xargs xdg-open \u0026amp;\u0026gt; /dev/null 据测量在我的电脑上这样搜索 80 万 行 左右的文本需要大约 12 秒左右的时间来索引，且过程中 fzf 占用 ~130mb 的内存。\nConvert WebP to JPEG/PNG $ sudo apt-get install webp $ cwebp -q [image_quality] [JPEG/PNG_filename] -o [WebP_filename] $ dwebp [WebP_filename] -o [PNG_filename] 例如\n$ ls *webp | xargs -I image sh -c \u0026#39;dwebp image -o image.png\u0026#39; Preserve File Permissions While Copying Files You can use the -p option of cp to preserve the mode, ownership, and timestamps of the file.\ndiff \u0026lt;(echo \u0026quot;$foo\u0026quot;) \u0026lt;(echo \u0026quot;$bar\u0026quot;) By searching the bash manpage for the characters \u0026lt;(, you can find that this is called “process substitution.”\nYou don\u0026rsquo;t need to worry about the efficiency of creating a temporary file, because the temporary file is really just a pipe, not a file on disk. Try this:\n$ echo \u0026lt;(echo foo) /dev/fd/63 This shows that the temporary file is really just the pipe “file descriptor 63.” Although it appears on the virtual /dev filesystem, the disk is never touched.\nThe actual efficiency issue that you might need to worry about here is the ‘process’ part of “process substitution.” Bash forks another process to perform the echo foo. On some platforms, like Cygwin, this can be very slow if performed frequently. However, on most modern platforms, forking is pretty fast. I just tried doing 1000 process substitutions at once by running the script:\necho \u0026lt;(echo foo) \u0026lt;(echo foo) ... 997 repetitions ... \u0026lt;(echo foo) It took 0.225s on my older Mac laptop, and 2.3 seconds in a Ubuntu virtual machine running on the same laptop. Dividing by the 1000 invocations, this shows that process substitutions takes less than 3 milliseconds—something totally dwarfed by the runtime of diff, and probably not anything you need to worry about!\n删除字符串空白符 #!/usr/bin/bash echo $1 | tr -d [:blank:] 科普 X 和 Wayland 简介 X即X11、X Window System，是用于在类UNIX的操作系统上的位图显示的窗口系统，提供了GUI环境的基本框架。X由X.Org Foundation维护，遵守MIT协议，当前参考实现为X.Org Server。在架构方面，X使用了C/S模型，客户端和服务器可以在同一个机器上，也可以在不同的机器上，X作为Server为应用程序这个Client提供显示和I/O服务。\nWayland是一个显示服务协议，服务端为Wayland Compositor，把X的X Server和Compositor合二为一，旨在替换X，作为类Unix操作系统上更现代、简介的窗口系统，遵守MIT协议，提供了Wayland Compositor的参考C语言实现Weston。\n时至今日，原本在X Server中做的事很多已被移到kernel或者单独的库中，因此X Server就显得比较累赘了。Wayland在架构上去掉了这个中间层，将compositor作为display server，使client与compositor直接通信，从而在灵活性和性能等方面上能够比前辈更加出色。\n查看是否使用 wayland\n$ echo $XDG_SESSION_TYPE 要切换就在登录界面选择 on wayland 好了。\n主要区别 这一切都得从头说起。\nX 协议设计于 1980 年代，那时候窗口界面刚刚起步，人们还没什么 3D 特效一类的想法，而且机能也不允许，放到今天任何一个有点桌面基础的人都能理解应该给每个窗口一个 buffer 然后把这些 buffer 里的 texture 贴出来的设计逻辑，但 那时候可没那么多内存让你给每个窗口一个 buffer。所以就如同各种常见的领域一样，有个小天才一拍脑子想，反正 最后显示到桌面上的都是一个屏幕大小，我们只要准备这么大一块内存就行了嘛！换句话说，每个窗口的 buffer 要去掉自己被覆盖住的内存，整体内存大小就是可控的，在内存里是直接没有被覆盖的部分的。\n不得不说这位的思路在当时还是很有意义的，加上窗口大小都是矩形的假设，计算实际显示区域并不难，于是 Xserver 就是这样设计的。它维护一个屏幕大小的 buffer 自己计算窗口的实际位置，发生了变化（比如一个窗口盖住另一个），就给变化的窗口发一个重绘信号，这个窗口再发出绘图申请，直接绘制到 Xserver 的 buffer 里。由于 Xserver 知道所有窗口的位置，它就可以重定向鼠标键盘输入过去。然后具体的窗口移动缩放交给 window manager，它再把改过的位置回报给 Xserver。\n一切事情都变得很美好，直到某天一个人提出一个问题：我想要半透明的终端！\n程序员是不屑于解决提出问题的人的，如果用现代程序员的思维，做一下 alpha 混合其实很简单，只要 Xserver 能读取上层窗口的颜色和下层窗口的颜色就行了，可是你还记得当年的小天才吗？Xserver 说不太好意思，对于 一个像素我内存里只有一层，就是最上面显示的那个窗口……并且积习难改，我们不能改这个 feature……你想上下混合？死宅不要整天做梦，这是老祖宗留下来的不能改啊。\n如果你用过没开启 混成 Compositing 的 XFCE 和半透明的 XFCE-Terminal，你会发现它是可以透出窗口下面的壁纸的，先别着急喊我骗子，你在终端下面放一个别的窗口试试？神奇的现象发生了，终端显示的还是壁纸……\n上有政策下有对策嘛，一些终端作者想到反正壁纸总是固定的，我读取壁纸图片，取出终端所在的位置，然后在我窗口做个 alpha 混合不就行了？但是人不能自己骗自己啊，这是个客户端的假透明，我们要学习 GNOME 开发者的思维：不够好就砍掉。（大雾\nX 一看不行啊，那我们改一下协议吧，加一个叫 混成器 compositor 的东西，如果你写了这个东西，X 就不是直接更新他自己的内存 buffer 了，而是交给混成器。混成器可以获取一系列窗口的内容，让它们都画到不同的 buffer 里面（内存终于够大了啊！），再把它们处理了丢到屏幕上去。Xserver 只是要求 compositor 最后返回一整个屏幕（通常是，也可以小一点）然后给这个直接贴到最上面去（可以简单理解为混成器画好一整张就行了，别的都不管了）。\n理论上来说，混成器想怎么放这些窗口就怎么放这些窗口，就算想把他们丢到屏幕外边都行，反正你最后返回一个图就行了，Xserver 也不管是不是涩图。\n但是有个尴尬的事情，输出给你管了，输入你管不着啊！之前说了 Xserver 自己按照自己存的窗口位置分配输入，你把窗口挪走了，Xserver 可还是按照自己记录的窗口位置分配输入的，如果你想自己处理窗口位置分配输入，好嘛，Xserver 里面的代码你再复制到你混成器里一份吧！\n所以实际上 compositor 里面怎么做的呢？我最后处理完的窗口，位置和 Xserver 记录的位置还得一样，然后 Xserver 给我那个返回整张屏幕的顶层窗口，我就不接收输入了，这样直接透过顶层点到下面，就和窗口位置对应了（什么乱七八糟的破玩意啊！）。如果你要做个动画呢？你做动画的时候，Xserver 那边记录的位置可不跟你变（要是变，按照 X 的设计你这数据得跑好几个来回），你的鼠标点击在这时候是不准的，传不到窗口里面。\n这些 compositor 都是各个桌面环境做的，他们一般都集成到自己的 window manager 里了。\n而且随着时间发展，越来越多的 Xserver 和 client 是跑在同一个机器上的，很多 client 想自己利用显卡处理图形，就有人在协议上打洞，Xserver 做的越来越少了，更多的事情 client 自己都做了。\n你还想再往 X 协议上糊一层吗？别糊了兄弟，你这也太挫了！一开始 X 的设计是提供机制而非策略，Xserver 自己是符合了（然后除了 Xorg 其他实现都死了），和 Xserver 配合的可是被他绑的死死的比如 compositor，性能翻了几倍还得拉着这些历史垃圾跑，Xserver 终于活成了自己最讨厌的样子。\nWayland 做的事情很简单，反正 compositor 都做这么多了，那直接把 Xserver 的功能也丢给 compositor 吧！Compositor 下层接的是 DRM 控制渲染，libinput 控制输入，GBM/EGLStreams 控制内存管理，上层更简单了，每个窗口丢给我一个 texture，我负责安排你们这些 texture 放在哪里，然后我按照我安排的位置，告诉你们鼠标进谁窗口了键盘进谁窗口了。然后因为要把这些 texture 混合到屏幕上，一般都用 OpenGL 的硬件加速，但在 Linux 下创建 OpenGL Context 的 GLX 库是和 X 绑定的，所以一般大家都用 OpenGL ES Context 的库 EGL。这个库只干扰最后合成图片时候的事情，至于你的 texture 用的是 OpenGL 还是 OpenGL ES 还是 CPU 画的都没有关系，现在 Wayland 一概不管了，你自己客户端处理自己的内容吧，我又不是 Xserver！\n所以对于 GNOME 和 KDE 等等而言，现在他们打交道的一个是内核一个是窗口，而不是以前一样和 Xserver 打交道了，省了数据交换，同时自己可以自由控制窗口输入输出面积。Xorg 应该被淘汰不是因为功能性原因，而是因为它的设计在当时很聪明，但现在只是历史包袱，实在太挫了。\n看完这篇文章建议回去阅读《X 中的混成器與 Composite 擴展》和《Explanations》，可以了解更多的实现细节，现在再看就不会那么混乱了。\nOthers Nvidia driver\nEnabling DRM KMS is required.\nGnome Night Light\nNote: Currently, Night Light doesn\u0026rsquo;t work on NVIDIA cards in Wayland sessions.\n解决办法就是不使用 Nvidia 闭源驱动或不使用 Wayland。\nGnome cursor\nNote: By default, on Wayland, Gnome applications should be unable to display your cursor themes located in ~/.local/share/icons. As a workaround, you can add that path to XCURSOR_PATH.\n$ gsettings list-recursively org.gnome.desktop.interface | grep cursor # get default cursor settings $ vi .bash_profile # Setting cursor on wayland export XCURSOR_PATH=${XCURSOR_PATH}:/usr/share/icons:~/.local/share/icons export XCURSOR_THEME=Yaru export XCURSOR_SIZE=24 # Add local bin export PATH=${PATH}:~/.local/bin 不同情况下的图形效果\n然后对比一下水族馆的图形性能数据：\n X11 + Intel 显卡，30fps 左右。 Wayland + Intel 显卡：接近 60fps。  其实 WebGL 用得不多啦（Google 地图更常卡在网络 I/O 上而不是渲染上）。更多的是播放在线（YouTube）视频啦。\n X11 + Intel 显卡，1080p 60fps，GPU 用满，丢帧三分之一！4k 60fps 也差不多。原来重点不是分辨率（反正 GPU 的解码能力还没用满），重点是视频的帧率啊。 Wayland + Intel 显卡，4k 60fps 都不怎么丢帧，更不说其它了。GPU 图形计算用到一半左右。  Disable Caps Lock Key\nWayland\u0026rsquo;s security model prevents programs other than the compositor from grabbing raw keyboard input. Some compositors support remapping keys (for example, mutter through gnome-tweaks), but many do not.\n Open gnome-tweaks Click on the Keyboard \u0026amp; Mouse \u0026gt; Additional Layout Option Set up Caps Lock behaviour as per your needs.  Qt application with the Wayland\nTelegram 使用 gnome wayland 表现不好，毕竟是用Qt开发的，比如cursor变大，图标没有了，输入法不跟随了。\n因此：To force the usage of X11 on a Wayland session, use QT_QPA_PLATFORM=xcb.\nExec=env QT_QPA_PLATFORM=xcb /home/kurome/.opt/telegram/Telegram -workdir /home/kurome/.local/share/TelegramDesktop/ -- %u 这样就不需要设置XCURSOR环境变量了。\nLTS There is a new release every 6 months (in April and October), with the version number being year.month (e.g.: 16.04 was released in April 2016). Every two years, the April release is a Long Term Support version.\nLTS releases are the ‘enterprise grade’ releases of Ubuntu and are used the most. An estimated 95% of all Ubuntu installations are LTS releases.\nInterim releases (normal releases) will introduce new capabilities from Canonical and upstream open source projects, they serve as a proving ground for these new capabilities.\n All Interim releases (13.04 and later) are only supported for 9 months. All LTS releases (12.04 and later) are supported for five years (now is ten years) on both the desktop and the server.  Now, support means:\n Updates for potential security problems and bugs (not new versions of software) Availability of Commercial support contracts from Canonical Support by Landscape, Canonical\u0026rsquo;s enterprise oriented server management tool set  Ubuntu releases additional versions of the last LTS between releases—such as 14.04.1, that incorporate all of the updates up to this point. This is called a Point-Release (or sometimes snapshot). Those are released every quarter to half year, as needed.\nThe most important thing (for most people) is how long you get to use an install without having to do a release upgrade. A non-LTS version of Ubuntu only gets updates for 9 months from its release so to stay up-to-date —which is critically important— you need to upgrade twice a year; you need to upgrade through every Ubuntu version…\nConversely an Ubuntu LTS release is supported for 5 years and you can upgrade directly from LTS to LTS. This gives you long-lived, solid base to target and test on that makes it super-easy to release-upgrade when you decide to. It\u0026rsquo;s therefore ideal for mass deployment, high-availability systems, and just people who don\u0026rsquo;t like doing release-upgrades.\n软件的稳定性 软件的稳定性其实往往来源于：足够多的使用者与足够多的反馈跟改进。\nLinux系统，在服务器端的大多数常用软件都有足够多的使用者，所以就足够稳定，由于它在服务器端市场占有率远高于微软，所以服务器端就是比微软稳定，很正常的事。\n在桌面端，市场占用率远低于微软，不稳定也是自然的。\n为什么Linux下命令行程序往往又好用又稳定？是因为用户喜欢装逼吗？不是，因为命令行程序是服务器端跟桌面端通用的，而服务器端程序经过了足够多用户的使用，经过了足够的反馈开发迭代，所以稳定。而图形界面只有桌面用户用，桌面占有率那么低，这些程序往往缺乏足够的测试人力也缺乏足够的开发维护人力，所以并不会非常稳定。\n那么，你要想体验Linux稳定，怎么办？答案就是只使用市场占有率高，用户量大，因而获得了充分测试的软件，这就稳定了。比方说只使用服务器端。或者桌面端只使用最常用的那些，例如终端仿真器，浏览器，输入法，gcc编译器之类，肯定是稳定的。\n你看我就用浏览器，输入法，xterm，screen，编程ide，vim，以及一堆命令行的东西，稳定得很啊，六个月才重启一次电脑，重启的那一次还是因为ubuntu升级。\nHow To Download A Large File Faster From Google Drive? Step 1: Fetching Your File ID\n Open your browser and go to your google drive, open login with the account that has the file you wish to download. Locate the file that you wish to download and select it. Right click the file and click on “get shareable link” You don’t need to copy the entire link here; you only need the file ID that we will be using later.  The link will look like this: https://drive.google.com/file/d/XXXXX/view?usp=sharing\nIn this link, you only need to pay attention to the alphanumeric file ID, displayed by XXXXX here.\nStep 2: Getting an OAuth Code\n Visit OAuth 2.0 Playground by clicking here. On the developer’s webpage, in the “Select \u0026amp; authorize APIs” click on the “Drive API v3” option, and select the: https://www.googleapis.com/auth/drive.readonly option from the available options. Once selected click Authorize APIs button on the bottom right corner of the tab. After you click on the Authorize APIs button you will be transferred to the google account login screen. Select the same google account in which you have your file stored. Allow Google OAuth 2.0 to access your drive if asked. When you get redirected back to the OAuth 2.0 playground screen click on the “Exchange Authorization Code for Tokens” button as shown. Copy the newly generated Access Token and save it on your notepad. You will be needing this in the next step.  Step 3: Downloading The File Using A Command Line Script\n$ curl -H \u0026#34;Authorization: Bearer YYYYY\u0026#34; https://www.googleapis.com/drive/v3/files/XXXXX?alt=media -o ZZZZZ In your command, replace “XXXXX” with the file ID from above, “YYYYY” with the access token from above, and “ZZZZZ” with the file name that will be saved (for example, “myFile.mp4” if you’re downloading an mp4 file).\nPress Enter and let the download begin.\nUSB插槽鬆動怎麼辦  手机  充电宝  笔记本  笔记本  如何将Google搜索限制为特定语言的结果 只是想在Google搜索中添加有关语言参数的更全面的答案。\n有4种与语言相关的选项。\nWeb界面语言： hl=\n例： www.google.com/search?q=vilnius\u0026amp;hl=lt\nWeb Interface Language Codes hl=zh-CN Chinese (Simplified) hl=zh-TW Chinese (Traditional) hl=en English hl=ja Japanese 指定语言的页面： lr=lang_\n例： www.google.com/search?q=vilnius\u0026amp;lr=lang_lt\nSearch Language Codes lr=lang_zh-CN Chinese (Simplified) lr=lang_zh-TW Chinese (Traditional) lr=lang_en English lr=lang_ja Japanese 来自指定国家/地区的页面： cr=country\n示例：www.google.com/search?q=vilnius\u0026amp;cr=countryLT 请注意，两个国家/地区代码字符必须大写！否则，Google会忽略该参数（自2017年1月3日起）（即使小写字母对于hl=和都适用lr=lang_）。\n还有另一个参数\u0026ndash; gl=用于搜索结果，因为它们将显示在指定的国家/地区。我尝试对其进行测试，但对我而言，不同参数值的结果没有不同。浏览器或我的Google帐户的某些其他参数/设置可能已过时或覆盖了该设置。\nHWE The Ubuntu LTS enablement (also called HWE or Hardware Enablement) stacks provide newer kernel and X support for existing Ubuntu LTS releases.\nThe 20.04 LTS HWE Stacks continue to follow Rolling Update Model, as has been in use since 16.04 LTS.\nHow does Ubuntu make money? Firstly a lot of people work on Ubuntu in their free time (many of them programming, but also those of here for instance answering people\u0026rsquo;s questions). Also some people donate to Ubuntu.\nHowever there is more to the story. Canonical Ltd. is a private company that created and continues to pay for Ubuntu. We know Canonical hadn\u0026rsquo;t been making a profit, but Canonical was initially founded by multi-millionaire Mark Shuttleworth which meant it didn\u0026rsquo;t have to focus on making money right away.\nHowever Canonical is now looking towards to making Ubuntu profitable. (After all, they have 600+ employees to pay every month!) There are some indications this has been successful. Their key revenue streams offer services around Ubuntu:\n Support services (mostly to business) alongside which they sell Landscape Contracting services to businesses (for instance working with OEMs such as Dell, or helping Google with Chrome OS). As Ubuntu makes its way onto mobile phones and TVs then this will grow. Ubuntu Software Centre\u0026rsquo;s paid section (Canonical takes a cut of purchases) The Canonical Store (selling physical Ubuntu branded items) - discontinued Closed-source projects wishing to use Launchpad.net can purchase a license Ubuntu One (online file storage and synchronization service) and Music Store (selling music from within Ubuntu) - discontinued. Amazon referrals. When you search the Ubuntu Dash, you may see Amazon products (unless you have turned it off). Ubuntu takes a cut of these.[ref]  All of these are areas that Canonical hopes will grow.\n认证硬件  Ubuntu certified hardware Red Hat certified hardware  如果不怎么玩游戏的话，建议是直接考虑那些不带独立显卡的笔记本电脑。因为在Linux下双显卡装驱动问题很多。\n说到牌子的话，建议是考虑戴尔笔记本。因为戴尔台式机和笔记本，都是尽可能地去兼容Ubuntu来设计的。这个不是说假话做广告。我也就这个问题，看过了几乎所有戴尔系列产品的技术文档了。基本上都是在支持的操作系统列表中，无一例外地包含了Ubuntu。如果是想买能完美使用Ubuntu的本子，戴尔是首选。戴尔绝大部分笔记本机型都能很好完美兼容Ubuntu。\n还有一个重要原因就是，ubuntu的所属公司，与戴尔公司是有合作的。也正因为如此，Ubuntu默认就包含了dell的大部分硬件通用驱动，甚至硬件底层管理模块都囊括其中。\nPNG, JPG, or JPEG Ideally, both JPG and JPEG are the same formats and there is no difference between these image extensions. JPEG was shortened to JPG to make it compatible with Windows.\n    PNG JPEG/JPG     What is it? It stands for Portable Network Graphics and is a raster-based graphics format. It stands Joint Photographic Experts Group and is popular format for images.   Compression Algorithm Lossless compression Lossy compression   Transparency Image transparency is maintained image transparency is not maintained   Image Size Bigger Smaller   Image Quality Better Inferior   Available colors 16 million 16 million   Common Extensions PNG JPEG or JPG   Best for Editing, scaling, and web content Storage, editing, image processing, and posting    12 Colors That Go With Black ![](/Distributions/black with green.png)\n在线用的 Linux  JS/UIX - Terminal: 进入后，点击open terminal即可。它提供非常简单的终端环境，而且没有自带gcc等编译套件，不过练习基本命令和shell脚本还是可以的。整体使用起来也比较流畅。 copy.sh：它可以全屏体验，让你感觉就是在一台真的Linux上玩耍，同时还支持多种发行版，想体验不同系统的可以试试。 实验楼：选择 Linux 课程，点击进入课程并打开默认在线环境，就可以开始使用一个完整的在线 Linux 环境（Ubuntu），几乎和本地安装的 Linux 系统没差！ Unix Terminal Online：这个网站也支持代码的编译运行，而且速度还可以。 jsLinux：它提供多种系统选择，你也可以在上面编译运行代码。不过整体感觉不是很流畅。 Bash Shell：专门用来练习 Shell 编程的好地方。 paiza：同上，可以用来学习shell脚本。 ShellCheck：如同它的名字，这是一个用来检查你的脚本是否存在问题的工具。  全局菜单 🗓️ 2022/04/05\nayatana 是 Canonical 发起的一个 Linux 端桌面统一体验的项目，规定了桌面托盘、通知消息、全局菜单等功能的实现，Unity 桌面也是这个项目的一部分，在2017年的时候 Canonical 宣布转向使用 Gnome，而 Unity 桌面环境将停止开发。虽然 Unity桌面环境停止开发，但是部分使用 DBus 通讯的接口却保留了下来。\nGnome 是大多数发行版官方默认的桌面的环境，但是原版不安装插件用起来的却是各种难受，包括缺少任务栏/系统托盘，非常占用空间的标题栏。早期使用插件Gnome-Global-AppMenu实现全局菜单，这个仅限于Gtk2/Gtk3，到了Gtk4不支持加载外置模块，导致Gtk4开发的软件的作者除非手动兼容，不然没有全局菜单。所以Gnome-Global-AppMenu 的开发者宣布停止开发这个插件。另外一个是Fildem，目前还在积极的维护。xfce/mate/budgie 桌面环境使用vala-panel-appmenu，效果未知。KDE 从 5.9 版本开始，官方提供了支持，到了现在非常的稳定，属于开箱即用。\nUnity 之所以有全局菜单是因为 Canonical 这公司针对常见的软件包做了修改，将本来在软件内展示的菜单，展示在状态栏上面，这种操作只是一种代码外挂，并不是软件本身主动调用很接口生成菜单，有时候还会出现软件本身菜单和全局菜单同时展示的情况。常见的 UI库 GTK2/GTK3/QT都通过这种方式获得了支持，部分软件比如Firefox则采用官方定制版本才能支持全局菜单，总之实现方面并不是很完美。\n全局菜单实现需要两个部分组成，一个是桌面环境(具体点是状态条)提供一个窗口菜单注册接口，并且检测运行软件运行情况，绘制菜单项目等功能。软件端则是侦测桌面环境是否支持全局菜单，侦测到支持全局菜单，就需要注册一个会话，并且将全局菜单发送到接口。后续内容将全局菜单展示的组件称为服务端，运行的软件作为客户端，服务端到客户端的通讯方式用的是 dbus。\nAndroid 相关 Transfer files between Linux and Android  Connect Using USB Cable Apps  KDE Connect/GSConnect Android File Transfer AirDroid   Bluetooth  Two Options to Recover Your PC With Android If your PC is out of action, you can install a new operating system or run a recovery environment thanks to Android. Two solid options are available:\n ISO 2 USB: Lets you burn an ISO file directly to a USB flash drive over USB-OTG. DriveDroid: Enables you to store bootable ISO files on Android. With the paid version, support for Windows 10 installation images is added.  AVIF  Android 12 將支援「AVIF」影像格式！它能取代 JPEG 成為新一代主流標準嗎？ AVIF图片格式简介  系统相关 Irqbalance BTW: I\u0026rsquo;m pretty sure there are many cases where irqbalance could be very useful for server\u0026rsquo;s tasks but not for Desktop usage and, especially, for laptop desktop users.\nLinux is very servers oriented and any linux distros want to distribute several versions of kernels. So we all have to running a huge amount useless things for servers hardware, software, protocols and ms azure stacks etc and including irqbalance.\nIf you don\u0026rsquo;t see 100% loading on CPU0 during your work-flow, you don\u0026rsquo;t need to use irqbalance at all. Also the modern kernel is managing it itself depending on cpu0 loading.\nSeems that linux \u0026gt; 4.9 is able to do irqbalance without an external daemon\nEven debian, ubuntu now disable it by default\nhttps://bugs.launchpad.net/ubuntu/+source/ubuntu-meta/+bug/1833322\nBlock internet access to certain programs The solution for me happened to be straight forward.\n  Create, validate new group; add required users to this group:\n  Create: groupadd no-internet\n  Validate: grep no-internet /etc/group\n  Add user: useradd -g no-internet username\nNote: If you\u0026rsquo;re modifying already existing user you should run: usermod -a -G no-internet userName check with : sudo groups userName\n    Create a script in your path and make it executable:\n  Create: nano /home/username/.local/bin/no-internet\n  Executable: chmod 755 /home/username/.local/bin/no-internet\n  Content:\n#!/bin/bash sg no-internet \u0026quot;$@\u0026quot;     Add iptables rule for dropping network activity for group no-internet:\n  iptables -I OUTPUT 1 -m owner --gid-owner no-internet -j DROP\nNote: Don\u0026rsquo;t forget to make the changes permanent, so it would be applied automatically after reboot. Doing it, depends on your Linux distribution.\n    Check it, for example on Firefox by running: no-internet \u0026quot;firefox\u0026quot;\n  In case you would want to make an exception and allow a program to access local network:\n iptables -A OUTPUT -m owner --gid-owner no-internet -d 192.168.1.0/24 -j ACCEPT iptables -A OUTPUT -m owner --gid-owner no-internet -d 127.0.0.0/8 -j ACCEPT iptables -A OUTPUT -m owner --gid-owner no-internet -j DROP  NOTE: In case of spawning the rules will be maintained. For example, if you run a program with no-internet rule and that program will open browser window, still the rules will be applied.\n通过Linux系统进入 BIOS $ sudo systemctl reboot --firmware-setup 5 Ways to Check CPU Info in Linux  lscpu /proc/cpuinfo lshw hwinfo dmidecodes hardinfo: gui  Logging in as Root in Ubuntu with Live CD $ sudo passwd root Keychain Squeezing the last drop of convenience out of ssh-agent: Keychain will allow to reuse an ssh-agent between logins, and optionally prompt for passphrases each time the user logs in.\n$ sudo apt install keychain $ vi ~/.bashrc . ~/.keychain/${HOSTNAME}-sh $ keychain ~/.ssh/id_rsa Regenerate initramfs To create/recreate/update the initramfs file means to update the initrd.img-* ramdisk files in /boot.\nNote: I prefer to create a totally fresh version by using the -c option, instead of just updating the existing file by using the -u option.\nThe proper command would be:\n$ sudo update-initramfs -c -k $(uname -r) This will create a fresh initrd.img-* file for your currently booted version of Ubuntu.\nHowever, if you can\u0026rsquo;t boot to the current version of Ubuntu, you may have to modify this command, and by booting to an older version of Ubuntu, you can do it this way:\nsudo update-initramfs -c -k 5.11.0-22-generic where the 5.11.0-22-generic part should be replaced with the version of the desired boot kernel.\nTo get more detailed information, type:\n$ man update-initramfs Reset lost root password 警告： 攻击者都可以使用上述方法修改系统，要保证系统安全，请限制物理上的访问，或者使用全磁盘加密。\n使用 LiveCD 通过 LiveCD 可以使用好几种方法：chroot并且使用passwd命令或者擦除密码域条目。任何Linux的LiveCD都可以使用，chroot时它必须匹配已经安装的架构类型。这里仅介绍 chroot 方式，因为这个方法更不容易出错。\n  启动LiveCD，挂载根文件系统.\n  然后通过下列命令重置密码：\n$ passwd --root MOUNT_POINT USER_NAME   卸载根文件系统。\n  重启，记下你的密码。\n  用 Bash 作为 Init   将 init=/bin/bash 内核参数加入启动加载器的启动项.\n  启动后可以看到 Bash 提示符。\n  根文件系统应该是只读挂载，需要以可读写模式重新挂载：\nmount -n -o remount,rw /   用 passwd 创建新的管理员密码。\n  通过 reboot -f 重启，不要再次忘记你的密码。\n  注意： 使用此法时有的键盘不能被初始系统正确加载，你可能不能在bash提示符后输入任何东西。如果出现这种情况，你不得不使用其他方法。\nMicrocode 每当听到有人说“这个问题更新一下微码就好了”，就觉得这个哥哥怎么这么迷人，好像在哪里见过。为了也让自己变成这种迷人的哥哥，我也研究了一下到底什么是微码。\n这里说的是跑在CPU处理器上的微码，不是IBM那群人嘴里说的那个微码。如果你之前没和IBM打过交道那就当这段话不存在。\n计算机体系结构是一层又一层的抽象，典型的比如操作系统对底层硬件的抽象。但鲜有人知的是，操作系统和底层硬件，尤其是CPU之间还存在着几层抽象。什么叫抽象，当然有很多种学术流的解释，但我土气一点的解释就是“不关心”，就是“Don’t care”，就是爱咋地咋地。\n用这个模式套用一下我们熟悉的抽象：操作系统要将数据写入磁盘，它不关心怎么操作磁盘；应用要给某个服务器发个数据包，它也不关心怎么操作网卡。\n回到我们的微码上来。我们现在常见的操作系统都是用C语言编写，它相对于汇编语言来说，也算是一种“高级语言”。编译器会将这种高级语言编译成汇编语言。只要C语言编写时“不关心”汇编指令是啥，那么就是相对汇编语言做了一次抽象。\n马上就到微码了。我们知道汇编指令是执行在CPU上的，那么汇编指令会关心在某个具体型号的CPU上是怎么执行的吗？肯定不会的。汇编的一条ADD指令在80286上可以执行，在最新的Icelake上也能执行，但这两个CPU内部早已发生了天翻地覆的变化，执行ADD的操作已经完全不同了。\n换句话说，就是汇编指令并“不关心”是如何在CPU上执行的。\n操作系统不关心如何操作磁盘和网卡，是因为这些都有对应的设备驱动操心。汇编指令不关心具体如何在CPU中执行，这个就是由微码来操心了。所以用类比的方式，可以把微码类比成汇编指令针对某一型号CPU的驱动。\n同样的汇编指令，会由该型号CPU的微码转成可以跑在该CPU上的微操作（Micro-ops/uops）。这些微操作指导CPU的电路完成汇编指令要求的意图。\n在大家还在编写汇编语言代码的时代，微码为汇编语言的编写提供了方便：\n 只关心汇编逻辑，而不用关心CPU内部电路设计和具体的执行方式 方便设计出新的汇编指令，由微码翻译成具体的执行逻辑，比如循环中“变量自减若大于零则转跳”，可以用一条汇编指令代替，脏活累活都交给微码去干 修复或绕过一些很难修复的处理器数字电路中的Bug  上述第二点也为CISC指令集的实现提供了技术基础。因为不可能所有复杂的指令都是由专门的执行复杂指令的硬件来完成的，也是由简单的数字逻辑模块组合而成的。\n在现代CPU里，是存在专门的将汇编指令翻译成微操作的硬件解码器的。但微码依旧存在（就是CPU微架构图中前端那个Microcode sequencer），它作为一个Lookup Table保存在一块ROM中，用来解码复杂的指令，比如浮点运算的指令等。一般是硬件解码器解码得比较快，而用微码解码会比较慢。\n理论上，如果你能更改某一个处理器的微码，那么经它翻译的指令可以变成任意其他的指令。因为它关心指令如何在CPU电路中执行。所以现在升级微码主要是用来解决处理器的稳定和安全性的问题。\n当然你也可以用它模拟自己没有的汇编指令，比如AVX系列，我只要在看到AVX512的汇编之后，把它翻译成两个“SIMD256”或者四个“SIMD128”指令就好了。\n看到这里，你给自己就又加了一层微码的buff。最后贴心地推荐一篇详细说明Microcode怎么执行的文章：Microprocessor Microcode Simple Example\n安装/更新微码 微码就是由 Intel/AMD 提供的 CPU 固件。Linux 的内核可以在引导时更新 CPU 固件，而无需 BIOS 更新。处理器的微码保存在内存中，在每次启动系统时，内核可以更新这个微码。这些来自 Intel/AMD 的微码的更新可以去修复 bug 或者使用补丁来防范 bug。\n查看当前的微码状态：\n$ sudo dmesg | grep microcode 使用包管理器\n$ sudo apt install intel-microcode 必须重启以激活微码更新：\n$ sudo reboot 手动\n只有在你的 CPU 制造商建议这么做的时候，才可以使用下列的方法去更新/安装微码，除此之外，都应该使用上面的方法去更新。大多数 Linux 发行版都可以通过包管理器来维护、更新微码。使用包管理器的方法是经过测试的，对大多数用户来说是最安全的方式。\nRepair grub When you install Windows, Windows assumes it is the only operating system (OS) on the machine, or at least it does not account for Linux. So it replaces GRUB with its own boot loader. What you have to do is replace the Windows boot loader with GRUB. I\u0026rsquo;ve seen various instructions for replacing GRUB by mucking around with GRUB commands or some such, but to me the easiest way is to simply chroot into your install and run update-grub. chroot is great because it allows you to work on your actual install, instead of trying to redirect things here and there. It is really clean.\nDNS缓存 使用以下命令来检查其状态。\n$ sudo systemctl status systemd-resolved 运行以下命令来检查DNS缓存统计信息。\n$ sudo systemd-resolve --statistics 运行以下命令来清除Ubuntu上的DNS缓存。\n$ sudo systemd-resolve --flush-caches DNS刷新命令不会清除缓存命中和未命中统计信息。 如果要清除所有缓存统计信息，则必须重新启动systemd解析的服务。\n$ sudo systemctl restart systemd-resolved Change username Unix-like operating systems decouple the user name from the user identity, so you may safely change the name without affecting the ID. All permissions, files, etc are tied to your identity (uid), not your username.\nTo manage every aspect of the user database, you use the usermod tool.\nTo change username (it is probably best to do this without being logged in):\nsudo usermod -l newUsername oldUsername This however, doesn\u0026rsquo;t rename the home folder.\nTo change home-folder, use\nsudo usermod -d /home/newHomeDir -m newUsername after you changed the username.\nFor instance, you could logout, drop to a console (Ctrl+Alt+F1), and sudo su - to become true root (as opposed to sudo -s, where $HOME is still /home/yourname.) Maybe you also have to kill some still running processes from this user first. To do so, enter ps -u username, look for the matching PID and kill them by kill PID-number.\nUpdate: as arrange mentioned, some files may reference your old home directory. You can either keep a symlink for backward compatibility, e g ln -s /home/newname /home/oldname or you can change the file contents with sed -i.bak 's/*oldname*/*newname*/g' *list of files* It creates a backup for each file with a .bak extension.\nSome additional information for not so experienced users like me: As I only have ONE user account (administrator), it would not let me change the username (\u0026ldquo;you are already logged in\u0026rdquo; was the response in TTY1 (Ctrl+Alt+F1). To get around this:\n  Login with your old credentials and add a new user, e.g. \u0026ldquo;temporary\u0026rdquo; in TTY1:\nsudo adduser temporary set the password.\n  Allow the temporary user to run sudo by adding the user to sudo group:\nsudo adduser temporary sudo   Log out with the command exit.\n  Return to tty1: Login with the \u0026lsquo;temporary\u0026rsquo; user account and password. Change your username and folder as mentioned above. exit (until you get the login prompt)\n  Go back to TTY7 (Ctrl+Alt+F7) to login on the GUI/normal desktop screen and see if this works.\n  Delete temporary user and folder:\nsudo deluser temporary sudo rm -r /home/temporary   Test Network Speed $ sudo apt install speedtest-cli $ speedtest 蓝牙与WiFi信号干扰 蓝牙和WIFI干扰？把蓝牙掐死就行了\n蓝牙和Wi-Fi信号干扰问题可能你也遇到过，两者主要都是使用2.4GHz频段，导致同时开启时，蓝牙的数据吞吐量会急剧下降，配对设备困难，Wi-Fi间歇性中断，网络受到限制。目前基本没什么办法可以根治这个问题，但你可以下面的方案临时帮你解决一些问题。本文提供了4种方法，可以参考下。\n方法1：连接至5GHz无线网络\n既然知道了问题出在频段冲突上，那么可以考虑购买一个双频（2.4GHz + 5GHz）路由器，并连接至5GHz的Wi-Fi网络。该方法可以彻底解决干扰问题，但银子也是必不可少的。\n方法2：更换Wi-Fi信道\n以TP-Link路由器为例，登录路由器Web管理页，在无线设置-\u0026gt;基本设置中找到信道选项，将其改为1、6、11中的任何一个。这些为2.4GHz的不重叠传输信道，相较于其他信道更稳定一些。\n方法3：开启网卡蓝牙共存功能\n在近几年生产的无线网卡中，都支持蓝牙共存功能，方法是在网络适配器属性的高级选项卡中，找到Bluetooth Collaboration或Bluetooth Coexistence Mode（名称可能有所不同），将其设为启用（Enable）。Windows会自动重新连接Wi-Fi，干扰蓝牙的情况也会有所缓解。\n对于 Linux\n$ lspci -knn | grep Net -A3; lsusb ... Kernel driver in use: ath9k Kernel modules: ath9k ... $ sudo tee /etc/modprobe.d/ath9k.conf \u0026lt;\u0026lt;\u0026lt; \u0026#34;options ath9k btcoex_enable=1\u0026#34; 方法4：远离干扰源\n将蓝牙终端与路由器、微波炉、无绳电话机等使用2.4GHz频段的设备隔开使用。\n然而蓝牙与WIFI干扰确实是头疼的问题：蓝牙鼠标会受到WIFI干扰经常反应迟缓，而蓝牙音箱则会导致WIFI断网，经常上传失败的绝望。。。。\n总之，无线信道的改进还在进行着。。。\nRAM \u0026amp; VRAM VRAM as RAM  MTD vramfs  RAM as VRAM Basically the answer is the operating system threats the whole memory pool for the graphics card, and ram as a virtual memory.\nVirtual memory is paged two ways through a partition like swap, or a image file like in windows.\nThe virtual memory then maps the references to memory when you call int* or \u0026amp;memory. To a physical address on your ram or vram depending on where it\u0026rsquo;s meant to go.\nThe game cannot force the kernel or operating system to allocate virtual memory to a certain place.\nThe kernel will dynamically decide where everything goes, and will write to your hard drive if you overflow the current physical limit.\nThere are tons of articles on virtual memory on windows, bsd and linux. Mac is technically a bsd fork and does use the same methods, and so does the ps4 os.\ntl;dr Basically what you are saying doesn\u0026rsquo;t make sense in terms of virtual memory and this is done automatically( Games automatically use RAM as VRAM when you run out of VRAM. That\u0026rsquo;s why, when you go over your VRAM limit, your FPS drops like a rock ).\nAlso some people in this thread are confusing video memory and virtual memory.\n功耗控制 针对散热不好的设备或者续航能力不佳的笔记本，功耗控制显得非常必要\n使用 TLP 延长电池寿命及续航  如有需要可参阅 TLP 官方文档 和 archwiki TLP。\n 多年来，Linux 在电池优化方面取得了很大进步，但仍然有一些可选步骤改善笔记本电脑的电池寿命并且延长续航。\nTLP 作为一款自由开源的高级电源管理工具提供开箱即用的默认配置。同时也可以高度定制化，以满足特定需求。\n电压下探  以下方法仅适用于 Intel 四代酷睿 ™ Haswell 及更新 CPU。有关 AMD CPU 和 Intel 四代酷睿 ™ Haswell 之前的 CPU 请参考 archWiki Undervolting CPU。\n 对处理器的电压进行最大限度的下探，在挖掘 CPU 体质的极限的同时，起到既能降低发热，又能最大限度保持性能的效果。\n如果正常操作，降低电压一般不会损害 CPU，一般建议从 50 毫伏进行尝试，每次降压尝试多增加 10 毫伏。只要确保在降低电压前，系统中任务均被正确保存即可。\n降低功率墙 除了电压的下探，同时也可以尝试对处理器的功率墙（TDP）做出降低的限制。比如考虑这种情况 —— 在 CPU 满睿频时，其实不需要默认的那么多功耗来维持，也许在默认功耗的基础上减几瓦，也能维持满睿频，这样就又可以进一步降低温度。对功率墙进行限制不同于对电压进行下探，若限制功率墙的参数较低，这会不可避免的损失较多的性能，但是在散热过差的设备上这也是一个好办法。\n对于功率墙的调整，有些主板在 BIOS 中提供了设置项可以直接调整。对于没有设置项的主板，有的主板是锁定了瞬时和长时功率墙，这种情况就无法调整功率墙了。有的主板 BIOS 随没有提供功率墙调整项，但依旧可以通过命令行设置。\n通过以下的命令可以查看主板是否可以调整功率墙：\ngrep . /sys/class/powercap/intel-rapl/intel-rapl:0/* 2\u0026gt; /dev/null 如果在输出中看到了如下的 enabled 值为 1，即可以调整。第一行的数字代表现有的功率墙限制：\n/sys/class/powercap/intel-rapl/intel-rapl:0/constraint_0_power_limit_uw:100000000 /sys/class/powercap/intel-rapl/intel-rapl:0/enabled:1 具体的调整步骤参考 Set Max TDP of Intel H-series CPU。\nCheck if port is in use $ sudo lsof -i -P -n | grep LISTEN $ sudo netstat -tulpn | grep LISTEN $ sudo ss -tulpn | grep LISTEN $ sudo lsof -i:22 ## see a specific port such as 22 ## $ sudo nmap -sTU -O IP-address-Here 在已有系统安装 Windows 如果是单块硬盘，而且你是 uefi 引导模式，那么先分好 Windows 分区：\n 用 Ubuntu 安装 u 盘启动电脑，选择中文语言，点击“试用” 会启动到桌面， 再点击桌面左下角开始菜单，找到工具、磁盘工具， 在磁盘工具选中你的硬盘，右键 Ubuntu 分区，调整大小 缩小分区 以便挪出 Windows 分区（尽量有 100G+）， 缩小后，在空出的空白部分右键，新建分区，新建 NTFS 分区。 弄好以后，重启电脑，用 win10 安装 u 盘或 ventoy U 盘准备安装 Windows。 在 Windows 安装程序中选中前面新建的 Windows 分区。  你一定要事先拿bcdboot创建一个ESP到u盘上作为备份，不然将来俩系统你覆写我我覆写你，你就开不了机了，得救援模式里搞\n如果没备份的话，可以这样 修复 引导：用 Ubuntu 安装盘启动电脑，选择中文语言，点击试用，进入桌面后联网，再右键桌面打开终端，执行\n$ sudo apt install boot-repair $ sudo boot-repair DNS TXT 记录 简介\nTXT 记录是为您所在网域之外的来源提供文本信息的一种 DNS 记录，可用于多种用途。该记录的值可以是人工可读文本，也可以是机器可读文本。使用 Google Cloud 服务时，TXT 记录可用于验证域名所有权和执行电子邮件安全措施，例如 SPF、DKIM 和 DMARC。\n要为您的网域添加或修改 TXT 记录，请参阅关于 TXT 记录。\n使用nslookup查询DNS的TXT记录\n 在Windows或Linux平台的命令行中直接输入nslookup即可打开nslookup。 接着输入一个域名，即可查询A记录。输入set type=mx，就会把查询状态调整到mx，接下来输入的域名全部查询mx记录。同样的，输入set type=txt，set type=cname可以查询相应的记录。 这里的server表示DNS服务器，Non-authoritative answer表示非权威应答，即DNS服务器的缓存。  $ nslookup \u0026gt; set type=txt \u0026gt; qq.ustclug.org ... Shutdown $ sudo shutdown -h +120 # 两小时后关机 $ sudo shutdown -h 23:00 # 表示在23点定时关机 Runlevel 制脚本目录/etc/rc.d，该目录下存在各个运行级别的脚本文件，以下是centos7为例的查询结果（ubuntu 下没有 /etc/rc.d 目录，都在 /etc/ 目录下）：\n# ls /etc/rc.d/ init.d rc0.d rc1.d rc2.d rc3.d rc4.d rc5.d rc6.d rc.local # ls /etc/rc.d/rc4.d/ K50netconsole S10network S64mysqld # ls /etc/init.d/ functions mysqld netconsole network README 对于SysVinit系统，它将从以下位置执行：\n运行级别0 - /etc/rc.d/rc0.d/ 运行级别1 - /etc/rc.d/rc1.d/ 运行级别2 - /etc/rc.d/rc2.d/ 运行级别3 - /etc/rc.d/rc3.d/ 运行级别4 - /etc/rc.d/rc4.d/ 运行级别5 - /etc/rc.d/rc5.d/ 运行级别6 - /etc/rc.d/rc6.d/ 对于systemd系统，它将从以下位置执行：\nrunlevel1.target – /etc/systemd/system/rescue.target runlevel2.target – /etc/systemd/system/multi-user.target.wants runlevel3.target – /etc/systemd/system/multi-user.target.wants runlevel4.target – /etc/systemd/system/multi-user.target.wants runlevel5.target – /etc/systemd/system/graphical.target.wants Explanation   /etc/rc.d/init.d\n该文件夹包含所有服务在各个运行等级中的全部启动脚本。一般来说，它们都是标准的shell脚本，遵守最基本的标准。每个脚本最少接受两个参数start和stop，它们分别代表启动和停止服务（如网页服务）。除此之外，init脚本通常还会接受一些额外的选项，如restart（重启服务器）、status（返回服务当前状态）、reload（告知服务从配置文件中重新载入配置）以及force-reload（强制服务重载它的配置）。当用不带参数的方式运行脚本的时候，一般应该返回一个它会接受的参数列表。\n  /etc/rc.d/rc0.d～/etc/rc.d/rc6.d\n这些文件夹分别包含每个运行等级对应的init脚本。在实际使用中，它们一般通过符号链接到/etc/init.d文件夹下的实际文件。不过要注意的是，这些文件夹下的init脚本都有一些特别的名字，命名都以S（start）、K（kill）或D（disable）开头，如K+nn+服务名或S+nn+服务名，其中nn为两位数字。当init进入一个运行等级的时候，它会按照数字顺序运行所有以K开头的脚本并传入stop参数，除非对应的init脚本在前一个运行等级中没有启动。然后init按照数字顺序运行所有以S开头的脚本并传入start参数。任何以D开头的init脚本都会被忽略—这让你可以在指定的运行等级禁止一个脚本，或者你也可以仅仅移除全部符号链接。所以如果你有两个脚本，S01foo和S05bar，init首先会运行S01foo start，当它进入特定的运行等级后再执行S05bar start。\n7个运行级别(runlevel)\n 运行级别0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动 运行级别1：单用户工作状态，root权限，用于系统维护，禁止远程登陆 运行级别2：多用户状态(没有NFS) 运行级别3：完全的多用户状态(有NFS)，登陆后进入控制台命令行模式 运行级别4：系统未使用，保留 运行级别5：X11控制台，登陆后进入图形GUI模式 运行级别6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动    /etc/rc.d/rc.local\n并非所有的发行版都使用了rc.local，通常它是一个留给用户修改的shell脚本。一般会在init进程结束的时候运行它，所以你可以在这里放一些想要运行的额外脚本，而不用再创建自己的init脚本。\n  /etc/rc.d/rc.sysinit\n/etc/rc.d/rc.sysinit主要做在各个运行模式中相同的初始化工作，包括设定PATH、设定网络配置（/etc/sysconfig/network）、启动swap分区、设定/proc等等。\n  /etc/rc.d/rc\n当运行级别改变时，负责启动/停止各种服务。\n  Default runlevel 我们可以使用以下五种方法检查Linux系统当前运行级别：\n runlevel命令：runlevel打印系统的上一个和当前运行级别。 who命令：打印有关当前登录用户的信息。它将使用“-r”选项打印运行级别信息。 systemctl命令：它控制systemd系统和服务管理器。 使用/etc/inittab文件：系统的默认运行级别在SysVinit System的/etc/inittab文件中指定。 使用/etc/systemd/system/default.target文件：系统的默认运行级别在systemd System的/etc/systemd/system/default.target文件中指定。  在目錄/etc/rc2.d/中的連結檔S03lightdm是負責啟動圖形界面及視窗管理系統LXDE的, 這表示原本約定成俗的runlevel, 其實只是參考, 重要的是, 在要執行的runlevel中放了什麼就是什麼, 也就是說, 原本rc2.d是多人文字模式, 沒有圖形界面的, 由於連結檔S03lightdm啟動了圖形界面, 系統就當然進入了圖形界面.\n要移除連結檔S03lightdm, 有幾種方式:\n  直接刪除, 沒了這個檔就不會進入圖形界面了:\n$ sudo rm /etc/rc2.d/S03lightdm   用系統工具update-rc.d:\n$ sudo update-rc.d lightdm disable 2   Execute command at startup/shutdown On Ubuntu, scripts for the different runlevels are executed according to their presence in the /etc/rc[0-6].d directories. Runlevel 0 corresponds to shutdown, and 6 to reboot.\nTypically the script itself is stored in /etc/init.d, and then symlinks are placed in the directories corresponding to the runlevels you require.\nSo in your case, write your script, store it in /etc/init.d/, then create a symlink in each of /etc/rc0.d and /etc/rc6.d (if you want both) pointing to your script.\nThe scripts in each runlevel directory will be executed in asciibetical order, so if the order within the runlevel matters to you, choose the name of your symlink accordingly.\nExample:\n  Create a shell executable file with your script in /etc/init.d/ directory:\n$ sudo vi /etc/init.d/myscript $ sudo chmod 0744 /etc/init.d/myscript $ chown root:sys /etc/init.d/myscript   The script should have the following format:\n#!/bin/bash # chkconfig: 2345 20 80 # description: Description comes here.... # Source function library. . /etc/init.d/functions start() { # code to start app comes here  # example: daemon program_name \u0026amp; } stop() { # code to stop app comes here  # example: killproc program_name } case \u0026#34;$1\u0026#34; in start) start ;; stop) stop ;; restart) stop start ;; status) # code to check status of app comes here  # example: status program_name ;; *) echo \u0026#34;Usage: $0{start|stop|status|restart}\u0026#34; esac exit 0 即必须包含 case 语句，该语句须有 start（对应 S） 与 stop （对应 K）两个选项。\n  Since this has to be executed during shutdown or reboot need to create softlinks in /etc/rc0.d/ and /etc/rc6.d\n$ sudo ln -s /etc/init.d/myscript /etc/rc0.d/K99myscript $ sudo ln -s /etc/init.d/myscript /etc/rc6.d/K99myscript If you are on a Red Hat based system（即 RedHat 下有专门工具用来执行上面建立软链接操作）\n  Enable the script\n$ chkconfig --add myscript $ chkconfig --level 2345 myscript on   Check the script is indeed enabled - you should see \u0026ldquo;on\u0026rdquo; for the levels you selected.\n$ chkconfig --list | grep myscript   在 ubuntu 上我尝试运行 sudo update-rc.d myscript enable 5，结果报错 systemd failing enable with \u0026ldquo;service is transient or generated\u0026rdquo;.。解释为：\nThe manual for [systemctl](https://www.freedesktop.org/software/systemd/man/systemctl.html#is-enabled UNIT…) tells us the following about the generated status:\n The unit file was generated dynamically via a generator tool. See systemd.generator(7). Generated unit files may not be enabled, they are enabled implicitly by their generator.\n So your error message means that one of the methods through which systemd can automatically generate unit files for you is in use, preventing you from using the one you wrote yourself.\n在我建立软链接后，比如 S01myscript，执行 sudo update-rc.d myscript disable 5 会变为 K01myscript，再执行 sudo update-rc.d myscript enable 5 会变为 S01myscript 并报上面错误。\n  Notes:\n The script in rc6.d must be with no .sh extension The name of your script must begin with K99 to run at the right time. The scripts in this directory are executed in alphabetical order.    Report a problem in Ubuntu If you notice a problem in Ubuntu, you can file a bug report.\n  Type Alt+F2 and type ubuntu-bug nameofprogram\nIf you have a hardware issue or don\u0026rsquo;t know the name of the program affected, just type ubuntu-bug\n If using ubuntu-bug does not work for some reason, file a bug manually and jump to step 4 in this instruction.\n   After running one of the above commands, Ubuntu will gather information about the bug. This may take a few minutes. Review the collected information if you wish. Click Send to continue.\n  A new web browser tab will open to continue processing the bug data. Ubuntu uses the website Launchpad to manage its bug reports. If you do not have a Launchpad account, you will need to register for one to file a bug and receive email updates about its status. You can do this by clicking Create a new account.\n  After logging in to Launchpad, enter a description of the problem in the summary field.\n  After clicking Next Launchpad will search for similar bugs in case the bug you are reporting has already been reported. If the bug has already been reported, you can mark that bug as also affecting you. You can also subscribe to the bug report to receive updates about progress with fixing it. If the bug has not already been reported, click No, I need to report a new bug.\n  Fill in the description field with as much information as you can. It\u0026rsquo;s important that you specify three things:\n What you expected to happen What actually happened If possible, a minimal series of steps necessary to make it happen, where step 1 is \u0026ldquo;start the program\u0026rdquo;    Your report will be given an ID number, and its status will be updated as it is being dealt with. Thanks for helping make Ubuntu better!\n  If you get the \u0026ldquo;This is not a genuine Ubuntu package\u0026rdquo; error, it means that the software you are trying to report a bug about is not from the official Ubuntu repositories. In this case, you cannot use Ubuntu\u0026rsquo;s built-in bug reporting tool.\nFor more information about reporting bugs in Ubuntu, please read the extensive online documentation.\nOptimizing for Gaming This guide is only for Arch and Ubuntu. Any derivatives like Manjaro, Mint, PopOS, etc should also work.\nEnable Multilib Multilib is required by Steam, So if you are running Steam you can skip this step, If you can not find Steam in your repositories this is your issue.\nAdd the architecture.\n$ sudo dpkg --add-architecture i386 Update the package manager\n$ sudo apt-get update Upgrade to newer packages\n$ sudo apt-get dist-upgrade GPU Drivers Having the right GPU drivers is imporant, else games won\u0026rsquo;t run properly.\nManually check which driver you need: https://www.nvidia.com/Download/index.aspx?lang=en-us\nFor Nvidia you need to add a repository\n$ sudo add-apt-repository ppa:graphics-drivers/ppa \u0026amp;\u0026amp; sudo apt-get upgrade For Nvidia 440 you need these packages so install them.\n$ sudo apt install nvidia-graphics-drivers-440 nvidia-settings vulkan vulkan-utils Now reboot\n$ sudo reboot If you use Gnome or GDM you might need to disable Wayland, This is not always the case, But I include it here just in case, If your System won\u0026rsquo;t reboot you can try this\n$ sudo nano /etc/gdm/custom.conf Remove the # in front of the #WaylandEnable=false line and it should force Xorg.\nLinux kernel Installing the newest kernel is generally the easiest kernel switch, There are other kernels available, I will include them later.\nThe easiest way is to use ukuu, First we need to install it.\n$ sudo add-apt-repository ppa:cappelikan/ppa $ sudo apt update $ sudo apt install mainline Now ukuu is installed, in this program you can select the newest stable kernel click install and when you reboot the new kernel is used. Do not remove your old kernel. If anything goes wrong you can select which kernel to boot in the grub screen at startup and remove the kernel that gives you trouble.\nFeral Gamemode gamemode 基本上是一组守护进程/库，它可以按需优化 Linux 系统的游戏性能。它实际上只是让 CPU 在用户玩游戏时自动运行在高性能模式下并帮助 Linux 用户从游戏中获得最佳性能。\n$ sudo apt install gamemode Manual\nInstall the dependencies\n$ sudo apt install meson libsystemd-dev pkg-config ninja-build git libdbus-1-dev libinih-dev Clone the repository\n$ git clone https://github.com/FeralInteractive/gamemode.git Change the directory into the just downloaded folder\n$ cd gamemode Change the tree to the newest version\n$ git checkout 1.5.1 Run the install script\n$ ./bootstrap.sh Usage\nNow that it is installed we need to enable the service with this command\n$ systemctl --user enable gamemoded \u0026amp;\u0026amp; systemctl --user start gamemoded To use gamemode for supertuxkart for example, run this terminal\n$ gamemoderun supertuxkart To use it in Steam edit the launch option for the desired game to\n$ gamemoderun %command% If gamemode does not run try to make it executable:\n$ sudo chmod +x /usr/bin/gamemoderun If gamemoderun does not work for you try this as a launch command:\n$ LD_PRELOAD=$LD_PRELOAD:/usr/lib/x86_64-linux-gnu/libgamemodeauto.so.0 %command% Nvidia Improvements Nvidia users might want to enable all options listed here to improve performance in games\n Force Full Composition Pipeline avoids screen tearing by letting the GPU do all the scaling. Triple Buffer avoids stuttering gameplay It allows for a stream of data instead of chunks of data. IndirectGLXProtocol forces the game to directly communicate with the Nvidia drivers. Coolbits enables your card to be overclocked which gamemode will make use of.  Create a Xorg Config file:\n$ sudo nvidia-xconfig Edit the file with the following command\n$ sudo nano /etc/X11/xorg.conf Add in these lines under the \u0026ldquo;Device\u0026rdquo; section between the other options\nOption \u0026#34;TripleBuffer\u0026#34; \u0026#34;on\u0026#34; Option \u0026#34;Coolbits\u0026#34; \u0026#34;28\u0026#34; Add in these lines under the \u0026ldquo;Screen\u0026rdquo; section between the other options.\nOption \u0026#34;metamodes\u0026#34; \u0026#34;nvidia-auto-select +0+0 {ForceCompositionPipeline=On, ForceFullCompositionPipeline=On}\u0026#34; Option \u0026#34;AllowIndirectGLXProtocol\u0026#34; \u0026#34;off\u0026#34; Try this one with risk, It will be sure to crash GNOME, I am not sure about other DEs\njust add it to the end of the file\nSection \u0026#34;Extensions\u0026#34; Option \u0026#34;Composite\u0026#34; \u0026#34;Disable\u0026#34; EndSection If you run into any problems, just hit CTRL ALT F3 to switch to a different tty login, run the command to edit the file again and put a # in front of the options that are giving you trouble, Most likely the last one\nAlternatively you can just completely remove the file with the following command\n$ sudo rm /etc/X11/xorg.conf Libstrangle Libstrangle is a tool that helps you control framerates but also vsync settings. This is especially handy for games that do not support these features, You would like to half your framerate to make it run better save some power or just give your hardware a break.\nLibstrangle can be used in multiple ways depending on what you want to achieve.\nTo use libstrangle you can simply type strangle and then the amount of frames you want to run. There are some examples below, But the features you will probably use are Vsync which you use by using the -v option, the rules for OpenGL and Vulkan are different, Here is what each number does for the different apis.\n OpenGL 0 Force off, 1 Force on, n - Sync to refresh rate Vulkan 0 Force off, 1 Mailbox mode, 2 Traditional vsync, 3 Adaptive vsync  You can also limit the game depending on the power state of your device, Set it to 60 while charging and on 30 while discharging for example. You do this by adding a second number right after a colon. in example, strangle 60:30. There are more features but they are not that commonly used, you can check the gitlab link above or simply type strangle -h for more information.\nTo limit the framerate of supertuxkart to 30 simply run\n$ strangle 30 supertuxkart To Force enable vsync on 60 fps for an OpenGL Steam game set the launch option to\n$ strangle -v 1 60 %command% To set the framerate of a vulkan game on Steam to 120 fps but 60 on battery power with adaptive vsync set this as your launch command\n$ strangle -v 3 120:60 %command% Mangohud Mangohud is a monitoring tool for Vulkan and OpenGL applications. It can show CPU and GPU usage, temps, But also framerates, frametimes and a lot more.\n$ sudo add-apt-repository ppa:flexiondotorg/mangohud $ sudo apt update $ sudo apt install mangohud To configure it with a GUI you can check out GOverlay below. For a manual configuration you can edit\n$ ~/.config/MangoHud/MangoHud.conf If you want exactly my configuration you can just copy this into it without the need for GOverlay.\nbackground_alpha=0.3 font_size=20 background_color=020202 text_color=ffffff position=top-right no_display toggle_hud=F11 cpu_stats cpu_temp cpu_color=007AFA gpu_stats gpu_temp gpu_color=00BD00 ram ram_color=B3000A vram vram_color=00801B io_read io_write io_color=B84700 arch engine_color=B200B0 frame_timing=1 frametime_color=00ff00 #output_file=/home/houtworm/mangohud_log_  #fps_limit 120 #media_player #toggle_logging=F10 You can tweak all the little things you want here. You can also create different configurations per game by adding a MangoHud.conf file to the game directory.\nTo use it for any game change its launch option to\n$ mangohud %command% To use it with non Steam games use the following command\n$ mangohud supertuxkart Some games might need the 32 bit version, try this if the normal command fails.\n$ mangohud.x86 %command% VKBasalt VKBasalt is a post processing layer for Vulkan which enables you to enhance graphics further. It only works with Vulkan, This includes all Proton games.\n$ git clone https://github.com/DadSchoorse/vkBasalt.git \u0026amp;\u0026amp; cd vkBasalt \u0026amp;\u0026amp; meson --buildtype=release builddir \u0026amp;\u0026amp; ninja -C builddir install To configure it first you need to create a config file, Run the following command to copy the example to a folder you can edit as the user.\n$ mkdir ~/.config/vkBasalt \u0026amp;\u0026amp; cp /usr/share/vkBasalt/vkBasalt.conf.example ~/.config/vkBasalt/vkBasalt.conf You can tweak all the little things you want here. You can also create different configurations per game by adding a vkBasalt.conf file to the game directory.\nTo use VKBasalt for any particular game enter this as a launch option.\nENABLE_VKBASALT=1 %command% You can also start non Steam games this way by typing the following command\nENABLE_VKBASALT=1 supertuxkart GOverlay GOverlay is a Graphical User Interface for managing MangoHud and VKBasalt\n$ sudo apt-get install lazarus git $ git clone https://github.com/benjamimgois/goverlay.git $ cd goverlay $ lazbuild -B goverlay.lpi mesa-demos and vulkan-tools are optional, You need them if you want to show the previews. You can find them in your distros repository\nXbox One Controller xpad works great, is the default on modern Linux distros and supports a wide range of controllers, But if you are like me and you only Xbox One controllers then using xpadneo is much better.\nFor Bluetooth to work with xpad and the Xbox One controllers you need to disable ertm (This is not needed for xpadneo)\ncreate the config file\n$ sudo nano /etc/modprobe.d/xbox_bt.conf Add the following line to the document and save and exit with CTRL + X.\noptions bluetooth disable_ertm=1 xpadneo supports Xbox One controllers wired and over bluetooth, It enables Force Feedback even the vibration inside the triggers, It supports battery level indication, It also fixes the mapping in many many games that where previously unplayable with a Xbox One controller on Linux.\nInstall the dependencies\n$ sudo apt-get install dkms linux-headers-`uname -r` Install xpadneo from Github\n$ git clone https://github.com/atar-axis/xpadneo.git \u0026amp;\u0026amp; cd xpadneo \u0026amp;\u0026amp; sudo ./install.sh Now you should be able to reboot and it should be all good, Having the controllers vibrate for a second when connected is a good indicator that it works.\nQUESTIONS Ubuntu 无法关机 $ sudo vim /etc/systemd/system.conf DefaultTimeoutStartSec=5s DefaultTimeoutStopSec=5s $ sudo systemctl reload DefaultTimeoutStartSec=, DefaultTimeoutStopSec= 设置启动/停止一个单元所允许的最大时长。若仅设置一个整数而没有单位，那么单位是秒。 也可以在整数后面加上时间单位后缀： \u0026ldquo;ms\u0026rdquo;(毫秒), \u0026ldquo;s\u0026rdquo;(秒), \u0026ldquo;min\u0026rdquo;(分钟), \u0026ldquo;h\u0026rdquo;(小时), \u0026ldquo;d\u0026rdquo;(天), \u0026ldquo;w\u0026rdquo;(周) 。 对于 Type=oneshot 类型的 service 单元， 这些选项没有意义(相当于全部被禁用)。 对于其他类型的 service 单元，可以在单元文件中设置 TimeoutStartSec=, TimeoutStopSec=, RestartSec= 以覆盖此处设置的默认值 (参见systemd.service(5))。 对于其他非 service 类型的单元， DefaultTimeoutStartSec= 是 TimeoutSec= 的默认值。\n注1：尽量不要使用上面更改。应该在完全清楚自己的更改造成的影响、产生的作用的前提下，做出更改。\n注2：作为桌面操作系统，如果有硬件驱动或其他各种莫名问题，可以尝试升级到最新版本来解决。\nACPI ERROR: AE_ALREADY_EXISTS These kinds of \u0026ldquo;errors\u0026rdquo; have been discussed ad nauseam, it\u0026rsquo;s simply the kernel telling you that the ACPI information received from the system seems to be incomplete in some way, update your BIOS/UEFI in hopes for a proper fix or ignore the error if you don\u0026rsquo;t notice anything off with your system.\n(And please don\u0026rsquo;t do something dumb like setting acpi=off just to get rid of these messages)\nCan\u0026rsquo;t run CS:GO at fullscreen  Open Steam Go to the \u0026ldquo;Library\u0026rdquo; Right-click the game which needs to be reconfigured Select \u0026ldquo;Properties\u0026rdquo; from the menu Click the \u0026ldquo;Set launch options\u0026hellip;\u0026rdquo; button type: -full and save  How To Disable Lock In Kubuntu open Workspace \u0026gt; Desktop Behavior \u0026gt; Screen Locking \u0026gt; uncheck Lock screen option\nGnome 3 displays two icons for same app No, there\u0026rsquo;s nothing wrong with your system.\nThe duplicated launcher icons explained:\nThe different icons are different commandline options. Some context applications with call the associated *.desktop icon. The exec option of the icon will depend on how the application is called.\nSome of the Icons you show in your image may be obvious because of the difference in the way they are named. You can see the difference in the way the app is called by right clicking and clicking on properties to see other differences.\nSome of the *.desktop files have a %U argument, used so the application will accept arguments.\nSome of the Launchers are different commands that are called differently and are named differently often by a symbolic link.\nSome exampes from the list in you image are:\nName: Online Accounts Command: unity-control-center credentials Name: Online Accounts Command: Online account credentials and settings Name: Personal File Sharing Command: gnome-file-share-properties Name: Rhythmbox Command: rhythmbox %U Name: Rhythmbox Command rhythmbox-client --select-source %U ssh_exchange_identification: Connection closed by remote host 原因是 Clash 开了 TUN 模式。关闭掉就好了。\nDisk show 129986 TB  (=ↀωↀ=)橘外猫, [2/7/22 11:16 AM] 这个是怎么回事啊\n雪梨, [2/7/22 11:21 AM] 分区表坏了？\n(=ↀωↀ=)橘外猫, [2/7/22 11:21 AM] 直接再分区吗？\n雪梨, [2/7/22 11:21 AM] 请鸽鱼老师看看诶\n雪梨, [2/7/22 11:22 AM] 还能挂载就先备份数据好了\n(=ↀωↀ=)橘外猫, [2/7/22 11:22 AM] 好的\nPegion Fish, [2/7/22 11:25 AM] JMS炸了？ 建议备份数据重建分区表 先重新插一次USB和硬盘\n(=ↀωↀ=)橘外猫, [2/7/22 11:27 AM] 重插了 用fdisk 重建吗？\nPegion Fish, [2/7/22 11:28 AM] 还是不正常？ 硬盘也重新插一下\n(=ↀωↀ=)橘外猫, [2/7/22 11:28 AM] 恩\n雪梨, [2/7/22 11:28 AM] 重建分区表，不是删掉分区再新增分区\n(=ↀωↀ=)橘外猫, [2/7/22 11:30 AM] 断电后自动好了 这是怎么回事啊\nThor Luo Bing-, [2/7/22 11:31 AM] 硬盘清空了\n(=ↀωↀ=)橘外猫, [2/7/22 11:32 AM] 没有，东西还在\nPegion Fish, [2/7/22 11:32 AM] 啊 这不是争产的吗 1T啊 这就是JMS主控抽风\n No Caching mode page found during early boot, I get following error message:\n[sdb] No Caching mode page found [sdb] Assuming drive cache: write through If I understand correctly, this is actually just a harmless info message and not an actual error. sdb is my USB disk, and it does not use caching .\nHard disks have a small amount of RAM cache to speed up write operations. The system can write a chunk of data to the disk cache without actually waiting for it to be written to the disk. This is sometimes called \u0026ldquo;write-back\u0026rdquo; mode. If there is no cache on the disk, data is directly written to it in \u0026ldquo;write-through\u0026rdquo; mode. The Asking for cache data failed warning usually occurs with devices such as USB flash drives, USB card readers, etc. which present themselves as SCSI devices to the system (sdX), but have no cache. The system asks the device: \u0026ldquo;Do you have a cache?\u0026rdquo; and gets no response. So it assumes there is no cache and puts it in \u0026ldquo;write-through\u0026rdquo; mode.\nCertificate verification failed 首先更改源文件，将所有的 https 改成 http ：\n$ sudo vi /etc/apt/sources.list deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse 1234 然后安装/更新证书 ca-certificates：\n$ sudo apt-get update $ sudo apt-get install --reinstall ca-certificates 最后将镜像源文件改回 https：\n$ sudo vi /etc/apt/sources.list deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse $ sudo apt-get update Move and overwrite subdirectories (and files) to parent directory You will have to copy them to the destination and then delete the source, using the commands cp -r * .. followed by rm -rf *.\nI don\u0026rsquo;t think you can \u0026ldquo;merge\u0026rdquo; directories using mv.\nSystem program problem detected The error \u0026ldquo;System program problem detected\u0026rdquo; comes up when a certain application crashes. Ubuntu has a program called Apport that is responsible for detecting such crashes and upon user consent, report these crashes to developers. This process intends to get the problem fixed by the developers.\nHowever it can be very annoying to common users, and there is no point in showing errors to users when they cannot do anything about it themselves. So you might want to disable them.\nRemove crash report files\nThe apport system creates crash report files in the /var/crash directory. These crash report files cause the error message to appear everytime Ubuntu boots.\n$ cd /var/crash $ ls _opt_google_chrome_chrome.1000.crash _usr_lib_chromium-browser_chromium-browser.1000.crash _usr_sbin_ulatencyd.0.crash _usr_share_apport_apport-gtk.1000.crash Just remove the crash report files\n$ sudo rm /var/crash/* After removing all the crash report files, the error message should stop popping up. However if a new crash takes place then it would appear again in future.\nTurn off apport\nAfter removing the old crash reports, if you still get the same error message, then you can completely turn off apport to get rid. Edit the configuration file at /etc/default/apport.\n$ gksudo gedit /etc/default/apport The file would contain something like this\n# set this to 0 to disable apport, or to 1 to enable it # you can temporarily override this with # sudo service apport start force_start=1 enabled=1 Just set the value of enabled to 0, and this will disable apport.\nenabled=0 Save the file and close it. From the next boot onwards, there should be no error messages ever. If you do not want to restart the system then restart apport from the command line.\n$ sudo restart apport i915 0000:00:02.0: [drm] ERROR CPU pipe A FIFO underrun Hi everyone, thanks for the help, after digging into the specific kernel issue page for i915 Intel drivers, I\u0026rsquo;ve found the problem and the temporary fix.\nThe problem has to do with issues related to C-States, or Intel\u0026rsquo;s powersaving states. On kernel\u0026rsquo;s 5.4 and below, only a max of PC3 is allowed, whereas in kernels 5.4+, deeper states (more powersaving) is used.\nAs james reports in\nhttps://gitlab.freedesktop.org/drm/intel/-/issues/272\n This problem seems to be related to the activity of deep package sleep states (on my hardware PC7 and deeper). I built and booted a 5.4 kernel and the problem went away, but that\u0026rsquo;s only because it wasn\u0026rsquo;t allowing package sleep states deeper than PC3. Check in powertop that states deeper than PC6 are actually being used under 5.4 and 5.8.\n and\n I\u0026rsquo;ve not found a fix, just worked around it with intel_idle.max_cstate=4.\n I have tested this, and adding\nintel_idle.max_cstate=4 to the cmdline of my kernel startup, does indeed fix my issues. While this bug is not yet solved in the kernel, I will mark it as solved here, as there\u0026rsquo;s nothing Arch Devs can really do about it. Please follow these issues for more information on fixes.\nRelated issue articles: https://gitlab.freedesktop.org/drm/intel/-/issues/2077\nEvince Document Viewer(42.0) does not remember last page in 22.04 Somebody added in launchpad that it could be related to apparmor, and I\u0026rsquo;ve tried temporarily disabling it with sudo apparmor_parser -R /etc/apparmor.d/usr.bin.evince as suggested by the poster. And both issues were solved.\nor\n$ sudo ln -s /etc/apparmor.d/usr.bin.evince /etc/apparmor.d/disable/ $ sudo systemctl restart apparmor.service $ sudo syst How can I create launchers on my desktop?  Note: gnome-desktop-item-edit was removed from gnome-panel in 19.10 (see gnome-desktop-item-edit: command not found on Ubuntu 19.10 and later even with the \u0026lsquo;gnome-panel\u0026rsquo; package installed). So, this answer is unlikely to work for 19.10 and later.\n The old GUI dialog is still available if you still want to use this:\nUsing ALT+F2 type\ngnome-desktop-item-edit --create-new ~/Desktop This will launch the old GUI Dialog and create a launcher on your Desktop.\n解决网易云音乐在 ubuntu 22.04 无法运行的问题 $ cd /tmp $ wget http://security.ubuntu.com/ubuntu/pool/main/g/glib2.0/libglib2.0-0_2.64.6-1~ubuntu20.04.3_amd64.deb $ wget http://mirrors.kernel.org/ubuntu/pool/main/p/pango1.0/libpangocairo-1.0-0_1.44.7-2ubuntu4_amd64.deb $ dpkg -x libglib2.0-0_2.64.6-1~ubuntu20.04.3_amd64.deb fakeroot $ dpkg -x libpangocairo-1.0-0_1.44.7-2ubuntu4_amd64.deb fakeroot $ sudo cp fakeroot/usr/lib/x86_64-linux-gnu/libgio-2.0.so.0 fakeroot/usr/lib/x86_64-linux-gnu/libpangocairo-1.0.so.0 /opt/netease/netease-cloud-music/libs/ 解决 ubuntu 22.04 无法启动 wps 需要安装旧版 libssl1.1\n$ wget http://security.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2.13_amd64.deb $ sudo apt install libssl1.1_1.1.1f-1ubuntu2.13_amd64.deb 然后就能启动 wps 了，\n或者也可以安装 snap 版 wps 2019\n$ sudo snap install wps-2019-snap ibus-rime 重复输入拼音 ibus rime在输入框输入中文，但是不按 enter，鼠标点击输入框其他地方，再点击输入框，之前输入的字符就会重新输入一遍。怎样使rime输入中文时候，点击其他地方后清空之前输入的拼音呢？\n 可以在 ibus 设置里取消“多个窗口间共享输入法状态”。但这只能解决多个窗口重复输入问题，单个窗口重复输入无法解决。  ","permalink":"https://sakamotokurome.github.io/posts/ubuntup4tips/","summary":"Backup Your System Ubuntu Help Arch Wiki Rsync 备份 #!/bin/bash set -o errexit set -o nounset set -o pipefail readonly SOURCE_DIR=/ readonly BACKUP_DIR=\u0026#34;$(findmnt -nr -o target -S /dev/mapper/luks-5277e33d-604f-4c1e-bc8c-40c14544614e)/Ubuntu2204\u0026#34; readonly DATETIME=\u0026#34;$(date \u0026#39;+%Y-%m-%d_%H:%M:%S\u0026#39;)\u0026#34; readonly BACKUP_PATH=\u0026#34;${BACKUP_DIR}/${DATETIME}\u0026#34; readonly LATEST_LINK=\u0026#34;${BACKUP_DIR}/latest\u0026#34; rsync -av \\ --delete \u0026#34;${SOURCE_DIR}/\u0026#34; \\ --link-dest \u0026#34;${LATEST_LINK}\u0026#34; \\ --exclude={\u0026#34;dev/*\u0026#34;,\u0026#34;proc/*\u0026#34;,\u0026#34;sys/*\u0026#34;,\u0026#34;tmp/*\u0026#34;,\u0026#34;run/*\u0026#34;,\u0026#34;mnt/*\u0026#34;,\u0026#34;media/*\u0026#34;,\u0026#34;lost+found/*\u0026#34;,\u0026#34;Trash/*\u0026#34;,\u0026#34;DataBackup/*\u0026#34;,\u0026#34;DataPool/*\u0026#34;,\u0026#34;swapfile\u0026#34;,\u0026#34;cxoffice\u0026#34;,\u0026#34;.cxoffice\u0026#34;,\u0026#34;*.iso\u0026#34;,\u0026#34;*.qcow2\u0026#34;,\u0026#34;.steam\u0026#34;,\u0026#34;Downloads/*\u0026#34;,\u0026#34;*.exe\u0026#34;,\u0026#34;Ventoy\u0026#34;,\u0026#34;Desktop/*\u0026#34;,\u0026#34;Music/*\u0026#34;,\u0026#34;.snapshots\u0026#34;,\u0026#34;Games\u0026#34;,\u0026#34;Pictures/*\u0026#34;,\u0026#34;Videos/*\u0026#34;,\u0026#34;.cache\u0026#34;} \\ \u0026#34;${BACKUP_PATH}\u0026#34; rm -rf \u0026#34;${LATEST_LINK}\u0026#34; ln -s \u0026#34;${BACKUP_PATH}\u0026#34; \u0026#34;${LATEST_LINK}\u0026#34; 注意： ${SOURCE_DIR","title":"Ubuntu Tips"},{"content":"Package Management dpkg 管理软件包 dpkg 意即 Debian 包管理器（Debian PacKaGe manager）。dpkg 是一个可以安装、构建、删除及管理 Debian 软件包的命令行工具。\n其它的一些工具如 dpkg-deb 和 dpkg-query 等使用 dpkg 作为执行某些操作的前端。\n现在大多数系统管理员使用 Apt、Apt-Get 及 Aptitude 等工具，不用费心就可以轻松地管理软件。\n尽管如此，必要的时候还是需要用 dpkg 来安装某些软件。\n常见命令及文件位置 dpkg 命令的语法:\n$ dpkg [\u0026lt;option\u0026gt; ...] \u0026lt;command\u0026gt; dpkg 相关文件的位置在 /var/lib/dpkg\n/var/lib/dpkg/status 包含了被 dpkg 命令（install、remove 等）所修改的包的信息\n/var/lib/dpkg/status 包含了可用包的列表\n安装/升级软件 在基于 Debian 的系统里，用以下命令来安装 .deb 软件包。要是已经安装了软件包，就会升级它。\n$ sudo dpkg -i package.deb 从文件夹里安装软件 在基于 Debian 的系统里，用下列命令从目录中逐个安装软件。这会安装 /opt/software 目录下的所有以 .deb 为后缀的软件。\n$ sudo dpkg -iR /opt/software 显示已安装软件列表 以下命令可以列出 Debian 系的系统中所有已安装的软件，同时会显示软件版本和描述信息。\n$ dpkg -l 查看指定的已安装软件 用以下命令列出指定的一个已安装软件，同时会显示软件版本和描述信息。\n$ dpkg -l package 查看软件安装目录 以下命令可以在基于 Debian 的系统上查看软件的安装路径。\n$ dpkg -L package 查看 deb 包内容 下列命令可以查看 deb 包内容。它会显示 .deb 包中的一系列文件。\n$ dpkg -c package.deb 显示软件的详细信息 以下命令可以显示软件的详细信息，如软件名、软件类别、版本、维护者、软件架构、依赖的软件、软件描述等等。\n$ dpkg -s package 查看文件属于哪个软件 用以下命令来查看文件属于哪个软件。\n$ dpkg -S /path/file 移除/删除软件 以下命令可以用来移除/删除一个已经安装的软件，但不删除配置文件。\n$ sudo dpkg -r package 清除软件 以下命令可以用来移除/删除包括配置文件在内的所有文件。\n$ sudo dpkg -P package Debian 打包入门 deb包本身有三部分组成：\n注：原文写的不是很好，具体学习还是看官方的 Debian 新维护者手册\nCardbook 是用于管理基于 CardDav 和 vCard 标准的联系人的Thunderbird扩展。\n使用 dh_make 在当前目录下创建一个 debian 目录。\n$ dh_make\\  --native \\  --single \\  --packagename cardbook_1.0.0 \\  --email minkush@example.com 一些重要的文件，比如 control、rules、changelog、copyright 等文件被初始化其中。所创建的文件的完整列表如下：\n$ find debian debian debian/manpage.sgml.ex debian/cardbook.doc-base.EX debian/changelog debian/control debian/postrm.ex debian/postinst.ex debian/source debian/source/format debian/README.Debian debian/manpage.1.ex debian/salsa-ci.yml.ex debian/rules debian/cardbook.cron.d.ex debian/README.source debian/preinst.ex debian/prerm.ex debian/copyright debian/cardbook-docs.docs debian/README debian/manpage.xml.ex 在当前目录执行 dpkg-buildpackage -us -uc -ui 将会在上层目录创建一个空的包文件以及四个名为 .changes、.deb、 .dsc、 .tar.gz 的文件。\n .dsc 文件包含了所发生的修改和签名 .deb 文件是用于安装的主要包文件。 .tar.gz （tarball）包含了源代码。  这个过程也在 debian/cardbook/usr/share/doc/cardbook 目录下创建了 README 和 changelog 文件。它们包含了关于这个包的基本信息比如描述、作者、版本。\n检查这个包安装的内容：\n$ dpkg -c cardbook_1.0.0_amd64.deb /usr /usr/share /usr/share/doc /usr/share/doc/cardbook /usr/share/doc/cardbook/README.Debian /usr/share/doc/cardbook/changelog.gz /usr/share/doc/cardbook/copyright build-essential 在 Ubuntu 中安装构建基础包（build-essential），只需要在终端中简单输入这个命令：\n$ sudo apt update \u0026amp;\u0026amp; sudo apt install build-essential 构建基础包（build-essential）实际上是属于 Debian 的。在它里面其实并不是一个软件。它包含了创建一个 Debian 包（.deb）所需的软件包列表。这些软件包包括 libc、gcc、g++、make、dpkg-dev 等。构建基础包包含这些所需的软件包作为依赖，所以当你安装它时，你只需一个命令就能安装所有这些软件包。\n请不要认为构建基础包是一个可以在一个命令中神奇地安装从 Ruby 到 Go 的所有开发工具的超级软件包。它包含一些开发工具，但不是全部。\nPackage converter  alien：Alien is really designed to be used to convert from alien file formats to the packaging format used by the distribution you run it on. gentoo-zh：gentoo 本质是通过 bash 安装软件，因此，可以参考此仓库尝试手动安装软件。  Is linux binary universal to all kinds of distributions?\nThis is two questions:\nIs a Linux binary universal to all distributions?\nIt depends:\n If the program is using nothing outside the Linux kernel, it will be universal except for the 32- or 64-bit question. A Linux \u0026ldquo;hello world\u0026rdquo; (a minimalistic program that just prints \u0026ldquo;hello world\u0026rdquo; to a terminal window) could probably be independent of the distribution. If the program is using any non-kernel library or service (which is most of Linux, the kernel is fairly small), there are differences in which libraries are included, which versions these libraries are and where they are located. So in this (most common) case distributions are not equal.  Why do many commercial programs say that they only work on one or a few distributions?\nBecause there is a very large number of Linux distributions, and nobody wants to test their program on all of them.\nA commercial vendor will normally say that they support only the distributions they have tested their software on. It may or may not work on other distributions, from the vendor\u0026rsquo;s perspective the point is just that you can\u0026rsquo;t complain if it does not work on a distribution they don\u0026rsquo;t support.\nWhich distributions are selected for testing depends on what the vendor expects their customers to be using. Commercial/professional programs commonly pick enterprise distributions, possibly through a reasoning similar to \u0026ldquo;people who paid for their OS are more likely to pay for our software\u0026rdquo;, possibly simply by counting the distributions used by their existing customers.\nSee also Mark Shuttleworth (the guy that is the reason we have an Ubuntu in the first place) on [binary compatibility between Ubuntu and Debian](https://wiki.ubuntu.com/MarkShuttleworth#What about binary compatibility) - Debian is the closest distribution relative of Ubuntu.\nAPT Debian 使用一套名为 Advanced Packaging Tool（APT）的工具来管理包系统。在基于 Debian 的 Linux 发行版中，有各种工具可以与 APT 进行交互，以方便用户安装、删除和管理的软件包。apt-get 便是其中一款广受欢迎的命令行工具，但是最常用的命令都被分散在了 apt-get、apt-cache 和 apt-config 这三条命令当中，apt 命令的引入就是为了解决命令过于分散的问题。（简单来说就是：apt = apt-get、apt-cache 和 apt-config 中最常用命令选项的集合）\n   apt 命令 取代的命令 命令的功能     apt install apt-get install 安装软件包   apt remove apt-get remove 移除软件包   apt purge apt-get purge 移除软件包及配置文件   apt update apt-get update 刷新存储库索引   apt upgrade apt-get upgrade 升级所有可升级的软件包   apt autoremove apt-get autoremove 自动删除不需要的包   apt full-upgrade apt-get dist-upgrade 在升级软件包时自动处理依赖关系   apt search apt-cache search 搜索应用程序   apt show apt-cache show 显示装细节   apt list  列出包含条件的包（已安装，可升级等）   apt edit-sources  编辑源列表    列出所有手动安装软件 $ apt-mark showmanual 查看软件包依赖 当你在 Linux 中安装一个软件包，有时这个软件包还需要其他的软件包来使它工作正常。这些额外的软件包就叫作这个包的依赖。假如这些软件包之前没有在系统中被安装，那么这些依赖在安装这个软件包的同时会被自动安装上。\n使用 apt show 来查看依赖\n你可以使用 apt show 命令 来展示一个包的详细信息。其中依赖信息就是其中一部分，你可以在以 “Depends” 打头的那些行中看到它们。\n例如，下面展示的是使用 apt show 展示 ubuntu-restricted-extras 这个包的详细信息：\n$ apt show ubuntu-restricted-extras Package: ubuntu-restricted-extras Version: 67 ... Depends: ubuntu-restricted-addons Recommends: libavcodec-extra, ttf-mscorefonts-installer, unrar ... 如你所见，ubuntu-restricted-extras 包依赖于 ubuntu-restricted-addons 这个软件包。\n但你得小心的是依赖包还可能依赖于其他包，这样一直循环往复直到尽头。但幸好 APT 包管理器可以为你处理这些复杂的依赖关系，自动地安装所有的依赖（大多数情况下）。\n什么是推荐包？\n你注意到了上面结果输出中以 “Recommends” 开头的那些行了吗？\n推荐包不是软件包的直接依赖，但它们可以开启软件包的一些额外功能。\n正如你上面看到的那样， ubuntu-restricted-extras 包有 ttf-mscorefonts-installer 这个推荐包，用来在 Ubuntu 上安装 Microsoft 的字体。\n这些推荐包也会默认被一同安装上，假如你想显式地禁止这些推荐包的安装，你可以像下面这样使用 –-no-install-recommends 选项。\n$ sudo apt install --no-install-recommends package_name 使用 apt-cache 来直接获取依赖信息\n上面通过 apt show 的方式会获取到大量信息，假如你想在脚本中获取到依赖信息，那么 apt-cache 命令将会给你一个更好且更简洁的输出结果。\n$ apt-cache depends package_name 使用 dpkg 来查看一个 DEB 文件的依赖\napt 和 apt-cache 都作用于软件仓库中的软件包，但假如你下载了一个 DEB 文件，那么这两个命令就不起作用了。\n在这种情形下，你可以使用 dpkg 命令的 -I 或 --info 选项。\n$ dpkg -I path_to_deb_file 依赖信息就可以在以 “Depends” 开头的那些行中找到。\n使用 apt-rdepends 来查看依赖及依赖的依赖\n假如你想查看更多关于依赖的信息，那么你可以使用 apt-rdepends 工具。这个工具可以创建完整的依赖树。这样你就可以得到一个软件包的依赖以及这些依赖的依赖。\n它不是一个常规的 apt 命令，所以你需要从 universe 软件仓库中安装上它：\n$ sudo apt install apt-rdepends 这个命令的输出通常很多，取决于依赖树的大小。\neading package lists... Done Building dependency tree Reading state information... Done shutter Depends: procps Depends: xdg-utils imagemagick Depends: imagemagick-6.q16 (\u0026gt;= 8:6.9.2.10+dfsg-2~) imagemagick-6.q16 Depends: hicolor-icon-theme Depends: libc6 (\u0026gt;= 2.4) Depends: libmagickcore-6.q16-6 (\u0026gt;= 8:6.9.10.2) Depends: libmagickwand-6.q16-6 (\u0026gt;= 8:6.9.10.2) hicolor-icon-theme libc6 Depends: libcrypt1 (\u0026gt;= 1:4.4.10-10ubuntu4) Depends: libgcc-s1 libcrypt1 Depends: libc6 (\u0026gt;= 2.25) apt-rdepends 工具的功能非常多样，它还可以用来计算反向依赖。这意味着你可以查看某个特定的包被哪些软件包依赖。\n$ apt-rdepends -r package_name 输出可能会非常多，因为它将打印出反向依赖树。\n$ apt-rdepends -r ffmpeg Reading package lists... Done Building dependency tree Reading state information... Done ffmpeg Reverse Depends: ardour-video-timeline (\u0026gt;= 1:5.12.0-3ubuntu4) Reverse Depends: deepin-screen-recorder (5.0.0-1build2) Reverse Depends: devede (4.15.0-2) Reverse Depends: dvd-slideshow (0.8.6.1-1) Reverse Depends: green-recorder (\u0026gt;= 3.2.3) Repository Mirror Select the fastest mirror\nYou can use deb mirror to have the best mirror picked for you automatically.\napt-get now supports a \u0026lsquo;mirror\u0026rsquo; method that will automatically select a good mirror based on your location. Putting:\ndeb mirror://mirrors.ubuntu.com/mirrors.txt precise main restricted universe multiverse deb mirror://mirrors.ubuntu.com/mirrors.txt precise-updates main restricted universe multiverse deb mirror://mirrors.ubuntu.com/mirrors.txt precise-backports main restricted universe multiverse deb mirror://mirrors.ubuntu.com/mirrors.txt precise-security main restricted universe multiverse on the top in your /etc/apt/sources.list file should be all that is needed to make it automatically pick a mirror for you based on your geographical location.\nThe command line way\nThere are many command line tools available to find the best APT mirrors based on download speed. I have tested the following tools and they are working just fine in my Ubuntu 20.04 LTS desktop.\n Apt-select Apt-smart  apt-fast apt-fast: A shellscript wrapper for apt that speeds up downloading of packages.\n$ sudo apt-get install aria2 $ sudo add-apt-repository ppa:apt-fast/stable $ sudo apt-get update $ sudo apt-get -y install apt-fast $ sudo nano /etc/apt-fast.conf MIRRORS=(\u0026#39;https://mirrors.bfsu.edu.cn/ubuntu/,https://mirrors.tuna.tsinghua.edu.cn/ubuntu/\u0026#39;) apt-aria2 #!/bin/bash  ## apt-aria2: To help download packages faster via aria2, instead of wget. ## Author: Anjishnu Sarkar ## Version: 0.5 ## Acknowledgement: This script is a rewrite of the apt-fast script by ## Matt Parnell (admin@mattparnell.com) (http://www.mattparnell.com) ## Usage: Same as apt-get. Using the option \u0026#34;-y\u0026#34; always. ## BUG: ## *) If this script is interuppted, then next time aria2 starts downloading ## the same from the begining. Can be solved - something to do with .st file. ## TODO: ## *) Start installing via apt-get as soon as first package is downloaded ## and also keep downloading at the same time. This however might lead ## to dependencies not being satisfied. ## Initialization(s): Download=\u0026#34;False\u0026#34; Install=\u0026#34;True\u0026#34; Confirm=\u0026#34;True\u0026#34; UniqueName=\u0026#34;$RANDOM\u0026#34; Options=\u0026#34;$@\u0026#34; ## Checking for commands which requires download while test -n \u0026#34;${1}\u0026#34; do case \u0026#34;${1}\u0026#34; in install|upgrade|dist-upgrade|source|build-dep) ## Download Download=\u0026#34;True\u0026#34; ;; update|remove|autoremove|purge|dselect-upgrade|clean|autoclean|check) ## Anything other than download Download=\u0026#34;False\u0026#34; ;; -d) ## Download only (don\u0026#39;t install) Install=\u0026#34;False\u0026#34; ;; -y) ## No need to ask for confirmation Confirm=\u0026#34;False\u0026#34; ;; *) ## Nothing to be done. If any wrong options/commands are given then ## let apt-get handle it. ;; esac shift done ## In case download is true if [ \u0026#34;$Download\u0026#34; == \u0026#34;True\u0026#34; ];then ## Installing pre-requisite(s): aria2 if ! which aria2c \u0026gt; /dev/null; then echo \u0026#34;Aria2 not installed. Installing aria2 first via apt-get\u0026#34; apt-get -y --force-yes install aria2 fi ArchiveDir=/var/cache/apt/archives/ cd ${ArchiveDir}/partial PrintUris=$(apt-get --yes --print-uris ${Options}) if [ $? -ne 0 ];then echo \u0026#34;Aborting.\u0026#34; exit 1 fi PackageInfo=$(echo \u0026#34;$PrintUris\u0026#34; | awk \u0026#39;/Reading package/,/After this operation/\u0026#39;) # echo \u0026#34;$PrintUris\u0026#34; | grep ^\\\u0026#39; | cut -d\\\u0026#39; -f2 \u0026gt; \u0026#34;$UniqueName\u0026#34;-uris.txt echo \u0026#34;$PrintUris\u0026#34; | grep \u0026#34;http:\u0026#34; | cut -d\\\u0026#39; -f2 \u0026gt; \u0026#34;$UniqueName\u0026#34;-uris.txt NumberOfPackages=$(wc -l \u0026#34;$UniqueName\u0026#34;-uris.txt | awk \u0026#39;{print $1}\u0026#39;) ## Print info echo \u0026#34;$PackageInfo\u0026#34; echo \u0026#34;Number of packages to be downloaded: $NumberOfPackages\u0026#34; ## Check whether package has already been installed or not InstallUpgradeMsg=$(echo \u0026#34;$PackageInfo\u0026#34; | grep \\  -e \u0026#34;The following NEW packages will be installed:\u0026#34; \\  -e \u0026#34;The following packages will be upgraded:\u0026#34;) if [ -z \u0026#34;$InstallUpgradeMsg\u0026#34; ];then rm -f \u0026#34;$UniqueName\u0026#34;-uris.txt exit 0 fi ## In $InstallUpgradeMsg is not null, then proceed... ## If confirm is true if [ \u0026#34;$Confirm\u0026#34; == \u0026#34;True\u0026#34; ];then echo -n \u0026#34;Do you want to continue [y|n]? \u0026#34; read Ans case \u0026#34;$Ans\u0026#34; in y|yes|\u0026#34;\u0026#34;) ;; n|no|*) echo \u0026#34;Abort.\u0026#34; rm -f \u0026#34;$UniqueName\u0026#34;-uris.txt exit 1 ;; esac fi if [ $NumberOfPackages -ne 0 ];then ## Downloading the packages echo \u0026#34;Proceeding with downloading ...\u0026#34; while read DebUrl do DebName=$(basename \u0026#34;$DebUrl\u0026#34;) echo \u0026#34;$DebName\u0026#34; AptConf=\u0026#34;/etc/apt/apt.conf\u0026#34; if [ -f \u0026#34;$AptConf\u0026#34; ];then http_proxy=$(grep -i \u0026#34;http::proxy\u0026#34; \u0026#34;$AptConf\u0026#34; | cut -d \\\u0026#34; -f2) fi if [ -n \u0026#34;$http_proxy\u0026#34; ];then echo \u0026#34;Using proxy...\u0026#34; aria2c -c -s 10 -j 10 --http-proxy=$http_proxy \u0026#34;$DebUrl\u0026#34; else echo \u0026#34;Not using proxy...\u0026#34; aria2c -c -s 10 -j 10 \u0026#34;$DebUrl\u0026#34; fi if [ $? -eq 0 ];then mv $DebName ${ArchiveDir} fi done \u0026lt; \u0026#34;$UniqueName\u0026#34;-uris.txt fi rm -f \u0026#34;$UniqueName\u0026#34;-uris.txt # echo \u0026#34;Installing...\u0026#34; if [ \u0026#34;$Install\u0026#34; == \u0026#34;True\u0026#34; ];then apt-get -y --force-yes ${Options} fi else ## Cases when download is false apt-get ${Options} fi PPA 软件仓库是一组文件，其中包含各种软件及其版本的信息，以及校验和等其他一些详细信息。每个版本的 Ubuntu 都有自己的四个官方软件仓库：\n Main - Canonical 支持的自由开源软件。 Universe - 社区维护的自由开源软件。 Restricted - 设备的专有驱动程序。 Multiverse - 受版权或法律问题限制的软件。  你可以在 这里 看到所有版本的 Ubuntu 的软件仓库。你可以浏览并转到各个仓库。\n这些信息存储在系统的 /etc/apt/sources.list 文件中。如果查看此文件的内容，你就会看到里面有软件仓库的网址。# 开头的行将被忽略。\nUbuntu 不会在官方仓库中立即提供新版本的软件。他们需要一个步骤来检查此新版本的软件是否与系统兼容，从而可以确保系统的稳定性。这意味着它需要经过几周才能在 Ubuntu 上可用，在某些情况下，这可能需要几个月的时间。\n为获取最新版本的软件，需要使用 PPA，PPA (Personal Package Archives) 允许开发者上传要构建的 Ubuntu 源包，并通过 Launchpad 作为 apt 的软件仓库发布。\n通过如下命令添加 PPA 软件仓库并获取最新版本软件：\n$ sudo add-apt-repository \u0026lt;PPA_info\u0026gt; $ sudo apt-get update $ sudo apt-get install \u0026lt;package_in_PPA\u0026gt; 当你使用 PPA 时，它不会更改原始的 sources.list 文件。相反，它在 /etc/apt/sources.d 目录中创建了两个文件，一个 .list 文件和一个带有 .save 后缀的备份文件。这是一种安全措施，可以确保添加的 PPA 不会和原始的 sources.list 文件弄混，它还有助于移除 PPA。\n开发人员为他们的软件创建的 PPA 称为官方 PPA。但有时，个人会创建由其他开发人员所创建的项目的 PPA。为什么会有人这样做？ 因为许多开发人员只提供软件的源代码。\n如果 PPA 不适用于你的系统版本，你可以点击应用程序 PPA 页面的 View package details，在这里，你可以单击软件包以显示更多详细信息，还可以在此处找到包的源代码和 DEB 文件。建议 使用 Gdebi 安装这些 DEB 文件 而不是通过软件中心，因为 Gdebi 在处理依赖项方面要好得多。\n就安全性而言，很少见到因为使用 PPA 之后你的 Linux 系统被黑客攻击或注入恶意软件。到目前为止，我不记得发生过这样的事件。官方 PPA 可以不加考虑的使用，使用非官方 PPA 完全是你自己的决定。根据经验，如果程序需要 sudo 权限，则应避免通过第三方 PPA 进行安装。\nAPT Proxy   Create a new configuration file named proxy.conf.\nsudo touch /etc/apt/apt.conf.d/proxy.conf   Open the proxy.conf file in a text editor.\nsudo vi /etc/apt/apt.conf.d/proxy.conf   Add the following line to set your HTTP proxy.\nAcquire::http::Proxy \u0026quot;http://user:password@proxy.server:port/\u0026quot;;   Add the following line to set your HTTPS proxy.\nAcquire::https::Proxy \u0026quot;http://user:password@proxy.server:port/\u0026quot;;   Save your changes and exit the text editor. Your proxy settings will be applied the next time you run Apt.\n  OR create a new file under the /etc/apt/apt.conf.d directory, and then add the following lines.\nAcquire { HTTP::proxy \u0026quot;http://127.0.0.1:8080\u0026quot;; HTTPS::proxy \u0026quot;http://127.0.0.1:8080\u0026quot;; } OR\n$ sudo -E apt install OR \u0026hellip;\nSnap \u0026amp; Flatpak 什么是Snap应用 如果你在使用Ubuntu 18.04/20.04 LTS版本的Ubuntu系统，会发现系统里面多了一个应用格式包——.snap包。Snap包是Ubuntu 16.04 LTS发布时引入的新应用格式包。\n当你在安装完snap后，你会发现在在根目录下会出现如/dev/loop0的挂载点，这些挂载点正是snap软件包的目录。Snap使用了squashFS文件系统，一种开源的压缩，只读文件系统，基于GPL协议发行。一旦snap被安装后，其就有一个只读的文件系统和一个可写入的区域。应用自身的执行文件、库、依赖包都被放在这个只读目录，意味着该目录不能被随意篡改和写入。\nsquashFS文件系统的引入，使得snap的安全性要优于传统的Linux软件包。同时，每个snap默认都被严格限制（confined），即限制系统权限和资源访问。但是，可通过授予权限策略来获得对系统资源的访问。这也是安全性更好的表现。\nSnap可包含一个或多个服务，支持cli（命令行）应用，GUI图形应用以及无单进程限制。因此，你可以单个snap下调用一个或多个服务。对于某些多服务的应用来说，非常方便。前面说到snap间相互隔离，那么怎么交换资源呢？答案是可以通过interface（接口）定义来做资源交换。interface被用于让snap可访问OpenGL加速，声卡播放、录制，网络和HOME目录。Interface由slot和plug组成即提供者和消费者。\n目前，Ubuntu的相关产品已以snap包的形式发布，例如Ubuntu MAAS，Juju，Multipass，MicroK8s，MicroStack等等。\nsnap \u0026ldquo;canonical-livepatch\u0026rdquo; has \u0026ldquo;install-snap\u0026rdquo; change in progress\nSnap 包是 Ubuntu 16.04 LTS 发布时引入的新应用格式包。目前已流行在很多 Linux 发行版上。并且可以很方便地安装常用软件，如 VLC、Sublime Text、VSCode、Node、WPS等\n当你在安装完 Snap 后，你会发现在在根目录下会出现如 /dev/loop0 的挂载点，这些挂载点正是 Snap 软件包的目录。\n  原因是软件之前安装了一次，只是安装失败。\n$ snap changessnap abort 5 ## 5 为安装失败软件的 ID   现在重新安装\n  一些软件最好在官网下载或在 Snap 中下载，官方 Repository 可能并不新，比如 VLC。\nWhy does \u0026ldquo;Automatically connect eligible plugs and slots of snap \u0026ldquo;okular\u0026rdquo;\u0026rdquo; take a relatively long time?\nIs just a way to indicate that supplementary material is being downloaded.\nIf one keeps Ubuntu\u0026rsquo;s system monitor open at the same time, it\u0026rsquo;s quite evident that \u0026ldquo;Automatically connect eligible plugs and slots \u0026hellip;\u0026rdquo; means a download is in progress.\n所以，解决办法是用 proxychains。\nSpeed Up Downloading This simple tutorial shows how to speed up the downloading process of snap application package by associating IP address with the snapcraft server in Ubuntu.\n1.) Open terminal either via Ctrl+Alt+T keyboard shortcut or by searching for ‘terminal’ from application menu. When terminal opens, run command:\n$ dig fastly.cdn.snapcraft.io fastly.cdn.snapcraft.io is deprecated. Get more Snapcraft Download CDNs\nIn the terminal output, copy the IP address under ‘ANSWER SECTION’.\n2.) Then run commands to edit the hosts file:\n$ sudo gedit /etc/hosts Type user password (no asterisk) when it prompts and hit Enter.\nWhen the files opens in gedit text editor, paste following line:\n$ 151.101.42.217 fastly.cdn.snapcraft.io Replace the IP address with which you got in step 1, and finally save the file.\n为Snapd设置代理 Snap，全称SnapCraft，是一个全新的应用软件环境。在Snap中，软件被封装在类似于Docker的容器中，即开即用，可随时获取，这一切由其后台服务snapd提供支持。Ubuntu从18.04开始，就引入它作为系统的一部分，而其他的Linux发行版（如Deepin）也可以通过软件管理工具进行安装（如sudo apt install snapd）。\nSnapCraft将软件包分发在自己的服务器上。然而，因为众所周知的原因，访问位于海外的Snap服务器异常缓慢，不加代理的情况下，下载速度会持续降到十几KB每秒。这使得我们不得不想办法通过代理服务器进行加速。\n一般地，Linux上的一些应用程序会通过读取环境变量http_proxy和https_proxy来应用代理服务器设置，典型的有Chrome。然而，Snap比较特别，它不会从环境变量中上述环境变量中读取代理服务器设置，因此直接使用export http_proxy=[代理服务器地址]或export https_proxy=[代理服务器地址]是不起作用的。\n那么，有何正确的方法？\n方法一：更改/etc/environment\n/etc/environment是一个Shell脚本，snapd会读取它，应用其中指定的配置信息。因此，设置代理服务器的正确目标，实际上就是这里。\n在/etc/environment中加入：\nhttp_proxy=http://[服务器地址]:[端口号] https_proxy=http://[服务器地址]:[端口号] 然后重启snapd服务：\n$ sudo systemctl restart snapd A system option was added in snap 2.28 to specify the proxy server.\n$ sudo snap set system proxy.http=\u0026#34;http://\u0026lt;proxy_addr\u0026gt;:\u0026lt;proxy_port\u0026gt;\u0026#34; $ sudo snap set system proxy.https=\u0026#34;http://\u0026lt;proxy_addr\u0026gt;:\u0026lt;proxy_port\u0026gt;\u0026#34; Documentation\n方法二：覆盖snapd的现有设置\n除了修改environment文件，也可以修改snapd服务的配置文件，在其加入Environment信息，信息内容实际上就是“方法一”中设置代理服务器的语句。\n运行以下命令，打开snapd的配置文件：\n$ sudo systemctl edit snapd.service 在打开的文本编辑器中，加入以下语句：\n[Service] Environment=http_proxy=http://proxy:port Environment=https_proxy=http://proxy:port 最后重新加载snapd服务：\n$ sudo systemctl daemon-reload $ sudo systemctl restart snapd.service 注意事项\n一般的本地代理都不支持HTTPS，所以https_proxy的值也只能是http地址，否则会出现如下错误：\ncannot install \u0026#34;conjure-up\u0026#34;: Post https://api.snapcraft.io/v2/snaps/refresh: proxyconnect tcp: EOF Snap 深远意义 近日,Ubuntu推出了Snap应用包格式,受到各主流发行版和软件基金会欢迎.这有何深远意义?\n  farseerfc\n首先「受到各主流发行版和软件基金会欢迎」這句可是 Ubuntu 的人說給媒體人的，別的發行版都還沒表態，見我另一個回答\nFlatpak 和 Snap package 技术上有何区别？各有何优劣？如何看待两者的发展前景？ - fc farseer 的回答\n然後，容器技術的重要性和 Linux 上第三方軟件開發商打包困難的問題很多人都提到了，都說得不錯，不再複述。\n我就提一下爲什麼 Ubuntu 要做這個，爲什麼 Ubuntu 要在這個時候大張旗鼓推這個。\n在操作系統領域幾十年來經久未變的一點是，操作系統本身不重要，重要的是能跑在其上的應用程序，現在的話說是生態環境。而應用程序不是針對操作系統本身撰寫，應用程序是針對操作系統提供的API/SDK撰寫，換句話說，掌握了API/SDK的控制權，就掌握了最寶貴的應用程序開發者，操作系統本身就得以長久發展。這就是爲什麼 Windows 遠比 Mac 賣得好的道理，Windows 掌握着桌面操作系統裏最穩定的SDK，幾十年來保持兼容性未曾變過，而 Mac 時常破壞 API 兼容性使得老程序不能再跑在新系統上。這個道理\nHow Microsoft Lost the API War\n這篇文章闡述得非常明白。\nGNU/Linux 乃至整個 FOSS 社區，在這一點上，其實非常另類。 GNU 系統從來沒有把「保持程序兼容性以吸引用戶和開發者」放在首要目標，GNU 的首要目標是「給用戶以自由」。那麼 GNU/Linux 的應用程序兼容性不好麼？並不見得，幾十年前的 ed/vi/xterm 程序現在還好好得跑在 各大發行版上，一些程序比 Windows 上的軟件還要古老很多。但是這並不是 GNU/Linux 和各大發行版致力於保護兼容性的結果，而是這些軟件「自由」的結果。因爲他們自由且開源，發行版維護者們可以拿他們的源代碼重新編譯以利用新的軟件庫新的 ABI ；因爲他們自由而且開源，上游維護者可以不斷更新他們的代碼讓他們適應新的技術新的框架新的 API ；因爲他們自由而且開源，當上游開發者放棄項目不再開發的時候，還會有有志之士挺身而出接替開發維護的職責。換句話說，在 Linux 發行版上，軟件的兼容性好是軟件自由的直接結果。\n這就是現在 GNU/Linux 發行版們打包軟件發佈軟件的模式，大家努力的目標是給予用戶自由。這一模式在自由開源軟件上非常有效，但是面對閉源軟件就不那麼有效了。閉源軟件的源代碼在開發者手上，沒有發行版打包者做銜接工作，所以閉源軟件在 GNU/Linux 上發佈起來非常困難。軟件的自由，除了乾淨放心保證隱私外對普通用戶來說沒有立竿見影的優勢，只對軟件開發者們有意義，所以 GNU/Linux 發行版一直是程序員的天堂，用戶的地獄。\n而 Ubuntu 作爲一個發行版，並沒有共享傳統發行版的自由精神。從一開始，Ubuntu努力的首要目標就不是給用戶自由，而是擴大普通用戶的基數。Ubuntu看到，對普通用戶而言，閉源軟件尤其是商業軟件同等重要甚至可能更重要，普通用戶寧願忍受不自由，寧願放棄隱私放棄控制權，也不願使用那些表面粗質功能匱乏的開源替代。所以 Ubuntu 需要打破傳統發行版的發佈方式，讓商業閉源軟件也能在 GNU/Linux 上輕鬆發佈。\n而且這條路的可行性早就驗證過了。Google 通過給 Linux 內核上包裝一層 Apache 協議的「自由性中立」的 userland 層，禁錮住了 GPL 的病毒傳播性，開發出 Android 系統，發展出 Android 之上的生態環境，吸引到了無數開發者爲其平臺寫（大部分閉源）軟件。另一點 Valve 通過 Steam 作爲兼容層，附帶大量依賴庫並保持 API 足夠穩定，同時充當遊戲開發者和 Steam 兼容層之間的橋樑，也順利地招攬到不少遊戲開發商爲 Steam 移植 Linux 平臺遊戲。這兩個先例都啓迪 Ubuntu ，這件事可以做並且可以做好。\n並且現在做 Snap 對 Ubuntu 有一個重大的好處，在於壟斷 SDK 控制權。Snap 架空了發行版提供的包管理器，甚至架空了發行版本身（提供的依賴庫），從而對開發者而言，針對 Snap 提供軟件包就不需要考慮發行版（這是好事）。如果 Snap 受到足夠多的開發者支持，發展出成熟的生態，那麼 Ubuntu 也就不再發愁今後的推廣之路了，因爲 Ubuntu 上的 Snap 支持必然比別的發行版要好。目前 Snap 上發佈或者安裝軟件包需要 Ubuntu One 身份認證，屬於中央化的 App Store 模式，這給予 Ubuntu 最直接的控制權（而不是 Ubuntu 宣稱的把控制權從發行版交還給開發者），到時候 Ubuntu 攜應用以令用戶，用戶並沒有選擇的權利和自由。另一點，Ubuntu要做手機系統做IoT系統，面向的用戶群就是 Android/iOS 的用戶群，這樣的用戶群下，用自由開源的生態在短期內顯然難以抗衡，所以必須引入商業生態，從而提供類似的軟件商店也是 Ubuntu 的必由之路。\n最開始的時候，Ubuntu 最大的敵人是微軟，這是它的 launchpad 上第一個 bug\nBug #1 (liberation) â€œMicrosoft has a majority market shareâ€ : Bugs : Ubuntu（Ubuntu第一个BUG：微软在新的桌面 PC 市场中占有多数市场份额。这是 Ubuntu 和其他项目旨在修复的错误。）\n現在 Ubuntu 和微軟成爲了合作關係，然後矛頭調轉直指一衆發行版，司馬昭之心可以想象。\n问题\n那用snap不需要依赖了吗？还是自带依赖？\n回答\nsnap沒看懂它準備怎麼搞， flatpak的做法似乎是分成「框架包」和「軟件包」，框架包是類似 gtk3 、qt5 這種非常大的東西，整個作爲一個框架，軟件包依賴框架包，然後自帶一些小的不屬於框架的依賴。\n问题\n“因爲他們自由而且開源”\n请问这里的“自由”的精确含义是什么？\n回答\n「用户可以自由地运行，拷贝，分发，学习，修改并改进该软件」(什么是自由软件？) 注意自由和開源並不是等價的，有些軟件，比如 kindle 的系統，是完全用 GPL 協議開源的，可以隨意獲取，但是很難修改它的軟件裝到 kindle 上去用。有另一些軟件，雖然沒有用開源協議開源，但是相對能很容易地獲取到源碼並且修改使用，比如很多大學的研究項目可以直接問負責人要到源碼。\n  梦断代码\n并不受欢迎啊，基于ubuntu的一大堆发行版，比如mint，zorin，直接不管snap，反而使用flatpak。\n说实话，snap挺作死的，当初unity桌面做的好好的，非要砍掉，snap应用却不砍，很迷惑，unity想统一桌面和手机，snap就是新的应用商店，还可以跨电脑和手机，可以说野心很大。可是unity没了，snap留着干嘛？\n说是跨发行版，其实它太致命了，它同时支持桌面应用和命令行应用，然而都做的不行，比如neovim，装了snap版的，然而neovim这货又是远程通信支持语言的。比如node.js，同时用snap版的nvim和nodejs会发现nvim根本用不了node.js，因为snap这容器直接把这俩货隔离了。这只是其中一个。桌面应用简直群魔乱舞，wps好几个版本，都是不同人上传的，这不像flathub，flathub有点像github，可以直接像提pr一样给作者提交新版本，而snap，只要某软件作者不维护，你想用新的只能另开一个。\n重点是snap还闭源，所以没法搭建镜像，其他厂商想接入也不好接入。\n  Difference between Snap and Flatpak Flatpak is designed to install and update “apps”; user-facing software such as video editors, chat programs and more.\nsnaps can install anything which contains a kernel, printer drivers, audio subsystems and more.\nSnap and Flatpak are the software behind two universal Linux app stores: the Snap Store and Flathub.\nAppImage Wiki 做得对比图表。\n群讨论 openSUSE 群\nFlatpak使用bubblewrap来隔离应用程序，bwrap是非常轻量化的沙箱程序，因此攻击面极小。但bwrap需要用户对Linux程序工作方式有准确的了解（使用哪些syscall），Flatpak相当于充当了一个bwrap的前端帮助控制bwrap权限。\n目前Flatpak的问题在于seccomp权限太过广泛，但目前Flatpak维护者已经意识到了这个问题（注释：在他们踩了一次坑之后），已经计划打算解决了。\n另一个问题是程序请求的权限过于广泛，但这更多是一个决策问题而不是技术问题，而且你可以用Flatseal手动调整权限。\nFlatpak你不能用常规程序方式来理解，每个程序都是一个完全独立的空间，只有给予了权限才有对应访问权，也可以用Portals调用文件选择器来获得单独一个文件的完全访问权，Flatpak版的Steam是把所有程序配置文件放在~/.var/app里面了，类似安卓下面的分区存储做法。\nAppImage就只是个自挂载程序，自带的文件透明挂载到它自己的根文件系统下面，所以依然依赖主机的一部分库。所以是的，跟打包者用的系统有关系。\nFlatpak不是这种机制，每个Flatpak空间是完全空白的，需要打包者自己选择加入哪些东西，所以Flatpak跨发行版的兼容性也更好。\n良好打包的AppImage可以有很好的跨发行版兼容性，但是代价就是需要手工测试每个发行版下面的效果。在跨发行版兼容性这点上我更看好Flatpak。\n最后，不要跟我提Snap，我不想碰那个东西，也对它没有研究的兴趣。\nFlatpak确实有很多可取之处，或者不能说是Flatpak可取，而是Linux桌面软件生态现状决定了，只有更激进的手段才能改变现状。\nAppImage那种策略还是过于不痛不痒了，结果就是程序仅仅是被打包成一个个单文件，但背后的库依赖地狱、权限隔离问题一个都没解决。\n但AppImage作者的想法本来也不是靠AppImage颠覆，他是希望Linux能够重新恢复LSB，确保发行版之间的兼容性本身可靠而不是依赖Flatpak这些技术，就类似于Windows上的软件不需要什么沙箱模拟器，你几乎可以保证旧版本的软件能在新版本运行。\n其实也可以说明，微软那种在桌面上采取的策略，很可能难以在Linux社区里推广开来，微软那种做法，确保绝对的向下兼容性，不是谁都有精力来做的。\n比如说如果让微软来做Wayland，那微软根本就不会把Wayland做出来，而是把X11一直迭代、削减臃肿功能直到性能和现代化图形技术栈的性能相匹敌，同时确保向下兼容性。而最新一代的X11很可能和最早的X11已经彻底不一样了，甚至会有“检测程序版本然后自动匹配对应的X11功能”这些奇怪的兼容性策略出来。或许有一天微软会把新项目叫做Wayland，但这个改名也仅仅是营销目的而不是技术目的。\n毕竟LSB已经没了，Ubuntu甚至砍掉32位兼容性，也可以说明其实Linux这边并没有太多人在乎这问题。\n毕竟“反正源代码都在那，重新编译一遍不就好了吗”\nFedora 群\n空のあお, [2/28/22 8:25 PM] 软件有不同版本的依赖 这些依赖很难共存 有些旧版依赖还有更旧的依赖 不说二进制兼容，有些连源码兼容都搞不定 就算搞定了，一段时间过后依赖升级了，还是得坏 flatpak的做法是维护abi稳定的qt和gtk两大ui库和必要桌面库的runtime，用来公用 通过容器隔离app，让每个app自己构建所需的特定依赖到容器里\n竹林里有冰, [2/28/22 8:33 PM] sandbox他是用bubblewrap实现的吧，你可以直接使用bubblewrap，应该一样可以做到他的沙盒化，更小巧一点 bubblewrap的缺点就是需要针对每个程序写上配置，除了有点麻烦其他倒还不错\nNeomonk Zen, [2/28/22 8:36 PM] 也不知flatpak的软件仓库，有没什么审核机制来防止恶意软件，如果没有的话，那还蛮可怕的，想想Chrome和Android的软件市场，都有很多恶意软件\nRobin Lee, [2/28/22 8:39 PM] 没有深入的审核，跟各大发行版的官方包差不多，但flatpak可以限制应用权限\n使用 Flatpak The official Flatpak PPA is the recommended way to install Flatpak. To install it, run the following in a terminal:\n$ sudo add-apt-repository ppa:flatpak/stable $ sudo apt update $ sudo apt install flatpak Flathub is the best place to get Flatpak apps. To enable it, run:\n$ sudo flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo To complete setup, restart your system. Now all you have to do is install some apps!\n上海交大 Flathub 镜像\n$ sudo flatpak remote-modify flathub --url=https://mirror.sjtu.edu.cn/flathub Flathub 中部分软件由于重分发授权问题，需要从官方服务器下载，无法使用镜像站加速。比如 NVIDIA 驱动、JetBrains 系列软件等。\n如果您中断了某次安装，重新下载可能会出现找不到文件的问题。您可以使用 flatpak repair 解决相关的问题。\nAsian Font Problems with Flatpak\n如果你遇到了游戏中无法显示亚洲字体的问题，这是因为 org.freedesktop.Platform 并没有包含合适的字体文件进去。首先尝试挂载你的本地字体：\n$ flatpak run --filesystem=~/.local/share/fonts --filesystem=~/.config/fontconfig com.valvesoftware.Steam 如果上述命令不起作用，考虑动手 hack 一下：直接将字体文件复制进 org.freedesktop.Platform 的目录下以启用字体，例如\n# replace ? with your version and hash /var/lib/flatpak/runtime/org.freedesktop.Platform/x86_64/?/?/files/etc/fonts/conf.avail /var/lib/flatpak/runtime/org.freedesktop.Platform/x86_64/?/?/files/etc/fonts/conf.d /var/lib/flatpak/runtime/org.freedesktop.Platform/x86_64/?/?/files/share/fonts tasksel: Install Group Software 安装\n$ sudo apt install tasksel list tasks\n$ tasksel --list-tasks displays description\n$ tasksel --task-desc dns-server install\n$ sudo apt install dns-server pacstall An AUR-inspired package manager for Ubuntu\nAppImage Linux apps that run anywhere\n包管理器的进化 今天，每个可计算设备都会使用某种软件来完成预定的任务。在软件开发的上古时期，为了找出软件中的 bug 和其它缺陷，软件会被严格的测试。在近十年间，软件被通过互联网来频繁分发，以试图通过持续不断的安装新版本的软件来解决软件的缺陷问题。在很多情况下，每个独立的应用软件都有其自带的更新器。而其它一些软件则让用户自己去搞明白如何获取和升级软件。\nLinux 较早采用了维护一个中心化的软件仓库来发布软件更新这种做法，用户可以在这个软件仓库里查找并安装软件。在这篇文章里， 笔者将回顾在 Linux 上的如何进行软件安装的历史，以及现代操作系统如何保持更新以应对软件安全漏洞（CVE）不断的曝光。\n手动安装软件 曾几何时，软件都是通过 FTP 或邮件列表（LCTT 译注：即通过邮件列表发布源代码的补丁包）来分发的（最终这些发布方式在互联网的迅猛发展下都演化成为一个个现今常见的软件发布网站）。（一般在一个 tar 文件中）只有一个非常小的文件包含了创建二进制的说明。你需要做的是先解压这个包，然后仔细阅读当中的 README 文件， 如果你的系统上恰好有 GCC（LCTT 译注：GNU C Compiler）或者其它厂商的 C 编译器的话，你得首先运行 ./configure 脚本，并在脚本后添加相应的参数，如库函数的路径、创建可执行文件的路径等等。除此之外，这个配置过程也会检查你操作系统上的软件依赖是否满足安装要求。如果缺失了任何主要的依赖，该配置脚本会退出不再继续安装，直到你满足了该依赖。如果该配置脚本正常执行完毕，将会创建一个 Makefile 文件。\n当有了一个 Makefile 文件时， 你就可以接下去执行 make 命令（该命令由你所使用的编译器提供）。make 命令也有很多参数，被称为 make 标识flag，这些标识能为你的系统优化最终生成出来的二进制可执行文件。在计算机世界的早期，这些优化是非常重要的，因为彼时的计算机硬件正在为了跟上软件迅速的发展而疲于奔命。今日今时，编译标识变得更加通用而不是为了优化哪些具体的硬件型号，这得益于现代硬件和现代软件相比已经变得成本低廉，唾手可得。\n最后，在 make 完成之后， 你需要运行 make install （或 sudo make install）（LCTT 译注：依赖于你的用户权限） 来“真正”将这个软件安装到你的系统上。可以想象，为你系统上的每一个软件都执行上述的流程将是多么无聊费时，更不用说如果更新一个已经安装的软件将会多复杂，多么需要精力投入。（LCTT 译注：上述流程也称 CMMI 安装， 即Configure、Make、Make Install）\n软件包 package（LCTT 译注：下文简称“包”）这个概念是用来解决在软件安装、升级过程中的复杂性的。包将软件安装升级中需要的多个数据文件合并成一个单独的文件，这将便于传输和（通过压缩文件来）减小存储空间（LCTT 译注：减少存储空间这一点在现在已经不再重要），包中的二进制可执行文件已根据开发者所选择的编译标识预编译。包本身包括了所有需要的元数据，如软件的名字、软件的说明、版本号，以及要运行这个软件所需要的依赖包等等。\n不同流派的 Linux 发行版都创造了它们自己的包格式，其中最常用的包格式有：\n .deb：这种包格式由 Debian、Ubuntu、Linux Mint 以及其它的变种使用。这是最早被发明的包类型。 .rpm：这种包格式最初被称作红帽包管理器Red Hat Package Manager（LCTT 译注： 取自英文的首字母）。使用这种包的 Linux 发行版有 Red Hat、Fedora、SUSE 以及其它一些较小的发行版。 .tar.xz：这种包格式只是一个软件压缩包而已，这是 Arch Linux 所使用的格式。  尽管上述的包格式自身并不能直接管理软件的依赖问题，但是它们的出现将 Linux 软件包管理向前推进了一大步。\n软件仓库 多年以前（当智能电话还没有像现在这样流行时），非 Linux 世界的用户是很难理解软件仓库的概念的。甚至今时今日，大多数完全工作在 Windows 下的用户还是习惯于打开浏览器，搜索要安装的软件（或升级包），下载然后安装。但是，智能电话传播了软件“商店”（LCTT 译注： 对应 Linux 里的软件仓库）这样一个概念。智能电话用户获取软件的方式和包管理器的工作方式已经非常相近了。些许不同的是，尽管大多数软件商店还在费力美化它的图形界面来吸引用户，大多数 Linux 用户还是愿意使用命令行来安装软件。总而言之，软件仓库是一个中心化的可安装软件列表，上面列举了在当前系统中预先配置好的软件仓库里所有可以安装的软件。\n包管理器 包管理器用来和相应的软件仓库交互，获取软件的相应信息。下面对流行做一个简短介绍。\n基于 PRM 包格式的包管理器 更新基于 RPM 的系统，特别是那些基于 Red Hat 技术的系统，有着非常有趣而又详实的历史。实际上，现在的 YUM 版本（用于 企业级发行版）和 DNF（用于社区版）就融合了好几个开源项目来提供它们现在的功能。\nRed Hat 最初使用的包管理器，被称为 RPM（红帽包管理器Red Hat Package Manager），时至今日还在使用着。不过，它的主要作用是安装本地的 RPM 包，而不是去在软件仓库搜索软件。后来开发了一个叫 up2date 的包管理器，它被用来通知用户包的最新更新，还能让用户在远程仓库里搜索软件并便捷的安装软件的依赖。尽管这个包管理器尽职尽责，但一些社区成员还是感觉 up2date 有着明显的不足。\n现在的 YUM 来自于好几个不同社区的努力。1999-2001 年一群在 Terra Soft Solution 的伙计们开发了Yellowdog Updater（YUP），将其作为 Yellow Dog Linux 图形安装器的后端。杜克大学Duke University喜欢这个主意就决定去增强它的功能，它们开发了Yellowdog Updater, Modified（YUM），这最终被用来帮助管理杜克大学的 Red Hat 系统。Yum 壮大的很快，到 2005 年，它已经被超过一半的 Linux 市场所采用。今日，几乎所有的使用 RPM 的的 Linux 都会使用 YUM 来进行包管理（当然也有一些例外）。\nDandified Yum（DNF）是 YUM 的下一代接班人。从 Fedora 18 开始被作为包管理器引入系统，不过它并没有被企业版所采用，所以它只在 Fedora（以及变种）上占据了主导地位。DNF 的用法和 YUM 几乎一模一样，它主要是用来解决性能问题、晦涩无说明的API、缓慢/不可靠的依赖解析，以及偶尔的高内存占用。DNF 是作为 YUM 的直接替代品来开发的，因此这里笔者就不重复它的用法了，你只用简单的将 yum 替换为 dnf 就行了。\nZypper 是用来管理 RPM 包的另外一个包管理器。这个包管理器主要用于 SUSE（和 openSUSE），在MeeGo、Sailfish OS、Tizen 上也有使用。它最初开发于 2006 年，已经经过了多次迭代。除了作为系统管理工具 YaST 的后端和有些用户认为它比 YUM 要快之外也没有什么好多说的。\n基于 Debian 的包管理器 作为一个现今仍在被积极维护的最古老的 Linux 发行版之一，Debian 的包管理系统和基于 RPM 的系统的包管理系统非常类似。它使用扩展名为 “.deb” 的包，这种文件能被一个叫做 dpkg 的工具所管理。dpgk 同 rpm 非常相似，它被设计成用来管理在存在于本地（硬盘）的包。它不会去做包依赖关系解析（它会做依赖关系检查，不过仅此而已），而且在同远程软件仓库交互上也并无可靠的途径。为了提高用户体验并便于使用，Debian 项目开始了一个软件项目：Deity，最终这个代号被丢弃并改成了现在的 Advanced Pack Tool（APT）。\n在 1998 年，APT 测试版本发布（甚至早于 1999 年的 Debian 2.1 发布），许多用户认为 APT 是基于 Debian 系统标配功能之一。APT 使用了和 RPM 一样的风格来管理仓库，不过和 YUM 使用单独的 .repo 文件不同，APT 曾经使用 /etc/apt/sources.list 文件来管理软件仓库，后来的变成也可以使用 /etc/apt/sources.d 目录来管理。如同基于 RPM 的系统一样，你也有很多很多选项配置来完成同样的事情。你可以编辑和创建前述的文件，或者使用图形界面来完成上述工作（如 Ubuntu 的“Software \u0026amp; Updates”）。\n现今大多数的 Ubuntu 教程里都径直使用了 apt。 单独一个 apt 设计用来实现那些最常用的 APT 命令的。apt 命令看上去是用来整合那些被分散在 apt-get、apt-cache 以及其它一些命令的的功能的。它还加上了一些额外的改进，如色彩、进度条以及其它一些小功能。\n基于 Arch 的包管理器 Arch Linux 使用称为 packman 的包管理器。和 .deb 以及 .rpm 不同，它使用更为传统的 LZMA2 压缩包形式 .tar.xz 。这可以使 Arch Linux 包能够比其它形式的压缩包（如 gzip）有更小的尺寸。自从 2002 年首次发布以来， pacman 一直在稳定发布和改善。使用它最大的好处之一是它支持 Arch Build System，这是一个从源代码级别构建包的构建系统。该构建系统借助一个叫 PKGBUILD 的文件，这个文件包含了如版本号、发布号、依赖等等的元数据，以及一个为编译遵守 Arch Linux 需求的包所需要的带有必要的编译选项的脚本。而编译的结果就是前文所提的被 pacman 所使用的 .tar.xz 的文件。\n上述的这套系统技术上导致了 Arch User Respository（AUR）的产生，这是一个社区驱动的软件仓库，仓库里包括有 PKGBUILD 文件以及支持补丁或脚本。这给 Arch Linux 带了无穷无尽的软件资源。最为明显的好处是如果一个用户（或开发者）希望他开发的软件能被广大公众所使用，他不必通过官方途径去在主流软件仓库获得许可。而不利之处则是它必须将依赖社区的流程，类似于 Docker Hub、 Canonical 的 Snap Packages（LCTT 译注： Canonical 是 Ubuntu 的发行公司），或者其它类似的机制。\n有很多特定于 AUR 的包管理器能被用来从 AUR 里的 PGKBUILD 文件下载、编译、安装。其中 yaourt 和 pacaur 颇为流行。不过，这两个项目已经被 Arch Wiki 列为“不继续开发以及有已知的问题未解决”。因为这个原因，这里直接讨论 aurman，除了会搜索 AUR 以及包含几个有帮助的（其实很危险）的选项之外，它的工作机制和 pacman 极其类似。\nconda 简介 Conda 是一个开源的软件包管理系统和环境管理系统，用于安装多个版本的软件包及其依赖关系，并在它们之间轻松切换。 Conda 是为 Python 程序创建的，适用于 Linux，OS X 和 Windows，也可以打包和分发其他软件。\n安装 conda分为anaconda和miniconda。anaconda是包含一些常用包的版本（这里的常用不代表你常用），miniconda则是精简版，需要啥装啥，所以推荐使用miniconda。\nminiconda官网：https://conda.io/miniconda.html\n选择适合自己的版本下载：\n$ wget -c https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh 这里选择的是latest-Linux版本，所以下载的程序会随着python的版本更新而更新。\n安装：\n$ chmod 777 Miniconda3-latest-Linux-x86_64.sh $ bash Miniconda3-latest-Linux-x86_64.sh 加不加入环境变量都可以。所谓的会污染环境等等问题可能都是将大量的软件直接安装在conda的base环境中引起的，只要养成好的使用习惯，灵活使用conda create 命令将不同的软件安装到自己单独的虚拟环境中就可以了。把conda这条蟒蛇关进一个一个的笼子里，才能更好的为我们的科研服务~\n添加频道 这个道理跟家里的电视机是一样一样的，安装conda就相当于买了一台电视机，但是有电视了不意味着你就能看节目了，你要手动添加频道才能看你想看的电视节目。\n添加清华的镜像channels：\n$ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ $ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ $ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ $ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ 为了分担清华源镜像的压力，北京外国语大学也开启了镜像站点，同样是由清华TUNA团队维护的，如果有小伙伴遇到清华源速度很慢的情况的话，可以考虑换成北外的镜像。\n$ conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/cloud/bioconda/ $ conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/cloud/conda-forge/ $ conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/free/ $ conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/main/ 显示安装的频道\n$ conda config --set show_channel_urls yes 查看已经添加的channels\n$ conda config --get channels 已添加的channel在哪里查看\n$ vim ~/.condarc 软件包管理 $ conda install gatk 搜索安装包 $ conda search gatk 安装完成后，可以用“which 软件名”来查看该软件安装的位置：\n$ which gatk 安装特定版本 $ conda install 软件名=版本号 $ conda install gatk=3.7 这时conda会先卸载已安装版本，然后重新安装指定版本。\n查看已安装软件 $ conda list 更新指定软件 $ conda update gatk 卸载指定软件 $ conda remove gatk 环境管理 退出conda环境 退出也很简单，之前我们是. ./activate 或者 (. ~/miniconda3/bin/activate)现在退出只要:\n$ . ./deactivate # 或者用  $ conda deactivate 就退出当前的环境了\n创建conda环境 之前创建的时候显示的是（base）这是conda的基本环境，有些软件依赖的是python2的版本，当你还是使用你的base的时候你的base里的python会被自动降级，有可能会引发别的软件的报错，所以，可以给一些特别的软件一些特别的关照，比如创建一个单独的环境。\n在conda环境下，输入conda env list（或者输入conda info --envs也是一样滴）查看当前存在的环境：\n$ conda env list 创建一个新的环境\n$ conda create -n python2 python=2  -n: 设置新的环境的名字 python=2 指定新环境的python的版本，非必须参数 这里也可以用一个-y参数，可以直接跳过安装的确认过程。  conda会创建一个新的python2的环境，并且会很温馨的提示你只要输入conda activate python2就可以启动这个环境了。\n删除环境 $ conda remove -n myenv --all 重命名环境 实际上conda并没有提供这样的功能，但是可以曲线救国，原理是先克隆一个原来的环境，命名成想要的名字，再把原来的环境删掉即可\n接下来演示把一个原来叫做py2的环境重新命名成python2：\n$ conda create -n python2 --clone py2 $ conda remove -n py2 --all 自动更新 Ubuntu 默认的配置会每天自动安装安全更新而忽略其它包的更新。\n更新机制 Ubuntu 默认定义了 4 个 systemd unit 执行更新任务，它们分别是：\n/lib/systemd/system/apt-daily-upgrade.service /lib/systemd/system/apt-daily-upgrade.timer /lib/systemd/system/apt-daily.service /lib/systemd/system/apt-daily.timer 中的 apt-daily.timer 和 apt-daily-upgrade.timer 是两个触发器，分别在每天指定的时间触发 apt-daily.service 和 apt-daily-upgrade.service。这两个 service 的类型都是 oneshot，意思是当任务完成后 service 进程退出。这两个 service 其实调用的是同一个脚本： /usr/lib/apt/apt.systemd.daily。apt-daily.service 为脚本传入参数 \u0026ldquo;update\u0026rdquo;，其功能为检查系统的更新并下载对应的更新包。apt-daily-upgrade.service 为脚本传入参数 \u0026ldquo;install\u0026rdquo;，其功能为安装更新并删除缓存在本地的更新包。\napt-daily.timer 默认每天触发两次，分别为 6 点和 18 点，主要是为了缓解服务器端的下载压力。我们可以根据自身业务的特点设置合适的触发时间。\napt-daily-upgrade.service 默认每天在 6 点触发一次，我们也可以设置为其它时间，比如午夜。\napt.systemd.daily /usr/lib/apt/apt.systemd.daily 脚本负责完成与更新相关的一系列工作，这些工作主要分为两大块：\n 检查更新并下载更新包 安装更新并清理更新包  apt.systemd.daily 脚本中调用 apt-config 命令从 /etc/apt/apt.conf.d/10periodic 文件和 /etc/apt/apt.conf.d/20auto-upgrades 读中取配变量，并根据这些变量的值来控制系统的更新策略。下面我们介绍几个比较重要的配置项。\n隔多少天执行一次 apt-get update，默认是 1 天，0 表示不执行该操作：\nAPT::Periodic::Update-Package-Lists \u0026#34;1\u0026#34;; 隔多少天执行一次 apt-get upgrade \u0026ndash;download-only 下载更新包，0 表示不执行该操作：\nAPT::Periodic::Download-Upgradeable-Packages \u0026#34;0\u0026#34;; 下载的更新版被缓存在目录 /var/cache/apt/archives/ 中，执行升级操作时直接从缓存目录中读取包文件而不是从网络上下载。\n隔多少天执行一次 apt-get autoclean 清除无用的更新包，0 表示不执行该操作：\nAPT::Periodic::AutocleanInterval \u0026#34;0\u0026#34;; 隔多少天执行一次 Unattended-Upgrade 执行系统安全更新(或者所有包的更新)，0 表示不执行该操作：\nAPT::Periodic::Unattended-Upgrade \u0026#34;1\u0026#34;; 通过这些配置，我们可以控制自动更新的频率和行为。注意，到目前为止的配置还只能安装系统的安全更新，如果要想安装所有包的更新还需要其它的配置。\n在继续介绍后面的内容前，让我们先来了解一下 apt.systemd.daily 脚本中用到的 apt-config 命令和 apt.systemd.daily 脚本依赖的配置文件。\napt-config 命令\napt-config 是一个被 APT 套件使用的内部命令，使用它可以在脚本中提取 /etc/apt/apt.conf 目录下配置文件中的信息。\n比如，如果要在脚本中获取 APT::Periodic::Update-Package-Lists 的设置，可以使用下面的代码：\n#!/bin/bash ABC=0 eval $(apt-config shell ABC APT::Periodic::Update-Package-Lists) echo ${ABC} 此时脚本变量 ABC 中保存的就是 APT::Periodic::Update-Package-Lists 的值。\n10periodic 和 20auto-upgrades\n/etc/apt/apt.conf.d/10periodic 是 update-notifier-common 的配置文件：\n$ dpkg-query -S /etc/apt/apt.conf.d/10periodic update-notifier-common: /etc/apt/apt.conf.d/10periodic 在 ubuntu 16.04 和 18.04 中，这两个文件的默认内容是一样的。apt.systemd.daily 脚本在注释中说我们可以通过 /etc/apt/apt.conf.d/10periodic 文件自定义相关的变量值，它通过 get-config 命令来获得这些变量的值。但是测试的结果是 /etc/apt/apt.conf.d/20auto-upgrades 文件中的变量会覆盖 /etc/apt/apt.conf.d/10periodic 文件中的变量。看来是 get-config 命令根据文件名称的顺序，排在后面的文件中的变量会覆盖前面文件中的变量。\n在 desktop 版本中，通过 GUI 程序修改相关的变量，这两个文件都会被修改并保持一致，所以在 server 版中我们最好也同时修改这两个文件并保持其内容一致。\nunattended-upgrades Ubuntu 实际上是通过 unattended-upgrades 命令来自动安装更新的。Ubuntu 16.04/18.04 默认安装了这个包，如果碰到没有安装的情况你还可以通过下面的命令自行安装：\n$ sudo apt install unattended-upgrades unattended-upgrades 的配置文件为 /etc/apt/apt.conf.d/50unattended-upgrades。\n注意，unattended-upgrades 不仅能够安装系统的安全更新，还可以安装所有包的更新。但是默认的配置只安装安全更新，我们可以通过配置项让 unattended-upgrades 安装所有的包更新或者只安装安全更新。\nunattended-upgrades 命令被设计为通过 cron 定时执行系统更新，但在 Ubuntu 16.04/18.04 中是通过 systemd 的 timer unit 定时触发 service unit 执行的。\nunattended-upgrades 命令的日志文件存放在 /var/log/unattended-upgrades 目录下。\nunattended-upgrade 命令常见的用法之一是检查系统是否有更新：\n$ sudo unattended-upgrade --dry-run 另一种用法是安装更新：\n$ sudo unattended-upgrade 在 apt.systemd.daily 脚本中执行 unattended-upgrade 命令时，由于更新包已经提前下载到缓存目录了(/var/cache/apt/archives)，所以直接它直接使用缓存中的更新包。\n配置文件 50unattended-upgrades\n50unattended-upgrades 文件中的默认配置只是安装安全更新：\nUnattended-Upgrade::Allowed-Origins { \u0026#34;${distro_id}:${distro_codename}\u0026#34;; \u0026#34;${distro_id}:${distro_codename}-security\u0026#34;; \u0026#34;${distro_id}ESM:${distro_codename}\u0026#34;; // \u0026#34;${distro_id}:${distro_codename}-updates\u0026#34;; // \u0026#34;${distro_id}:${distro_codename}-proposed\u0026#34;; // \u0026#34;${distro_id}:${distro_codename}-backports\u0026#34;; }; 如果要自动安装所有包的更新，只要取消下面行的注释就行了：\n\u0026#34;${distro_id}:${distro_codename}-updates\u0026#34;; 我们还可以通过黑名单的方式指定不更新哪些包：\nUnattended-Upgrade::Package-Blacklist { \u0026#34;vim\u0026#34;; \u0026#34;libc6\u0026#34;; \u0026#34;libc6-dev\u0026#34;; \u0026#34;libc6-i686\u0026#34;; }; 下面的配置项指定在更新后移除无用的包：\nUnattended-Upgrade::Remove-Unused-Kernel-Packages \u0026#34;true\u0026#34;; Unattended-Upgrade::Remove-Unused-Dependencies \u0026#34;true\u0026#34;; 有些更新需要重启系统，而默认的配置是不重启系统的。下面的配置允许重启系统(更新完成后，如果需要重启，立即重启系统)：\nUnattended-Upgrade::Automatic-Reboot \u0026#34;true\u0026#34;; 但是多数情况下我们更期望指定一个时间让系统重启(如果需要重启，在下面配置中指定的时间重启系统)：\nUnattended-Upgrade::Automatic-Reboot-Time \u0026#34;02:38\u0026#34;; 在系统更新的过程中发生了错误怎么办？当然是通知管理员啦！下面的配置在发生错误时给管理员发送邮件：\nUnattended-Upgrade::Mail \u0026#34;user@example.com\u0026#34;; Unattended-Upgrade::MailOnlyOnError \u0026#34;true\u0026#34;; 注意：如果要向外网发送邮件，需要安装 mailx 等工具。\n关闭自动更新 如果你的主机运行在封闭的环境中，并且无法连接到有效的更新源，此时可以选择关闭自动更新功能。首选的方法是停止相关的服务：\n$ sudo systemctl stop apt-daily.service $ sudo systemctl stop apt-daily.timer $ sudo systemctl stop apt-daily-upgrade.service $ sudo systemctl stop apt-daily-upgrade.timer $ sudo systemctl disable apt-daily.service $ sudo systemctl disable apt-daily.timer $ sudo systemctl disable apt-daily-upgrade.service $ sudo systemctl disable apt-daily-upgrade.timer 或者修改自动更新程序的配置文件也可以，同时更新 /etc/apt/apt.conf.d/10periodic 和 /etc/apt/apt.conf.d/20auto-upgrades：\nAPT::Periodic::Update-Package-Lists \u0026#34;1\u0026#34;; APT::Periodic::Unattended-Upgrade \u0026#34;1\u0026#34;; 改为\nAPT::Periodic::Update-Package-Lists \u0026#34;0\u0026#34;; APT::Periodic::Unattended-Upgrade \u0026#34;0\u0026#34;; 文件系统 fstab /etc/fstab是用来存放文件系统的静态信息的文件。当系统启动的时候，系统会自动地从这个文件读取信息，并且会自动将此文件中指定的文件系统挂载到指定的目录。\n查看/etc/fstab\n# cat /etc/fstab \u0026lt;file system\u0026gt; \u0026lt;dir\u0026gt; \u0026lt;type\u0026gt; \u0026lt;options\u0026gt; \u0026lt;dump\u0026gt; \u0026lt;pass\u0026gt; tmpfs /tmp tmpfs nodev,nosuid 0 0 /dev/sda1 / ext4 defaults,noatime 0 1 /dev/sda2 none swap defaults,nodelalloc 0 0 /dev/sda3 /home ext4 defaults,noatime 0 2 分别解释一下各字段的用处：\n \u0026lt;file system\u0026gt; 要挂载的分区或存储设备 \u0026lt;dir\u0026gt; 挂载的目录位置 \u0026lt;type\u0026gt; 挂载分区的文件系统类型，比如：ext3、ext4、xfs、swap \u0026lt;options\u0026gt; 挂载使用的参数有哪些。举例如下：  auto - 在启动时或键入了 mount -a 命令时自动挂载。 noauto - 只在你的命令下被挂载。 exec - 允许执行此分区的二进制文件。 noexec - 不允许执行此文件系统上的二进制文件。 ro - 以只读模式挂载文件系统。 rw - 以读写模式挂载文件系统。 user - 允许任意用户挂载此文件系统，若无显示定义，隐含启用 noexec, nosuid, nodev 参数。 users - 允许所有 users 组中的用户挂载文件系统. nouser - 只能被 root 挂载。 owner - 允许设备所有者挂载。 sync - I/O 同步进行。 async - I/O 异步进行。 dev - 解析文件系统上的块特殊设备。 nodev - 不解析文件系统上的块特殊设备。 suid - 允许 suid 操作和设定 sgid 位。这一参数通常用于一些特殊任务，使一般用户运行程序时临时提升权限。 nosuid - 禁止 suid 操作和设定 sgid 位。 noatime - 不更新文件系统上 inode 访问记录，可以提升性能。 nodiratime - 不更新文件系统上的目录 inode 访问记录，可以提升性能(参见 atime 参数)。 relatime - 实时更新 inode access 记录。只有在记录中的访问时间早于当前访问才会被更新。（与 noatime 相似，但不会打断如 mutt 或其它程序探测文件在上次访问后是否被修改的进程。），可以提升性能。 flush - vfat 的选项，更频繁的刷新数据，复制对话框或进度条在全部数据都写入后才消失。 defaults - 使用文件系统的默认挂载参数，例如 ext4 的默认参数为:rw, suid, dev, exec, auto, nouser, async.   \u0026lt;dump\u0026gt; dump 工具通过它决定何时作备份。dump 会检查其内容，并用数字来决定是否对这个文件系统进行备份。 允许的数字是 0 和 1 。0 表示忽略， 1 则进行备份。大部分的用户是没有安装 dump 的 ，对他们而言 \u0026lt;dump\u0026gt; 应设为 0。 \u0026lt;pass\u0026gt; fsck 读取 \u0026lt;pass\u0026gt; 的数值来决定需要检查的文件系统的检查顺序。允许的数字是0, 1, 和2。 根目录应当获得最高的优先权 1, 其它所有需要被检查的设备设置为 2。 0 表示设备不会被 fsck 所检查。  示例：\n/dev/sda1 /mnt/LinuxOSBuckup ext4 defaults 0 2 UUID of Storage Devices Finding UUID with blkid\n$ sudo blkid Finding UUID with ls\n$ ls -l /dev/disk/by-uuid Finding UUID with lsblk\n$ sudo lsblk -f LVM 在对磁盘分区的大小进行规划时，往往不能确定这个分区要使用的空间的大小。而使用 fdisk、gdisk 等工具对磁盘分区后，每个分区的大小就固定了。如果分区设置的过大，就白白浪费了磁盘空间；如果分区设置的过小，就会导致空间不够用的情况出现。对于分区过小的问题，可以从新划分磁盘的分区，或者通过软连接的方式将此分区的目录链接到另外一个分区。这样虽然能够临时解决问题，但是给管理带来了麻烦。类似的问题可以通过 LVM 来解决。\nLVM 是什么 LVM 是 Logical Volume Manager 的缩写，中文一般翻译为 \u0026ldquo;逻辑卷管理\u0026rdquo;，它是 Linux 下对磁盘分区进行管理的一种机制。LVM 是建立在磁盘分区和文件系统之间的一个逻辑层，系统管理员可以利用 LVM 在不重新对磁盘分区的情况下动态的调整分区的大小。如果系统新增了一块硬盘，通过 LVM 就可以将新增的硬盘空间直接扩展到原来的磁盘分区上。\nLVM 的优点如下：\n 文件系统可以跨多个磁盘，因此大小不再受物理磁盘的限制。 可以在系统运行状态下动态地扩展文件系统大小。 可以以镜像的方式冗余重要数据到多个物理磁盘上。 可以很方便地导出整个卷组，并导入到另外一台机器上。  LVM 也有一些缺点：\n 在从卷组中移除一个磁盘的时候必须使用 reducevg 命令(这个命令要求root权限，并且不允许在快照卷组中使用)。 当卷组中的一个磁盘损坏时，整个卷组都会受影响。 因为增加了一个逻辑层，存储的性能会受影响。  LVM 的优点对服务器的管理非常有用，但对于桌面系统的帮助则没有那么显著，所以需要我们根据使用的场景来决定是否应用 LVM。\nLVM 中的基本概念 通过 LVM 技术，可以屏蔽掉磁盘分区的底层差异，在逻辑上给文件系统提供了一个卷的概念，然后在这些卷上建立相应的文件系统。下面是 LVM 中主要涉及的一些概念。\n **物理存储设备(Physical Media)：**指系统的存储设备文件，比如 /dev/sda、/dev/sdb 等。 **PV(物理卷 Physical Volume)：**指硬盘分区或者从逻辑上看起来和硬盘分区类似的设备(比如 RAID 设备)。 **VG(卷组 Volume Group)：**类似于非 LVM 系统中的物理硬盘，一个 LVM 卷组由一个或者多个 PV(物理卷)组成。 **LV(逻辑卷 Logical Volume)：**类似于非 LVM 系统上的磁盘分区，LV 建立在 VG 上，可以在 LV 上建立文件系统。 **PE(Physical Extent)：**PV(物理卷)中可以分配的最小存储单元称为 PE，PE 的大小是可以指定的。 **LE(Logical Extent)：**LV(逻辑卷)中可以分配的最小存储单元称为 LE，在同一个卷组中，LE 的大小和 PE 的大小是一样的，并且一一对应。  可以这么理解，LVM 是把硬盘的分区分成了更小的单位(PE)，再用这些单元拼成更大的看上去像分区的东西(PV)，进而用 PV 拼成看上去像硬盘的东西(VG)，最后在这个新的硬盘上创建分区(LV)。文件系统则建立在 LV 之上，这样就在物理硬盘和文件系统中间添加了一层抽象(LVM)。下图大致描述了这些概念之间的关系：\n对上图中的结构做个简单的介绍：\n两块物理硬盘 A 和 B 组成了 LVM 的底层结构，这两块硬盘的大小、型号可以不同。PV 可以看做是硬盘上的分区，因此可以说物理硬盘 A 划分了两个分区，物理硬盘 B 划分了三个分区。然后将前三个 PV 组成一个卷组 VG1，后两个 PV 组成一个卷组 VG2。接着在卷组 VG1 上划分了两个逻辑卷 LV1 和 LV2，在卷组 VG2 上划分了一个逻辑卷 LV3。最后，在逻辑卷 LV1、LV2 和 LV3 上创建文件系统，分别挂载在 /usr、/home 和 /var 目录。\nLVM 工具 在安装 Linux 时，如果选择使用 LVM 创建分区，就会安装 LVM 相关的工具。当前这个软件包的名称为 lvm2，其中包含了大量 LVM 工具。比如单是查看 LVM 相关实体状态的命令就有如下一些：\n$ sudo pvscan $ sudo pvs $ sudo pvdisplay $ sudo vgscan $ sudo vgs $ sudo vgdisplay $ sudo lvscan $ sudo lvs $ sudo lvdisplay 如果安装系统时没有默认安装 LVM 工具包，可以通过下面的命令安装它们：\n$ sudo apt update $ sudo apt install lvm2 接下来我们通过例子来演示如何使用 LVM 来一步步的创建出逻辑卷(LV)，然后在 LV 上创建文件系统并挂载到 Linux 系统中。\n使用 gdisk 对物理磁盘进行分区 目前常见的磁盘分区格式有两种，MBR 分区和 GPT 分区。\nMBR 分区，MBR 的意思是 \u0026ldquo;主引导记录\u0026rdquo;。MBR 最大支持 2TB 容量，在容量方面存在着极大的瓶颈。\nGPT 分区，GPT 意为 GUID 分区表，它支持的磁盘容量比 MBR 大得多。这是一个正逐渐取代 MBR 的新标准，它是由 UEFI 辅住而形成的，将来 UEFI 用于取代老旧的 BIOS，而 GPT 则取代老旧的 MBR。\n使用 fdisk 工具创建 MBR 磁盘分区，而 gdisk 是 Linux 系统中 GPT 格式的磁盘分区管理工具。\n假设我们的 Linux 系统中增加了一块新的磁盘，系统对应的设备名为 /dev/sdb，下面我们通过 gdisk 命令对这个磁盘进行分区。\n在用 gdisk 命令对磁盘分区前，我们先用 parted 命令查看 /dev/sdb 当前的分区情况：\n$ sudo parted /dev/sdb print 下面通过 gdisk 命令创建分区：\n$ sudo gdisk /dev/sdb 通过 p 命令可以查看磁盘当前的状态：输出中的前几行是磁盘的基本信息，比如总大小，一共有多少个扇区(sector)，每个扇区的大小，当前剩余的空间等等。\n然后是已经存在的分区信息：\n 第一列 Number 显示了分区的编号，比如 1 号指 /dev/sdb1。 第二列 Start 表示磁盘分区的起始位置。 第三列 End 表示磁盘分区的结束位置。 第四列 Size 显示分区的容量。 第五列 Code 和第六列 Name 显示分区类型的 ID和名称，比如 Linux filesystem 为 8300，Linux swap 为 8200，Linux LVM 为 8e00。  通过 n 命令来创建新分区：\n分区编号和开始/结束的扇区都直接通过回车选择默认值，这样所有的磁盘空间都划分到了一个分区中，然后输入 8e00 说明我们要创建的分区类型为 Linux LVM。最后输入 w 命令并确认执行分区操作。分区成功后可通过 p 命令查看我们创建的分区的信息。\n创建物理卷 PV # pvcreate DEVICE 现在我们可以基于磁盘分区 /dev/sdb1 来创建 LVM 物理卷(LV)，可以通过 pvcreate 命令来完成：\n$ sudo pvcreate /dev/sdb1 此时 /dev/sdb1 已经完成了从磁盘分区到 PV 的华丽转身！注意上面的命令，磁盘分区被直接转换成了 PV，连名称都没有变化！我们可以通过 pvs 命令查看 /dev/sdb1，目前它还没有被加入到 VG 中。\n创建卷组 VG # vgcreate \u0026lt;volume_group\u0026gt; \u0026lt;physical_volume1\u0026gt; \u0026lt;physical_volume2\u0026gt; ... 基于一个或多个 PV，可以创建 VG。我们使用刚才创建的 PV /dev/sdb1 来创建一个名称为 nickvg 的 VG：\n$ sudo vgcreate -s 32G nickvg /dev/sdb1 注意 vgcreate 命令中的 -s 选项，它指定了 PE(Physical Extent) 的大小。可以通 vgs 命令观察 VG 的信息：\n$ sudo vgs nickvg 如果目标 VG 已经存在，则使用 vgextend 把 PV 加入到 VG 中即可。\n# vgextend \u0026lt;卷组名\u0026gt; \u0026lt;物理卷\u0026gt; 创建逻辑卷 LV # lvcreate -L \u0026lt;卷大小\u0026gt; \u0026lt;卷组名\u0026gt; -n \u0026lt;卷名\u0026gt; 有了 VG 就可以创建逻辑卷 LV 了，lvcreate 命令用来创建 LV，让我们在前面创建的 nickvg 上创建名称为 nicklv00 的 LV：\n$ sudo lvcreate -L 15G -n nicklv00 nickvg 选项 -L 指定新建 LV 的容量，这里是 15G；选项 -n 则指定新建 LV 的名称，这里为 nicklv00。可以通过 lvs 命令观察 LV 的信息，注意需要同时指出 LV 所在的 VG：\n$ sudo lvs nickvg/nicklv00 如果你想让要创建的逻辑卷拥有卷组（VG）的所有未使用空间，请使用以下命令：\n# lvcreate -l +100%FREE \u0026lt;volume_group\u0026gt; -n \u0026lt;logical_volume\u0026gt; 格式化逻辑卷(创建文件系统) # mkfs.\u0026lt;类型\u0026gt; /dev/mapper/\u0026lt;卷组名\u0026gt;-\u0026lt;卷名\u0026gt; # mount /dev/mapper/\u0026lt;卷组名\u0026gt;-\u0026lt;卷名\u0026gt; \u0026lt;挂载点\u0026gt; 当我们创建 LV nickvg/nicklv00 时，其实是创建了名称为 /dev/nickvg/nicklv00 的设备文件。\n现在你的逻辑卷应该已经在/dev/mapper/和/dev/YourVolumeGroupName中了。\n现在我们来格式化这个逻辑卷(在该 LV 上创建文件系统)，目标为比较常见的 ext4 格式：\n$ sudo mkfs.ext4 /dev/nickvg/nicklv00 然后创建个目录，比如 /home/doc，并把新建的文件系统挂载到这个目录上：\n$ sudo mkdir /home/doc $ sudo mount /dev/nickvg/nicklv00 /home/doc 最后可以通过 df 命令查看这个文件系统的使用情况。\n开机自动挂载 编辑 /etc/fstab 文件：\n$ sudo vim /etc/fstab 把下面的行添加的文件末尾并保存文件：\n/dev/mapper/nickvg-nicklv00 /home/doc ext4 defaults 0 2 调整逻辑卷 同时缩小逻辑卷和其文件系统\n 注意： 只有ext2，ext3，ext4，ReiserFS和 XFS 文件系统支持以下操作。\n 将MyVolGroup组中的逻辑卷mediavol扩大10GiB，并同时扩大其文件系统：\n# lvresize -L +10G --resizefs MyVolGroup/mediavol 将MyVolGroup组中的逻辑卷mediavol大小调整为15GiB，并同时调整其文件系统：\n# lvresize -L 15G --resizefs MyVolGroup/mediavol 将卷组中的所有剩余空间分配给mediavol：\n# lvresize -l +100%FREE --resizefs MyVolGroup/mediavol 重命名卷 重命名卷组\n要重命名一个卷组，请使用vgrename(8)命令。\n可使用下面的任意一条命令将卷组vg02重命名为my_volume_group\n# vgrename /dev/vg02 /dev/my_volume_group # vgrename vg02 my_volume_group 重命名逻辑卷\n要重命名一个逻辑卷，请使用lvrename(8)命令。\n可使用下面的任意一条命令将vg02组中的逻辑卷lvold重命名为lvnew.\n# lvrename /dev/vg02/lvold /dev/vg02/lvnew # lvrename vg02 lvold lvnew 移除逻辑卷 警告： 在移除逻辑卷之前，请先备份好数据以免丢失！\n首先，找到你所要移除的逻辑卷的名称。你可以使用以下命令来查看系统的所有逻辑卷：\n# lvs 接下来，找到你所要移除的逻辑卷的挂载点\n$ lsblk 并卸载它：\n# umount /\u0026lt;mountpoint\u0026gt; 最后，使用以下命令来移除逻辑卷：\n# lvremove \u0026lt;volume_group\u0026gt;/\u0026lt;logical_volume\u0026gt; 例如：\n# lvremove VolGroup00/lvolhome 请输入y来确定你要执行移除逻辑卷操作。\n此外，请不要忘了更新/etc/fstab。\n你可以再次使用lvs命令来确认你的逻辑卷已被移除。\nLVM 快照 LVM 机制还提供了对 LV 做快照的功能，也就是说可以给文件系统做一个备份，这也是设计 LVM 快照的主要目的。LVM 的快照功能采用写时复制技术(Copy-On-Write，COW)，这比传统的备份技术的效率要高很多。创建快照时不用停止服务，就可以对数据进行备份。说明：LVM 还支持 thin 类型的快照，但是本文中的快照都是指 COW 类型的快照。\nLVM 采用的写时复制，是指当 LVM 快照创建的时候，仅创建到实际数据的 inode 的硬链接(hark-link)而已。只要实际的数据没有改变，快照就只包含指向数据的 inode 的指针，而非数据本身。快照会跟踪原始卷中块的改变，一旦你更改了快照对应的文件或目录，这个时候原始卷上将要改变的数据会在改变之前拷贝到快照预留的空间。\nLVM 快照的原理\n创建快照实际上也是创建了一个逻辑卷，只不过该卷的属性与普通逻辑卷的属性有些不一样。我们可以通过下图来理解快照数据卷(图中的实线框表示快照区域，虚线框表示文件系统)：\n左图为最初创建的快照数据卷状况，LVM 会预留一个区域 (比如左图的左侧三个 PE 区块) 作为数据存放处。 此时快照数据卷内并没有任何数据，而快照数据卷与源数据卷共享所有的 PE 数据， 因此你会看到快照数据卷的内容与源数据卷中的内容是一模一样的。 等到系统运行一阵子后，假设 A 区域的数据被更新了(上面右图所示)，则更新前系统会将该区域的数据移动到快照数据卷中， 所以在右图的快照数据卷中被占用了一块 PE 成为 A，而其他 B 到 I 的区块则还是与源数据卷共享！\n由於快照区与原本的 LV 共享很多 PE 区块，因此快照区与被快照的 LV 必须要在同一个 VG 上头，下面两点非常重要：\n VG中需要预留存放快照本身的空间，不能全部被占满。 快照所在的 VG 必须与被备份的 LV 的 VG 相同，否则创建快照会失败。  创建 LVM 快照\n其实快照就是一个特殊类型的数据卷，所以创建快照的命令和创建数据卷的命令相同，也是 lvcreate：\n# lvcreate --size 100M --snapshot --name snap01 /dev/vg0/lv 此时如果把 LV snap01 挂载到系统中，里面的内容和 LV /dev/vg0/lv 中的内容是一样的。\n创建的快照的大小可以比源数据卷小，但是当源数据卷中的数据更新过多时会导致快照容量不足而引起的错误并丢失数据。如上你可以修改少于100M的数据，直到该快照逻辑卷空间不足为止。\n创建快照后，如果源数据卷中的文件被更新了，快照系统中则保存着其创建快照时的版本。\n还原部分数据\n如果我们明确的知道需要还原某个文件，可以挂载快照数据卷，直接拷贝其中旧版本的文件即可。\n合并快照(merge snapshot)\n要将逻辑卷卷\u0026rsquo;lv' 恢复到创建快照\u0026rsquo;snap01\u0026rsquo;时的状态，即还原整个数据卷上的数据，请使用：\n# lvconvert --merge /dev/vg0/snap01 如果逻辑卷处于活动状态，则在下次重新启动时将进行合并（merging）(合并（merging）甚至可在LiveCD中进行)。\n注意： 合并后快照将被删除。\n可以拍摄多个快照，每个快照都可以任意与对应的逻辑卷合并。\n快照可以被挂载，并可用dd或者tar备份。使用dd备份的快照的大小为拍摄快照后对应逻辑卷中变更过文件的大小。 要使用备份，只需创建并挂载一个快照，并将备份写入或解压到其中。再将快照合并到对应逻辑卷即可。\n快照主要用于提供一个文件系统的拷贝，以用来备份; 比起直接备份分区，使用快照备份可以提供一个更符合原文件系统的镜像。\nZFS 历史 ZFS 是由 Matthew Ahrens 和 Jeff Bonwick 在 2001 年开发的。ZFS 是作为 Sun MicroSystem 公司的 OpenSolaris 的下一代文件系统而设计的。在 2008 年，ZFS 被移植到了 FreeBSD 。同一年，一个移植 ZFS on Linux 的项目也启动了。然而，由于 ZFS 是CDDL 许可的，它和 GPL 不兼容，因此不能将它迁移到 Linux 内核中。为了解决这个问题，绝大多数 Linux 发行版提供了一些方法来安装 ZFS　。\n在甲骨文公司收购太阳微系统公司之后不久，OpenSolaris 就闭源了，这使得 ZFS 的之后的开发也变成闭源的了。许多 ZFS 开发者对这件事情非常不满。三分之二的 ZFS 核心开发者，包括 Ahrens 和 Bonwick，因为这个决定而离开了甲骨文公司。他们加入了其它公司，并于 2013 年 9 月创立了 OpenZFS 这一项目。该项目引领着 ZFS 的开源开发。\n让我们回到上面提到的许可证问题上。既然 OpenZFS 项目已经和 Oracle 公司分离开了，有人可能好奇他们为什么不使用和 GPL 兼容的许可证，这样就可以把它加入到 Linux 内核中了。根据 OpenZFS 官网 的介绍，更改许可证需要联系所有为当前 OpenZFS 实现贡献过代码的人（包括初始的公共 ZFS 代码以及 OpenSolaris 代码），并得到他们的许可才行。这几乎是不可能的（因为一些贡献者可能已经去世了或者很难找到），因此他们决定保留原来的许可证。\n特性 正如前面所说过的，ZFS 是一个先进的文件系统。因此，它有一些有趣的特性。\n存储池 与大多数文件系统不同，ZFS 结合了文件系统和卷管理器的特性。这意味着，它与其他文件系统不同，ZFS 可以创建跨越一系列硬盘或池的文件系统。不仅如此，你还可以通过添加硬盘来增大池的存储容量。ZFS 可以进行分区和格式化。\n写时拷贝 Copy-on-write 是另一个有趣并且很酷的特性。在大多数文件系统上，当数据被重写时，它将永久丢失。而在 ZFS 中，新数据会写到不同的块。写完成之后，更新文件系统元数据信息，使之指向新的数据块（LCTT 译注：更新之后，原数据块成为磁盘上的垃圾，需要有对应的垃圾回收机制）。这确保了如果在写新数据的时候系统崩溃（或者发生其它事，比如突然断电），那么原数据将会保存下来。这也意味着，在系统发生崩溃之后，不需要运行 fsck 来检查和修复文件系统。\n快照 写时拷贝使得 ZFS 有了另一个特性：snapshots。ZFS 使用快照来跟踪文件系统中的更改。快照包含文件系统的原始版本（文件系统的一个只读版本），实时文件系统则包含了自从快照创建之后的任何更改。没有使用额外的空间。因为新数据将会写到实时文件系统新分配的块上。如果一个文件被删除了，那么它在快照中的索引也会被删除。所以，快照主要是用来跟踪文件的更改，而不是文件的增加和创建。\n快照可以挂载成只读的，以用来恢复一个文件的过去版本。实时文件系统也可以回滚到之前的快照。回滚之后，自从快照创建之后的所有更改将会丢失。\n数据完整性验证和自动修复 当向 ZFS 写入新数据时，会创建该数据的校验和。在读取数据的时候，使用校验和进行验证。如果前后校验和不匹配，那么就说明检测到了错误，然后，ZFS 会尝试自动修正错误。\nRAID-Z ZFS 不需要任何额外软件或硬件就可以处理 RAID（磁盘阵列）。毫不奇怪，因为 ZFS 有自己的 RAID 实现：RAID-Z 。RAID-Z 是 RAID-5 的一个变种，不过它克服了 RAID-5 的写漏洞：意外重启之后，数据和校验信息会变得不同步（LCTT 译注：RAID-5 的条带在正写入数据时，如果这时候电源中断，那么奇偶校验数据将跟该部分数据不同步，因此前边的写无效；RAID-Z 用了 “可变宽的 RAID 条带” 技术，因此所有的写都是全条带写入）。为了使用基本级别的 RAID-Z（RAID-Z1），你需要至少三块磁盘，其中两块用来存储数据，另外一块用来存储奇偶校验信息。而 RAID-Z2 需要至少两块磁盘存储数据以及两块磁盘存储校验信息。RAID-Z3 需要至少两块磁盘存储数据以及三块磁盘存储校验信息。另外，只能向 RAID-Z 池中加入偶数倍的磁盘，而不能是奇数倍的。\n巨大的存储潜力 创建 ZFS 的时候，它是作为最后一个文件系统而设计的 。那时候，大多数文件系统都是 64 位的，ZFS 的创建者决定直接跳到 128 位，等到将来再来证明这是对的。这意味着 ZFS 的容量大小是 32 位或 64 位文件系统的 1600 亿亿倍。事实上，Jeff Bonwick（其中一个创建者）说：“完全填满一个 128 位的存储池所需要的能量，从字面上讲，比煮沸海洋需要的还多。”\n如何安装 ZFS？ 如果你想立刻使用 ZFS（开箱即用），那么你需要安装 FreeBSD 或一个使用 illumos 内核的操作系统。illumos 是 OpenSolaris 内核的一个克隆版本。\n事实上，支持 ZFS 是一些有经验的 Linux 用户选择 BSD 的主要原因。\n如果你想在 Linux 上尝试 ZFS，那么只能在存储文件系统上使用。据我所知，没有任何 Linux 发行版可以在根目录上安装 ZFS，实现开箱即用。如果你对在 Linux 上尝试 ZFS 感兴趣，那么 ZFS on Linux 项目 上有大量的教程可以指导你怎么做。\n在 Ubuntu 上使用 ZFS 如果您正在考虑将 ZFS 用于您的超高速 NVMe SSD，这可能不是一个最佳选择。 它比别的文件系统要慢，不过，这完全没有问题， 它旨在存储大量的数据并保持安全。\n$ sudo apt-get install zfsutils-linux 创建池 在 ZFS 中，池大致相当于 RAID 。 它们很灵活且易于操作。\nRAID0\nRAID0 只是把你的硬盘集中到一个池子里面，就像一个巨大的驱动器一样。 它可以提高你的驱动器速度，（LCTT 译注：数据条带化后，并行访问，可以提高文件读取速度）但是如果你的驱动器有损坏，你可能会失丢失数据。\n在计算机数据存储中，数据条带化是一种对逻辑顺序数据（例如文件）进行分段的技术，以便将连续的段存储在不同的物理存储设备上。\n要使用 ZFS 实现 RAID0，只需创建一个普通的池。\n$ sudo zpool create your-pool /dev/sdc /dev/sdd RAID1（镜像）\n您可以在 ZFS 中使用 mirror 关键字来实现 RAID1 功能。 RAID1 会创建一个一对一的驱动器副本。 这意味着您的数据一直在备份。 它也提高了性能。 当然，你将一半的存储空间用于了复制。\n$ sudo zpool create your-pool mirror /dev/sdc /dev/sdd RAID5/RAIDZ1\nZFS 将 RAID5 功能实现为 RAIDZ1。 RAID5 要求驱动器至少是 3 个。并允许您通过将备份奇偶校验数据写入驱动器空间的 1/n（n 是驱动器数），留下的是可用的存储空间。 如果一个驱动器发生故障，阵列仍将保持联机状态，但应尽快更换发生故障的驱动器（LCTT 译注：与原文翻译略有不同，原文是驱动器的数目是三的倍数，根据 wiki， RAID5 至少需要 3 块驱动器，也可以从下面的命令中猜测)。\n$ sudo zpool create your-pool raidz1 /dev/sdc /dev/sdd /dev/sde RAID6/RAIDZ2\nRAID6 与 RAID5 几乎完全相同，但它至少需要四个驱动器。 它将奇偶校验数据加倍，最多允许两个驱动器损坏，而不会导致阵列关闭（LCTT 译注：这里也与原文略有出入，原文是驱动器的数目是四的倍数，根据 wiki ，RAID6 至少需要四个驱动器)。\n$ sudo zpool create your-pool raidz2 /dev/sdc /dev/sdd /dev/sde /dev/sdf RAID10（条带化镜像）\nRAID10 旨在通过数据条带化提高存取速度和数据冗余来成为一个两全其美的解决方案。 你至少需要四个驱动器，但只能使用一半的空间。 您可以通过在同一个池中创建两个镜像来创建 RAID10 中的池（LCTT 译注：这里也与原文略有出入，原文是驱动器的数目是四的倍数，根据 wiki， RAID10 至少需要四个驱动器）。\n$ sudo zpool create your-pool mirror /dev/sdc /dev/sdd mirror /dev/sde /dev/sdf 池的操作 还有一些管理工具，一旦你创建了你的池，你就必须使用它们来操作。 首先，检查你的池的状态。\n$ sudo zpool status 更新\n当你更新 ZFS 时，你也需要更新你的池。 当您检查它们的状态时，您的池会通知您任何更新。 要更新池，请运行以下命令。\n$ sudo zpool upgrade your-pool 你也可以更新全部池。\n$ sudo zpool upgrade -a 添加驱动器\n您也可以随时将驱动器添加到池中。 告诉 zpool 池的名称和驱动器的位置，它会处理好一切。\n$ sudo zpool add your-pool /dev/sdx 实例 使用两块硬盘上的等容量分区建立 raid 1。\n$ ls -l /dev/disk/by-id usb-JMicron_Generic_DISK00_0123456789ABCDEF-0:0-part1 -\u0026gt; ../../sdb1 usb-JMicron_Generic_DISK01_0123456789ABCDEF-0:1-part2 -\u0026gt; ../../sdc2 $ sudo zpool create -f -o ashift=12 -o cachefile=/etc/zfs/zpool.cache -O compression=lz4 -O xattr=sa -O relatime=on -O acltype=posixacl -O dedup=off -m none dpool mirror usb-JMicron_Generic_DISK00_0123456789ABCDEF-0:0-part1 usb-JMicron_Generic_DISK01_0123456789ABCDEF-0:1-part2 $ sudo zfs create -o mountpoint=none -o canmount=off dpool/DATA $ sudo zfs create -o mountpoint=/home/kurome/DataPool dpool/DATA/important $ sudo zpool export dpool $ sudo zpool import dpool udev 如果你使用Linux比较长时间了，那你就知道，在对待设备文件这块，Linux改变了几次策略。在Linux早期，设备文件仅仅是是一些带有适当的属性集的普通文件，它由mknod命令创建，文件存放在/dev目录下。后来，采用了devfs, 一个基于内核的动态设备文件系统，他首次出现在2.3.46内核中。Mandrake，Gentoo等Linux分发版本采用了这种方式。devfs创建 的设备文件是动态的。但是devfs有一些严重的限制，从2.6.13版本后移走了。目前取代他的便是文本要提到的udev－－一个用户空间程序。\n目前很多的Linux分发版本采纳了udev的方式，因为它在Linux设备访问，特别是那些对设备有极端需求的站点(比如需要控制上千个硬盘)和热插拔设备(比如USB摄像头和MP3播放器)上解决了几个问题。下面我我们来看看如何管理udev设备。\n实际上，对于那些为磁盘，终端设备等准备的标准配置文件而言，你不需要修改什么。但是，你需要了解udev配置来使用新的或者外来设备，如果不修改配置， 这些设备可能无法访问，或者说Linux可能会采用不恰当的名字，属组或权限来创建这些设备文件。你可能也想知道如何修改RS－232串口，音频设备等文件的属组或者权限。这点在实际的Linux实施中是会遇到的。\n为什么使用udev 在此之前的设备文件管理方法(静态文件和devfs)有几个缺点：\n 不确定的设备映射。特别是那些动态设备，比如USB设备，设备文件到实际设备的映射并不可靠和确定。举一个例子：如果你有两个USB打印机。一个可能称 为/dev/usb/lp0,另外一个便是/dev/usb/lp1。但是到底哪个是哪个并不清楚，lp0,lp1和实际的设备没有一一对应的关系，因为 他可能因为发现设备的顺序，打印机本身关闭等原因而导致这种映射并不确定。理想的方式应该是：两个打印机应该采用基于他们的序列号或者其他标识信息的唯一 设备文件来映射。但是静态文件和devfs都无法做到这点。 没有足够的主/辅设备号。我们知道，每一个设备文件是有两个8位的数字：一个是主设备号 ，另外一个是辅设备号来分配的。这两个8位的数字加上设备类型(块设备或者字符设备)来唯一标识一个设备。不幸的是，关联这些身边的的数字并不足够。 /dev目录下文件太多。一个系统采用静态设备文件关联的方式，那么这个目录下的文件必然是足够多。而同时你又不知道在你的系统上到底有那些设备文件是激活的。 命名不够灵活。尽管devfs解决了以前的一些问题，但是它自身又带来了一些问题。其中一个就是命名不够灵活；你别想非常简单的就能修改设备文件的名字。缺省的devfs命令机制本身也很奇怪，他需要修改大量的配置文件和程序。 内核内存使用，devfs特有的另外一个问题是，作为内核驱动模块，devfs需要消耗大量的内存，特别当系统上有大量的设备时(比如上面我们提到的系统一个上有好几千磁盘时)  udev的目标是想解决上面提到的这些问题，他通采用用户空间(user-space)工具来管理/dev/目录树，他和文件系统分开。知道如何改变缺省配置能让你之大如何定制自己的系统，比如创建设备字符连接，改变设备文件属组，权限等。\nudev配置文件 主要的udev配置文件是/etc/udev/udev.conf。这个文件通常很短，他可能只是包含几行#开头的注释，然后有几行选项：\nudev_root=“/dev/” udev_rules=“/etc/udev/rules.d/” udev_log=“err“ 上面的第二行非常重要，因为他表示udev规则存储的目录，这个目录存储的是以.rules结束的文件。每一个文件处理一系列规则来帮助udev分配名字给设备文件以保证能被内核识别。\n你的/etc/udev/rules.d下面可能有好几个udev规则文件，这些文件一部分是udev包安装的，另外一部分则是可能是别的硬件或者软件包 生成的。比如在Fedora Core 5系统上，sane-backends包就会安装60-libsane.rules文件，另外initscripts包会安装60-net.rules文 件。这些规则文件的文件名通常是两个数字开头，它表示系统应用该规则的顺序。\n规则文件里的规则有一系列的键/值对组成，键/值对之间用逗号(,)分割。每一个键或者是用户匹配键，或者是一个赋值键。匹配键确定规则是否被应用，而赋 值键表示分配某值给该键。这些值将影响udev创建的设备文件。匹配键和赋值键操作符解释见下表：\n   操作符 匹配或赋值 解释     == 匹配 相等比较   != 匹配 不等比较   = 赋值 分配一个特定的值给该键，他可以覆盖之前的赋值。   += 赋值 追加特定的值给已经存在的键   := 赋值 分配一个特定的值给该键，后面的规则不可能覆盖它。    这有点类似我们常见的编程语言，比如C语言。只是这里的键一次可以处理多个值。有一些键在udev规则文件里经常出现，这些键的值可以使用通配符(*,?,甚至范围，比如[0-9])，这些常用键列举如下：\n   键 含义     ACTION 一个时间活动的名字，比如add，当设备增加的时候   KERNEL 在内核里看到的设备名字，比如sd*表示任意SCSI磁盘设备   DEVPATH 内核设备路径，比如/devices/*   SUBSYSTEM 子系统名字，比如sound,net   BUS 总线的名字，比如IDE,USB   DRIVER 设备驱动的名字，比如ide-cdromID 独立于内核名字的设备名字   SYSFS{ value} sysfs属性值，他可以表示任意   ENV{ key} 环境变量，可以表示任意   PROGRAM 可执行的外部程序，如果程序返回0值，该键则认为为真(true)   RESULT 上一个PROGRAM调用返回的标准输出。   NAME 根据这个规则创建的设备文件的文件名。注意：仅仅第一行的NAME描述是有效的，后面的均忽略。 如果你想使用使用两个以上的名字来访问一个设备的话，可以考虑SYMLINK键。   SYMLINK 根据规则创建的字符连接名   OWNER 设备文件的属组   GROUP 设备文件所在的组。   MODE 设备文件的权限，采用8进制   RUN 为设备而执行的程序列表   LABEL 在配置文件里为内部控制而采用的名字标签(下下面的GOTO服务)   GOTO 跳到匹配的规则（通过LABEL来标识），有点类似程序语言中的GOTO   IMPORT{ type} 导入一个文件或者一个程序执行后而生成的规则集到当前文件   WAIT_FOR_SYSFS 等待一个特定的设备文件的创建。主要是用作时序和依赖问题。   PTIONS 特定的选项： last_rule 对这类设备终端规则执行； ignore_device 忽略当前规则； ignore_remove 忽略接下来的并移走请求。all_partitions 为所有的磁盘分区创建设备文件。    我们给出一个列子来解释如何使用这些键。下面的例子来自Fedora Core 5系统的标准配置文件。\nKERNEL==\u0026#34;*\u0026#34;, OWNER=\u0026#34;root\u0026#34; GROUP=\u0026#34;root\u0026#34;, MODE=\u0026#34;0600\u0026#34; KERNEL==\u0026#34;tty\u0026#34;, NAME=\u0026#34;%k\u0026#34;, GROUP=\u0026#34;tty\u0026#34;, MODE=\u0026#34;0666\u0026#34;, OPTIONS=\u0026#34;last_rule\u0026#34; KERNEL==\u0026#34;scd[0-9]*\u0026#34;, SYMLINK+=\u0026#34;cdrom cdrom-%k\u0026#34; KERNEL==\u0026#34;hd[a-z]\u0026#34;, BUS==\u0026#34;ide\u0026#34;, SYSFS{removable}==\u0026#34;1\u0026#34;, SYSFS{device/media}==\u0026#34;cdrom\u0026#34;, SYMLINK+=\u0026#34;cdrom cdrom-%k\u0026#34; ACTION==\u0026#34;add\u0026#34;, SUBSYSTEM==\u0026#34;scsi_device\u0026#34;, RUN+=\u0026#34;/sbin/modprobe sg\u0026#34; 上面的例子给出了5个规则，每一个都是KERNEL或者ACTION键开头：\n 第一个规则是缺省的，他匹配任意被内核识别到的设备，然后设定这些设备的属组是root，组是root，访问权限模式是0600(-rw——-)。这也是一个安全的缺省设置保证所有的设备在默认情况下只有root可以读写 第二个规则也是比较典型的规则了。它匹配终端设备(tty)，然后设置新的权限为0600，所在的组是tty。它也设置了一个特别的设备文件名:%K。在这里例子里，%k代表设备的内核名字。那也就意味着内核识别出这些设备是什么名字，就创建什么样的设备文件名。 第三行开始的KERNEL==”scd[0-9]*”,表示 SCSI CD-ROM 驱动. 它创建一对设备符号连接：cdrom和cdrom-%k。 第四行，开始的 KERNEL==”hd[a-z]“, 表示ATA CDROM驱动器。这个规则创建和上面的规则相同的符号连接。ATA CDROM驱动器需要sysfs值以来区别别的ATA设备，因为SCSI CDROM可以被内核唯一识别。. 第五行以 ACTION==”add”开始，它告诉udev增加 /sbin/modprobe sg 到命令列表，当任意SCSI设备增加到系统后，这些命令将执行。其效果就是计算机应该会增加sg内核模块来侦测新的SCSI设备。  当然，上面仅仅是一小部分例子，如果你的系统采用了udev方式，那你应该可以看到更多的规则。如果你想修改设备的权限或者创建信的符号连接，那么你需要熟读这些规则，特别是要仔细注意你修改的那些与之相关的设备。\n修改你的udev配置 在修改udev配置之前，我们一定要仔细，通常的考虑是：你最好不要修改系统预置的那些规则，特别不要指定影响非常广泛的配置，比如上面例子中的第一行。不正确的配置可能会导致严重的系统问题或者系统根本就无法这个正确的访问设备。\n而我们正确的做法应该是在/etc/udev/rules.d/下创建一个新的规则文件。确定你给出的文件的后缀是rules文件名给出的数字序列应该比标准配置文件高。比如，你可以创建一个名为99-my-udev.rules的规则文件。在你的规则文件中，你可以指定任何你想修改的配置，比如，假设你 修改修改floppy设备的所在组，还准备创建一个新的符号连接/dev/floppy，那你可以这么写：\nKERNEL==”fd[0-9]*“, GROUP=“users“, SYMLINK+=“floppy“ 有些发行版本，比如Fedora，采用了外部脚本来修改某些特定设备的属组，组关系和权限。因此上面的改动可能并不见得生效。如果你遇到了这个问题，你就需要跟踪和修改这个脚本来达到你的目的。或者你可以修改PROGRAM或RUN键的值来做到这点。\n某些规则的修改可能需要更深的挖掘。比如，你可能想在一个设备上使用sysfs信息来唯一标识一个设备。这些信息最好通过udevinfo命令来获取。\n$ udevinfo –a –p $(udevinfo –q path –n /dev/hda) 上面的命令两次使用udevinfo：一次是返回sysfs设备路径(他通常和我们看到的Linux设备文件名所在路径－－/dev/hda－－不同)；第 二次才是查询这个设备路径，结果将是非常常的syfs信息汇总。你可以找到最够的信息来唯一标志你的设备，你可以采用适当的替换udev配置文件中的 SYSFS选项。下面的结果就是上面的命令输出\n[root@localhost rules.d]# udevinfo -a -p $(udevinfo -q path -n /dev/hda1) Udevinfo starts with the device specified by the devpath and then walks up the chain of parent devices. It prints for every device found,all possible attributes in the udev rules key format. A rule to match, can be composed by the attributes of the device and the attributes from one single parent device. looking at device \u0026#39;/block/hda/hda1\u0026#39;: KERNEL==\u0026#34;hda1\u0026#34; SUBSYSTEM==\u0026#34;block\u0026#34; DRIVER==\u0026#34;\u0026#34; ATTR{stat}==\u0026#34; 1133 2268 2 4\u0026#34; ATTR{size}==\u0026#34;208782\u0026#34; ATTR{start}==\u0026#34;63\u0026#34; ATTR{dev}==\u0026#34;3:1\u0026#34; looking at parent device \u0026#39;/block/hda\u0026#39;: KERNELS==\u0026#34;hda\u0026#34; SUBSYSTEMS==\u0026#34;block\u0026#34; DRIVERS==\u0026#34;\u0026#34; ATTRS{stat}==\u0026#34;28905 18814 1234781 302540 34087 133247 849708 981336 0 218340 1283968\u0026#34; ATTRS{size}==\u0026#34;117210240\u0026#34; ATTRS{removable}==\u0026#34;0\u0026#34; ATTRS{range}==\u0026#34;64\u0026#34; ATTRS{dev}==\u0026#34;3:0\u0026#34; looking at parent device \u0026#39;/devices/pci0000:00/0000:00:1f.1/ide0/0.0\u0026#39;: KERNELS==\u0026#34;0.0\u0026#34; SUBSYSTEMS==\u0026#34;ide\u0026#34; DRIVERS==\u0026#34;ide-disk\u0026#34; ATTRS{modalias}==\u0026#34;ide:m-disk\u0026#34; ATTRS{drivename}==\u0026#34;hda\u0026#34; ATTRS{media}==\u0026#34;disk\u0026#34; looking at parent device \u0026#39;/devices/pci0000:00/0000:00:1f.1/ide0\u0026#39;: KERNELS==\u0026#34;ide0\u0026#34; SUBSYSTEMS==\u0026#34;\u0026#34; DRIVERS==\u0026#34;\u0026#34; looking at parent device \u0026#39;/devices/pci0000:00/0000:00:1f.1\u0026#39;: KERNELS==\u0026#34;0000:00:1f.1\u0026#34; SUBSYSTEMS==\u0026#34;pci\u0026#34; DRIVERS==\u0026#34;PIIX_IDE\u0026#34; ATTRS{broken_parity_status}==\u0026#34;0\u0026#34; ATTRS{enable}==\u0026#34;1\u0026#34; ATTRS{modalias}==\u0026#34;pci:v00008086d000024CAsv0000144Dsd0000C009bc01sc01i8a\u0026#34; ATTRS{local_cpus}==\u0026#34;1\u0026#34; ATTRS{irq}==\u0026#34;11\u0026#34; ATTRS{class}==\u0026#34;0x01018a\u0026#34; ATTRS{subsystem_device}==\u0026#34;0xc009\u0026#34; ATTRS{subsystem_vendor}==\u0026#34;0x144d\u0026#34; ATTRS{device}==\u0026#34;0x24ca\u0026#34; ATTRS{vendor}==\u0026#34;0x8086\u0026#34; looking at parent device \u0026#39;/devices/pci0000:00\u0026#39;: KERNELS==\u0026#34;pci0000:00\u0026#34; SUBSYSTEMS==\u0026#34;\u0026#34; DRIVERS==\u0026#34;\u0026#34; 举一个例子：假设你想修改USB扫描仪的配置。通过一系列的尝试，你已经为这个扫描仪标识了Linux设备文件(每次打开扫描仪时，名字都会变)。你可以使 用上面的命令替换这个正确的Linux设备文件名，然后定位输出的采用SYSFS{idVendor}行和SYSFS{idProduct}行。最后你可 以使用这些信息来为这个扫描仪创建新的选项。\nSYSFS{idVendor}==\u0026#34;0686\u0026#34;, SYSFS{idProduct}==\u0026#34;400e\u0026#34;, SYMLINK+=\u0026#34;scanner\u0026#34;, MODE=\u0026#34;0664\u0026#34;, group=\u0026#34;scanner\u0026#34; 上面的例子表示将扫描仪的组设置为scanner，访问权限设置为0664,同时创建一个/dev/scanner的符号连接。\nTips Mounting usb automatically \u0026amp; having usb\u0026rsquo;s label as mountpoint\nHow to automatically mount USB drives with custom mount point\nSystemd LINUX PID 1 和 SYSTEMD 要说清 Systemd，得先从Linux操作系统的启动说起。Linux 操作系统的启动首先从 BIOS 开始，然后由 Boot Loader 载入内核，并初始化内核。内核初始化的最后一步就是启动 init 进程。这个进程是系统的第一个进程，PID 为 1，又叫超级进程，也叫根进程。它负责产生其他所有用户进程。所有的进程都会被挂在这个进程下，如果这个进程退出了，那么所有的进程都被 kill 。如果一个子进程的父进程退了，那么这个子进程会被挂到 PID 1 下面。（注：PID 0 是内核的一部分，主要用于内进换页，参看：Process identifier）\nSysV Init PID 1 这个进程非常特殊，其主要就任务是把整个操作系统带入可操作的状态。比如：启动 UI – Shell 以便进行人机交互，或者进入 X 图形窗口。传统上，PID 1 和传统的 Unix System V 相兼容的，所以也叫 sysvinit，这是使用得最悠久的 init 实现。Unix System V 于1983年 release。\n在 sysvint 下，有好几个运行模式，又叫 runlevel。比如：常见的 3 级别指定启动到多用户的字符命令行界面，5 级别指定启起到图形界面，0 表示关机，6 表示重启。其配置在 /etc/inittab 文件中。\n与此配套的还有 /etc/init.d/ 和 /etc/rc[X].d，前者存放各种进程的启停脚本（需要按照规范支持 start，stop子命令），后者的 X 表示不同的 runlevel 下相应的后台进程服务，如：/etc/rc3.d 是 runlevel=3 的。 里面的文件主要是 link 到 /etc/init.d/ 里的启停脚本。其中也有一定的命名规范：S 或 K 打头的，后面跟一个数字，然后再跟一个自定义的名字，如：S01rsyslog，S02ssh。S 表示启动，K表示停止，数字表示执行的顺序。\nUpStart Unix 和 Linux 在 sysvint 运作多年后，大约到了2006年的时候，Linux内核进入2.6时代，Linux有了很多更新。并且，Linux开始进入桌面系统，而桌面系统和服务器系统不一样的是，桌面系统面临频繁重启，而且，用户会非常频繁的使用硬件的热插拔技术。于是，这些新的场景，让 sysvint 受到了很多挑战。\n比如，打印机需要CUPS等服务进程，但是如果用户没有打机印，启动这个服务完全是一种浪费，而如果不启动，如果要用打印机了，就无法使用，因为sysvint 没有自动检测的机制，它只能一次性启动所有的服务。另外，还有网络盘挂载的问题。在 /etc/fstab 中，负责硬盘挂载，有时候还有网络硬盘（NFS 或 iSCSI）在其中，但是在桌面机上，有很可能开机的时候是没有网络的， 于是网络硬盘都不可以访问，也无法挂载，这会极大的影响启动速度。sysvinit 采用 netdev 的方式来解决这个问题，也就是说，需要用户自己在 /etc/fstab 中给相应的硬盘配置上 netdev 属性，于是 sysvint 启动时不会挂载它，只有在网络可用后，由专门的 netfs 服务进程来挂载。这种管理方式比较难以管理，也很容易让人掉坑。\n所以，Ubuntu 开发人员在评估了当时几个可选的 init 系统后，决定重新设计这个系统，于是，这就是我们后面看到的 upstart 。 upstart 基于事件驱动的机制，把之前的完全串行的同步启动服务的方式改成了由事件驱动的异步的方式。比如：如果有U盘插入，udev 得到通知，upstart 感知到这个事件后触发相应的服务程序，比如挂载文件系统等等。因为使用一个事件驱动的玩法，所以，启动操作系统时，很多不必要的服务可以不用启动，而是等待通知，lazy 启动。而且事件驱动的好处是，可以并行启动服务，他们之间的依赖关系，由相应的事件通知完成。\nupstart 有着很不错的设计，其中最重要的两个概念是 Job 和 Event。\nJob 有一般的Job，也有service的Job，并且，upstart 管理了整个 Job 的生命周期，比如：Waiting, Starting, pre-Start, Spawned, post-Start, Running, pre-Stop, Stopping, Killed, post-Stop等等，并维护着这个生命周期的状态机。\nEvent 分成三类，signal, method 和 hooks。signal 就是异步消息，method 是同步阻塞的。hooks 也是同步的，但介于前面两者之间，发出hook事件的进程必须等到事件完成，但不检查是否成功。\n但是，upstart 的事件非常复杂，也非常纷乱，各种各样的事件（事件没有归好类）导致有点凌乱。不过因为整个事件驱动的设计比之前的 sysvinit 来说好太多，所以，也深得欢迎。\nSystemd 直到2010的有一天，一个在 RedHat工作的工程师 Lennart Poettering 和 Kay Sievers ，开始引入了一个新的 init 系统—— systemd。这是一个非常非常有野心的项目，这个项目几乎改变了所有的东西，systemd 不但想取代已有的 init 系统，而且还想干更多的东西。\nLennart 同意 upstart 干的不错，代码质量很好，基于事件的设计也很好。但是他觉得 upstart 也有问题，其中最大的问题还是不够快，虽然 upstart 用事件可以达到一定的启动并行度，但是，本质上来说，这些事件还是会让启动过程串行在一起。 如：NetworkManager 在等 D-Bus 的启动事件，而 D-Bus 在等 syslog 的启动事件。\nLennart 认为，实现上来说，upstart 其实是在管理一个逻辑上的服务依赖树，但是这个服务依赖树在表现形式上比较简单，你只需要配置——“启动 B好了就启动A”或是“停止了A后就停止B”这样的规则。但是，Lennart 说，这种简单其实是有害的（this simplification is actually detrimental）。他认为，\n  从一个系统管理的角度出来，他一开始会设定好整个系统启动的服务依赖树，但是这个系统管理员要人肉的把这个本来就非常干净的服务依整树给翻译成计算机看的懂的 Event/Action 形式，而且 Event/Action 这种配置方式是运行时的，所以，你需要运行起来才知道是什么样的。\n  Event逻辑从头到脚到处都是，这个事件扩大了运维的复杂度，还不如之前的 sysvint。 也就是说，当用户配置了 “启动 D-Bus 后请启动 NetworkManager”， 这个 upstart 可以干，但是反过来，如果，用户启动 NetworkManager，我们应该先去启动他的前置依赖 D-Bus，然而你还要配置相应的反向 Event。本来，我只需要配置一条依赖的，结果现在我要配置很多很多情况下的Event。\n  最后，upstart 里的 Event 的并不标准，很混乱，没有良好的定义。比如：既有，进程启动，运行，停止的事件，也有USB设备插入、可用、拔出的事件，还有文件系统设备being mounted、 mounted 和 umounted 的事件，还有AC电源线连接和断开的事件。你会发现，这进程启停的、USB的、文件系统的、电源线的事件，看上去长得很像， 但是没有被标准化抽像出来掉，因为绝大多数的事件都是三元组：start, condition, stop 。这种概念设计模型并没有在 upstart 中出现。因为 upstart 被设计为单一的事件，而忽略了逻辑依赖。\n  当然，如果 systemd 只是解决 upstart 的问题，他就改造 upstart 就好了，但是 Lennart 的野心不只是想干个这样的事，他想干的更多。\n首先，systemd 清醒的认识到了 init 进程的首要目标是要让用户快速的进入可以操作OS的环境，所以，这个速度一定要快，越快越好，所以，systemd 的设计理念就是两条：\n To start less. And to start more in parallel.  也就是说，按需启动，能不启动就不启动，如果要启动，能并行启动就并行启动，包括你们之间有依赖，我也并行启动。按需启动还好理解，那么，有依赖关系的并行启动，它是怎么做到的？这里，systemd 借鉴了 MacOS 的 Launchd 的玩法（在Youtube上有一个分享——Launchd: One Program to Rule them All，在苹果的开源网站上也有相关的设计文档——About Daemons and Services）\n要解决这些依赖性，systemd 需要解决好三种底层依赖—— Socket， D-Bus ，文件系统。\n  Socket依赖。如果服务C依赖于服务S的socket，那么就要先启动S，然后再启动C，因为如果C启动时找不到S的Socket，那么C就会失败。systemd 可以帮你在S还没有启动好的时候，建立一个socket，用来接收所有的C的请求和数据，并缓存之，一旦S全部启动完成，把systemd替换好的这个缓存的数据和Socket描述符替换过去。\n  D-Bus依赖。D-Bus 全称 Desktop Bus，是一个用来在进程间通信的服务。除了用于用户态进程和内核态进程通信，也用于用户态的进程之前。现在，很多的现在的服务进程都用 D-Bus 而不是Socket来通信。比如：NetworkManager 就是通过 D-Bus 和其它服务进程通讯的，也就是说，如果一个进程需要知道网络的状态，那么就必需要通过 D-Bus 通信。D-Bus 支持 “Bus Activation”的特性。也就是说，A要通过 D-Bus 服务和B通讯，但是B没有启动，那么 D-Bus 可以把B起来，在B启动的过程中，D-Bus 帮你缓存数据。systemd 可以帮你利用好这个特性来并行启动 A 和 B。\n  文件系统依赖。系统启动过程中，文件系统相关的活动是最耗时的，比如挂载文件系统，对文件系统进行磁盘检查（fsck），磁盘配额检查等都是非常耗时的操作。在等待这些工作完成的同时，系统处于空闲状态。那些想使用文件系统的服务似乎必须等待文件系统初始化完成才可以启动。systemd 参考了 autofs 的设计思路，使得依赖文件系统的服务和文件系统本身初始化两者可以并发工作。autofs 可以监测到某个文件系统挂载点真正被访问到的时候才触发挂载操作，这是通过内核 automounter 模块的支持而实现的。比如一个 open() 系统调用作用在某个文件系统上的时候，而这个文件系统尚未执行挂载，此时 open() 调用被内核挂起等待，等到挂载完成后，控制权返回给 open() 系统调用，并正常打开文件。这个过程和 autofs 是相似的。\n  下图来自 Lennart 的演讲里的一页PPT，展示了不同 init 系统的启动。\n除此之外，systemd 还在启动时管理好了一些下面的事。\n用C语言取代传统的脚本式的启动。前面说过，sysvint 用 /etc/rcX.d 下的各种脚本启动。然而这些脚本中需要使用 awk, sed, grep, find, xargs 等等这些操作系统的命令，这些命令需要生成进程，生成进程的开销很大，关键是生成完这些进程后，这个进程就干了点屁大的事就退了。换句话说就是，我操作系统干了那么多事为你拉个进程起来，结果你就把个字串转成小写就退了，把我操作系统当什么了？\n在正常的一个 sysvinit 的脚本里，可能会有成百上千个这样的命令。所以，慢死。因此，systemd 全面用 C 语言全部取代了。一般来说，sysvinit 下，操作系统启动完成后，用 echo $$ 可以看到，pid 被分配到了上千的样子，而 systemd 的系统只是上百。\n另外，systemd 是真正一个可以管住服务进程的——可以跟踪上服务进程所fork/exec出来的所有进程。\n  我们知道， 传统 Unix/Linux 的 Daemon 服务进程的最佳实践基本上是这个样子的（具体过程可参看这篇文章“[SysV Daemon](http://0pointer.de/public/systemd-man/daemon.html#SysV Daemons)”）\n 进程启动时，关闭所有的打开的文件描述符（除了标准描述符0,1,2），然后重置所有的信号处理。 调用 fork() 创建子进程，在子进程中 setsid()，然后父进程退出（为了后台执行） 在子进程中，再调用一次 fork()，创建孙子进程，确定没有交互终端。然后子进程退出。 在孙子进程中，把标准输入标准输出标准错误都连到 /dev/null 上，还要创建 pid 文件，日志文件，处理相关信号 …… 最后才是真正开始提供服务。    在上面的这个过程中，服务进程除了两次 fork 外还会 fork 出很多很多的子进程（比如说一些Web服务进程，会根据用户的请求链接来 fork 子进程），这个进程树是相当难以管理的，因为，一旦父进程退出来了，子进程就会被挂到 PID 1下，所以，基本上来说，你无法通过服务进程自已给定的一个pid文件来找到所有的相关进程（这个对开发者的要求太高了），所以，在传统的方式下用脚本启停服务是相当相当的 Buggy 的，因为无法做对所有的服务生出来的子子孙孙做到监控。\n  为了解决这个问题，upstart 通过变态的 strace 来跟踪进程中的 fork() 和 exec() 或 exit() 等相关的系统调用。这种方法相当笨拙。 systemd 使用了一个非常有意思的玩法来 tracking 服务进程生出来的所有进程，那就是用 cgroup （我在 Docker 的基础技术“cgroup篇”中讲过这个东西）。cgroup主要是用来管理进程组资源配额的事，所以，无论服务如何启动新的子进程，所有的这些相关进程都会同属于一个 cgroup，所以，systemd 只需要简单的去遍历一下相应的 cgroup 的那个虚文件系统目录下的文件，就可以正确的找到所有的相关进程，并将他们一一停止。\n  另外，systemd 简化了整个 daemon 开发的过程：\n 不需要两次 fork()，只需要实现服务本身的主逻辑就可以了。 不需要 setsid()，systemd 会帮你干 不需要维护 pid文件，systemd 会帮处理。 不需要管理日志文件或是使用syslog，或是处理HUP的日志reload信号。把日志打到 stderr 上，systemd 帮你管理。 处理 SIGTERM 信号，这个信号就是正确退出当前服务，不要做其他的事。 ……  除此之外，systemd 还能——\n 自动检测启动的服务间有没有环形依赖。 内建 autofs 自动挂载管理功能。 日志服务。systemd 改造了传统的 syslog 的问题，采用二进制格式保存日志，日志索引更快。 快照和恢复。对当前的系统运行的服务集合做快照，并可以恢复。 ……  还有好多好多，他接管很多很多东西，于是就让很多人不爽了，因为他在干了很多本不属于 PID 1 的事。\nSystemd 争论和八卦 于是 systemd 这个东西成了可能是有史以来口水战最多的一个开源软件了。systemd 饱受各种争议，最大的争议就是他破坏了 Unix 的设计哲学（相关的哲学可以读一下《Unix编程艺术》），干了一个大而全而且相当复杂的东西。当然，Lennart 并不同意这样的说法，他后来又写一篇blog “The Biggest Myths”来解释 systemd 并不是这样的，大家可以前往一读。\n这个争议大到什么样子呢？2014 年，Debian Linux 因为想准备使用 systemd 来作为标准的 init 守护进程来替换 sysvinit 。而围绕这个事的争论达到了空前的热度，争论中充满着仇恨，systemd 的支持者和反对者都在互相辱骂，导致当时 Debian 阵营开始分裂。还有人给 Lennart 发了死亡威胁的邮件，用比特币雇凶买杀手，扬言要取他的性命，在Youbute上传了侮辱他的歌曲，在IRC和各种社交渠道上给他发下流和侮辱性的消息。这已经不是争议了，而是一种不折不扣的仇恨！\n于是，Lennart 在 Google Plus 上发了贴子，批评整个 Linux 开源社区和 Linus 本人。他大意说，\n 这个社区太病态了，全是 ass holes，你们不停用各种手段在各种地方用不同的语言和方式来侮辱和漫骂我。我还是一个年轻人，我从来没有经历过这样的场面，但是今天我已经对这种场面很熟悉了。我有时候说话可能不准确，但是我不会像他样那样说出那样的话，我也没有被这些事影响，因为我脸皮够厚，所以，为什么我可以在如何大的反对声面前让 systemd 成功，但是，你们 Linux 社区太可怕了。你们里面的有精神病的人太多了。另外，对于Linus Torvalds，你是这个社区的 Role Model，但可惜你是一个 Bad Role Model，你在社区里的刻薄和侮辱性的言行，基本从一定程度上鼓励了其它人跟你一样，当然，并不只是你一个人的问题，而是在你周围聚集了一群和你一样的这样干的人。送你一句话—— A fish rots from the head down ！一条鱼是从头往下腐烂的……\n 这篇契文很长，喜欢八卦的同学可以前往一读。感受一下 Lennart 当时的心态（我觉得能算上是非常平稳了）。\nLinus也在被一媒体问起 systemd 这个事来（参看“Torvalds says he has no strong opinions on systemd”），Linus在采访里说，\n 我对 systemd 和 Lennart 的贴子没有什么强烈的想法。虽然，传统的 Unix 设计哲学—— “Do one thing and Do it well”，很不错，而且我们大多数人也实践了这么多年，但是这并不代表所有的真实世界。在历史上，也不只有systemd 这么干过。但是，我个人还是 old-fashioned 的人，至少我喜欢文本式的日志，而不是二进制的日志。但是 systemd 没有必要一定要有这样的品味。哦，我说细节了……\n 今天，systemd 占据了几乎所有的主流的 Linux 发行版的默认配置，包括：Arch Linux、CentOS、CoreOS、Debian、Fedora、Megeia、OpenSUSE、RHEL、SUSE企业版和 Ubuntu。而且，对于 CentOS, CoreOS, Fedora, RHEL, SUSE这些发行版来说，不能没有 systemd。（Ubuntu 还有一个不错的wiki – Systemd for Upstart Users 阐述了如何在两者间切换）\n其它 还记得在《缓存更新的套路》一文中，我说过，如果你要做好架构，首先你得把计算机体系结构以及很多老古董的基础技术吃透了。因为里面会有很多可以借鉴和相通的东西。那么，你是否从这篇文章里看到了一些有分布式架构相似的东西？\n比如：从 sysvinit 到 upstart 再到 systemd，像不像是服务治理？Linux系统下的这些服务进程，是不是很像分布式架构中的微服务？还有那个D-Bus，是不是很像SOA里的ESB？而 init 系统是不是很像一个控制系统？甚至像一个服务编排（Service Orchestration）系统？\n分布式系统中的服务之间也有很多依赖，所以，在启动一个架构的时候，如果我们可以做到像 systemd 那样并行启动的话，那么是不是就像是一个微服务的玩法了？\n嗯，你会发现，技术上的很多东西是相通的，也是互相有对方的影子，所以，其实技术并不多。关键是我们学在了表面还是看到了本质。\n命令 Systemd 是 Linux 系统工具，用来启动守护进程，已成为大多数发行版的标准配置。\n系统管理 Systemd 并不是一个命令，而是一组命令，涉及到系统管理的方方面面。\nsystemctl\nsystemctl是 Systemd 的主命令，用于管理系统。\n# 重启系统 $ sudo systemctl reboot # 关闭系统，切断电源 $ sudo systemctl poweroff # CPU停止工作 $ sudo systemctl halt # 暂停系统 $ sudo systemctl suspend # 让系统进入冬眠状态 $ sudo systemctl hibernate # 让系统进入交互式休眠状态 $ sudo systemctl hybrid-sleep # 启动进入救援状态（单用户状态） $ sudo systemctl rescue systemd-analyze\nsystemd-analyze命令用于查看启动耗时。\n# 查看启动耗时 $ systemd-analyze # 查看每个服务的启动耗时 $ systemd-analyze blame # 显示瀑布状的启动过程流$ $ systemd-analyze critical-chain # 显示指定服务的启动流 $ systemd-analyze critical-chain atd.service hostnamectl\nhostnamectl命令用于查看当前主机的信息。\n# 显示当前主机的信息 $ hostnamectl # 设置主机名。 $ sudo hostnamectl set-hostname rhel7 localectl\nlocalectl命令用于查看本地化设置。\n# 查看本地化设置 $ localectl # 设置本地化参数。 $ sudo localectl set-locale LANG=en_GB.utf8 $ sudo localectl set-keymap en_GB timedatectl\ntimedatectl命令用于查看当前时区设置。\n# 查看当前时区设置 $ timedatectl # 显示所有可用的时区 $ timedatectl list-timezones # 设置当前时区 $ sudo timedatectl set-timezone America/New_York $ sudo timedatectl set-time YYYY-MM-DD $ sudo timedatectl set-time HH:MM:SS loginctl\nloginctl命令用于查看当前登录的用户。\n# 列出当前session $ loginctl list-sessions # 列出当前登录用户 $ loginctl list-users # 列出显示指定用户的信息 $ loginctl show-user ruanyf Unit 含义\nSystemd 可以管理所有系统资源。不同的资源统称为 Unit（单元）。简单说，单元就是 Systemd 的最小功能单位，是单个进程的描述。一个个小的单元互相调用和依赖，组成一个庞大的任务管理系统，这就是 Systemd 的基本思想。\n由于 Systemd 要做的事情太多，导致单元有很多不同的种类，大概一共有12种。\n Service unit：系统服务 Target unit：多个 Unit 构成的一个组 Device Unit：硬件设备 Mount Unit：文件系统的挂载点 Automount Unit：自动挂载点 Path Unit：文件或路径 Scope Unit：不是由 Systemd 启动的外部进程 Slice Unit：进程组，资源分配 Snapshot Unit：Systemd 快照，可以切回某个快照 Socket Unit：进程间通信的 socket Swap Unit：swap 文件 Timer Unit：定时器  systemctl list-units命令可以查看当前系统的所有 Unit 。\n# 列出正在运行的 Unit $ systemctl list-units # 列出所有Unit，包括没有找到配置文件的或者启动失败的 $ systemctl list-units --all # 列出所有没有运行的 Unit $ systemctl list-units --all --state=inactive # 列出所有加载失败的 Unit $ systemctl list-units --failed # 列出所有正在运行的、类型为 service 的 Unit $ systemctl list-units --type=service Unit 的状态\nsystemctl status命令用于查看系统状态和单个 Unit 的状态。\n# 显示系统状态 $ systemctl status # 显示单个 Unit 的状态 $ sysystemctl status bluetooth.service # 显示远程主机的某个 Unit 的状态 $ systemctl -H root@rhel7.example.com status httpd.service 例如查看 httpd 状态\n$ sudo systemctl status httpd httpd.service - The Apache HTTP Server Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled) Active: active (running) since 金 2014-12-05 12:18:22 JST; 7min ago Main PID: 4349 (httpd) Status: \u0026#34;Total requests: 1; Current requests/sec: 0; Current traffic: 0 B/sec\u0026#34; CGroup: /system.slice/httpd.service ├─4349 /usr/sbin/httpd -DFOREGROUND ├─4350 /usr/sbin/httpd -DFOREGROUND ├─4351 /usr/sbin/httpd -DFOREGROUND ├─4352 /usr/sbin/httpd -DFOREGROUND ├─4353 /usr/sbin/httpd -DFOREGROUND └─4354 /usr/sbin/httpd -DFOREGROUND 12月 05 12:18:22 localhost.localdomain systemd[1]: Starting The Apache HTTP Server... 12月 05 12:18:22 localhost.localdomain systemd[1]: Started The Apache HTTP Server. 12月 05 12:22:40 localhost.localdomain systemd[1]: Started The Apache HTTP Server. 上面的输出结果含义如下。\n Loaded行：配置文件的位置，是否设为开机启动 Active行：表示正在运行 Main PID行：主进程ID Status行：由应用本身（这里是 httpd ）提供的软件当前状态 CGroup块：应用的所有子进程 日志块：应用的日志  除了status命令，systemctl还提供了三个查询状态的简单方法，主要供脚本内部的判断语句使用。\n# 显示某个 Unit 是否正在运行 $ systemctl is-active application.service # 显示某个 Unit 是否处于启动失败状态 $ systemctl is-failed application.service # 显示某个 Unit 服务是否建立了启动链接 $ systemctl is-enabled application.service Unit 管理\n对于用户来说，最常用的是下面这些命令，用于启动和停止 Unit（主要是 service）。\n# 立即启动一个服务 $ sudo systemctl start apache.service # 立即停止一个服务 $ sudo systemctl stop apache.service # 重启一个服务 $ sudo systemctl restart apache.service # 杀死一个服务的所有子进程 $ sudo systemctl kill apache.service # 重新加载一个服务的配置文件 $ sudo systemctl reload apache.service # 重载所有修改过的配置文件 $ sudo systemctl daemon-reload # 显示某个 Unit 的所有底层参数 $ systemctl show httpd.service # 显示某个 Unit 的指定属性的值 $ systemctl show -p CPUShares httpd.service # 设置某个 Unit 的指定属性 $ sudo systemctl set-property httpd.service CPUShares=500 有时候，该命令可能没有响应，执行systemctl stop服务停不下来。这时候就不得不\u0026quot;杀进程\u0026quot;了，向正在运行的进程发出kill信号，执行systemctl kill。\n依赖关系\nUnit 之间存在依赖关系：A 依赖于 B，就意味着 Systemd 在启动 A 的时候，同时会去启动 B。\nsystemctl list-dependencies命令列出一个 Unit 的所有依赖。\n$ systemctl list-dependencies nginx.service 上面命令的输出结果之中，有些依赖是 Target 类型（详见下文），默认不会展开显示。如果要展开 Target，就需要使用--all参数。\n$ systemctl list-dependencies --all nginx.service Unit 的配置文件 概述\n每一个 Unit 都有一个配置文件，告诉 Systemd 怎么启动这个 Unit 。\n除了系统默认的单元文件/lib/systemd/system，Systemd 默认从目录/etc/systemd/system/读取配置文件。但是，里面存放的大部分文件都是符号链接，指向目录/usr/lib/systemd/system/。那些支持 Systemd 的软件，安装的时候，也会自动在/usr/lib/systemd/system目录添加一个配置文件。\nsystemctl enable命令用于在/etc/systemd/system/和/usr/lib/systemd/system之间，建立符号链接关系。\n$ sudo systemctl enable clamd@scan.service # 等同于 $ sudo ln -s \u0026#39;/usr/lib/systemd/system/clamd@scan.service\u0026#39; \u0026#39;/etc/systemd/system/multi-user.target.wants/clamd@scan.service\u0026#39; 如果配置文件里面设置了开机启动，systemctl enable命令相当于激活开机启动。\n与之对应的，systemctl disable命令用于在两个目录之间，撤销符号链接关系，相当于撤销开机启动。\n$ sudo systemctl disable clamd@scan.service 配置文件的后缀名，就是该 Unit 的种类，比如sshd.socket。如果省略，Systemd 默认后缀名为.service，所以sshd会被理解成sshd.service。\n设置开机启动以后，软件并不会立即启动，必须等到下一次开机。如果想现在就运行该软件，那么要执行systemctl start命令。\n配置文件的状态\nsystemctl list-unit-files命令用于列出所有配置文件。\n# 列出所有配置文件 $ systemctl list-unit-files # 列出指定类型的配置文件 $ systemctl list-unit-files --type=service 这个命令会输出一个列表。\n$ systemctl list-unit-filesUNIT FILE STATEchronyd.service enabledclamd@.service staticclamd@scan.service disabled 这个列表显示每个配置文件的状态，一共有四种。\n enabled：已建立启动链接 disabled：没建立启动链接 static：该配置文件没有[Install]部分（无法执行），只能作为其他配置文件的依赖 masked：该配置文件被禁止建立启动链接  注意，从配置文件的状态无法看出，该 Unit 是否正在运行。这必须执行前面提到的systemctl status命令。\n$ systemctl status bluetooth.service 一旦修改配置文件，就要让 Systemd 重新加载配置文件，然后重新启动，否则修改不会生效。\n$ sudo systemctl daemon-reload $ sudo systemctl restart httpd.service 配置文件的格式\n配置文件就是普通的文本文件，可以用文本编辑器打开。\nsystemctl cat命令可以查看配置文件的内容。\n$ systemctl cat sshd.service [Unit] Description=OpenSSH server daemon Documentation=man:sshd(8) man:sshd_config(5) After=network.target sshd-keygen.service Wants=sshd-keygen.service [Service] EnvironmentFile=/etc/sysconfig/sshd ExecStart=/usr/sbin/sshd -D $OPTIONS ExecReload=/bin/kill -HUP $MAINPID Type=simpleKill Mode=process Restart=on-failure RestartSec=42s [Install] WantedBy=multi-user.target 从上面的输出可以看到，配置文件分成几个区块。每个区块的第一行，是用方括号表示的区别名，比如[Unit]。注意，配置文件的区块名和字段名，都是大小写敏感的。\n每个区块内部是一些等号连接的键值对。\n[Section] Directive1=value Directive2=value . . . 注意，键值对的等号两侧不能有空格。\n配置文件的区块\n[Unit]区块通常是配置文件的第一个区块，用来定义 Unit 的元数据，以及配置与其他 Unit 的关系。它的主要字段如下。\n  Description：当前服务的简单描述\n  Documentation：文档地址\n  启动顺序\n Before：如果该字段指定的 Unit 也要启动，那么必须在当前 Unit 之后启动 After：如果该字段指定的 Unit 也要启动，那么必须在当前 Unit 之前启动。如network.target或sshd-keygen.service需要启动，那么sshd.service应该在它们之后启动。    依赖关系：\n举例来说，某 Web 应用需要 postgresql 数据库储存数据。在配置文件中，Before、After 只定义要在 postgresql 之后启动，而没有定义依赖 postgresql 。上线后，由于某种原因，postgresql 需要重新启动，在停止服务期间，该 Web 应用就会无法建立数据库连接。\n注意，Wants字段与Requires字段只涉及依赖关系，与启动顺序无关，默认情况下是同时启动的。\n Wants：与当前 Unit 配合的其他 Unit，如果它们没有运行，当前 Unit 不会启动失败。如sshd.service与sshd-keygen.service之间存在\u0026quot;弱依赖\u0026quot;关系，即如果\u0026quot;sshd-keygen.service\u0026quot;启动失败或停止运行，不影响sshd.service继续执行。 Requires：当前 Unit 依赖的其他 Unit，如果它们没有运行，当前 Unit 会启动失败。Requires字段则表示\u0026quot;强依赖\u0026quot;关系，即如果该服务启动失败或异常退出，那么sshd.service也必须退出。    BindsTo：与Requires类似，它指定的 Unit 如果退出，会导致当前 Unit 停止运行\n  Conflicts：这里指定的 Unit 不能与当前 Unit 同时运行\n  Condition...：当前 Unit 运行必须满足的条件，否则不会运行\n  Assert...：当前 Unit 运行必须满足的条件，否则会报启动失败\n  StartLimitIntervalSec=interval, StartLimitBurst=burst：设置单元的启动频率限制。 也就是该单元在 interval 时间内最多允许启动 burst 次。\n   [Service]区块用来定义如何启动当前服务，只有 Service 类型的 Unit 才有这个区块。它的主要字段如下。\n  EnvironmentFile字段：指定当前服务的环境参数文件。该文件内部的key=value键值对，可以用$key的形式，在当前配置文件中获取。sshd 的环境参数文件是/etc/sysconfig/sshd。\n  ExecStart字段：定义启动进程时执行的命令。是配置文件里面最重要的字段。上面的例子中，启动sshd，执行的命令是/usr/sbin/sshd -D $OPTIONS，其中的变量$OPTIONS就来自EnvironmentFile字段指定的环境参数文件。与之作用相似的，还有如下这些字段。\n ExecReload字段：重启服务时执行的命令 ExecStop字段：停止服务时执行的命令 ExecStartPre字段：启动服务之前执行的命令 ExecStartPost字段：启动服务之后执行的命令 ExecStopPost字段：停止服务之后执行的命令    Type：字段定义启动类型。它可以设置的值如下。\n simple（默认值）：ExecStart字段启动的进程为主进程 forking：ExecStart字段将以fork()方式启动，此时父进程将会退出，子进程将成为主进程 oneshot：类似于simple，但只执行一次，Systemd 会等它执行完，才启动其他服务 dbus：类似于simple，但会等待 D-Bus 信号后启动 notify：类似于simple，启动结束后会发出通知信号，然后 Systemd 再启动其他服务 idle：类似于simple，但是要等到其他任务都执行完，才会启动该服务。一种使用场合是为让该服务的输出，不与其他服务的输出相混合    KillMode字段：定义 Systemd 如何停止服务。\n control-group（默认值）：当前控制组里面的所有子进程，都会被杀掉 process：只杀主进程。比如sshd的KillMode设为process，子进程打开的 SSH session 仍然保持连接。 mixed：主进程将收到 SIGTERM 信号，子进程收到 SIGKILL 信号 none：没有进程会被杀掉，只是执行服务的 stop 命令。    Restart：Restart字段：定义了服务退出后，Systemd 重启该服务的方式。\n no（默认值）：退出后不会重启 on-success：只有正常退出时（退出状态码为0），才会重启 on-failure：非正常退出时（退出状态码非0），包括被信号终止和超时，才会重启。比如sshd任何意外的失败，都将重启sshd；如果 sshd 正常停止（比如执行systemctl stop命令），它就不会重启。对于守护进程，推荐设为on-failure。 on-abnormal：只有被信号终止和超时，才会重启。对于那些允许发生错误退出的服务，可以设为on-abnormal。 on-abort：只有在收到没有捕捉到的信号终止时，才会重启 on-watchdog：超时退出，才会重启 always：不管是什么退出原因，总是重启     退出原因(↓) | Restart= (→) no always on-success on-failure on-abnormal on-abort on-watchdog     正常退出  X X       退出码不为\u0026quot;0\u0026quot;  X  X      进程被强制杀死  X  X X X    systemd 操作超时  X  X X     看门狗超时  X  X X  X      RestartSec字段：表示 Systemd 重启服务之前，需要等待的秒数。\n  TimeoutSec：定义 Systemd 停止当前服务之前等待的秒数\n  所有的启动设置之前，都可以加上一个连词号（-），表示\u0026quot;抑制错误\u0026quot;，即发生错误的时候，不影响其他命令的执行。比如，EnvironmentFile=-/etc/sysconfig/sshd（注意等号后面的那个连词号），就表示即使/etc/sysconfig/sshd文件不存在，也不会抛出错误。\n [Install]通常是配置文件的最后一个区块，定义如何安装这个配置文件，即怎样做到开机启动。它的主要字段如下。\n WantedBy字段：表示该服务所在的 Target，它的值是一个或多个 Target。Target的含义是服务组，表示一组服务。WantedBy=multi-user.target指的是，sshd 所在的 Target 是multi-user.target。当前 Unit 激活时（enable）符号链接会放入/etc/systemd/system目录下面 [Target 名].wants子目录中，如multi-user.target.wants子目录。 RequiredBy：它的值是一个或多个 Target，当前 Unit 激活时，符号链接会放入/etc/systemd/system目录下面以 Target 名 + .required后缀构成的子目录中 Alias：当前 Unit 可用于启动的别名 Also：当前 Unit 激活（enable）时，会被同时激活的其他 Unit  Unit 配置文件的完整字段清单，请参考官方文档。\nTarget 启动计算机的时候，需要启动大量的 Unit。如果每一次启动，都要一一写明本次启动需要哪些 Unit，显然非常不方便。Systemd 的解决方案就是 Target。\n简单说，Target 就是一个 Unit 组，包含许多相关的 Unit 。启动某个 Target 的时候，Systemd 就会启动里面所有的 Unit。从这个意义上说，Target 这个概念类似于\u0026quot;状态点\u0026quot;，启动某个 Target 就好比启动到某种状态。\n传统的init启动模式里面，有 RunLevel 的概念，跟 Target 的作用很类似。不同的是，RunLevel 是互斥的，不可能多个 RunLevel 同时启动，但是多个 Target 可以同时启动。\n# 查看当前系统的所有 Target $ systemctl list-unit-files --type=target # 查看一个 Target 包含的所有 Unit $ systemctl list-dependencies multi-user.target # 查看启动时的默认 Target，在这个组里的所有服务，都将开机启动。 $ systemctl get-default # 设置启动时的默认 Target $ sudo systemctl set-default multi-user.target # 切换 Target 时，默认不关闭前一个 Target 启动的进程， # systemctl isolate 命令改变这种行为， # 关闭前一个 Target 里面所有不属于后一个 Target 的进程 $ sudo systemctl isolate multi-user.target Target 与 传统 RunLevel 的对应关系如下。\nTraditional runlevel New target name Symbolically linked to... Runlevel 0 | runlevel0.target -\u0026gt; poweroff.target Runlevel 1 | runlevel1.target -\u0026gt; rescue.target Runlevel 2 | runlevel2.target -\u0026gt; multi-user.target Runlevel 3 | runlevel3.target -\u0026gt; multi-user.target Runlevel 4 | runlevel4.target -\u0026gt; multi-user.target Runlevel 5 | runlevel5.target -\u0026gt; graphical.target Runlevel 6 | runlevel6.target -\u0026gt; reboot.target 它与init进程的主要差别如下。\n（1）默认的 RunLevel（在/etc/inittab文件设置）现在被默认的 Target 取代，位置是/etc/systemd/system/default.target，通常符号链接到graphical.target（图形界面）或者multi-user.target（多用户命令行）。\n（2）启动脚本的位置，以前是/etc/init.d目录，符号链接到不同的 RunLevel 目录 （比如/etc/rc3.d、/etc/rc5.d等），现在则存放在/lib/systemd/system和/etc/systemd/system目录。\n（3）配置文件的位置，以前init进程的配置文件是/etc/inittab，各种服务的配置文件存放在/etc/sysconfig目录。现在的配置文件主要存放在/lib/systemd目录，在/etc/systemd目录里面的修改可以覆盖原始设置。\n日志管理 Systemd 统一管理所有 Unit 的启动日志。带来的好处就是，可以只用journalctl一个命令，查看所有日志（内核日志和应用日志）。日志的配置文件是/etc/systemd/journald.conf。\njournalctl功能强大，用法非常多。\n# 查看所有日志（默认情况下 ，只保存本次启动的日志） $ sudo journalctl # 查看内核日志（不显示应用日志） $ sudo journalctl -k # 查看系统本次启动的日志 $ sudo journalctl -b $ sudo journalctl -b -0 # 查看上一次启动的日志（需更改设置） $ sudo journalctl -b -1 # 查看指定时间的日志 $ sudo journalctl --since=\u0026#34;2012-10-30 18:17:16\u0026#34; $ sudo journalctl --since \u0026#34;20 min ago\u0026#34; $ sudo journalctl --since yesterday $ sudo journalctl --since \u0026#34;2015-01-10\u0026#34; --until \u0026#34;2015-01-11 03:00\u0026#34; $ sudo journalctl --since 09:00 --until \u0026#34;1 hour ago\u0026#34; # 显示尾部的最新10行日志 $ sudo journalctl -n # 显示尾部指定行数的日志 $ sudo journalctl -n 20 # 实时滚动显示最新日志 $ sudo journalctl -f # 查看指定服务的日志 $ sudo journalctl /usr/lib/systemd/systemd # 查看指定进程的日志 $ sudo journalctl _PID=1 # 查看某个路径的脚本的日志 $ sudo journalctl /bin/bash # 查看指定用户的日志 $ sudo journalctl _UID=33 --since today # 查看某个 Unit 的日志 $ sudo journalctl -u nginx.service $ sudo journalctl -u nginx.service --since today # 实时滚动显示某个 Unit 的最新日志 $ sudo journalctl -u nginx.service -f # 合并显示多个 Unit 的日志 $ journalctl -u nginx.service -u php-fpm.service --since today # 查看指定优先级（及其以上级别）的日志，共有8级 # 0: emerg # 1: alert # 2: crit # 3: err # 4: warning # 5: notice # 6: info # 7: debug $ sudo journalctl -p err -b # 日志默认分页输出，--no-pager 改为正常的标准输出 $ sudo journalctl --no-pager # 以 JSON 格式（单行）输出 $ sudo journalctl -b -u nginx.service -o json # 以 JSON 格式（多行）输出，可读性更好 $ sudo journalctl -b -u nginx.serviceqq -o json-pretty # 显示日志占据的硬盘空间 $ sudo journalctl --disk-usage # 指定日志文件占据的最大空间 $ sudo journalctl --vacuum-size=1G # 指定日志文件保存多久 $ sudo journalctl --vacuum-time=1years 定时器示例 邮件脚本 先写一个发邮件的脚本mail.sh。\n#!/usr/bin/env bash echo \u0026#34;This is the body\u0026#34; | /usr/bin/mail -s \u0026#34;Subject\u0026#34; someone@example.com 上面代码的someone@example.com，请替换成你的邮箱地址。\n然后，执行这个脚本。\n$ bash mail.sh 执行后，你应该就会收到一封邮件，标题为Subject。\n如果你的 Linux 系统不能发邮件，建议安装 ssmtp 或者 msmtp。另外，mail命令的用法，可以参考这里。\nService 单元 Service 单元就是所要执行的任务，比如发送邮件就是一种 Service。\n新建 Service 非常简单，就是在/usr/lib/systemd/system目录里面新建一个文件，比如mytimer.service文件，你可以写入下面的内容。\n[Unit] Description=MyTimer [Service] ExecStart=/bin/bash /path/to/mail.sh 注意，定义的时候，所有路径都要写成绝对路径，比如bash要写成/bin/bash，否则 Systemd 会找不到。\n现在，启动这个 Service。\n$ sudo systemctl start mytimer.service 如果一切正常，你应该就会收到一封邮件。\nTimer 单元 Service 单元只是定义了如何执行任务，要定时执行这个 Service，还必须定义 Timer 单元。\n/usr/lib/systemd/system目录里面，新建一个mytimer.timer文件，写入下面的内容。\n[Unit] Description=Runs mytimer every hour [Timer] OnUnitActiveSec=1h Unit=mytimer.service [Install] WantedBy=multi-user.target 这个 Timer 单元文件分成几个部分。\n[Timer]部分定制定时器。Systemd 提供以下一些字段。\n OnActiveSec：定时器生效后，多少时间开始执行任务 OnBootSec：系统启动后，多少时间开始执行任务 OnStartupSec：Systemd 进程启动后，多少时间开始执行任务 OnUnitActiveSec：该单元上次执行后，等多少时间再次执行 OnUnitInactiveSec： 定时器上次关闭后多少时间，再次执行 OnCalendar：基于绝对时间，而不是相对时间执行 AccuracySec：如果因为各种原因，任务必须推迟执行，推迟的最大秒数，默认是60秒 Unit：真正要执行的任务，默认是同名的带有.service后缀的单元 Persistent：如果设置了该字段，即使定时器到时没有启动，也会自动执行相应的单元 WakeSystem：如果系统休眠，是否自动唤醒系统  上面的脚本里面，OnUnitActiveSec=1h表示一小时执行一次任务。其他的写法还有OnCalendar=*-*-* 02:00:00表示每天凌晨两点执行，OnCalendar=Mon *-*-* 02:00:00表示每周一凌晨两点执行，具体请参考中文手册。\nSystem time 硬件时钟和系统时钟 系统用两个时钟保存时间：\n  硬件时钟（即实时时钟 RTC 或 CMOS 时钟）仅能保存：年、月、日、时、分、秒这些时间数值，无法保存时间标准(UTC 或 localtime)和是否使用夏令时调节。\n  系统时钟（即软件时间）与硬件时间分别维护，保存了：时间、时区和夏令时设置。Linux 内核保存为自 UTC 时间 1970 年1月1日经过的秒数。初始系统时钟是从硬件时间计算得来，计算时会考虑/etc/adjtime的设置。系统启动之后，系统时钟与硬件时钟独立运行，Linux 通过时钟中断计数维护系统时钟。\n  大部分操作系统的时间管理包括如下方面：\n 启动时根据硬件时钟设置系统时间 运行时通过时间同步联网校正时间 关机时根据系统时间设置硬件时间  读取时间 下面命令可以获得硬件时间和系统时间:\n$ timedatectl Local time: Thu 2022-01-27 10:35:26 CST Universal time: Thu 2022-01-27 02:35:26 UTC RTC time: Thu 2022-01-27 02:35:26 Time zone: Asia/Shanghai (CST, +0800) System clock synchronized: yes NTP service: active RTC in local TZ: no  Local time 是系统时钟。 RTC time 是硬件时钟，你会发现其与 Universal time 一样，即硬件时钟用 UTC。 Time zone 是时区。 System clock synchronized 是 ntp 时间同步是否成功。 RTC in local TZ 是硬件时钟用地方时。  时间标准 时间表示有两个标准：localtime 和 UTC(Coordinated Universal Time) 。UTC 是与时区无关的全球时间标准。尽管概念上有差别，UTC 和 GMT (格林威治时间) 是一样的。localtime 标准则依赖于当前时区。\n时间标准由操作系统设定，Windows 默认使用 localtime，Mac OS 默认使用 UTC，而 UNIX 系列的操作系统两者都有。使用 Linux 时，最好将硬件时钟设置为 UTC 标准，并在所有操作系统中使用。这样 Linux 系统就可以自动调整夏令时设置，而如果使用 localtime 标准那么系统时间不会根据夏令时自动调整。\n通过如下命令可以检查当前设置，systemd 默认硬件时钟为协调世界时（UTC）。\n$ timedatectl status | grep local RTC in local TZ: no 将硬件时间设置为 localtime：\n# timedatectl set-local-rtc 1 硬件时间设置成 UTC：\n# timedatectl set-local-rtc 0 Windows 系统使用 UTC Windows 操作系统将硬件时钟设置为 localtime。\n注意：经过在 Windows 10 Enterprise LTSC 2019 和 Ubuntu 20.04.4 双系统上测试，将 Windows 的硬件时钟设置为 UTC 后，两个系统时间并不一致；而将 Ubuntu 的硬件时钟设置为 localtime 则达到了预期目标。\nWindows 其实也能处理 UTC，需要修改注册表。使用 regedit,新建如下 DWORD 值，并将其值设为十六进制的 1。\nHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation\\RealTimeIsUniversal 也可以用管理员权限启动命令行来完成：\nreg add \u0026#34;HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\TimeZoneInformation\u0026#34; /v RealTimeIsUniversal /d 1 /t REG_DWORD /f 或者建立一个 .reg 文件并双击：\nWindows Registry Editor Version 5.00 [HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation] \u0026#34;RealTimeIsUniversal\u0026#34;=dword:00000001 时区 检查当前时区：\n$ timedatectl status 显示可用时区：\n$ timedatectl list-timezones 修改时区：\n# timedatectl set-timezone \u0026lt;Zone\u0026gt;/\u0026lt;SubZone\u0026gt; # timedatectl set-timezone Asia/Shanghai 此命令会创建一个/etc/localtime软链接，指向/usr/share/zoneinfo/中的时区文件，如果手动创建此链接请确保是相对链接而不是绝对链接。\n# ln -sf /usr/share/zoneinfo/Zone/SubZone /etc/localtime 时钟偏移 最能代表“真实时间”的是国际原子时钟)，所有的时钟都是有误差的。电子时钟的时间是不准的，但是一般有固定的偏移。这种于基值的差称为“time skew”或“时间偏移”。用 hwclock 设置硬件时间时，会计算每天偏移的秒数。偏移值是原硬件时间与新设置硬件时间的差，并且考虑上次硬件时间设置时的偏移。新的偏移值会在设置时钟时写到文件 /etc/adjtime 。\n注意： 如果硬件时间值与原值的差小于 24 小时，偏移量不会重新计算，因为时间过短，无法精确设置偏移。\n如果硬件时钟总是过快或过慢，可能是计算了错误的偏移值。硬件时钟设置错误或者时间标准与其他操作系统不一致导致。删除文件 /etc/adjtime 可以删除偏移值，然后设置正确的硬件时钟和系统时钟，并检查时间标准是不是设置正确。\n注意： 使用 Systemd 时，要使用 /etc/adjtime中的 drift 值（即无法或不想使用 NTP 时）；需要每次调用 hwclock --adjust命令，可以通过 cron 任务实现。\n时钟同步 网络时间协议 (NTP) 是一个通过包交换和可变延迟网络来同步计算机系统时间的协议。下列为这个协议的实现：\n NTP 守护进程是这个协议的参考实现，推荐用于时间服务器。它也可以调节中断频率和每秒滴答次数以减少系统时钟误差，使得硬件时钟每隔11秒重新同步一次。 systemd-timesyncd 是一个简单的 SNTP 守护进程。它只实现了客户端，专用于从远程服务器查询时间，更适用于绝大部分安装的情形。  timedatectl：在最新的 Ubuntu 版本中，timedatectl替代了老旧的 ntpdate。默认情况下，timedatectl在系统启动的时候会立刻同步时间，并在稍后网络连接激活后通过 socket 再次检查一次。\ntimesyncd：在最新的 Ubuntu 版本中，timesyncd替代了 ntpd的客户端的部分。默认情况下 timesyncd会定期检测并同步时间。它还会在本地存储更新的时间，以便在系统重启时做时间单步调整。更多配置文件信息请参见 man timesyncd.conf：\n时间服务器：默认情况下，基于 systemd 的工具都是从ntp.ubuntu.com请求时间同步的。自定义例如\n$ sudo vim /etc/systemd/timesyncd.conf NTP=ntp.aliyun.com cn.ntp.org.cn ntp.ntsc.ac.cn NTP 服务器列表：\n Windows系统上自带的两个：time.windows.com 和 time.nist.gov MacOS上自带的两个：time.apple.com 和 time.asia.apple.com NTP授时快速域名服务：cn.ntp.org.cn 中国科学院国家授时中心：ntp.ntsc.ac.cn 开源NTP服务器：cn.pool.ntp.org 阿里云授时服务器：ntp.aliyun.com 腾讯云授时服务器：time1.cloud.tencent.com 、time2.cloud.tencent.com 、time3.cloud.tencent.com、time4.cloud.tencent.com、time5.cloud.tencent.com 清华大学授时服务器：ntp.tuna.tsinghua.edu.cn  要重新同步网络时间，可以重启ntp：\n$ sudo systemctl restart systemd-timesyncd $ sudo journalctl -f -u systemd-timesyncd $ timedatectl timesync-status 其他 Firejail 防火墙 保障数据的安全性是继保障数据的可用性之后最为重要的一项工作。防火墙作为公网与内网之间的保护屏障，在保障数据的安全性方面起着至关重要的作用。\n防火墙管理工具 众所周知，相较于企业内网，外部的公网环境更加恶劣，罪恶丛生。在公网与企业内网之间充当保护屏障的防火墙虽然有软件或硬件之分，但主要功能都是依据策略对穿越防火墙自身的流量进行过滤。就像家里安装的防盗门一样，目的是保护亲人和财产安全。防火墙策略可以基于流量的源目地址、端口号、协议、应用等信息来定制，然后防火墙使用预先定制的策略规则监控出入的流量，若流量与某一条策略规则相匹配，则执行相应的处理，反之则丢弃。这样一来，就能够保证仅有合法的流量在企业内网和外部公网之间流动了。\n从RHEL 7系统开始，firewalld防火墙正式取代了iptables防火墙。对于接触Linux系统比较早或学习过RHEL 5/6系统的读者来说，当他们发现曾经掌握的知识在RHEL 7/8中不再适用，需要全新学习firewalld时，难免会有抵触心理。其实，iptables与firewalld都不是真正的防火墙，它们都只是用来定义防火墙策略的防火墙管理工具而已；或者说，它们只是一种服务。iptables服务会把配置好的防火墙策略交由内核层面的netfilter网络过滤器来处理，而firewalld服务则是把配置好的防火墙策略交由内核层面的nftables包过滤框架来处理。换句话说，当前在Linux系统中其实存在多个防火墙管理工具，旨在方便运维人员管理Linux系统中的防火墙策略，我们只需要配置妥当其中的一个就足够了。\n虽然这些工具各有优劣，但它们在防火墙策略的配置思路上是保持一致的。大家甚至可以不用完全掌握本章介绍的内容，只要在这多个防火墙管理工具中任选一款并将其学透，就足以满足日常的工作需求了。\nIptables 在早期的Linux系统中，默认使用的是iptables防火墙管理服务来配置防火墙。尽管新型的firewalld防火墙管理服务已经被投入使用多年，但是大量的企业在生产环境中依然出于各种原因而继续使用iptables。\n策略与规则链 防火墙会按照从上到下的顺序来读取配置的策略规则，在找到匹配项后就立即结束匹配工作并去执行匹配项中定义的行为（即放行或阻止）。如果在读取完所有的策略规则之后没有匹配项，就去执行默认的策略。一般而言，防火墙策略规则的设置有两种：“通”（即放行）和“堵”（即阻止）。当防火墙的默认策略为拒绝时（堵），就要设置允许规则（通），否则谁都进不来；如果防火墙的默认策略为允许，就要设置拒绝规则，否则谁都能进来，防火墙也就失去了防范的作用。\niptables服务把用于处理或过滤流量的策略条目称之为规则，多条规则可以组成一个规则链，而规则链则依据数据包处理位置的不同进行分类，具体如下：\n 在进行路由选择前处理数据包（PREROUTING）； 处理流入的数据包（INPUT）； 处理流出的数据包（OUTPUT）； 处理转发的数据包（FORWARD）； 在进行路由选择后处理数据包（POSTROUTING）。  一般来说，从内网向外网发送的流量一般都是可控且良性的，因此使用最多的就是INPUT规则链，该规则链可以增大黑客人员从外网入侵内网的难度。\n比如在您居住的社区内，物业管理公司有两条规定：禁止小商小贩进入社区；各种车辆在进入社区时都要登记。显而易见，这两条规定应该是用于社区的正门的（流量必须经过的地方），而不是每家每户的防盗门上。根据前面提到的防火墙策略的匹配顺序，可能会存在多种情况。比如，来访人员是小商小贩，则直接会被物业公司的保安拒之门外，也就无须再对车辆进行登记。如果来访人员乘坐一辆汽车进入社区正门，则“禁止小商小贩进入社区”的第一条规则就没有被匹配到，因此按照顺序匹配第二条策略，即需要对车辆进行登记。如果是社区居民要进入正门，则这两条规定都不会匹配到，因此会执行默认的放行策略。\n但是，仅有策略规则还不能保证社区的安全，保安还应该知道采用什么样的动作来处理这些匹配的流量，比如“允许”“拒绝”“登记”“不理它”。这些动作对应到iptables服务的术语中分别是ACCEPT（允许流量通过）、REJECT（拒绝流量通过）、LOG（记录日志信息）、DROP（拒绝流量通过）。“允许流量通过”和“记录日志信息”都比较好理解，这里需要着重讲解的是REJECT和DROP的不同点。就DROP来说，它是直接将流量丢弃而且不响应；REJECT则会在拒绝流量后再回复一条“信息已经收到，但是被扔掉了”信息，从而让流量发送方清晰地看到数据被拒绝的响应信息。\n下面举一个例子，让各位读者更直观地理解这两个拒绝动作的不同之处。比如有一天您正在家里看电视，突然听到有人敲门，您透过防盗门的猫眼一看是推销商品的，便会在不需要的情况下开门并拒绝他们（REJECT）。但如果看到的是债主带了十几个小弟来讨债，此时不仅要拒绝开门，还要默不作声，伪装成自己不在家的样子（DROP）。\n当把Linux系统中的防火墙策略设置为REJECT动作后，流量发送方会看到端口不可达的响应：\n[root@linuxprobe ~]# ping -c 4 192.168.10.10 PING 192.168.10.10 (192.168.10.10) 56(84) bytes of data. From 192.168.10.10 icmp_seq=1 Destination Port Unreachable From 192.168.10.10 icmp_seq=2 Destination Port Unreachable From 192.168.10.10 icmp_seq=3 Destination Port Unreachable From 192.168.10.10 icmp_seq=4 Destination Port Unreachable --- 192.168.10.10 ping statistics --- 4 packets transmitted, 0 received, +4 errors, 100 packet loss, time 3002ms 而把Linux系统中的防火墙策略修改成DROP动作后，流量发送方会看到响应超时的提醒。但是流量发送方无法判断流量是被拒绝，还是接收方主机当前不在线：\n[root@linuxprobe ~]# ping -c 4 192.168.10.10 PING 192.168.10.10 (192.168.10.10) 56(84) bytes of data. --- 192.168.10.10 ping statistics --- 4 packets transmitted, 0 received, 100 packet loss, time 3000ms 基本的命令参数 iptables是一款基于命令行的防火墙策略管理工具，具有大量的参数，学习难度较大。好在对于日常的防火墙策略配置来讲，大家无须深入了解诸如“四表五链”的理论概念，只需要掌握常用的参数并做到灵活搭配即可，这就足以应对日常工作了。\n根据OSI七层模型的定义，iptables属于数据链路层的服务，所以可以根据流量的源地址、目的地址、传输协议、服务类型等信息进行匹配；一旦匹配成功，iptables就会根据策略规则所预设的动作来处理这些流量。另外，再次提醒一下，防火墙策略规则的匹配顺序是从上到下的，因此要把较为严格、优先级较高的策略规则放到前面，以免发生错误。表8-1总结归纳了常用的iptables命令参数。再次强调，无须死记硬背这些参数，只需借助下面的实验来理解掌握即可。\n命令格式 iptables [-t table] COMMAND chain CRETIRIA -j ACTION  -t table ：filter/nat/mangle COMMAND：定义如何对规则进行管理 chain：指定你接下来的规则到底是在哪个链上操作的，当定义策略的时候，是可以省略的 CRETIRIA:指定匹配标准 -j ACTION :指定如何进行处理  参数说明    参数 说明 示例     -t 对指定的表操作(raw、mangle、nat、filter)，默认 filter 表 iptables -t nat   -j 要进行的处理动作:DROP(丢弃)，REJECT(拒绝)，ACCEPT(接受)，SANT(基于原地址的转换) iptable -A INPUT 1 -s 192.168.120.0 -j DROP    通用匹配\n   参数 说明 示例     -p 协议（tcp/udp/icmp） iptables -A INPUT -p tcp   -s 匹配原地址，加\u0026quot; ! \u0026ldquo;表示除这个IP外，192.168.1.0/255.255.255.0 示一组范围内的地址 iptables -A INPUT -s 192.168.1.1   -d 匹配目的地址 ，地址格式同 -s iptables -A INPUT -d 192.168.12.1   -i 匹配入口网卡流入的数据，无此项表示可以来自任何一个网络接口 iptables -A INPUT -i eth0   -o 匹配出口网卡流出的数据 iptables -A FORWARD -o eth0    查看管理命令\n   参数 说明 示例     -L 列出指定链上面的所有规则，如果没有指定链，列出表上所有链的所有规则 iptables -L    规则管理命令\n   参数 说明 示例     -A 在指定链的末尾插入指定的规则 iptables -A INPUT   -I 在链中的指定位置插入规则。默认规则号是1，在链的头部插入规则 iptables -I INPUT 1 \u0026ndash;dport 80 -j ACCEPT   -D 在指定的链中删除指定规则号的规则。 iptables -D INPUT 1   -R 修改指定规则号的规则 iptable -R INPUT 1 -s 192.168.120.0 -j DROP    链管理命令\n   参数 说明 示例     -F 清空规则链 iptables -F   -N 新的规则 iptables -N allowed    其他\n   参数 说明 示例     \u0026ndash;sport 匹配源端口流入的数据 iptables -A INPUT -p tcp \u0026ndash;sport 22   \u0026ndash;dport 匹配目的端口流出的数据 iptables -A INPUT -p tcp \u0026ndash;dport 22   \u0026ndash;to-source 指定SANT转换后的地址 iptables -t nat -A POSTROUTING -s 192.168.10.0/24 -j SANT \u0026ndash;to-source 172.16.100.1   -m 使用扩展模块来进行数据包的匹配(multiport/tcp/state/addrtype) iptables -m multiport    动作说明 处理动作除了 ACCEPT、REJECT、DROP、REDIRECT 和 MASQUERADE 以外，还多出 LOG、ULOG、DNAT、SNAT、MIRROR、QUEUE、RETURN、TOS、TTL、MARK 等，其中某些处理动作不会中断过滤程序，某些处理动作则会中断同一规则链的过滤，并依照前述流程继续进行下一个规则链的过滤，一直到堆栈中的规则检查完毕为止。透过这种机制所带来的好处是，我们可以进行复杂、多重的封包过滤，简单的说，iptables 可以进行纵横交错式的过滤（tables）而非链状过滤（chains）。\n   动作 说明 示例     ACCEPT 将封包放行，进行完此处理动作后，将不再比对其它规则，直接跳往下一个规则链（nat:postrouting）    REJECT 拦阻该封包，并传送封包通知对方，可以传送的封包有几个选择：ICMP port-unreachable、ICMP echo-reply 或是 tcp-reset（这个封包会要求对方关闭联机），进行完此处理动作后，将不再比对其它规则，直接 中断过滤程序。 iptables -A FORWARD -p TCP \u0026ndash;dport 22 -j REJECT \u0026ndash;reject-with tcp-reset   DROP 丢弃封包不予处理，进行完此处理动作后，将不再比对其它规则，直接中断过滤程序。    REDIRECT 将封包重新导向到另一个端口（PNAT），进行完此处理动作后，将 会继续比对其它规则。 这个功能可以用来实作通透式 porxy 或用来保护 web 服务器。 iptables -t nat -A PREROUTING -p tcp \u0026ndash;dport 80 -j REDIRECT \u0026ndash;to-ports 8080   MASQUERADE 改写封包来源 IP 为防火墙 NIC IP，可以指定 port 对应的范围，进行完此处理动作后，直接跳往下一个规则链（mangle:postrouting）。这个功能与 SNAT 略有不同，当进行 IP 伪装时，不需指定要伪装成哪个 IP，IP 会从网卡直接读取，当使用拨接连线时，IP 通常是由 ISP 公司的 DHCP 服务器指派的，这个时候 MASQUERADE 特别有用。 iptables -t nat -A POSTROUTING -p TCP -j MASQUERADE \u0026ndash;to-ports 1024-31000   LOG 将封包相关讯息纪录在 /var/log 中，详细位置请查阅 /etc/syslog.conf 组态档，进行完此处理动作后，将会继续比对其它规则。 iptables -A INPUT -p tcp -j LOG \u0026ndash;log-prefix \u0026ldquo;INPUT packets\u0026rdquo;   SNAT 改写封包来源 IP 为某特定 IP 或 IP 范围，可以指定 port 对应的范围，进行完此处理动作后，将直接跳往下一个规则链（mangle:postrouting）。 iptables -t nat -A POSTROUTING -p tcp-o eth0 -j SNAT \u0026ndash;to-source 194.236.50.155-194.236.50.160:1024-32000   DNAT 改写封包目的地 IP 为某特定 IP 或 IP 范围，可以指定 port 对应的范围，进行完此处理动作后，将会直接跳往下一个规则链（filter:input 或 filter:forward）。 iptables -t nat -A PREROUTING -p tcp -d 15.45.23.67 \u0026ndash;dport 80 -j DNAT \u0026ndash;to-destination 192.168.1.1-192.168.1.10:80-100   MIRROR 镜射封包，也就是将来源 IP 与目的地 IP 对调后，将封包送回，进行完此处理动作后，将会中断过滤程序。    QUEUE 中断过滤程序，将封包放入队列，交给其它程序处理。透过自行开发的处理程序，可以进行其它应用，例如：计算联机费用……等。    RETURN 结束在目前规则链中的过滤程序，返回主规则链继续过滤，如果把自订规则链看成是一个子程序，那么这个动作，就相当于提早结束子程序并返回到主程序中。    MARK 将封包标上某个代号，以便提供作为后续过滤的条件判断依据，进行完此处理动作后，将会继续比对其它规则。 iptables -t mangle -A PREROUTING -p tcp \u0026ndash;dport 22 -j MARK \u0026ndash;set-mark 2    例子 1．在iptables命令后添加-L参数查看已有的防火墙规则链。\n[root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination ACCEPT udp -- anywhere anywhere udp dpt:domain ACCEPT tcp -- anywhere anywhere tcp dpt:domain ACCEPT udp -- anywhere anywhere udp dpt:bootps ACCEPT tcp -- anywhere anywhere tcp dpt:bootps Chain FORWARD (policy ACCEPT) target prot opt source destination ACCEPT all -- anywhere 192.168.122.0/24 ctstate RELATED,ESTABLISHED ACCEPT all -- 192.168.122.0/24 anywhere ACCEPT all -- anywhere anywhere REJECT all -- anywhere anywhere reject-with icmp-port-unreachable REJECT all -- anywhere anywhere reject-with icmp-port-unreachable Chain OUTPUT (policy ACCEPT) target prot opt source destination ACCEPT udp -- anywhere anywhere udp dpt:bootpc 2．在iptables命令后添加-F参数清空已有的防火墙规则链。\n[root@linuxprobe ~]# iptables -F [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination 3．把INPUT规则链的默认策略设置为拒绝。\n[root@linuxprobe ~]# iptables -P INPUT DROP [root@linuxprobe ~]# iptables -L Chain INPUT (policy DROP) target prot opt source destination Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination 前文提到，防火墙策略规则的设置无非有两种方式：“通”和“堵”。当把INPUT链设置为默认拒绝后，就要往里面写入允许策略了，否则所有流入的数据包都会被默认拒绝掉。同学们需要留意的是，规则链的默认策略拒绝动作只能是DROP，而不能是REJECT。\n4．向INPUT链中添加允许ICMP流量进入的策略规则。\n在日常运维工作中，经常会使用ping命令来检查对方主机是否在线，而向防火墙的INPUT规则链中添加一条允许ICMP流量进入的策略规则就默认允许了这种ping命令检测行为。\n[root@linuxprobe ~]# iptables -I INPUT -p icmp -j ACCEPT [root@linuxprobe ~]# ping -c 4 192.168.10.10 PING 192.168.10.10 (192.168.10.10) 56(84) bytes of data. 64 bytes from 192.168.10.10: icmp_seq=1 ttl=64 time=0.154 ms 64 bytes from 192.168.10.10: icmp_seq=2 ttl=64 time=0.041 ms 64 bytes from 192.168.10.10: icmp_seq=3 ttl=64 time=0.038 ms 64 bytes from 192.168.10.10: icmp_seq=4 ttl=64 time=0.046 ms --- 192.168.10.10 ping statistics --- 4 packets transmitted, 4 received, 0 packet loss, time 104ms rtt min/avg/max/mdev = 0.038/0.069/0.154/0.049 ms 5．删除INPUT规则链中刚刚加入的那条策略（允许ICMP流量），并把默认策略设置为允许。\n使用-F参数会清空已有的所有防火墙策略；使用-D参数可以删除某一条指定的策略，因此更加安全和准确。\n[root@linuxprobe ~]# iptables -D INPUT 1 [root@linuxprobe ~]# iptables -P INPUT ACCEPT [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination 6．将INPUT规则链设置为只允许指定网段的主机访问本机的22端口，拒绝来自其他所有主机的流量。\n要对某台主机进行匹配，可直接写出它的IP地址；如需对网段进行匹配，则需要写为子网掩码的形式（比如192.168.10.0/24）。\n[root@linuxprobe ~]# iptables -I INPUT -s 192.168.10.0/24 -p tcp --dport 22 -j ACCEPT [root@linuxprobe ~]# iptables -A INPUT -p tcp --dport 22 -j REJECT [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination ACCEPT tcp -- 192.168.10.0/24 anywhere tcp dpt:ssh REJECT tcp -- anywhere anywhere tcp dpt:ssh reject-with icmp-port-unreachable ………………省略部分输出信息……………… 再次重申，防火墙策略规则是按照从上到下的顺序匹配的，因此一定要把允许动作放到拒绝动作前面，否则所有的流量就将被拒绝掉，从而导致任何主机都无法访问我们的服务。另外，这里提到的22号端口是ssh服务使用的。\n在设置完上述INPUT规则链之后，使用IP地址在192.168.10.0/24网段内的主机访问服务器（即前面提到的设置了INPUT规则链的主机）的22端口，效果如下：\n[root@Client A ~]# ssh 192.168.10.10 The authenticity of host \u0026#39;192.168.10.10 (192.168.10.10)\u0026#39; can\u0026#39;t be established. ECDSA key fingerprint is SHA256:5d52kZi1la/FJK4v4jibLBZhLqzGqbJAskZiME6ZXpQ. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added \u0026#39;192.168.10.10\u0026#39; (ECDSA) to the list of known hosts. root@192.168.10.10\u0026#39;s password: 此处输入服务器密码 Activate the web console with: systemctl enable --now cockpit.socket Last login: Wed Jan 20 16:30:28 2021 from 192.168.10.1 然后，再使用IP地址在192.168.20.0/24网段内的主机访问服务器的22端口（虽网段不同，但已确认可以相互通信），效果如下：\n[root@Client B ~]# ssh 192.168.10.10 Connecting to 192.168.10.10:22... Could not connect to \u0026#39;192.168.10.10\u0026#39; (port 22): Connection failed. 由上可以看到，提示连接请求被拒绝了（Connection failed）。\n7．向INPUT规则链中添加拒绝所有人访问本机12345端口的策略规则。\n[root@linuxprobe ~]# iptables -I INPUT -p tcp --dport 12345 -j REJECT [root@linuxprobe ~]# iptables -I INPUT -p udp --dport 12345 -j REJECT [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination REJECT udp -- anywhere anywhere udp dpt:italk reject-with icmp-port-unreachable REJECT tcp -- anywhere anywhere tcp dpt:italk reject-with icmp-port-unreachable ACCEPT tcp -- 192.168.10.0/24 anywhere tcp dpt:ssh REJECT tcp -- anywhere anywhere tcp dpt:ssh reject-with icmp-port-unreachable ………………省略部分输出信息……………… 8．向INPUT规则链中添加拒绝192.168.10.5主机访问本机80端口（Web服务）的策略规则。\n[root@linuxprobe ~]# iptables -I INPUT -p tcp -s 192.168.10.5 --dport 80 -j REJECT [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination REJECT tcp -- 192.168.10.5 anywhere tcp dpt:http reject-with icmp-port-unreachable REJECT udp -- anywhere anywhere udp dpt:italk reject-with icmp-port-unreachable REJECT tcp -- anywhere anywhere tcp dpt:italk reject-with icmp-port-unreachable ACCEPT tcp -- 192.168.10.0/24 anywhere tcp dpt:ssh REJECT tcp -- anywhere anywhere tcp dpt:ssh reject-with icmp-port-unreachable ………………省略部分输出信息……………… 9．向INPUT规则链中添加拒绝所有主机访问本机1000～1024端口的策略规则。\n前面在添加防火墙策略时，使用的是-I参数，它默认会把规则添加到最上面的位置，因此优先级是最高的。如果工作中需要添加一条最后“兜底”的规则，那就用-A参数吧。这两个参数的效果差别还是很大的：\n[root@linuxprobe ~]# iptables -A INPUT -p tcp --dport 1000:1024 -j REJECT [root@linuxprobe ~]# iptables -A INPUT -p udp --dport 1000:1024 -j REJECT [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination REJECT tcp -- 192.168.10.5 anywhere tcp dpt:http reject-with icmp-port-unreachable REJECT udp -- anywhere anywhere udp dpt:italk reject-with icmp-port-unreachable REJECT tcp -- anywhere anywhere tcp dpt:italk reject-with icmp-port-unreachable ACCEPT tcp -- 192.168.10.0/24 anywhere tcp dpt:ssh REJECT tcp -- anywhere anywhere tcp dpt:ssh reject-with icmp-port-unreachable REJECT tcp -- anywhere anywhere tcp dpts:cadlock2:1024 reject-with icmp-port-unreachable REJECT udp -- anywhere anywhere udp dpts:cadlock2:1024 reject-with icmp-port-unreachable ………………省略部分输出信息……………… 有关iptables命令的知识讲解到此就结束了，大家是不是意犹未尽？考虑到Linux防火墙的发展趋势，大家只要能把上面的实例吸收消化，就可以完全搞定日常的iptables配置工作了。但是请特别注意，使用iptables命令配置的防火墙规则默认会在系统下一次重启时失效，如果想让配置的防火墙策略永久生效，还要执行保存命令：\n[root@linuxprobe ~]# iptables-save  # Generated by xtables-save v1.8.2 on Wed Jan 20 16:56:27 2021 ………………省略部分输出信息……………… 对了，如果公司服务器是5/6/7版本的话，对应的保存命令应该是：\n[root@linuxprobe ~]# service iptables save iptables: Saving firewall rules to /etc/sysconfig/iptables: [ OK ] 基本概念 iptables 是一个配置 Linux 内核 防火墙 的命令行工具，是 Netfilter 项目的一部分。术语 iptables 也经常代指该内核级防火墙。iptables 可以直接配置，也可以通过许多 控制台 和 图形化 前端配置。iptables 用于 ipv4，ip6tables 用于 IPv6。iptables和ip6tables 拥有相同的语法，但是有些特别的选项，对 IPv4 和 IPv6 有些不同的。\niptables 可以检测、修改、转发、重定向和丢弃 IPv4 数据包。过滤 IPv4 数据包的代码已经内置于内核中，并且按照不同的目的被组织成 表 的集合。表 由一组预先定义的 链 组成，链 包含遍历顺序规则（即结构是：iptables -\u0026gt; Tables -\u0026gt; Chains -\u0026gt; Rules）。每一条规则包含一个谓词的潜在匹配和相应的动作（称为 目标），如果谓词为真，该动作会被执行。也就是说条件匹配。iptables 是用户工具，允许用户使用 链 和 规则。很多新手面对复杂的 linux IP 路由时总是感到气馁，但是，实际上最常用的一些应用案例（NAT 或者基本的网络防火墙）并不是很复杂。\n理解 iptables 如何工作的关键是上面这张图（Netfilter模型）。图中在上面的小写字母代表 表，在下面的大写字母代表 链。从任何网络端口 进来的每一个 IP 数据包都要从上到下的穿过这张图。一种常见的错误认知是认为 iptables 对从内部端口进入的数据包和从面向互联网端口进入的数据包采取不同的处理方式，相反，iptabales 对从任何端口进入的数据包都会采取相同的处理方式。可以定义规则使 iptables 采取不同的方式对待从不同端口进入的数据包。当然一些数据包是用于本地进程的，因此在图中表现为从顶端进入，到 \u0026lt;Local Process\u0026gt; 停止，而另一些数据包是由本地进程生成的，因此在图中表现为从 \u0026lt;Local Process\u0026gt; 发出，一直向下穿过该流程图。一份关于该流程图如何工作的详细解释请参考Iptables Tutorial。\n一个解释原理的例子：假设使用路由器作为网关(即我们平时的上网方式，即\u0026lt;Local Process\u0026gt; 是路由器)\n那么：\n 局域网设备通过路由器访问互联网的流量方向：PREROUTING链-\u0026gt;FORWARD链-\u0026gt;POSTINGROUTING链 局域网设备访问路由器的流量(如登陆路由器 web 管理界面/ssh 连接路由器/访问路由器的 dns 服务器等)方向：PREROUTING链-\u0026gt;INPUT链-\u0026gt;网关本机 路由器访问互联网的流量方向：网关本机-\u0026gt;OUTPUT链-\u0026gt;POSTINGROUTING链  表(Tables) ptables 包含 5 张表（tables）:\n raw 用于配置数据包，raw 中的数据包不会被系统跟踪。 filter 是用于存放所有与防火墙相关操作的默认表。 nat 用于 网络地址转换（例如：端口转发）。 mangle 用于对特定数据包的修改（参考 损坏数据包）。 security 用于 强制访问控制 网络规则（例如： SELinux \u0026ndash; 详细信息参考 该文章）。  大部分情况仅需要使用 filter 和 nat。其他表用于更复杂的情况——包括多路由和路由判定——已经超出了本文介绍的范围。\n链(Chains) 表由链组成，链是一些按顺序排列的规则的列表。默认的 filter 表包含 INPUT， OUTPUT 和 FORWARD 3条内建的链，这3条链作用于数据包过滤过程中的不同时间点，如该上面流程图所示。nat 表包含PREROUTING， POSTROUTING 和 OUTPUT 链。\n使用 iptables(8) 查看其他表中内建链的描述。\n默认情况下，任何链中都没有规则。可以向链中添加自己想用的规则。链的默认规则通常设置为 ACCEPT，如果想确保任何包都不能通过规则集，那么可以重置为 DROP。默认的规则总是在一条链的最后生效，所以在默认规则生效前数据包需要通过所有存在的规则。\n用户可以加入自己定义的链，从而使规则集更有效并且易于修改。如何使用自定义链请参考 Simple stateful firewall。\n规则 (Rules) 数据包的过滤基于 规则。规则由一个目标（数据包包匹配所有条件后的动作）和很多匹配（导致该规则可以应用的数据包所满足的条件）指定。一个规则的典型匹配事项是数据包进入的端口（例如：eth0 或者 eth1）、数据包的类型（ICMP, TCP, 或者 UDP）和数据包的目的端口。\n目标使用 -j 或者 --jump 选项指定。目标可以是用户定义的链（例如，如果条件匹配，跳转到之后的用户定义的链，继续处理）、一个内置的特定目标或者是一个目标扩展。内置目标是 ACCEPT， DROP， QUEUE 和 RETURN，目标扩展是 REJECT 和 LOG。如果目标是内置目标，数据包的命运会立刻被决定并且在当前表的数据包的处理过程会停止。如果目标是用户定义的链，并且数据包成功穿过第二条链，目标将移动到原始链中的下一个规则。目标扩展可以被终止（像内置目标一样）或者不终止（像用户定义链一样）。详细信息参阅 iptables-extensions(8)。\n遍历链(Traversing Chains) 该流程图描述链了在任何接口上收到的网络数据包是按照怎样的顺序穿过表的交通管制链。第一个路由策略包括决定数据包的目的地是本地主机（这种情况下，数据包穿过 INPUT 链），还是其他主机（数据包穿过 FORWARD 链）；中间的路由策略包括决定给传出的数据包使用那个源地址、分配哪个接口；最后一个路由策略存在是因为先前的 mangle 与 nat 链可能会改变数据包的路由信息。数据包通过路径上的每一条链时，链中的每一条规则按顺序匹配；无论何时匹配了一条规则，相应的 target/jump 动作将会执行。最常用的3个 target 是 ACCEPT, DROP ,或者 jump 到用户自定义的链。内置的链有默认的策略，但是用户自定义的链没有默认的策略。在 jump 到的链中，若每一条规则都不能提供完全匹配，那么数据包像下面这张图片描述的一样返回到调用链。在任何时候，若 DROP target 的规则实现完全匹配，那么被匹配的数据包会被丢弃，不会进行进一步处理。如果一个数据包在链中被 ACCEPT，那么它也会被所有的父链 ACCEPT，并且不再遍历其他父链。然而，要注意的是，数据包还会以正常的方式继续遍历其他表中的其他链。\n模块(Modules) 有许多模块可以用来扩展 iptables，例如 connlimit, conntrack, limit 和 recent。这些模块增添了功能，可以进行更复杂的过滤。\nFirewalld RHEL 8系统中集成了多款防火墙管理工具，其中firewalld（Dynamic Firewall Manager of Linux systems，Linux系统的动态防火墙管理器）服务是默认的防火墙配置管理工具，它拥有基于CLI（命令行界面）和基于GUI（图形用户界面）的两种管理方式。\n相较于传统的防火墙管理配置工具，firewalld支持动态更新技术并加入了区域（zone）的概念。简单来说，区域就是firewalld预先准备了几套防火墙策略集合（策略模板），用户可以根据生产场景的不同而选择合适的策略集合，从而实现防火墙策略之间的快速切换。例如，我们有一台笔记本电脑，每天都要在办公室、咖啡厅和家里使用。按常理来讲，这三者的安全性按照由高到低的顺序来排列，应该是家庭、公司办公室、咖啡厅。当前，我们希望为这台笔记本电脑制定如下防火墙策略规则：在家中允许访问所有服务；在办公室内仅允许访问文件共享服务；在咖啡厅仅允许上网浏览。在以往，我们需要频繁地手动设置防火墙策略规则，而现在只需要预设好区域集合，然后轻点鼠标就可以自动切换了，从而极大地提升了防火墙策略的应用效率。firewalld中常见的区域名称（默认为public）以及相应的策略规则如表所示。\n   区域 默认规则策略     trusted 允许所有的数据包   home 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh、mdns、ipp-client、amba-client与dhcpv6-client服务相关，则允许流量   internal 等同于home区域   work 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh、ipp-client与dhcpv6-client服务相关，则允许流量   public 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh、dhcpv6-client服务相关，则允许流量   external 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh服务相关，则允许流量   dmz 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh服务相关，则允许流量   block 拒绝流入的流量，除非与流出的流量相关   drop 拒绝流入的流量，除非与流出的流量相关    终端管理工具 命令行终端是一种极富效率的工作方式，firewall-cmd是firewalld防火墙配置管理工具的CLI（命令行界面）版本。它的参数一般都是以“长格式”来提供的。大家不要一听到长格式就头大，因为RHEL 8系统支持部分命令的参数补齐，其中就包含这条命令（很酷吧）。也就是说，现在除了能用Tab键自动补齐命令或文件名等内容之外，还可以用Tab键来补齐表所示的长格式参数。这太棒了！\n   参数 作用     \u0026ndash;get-default-zone 查询默认的区域名称   \u0026ndash;set-default-zone=\u0026lt;区域名称\u0026gt; 设置默认的区域，使其永久生效   \u0026ndash;get-zones 显示可用的区域   \u0026ndash;get-services 显示预先定义的服务   \u0026ndash;get-active-zones 显示当前正在使用的区域与网卡名称   \u0026ndash;add-source= 将源自此IP或子网的流量导向指定的区域   \u0026ndash;remove-source= 不再将源自此IP或子网的流量导向某个指定区域   \u0026ndash;add-interface=\u0026lt;网卡名称\u0026gt; 将源自该网卡的所有流量都导向某个指定区域   \u0026ndash;change-interface=\u0026lt;网卡名称\u0026gt; 将某个网卡与区域进行关联   \u0026ndash;list-all 显示当前区域的网卡配置参数、资源、端口以及服务等信息   \u0026ndash;list-all-zones 显示所有区域的网卡配置参数、资源、端口以及服务等信息   \u0026ndash;add-service=\u0026lt;服务名\u0026gt; 设置默认区域允许该服务的流量   \u0026ndash;add-port=\u0026lt;端口号/协议\u0026gt; 设置默认区域允许该端口的流量   \u0026ndash;remove-service=\u0026lt;服务名\u0026gt; 设置默认区域不再允许该服务的流量   \u0026ndash;remove-port=\u0026lt;端口号/协议\u0026gt; 设置默认区域不再允许该端口的流量   \u0026ndash;reload 让“永久生效”的配置规则立即生效，并覆盖当前的配置规则   \u0026ndash;panic-on 开启应急状况模式   \u0026ndash;panic-off 关闭应急状况模式    与Linux系统中其他的防火墙策略配置工具一样，使用firewalld配置的防火墙策略默认为运行时（Runtime）模式，又称为当前生效模式，而且会随着系统的重启而失效。如果想让配置策略一直存在，就需要使用永久（Permanent）模式了，方法就是在用firewall-cmd命令正常设置防火墙策略时添加\u0026ndash;permanent参数，这样配置的防火墙策略就可以永久生效了。但是，永久生效模式有一个“不近人情”的特点，就是使用它设置的策略只有在系统重启之后才能自动生效。如果想让配置的策略立即生效，需要手动执行firewall-cmd \u0026ndash;reload命令。\n接下来的实验都很简单，但是提醒大家一定要仔细查看使用的是Runtime模式还是Permanent模式。如果不关注这个细节，就算正确配置了防火墙策略，也可能无法达到预期的效果。\n1．查看firewalld服务当前所使用的区域。\n这是一步非常重要的操作。在配置防火墙策略前，必须查看当前生效的是哪个区域，否则配置的防火墙策略将不会立即生效。\n[root@linuxprobe ~]# firewall-cmd --get-default-zone public 2．查询指定网卡在firewalld服务中绑定的区域。\n在生产环境中，服务器大多不止有一块网卡。一般来说，充当网关的服务器有两块网卡，一块对公网，另外一块对内网，那么这两块网卡在审查流量时所用的策略肯定也是不一致的。因此，可以根据网卡针对的流量来源，为网卡绑定不同的区域，实现对防火墙策略的灵活管控。\n[root@linuxprobe ~]# firewall-cmd --get-zone-of-interface=ens160 public 3．把网卡默认区域修改为external，并在系统重启后生效。\n[root@linuxprobe ~]# firewall-cmd --permanent --zone=external --change-interface=ens160 The interface is under control of NetworkManager, setting zone to \u0026#39;external\u0026#39;. success [root@linuxprobe ~]# firewall-cmd --permanent --get-zone-of-interface=ens160 external 4．把firewalld服务的默认区域设置为public。\n默认区域也叫全局配置，指的是对所有网卡都生效的配置，优先级较低。在下面的代码中可以看到，当前默认区域为public，而ens160网卡的区域为external。此时便是以网卡的区域名称为准。\n通俗来说，默认区域就是一种通用的政策。例如，食堂为所有人准备了一次性餐具，而环保主义者则会自己携带碗筷。如果您自带了碗筷，就可以用自己的；反之就用食堂统一提供的。\n[root@linuxprobe ~]# firewall-cmd --set-default-zone=public Warning: ZONE_ALREADY_SET: public success [root@linuxprobe ~]# firewall-cmd --get-default-zone  public [root@linuxprobe ~]# firewall-cmd --get-zone-of-interface=ens160 external 5．启动和关闭firewalld防火墙服务的应急状况模式。\n如果想在1s的时间内阻断一切网络连接，有什么好办法呢？大家下意识地会说：“拔掉网线！”这是一个物理级别的高招。但是，如果人在北京，服务器在异地呢？panic紧急模式在这个时候就派上用场了。使用\u0026ndash;panic-on参数会立即切断一切网络连接，而使用\u0026ndash;panic-off则会恢复网络连接。切记，紧急模式会切断一切网络连接，因此在远程管理服务器时，在按下回车键前一定要三思。\n[root@linuxprobe ~]# firewall-cmd --panic-on success [root@linuxprobe ~]# firewall-cmd --panic-off success 6．查询SSH和HTTPS协议的流量是否允许放行。\n在工作中可以不使用\u0026ndash;zone参数指定区域名称，firewall-cmd命令会自动依据默认区域进行查询，从而减少用户输入量。但是，如果默认区域与网卡所绑定的不一致时，就会发生冲突，因此规范写法的zone参数是一定要加的。\n[root@linuxprobe ~]# firewall-cmd --zone=public --query-service=ssh yes [root@linuxprobe ~]# firewall-cmd --zone=public --query-service=https no 7．把HTTPS协议的流量设置为永久允许放行，并立即生效。\n默认情况下进行的修改都属于Runtime模式，即当前生效而重启后失效，因此在工作和考试中尽量避免使用。而在使用\u0026ndash;permanent参数时，则是当前不会立即看到效果，而在重启或重新加载后方可生效。于是，在添加了允许放行HTTPS流量的策略后，查询当前模式策略，发现依然是不允许放行HTTPS协议的流量：\n[root@linuxprobe ~]# firewall-cmd --permanent --zone=public --add-service=https success [root@linuxprobe ~]# firewall-cmd --zone=public --query-service=https no 不想重启服务器的话，就用\u0026ndash;reload参数吧：\n[root@linuxprobe ~]# firewall-cmd --reload success [root@linuxprobe ~]# firewall-cmd --zone=public --query-service=https yes 8．把HTTP协议的流量设置为永久拒绝，并立即生效。\n由于在默认情况下HTTP协议的流量就没有被允许，所以会有“Warning: NOT_ENABLED: http”这样的提示信息，因此对实际操作没有影响。\n[root@linuxprobe ~]# firewall-cmd --permanent --zone=public --remove-service=http Warning: NOT_ENABLED: http success [root@linuxprobe ~]# firewall-cmd --reload  success 9．把访问8080和8081端口的流量策略设置为允许，但仅限当前生效。\n[root@linuxprobe ~]# firewall-cmd --zone=public --add-port=8080-8081/tcp success [root@linuxprobe ~]# firewall-cmd --zone=public --list-ports 8080-8081/tcp 10．把原本访问本机888端口的流量转发到22端口，要且求当前和长期均有效。\nSSH远程控制协议是基于TCP/22端口传输控制指令的，如果想让用户通过其他端口号也能访问ssh服务，就可以试试端口转发技术了。通过这项技术，新的端口号在收到用户请求后会自动转发到原本服务的端口上，使得用户能够通过新的端口访问到原本的服务。\n来举个例子帮助大家理解。假设小强是电子厂的工人，他喜欢上了三号流水线上的工人小花，但不好意思表白，于是写了一封情书并交给门卫张大爷，希望由张大爷转交给小花。这样一来，情书（信息）的传输由从小强到小花，变成了小强到张大爷再到小花，情书（信息）依然能顺利送达。\n使用firewall-cmd命令实现端口转发的格式有点长，这里为大家总结好了：\nfirewall-cmd --permanent --zone=\u0026lt;区域\u0026gt; --add-forward-port=port=\u0026lt;源端口号\u0026gt;:proto=\u0026lt;协议\u0026gt;:toport=\u0026lt;目标端口号\u0026gt;:toaddr=\u0026lt;目标IP地址\u0026gt; 上述命令中的目标IP地址一般是服务器本机的IP地址：\n[root@linuxprobe ~]# firewall-cmd --permanent --zone=public --add-forward-port=port=888:proto=tcp:toport=22:toaddr=192.168.10.10 success [root@linuxprobe ~]# firewall-cmd --reload success 在客户端使用ssh命令尝试访问192.168.10.10主机的888端口，访问成功：\n[root@client A ~]# ssh -p 888 192.168.10.10 The authenticity of host \u0026#39;[192.168.10.10]:888 ([192.168.10.10]:888)\u0026#39; can\u0026#39;t be established. ECDSA key fingerprint is b8:25:88:89:5c:05:b6:dd:ef:76:63:ff:1a:54:02:1a. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added \u0026#39;[192.168.10.10]:888\u0026#39; (ECDSA) to the list of known hosts. root@192.168.10.10\u0026#39;s password:此处输入远程root管理员的密码 Last login: Sun Jul 19 21:43:48 2021 from 192.168.10.10 11．富规则的设置。\n富规则也叫复规则，表示更细致、更详细的防火墙策略配置，它可以针对系统服务、端口号、源地址和目标地址等诸多信息进行更有针对性的策略配置。它的优先级在所有的防火墙策略中也是最高的。比如，我们可以在firewalld服务中配置一条富规则，使其拒绝192.168.10.0/24网段的所有用户访问本机的ssh服务（22端口）：\n[root@linuxprobe ~]# firewall-cmd --permanent --zone=public --add-rich-rule=\u0026#34;rule family=\u0026#34;ipv4\u0026#34; source address=\u0026#34;192.168.10.0/24\u0026#34; service name=\u0026#34;ssh\u0026#34; reject\u0026#34; success [root@linuxprobe ~]# firewall-cmd --reload success 在客户端使用ssh命令尝试访问192.168.10.10主机的ssh服务（22端口）：\n[root@client A ~]# ssh 192.168.10.10 Connecting to 192.168.10.10:22... Could not connect to \u0026#39;192.168.10.10\u0026#39; (port 22): Connection failed. 图形管理工具 在各种版本的Linux系统中，几乎没有能让刘遄老师欣慰并推荐的图形化工具，但是firewall-config做到了。它是firewalld防火墙配置管理工具的GUI（图形用户界面）版本，几乎可以实现所有以命令行来执行的操作。毫不夸张地说，即使读者没有扎实的Linux命令基础，也完全可以通过它来妥善配置RHEL 8中的防火墙策略。\n成功安装firewall-config后，其工具的界面如图所示：\n其功能具体如下。\n1：选择运行时（Runtime）或永久（Permanent）模式的配置。\n2：可选的策略集合区域列表。\n3：常用的系统服务列表。\n4：主机地址的黑白名单。\n5：当前正在使用的区域。\n6：管理当前被选中区域中的服务。\n7：管理当前被选中区域中的端口。\n8：设置允许被访问的协议。\n9：设置允许被访问的端口。\n10：开启或关闭SNAT（源网络地址转换）技术。\n11：设置端口转发策略。\n12：控制请求icmp服务的流量。\n13：管理防火墙的富规则。\n14：被选中区域的服务，若勾选了相应服务前面的复选框，则表示允许与之相关的流量。\n15：firewall-config工具的运行状态。\n除了图中列出的功能，还有用于将网卡与区域绑定的Interfaces选项，以及用于将IP地址与区域绑定的Sources选项。另外再啰唆一句。在使用firewall-config工具配置完防火墙策略之后，无须进行二次确认，因为只要有修改内容，它就自动进行保存。\n下面进行动手实践环节。\n先将当前区域中请求http服务的流量设置为允许放行，但仅限当前生效。具体配置如图所示：\n尝试添加一条防火墙策略规则，使其放行访问8080～8088端口（TCP协议）的流量，并将其设置为永久生效，以达到系统重启后防火墙策略依然生效的目的。在按照下图所示的界面配置完毕之后，还需要在Options菜单中单击Reload Firewalld命令，让配置的防火墙策略立即生效。这与在命令行中使用\u0026ndash;reload参数的效果一样。\n放行访问8080～8088端口的流量：\n让配置的防火墙策略规则立即生效：\n前面在讲解firewall-config工具的功能时，曾经提到了SNAT（Source Network Address Translation，源网络地址转换）技术。SNAT是一种为了解决IP地址匮乏而设计的技术，它可以使得多个内网中的用户通过同一个外网IP接入Internet。该技术的应用非常广泛，甚至可以说我们每天都在使用，只不过没有察觉到罢了。比如，当通过家中的网关设备（无线路由器）访问本书配套站点www.linuxprobe.com时，就用到了SNAT技术。\n大家可以看一下在网络中不使用SNAT技术和使用SNAT技术时的情况。在没有使用SNAT技术的局域网中有多台PC，如果网关服务器没有应用SNAT技术，则互联网中的网站服务器在收到PC的请求数据包，并回送响应数据包时，将无法在网络中找到这个私有网络的IP地址，所以PC也就收不到响应数据包了。在使用SNAT技术处理过的局域网中，由于网关服务器应用了SNAT技术，所以互联网中的网站服务器会将响应数据包发给网关服务器，再由后者转发给局域网中的PC。\n没有使用SNAT技术的网络：\n使用SNAT技术处理过的网络：\n使用iptables命令实现SNAT技术是一件很麻烦的事情，但是在firewall-config中却是小菜一碟了。用户只需按照下图进行配置，并选中Masquerade zone复选框，就自动开启了SNAT技术。\n为了让大家直观查看不同工具在实现相同功能时的区别，针对前面使用firewall-cmd配置的防火墙策略规则，这里使用firewall-config工具进行了重新演示：将本机888端口的流量转发到22端口，且要求当前和长期均有效，具体如下图所示：\n配置本地的端口转发：\n让防火墙效策略规则立即生效：\n用命令配置富规则可真辛苦，幸好我们现在有了图形用户界面的工具。让192.168.10.20主机访问本机的1234端口号，如下图所示。其中Element选项能够根据服务名称、端口号、协议等信息进行匹配；Source与Destination选项后的inverted复选框代表反选功能，将其选中则代表对已填写信息进行反选，即选中填写信息以外的主机地址；Log复选框在选中后，日志不仅会被记录到日志文件中，而且还可以在设置日志的级别（Level）后，再将日志记录到日志文件中，以方便后续的筛查。\n如果生产环境中的服务器有多块网卡在同时提供服务（这种情况很常见），则对内网和对外网提供服务的网卡要选择的防火墙策略区域也是不一样的。也就是说，可以把网卡与防火墙策略区域进行绑定，这样就可以使用不同的防火墙区域策略，对源自不同网卡的流量进行有针对性的监控，效果会更好。\n把网卡与防火墙策略区域进行绑定：\n网卡与策略区域绑定完成：\n最后再提一句，firewall-config工具真的非常实用，很多原本复杂的长命令被图形化按钮替代，设置规则也简单明了，足以应对日常工作。所以再次向大家强调配置防火墙策略的原则—只要能实现所需的功能，用什么工具请随君便。\n服务的访问控制列表 TCP Wrapper是RHEL 6/7系统中默认启用的一款流量监控程序，它能够根据来访主机的地址与本机的目标服务程序做出允许或拒绝的操作。在RHEL 8版本中，它已经被firewalld正式替代。换句话说，Linux系统中其实有两个层面的防火墙，第一种是前面讲到的基于TCP/IP协议的流量过滤工具，而TCP Wrapper服务则是能允许或禁止Linux系统提供服务的防火墙，从而在更高层面保护了Linux系统的安全运行。\nTCP Wrapper服务的防火墙策略由两个控制列表文件所控制，用户可以编辑允许控制列表文件来放行对服务的请求流量，也可以编辑拒绝控制列表文件来阻止对服务的请求流量。控制列表文件修改后会立即生效，系统将会先检查允许控制列表文件（/etc/hosts.allow），如果匹配到相应的允许策略则放行流量；如果没有匹配，则会进一步匹配拒绝控制列表文件（/etc/hosts.deny），若找到匹配项则拒绝该流量。如果这两个文件都没有匹配到，则默认放行流量。\n由于RHEL 8版本已经不再支持TCP Wrapper服务程序，因此我们接下来选择在一台老版本的服务器上进行实验。TCP Wrapper服务的控制列表文件配置起来并不复杂，常用的参数如表所示。\n   客户端类型 示例 满足示例的客户端列表     单一主机 192.168.10.10 IP地址为192.168.10.10的主机   指定网段 192.168.10. IP段为192.168.10.0/24的主机   指定网段 192.168.10.0/255.255.255.0 IP段为192.168.10.0/24的主机   指定DNS后缀 .linuxprobe.com 所有DNS后缀为.linuxprobe.com的主机   指定主机名称 www.linuxprobe.com 主机名称为www.linuxprobe.com的主机   指定所有客户端 ALL 所有主机全部包括在内    在配置TCP Wrapper服务时需要遵循两个原则：\n 编写拒绝策略规则时，填写的是服务名称，而非协议名称； 建议先编写拒绝策略规则，再编写允许策略规则，以便直观地看到相应的效果。  下面编写拒绝策略规则文件，禁止访问本机sshd服务的所有流量（无须修改/etc/hosts.deny文件中原有的注释信息）：\n[root@linuxprobe ~]# vim /etc/hosts.deny # # hosts.deny This file contains access rules which are used to # deny connections to network services that either use # the tcp_wrappers library or that have been # started through a tcp_wrappers-enabled xinetd. # # The rules in this file can also be set up in # /etc/hosts.allow with a \u0026#39;deny\u0026#39; option instead. # # See \u0026#39;man 5 hosts_options\u0026#39; and \u0026#39;man 5 hosts_access\u0026#39; # for information on rule syntax. # See \u0026#39;man tcpd\u0026#39; for information on tcp_wrappers sshd:* [root@linuxprobe ~]# ssh 192.168.10.10 ssh_exchange_identification: read: Connection reset by peer 接下来，在允许策略规则文件中添加一条规则，使其放行源自192.168.10.0/24网段，且访问本机sshd服务的所有流量。可以看到，服务器立刻就放行了访问sshd服务的流量，效果非常直观：\n[root@linuxprobe ~]# vim /etc/hosts.allow # # hosts.allow This file contains access rules which are used to # allow or deny connections to network services that # either use the tcp_wrappers library or that have been # started through a tcp_wrappers-enabled xinetd. # # See \u0026#39;man 5 hosts_options\u0026#39; and \u0026#39;man 5 hosts_access\u0026#39; # for information on rule syntax. # See \u0026#39;man tcpd\u0026#39; for information on tcp_wrappers sshd:192.168.10. [root@linuxprobe ~]# ssh 192.168.10.10 The authenticity of host \u0026#39;192.168.10.10 (192.168.10.10)\u0026#39; can\u0026#39;t be established. ECDSA key fingerprint is 70:3b:5d:37:96:7b:2e:a5:28:0d:7e:dc:47:6a:fe:5c. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added \u0026#39;192.168.10.10\u0026#39; (ECDSA) to the list of known hosts. root@192.168.10.10\u0026#39;s password: Last login: Wed May 4 07:56:29 2021 [root@linuxprobe ~]#  Cockpit 驾驶舱管理工具 首先，Cockpit是一个英文单词，即“（飞机、船或赛车的）驾驶舱、驾驶座”，它用名字传达出了功能丰富的特性。其次，Cockpit是一个基于Web的图形化服务管理工具，对用户相当友好，即便是新手也可以轻松上手。而且它天然具备很好的跨平台性，因此被广泛应用于服务器、容器、虚拟机等多种管理场景。最后，红帽公司对Cockpit也十分看重，直接将它默认安装到了RHEL 8系统中，由此衍生的CentOS和Fedora也都标配有Cockpit。\nCockpit在默认情况下就已经被安装到系统中。下面执行dnf命令对此进行确认：\n[root@linuxprobe ~]# dnf install cockpit Updating Subscription Management repositories. Unable to read consumer identity This system is not registered to Red Hat Subscription Management. You can use subscription-manager to register. AppStream 3.1 MB/s | 3.2 kB 00:00 BaseOS 2.7 MB/s | 2.7 kB 00:00 Package cockpit-185-2.el8.x86_64 is already installed. Dependencies resolved. Nothing to do. Complete! 但是，Cockpit服务程序在RHEL 8版本中没有自动运行，下面将它开启并加入到开机启动项中：\n[root@linuxprobe ~]# systemctl start cockpit [root@linuxprobe ~]# systemctl enable cockpit.socket Created symlink /etc/systemd/system/sockets.target.wants/cockpit.socket → /usr/lib/systemd/system/cockpit.socket. 在Cockpit服务启动后，打开系统自带的浏览器，在地址栏中输入“本机地址:9090”即可访问。由于访问Cockpit的流量会使用HTTPS进行加密，而证书又是在本地签发的，因此还需要进行添加并信任本地证书的操作。\n添加额外允许的证书：\n确认信任本地证书：\n进入Cockpit的登录界面后，输入root管理员的账号与系统密码，单击Log In按钮后即可进入：\n进入Cockpit的Web界面，发现里面可谓“别有洞天”。Cockpit总共分为13个功能模块：系统状态（System）、日志信息（Logs）、硬盘存储（Storage）、网卡网络（Networking）、账户安全（Accounts）、服务程序（Services）、软件仓库（Applications）、报告分析（Diagnostic Reports）、内核排错（Kernel Dump）、SElinux、更新软件（Software Updates）、订阅服务（Subscriptions）、终端界面（Terminal）。下面逐一进行讲解。\n1．System\n进入Cockpit界面后默认显示的便是System（系统）界面，在该界面中能够看到系统架构、版本、主机名与时间等信息，还能够动态地展现出CPU、硬盘、内存和网络的复杂情况，这有点类似于Web版的“Winodws系统任务管理器”，属实好用。\n系统状态界面：\n2．Logs\n这个模块能够提供系统的全部日志，但是同学们可能会好奇，“为什么下图中的内容这么有限呢”？原因出在图中的两个选项中：时间和日志级别。通过这两个选项可以让用户更快地找到所需信息，而不是像/var/log/message文件那样一股脑儿地都抛给用户。\n日志信息界面：\n3．Storage\n这个功能模块是同学们最喜欢的一个模块，原因不是这个模块显示了硬盘的I/O读写负载情况，而是可以让用户通过该界面，用鼠标创建出RAID、LVM、VDO和iSCSI等存储设备。是的，您没有看错，RAID和LVM都可以用鼠标进行创建了，是不是很开心呢？\n硬盘存储界面：\n4．Networking\n既然名为Networking模块，那么动态看网卡的输出和接收值肯定是这个模块的标配功能了。我们不仅可以在这里进行网卡的绑定（Bonding）和聚合（Team），还可以创建桥接网卡及添加VLAN。最下方会单独列出与网卡相关的日志信息。\n网卡网络界面：\n**5．**Accounts\n大家千万别小看Accounts模块，虽然它的账户安全界面有些简陋，只有一个用于创建账户的按钮，但只要点击进入某个用户的管理界面中，马上会发现“别有洞天”——账户管理界面，这个界面中的功能非常丰富，我们在这里可以对用户进行重命名，设置用户的权限，还可以锁定、修改密码以及创建SSH密钥信息。\n账户安全界面：\n账户管理界面：\n6．Services\n在Services功能模块的界面中，可以查看系统中已有的服务列表和运行状态。单击某一服务，进入该服务的管理界面后，可以对具体的服务进行开启、关闭操作。在Services功能模块中设置了服务并将其加入到开机启动项后，在系统重启后也依然会为用户提供服务。\n服务程序界面：\n服务管理界面：\n7．Applications\n后期采用Cockpit或红帽订阅服务安装的软件都会显示在这个功能模块中。\n软件仓库界面：\n8．Diagnostic Report\nDiagnostic Report模块的功能是帮助用户收集及分析系统的信息，找到系统出现问题的原因。单击Create Report按钮后大约两分钟左右，会出现报告生成完毕的弹窗。好吧，摊牌了，这个功能其实很鸡肋，就是将sosreport命令做成了一个网页按钮。\n报告分析界面：\n报告生成完毕：\n9．Kernel Dump\nKernel Dump（Kdump）是一个在系统崩溃、死锁或死机时用来收集内核参数的一个服务。举例来说，如果有一天系统崩溃了，这时Kdump服务就会开始工作，将系统的运行状态和内核数据收集到一个名为dump core的文件中，以便后续让运维人员分析并找出问题所在。由于我们在安装系统时没有启动该服务，所以可以等到后续使用时再开启该功能界面。\n内核排错界面：\n10．SElinux\n下图所示为SELinux服务的控制按钮和警告信息界面。\nSElinux管理界面：\n11．Software Updates\n这里提到的Software Updates并不是我们用来更新其他常规软件的一个界面，而是用来对红帽客户订阅的服务进行更新的界面。用户只有在购买了红帽第三方服务后才能使用这里面的功能。在购买了红帽订阅服务后，用户便可以在这里下载到相应服务程序的最新版本和稳定版本。\n更新软件界面：\n12．Subscriptions\n这里依然是一则红帽公司的“小广告”—如果想成为尊贵的红帽服务用户，要付费购买订阅服务。个人用户无须购买，而且这对我们的后续实验没有任何影响。\n订阅服务界面：\n12．Terminal\n压轴的总是在最后。Cockpit服务提供了Shell终端的在线控制平台，可方便用户通过网页上的终端功能管理服务器。这个功能深受运维人员喜爱。\n终端管理界面\n至此，相信各位读者已经充分掌握了防火墙的管理能力。防火墙管理工具有很多种，我们任选其一即可。在配置后续的服务前，大家要记得检查网络和防火墙的状态，以避免出现服务明明配置正确，但无法从外部访问的情况，最终影响实验效果。\n在 Ubuntu 上使用 UFW\u0026amp;GUFW Ubuntu 20.04 随附了一个称为UFW（非复杂防火墙）的防火墙配置工具。 它是用于管理iptables防火墙规则的用户友好型前端。 它的主要目标是使防火墙的管理变得更容易，或者顾名思义，变得简单。而GUFW是UFW的图形介面。\n检查UFW状态 UFW默认情况下处于禁用状态。 您可以使用以下命令检查UFW服务的状态：\n$ sudo ufw status verbose 输出将显示防火墙状态为非活动：\nStatus: inactive 如果UFW已激活，则输出将类似于以下内容：\nStatus: active UFW默认策略 UFW防火墙的默认行为是阻止所有传入和转发流量，并允许所有出站流量。 这意味着除非您专门打开端口，否则任何尝试访问您的服务器的人都将无法连接。 服务器上运行的应用程序和服务将可以访问外界。\n默认策略在/etc/default/ufw文件中定义，可以通过手动修改文件或使用sudo ufw default \u0026lt;policy\u0026gt; \u0026lt;chain\u0026gt;命令来更改。\n防火墙策略是建立更复杂和用户定义的规则的基础。 通常，最初的UFW默认策略是一个很好的起点。\n应用配置文件 应用程序配置文件是INI格式的文本文件，描述了服务并包含该服务的防火墙规则。 在安装软件包期间，会在/etc/ufw/applications.d目录中创建应用程序配置文件。\n您可以通过键入以下内容列出服务器上所有可用的应用程序配置文件：\n$ sudo ufw app list Available applications: Nginx Full Nginx HTTP Nginx HTTPS OpenSSH 要查找有关特定配置文件和包含的规则的更多信息，请使用以下命令：\n$ sudo ufw app info \u0026#39;Nginx Full\u0026#39; Profile: Nginx Full Title: Web Server (Nginx, HTTP + HTTPS) Description: Small, but very powerful and efficient web server Ports: 80,443/tcp 输出显示“ Nginx Full”配置文件打开了端口80和443。\n您也可以为应用创建自定义配置文件。\n启用UFW 如果要从远程位置连接到Ubuntu，则在启用UFW防火墙之前，必须明确允许传入的SSH连接。 否则，您将无法连接到计算机。\n要将您的UFW防火墙配置为允许传入的SSH连接，请键入以下命令：\n$ sudo ufw allow ssh Rules updated Rules updated (v6) 如果SSH在非标准端口上运行，则需要打开该端口。\n例如，如果您的ssh守护程序侦听端口7722，请输入以下命令以允许该端口上的连接：\n$ sudo ufw allow 7722/tcp 现在已将防火墙配置为允许传入的SSH连接，您可以通过键入以下内容来启用它：\n$ sudo ufw enable Command may disrupt existing ssh connections. Proceed with operation (y|n)? y Firewall is active and enabled on system startup 将警告您启用防火墙可能会破坏现有的ssh连接，只需键入y并单击Enter。\n打开端口 根据系统上运行的应用程序，您可能还需要打开其他端口。 打开端口的一般语法如下：\n$ ufw allow port_number/protocol 以下是有关如何允许HTTP连接的几种方法。\n第一种选择是使用服务名称。 UFW检查/etc/services文件中指定服务的端口和协议：\n$ sudo ufw allow http 您还可以指定端口号和协议：\n$ sudo ufw allow 80/tcp 如果未给出协议，则UFW会同时为tcp和udp创建规则。\n另一个选择是使用应用程序配置文件； 在这种情况下，“ Nginx HTTP”：\n$ sudo ufw allow \u0026#39;Nginx HTTP\u0026#39; UFW还支持使用proto关键字指定协议的另一种语法：\n$ sudo ufw allow proto tcp to any port 80 端口范围\nUFW还允许您打开端口范围。 起始端口和结束端口用冒号（:）分隔，并且您必须指定协议tcp或udp。\n例如，如果要同时在tcp和udp上允许端口从7100到7200，则可以运行以下命令：\n$ sudo ufw allow 7100:7200/tcp 特定的IP地址和端口\n要允许来自给定源IP的所有端口上的连接，请使用from关键字，后跟源地址。\n以下是将IP地址列入白名单的示例：\n$ sudo ufw allow from 64.63.62.61 如果要仅允许给定IP地址访问特定端口，请使用to any port关键字，后跟端口号。\n例如，要允许IP地址为64.63.62.61的计算机访问端口22，请输入：\n$ sudo ufw allow from 64.63.62.61 to any port 22 子网\n允许连接到IP地址子网的语法与使用单个IP地址时的语法相同。 唯一的区别是您需要指定子网掩码。\n下面是一个示例，显示了如何允许访问从192.168.0.1到192.168.0.254的IP地址到端口7890（clash）：\n$ sudo ufw allow from 192.168.0.0/24 to any port 7890 特定网络接口\n要允许在特定的网络接口上进行连接，请使用in on关键字，后跟网络接口(网卡)的名称：\n$ sudo ufw allow in on eth2 to any port 3306 拒绝连接 所有传入连接的默认策略均设置为deny，如果您未更改默认策略，除非您专门打开连接，否则UFW会阻止所有传入连接。\n撰写拒绝规则与撰写允许规则相同； 您只需要使用deny关键字而不是allow。\n假设您打开了端口80和443，并且服务器受到23.24.25.0/24网络的攻击。 要拒绝来自23.24.25.0/24的所有连接，您可以运行以下命令：\n$ sudo ufw deny from 23.24.25.0/24 以下是拒绝访问23.24.25.0/24中的端口80和443的示例，您可以使用以下命令：\n$ sudo ufw deny proto tcp from 23.24.25.0/24 to any port 80,443 删除UFW规则 有两种方法可以通过规则编号和指定实际规则来删除UFW规则。\n按规则号删除规则比较容易，尤其是当您不熟悉UFW时。 要首先通过规则编号删除规则，您需要找到要删除的规则的编号。 要获取编号规则的列表，请使用ufw status numbered命令：\n$ sudo ufw status numbered Status: active To Action From -- ------ ---- [ 1] 22/tcp ALLOW IN Anywhere [ 2] 80/tcp ALLOW IN Anywhere [ 3] 8080/tcp ALLOW IN Anywhere 要删除规则号3，该规则号允许连接到端口8080，请输入：\n$ sudo ufw delete 3 第二种方法是通过指定实际规则来删除规则。 例如，如果您添加了打开端口8069的规则，则可以使用以下命令将其删除：\n$ sudo ufw delete allow 8069 禁用UFW 如果出于任何原因要停止UFW并停用所有规则，则可以使用：\n$ sudo ufw disable 以后，如果您想重新启用UTF并激活所有规则，只需键入：\n$ sudo ufw enable 重设UFW 重置UFW将禁用UFW，并删除所有活动规则。 如果您想还原所有更改并重新开始，这将很有帮助。\n要重置UFW，请输入以下命令：\n$ sudo ufw reset IP伪装 IP伪装是Linux内核中NAT（网络地址转换）的一种变体，它通过重写源IP地址和目标IP地址和端口来转换网络流量。 借助IP伪装，您可以使用一台充当网关的Linux计算机，允许专用网络中的一台或多台计算机与Internet通信。\n使用UFW配置IP伪装涉及几个步骤。\n首先，您需要启用IP转发。 为此，请打开/etc/ufw/sysctl.conf文件，查找并取消注释以下行：net.ipv4.ip_forward = 1：\n$ sudo nano /etc/ufw/sysctl.conf net/ipv4/ip_forward=1 接下来，您需要配置UFW以允许转发数据包。 打开UFW配置文件，找到DEFAULT_FORWARD_POLICY键，然后将值从DROP更改为ACCEPT：\n$ sudo nano /etc/default/ufw DEFAULT_FORWARD_POLICY=\u0026#34;ACCEPT\u0026#34; 现在，您需要在nat表中设置POSTROUTING链的默认策略和伪装规则。 为此，请打开/etc/ufw/before.rules文件，附加以下几行：\n$ sudo nano /etc/ufw/before.rules #NAT table rules *nat :POSTROUTING ACCEPT [0:0] # Forward traffic through eth0 - Change to public network interface -A POSTROUTING -s 10.8.0.0/16 -o eth0 -j MASQUERADE # don\u0026#39;t delete the \u0026#39;COMMIT\u0026#39; line or these rules won\u0026#39;t be processed COMMIT 别忘了在-A POSTROUTING行中替换eth0以匹配公共网络接口的名称：\n完成后，保存并关闭文件。\n最后，通过禁用和重新启用UFW重新加载UFW规则：\n$ sudo ufw disable $ sudo ufw e Linux Kernel 来自 Wikipedia:\n 内核是计算机操作系统的核心组件，对系统有完全的控制。开机时最先启动，然后负责后续的启动工作。它负责处理其它软件的请求，将这些请求转化为中央处理器的数据处理请求。内核还负责管理内存，管理系统和其它打印机、扬声器等外围设备的通讯，是操作系统最基础的部分。\n 内核包安装在/boot/下的文件系统上。为了能够引导到内核，必须适当配置启动加载器。\nKernel module 内核模块是可以按需加载或卸载的内核代码，可以不重启系统就扩充内核的功能。\n要创建内核模块，请阅读此指南。模块可以设置成内置或者动态加载，要编译成可动态加载，需要在内核配置时将模块配置为 M (模块)。\n获取信息 模块保存在 /lib/modules/kernel_release (使用 uname -r 命令显示当前内核版本)。\n注意： 模块名通常使用 (_) 或 - 连接，但是这些符号在 modprobe 命令和 /etc/modprobe.d/ 配置文件中都是可以相互替换的。\n显示当前装入的内核模块：\n$ lsmod 在上面的输出中：\n Module 显示每个模块的名称 Size 显示每个模块的大小（并不是它们占的内存大小） Used by 显示每个模块被使用的次数和使用它们的模块  显然，这里有很多模块。加载的模块数量取决于你的系统和版本以及正在运行的内容。我们可以这样计数：\n$ lsmod | wc -l 67 modules.builtin 文件中列出了所有构建在内核中的模块\n$ more /lib/modules/$(uname -r)/modules.builtin | head -10 kernel/arch/x86/crypto/crc32c-intel.ko kernel/arch/x86/events/intel/intel-uncore.ko kernel/arch/x86/platform/intel/iosf_mbi.ko kernel/mm/zpool.ko kernel/mm/zbud.ko kernel/mm/zsmalloc.ko kernel/fs/binfmt_script.ko kernel/fs/mbcache.ko kernel/fs/configfs/configfs.ko kernel/fs/crypto/fscrypto.ko 显示模块信息：\n$ modinfo module_name 显示所有模块的配置信息：\n$ modprobe -c | less 显示某个模块的配置信息：\n$ modprobe -c | grep module_name 显示一个装入模块使用的选项：\n$ systool -v -m module_name 显示模块的依赖关系：\n$ modprobe --show-depends module_name 使用systemd自动加载模块 目前，所有必要模块的加载均由 udev 自动完成。所以，如果不需要使用任何额外的模块，就没有必要在任何配置文件中添加启动时加载的模块。但是，有些情况下可能需要在系统启动时加载某个额外的模块，或者将某个模块列入黑名单以便使系统正常运行。\n内核模块可以在/etc/modules-load.d/ 下的文件中明确列出，以便systemd在引导过程中加载它们。 每个配置文件都以 /etc/modules-load.d/\u0026lt;program\u0026gt;.conf的样式命名。 配置文件仅包含要加载的内核模块名称列表，以换行符分隔。 空行和第一个非空白字符为#或;的行被忽略。\n$ cat /etc/modules-load.d/virtio-net.conf # Load virtio_net.ko at boot virtio_net 另见modules-load.d(5)。\n手动加载卸载 控制内核模块载入/移除的命令是kmod 软件包提供的, 要手动装入模块的话，执行:\n# modprobe module_name 按文件名加载模块:\n# insmod filename [args] 注意： 如果升级了内核但是没有重启，路径 /usr/lib/modules/$(uname -r)/ 已经不存在。modprobe 会返回错误 1，没有额外的错误信息。如果出现 modprobe 加载失败，请检查模块路径以确认是否是这个问题导致。\n如果要移除一个模块：\n# modprobe -r module_name 或者:\n# rmmod module_name 配置模块参数 手动加载时设置 传递参数的基本方式是使用 modprobe 选项，格式是 key=value：\n# modprobe module_name parameter_name=parameter_value 使用 /etc/modprobe.d/中的文件 要通过配置文件传递参数，在 /etc/modprobe.d/ 中放入任意名称 .conf 文件，加入:\n$ sudo gedit /etc/modprobe.d/myfilename.conf options modname parametername=parametercontents 例如\n$ sudo gedit /etc/modprobe.d/thinkfan.conf # On thinkpads, this lets the thinkfan daemon control fan speed options thinkpad_acpi fan_control=1 注意： 如果要在启动时就修改内核参数(从 init ramdisk 开始)，需要将相应的.conf-文件加入 mkinitcpio.conf 的 FILES 参数中。\n使用内核命令行 如果模块直接编译进内核，也可以通过启动管理器(GRUB, LILO 或 Syslinux)的内核行加入参数：\nmodname.parametername=parametercontents 例如:\nthinkpad_acpi.fan_control=1 别名 $ cat /etc/modprobe.d/myalias.conf # Lets you use \u0026#39;mymod\u0026#39; in MODULES, instead of \u0026#39;really_long_module_name\u0026#39; alias mymod really_long_module_name 有些模块具有别名，以方便其它程序自动装入模块。禁用这些别名可以阻止自动装入，但是仍然可以手动装入。\n$ cat /etc/modprobe.d/modprobe.conf # Prevent autoload of bluetooth alias net-pf-31 off # Prevent autoload of ipv6 alias net-pf-10 off 黑名单 禁用内核模块 对内核模块来说，黑名单是指禁止某个模块装入的机制。当对应的硬件不存在或者装入某个模块会导致问题时很有用。\n有些模块作为 initramfs 的一部分装入。\nmkinitcpio -M 会显示所有自动检测到到模块：要阻止 initramfs 装入某些模块，可以在 /etc/modprobe.d中将它们加入黑名单。并应在映像生成过程中通过modconf挂钩将其添加。\n运行 mkinitcpio -v 会显示各种钩子(例如 filesystem 钩子, SCSI 钩子等)装入的模块。如果您的HOOKS 数组中没有 modconf 钩子（例如，和默认配置不同）则请将该\u0026rdquo;.conf\u0026quot;文件添加到/etc/mkinitcpio.conf中的FILES数组中。一旦您将其列入黑名单，请重新生成 initramfs，然后重新启动。\n使用 /etc/modprobe.d/ 中的文件 在 /etc/modprobe.d/ 中创建 .conf 文件，使用 blacklist 关键字屏蔽不需要的模块，例如如果不想装入 pcspkr 模块：\n$ sudo gedit /etc/modprobe.d/nobeep.conf # Do not load the pcspkr module on boot blacklist pcspkr 注意： blacklist 命令将屏蔽一个模板，所以不会自动装入，但是如果其它非屏蔽模块需要这个模块，系统依然会装入它。\n要避免这个行为，可以让 modprobe 使用自定义的 install 命令，而不是像往常一样将模块插入内核，因此您可以通过以下方式强制模块始终无法加载：\n$ sudo gedit /etc/modprobe.d/blacklist.conf ... install MODULE /bin/true ... 这样就可以 \u0026ldquo;屏蔽\u0026rdquo; 模块及所有依赖它的模块。\n使用内核命令行 提示： 如果模块损坏导致无法引导系统，这将非常有用。\n您也可以从引导加载程序中将模块列入黑名单。\n如Kernel参数.中所述，只需将module_blacklist=modname1,modname2,modname3 添加到引导加载程序的内核行中即可。\n注意： 将多个模块列入黑名单时，请注意，它们之间仅用逗号分隔。 空格或其他内容可能会破坏语法。\nKernel parameters 一共有三种办法，可以给内核传递参数，用于控制其行为方式：\n 在编译内核时（这个最根本，会决定后面两种方法） 内核启动时(通常是在一个启动管理器里设置). 在运行时 (通过修改在 /proc 和 /sys中的文件).  本页面主要是讲第二种方法。内核参数可以在启动时临时修改，也可以永久性写到启动管理器的配置文件中，永远起作用。下面示例把参数quiet 和 splash 加到启动管理器。\nsystemd-boot   当启动菜单出现时 按 e进入编辑界面:\ninitrd=\\initramfs-linux.img root=/dev/sda2 quiet splash   如果想永久加入参数，编辑 /boot/loader/entries/arch.conf (假设你已经设置好了 EFI system partition) 的options 行:\n  注意：\n 如果没有设置显示启动菜单, 你需要按住Space启动电脑来进入启动菜单 。 如果不能够从启动菜单上进行编辑，修改 /boot/loader/loader.conf 加入 editor 1 来开启编辑功能。  更多信息请参见 systemd-boot .\nGRUB   在菜单出现后按 e 然后将它们添加至 linux 行：\nlinux /boot/vmlinuz-linux root=UUID=978e3e81-8048-4ae1-8a06-aa727458e8ff ro quiet splash 按 b 以便用这些参数启动。\n  要使改变在重启后仍生效，您可以手动编辑 /boot/grub/grub.cfg 中的如上内容。对于初学者，建议编辑 /etc/default/grub 并将您的内核选项添加至 GRUB_CMDLINE_LINUX_DEFAULT 行：\nGRUB_CMDLINE_LINUX_DEFAULT=\u0026quot;quiet splash\u0026quot; 然后重新生成 grub.cfg 文件：\n# grub-mkconfig -o /boot/grub/grub.cfg   有关配置GRUB的更多信息，请参阅 GRUB 。\n发布时间表 内核发布时间表：有吗？ 短的回答是，每两到三个月就有一个新的内核版本发布。长的回答是，这不是一个硬性规定。\n这个意思是，你经常会看到每两到三个月就有一个新的内核版本发布。这是内核维护者团队的目标，但并没有规定新版本必须在前一个版本的 8 周后准时发布的期限。\n新的内核版本（通常）是由 Linus Torvalds 在它准备好的时候发布的。通常是每 2 到 3 个月发布一次。该版本被宣布为“稳定”，一般以 X.Y 的格式编号。\n但这并不是 X.Y 开发的结束。稳定版会有更多的小版本以进行错误的修复。这些小版本在稳定版的内核上又增加了一个点，就像是 X.Y.Z。\n虽然 X.Y（通常）是由 Linux 创造者 Linus Torvalds 发布的，但是维护稳定的 X.Y 内核、合并错误修复和发布 X.Y.Z 版本的责任是由另外的内核开发者负责的。\n一个内核版本支持多长时间？ 和发布一样，一个内核版本支持多长时间也没有固定的日期和时间表。\n一个普通的稳定内核版本通常会被支持两个半月到三个月，这取决于下一个稳定内核版本的发布时间。\n例如，稳定版内核 5.14 会在稳定版内核 5.15 发布后的几周内达到生命末期。结束支持是由该稳定内核版本的维护者在 Linux 内核邮件列表中宣布的。用户和贡献者会被要求切换到新发布的稳定版本。\n但这只适用于正常的稳定内核版本，还有 LTS（长期支持）内核版本，它们的支持期要比 3 个月长得多。\nLTS 内核：它支持多长时间？ LTS 内核也没有固定的发布时间表。通常，每年都有一个 LTS 内核版本，一般是当年的最后一个版本，它至少会被支持两年。但同样，这里也没有固定的规则。\nLTS 内核的维护者可以同意某个 LTS 内核的维护时间超过通常的两年。这个协议是根据必要性和参与的人员来达成的。\n这种情况经常发生在 Android 项目中。由于两年的时间不足以让制造商结束对他们的硬件和软件功能的支持，你经常会发现一些 LTS 内核会被支持六年之久。\n你可以 在 Linux 内核网站上 找到这个信息。\n你的发行版可能没有跟随通常的 Linux 内核版本 如果你检查你的 Linux 内核版本，你可能会发现 你的发行版使用了一个旧的内核。也有可能该发行版提供的内核已经在内核网站上被标记为到达了生命末期。\n不要惊慌。你的发行版会负责修补内核的错误和漏洞。除非你真的在使用一个不知名的 Linux 发行版，否则你可以相信你的发行版会保持它的安全和健全。\n如果你有足够的理由，比如为了支持更新的硬件，你可以自由地在你使用的任何发行版或 Ubuntu 中安装最新的 Linux 内核 。\n如果你想了解更多细节，我已经 在这里解释了为什么你的发行版使用过时的 Linux 内核。\n安装内核 dpkg\n从 kernel.ubuntu.com 网站手动下载可用的最新 Linux 内核：\n linux-image-X.Y.Z-generic-.deb linux-modules-X.Y.Z-generic-.deb  手动安装内核：\n$ sudo dpkg --install *.deb 重启系统，使用新内核：\n$ sudo reboot 检查是否如你所愿：\n$ uname -r apt-get\n不同于上一个方法，这种方法会从 Ubuntu 官方仓库下载、安装内核版本：\n运行：\n$ sudo apt-get upgrade linux-image-generic XanMod Kernel 最新内核集成的一些新特性的确是可以提升性能的。xanmod 内核的安装可以去它们的官方网站来查询，xanmod 内核的特性很多地方都有，官方也写的有很多，不过大多数还是以下几点：\n 改善了 CPU 调度能力 改善了 I/O 的调度能力 增加了一些和性能有关的第三方补丁 使用了最新的 GCC 进行编译 使用了最新的 MicroCode  安装的方式也比较简单，添加源并且更新安装就行了：\n$ echo \u0026#39;deb http://deb.xanmod.org releases main\u0026#39; | sudo tee /etc/apt/sources.list.d/xanmod-kernel.list \u0026amp;\u0026amp; wget -qO - https://dl.xanmod.org/gpg.key | sudo apt-key add - 然后安装，我个人安装的是最新的 5.8.1 的 edge：\n$ sudo apt update \u0026amp;\u0026amp; sudo apt install linux-xanmod-edge 安装完毕后还可以安装最新的微码：\n$ sudo apt update \u0026amp;\u0026amp; sudo apt install linux-xanmod 重启以应用\n$ sudo reboot Zen/Liquorix Kernel  一些内核黑客合作的结果，是适合日常使用的优秀内核 以吞吐量和功耗为代价来换取性能 相对 linux 内核加入了 Fsync 功能。Fsync 是维尔福公司发布的一个可以帮助提升大量多线程应用运行帧率的特殊内核补丁，这对改善游戏性能有很大帮助。在一些采用 .Net 的 wine 游戏中会有 明显的性能提升 如果你使用英伟达显卡，记得更换驱动为相应的 dkms 版本。一般来说较新的显卡安装 nvidia-dkms 即可。DKMS，即 Dynamic Kernel Module System。可以使内核变更（如升级）后自动编译模块，适配新内核。  Questions about: I\u0026rsquo;m not a kernel expert, but my understanding is that there are different ways for the kernel to prioritize tasks to be processed by the CPU. Priority on a server or workstation is different from a gaming PC. The Zen (and Liquorix) kernel alters the way this is done to optimise for gaming and multimedia. From what I can tell, the difference between the Zen and Liquorix kernels is the scheduler used, but are otherwise the same. There\u0026rsquo;s more info here.\nUbuntu Prerequisites:\n$ sudo add-apt-repository ppa:damentz/liquorix \u0026amp;\u0026amp; sudo apt-get update The Liquorix kernel can be installed by way of meta-packages. This will guarantee that the latest kernel is installed on every upgrade.\n64-bit:\n$ sudo apt-get install linux-image-liquorix-amd64 linux-headers-liquorix-amd64 Mainline Kernel 切換内核 可以通过修改 /etc/default/grub 中的 GRUB_DEFAULT 值来改变默认启动项。\n查看 grub menu 目前的選項 ：\n$ grep -A100 submenu /boot/grub/grub.cfg |grep menuentry submenu \u0026#39;Advanced options for Ubuntu\u0026#39; $menuentry_id_option \u0026#39;gnulinux-advanced-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026#39; { menuentry \u0026#39;Ubuntu, with Linux 4.4.0-1062-aws\u0026#39; --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option \u0026#39;gnulinux-4.4.0-1062-aws-advanced-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026#39; { menuentry \u0026#39;Ubuntu, with Linux 4.4.0-1062-aws (recovery mode)\u0026#39; --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option \u0026#39;gnulinux-4.4.0-1062-aws-recovery-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026#39; { menuentry \u0026#39;Ubuntu, with Linux 4.4.0-1061-aws\u0026#39; --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option \u0026#39;gnulinux-4.4.0-1061-aws-advanced-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026#39; { menuentry \u0026#39;Ubuntu, with Linux 4.4.0-1061-aws (recovery mode)\u0026#39; --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option \u0026#39;gnulinux-4.4.0-1061-aws-recovery-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026#39; { 接下來修改 grub config 檔案：\n$ sudo nano /etc/default/grup 找到 GRUB_DEFAULT=0 ，將數字 0 改成想用來開機的 kernel，以這個例子來說：\n 0 = \u0026lsquo;Ubuntu, with Linux 4.4.0-1062-aws\u0026rsquo; = \u0026lsquo;gnulinux-4.4.0-1062-aws-advanced-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026rsquo; 1 = \u0026lsquo;Ubuntu, with Linux 4.4.0-1062-aws (recovery mode)\u0026rsquo; = \u0026lsquo;gnulinux-4.4.0-1062-aws-recovery-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026rsquo; 2 = \u0026lsquo;Ubuntu, with Linux 4.4.0-1061-aws\u0026rsquo; = \u0026lsquo;gnulinux-4.4.0-1061-aws-advanced-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026rsquo; 3 = \u0026lsquo;Ubuntu, with Linux 4.4.0-1061-aws (recovery mode)\u0026rsquo; = \u0026lsquo;gnulinux-4.4.0-1061-aws-recovery-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026rsquo;  GRUB 启动项序号从 0 开始计数，0 代表第一个启动项，也是上述选项的默认值，1 表示第二个启动项，以此类推。主菜单和子菜单项之间用 \u0026gt; 隔开。\n下面的例子启动的是主菜单项 \u0026lsquo;Advanced options for Arch Linux\u0026rsquo; 下子菜单的第三项：\n  使用数字编号：\nGRUB_DEFAULT=2 # or GRUB_DEFAULT=\u0026#34;1\u0026gt;2\u0026#34;   使用菜单标题：\nGRUB_DEFAULT=\u0026#34;Advanced options for Ubuntu\u0026gt;Ubuntu, with Linux 4.4.0-1061-aws\u0026#34;   还可以这样：\nGRUB_DEFAULT=\u0026#34;gnulinux-advanced-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026gt;gnulinux-4.4.0-1061-aws-advanced-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026#34;   更新 grup 設定：\n$ sudo update-grub $ sudo reboot   删除旧内核 随着时间的流逝，持续的内核更新会在系统中积聚大量的不再使用的内核，浪费你的磁盘空间。每个内核镜像和其相关联的模块/头文件会占用200-400MB的磁盘空间，因此由不再使用的内核而浪费的磁盘空间会快速地增加。\nGRUB管理器为每个旧内核都维护了一个GRUB入口，以备你想要使用它们。\n作为磁盘清理的一部分，如果你不再使用这些，你可以考虑清理掉这些镜像。\n在删除旧内核之前，记住最好留有2个最近的内核（最新的和上一个版本），以防主要的版本出错。\n在Ubuntu内核镜像包含了以下的包。\n linux-image-: 内核镜像 linux-image-extra-: 额外的内核模块 linux-headers-: 内核头文件  首先检查系统中安装的内核镜像。\n$ dpkg --list | grep linux-image $ dpkg --list | grep linux-headers 在列出的内核镜像中，你可以移除一个特定的版本。\n$ sudo apt-get purge linux-image-3.19.0-15 $ sudo apt-get purge linux-headers-3.19.0-15 上面的命令会删除内核镜像和它相关联的内核模块和头文件。\n注意如果你还没有升级内核那么删除旧内核会自动触发安装新内核。这样在删除旧内核之后，GRUB配置会自动升级来移除GRUB菜单中相关GRUB入口。\n如果你有很多没用的内核，你可以用shell表达式来一次性地删除多个内核。注意这个括号表达式只在bash或者兼容的shell中才有效。\n$ sudo apt-get purge linux-image-3.19.0-{18,20,21,25} $ sudo apt-get purge linux-headers-3.19.0-{18,20,21,25} 上面的命令会删除4个内核镜像：3.19.0-18、3.19.0-20、3.19.0-21 和 3.19.0-25。\n如果GRUB配置由于任何原因在删除旧内核后没有正确升级，你可以尝试手动用update-grub2命令来更新配置。\n$ sudo update-grub2 现在就重启来验证GRUB菜单是否已经正确清理了。\n编写第一个内核模块 容器 Namespace 概念 **namespace 是 Linux 内核用来隔离内核资源的方式。**通过 namespace 可以让一些进程只能看到与自己相关的一部分资源，而另外一些进程也只能看到与它们自己相关的资源，这两拨进程根本就感觉不到对方的存在。具体的实现方式是把一个或多个进程的相关资源指定在同一个 namespace 中。\nLinux namespaces 是对全局系统资源的一种封装隔离，使得处于不同 namespace 的进程拥有独立的全局系统资源，改变一个 namespace 中的系统资源只会影响当前 namespace 里的进程，对其他 namespace 中的进程没有影响。\n用途 实际上，Linux 内核实现 namespace 的一个主要目的就是实现轻量级虚拟化(容器)服务。在同一个 namespace 下的进程可以感知彼此的变化，而对外界的进程一无所知。这样就可以让容器中的进程产生错觉，认为自己置身于一个独立的系统中，从而达到隔离的目的。也就是说 linux 内核提供的 namespace 技术为 docker 等容器技术的出现和发展提供了基础条件。\n我们可以从 docker 实现者的角度考虑该如何实现一个资源隔离的容器。比如是不是可以通过 chroot 命令切换根目录的挂载点，从而隔离文件系统。为了在分布式的环境下进行通信和定位，容器必须要有独立的 IP、端口和路由等，这就需要对网络进行隔离。同时容器还需要一个独立的主机名以便在网络中标识自己。接下来还需要进程间的通信、用户权限等的隔离。最后，运行在容器中的应用需要有进程号(PID)，自然也需要与宿主机中的 PID 进行隔离。也就是说这六种隔离能力是实现一个容器的基础，让我们看看 linux 内核的 namespace 特性为我们提供了什么样的隔离能力：\n上表中的前六种 namespace 正是实现容器必须的隔离技术，至于新近提供的 Cgroup namespace 目前还没有被 docker 采用。相信在不久的将来各种容器也会添加对 Cgroup namespace 的支持。\n发展历史 Linux 在很早的版本中就实现了部分的 namespace，比如内核 2.4 就实现了 mount namespace。大多数的 namespace 支持是在内核 2.6 中完成的，比如 IPC、Network、PID、和 UTS。还有个别的 namespace 比较特殊，比如 User，从内核 2.6 就开始实现了，但在内核 3.8 中才宣布完成。同时，随着 Linux 自身的发展以及容器技术持续发展带来的需求，也会有新的 namespace 被支持，比如在内核 4.6 中就添加了 Cgroup namespace。\nLinux 提供了多个 API 用来操作 namespace，它们是 clone()、setns() 和 unshare() 函数，为了确定隔离的到底是哪项 namespace，在使用这些 API 时，通常需要指定一些调用参数：CLONE_NEWIPC、CLONE_NEWNET、CLONE_NEWNS、CLONE_NEWPID、CLONE_NEWUSER、CLONE_NEWUTS 和 CLONE_NEWCGROUP。如果要同时隔离多个 namespace，可以使用 | (按位或)组合这些参数。同时我们还可以通过 /proc 下面的一些文件来操作 namespace。\n查看进程所属的 namespace\n从版本号为 3.8 的内核开始，/proc/[pid]/ns 目录下会包含进程所属的 namespace 信息，使用下面的命令可以查看当前进程所属的 namespace 信息：\n$ ll /proc/$$/ns total 0 lrwxrwxrwx 1 kurome kurome 0 Mar 3 11:33 cgroup -\u0026gt; \u0026#39;cgroup:[4026531835]\u0026#39; lrwxrwxrwx 1 kurome kurome 0 Mar 3 11:33 ipc -\u0026gt; \u0026#39;ipc:[4026531839]\u0026#39; lrwxrwxrwx 1 kurome kurome 0 Mar 3 11:33 mnt -\u0026gt; \u0026#39;mnt:[4026531840]\u0026#39; lrwxrwxrwx 1 kurome kurome 0 Mar 3 11:33 net -\u0026gt; \u0026#39;net:[4026532008]\u0026#39; lrwxrwxrwx 1 kurome kurome 0 Mar 3 11:33 pid -\u0026gt; \u0026#39;pid:[4026531836]\u0026#39; lrwxrwxrwx 1 kurome kurome 0 Mar 3 11:33 pid_for_children -\u0026gt; \u0026#39;pid:[4026531836]\u0026#39; lrwxrwxrwx 1 kurome kurome 0 Mar 3 11:33 time -\u0026gt; \u0026#39;time:[4026531834]\u0026#39; lrwxrwxrwx 1 kurome kurome 0 Mar 3 11:33 time_for_children -\u0026gt; \u0026#39;time:[4026531834]\u0026#39; lrwxrwxrwx 1 kurome kurome 0 Mar 3 11:33 user -\u0026gt; \u0026#39;user:[4026531837]\u0026#39; lrwxrwxrwx 1 kurome kurome 0 Mar 3 11:33 uts -\u0026gt; \u0026#39;uts:[4026531838]\u0026#39; 首先，这些 namespace 文件都是链接文件。链接文件的内容的格式为 xxx:[inode number]。其中的 xxx 为 namespace 的类型，inode number 则用来标识一个 namespace，我们也可以把它理解为 namespace 的 ID。如果两个进程的某个 namespace 文件指向同一个链接文件，说明其相关资源在同一个 namespace 中。\n其次，在 /proc/[pid]/ns 里放置这些链接文件的另外一个作用是，一旦这些链接文件被打开，只要打开的文件描述符(fd)存在，那么就算该 namespace 下的所有进程都已结束，这个 namespace 也会一直存在，后续的进程还可以再加入进来。\n除了打开文件的方式，我们还可以通过文件挂载的方式阻止 namespace 被删除。比如我们可以把当前进程中的 uts 挂载到 ~/uts 文件：\n$ touch ~/uts $ sudo mount --bind /proc/$$/ns/uts ~/uts 使用 stat 命令检查下结果：\n$ stat ~/uts 很神奇吧，~/uts 的 inode 和链接文件中的 inode number 是一样的，它们是同一个文件。\nclone() 函数 我们可以通过 clone() 在创建新进程的同时创建 namespace。clone() 在 C 语言库中的声明如下：\n/* Prototype for the glibc wrapper function */ #define _GNU_SOURCE #include \u0026lt;sched.h\u0026gt;int clone(int (*fn)(void *), void *child_stack, int flags, void *arg); 实际上，clone() 是在 C 语言库中定义的一个封装(wrapper)函数，它负责建立新进程的堆栈并且调用对编程者隐藏的 clone() 系统调用。Clone() 其实是 linux 系统调用 fork() 的一种更通用的实现方式，它可以通过 flags 来控制使用多少功能。一共有 20 多种 CLONE_ 开头的 falg(标志位) 参数用来控制 clone 进程的方方面面(比如是否与父进程共享虚拟内存等)，下面我们只介绍与 namespace 相关的 4 个参数：\n fn：指定一个由新进程执行的函数。当这个函数返回时，子进程终止。该函数返回一个整数，表示子进程的退出代码。 child_stack：传入子进程使用的栈空间，也就是把用户态堆栈指针赋给子进程的 esp 寄存器。调用进程(指调用 clone() 的进程)应该总是为子进程分配新的堆栈。 flags：表示使用哪些 CLONE_ 开头的标志位，与 namespace 相关的有CLONE_NEWIPC、CLONE_NEWNET、CLONE_NEWNS、CLONE_NEWPID、CLONE_NEWUSER、CLONE_NEWUTS 和 CLONE_NEWCGROUP。 arg：指向传递给 fn() 函数的参数。  setns() 函数 通过 setns() 函数可以将当前进程加入到已有的 namespace 中。setns() 在 C 语言库中的声明如下：\n#define _GNU_SOURCE #include \u0026lt;sched.h\u0026gt;int setns(int fd, int nstype); 和 clone() 函数一样，C 语言库中的 setns() 函数也是对 setns() 系统调用的封装：\n fd：表示要加入 namespace 的文件描述符。它是一个指向 /proc/[pid]/ns 目录中文件的文件描述符，可以通过直接打开该目录下的链接文件或者打开一个挂载了该目录下链接文件的文件得到。 nstype：参数 nstype 让调用者可以检查 fd 指向的 namespace 类型是否符合实际要求。若把该参数设置为 0 表示不检查。  前面我们提到：可以通过挂载的方式把 namespace 保留下来。保留 namespace 的目的是为以后把进程加入这个 namespace 做准备。在 docker 中，使用 docker exec 命令在已经运行着的容器中执行新的命令就需要用到 setns() 函数。为了把新加入的 namespace 利用起来，还需要引入 execve() 系列的函数，该函数可以执行用户的命令，比较常见的用法是调用 /bin/bash 并接受参数运行起一个 shell。\nunshare() 函数 通过 unshare 函数可以在原进程上进行 namespace 隔离。也就是创建并加入新的 namespace 。unshare() 在 C 语言库中的声明如下：\n#define _GNU_SOURCE #include \u0026lt;sched.h\u0026gt;int unshare(int flags); 和前面两个函数一样，C 语言库中的 unshare() 函数也是对 unshare() 系统调用的封装。调用 unshare() 的主要作用就是：不启动新的进程就可以起到资源隔离的效果，相当于跳出原先的 namespace 进行操作。\n系统还默认提供了一个叫 unshare 的命令，其实就是在调用 unshare() 系统调用。下面的 demo 使用 unshare 命令把当前进程的 user namespace 设置成了 root：\n$ whoami nick $ unshare --map-root-user --user sh -c whoami root cgroups 简介 说实话，一些未知的软件应用可能需要被控制或限制——至少是为了稳定性或者某种程度上的安全性。很多时候，一个bug或者仅仅只是烂代码就有可能破坏掉整个机器甚至可能削弱整个生态。幸运的是，有一种方式可以控制应用程序，Linux控制组（cgroups）是一个内核功能，用于限制、记录和隔离一个或多个进程对CPU、内存、磁盘I/O 以及网络的访问及使用。\n即，cgroups(Control Groups) 是 linux 内核提供的一种机制，这种机制可以根据需求把一系列系统任务及其子任务整合(或分隔)到按资源划分等级的不同组内，从而为系统资源管理提供一个统一的框架。简单说，cgroups 可以限制、记录任务组所使用的物理资源。本质上来说，cgroups 是内核附加在程序上的一系列钩子(hook)，通过程序运行时对资源的调度触发相应的钩子以达到资源追踪和限制的目的。\n控制组技术最初是由谷歌开发的，最终在2.6.24版本（2008年1月）中并入Linux内核主线。这项技术被部分重新设计，添加了kernfs（用于分割一些sysfs逻辑），这些改变被合并到3.15和3.16版本的内核中。\n实现 cgroups 的主要目的是为不同用户层面的资源管理提供一个统一化的接口。从单个任务的资源控制到操作系统层面的虚拟化（Linux 容器或者LXC），cgroups 提供了四大功能：\n 资源限制：一个控制组可以配置成不能超过指定的内存限制或是不能使用超过一定数量的处理器或限制使用特定的外围设备。 优先级：一个或者多个控制组可以配置成使用更少或者更多的CPU 时间片数量或者磁盘 IO 带宽，实际上就等同于控制了任务运行的优先级。 记录：一个控制组的资源使用情况会被监督以及测量。 控制：进程组可以被冻结，暂停或者重启。  概念 Task(任务) 在 linux 系统中，内核本身的调度和管理并不对进程和线程进行区分，只是根据 clone 时传入的参数的不同来从概念上区分进程和线程。这里使用 task 来表示系统的一个进程或线程。\nCgroup(控制组) cgroups 中的资源控制以 cgroup 为单位实现。Cgroup 表示按某种资源控制标准划分而成的任务组，包含一个或多个子系统。一个任务可以加入某个 cgroup，也可以从某个 cgroup 迁移到另一个 cgroup。\nSubsystem(子系统) cgroups 中的子系统就是一个资源调度控制器(又叫 controllers)。比如 CPU 子系统可以控制 CPU 的时间分配，内存子系统可以限制内存的使用量。内核版本 4.10.0，支持的 subsystem 如下( cat /proc/cgroups)：\n blkio 对块设备的 IO 进行限制。 cpu 限制 CPU 时间片的分配，与 cpuacct 挂载在同一目录。 cpuacct 生成 cgroup 中的任务占用 CPU 资源的报告，与 cpu 挂载在同一目录。 cpuset 给 cgroup 中的任务分配独立的 CPU(多处理器系统) 和内存节点。 devices 允许或禁止 cgroup 中的任务访问设备。 freezer 暂停/恢复 cgroup 中的任务。 hugetlb 限制使用的内存页数量。 memory 对 cgroup 中的任务的可用内存进行限制，并自动生成资源占用报告。 net_cls 使用等级识别符（classid）标记网络数据包，这让 Linux 流量控制器（tc 指令）可以识别来自特定 cgroup 任务的数据包，并进行网络限制。 net_prio 允许基于 cgroup 设置网络流量(netowork traffic)的优先级。 perf_event 允许使用 perf 工具来监控 cgroup。 pids 限制任务的数量。  Hierarchy(层级) 层级有一系列 cgroup 以一个树状结构排列而成，每个层级通过绑定对应的子系统进行资源控制。层级中的 cgroup 节点可以包含零个或多个子节点，子节点继承父节点挂载的子系统。一个操作系统中可以有多个层级。\n接口 （以下为 Ubuntu 20.04，内核 5.13.0-30-generic）\ncgroups 以文件的方式提供应用接口，我们可以通过 mount 命令来查看 cgroups 默认的挂载点：\n$ mount | grep cgroup tmpfs on /sys/fs/cgroup type tmpfs (ro,nosuid,nodev,noexec,mode=755,inode64) cgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,name=systemd) ... cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset) 第一行的 tmpfs 说明 /sys/fs/cgroup 目录下的文件都是存在于内存中的临时文件。\n第二行的挂载点 /sys/fs/cgroup/systemd 用于 systemd 系统对 cgroups 的支持。\n其余的挂载点则是内核支持的各个子系统的根级层级结构。\n需要注意的是，在使用 systemd 系统的操作系统中，/sys/fs/cgroup 目录都是由 systemd 在系统启动的过程中挂载的，并且挂载为只读的类型。换句话说，系统是不建议我们在 /sys/fs/cgroup 目录下创建新的目录并挂载其它子系统的。这一点与之前的操作系统不太一样。\n下面让我们来探索一下 /sys/fs/cgroup 目录及其子目录下都是些什么：\n$ ls /sys/fs/cgroup blkio cpu,cpuacct freezer misc net_prio rdma cpu cpuset hugetlb net_cls perf_event systemd cpuacct devices memory net_cls,net_prio pids unified /sys/fs/cgroup 目录下是各个子系统的根目录。我们以 memory 子系统为例，看看 memory 目录下都有什么？\n$ ls /sys/fs/cgroup/memory cgroup.clone_children memory.memsw.limit_in_bytes cgroup.event_control memory.memsw.max_usage_in_bytes cgroup.procs memory.memsw.usage_in_bytes cgroup.sane_behavior memory.move_charge_at_immigrate memory.failcnt memory.numa_stat memory.force_empty memory.oom_control memory.kmem.failcnt memory.pressure_level memory.kmem.limit_in_bytes memory.soft_limit_in_bytes memory.kmem.max_usage_in_bytes memory.stat memory.kmem.slabinfo memory.swappiness memory.kmem.tcp.failcnt memory.usage_in_bytes memory.kmem.tcp.limit_in_bytes memory.use_hierarchy memory.kmem.tcp.max_usage_in_bytes notify_on_release memory.kmem.tcp.usage_in_bytes release_agent memory.kmem.usage_in_bytes system.slice memory.limit_in_bytes tasks memory.max_usage_in_bytes user.slice memory.memsw.failcnt 这些文件就是 cgroups 的 memory 子系统中的根级设置。比如 memory.limit_in_bytes 中的数字用来限制进程的最大可用内存，memory.swappiness 中保存着使用 swap 的权重等等。\n手动方法 你可以直接或者间接（通过LXC、libvirt或者Docker）访问及管理控制组，这里我首先介绍使用sysfs以及libgroups库。接下来的示例需要你预先安装一个必须的包。\n$ sudo apt-get install libcgroup1 cgroup-tools 我将使用一个简单的shell脚本文件test.sh作为示例应用程序，它将会在无限while循环中运行以下两个命令。\n$ cat test.sh !/bin/shwhile [ 1 ]; do echo \u0026#34;hello world\u0026#34; sleep 60 done 安装必要的包后，你可以直接通过sysfs的目录结构来配置你的控制组，例如，要在内存子系统中创建一个叫做foo的控制组，只需要在/sys/fs/cgroup/memory底下新建一个叫做foo的目录：\n$ sudo mkdir /sys/fs/cgroup/memory/foo 在我们使用 cgroups 时，最好不要直接在各个子系统的根目录下直接修改其配置文件。推荐的方式是为不同的需求在子系统树中定义不同的节点。\ncgroups 的文件系统会在创建文件目录的时候自动创建配置文件：\n$ ls /sys/fs/cgroup/memory/foo cgroup.clone_children memory.memsw.failcnt cgroup.event_control memory.memsw.limit_in_bytes cgroup.procs memory.memsw.max_usage_in_bytes memory.failcnt memory.memsw.usage_in_bytes memory.force_empty memory.move_charge_at_immigrate memory.kmem.failcnt memory.numa_stat memory.kmem.limit_in_bytes memory.oom_control memory.kmem.max_usage_in_bytes memory.pressure_level memory.kmem.slabinfo memory.soft_limit_in_bytes memory.kmem.tcp.failcnt memory.stat memory.kmem.tcp.limit_in_bytes memory.swappiness memory.kmem.tcp.max_usage_in_bytes memory.usage_in_bytes memory.kmem.tcp.usage_in_bytes memory.use_hierarchy memory.kmem.usage_in_bytes notify_on_release memory.limit_in_bytes tasks memory.max_usage_in_bytes 默认情况下，每个新建的控制组将会继承对系统整个内存池的访问权限。但对于某些应用程序，这些程序拒绝释放已分配的内存并继续分配更多内存，这种默认继承方式显然不是个好主意。要使程序的内存限制变得更为合理，你需要更新文件memory.limit_in_bytes。\n限制控制组foo下运行的任何应用的内存上限为50MB：\n$ echo 50000000 | sudo tee /sys/fs/cgroup/memory/foo/memory.limit_in_bytes 验证设置：\n$ sudo cat memory.limit_in_bytes 49999872 请注意，回读的值始终是内核页面大小的倍数（即4096字节或4KB）。这个值是内存的最小可分配大小。\n启动应用程序test.sh：\n$ sh ~/test.sh 使用进程ID（PID），将应用程序移动到内存控制器底下的控制组foo：\n$ echo 2152 | sudo tee /sys/fs/cgroup/memory/foo/cgroup.procs 使用相同的PID，列出正在运行的进程并验证它是否在正确的控制组下运行：\n$ ps -o cgroup 2152 CGROUP 5:devices:/user.slice,4:pids:/user.slice/user-1000.slice/user@1000.service,3:m... 或者通过 /proc/[pid]/cgroup 来查看指定进程属于哪些 cgroup：\n$ cat /proc/2152/cgroup 13:cpuset:/ 12:blkio:/ 11:misc:/ 10:rdma:/ 9:freezer:/ 8:cpu,cpuacct:/ 7:perf_event:/ 6:hugetlb:/ 5:devices:/user.slice 4:pids:/user.slice/user-1000.slice/user@1000.service 3:memory:/foo #here 2:net_cls,net_prio:/ 1:name=systemd:/user.slice/user-1000.slice/user@1000.service/gnome\\x2dsession\\x2dmanager.slice/gnome-session-manager@ubuntu.service 0::/user.slice/user-1000.slice/user@1000.service/gnome\\x2dsession\\x2dmanager.slice/gnome-session-manager@ubuntu.service 每一行包含用冒号隔开的三列，他们的含义分别是：\n cgroup 树的 ID， 和 /proc/cgroups 文件中的 ID 一一对应。 和 cgroup 树绑定的所有 subsystem，多个 subsystem 之间用逗号隔开。这里 name=systemd 表示没有和任何 subsystem 绑定，只是给他起了个名字叫 systemd。 进程在 cgroup 树中的路径，即进程所属的 cgroup，这个路径是相对于挂载点的相对路径。  你还可以通过读取文件来监控控制组正在使用的资源。在这种情况下，你可以查看你的进程（以及生成的子进程）被分配的内存大小。\n$ cat /sys/fs/cgroup/memory/foo/memory.usage_in_bytes 188416 当进程“迷路”时 现在让我们重新创建相同的场景，但这次我们将控制组foo的内存限制从50MB改为500 bytes：\n$ echo 500 | sudo tee /sys/fs/cgroup/memory/foo/memory.limit_in_bytes 注意：如果任务超出其定义的限制，内核将进行干预，并在某些情况下终止该任务。\n同样，当您重新读取值时，它将始终是内核页面大小的倍数。因此，虽然您将其设置为500字节，但它实际上被设置为4 KB：\n$ cat /sys/fs/cgroup/memory/foo/memory.limit_in_bytes 4096 启动应用程序test.sh，将其移动到控制组下并监视系统日志：\n$ sudo tail -f /var/log/messages ... 请注意，内核的Out-Of-Mempry Killer（也叫做oom-killer 内存不足杀手）在应用程序达到4KB限制时就会介入。它会杀死应用程序，应用程序将不再运行，你可以通过输入以下命令进行验证：\n$ ps -o cgroup 2152 使用libcgroup 之前描述的许多早期步骤都可以通过libcgroup包中提供的管理工具进行简化。例如，使用cgcreate二进制文件的单个命令即可创建sysfs条目和文件。\n输入以下命令即可在内存子系统下创建一个叫做foo的控制组：\n$ sudo cgcreate -g memory:foo 注意：libcgroup提供了一种管理控制组中任务的机制。\n使用与之前相同的方法，你就可以开始设置内存阈值：\n$ echo 50000000 | sudo tee /sys/fs/cgroup/memory/foo/memory.limit_in_bytes 验证新配置的设置：\n$ sudo cat memory.limit_in_bytes 50003968 使用cgexec二进制文件在控制组foo中运行应用程序：\n$ sudo cgexec -g memory:foo ~/test.sh 使用它的进程ID - PID来验证应用程序是否在控制组和子系统（内存）下运行：\n$ ps -o cgroup 2945 CGROUP 6:memory:/foo,1:name=systemd:/user.slice/user-0.slice/session-1.scope 如果您的应用程序不再运行，并且您想要清理并删除控制组，则可以使用二进制文件cgdelete来执行此操作。要从内存控制器下删除控制组foo，请输入：\n$ sudo cgdelete memory:foo 持久组 您也可以通过一个简单的配置文件和服务的启动来完成上述所有操作。您可以在/etc/cgconfig.conf文件中定义所有控制组名称和属性。以下为foo组添加了一些属性：\n$ cat /etc/cgconfig.conf group foo { cpu { cpu.shares = 100; } memory { memory.limit_in_bytes = 5000000; } } cpu.shares选项定义了该组的CPU优先级。默认情况下，所有组都继承1024 shares（CPU share指的是控制组中的任务被分配到的CPU的 time的优先级，即值越大，分配到的CPU time越多，这个值需大于等于2），即100%的CPU time（CPU time是CPU用于处理一个程序所花费的时间）。通过将cpu.shares的值降低到更保守的值（如100），这个组将会被限制只能使用大概10%的CPU time。\n就如之前讨论的，在控制组中运行的进程也可以被限制它能访问的CPUs（内核）的数量。将以下部分添加到同一个配置文件cgconfig.conf中组名底下。\ncpuset { cpuset.cpus=\u0026quot;0-5\u0026quot;; } 有了这个限制，这个控制组会将应用程序绑定到到0核到5核——也就是说，它只能访问系统上的前6个CPU核。\n接下来，您需要使用cgconfig服务加载此配置。首先，启用cgconfig以在系统启动时能够加载上述配置：\n$ sudo systemctl enable cgconfig Create symlink from /etc/systemd/system/sysinit.target.wants/cgconfig.service to /usr/lib/systemd/system/cgconfig.service. 现在，启动cgconfig服务并手动加载相同的配置文件（或者您可以跳过此步骤直接重启系统）：\n$ sudo systemctl start cgconfig 在控制组foo下启动该应用程序并将其绑定到您设置的内存和CPU限制：\n$ sudo cgexec -g memory,cpu,cpuset:foo ~/test.sh \u0026amp; 除了将应用程序启动到预定义的控制组之外，其余所有内容都将在系统重新启动后持续存在。但是，您可以通过定义依赖于cgconfig服务的启动初始脚本来启动该应用程序，自动执行该过程。\n总结 通常来说，限制一个机器上一个或者多个任务的权限是必要的。控制组提供了这项功能，通过使用它，您可以对一些特别重要或无法控制的应用程序实施严格的硬件和软件限制。如果一个应用程序没有设置上限阈值或限制它可以在系统上消耗的内存量，cgroups可以解决这个问题。如果另一个应用程序没有CPU上的限制，那么cgroups可以再一次解决您的问题。您可以通过cgroup完成这么多工作，只需花一点时间，您就可以使用你的操作系统环境恢复稳定性，安全性和健全性。\n使用 Systemd 当 Linux 的 init 系统发展到 systemd 之后，systemd 与 cgroups 发生了融合(或者说 systemd 提供了 cgroups 的使用和管理接口)。\nSystemd 依赖 cgroups\n要理解 systemd 与 cgroups 的关系，我们需要先区分 cgroups 的两个方面：层级结构(A)和资源控制(B)。首先 cgroups 是以层级结构组织并标识进程的一种方式，同时它也是在该层级结构上执行资源限制的一种方式。我们简单的把 cgroups 的层级结构称为 A，把 cgrpups 的资源控制能力称为 B。\n对于 systemd 来说，A 是必须的，如果没有 A，systemd 将不能很好的工作。而 B 则是可选的，如果你不需要对资源进行控制，那么在编译 Linux 内核时完全可以去掉 B 相关的编译选项。\nSystemd 默认挂载的 cgroups 系统\n在系统的开机阶段，systemd 会把支持的 controllers (subsystem 子系统)挂载到默认的 /sys/fs/cgroup/ 目录下面，除了 systemd 目录外，其它目录都是对应的 subsystem。\n/sys/fs/cgroup/systemd 目录是 systemd 维护的自己使用的非 subsystem 的 cgroups 层级结构。换句话说就是，并不允许其它的程序动这个目录下的内容。其实 /sys/fs/cgroup/systemd 目录对应的 cgroups 层级结构就是 systemd 用来使用 cgoups 中 feature A 的。\nCgroup 的默认层级\n过将 cgroup 层级系统与 systemd unit 树绑定，systemd 可以把资源管理的设置从进程级别移至应用程序级别。因此，我们可以使用 systemctl 指令，或者通过修改 systemd unit 的配置文件来管理 unit 相关的资源。\n默认情况下，systemd 会自动创建 slice、scope 和 service unit 的层级来为 cgroup 树提供统一的层级结构。\n系统中运行的所有进程，都是 systemd init 进程的子进程。在资源管控方面，systemd 提供了三种 unit 类型：\n service： 一个或一组进程，由 systemd 依据 unit 配置文件启动。service 对指定进程进行封装，这样进程可以作为一个整体被启动或终止。 scope：一组外部创建的进程。由进程通过 fork() 函数启动和终止、之后被 systemd 在运行时注册的进程，scope 会将其封装。例如：用户会话、 容器和虚拟机被认为是 scope。 slice： 一组按层级排列的 unit。slice 并不包含进程，但会组建一个层级，并将 scope 和 service 都放置其中。真正的进程包含在 scope 或 service 中。在这一被划分层级的树中，每一个 slice 单位的名字对应通向层级中一个位置的路径。  以通过 systemd-cgls 命令来查看 cgroups 的层级结构\nControl group /: -.slice ├─419 bpfilter_umh ├─user.slice │ ├─user-125.slice │ │ ├─session-c1.scope │ │ │ ├─1101 gdm-session-worker [pam/gdm-launch-environment] │ │ │ ├─1158 /usr/lib/gdm3/gdm-x-session dbus-run-session -- gnome-session -\u0026gt; │ │ │ ├─1160 /usr/lib/xorg/Xorg vt1 -displayfd 3 -auth /run/user/125/gdm/Xau\u0026gt; │ │ │ ├─1347 dbus-run-session -- gnome-session --autostart /usr/share/gdm/gr\u0026gt; │ │ │ ├─1348 dbus-daemon --nofork --print-address 4 --session │ │ │ ├─1349 /usr/libexec/gnome-session-binary --systemd --autostart /usr/sh\u0026gt; │ │ │ ├─1352 /usr/libexec/at-spi-bus-launcher │ │ │ ├─1357 /usr/bin/dbus-daemon --config-file=/usr/share/defaults/at-spi2/\u0026gt; │ │ │ ├─1378 /usr/bin/gnome-shell │ │ │ ├─1432 ibus-daemon --panel disable --xim │ │ │ ├─1435 /usr/libexec/ibus-dconf │ │ │ ├─1438 /usr/libexec/ibus-x11 --kill-daemon │ │ │ ├─1440 /usr/libexec/ibus-portal │ │ │ ├─1451 /usr/libexec/at-spi2-registryd --use-gnome-session service、scope 和 slice unit 被直接映射到 cgroup 树中的对象。当这些 unit 被激活时，它们会直接一一映射到由 unit 名建立的 cgroup 路径中。例如，cron.service 属于 system.slice，会直接映射到 cgroup system.slice/cron.service/ 中。 注意，所有的用户会话、虚拟机和容器进程会被自动放置在一个单独的 scope 单元中。\n默认情况下，系统会创建四种 slice：\n -.slice：根 slice system.slice：所有系统 service 的默认位置 user.slice：所有用户会话的默认位置 machine.slice：所有虚拟机和 Linux 容器的默认位置  创建临时的 cgroup\n对资源管理的设置可以是 transient(临时的)，也可以是 persistent (永久的)。我们先来介绍如何创建临时的 cgroup。\n需要使用 systemd-run 命令创建临时的 cgroup，它可以创建并启动临时的 service 或 scope unit，并在此 unit 中运行程序。systemd-run 命令默认创建 service 类型的 unit，比如我们创建名称为 toptest 的 service 运行 top 命令：\n$ sudo systemd-run --unit=toptest --slice=test top -b 然后查看一下 test.slice 的状态：\n$ sudo systemctl status test.slice 创建了一个 test.slice/toptest.service cgroup 层级关系。再看看 toptest.service 的状态：\n$ sudo systemctl status toptest.service top 命令被包装成一个 service 运行在后台了！\n接下来我们就可以通过 systemctl 命令来限制 toptest.service 的资源了。在限制前让我们先来看一看 top 进程的 cgroup 信息：\n$ cat /proc/2850/cgroup 比如我们限制 toptest.service 的 CPUShares 为 600，可用内存的上限为 550M：\n$ sudo systemctl set-property toptest.service CPUShares=600 MemoryLimit=500M 再次检查 top 进程的 cgroup 信息：\n$ cat /proc/2850/cgroup 在 CPU 和 memory 子系统中都出现了 toptest.service 的名字。同时去查看 /sys/fs/cgroup/memory/test.slice 和 /sys/fs/cgroup/cpu/test.slice 目录，这两个目录下都多出了一个 toptest.service 目录。我们设置的 CPUShares=600 MemoryLimit=500M 被分别写入了这些目录下的对应文件中。\n临时 cgroup 的特征是，所包含的进程一旦结束，临时 cgroup 就会被自动释放。比如我们 kill 掉 top 进程，然后再查看 /sys/fs/cgroup/memory/test.slice 和 /sys/fs/cgroup/cpu/test.slice 目录，刚才的 toptest.service 目录已经不见了。\n通过配置文件修改 cgroup\n所有被 systemd 监管的 persistent cgroup(持久的 cgroup)都在 /usr/lib/systemd/system/ 目录中有一个 unit 配置文件。比如我们常见的 service 类型 unit 的配置文件。我们可以通过设置 unit 配置文件来控制应用程序的资源，persistent cgroup 的特点是即便系统重启，相关配置也会被保留。需要注意的是，scope unit 不能以此方式创建。下面让我们为 cron.service 添加 CPU 和内存相关的一些限制，编辑 /lib/systemd/system/cron.service 文件：\n$ sudo vim /lib/systemd/system/cron.service [Service] CPUShares=600 MemoryLimit=500M EnviromentFile=-/etc/default/cron ExecStart=/usr/sbin/cron -f $EXTRA_OPTS IgnoreSIGPIPE=false KillMode=process 然后重新加载配置文件并重启 cron.service：\n$ sudo systemctl daemon-reload $ sudo systemctl restart cron.service 现在去查看 /sys/fs/cgroup/memory/system.slice/cron.service/memory.limit_in_bytes 和 /sys/fs/cgroup/cpu/system.slice/cron.service/cpu.shares 文件，是不是已经包含我们配置的内容了！\n通过 systemctl 命令修改 cgroup\n除了编辑 unit 的配置文件，还可以通过 systemctl set-property 命令来修改 cgroup，这种方式修该的配置也会在重启系统时保存下来。现在我们把 cron.service 的 CPUShares 改为 700：\n$ sudo systemctl set-property cron.service CPUShares=700 查看 /sys/fs/cgroup/cpu/system.slice/cron.service/cpu.shares 文件的内容应该是 700，重启系统后该文件的内容还是 700。\nSystemd-cgtop 命令\n类似于 top 命令，systemd-cgtop 命令显示 cgoups 的实时资源消耗情况。\n通过它我们就可以分析应用使用资源的情况。\nLXC LXC（Linux容器，Linux Container）相当于你运行了一个接近于裸机的虚拟机。这项技术始于2008年，LXC的大部分功能来自于Solaris容器（又叫做Solaries Zones）以及之前的FreeBSD jails技术。 LXC并不是创建一个成熟的虚拟机，而是创建了一个拥有自己进程程和网络空间的虚拟环境，使用命名空间来强制进程隔离并利用内核的控制组（cgroups）功能，该功能可以限制，计算和隔离一个或多个进程的CPU，内存，磁盘I / O和网络使用情况。 您可以将这种用户空间框架想像成是chroot的高级形式。\n chroot 是一个改变当前运行进程以及其子进程的根目录的操作。一个运行在这种环境的程序无法访问根目录外的文件和命令。\n 注意：LXC使用命名空间来强制进程隔离，同时利用内核的控制组来计算以及限制一个或多个进程的CPU，内存，磁盘I / O和网络使用。\n但容器究竟是什么？简短的答案是容器将软件应用程序与操作系统分离，为用户提供干净且最小的Linux环境，与此同时在一个或多个隔离的“容器”中运行其他所有内容。容器的目的是启动一组有限数量的应用程序或服务（通常称为微服务），并使它们在独立的沙盒环境中运行。\n这种隔离可防止在给定容器内运行的进程监视或影响在另一个容器中运行的进程。此外，这些集装箱化服务不会影响或干扰主机。能够将分散在多个物理服务器上的许多服务合并为一个的想法是数据中心选择采用该技术的众多原因之一。\n容器有以下几个特点：\n 安全性：容器里可以运行网络服务，这可以限制安全漏洞或违规行为造成的损害。那些成功利用那个容器的一个或多个应用的安全漏洞的入侵者将会被限制在只能在那个容器中做一些操作。 隔离性：容器允许在同一物理机器上部署一个或多个应用程序，即使这些应用程序必须在不同的域下运行，每个域都需要独占访问其各自的资源。例如，通过将每个容器关联的不同IP地址，在不同容器中运行的多个应用程序可以绑定到同一物理网络接口。 虚拟化和透明性：容器为系统提供虚拟化环境，这个环境可以隐藏或限制系统底层的物理设备或系统配置的可见性。容器背后的一般原则是避免更改运行应用程序的环境，但解决安全性或隔离问题除外。  使用LXC的工具 对于大多数现代Linux发行版，内核都启用了控制组，但您很可能仍需要安装LXC工具。\n对于Ubuntu或Debian，只需键入：\n$ sudo apt-get install lxc 现在，在开始使用这些工具之前，您需要配置您的环境。在此之前，您需要验证当前用户是否同时在/etc/subuid和/etc/subgid中定义了uid和gid：\n$ cat /etc/subuid petros:100000:65536 $ cat /etc/subgid petros:100000:65536 如果~/.config/lxc不存在，则创建该目录，并且把配置文件/etc/lxc/default.conf复制到~/.config/lxc/default.conf.，将以下两行添加到文件末尾：\nlxc.id_map = u 0 100000 65536 lxc.id_map = g 0 100000 65536 结果如下：\n$ cat ~/.config/lxc/default.conf lxc.network.type = veth lxc.network.link = lxcbr0 lxc.network.flags = up lxc.network.hwaddr = 00:16:3e:xx:xx:xx lxc.id_map = u 0 100000 65536 lxc.id_map = g 0 100000 65536 将以下命令添加到/etc/lxc/lxc-usernet文件末尾（把第一列换成你的username）：\npetros veth lxcbr0 10 最快使这些配置生效的方法是重启或者将用户登出再登入。\n重新登录后，请验证当前是否已加载veth网络驱动程序：\n$ lsmod | grep veth veth 16384 0 如果没有，请输入：\n$ sudo modprobe veth 现在您可以使用LXC工具集来下载，运行，管理Linux容器。\n接下来，下载容器镜像并将其命名为“example-container”。当您键入以下命令时，您将看到一长串许多Linux发行版和版本支持的容器：\n$ sudo lxc-create -t download -n example-container 将会有三个弹出框让您分别选择发行版名称（distribution），版本号（release）以及架构（architecture）。请选择以下三个选项：\nDistribution: ubuntu Release: xenial Architecture: amd64 选择后点击Enter，rootfs将在本地下载并配置。出于安全原因，每个容器不附带OpenSSH服务器或用户帐户。同时也不会提供默认的root密码。要更改root密码并登录，必须在容器目录路径中运行lxc-attach或chroot（在启动之后）。\n启动容器：\n$ sudo lxc-start -n example-container -d -d选项表示隐藏容器，它会在后台运行。如果您想要观察boot的过程，只需要将-d换成-F。那么它将在前台运行，登录框出现时结束。\n你可能会遇到如下错误：\n$ sudo lxc-start -n example-container -d lxc-start: tools/lxc_start.c: main: 366 The container failed to start. lxc-start: tools/lxc_start.c: main: 368 To get more details, run the container in foreground mode. lxc-start: tools/lxc_start.c: main: 370 Additional information can be obtained by setting the --logfile and --logpriority options. 如果你遇到了，您需要通过在前台运行lxc-start服务来调试它：\n$ sudo lxc-start -n example-container -F lxc-start: conf.c: instantiate_veth: 2685 failed to create veth pair (vethQ4NS0B and vethJMHON2): Operation not supported lxc-start: conf.c: lxc_create_network: 3029 failed to create netdev lxc-start: start.c: lxc_spawn: 1103 Failed to create the network. lxc-start: start.c: __lxc_start: 1358 Failed to spawn container \u0026#34;example-container\u0026#34;. lxc-start: tools/lxc_start.c: main: 366 The container failed to start. lxc-start: tools/lxc_start.c: main: 370 Additional information can be obtained by setting the --logfile and --logpriority options. 从以上示例，你可以看到模块veth没有被引入，在引入之后，将会解决这个问题。\n之后，打开第二个terminal窗口，验证容器的状态。\n$ sudo lxc-info -n example-container Name: example-container State: RUNNING PID: 1356 IP: 10.0.3.28 CPU use: 0.29 seconds BlkIO use: 16.80 MiB Memory use: 29.02 MiB KMem use: 0 bytes Link: vethPRK7YU TX bytes: 1.34 KiB RX bytes: 2.09 KiB Total bytes: 3.43 KiB 也可以通过另一种方式来查看所有安装的容器，运行命令：\n$ sudo lxc-ls -f NAME STATE AUTOSTART GROUPS IPV4 IPV6 example-container RUNNING 0 - 10.0.3.28 - 但是问题是你仍然不能登录进去，你只需要直接attach到正在运行的容器，创建你的用户，使用passwd命令改变相关的密码。\n$ sudo lxc-attach -n example-container root@example-container:/# root@example-container:/# useradd petros root@example-container:/# passwd petros Enter new UNIX password: Retype new UNIX password: passwd: password updated successfully 更改密码后，您将能够从控制台直接登录到容器，而无需使用lxc-attach命令：\n$ sudo lxc-console -n example-container 如果要通过网络连接到此运行容器，请安装OpenSSH服务器：\n# apt-get install openssh-server 抓取容器的本地IP地址：\n# ip addr show eth0|grep inet inet 10.0.3.25/24 brd 10.0.3.255 scope global eth0 inet6 fe80::216:3eff:fed8:53b4/64 scope link 然后在主机的新的控制台窗口中键入：\n$ ssh 10.0.3.25 瞧！您现在可以SSH到正在运行的容器并键入您的用户名和密码。\n在主机系统上，而不是在容器内，可以观察在启动容器后启动和运行的LXC进程：\n$ ps aux | grep lxc | grep -v grep ... 要停止容器，请键入（在主机）：\n$ sudo lxc-stop -n example-container 停止后，验证容器的状态：\n$ sudo lxc-ls -f NAME STATE AUTOSTART GROUPS IPV4 IPV6 example-container STOPPED 0 - - - $ sudo lxc-info -n example-container Name: example-container State: STOPPED 要彻底销毁容器 - 即从主机system—type清除它：\n$ sudo lxc-destroy -n example-container Destroyed container example-container 销毁后，可以验证是否已将其删除：\n$ sudo lxc-info -n example-container example-container doesn\u0026#39;t exist $ sudo lxc-ls -f 注意：如果您尝试销毁正在运行的容器，该命令将失败并告知您容器仍在运行：\n$ sudo lxc-destroy -n example-container example-container is running 在销毁容器前必须先停止它。\n高级配置 有时，可能需要配置一个或多个容器来完成一个或多个任务。 LXC通过让管理员修改位于/var/lib/lxc中的容器配置文件来简化这一过程：\n$ sudo su # cd /var/lib/lxc # ls example-container 容器的父目录将包含至少两个文件：1）容器配置文件和 2）容器的整个rootfs：\n# cd example-container/ # ls config rootfs 假设您想要在主机系统启动时自动启动名称为example-container的容器。那么您需要将以下行添加到容器的配置文件/var/lib/lxc/example-container/config的尾部：\n# Enable autostart lxc.start.auto = 1 重新启动容器或重新启动主机系统后，您应该看到如下内容：\n$ sudo lxc-ls -f NAME STATE AUTOSTART GROUPS IPV4 IPV6 example-container RUNNING 1 - 10.0.3.25 - 注意 AUTOSTART 字段现在被设置为“1”。\n如果在容器启动时，您希望容器绑定装载主机上的目录路径，请将以下行添加到同一文件的尾部：\n# 将挂载系统路径绑定到本地路径 lxc.mount.entry = /mnt mnt none bind 0 0 通过上面的示例，当容器重新启动时，您将看到容器本地的 / mnt目录可访问的主机/ mnt目录的内容。\n特权与非特权容器 您经常会发现在与LXC相关的内容中讨论特权容器和非特权容器的概念。但它们究竟是什么呢？这个概念非常简单，并且LXC容器可以在任一配置下运行。\n根据设计，无特权容器被认为比特权容器更安全，更保密。无特权容器运行时，容器的root UID映射到主机系统上的非root UID。这使得攻击者即使破解了容器，也难以获得对底层主机的root权限。简而言之，如果攻击者设法通过已知的软件漏洞破坏了您的容器，他们会立即发现自己无法获取任何主机权限。\n特权容器可能使系统暴露于此类攻击。这就是为什么我们最好在特权模式下运行尽量少的容器。确定需要特权访问的容器，并确保付出额外的努力来定期更新并以其他方式锁定它们。\n然而，Docker又是什么呢？ 我花了相当多的时间谈论Linux容器，但是Docker呢？它是生产中部署最多的容器解决方案。自首次推出以来，Docker已经风靡Linux计算世界。 Docker是一种Apache许可的开源容器化技术，旨在自动化在容器内创建和部署微服务这类重复性任务。 Docker将容器视为非常轻量级和模块化的虚拟机。最初，Docker是在LXC之上构建的，但它已经远离了这种依赖，从而带来了更好的开发人员和用户体验。与LXC非常相似，Docker继续使用内核cgroup子系统。该技术不仅仅是运行容器，还简化了创建容器，构建映像，共享构建的映像以及对其进行版本控制的过程。\nDocker主要关注于：\n 可移植性：Docker提供基于镜像的部署模型。这种类型的可移植性允许更简单的方式在多个环境中共享应用程序或服务集合（以及它们的所有依赖）。 版本控制：单个Docker镜像由一系列组合层组成。每当镜像被更改时，都会创建一个新层。例如，每次用户指定命令（例如运行或复制）时，都会创建一个新层。 Docker将重用这些层用于新的容器构建。分层到Docker是它自己的版本控制方法。 回滚：再次，每个Docker镜像都有很多层。如果您不想使用当前运行的层，则可以回滚到以前的版本。这种敏捷性使软件开发人员可以更轻松地持续集成和部署他们的软件技术。 快速部署：配置新硬件通常需要数天时间。并且，安装和配置它的工作量和开销是非常繁重的。使用Docker，您可以在几秒钟将镜像启动并运行，相比于之前，节省了大量的时间。当你使用完一个容器时，你可以轻松地销毁它。  从本质上说，Docker和LXC都非常相似。它们都是用户空间和轻量级虚拟化平台，它们利用cgroup和命名空间来管理资源隔离。但是，两者之间也存在许多明显的差异。\n进程管理 Docker将容器限制为单个进程运行。如果您的应用程序包含X个并发进程，Docker将要求您运行X个容器，每个容器都有自己单独的进程。 LXC不是这样，LXC运行具有传统init进程的容器，反过来，可以在同一容器内托管多个进程。例如，如果要托管LAMP（Linux + Apache + MySQL + PHP）服务器，每个应用程序的每个进程都需要跨越多个Docker容器。\n状态管理 Docker被设计为无状态，意味着它不支持持久存储。有很多方法可以解决这个问题，但同样，只有在进程需要时才需要它。创建Docker镜像时，它将包含只读层。这不会改变。在运行时，如果容器的进程对其内部状态进行任何更改，则将保持内部状态和镜像的当前状态之间的差异，直到对Docker镜像进行提交（创建新层）或直到容器被删除，差异也会消失。\n可移植性 在讨论Docker时，这个词往往被过度使用——因为它是Docker相对于LXC的最重要的优势。 Docker从应用程序中抽象出网络，存储和操作系统细节方面做得更好。这样就形成了一个真正独立于配置的应用程序，保证应用程序的环境始终保持不变，无论启用它的机器配置环境如何。\nDocker旨在使开发人员和系统管理员都受益。它已成为许多DevOps（开发人员+维护人员）工具链中不可或缺的一部分。开发人员可以专注于编写代码，而无需担心最终托管它的系统是什么。使用Docker，无需安装和配置复杂数据库，也无需担心在不兼容的语言工具链版本之间切换。 Docker为维护人员提供了更多的灵活性，通常可以减少托管一些较小和更基本的应用程序所需的物理系统数量。 Docker简化了软件交付。新功能和错误/安全修复程序可以快速到达客户，无需任何麻烦，意外或停机。\n总结 为了基础设施安全性和系统稳定性而隔离进程并不像听起来那么痛苦。 Linux内核提供了所有必要的工具，使简单易用的用户空间应用程序【如LXC（甚至Docker）】能够在隔离的沙盒环境中管理操作系统的微实例及其本地服务。\n沙箱 在计算机安全领域，沙箱(Sandbox)是一种程序的隔离运行机制，其目的是限制不可信进程的权限。沙箱技术经常被用于执行未经测试的或不可信的客户程序。为了避免不可信程序可能破坏其它程序的运行，沙箱技术通过为不可信客户程序提供虚拟化的磁盘、内存以及网络资源，而这种虚拟化手段对客户程序来说是透明的。由于沙箱里的资源被虚拟化（或被间接化），所以沙箱里的不可信程序的恶意行为往往会被限制在沙箱中。\n沙箱技术一直是系统安全领域的挑战，不存在说哪一种方案是足够安全的。沙箱技术方案通常是需要结合多种系统安全技术来实现，采用防御纵深(Defence in Depth)的设计原则，筑建多道防御屏障，尽可能地将安全风险将为最低。下面我们主要讨论如何利用Linux kernel所提供的安全功能来建立有效的沙箱技术。\n在讨论之前，我们简单回顾一下Linux安全模型相关的内容（假设读者已经非常熟悉）：\n(1) 每个进程都有自己的地址空间；\n(2) MMU硬件机制来保证地址空间的隔离；\n(3) Kernel是系统的TCB(Trusted Computing Base)，是安全策略的制定者和执行者；\n(4) 进程是最小的权限边界；\n(5) root具有最高权限，它能控制一切；\n(6) 其它用户受DAC(Discretionary Access Control)限制，如文件系统的UGO权限控制。\n进程是最小的权限边界，其根本原因是MMU能保证进程地址空间的隔离。\nLinux Kernel还提供了与进程降权(drop privilege)相关的一些功能：\n setuid POSIX.1e capability chroot jail Quota control (eg, cgroup, namespace) Linux Container Linux Security Module (LSM)  下面我们会介绍如何在实践中利用这些诀窍来构建一个有效的sandbox.\nSandboxing systemd-nspawn 中文手册 入门笔记 🗓️ 2021/02/05\n介绍 systemd-nspawn是一个类似chroot一样的命令，用来启动一个容器，但是有比chroot更加强大的功能，能够完全虚拟化文件系统、进程树等系统，同时对于容器的网络接口、资源占用进行限制。\nsystemd-nspawn与docker类似，但又存在一些不同点，这些不同点主要是因为软件设计运行的场景不一样。Docker容器更加注重颗粒化的管理，容器作为最基本的单位，每个容器只运行单一的进程，并且由多个容器组成一个运用，比如如果要通过Docker运行WordPress，还需要配置一个MariaDB或是MySQL容器，这样的架构方便进行集群和批量管理，能弹性的扩展资源，更适合在云计算平台上使用。\n相对Docker而言，systemd-nspawn的一些特点，让我觉得在一些场景上，systemd-nspawn更适合个人/单机使用：\n systemd-nspawn启动一个容器则会完整的启动整个系统，可以把依赖的服务都集中到一个容器里面 systemd-nspawn是systemd自带组件，而systemd目前作为主流发行版的默认init进程，基本上所有Linux发行版都会自带 容器内到容器外的无缝对接，使用systemctl加上参数--machine就可以控制容器内的服务，journalctl也支持查看容器内服务的日志 systemd-nspawn可以直接使用现在的文件系统作为容器的rootfs启动，不同于Docker的copy-on-write，这点看似比较傻瓜，却比较实用，特别是个人非常折腾的时候。  配置 容器的配置非常的简单，只要保证容器rootfs存在，就可以启动容器，Debian系容器使用工具debootstrap 下载，Arch对应使用pacstrap安装，由于容器与主机共享内核，容器内部不需要安装内核和内核模块。\n   容器名称 myContainer     服务单元 systemd-nspawn@myContainer.service   容器根目录 /var/lib/machines/myContainer   配置文件 /etc/systemd/nspawn/myContainer.nspawn    容器内部包括常见设定，包括root密码、时区、主机名等可以使用systemd-nspawn -D root启动（忽略-b参数）跳过登录过程启动容器，之后进行配置。容器本身运行环境、资源限制则通过.nspawn配置完成，主要的配置包括文件系统还有网络配置。\n用户空间隔离 --private-users参数用于隔离用户空间文件的uid/gid，如果不设定这个参数，默认是打开的，即运行时候容器内和容器外，文件拥有者不一样，具体表现为容器内的uid/gid在实际文件系统中会添加一段偏移，容器外可以控制容器内文件，但是如果直接拷贝文件到容器里面，容器内运行的进程是没有读写权限的。\n如果启用了--private-users参数，原有文件依旧会保持原有uid/gid，只有在容器内发生读写的时候，产生新的文件才会映射到新的拥有者，通过开启--private-users-chown参数，强行迫使原有文件全部映射到新的用户和用户组。同理，也可以反向操作，将发生偏移的容器内的文件，全部修改回正常的uid/gid\n私有网络配置 --private-network参数对应配置文件[Network]下的Private，启用这个参数之后，宿主机网络和容器网络将隔离开，只能通过NAT或是桥接方式通讯，设置--network-interface、--network-macvlan、--network-ipvlan、--network-veth都会间接开启私有网络。\n--network-interface 参数指定一个网络给容器，这个参数不是共享网卡，而是直接从宿主机中移除这个网卡，并添加到容器中，在停用容器之后才会返回这个网卡。参数对应配置文件中[Network]Interface。注意：不能直接把无线网卡分配给容器，如果要分配无线网卡给容器，无线网卡必须支持命名空间。\n--network-macvlan/--network-ipvlan，相当于桥接，网卡的前缀是mv-/iv-，macvlan是同个网卡不同MAC地址，ipvlan是同个MAC地址不同IP地址。这两个方法都有一个缺点，那就是无法直接于宿主机通讯，即使处于同一个网段下面。\n--network-veth，在主机和容器之间创建一个虚拟网卡，网卡前缀是ve-，--network-bridge把主机上的桥接网卡映射到容器里面，不能直接指定主机上的物理网卡，必须在主机端建立bridge之后，把这个bridge分配给容器，这个参数会间接启用--network-veth。\n其他的网络相关参数还有 --network-zone=或是--port，用于批量管理容器网络，后者用于暴露端口到主机，不过都是在开启私有网络并且配置完整的时候可以启用，具体可以去看手册。\n要禁用私有网络，设定参数--network-veth=no/--private-network=no或是在配置文件里面添加:\n[Network] Private=no VirtualEthernet=no 这样子容器于主机共享网络接口。\n资源限定 限定容器能占用资源有时候也是非常重要的，这一部分可以参考systemd资源控制\nsystemctl set-property systemd-nspawn@container-name.service MemoryMax=2G systemctl set-property systemd-nspawn@container-name.service CPUQuota=200% 容器管理 容器管理使用命令machinectl ，但是实际上也是等同systemctl对应的命令\n   machinectl systemctl 说明     machinectl list systemctl list-machines 列出正在运行的容器   machinectl login name  连接到容器控制台   machinectl status name systemctl status systemd-nspawn@name 查看容器运行状态   machinectl start name systemctl start systemd-nspawn@name 启动容器   machinectl poweroff name systemctl stop systemd-nspawn@name 关闭容器   machinectl reboot name systemctl restart systemd-nspawn@name 重启容器   machinectl terminate name  强行停止容器，在容器没有反应的时候使用   machinectl enable name systemctl enable systemd-nspawn@name 开机自启   machinectl disable name systemctl disable systemd-nspawn@name 禁用自启    nspawn.org A hub for systemd-nspawn containers and images.\nnspawn.org 目前提供了 Arch、CentOS、Debian、Fedora、Ubuntu 的各版本镜像，并可以直接用 systemd-nspawn 的验证机制进行签名验证。\n推荐的用法是使用其提供的 “nspawn” 工具。下面以创建一个 Fedora 30 容器为例：\n  获取工具：\n$ wget https://raw.githubusercontent.com/nspawn/nspawn/master/nspawn $ chmod +x nspawn   获取 Fedora 30 镜像：\n$ sudo ./nspawn init fedora/30/tar   启动容器并获取 shell：\n$ sudo machinectl start fedora-30-tar $ sudo machinectl shell fedora-30-tar Connected to machine fedora-30-tar. Press ^] three times within 1s to exit session. [root@fedora30 ~]#   一些背景：容器默认的存储路径在 /var/lib/machines/。nspawn.org 的创建者是 shibumi，目前是 Arch Linux Trusted User。所有的镜像使用 mkosi 制作，定义文件均在 GitHub 上。除了 nspawn 容器镜像，这个站点还提供可引导的 GPT-UEFI 镜像。\nBubblewrap 使用 bwrap 沙盒 bwrap 是命令的名字。这个项目的名字叫 bubblewrap。它是一个使用 Linux 命名空间的非特权沙盒（有用户命名空间支持的话）。\n我之前使用过 Gentoo 的 sandbox 工具。它是 Gentoo 用于打包的工具，使用的是 LD_PRELOAD 机制，所以并不可靠。主要用途也就是避免打包软件的时候不小心污染到用户家目录。\n使用 bwrap 的话，限制是强制的，没那么容易绕过（至于像 Go 这种因为不使用 libc 而意外绕过就更难得了）。不过 bwrap 不会在触发限制的时候报错。\nbwrap 的原理是，把 / 放到一个 tmpfs 上，然后需要允许访问的目录通过 bind mount 弄进来。所以没弄进来的部分就是不存在，写数据的话就存在内存里，用完就扔掉了。这一点和 systemd 也不一样——systemd 会把不允许的地方挂载一个没权限访问的目录过去。\nbwrap 的挂载分为只读和可写挂载。默认是 nodev 的，所以在里边是不能挂载硬盘设备啥的。它也提供最简 /proc 和 /dev，需要手动指定。整个 / 都是通过命令行来一点点填充内容的，所以很容易漏掉部分内容（比如需要联网的时候忘记挂载 resolv.conf 或者 TLS 证书），而不会不小心允许不应当允许访问的地方（当然前提是不偷懒直接把外面的 / 挂载过去啦）。\n至于别的命名空间，有 --unshare-all 选项，不用写一堆了。如果需要网络，就加个 --share-net（这个选项文档里没写）。没有别的网络方案，因为没特权，不能对网络接口进行各种操作。--die-with-parent 可以保证不会有残留进程一直跑着。\n我目前的打包命令长这样：\nalias makepkg=\u0026#39;bwrap --unshare-all --share-net --die-with-parent \\ --ro-bind /usr /usr --ro-bind /etc /etc --proc /proc --dev /dev \\ --symlink usr/bin /bin --symlink usr/bin /sbin --symlink usr/lib /lib --symlink usr/lib /lib64 \\ --bind $PWD /build/${PWD:t} --ro-bind /var/lib/pacman /var/lib/pacman --ro-bind ~/.ccache ~/.ccache \\ --bind ~/.cache/ccache ~/.cache/ccache --chdir /build/${PWD:t} /usr/bin/makepkg\u0026#39; 以后应该随着问题的出现还会修改的。\n其实我学 bwrap 主要不是自己打包啦（毕竟基本上都交给 lilac 了），而是给 lilac 加固。Arch 的打包脚本是 shell 脚本，所以很多时候不执行脚本就没办法获取一些信息、进行某些操作。唉，这些发行版都喜欢糙快猛的风格，然后在上边打各种补丁。deb 和 rpm 的打包也都是基于 shell 脚本的。而 lilac 经常通过脚本编辑打包脚本，或者从 AUR 取，万一出点事情，把不该删的东西给删掉了，或者把私钥给上传了，就不好了。所以前些天我给 lilac 执行 PKGBUILD 的地方全部加上了 bwrap。期间还发现 makepkg --printsrcinfo 不就是读取 PKGBUILD 然后打印点信息嘛，竟然不断要求读取 install 脚本，还要对打包目录可写……\n另一个用法是，跑不那么干净的软件。有些软件不得不用，又害怕它在自己家里拉屎，就可以让它在沙盒里放肆了。比如使用反斜杠作为文件路径分隔符写一堆奇怪文件名的 WPS Office。再比如不确定软件会不会到处拉屎，所以事先确认一下。我以前使用的是基于 systemd-nspawn 和 overlayfs 的方案（改进自基于 aufs 和 lxc 的方案所以名字没改），不过显然 bwrap 更轻量一些。跑 GUI 的话，我用的命令长这样：\nbwrap --unshare-all --die-with-parent --ro-bind / / \\  --tmpfs /sys --tmpfs /home --tmpfs /tmp --tmpfs /run --proc /proc --dev /dev \\  --ro-bind ~/.fonts ~/.fonts --ro-bind ~/.config/fontconfig ~/.config/fontconfig \\  --bind ~/.cache/fontconfig ~/.cache/fontconfig --ro-bind ~/.Xauthority ~/.Xauthority \\  --ro-bind /tmp/.X11-unix /tmp/.X11-unix --ro-bind /run/user/$UID/bus /run/user/$UID/bus \\  --chdir ~ /bin/bash 其实还可以用来给别的发行版编译东西，取代我之前使用 systemd-nspawn 的方案。bwrap 在命令行上指定如何挂载，倒是十分方便灵活，很适合这种需要共享工作目录的情况呢。以后有需要的时候我再试试看。（好像一般人都是使用 docker / podman 的，但是我喜欢使用自己建立和维护的 rootfs，便于开发和调试，也更安全。）\n和 bwrap 类似的工具还有 SELinux 和 AppArmor。它们是作用于整个系统的，Arch Linux 安装会很麻烦，对于我的需求也过于复杂。Firejail 是面向应用程序的，但是配置起来也挺不容易。bwrap 更偏重于提供底层功能而不是完整的解决方案，具体用法可以让用户自由发挥。\naur-apps #!/bin/bash # # aur-apps，利用 bwrap 沙盒让 ubuntu 能用 aur 和 archlinuxcn 源安装软件运行 # AUR_DIR=\u0026#34;${AUR_DIR:-$HOME/.local/lib/aur-apps/}\u0026#34; AUR_CACHE_DIR=\u0026#34;${ARCH_DIR:-$AUR_DIR/cache/}\u0026#34; AUR_APP_DATA_DIR=\u0026#34;${ARCH_DIR:-$AUR_DIR/data/}\u0026#34; ARCH_DIR=\u0026#34;${ARCH_DIR:-$AUR_DIR/root.x86_64/}\u0026#34; ARCH_IMAGE_MIRROR=\u0026#34;${ARCH_IMAGE_MIRROR:-http://mirrors.163.com/archlinux/iso/latest/}\u0026#34; #MIRRORLIST=\u0026#39;https://mirrors.163.com/archlinux/$repo/os/$arch\u0026#39; #ARCHLINUXCN=\u0026#39;https://mirrors.163.com/archlinux-cn/$arch\u0026#39; MIRRORLIST=\u0026#39;http://mirrors.aliyun.com/archlinux/$repo/os/$arch\u0026#39; ARCHLINUXCN=\u0026#39;https://mirrors.aliyun.com/archlinuxcn/$arch\u0026#39; AUR_DESKTOP_FILES_DIR=\u0026#34;$HOME/.local/share/applications/aur-apps/\u0026#34; APT_AUR=\u0026#39;#!/bin/bash # fix the poorly designed pacman/yay command list()( set -x yay -Sl \u0026#34;$@\u0026#34; ) search()( set -x yay -Ss \u0026#34;$@\u0026#34; ) show()( set -x yay -Si \u0026#34;$@\u0026#34; ) showfiles()( set -x yay -Fl \u0026#34;$@\u0026#34; || yay -Ql \u0026#34;$@\u0026#34; ) install()( set -x yay -S \u0026#34;$@\u0026#34; ) remove()( set -x yay -Rns \u0026#34;$@\u0026#34; ) update()( set -x yay -Sy \u0026#34;$@\u0026#34; \u0026amp;\u0026amp; yay -Fy \u0026#34;$@\u0026#34; ) upgrade()( set -x yay -Syua \u0026#34;$@\u0026#34; \u0026amp;\u0026amp; yay -Fy \u0026#34;$@\u0026#34; ) upgradeable()( set -x yay -Pu ) files()( set -x yay -F \u0026#34;$@\u0026#34; ) autoclean()( set -x yay -Yc ) status()( set -x yay -Ps ) help(){ echo commands： declare -F | grep -oP \u0026#39; [a-z]+.*\u0026#39; | sort } if [ \u0026#34;$(type -t $1)\u0026#34; = function ] ; then \u0026#34;$@\u0026#34; else help fi \u0026#39; ## initialize init(){ [ ! -e /usr/bin/bwrap ] \u0026amp;\u0026amp; echo \u0026#34;+ sudo apt install bwrap\u0026#34; \u0026amp;\u0026amp; sudo apt install bubblewrap mkdir -p \u0026#34;$AUR_DIR\u0026#34; mkdir -p \u0026#34;$AUR_CACHE_DIR/pacman/pkg/\u0026#34; mkdir -p \u0026#34;$AUR_CACHE_DIR/_cache/\u0026#34; mkdir -p \u0026#34;$AUR_APP_DATA_DIR\u0026#34; mkdir -p \u0026#34;$ARCH_DIR/$HOME/.cache\u0026#34; cd \u0026#34;$AUR_DIR\u0026#34; image_name=$(_wget_arch_image) test -n \u0026#34;$image_name\u0026#34; || { echo \u0026#34;can not download the archlinux-bootstrap image file, exit.\u0026#34; ; exit 1 ; } # root.x86_64 tar xvf \u0026#34;$image_name\u0026#34; # setup pacman echo \u0026#34;Server = $MIRRORLIST\u0026#34; \u0026gt;\u0026gt; root.x86_64/etc/pacman.d/mirrorlist echo -e \u0026#34;\\n[archlinuxcn]\\nServer = $ARCHLINUXCN\u0026#34; \u0026gt;\u0026gt; root.x86_64/etc/pacman.conf echo -e \u0026#34;\\n[multilib]\\nInclude = /etc/pacman.d/mirrorlist\u0026#34; \u0026gt;\u0026gt; root.x86_64/etc/pacman.conf # fix the poorly designed pacman/run yay command echo \u0026#34;$APT_AUR\u0026#34; \u0026gt; root.x86_64/usr/local/bin/apt-aur chmod +x root.x86_64/usr/local/bin/apt-aur # use snapctl xdg-open echo -e \u0026#39;#!/bin/sh test -a /usr/bin/snapctl \u0026amp;\u0026amp; exec snapctl user-open \u0026#34;$@\u0026#34; || exec /usr/bin/xdg-open \u0026#34;$@\u0026#34; \u0026#39; \u0026gt; root.x86_64/usr/local/bin/xdg-open chmod +x root.x86_64/usr/local/bin/xdg-open # init arch # init locale echo zh_CN.UTF-8 UTF-8 \u0026gt;\u0026gt; root.x86_64/etc/locale.gen bwrap_root locale-gen # fix makepkg, pacman with bwrap sed -i \u0026#39;s/^CheckSpace/##CheckSpace/\u0026#39; root.x86_64/etc/pacman.conf _fix_files # add user bwrap_root useradd -u $(id -u) \u0026#34;$USER\u0026#34; # setup pacman bwrap_root pacman-key --init bwrap_root pacman-key --populate archlinux bwrap_root pacman -Sy bwrap_root pacman -Fy bwrap_root pacman --noconfirm -S fakeroot which bwrap_root cp /usr/bin/fakeroot /usr/local/bin/sudo # use fakeroot as sudo echo \u0026#34;+ sudo arch-chroot\u0026#34; arch_chroot pacman --noconfirm -S archlinuxcn-keyring ; sudo chown -R $USER: \u0026#34;$ARCH_DIR\u0026#34; # makepkg expect base-devel #bwrap_root pacman --noconfirm -S base-devel git make patch yay xdg-desktop-portal-kde xdg-desktop-portal-gtk extra/breeze-gtk extra/noto-fonts-cjk bwrap_root pacman --noconfirm -S base-devel git make patch yay xdg-desktop-portal-gtk extra/breeze-gtk fcitx fcitx-qt5 fcitx-qt6 ## cd - } # fix files _fix_files(){ grep -q \u0026#39;EUID == 0\u0026#39; \u0026#34;$ARCH_DIR/usr/bin/makepkg\u0026#34; \u0026amp;\u0026amp; sed -i \u0026#39;s/EUID == 0/EUID == 1/\u0026#39; \u0026#34;$ARCH_DIR/usr/bin/makepkg\u0026#34; } # like apt list list(){ bwrap_user yay -Sl \u0026#34;$@\u0026#34; } # like apt search search(){ bwrap_user yay -Ss \u0026#34;$@\u0026#34; } # like apt show show(){ bwrap_user yay -Si \u0026#34;$@\u0026#34; } # like apt-file list or dpkg -L showfiles(){ bwrap_user yay -Fl \u0026#34;$@\u0026#34; || bwrap_user yay -Ql \u0026#34;$@\u0026#34; } # like apt install install(){ _fix_files bwrap_user yay -S \u0026#34;$@\u0026#34; \u0026amp;\u0026amp; update_desktop_menu } # like apt remove remove(){ _fix_files bwrap_user yay -Rns \u0026#34;$@\u0026#34; \u0026amp;\u0026amp; update_desktop_menu } # like apt update update(){ bwrap_user yay -Sy \u0026#34;$@\u0026#34; \u0026amp;\u0026amp; bwrap_root yay -Fy \u0026#34;$@\u0026#34; } # like apt upgrade upgrade(){ _fix_files bwrap_user yay -Syua \u0026#34;$@\u0026#34; \u0026amp;\u0026amp; bwrap_root yay -Fy \u0026#34;$@\u0026#34; } # apt list --upgradable upgradeable(){ bwrap_user yay -Pu } # like apt-file search files(){ bwrap_user yay -F \u0026#34;$@\u0026#34; } # like apt autoclean autoclean(){ _fix_files bwrap_root yay -Yc } # like apt policy status(){ bwrap_user yay -Ps } # download archlinux-bootstrap image _wget_arch_image()( image_name=$(wget -O- \u0026#34;$ARCH_IMAGE_MIRROR\u0026#34; | grep -m 1 -oP \u0026#39;archlinux-bootstrap-20.*?x86_64\\.tar\\.gz\u0026#39; | head -1) wget -c \u0026#34;$ARCH_IMAGE_MIRROR/$image_name\u0026#34; \u0026amp;\u0026amp; echo $image_name ) # gen .menu file _gen_desktop_file_menu_file(){ DIR=$(basename $AUR_DESKTOP_FILES_DIR) echo \u0026#39;\u0026lt;!DOCTYPE Menu PUBLIC \u0026#34;-//freedesktop//DTD Menu 1.0//EN\u0026#34; \u0026#34;http://www.freedesktop.org/standards/menu-spec/menu-1.0.dtd\u0026#34;\u0026gt; \u0026lt;!-- Do not edit manually - generated and managed by xdg-desktop-menu --\u0026gt; \u0026lt;Menu\u0026gt; \u0026lt;Name\u0026gt;Applications\u0026lt;/Name\u0026gt; \u0026lt;Menu\u0026gt; \u0026lt;Name\u0026gt;aur-apps\u0026lt;/Name\u0026gt; \u0026lt;Directory\u0026gt;aur-apps.directory\u0026lt;/Directory\u0026gt; \u0026lt;Include\u0026gt;\u0026#39; ls \u0026#34;$AUR_DESKTOP_FILES_DIR\u0026#34; | while read fn ; do echo \u0026#34; \u0026lt;Filename\u0026gt;$DIR-$fn\u0026lt;/Filename\u0026gt;\u0026#34; done echo \u0026#39; \u0026lt;/Include\u0026gt; \u0026lt;/Menu\u0026gt; \u0026lt;/Menu\u0026gt;\u0026#39; } # update start menu update_desktop_menu(){ mkdir -p \u0026#34;$AUR_DESKTOP_FILES_DIR\u0026#34; ln -s \u0026#34;$ARCH_DIR/usr/share/pixmaps/\u0026#34;* ~/.local/share/pixmaps/ 2\u0026gt;/dev/null rm \u0026#34;$AUR_DESKTOP_FILES_DIR\u0026#34;/* cp \u0026#34;$ARCH_DIR/usr/share/applications/\u0026#34;* \u0026#34;$AUR_DESKTOP_FILES_DIR\u0026#34; sed -i \u0026#39;s/Exec=/Exec=aur-apps run /\u0026#39; \u0026#34;$AUR_DESKTOP_FILES_DIR/\u0026#34;* echo \u0026#39;[Desktop Entry] Version=1.0 Type=Directory Name=Aur Apps Icon=applications-multimedia\u0026#39; \u0026gt; ~/.local/share/desktop-directories/aur-apps.directory _gen_desktop_file_menu_file \u0026gt; ~/.config/menus/applications-merged/aur-apps.menu xdg-desktop-menu forceupdate xdg-icon-resource forceupdate } _get_bind_try_args()( quote () { local quoted=${1//\\\u0026#39;/\\\u0026#39;\\\\\\\u0026#39;\\\u0026#39;}; printf \u0026#39;%s\u0026#39; \u0026#34;$quoted\u0026#34; } # --bind-try args { for i in DESKTOP DOWNLOAD TEMPLATES PUBLICSHARE DOCUMENTS MUSIC PICTURES VIDEOS ; do xdg-user-dir $i ; done } | while read i do bind_try=$(quote \u0026#34;$i\u0026#34;) echo -n \u0026#34; --bind $bind_try$bind_try\u0026#34; done ) # fix environment variable _fix_env(){ } # run command run(){ bwrap_user \u0026#34;$@\u0026#34; } # user bwrap bwrap_user()( if [ ! -e \u0026#34;$ARCH_DIR/usr/bin/pacman\u0026#34; ] ; then echo \u0026#34;aur for ubuntu was not initialized, please run init\u0026#34; read -e -p \u0026#34;would you like to initialize now? [Y/n] \u0026#34; ret [ \u0026#34;$ret\u0026#34; = y -o \u0026#34;$ret\u0026#34; = Y ] || exit 1 init fi #xdg_open_file=$(ls /snap/core/*/usr/bin/xdg-open | head -1) bind_try_args=`_get_bind_try_args` [ \u0026#34;$1\u0026#34; = which ] || set -x bwrap --bind \u0026#34;$ARCH_DIR\u0026#34; / \\  --bind-try \u0026#34;$AUR_APP_DATA_DIR\u0026#34; \u0026#34;$HOME\u0026#34; \\  --bind-try \u0026#34;$AUR_CACHE_DIR/pacman/pkg/\u0026#34; /var/cache/pacman/pkg/ \\  --bind-try \u0026#34;$AUR_CACHE_DIR/_cache/\u0026#34; \u0026#34;$HOME/.cache\u0026#34; \\  $bind_try_args \\  --ro-bind /etc/resolv.conf /etc/resolv.conf --ro-bind /etc/hosts /etc/hosts \\  --dev-bind /dev /dev --dev-bind /proc /proc --dev-bind /sys /sys --bind /tmp /tmp --dev-bind /run /run \\  --ro-bind-try /usr/share/fonts/opentype/noto/ /usr/share/fonts/noto \\  --ro-bind-try /usr/bin/snapctl /usr/bin/snapctl \\  --ro-bind-try /usr/share/themes/Yaru /usr/share/themes/Yaru \\  --share-net --die-with-parent \u0026#34;${@:-bash}\u0026#34; ) # fakeroot bwrap #bwrap_fakeroot(){ # bwrap_user fakeroot \u0026#34;$@\u0026#34; #} # root bwrap bwrap_root()( set -x bwrap --bind \u0026#34;$ARCH_DIR\u0026#34; / \\  --bind-try \u0026#34;$AUR_APP_DATA_DIR\u0026#34; \u0026#34;$HOME\u0026#34; \\  --bind-try \u0026#34;$AUR_CACHE_DIR/pacman/pkg/\u0026#34; /var/cache/pacman/pkg/ \\  --bind-try \u0026#34;$AUR_CACHE_DIR/_cache/\u0026#34; \u0026#34;$HOME/.cache\u0026#34; \\  --ro-bind /etc/resolv.conf /etc/resolv.conf --ro-bind /etc/hosts /etc/hosts \\  --dev-bind /dev /dev --dev-bind /proc /proc --dev-bind /sys /sys --bind /tmp /tmp --dev-bind /run /run \\  --ro-bind-try /usr/share/fonts/opentype/noto/ /usr/share/fonts/noto \\  --ro-bind-try /usr/bin/snapctl /usr/bin/snapctl \\  --ro-bind-try /usr/share/themes/Yaru /usr/share/themes/Yaru \\  --share-net --die-with-parent --uid 0 --gid 0 --unshare-user \u0026#34;${@:-bash}\u0026#34; ) # sudo arch-chroot arch_chroot()( set -x sudo \u0026#34;$ARCH_DIR/usr/bin/arch-chroot\u0026#34; \u0026#34;$ARCH_DIR\u0026#34; \u0026#34;$@\u0026#34; ) # list commands help(){ echo commands： declare -F | grep -oP \u0026#39; [a-z]+.*\u0026#39; | sort } # interactive cmd _cmd_main()( _fix_env if [ -n \u0026#34;$1\u0026#34; ] ; then if [ \u0026#34;$(type -t $1)\u0026#34; = function ] ; then \u0026#34;$@\u0026#34; exit elif bwrap_user which \u0026#34;$1\u0026#34; ; then bwrap_user \u0026#34;$@\u0026#34; exit else echo \u0026#34;command not found.\u0026#34; help exit fi fi while read -e -p \u0026#39;aur\u0026gt; \u0026#39; CMD ; do if [ \u0026#34;$CMD\u0026#34; = q -o \u0026#34;$CMD\u0026#34; = quit ] ; then exit elif [ \u0026#34;$(type -t ${CMD/ */})\u0026#34; = function ] ; then $CMD elif bwrap_user which \u0026#34;${CMD/ */}\u0026#34; ; then bwrap_user $CMD continue else echo \u0026#34;command not found.\u0026#34; help fi done ) _cmd_main \u0026#34;$@\u0026#34; 权限 ugo Linux 系统中文件的 ugo 权限是 Linux 进行权限管理的基本方式。\n所有者和组 Linux 文件的 ugo 权限把对文件的访问者划分为三个类别：文件的所有者、组和其他人。所谓的 ugo 就是指 user(也称为 owner)、group 和 other 三个单词的首字母组合。\n用户和组的信息分别记录在 /etc/passwd、/etc/group 文件中，这两个文件的内容是任何人都有权查看的，可以直接以读取文本文件的方式查看其内容，其中的每一行代表一个用户。\n文件的所有者\n文件的所有者一般是创建该文件的用户，对该文件具有完全的权限。在一台允许多个用户访问的 Linux 主机上，可以通过文件的所有者来区分一个文件属于某个用户。当然，一个用户也无权查看或更改其它用户的文件。\n文件所属的组\n假如有几个用户合作开发同一个项目，如果每个用户只能查看和修改自己创建的文件就太不方便了，也就谈不上什么合作了。所以需要一个机制允许一个用户查看和修改其它用户的文件，此时就用到组的概念的。我们可以创建一个组，然后把需要合作的用户都添加都这个组中。在设置文件的访问权限时，允许这个组中的用户对该文件进行读取和修改。\n其他人\n如果我想把一个文件共享给系统中的所有用户该怎么办？通过组的方式显然是不合适的，因为需要把系统中的所有用户都添加到一个组中。并且系统中添加了新用户该怎么办，每添加一个新用户就把他添加到这个组中吗？这个问题可以通过其他人的概念解决。在设置文件的访问权限时，允许其他人户对该文件进行读取和修改。\n文件属性 使用 ll 命令可以查看文件的属性信息：\n$ ll Desktop drwxr-xr-x 2 nick nick 4.0K Mar 2 15:06 Desktop  drwxr-xr-x 指明文件的类型和 ugo 权限信息。 2 是对文件的引用计数。 nick 是文件的所有者，文件的所有者一般是创建该文件的用户，对该文件具有完全的权限。 nick 是文件所属的组，我们通过 adduser 命令创建用户时一般会创建一个同名的组，该用户就属于与他同名的组(比如笔者机器上的用户 nick 就属于 nick 组)。当我们创建文件和目录时，其默认所属的组就是所有者所在的组。  其它的信息我们暂时忽略。\n文件类型\ndrwxr-xr-x 的第一个字符描述文件的类型，常见的类型有如下几种：\n d 表示目录 - 表示普通文件 l 表示链接文件 b 表示块设备文件 c 表示字符设备文件 s 表示 socket 文件  ugo 权限信息\n10 个字符，除去第一个表示文件类型的字符，其它 9 个字符表示文件的 ugo 权限信息\n这 9 个字符以三个为一组，都是 rwx 或 - 的组合。其中，r 代表可读(read)、 w 代表可写(write)、 x 代表可执行(execute)。 这三个权限的位置不会改变，如果没有对应的权限，就会以 -(减号)代替。\n*第一组为文件所有者的权限，第二组为文件所属组的权限，第三组为其他人的权限。*其表示的具体含义为：文件所有者具有对文件的读写权限，文件所属组的用户具有对文件读写的权限，而其他人只有读取文件的权限。\n下面详细的解释一下文件读写执行的权限：\n r (read)：可以读取文件的实际内容，比如读取文本文件内的文字等。 w (write)：可以编辑、增加、删除文件的内容(但不含删除该文件)。 x (execute)：该文件具有可以被系统执行的权限。  可以看出，对于文件来说，rwx 主要针对的是文件的内容。\n对目录而言，目录中存储的主要是目录下文件名称的列表，这与普通文件是有些不同的：\n r (read contents in directory) 表示具有读取目录下文件名称的权限，也就是说你可以通过 ls 命令把目录下的文件列表查询出来。 w (modify contents of directory) 具有 w 权限表明你可以在该目录下执行如下的操作：  创建新的文件和目录 删除已经存在的文件与目录(不论该文件的权限为何!) 重命名已存在的文件或目录 移动该目录内文件、目录的位置   x (access directory) 目录虽然不能被执行，但是却具有可以执行的权限。目录的 x 权限表示用户是否可以进入该目标并成为当前的工作目录。注意，如果用户对目录没有 x 权限，则无法查看该目录下的文件的内容(注意与 r 权限的区别)。  综上，如果要允许目录被其他人浏览时，至少要给予 r 和 x 的权限。\n改变权限 在新建文件时会根据创建者的身份和其它的一些设置为文件生成默认的权限。\n接下来我们介绍如何通过命令修改文件权限相关的信息。\n改变文件所有者\n通过 chown 命令可以改变文件的所有者：\n$ sudo chown tester testfile 改变文件所属的组\n通过 chgrp 命令可以改变文件所属的组：\n$ sudo chgrp tester testfile 改变文件的权限\n通过 chmod 命令可以改变文件的权限。对于文件的 rwx 权限，有两种表示方法，数字表示法和字符表示法。\n以数字表示权限的方式如下：\n r: 4 w: 2 x: 1  如果是 rwx 权限就是 4 + 2 + 1 = 7 ，r-x 就是 4 + 1 = 5 ，\u0026mdash; 则为 0。所以 rw-rw-r\u0026ndash; 就可以用 664 来表示。如果我们想把文件的权限修改为 rwxrwxrwx，可以使用下面的命令：\n$ chmod 777 testfile 以字符表示权限的方式如下：用字符 u, g, o 分别代表文件所有者(user)、文件所属的组(group)和其他人(other)，这就是 ugo 权限叫法的由来。只不过还有一个 a 可以表示全部的身份(all)。具体更改权限的语法如下：\nchmod [ugoa][+-=][rwx] 文件/目录 比如我们可以通过下面的命令把 testfile 的权限设为 rw-rw-r\u0026ndash;：\n$ chmod ug=rw,o=r testfile 如果想去掉组的 w 权限并给其他人添加 x 权限可以执行下面的命令：\n$ chmod g-w,o+x testfile 我们还可通过 a 为全部身份设置权限，比如 rwx：\n$ chmod a=rwx testfile 特殊权限 setuid 和 setgid 分别是 set uid ID upon execution 和 set group ID upon execution 的缩写。我们一般会再次把它们缩写为 suid 和 sgid。它们是控制文件访问的权限标志(flag)，它们分别允许用户以可执行文件的 owner 或 owner group 的权限运行可执行文件。\nSUID 在 Linux 中，所有账号的密码记录在 /etc/shadow 这个文件中，并且只有 root 可以读写入这个文件：\n$ ll /etc/shadow -rw-r----- 1 root shadow 1.5K Feb 25 12:46 /etc/shadow 如果另一个普通账号 tester 需要修改自己的密码，就要访问 /etc/shadow 这个文件。但是明明只有 root 才能访问 /etc/shadow 这个文件，这究竟是如何做到的呢？事实上，tester 用户是可以修改 /etc/shadow 这个文件内的密码的，就是通过 SUID 的功能。让我们看看 passwd 程序文件的权限信息：\n$ ll /usr/bin/passwd -rwsr-xr-x 1 root root 67K Jul 15 2021 /usr/bin/passwd 上图红框中的权限信息有些奇怪，owner 的信息为 rws 而不是 rwx。当 s 出现在文件拥有者的 x 权限上时，就被称为 SETUID BITS 或 SETUID ，其特点如下：\n SUID 权限仅对二进制可执行文件有效 如果执行者对于该二进制可执行文件具有 x 的权限，执行者将具有该文件的所有者的权限 本权限仅在执行该二进制可执行文件的过程中有效  下面我们来看 tester 用户是如何利用 SUID 权限完成密码修改的：\n tester 用户对于 /usr/bin/passwd 这个程序具有执行权限，因此可以执行 passwd 程序 passwd 程序的所有者为 root tester 用户执行 passwd 程序的过程中会暂时获得 root 权限 因此 tester 用户在执行 passwd 程序的过程中可以修改 /etc/shadow 文件  但是如果由 tester 用户执行 cat 命令去读取 /etc/shadow 文件确是不行的：\n$ ll /bin/cat -rwxr-xr-x 1 root root 43K Sep 5 2019 /bin/cat 原因很清楚，tester 用户没有读 /etc/shadow 文件的权限，同时 cat 程序也没有被设置 SUID。我们可以通过下图来理解这两种情况：\nSGID 当 s 标志出现在用户组的 x 权限时称为 SGID。SGID 的特点与 SUID 相同，我们通过 /usr/bin/mlocate 程序来演示其用法。mlocate 程序通过查询数据库文件 /var/lib/mlocate/mlocate.db 实现快速的文件查找。 mlocate 程序的权限如下图所示：\n$ ll /usr/bin/mlocate -rwxr-sr-x 1 root mlocate 39520 Nov 18 2014 /usr/bin/mlocate* 很明显，它被设置了 SGID 权限。下面是数据库文件 /var/lib/mlocate/mlocate.db 的权限信息：\n$ ll /var/lib/mlocate/mlocate.db -rw-r----- 1 root mlocate 12101109 Aug 13 07:35 /var/lib/mlocate/mlocate.db 普通用户 tester 执行 mlocate 命令时，tester 就会获得用户组 mlocate 的执行权限，又由于用户组 mlocate 对 mlocate.db 具有读权限，所以 tester 就可以读取 mlocate.db 了。程序的执行过程如下图所示：\n除二进制程序外，SGID 也可以用在目录上。当一个目录设置了 SGID 权限后，它具有如下功能：\n 用户若对此目录具有 r 和 x 权限，该用户能够进入该目录 用户在此目录下的有效用户组将变成该目录的用户组 若用户在此目录下拥有 w 权限，则用户所创建的新文件的用户组与该目录的用户组相同  SBIT 其实 SBIT 与 SUID 和 SGID 的关系并不大。SBIT 是 the restricted deletion flag or sticky bit 的简称。\nSBIT 目前只对目录有效，用来阻止非文件的所有者删除文件。比较常见的例子就是 /tmp 目录：\n$ ls -ld /tmp drwxrwxrwt 22 root root 4096 Mar 2 20:57 /tmp 权限信息中最后一位 t 表明该目录被设置了 SBIT 权限。SBIT 对目录的作用是：当用户在该目录下创建新文件或目录时，仅有自己和 root 才有权力删除。\n设置权限 以数字的方式设置权限\nSUID、SGID、SBIT 权限对应的数字如下：\nSUID-\u0026gt;4 SGID-\u0026gt;2 SBIT-\u0026gt;1 所以如果要为一个文件权限为 \u0026ldquo;-rwxr-xr-x\u0026rdquo; 的文件设置 SUID 权限，需要在原先的 755 前面加上 4，也就是 4755：\n$ chmod 4755 filename 同样，可以用 2 和 1 来设置 SGID 和 SBIT 权限。设置完成后分别会用 s, s, t 代替文件权限中的 x。\n其实，还可能出现 S 和 T 的情况。s 和 t 是替代 x 这个权限的，但是，如果它本身没有 x 这个权限，添加 SUID、SGID、SBIT 权限后就会显示为大写 S 或大写 T。比如我们为一个权限为 666 的文件添加 SUID、SGID、SBIT 权限：\n$ chmod 666 nickfile $ ll nickfile -rw-rw-rw- 1 nick nick 0 Mar 2 21:03 nickfile $ chmod 7666 nickfile $ ll nickfile -rwSrwSrwT 1 nick nick 0 Mar 2 21:03 nickfile 通过符号类型改变权限\n除了使用数字来修改权限，还可以使用符号：\n$ chmod u+s testfile # 为 testfile 文件加上 SUID 权限。 $ chmod g+s testdir # 为 testdir 目录加上 SGID 权限。 $ chmod o+t testdir # 为 testdir 目录加上 SBIT 权限。 umask 默认权限 为了查看用户创建的文件和目录的默认权限，我们用一个普通的用户创建文件 myfile 和目录 mydir 并查看它们的默认权限：\n$ touch myfile $ mkdir mydir $ ll total 4.0K drwxrwxr-x 2 nick nick 4.0K Mar 2 21:09 mydir -rw-rw-r-- 1 nick nick 0 Mar 2 21:09 myfile 目录的权限为 775，文件的权限为 664。默认情况下对于目录来说最大的权限是 777，对于文件来说最大的权限一般为 666(只有可以执行的文件才添加可执行权限)。所以我们创建的文件和目录的共同特点是从最大权限中减其他用户的写权限。而这个被减去的值就是我们常说的 umask。umask 还是 bash 的一个内置命令，默认输出当前用户的 umask 值：\n$ umask 002 注意，umask 显示的值为从默认的最大权限中减去的值。\n默认策略 系统在用户登录时通过 login 程序调用 pam_umask 模块设置用户默认的 umask。从 login 程序的配置文件 /etc/login.defs 中我们可以找到 umask 相关的配置：\n... UMASK 022 ... USERGROUPS_ENAB yes ... 用户的默认 umask 应该是 022，但当 USERGROUPS_ENAB 被设置为 yes 时(默认值)，对于 uid 和 gid 相同且用户名和主组名相同的用户，系统会把其 umask 改为 002。\n于 root 用户的特殊性，它默认的 umask 与其它用户是不同的，其值为 022：\n# umask 0022 第一个 0 表示 8 进制，这里我们可以暂时忽略它。\n命令 umask 是 bash 的一个内置命令，用来显示或设置新建文件/目录的权限掩码(umask)。前面我们以数字的方式输出了用户默认的 umask 值，这次我们以符号的方式进行输出：\n$ umask -S u=rwx,g=rwx,o=rx 以符号输出的就是用户创建目录时的默认权限，也就是 775。\n为了改变用户创建的文件/目录的默认值，我们可以改变 umask 的默认值。\n设置 umask 值\n最简单的方式就是为 umask 命令指定一个数字：\n$ umask 026 026 的含义为：去掉 group 中的写权限，去掉 other 中的读写权限。\n这时创建的文件权限为 640，目录权限为 751。注意，修改 umask 后只有新建的文件和目录受影响，已经存在的文件和目录的权限不会被影响。\n以符号的方式设置 umask 值\n比如下面的命令：\n$ umask u=,g=w,o=rwx 上面的命令表示从 group 中去掉写权限，从 other 中去掉读写执行的权限。\n注意：\u0026quot;=\u0026quot; 号在 umask 命令和 chmod 命令中的作用恰恰相反。在 chmod 命令中，利用它来设置指定的权限，而其余权限则被删除。但是在 umask 命令中，将在原有权限的基础上删除指定的权限。\n在 ~/.bashrc 文件中为用户设置默认的 umask\n如果让用户每次登陆后都执行 umask 命令修改默认的 umask 值是不科学的，我们可以在用户的 ~/.bashrc 文件中执行 umask 命令，这样用户登录后 umask 的值自动就变成了设置的值。把下面的命令添加到 ~/.bashrc 文件的最后一行：\numask 026 与 ACL 如果一个目录没有被设置 default ACL，那么将由 umask 决定新文件的 ACL 权限。这种情况其实就是我们常见的没有 ACL 权限时的情况。比如我们设置 umask 为 026，那么创建的文件和目录的权限就是由它决定的。\n如果一个目录被设置了 default ACL，那么将会由文件创建函数的 mode 参数和目录的 default ACL 共通决定新文件的 ACL 权限，此时 umask 被忽略。还以 umask 026 为例，我们创建一个目录 dir2 并设置 default ACL 权限：\n$ setfacl -m d:u:tester:rwx dir2 $ getfacl dir2 # file: dir2 # owner: nick # group: nick user::rwx group::r-x other::--x default:user::rwx default:user:tester:rwx default:group::rwx default😷:rwx default:other::r-x 然后在 dir2 目录中创建文件 testfile：\n$ dir2 touch testfile $ dir2 ll testfile -rw-rw-r--+ 1 nick nick 0 Mar 2 21:26 testfile 这次 testfile 的权限已经不受 umask 的影响了！\nACL ACL的全称是 Access Control List (访问控制列表) ，一个针对文件/目录的访问控制列表。它在UGO权限管理的基础上为文件系统提供一个额外的、更灵活的权限管理机制。它被设计为UNIX文件权限管理的一个补充。ACL允许你给任何特定的用户或用户组设置任何文件/目录的访问权限。\nACL需要Linux内核和文件系统的配合才能工作，大多数Linux发行版本默认都是支持的。但最好还是能够先检查一下：\n$ sudo tune2fs -l /dev/sda1 | grep \u0026#34;Default mount options:\u0026#34; Default mount options: user_xattr acl 设置权限 可以使用setfacl和getfacl命令来设置或观察文件/目录的acl权限。\n当前用户是 nick，再创建两个用户 tester 和 tester1 用来进行测试：\n$ sudo adduser tester 创建文件 aclfile，检查其默认的权限信息：\n$ touch aclfile $ ll aclfile -rw-rw-r-- 1 nick nick 0 Mar 2 21:40 aclfile $ getfacl aclfile # file: aclfile # owner: nick # group: nick user::rw- group::rw- other::r-- 把用户切换为 tester，发现没有写文件的权限：\n$ echo \u0026#34;hello\u0026#34; \u0026gt;\u0026gt; aclfile bash: aclfile: Permission denied 这是因为 other 没有写 aclfile 文件的权限。\n下面我们为 tester 用户赋予读写 aclfile 文件的权限：\n$ setfacl -m u:tester:rw aclfile 修改成功后再次以 tester 用户的身份向 aclfile 文件写入数据，这次已经可以正常写入了。查看 aclfile 文件的权限：\n$ getfacl aclfile # file: aclfile # owner: nick # group: nick user::rw- user:tester:rw- group::rw- mask::rw- other::r-- 多出了一些信息，其中比较重要的是 user:tester:rw-，就是它让用户 tester 具有了读写 aclfile 的权限。\n针对用户组来设置权限和针对用户的设置几乎一样，只是把小写的 u 换成小写的 g 就行了。\n继承权限 acl 能让创建的子文件或者子文件夹继承父文件夹的权限设置！\n$ mkdir mydir $ ll -d mydir drwxrwxr-x 2 nick nick 4.0K Mar 2 21:09 mydir $ setfacl -m d:u:tester:rwx mydir $ getfacl mydir # file: mydir # owner: nick # group: nick user::rwx group::rwx other::r-x default:user::rwx default:user:tester:rwx default:group::rwx default😷:rwx default:other::r-x 这次多出了一些以 default 开头的行，这些 default 权限信息只能在目录上设置，然后会被目录中创建的文件和目录继承。下面分别在 mydir 目录下创建文件 testfile 和目录 testdir，并查看它们的 acl 权限：\n$ touch testfile $ mkdir testdir $ getfacl testfile # file: testfile # owner: nick # group: nick user::rw- user:tester:rwx group::rwx mask::rw- other::r-- 从上面可以看到文件 testfile 继承了父目录的 acl 权限，因此用户 tester 对它有读写权限。下面再看看 testdir 目录：\n$ getfacl testdir # file: testdir # owner: nick # group: nick user::rwx user:nick:rwx group::rwx mask::rwx other::r-x default:user::rwx default:user:tester:rwx default:group::rwx default😷:rwx default:other::r-x 从图中可以看出，testdir 目录不仅继承了 tester 的访问权限，还继承了父目录上的 default 权限。也就是说我们通过这种方式设置在目录上的权限可以被子目录递归的继承下去。\n操作权限 更改 -m 选项其实是在更改文件和目录的 ACL 权限\n 当一个用户或组的 ACL 权限不存在时，-m 选项执行的是添加操作， 如果一个用户或组的 ACL 权限已经存在时，-m 选项执行的是更新操作。  $ setfacl -m u:tester:rwx aclfile $ setfacl -m u:tester:rw aclfile -set 选项会先清除掉原有的 ACL 权限，然后添加新的权限\n$ setfacl --set u::rw,u:tester:rwx,g::r,o::- aclfile $ getfacl aclfile # file: aclfile # owner: nick # group: nick user::rw- user:tester:rwx group::r-- mask::rwx other::--- 需要注意的是一定要包含 UGO 权限的设置，不能象 -m 一样只包含 ACL 权限。o::- 是另一个需要注意的地方，其完整的写法是 other::-，就像 u::rw 的完整写法是 user::rw- 一样。通常我们可以把 \u0026ldquo;-\u0026rdquo; 省略，但是当权限位只包含 \u0026ldquo;-\u0026rdquo; 时，就至少要保留一个。如果写成了o::，就会报错。\n删除 通过 setfacl 命令的 -x 选项来删除指定用户或组的 ACL 权限，还可以通过 -b 选项来清除文件和目录上所有的 ACL 权限。\n下面通过 -x 选项删除 user tester 的 ACL 权限，注意命令中只指定了用户的名称而没有指定权限信息：\n$ getfacl aclfile # file: aclfile # owner: nick # group: nick user::rw- user:tester:rwx group::rw- mask::rwx other::r-- $ setfacl -x u:tester aclfile $ getfacl aclfile # file: aclfile # owner: nick # group: nick user::rw- group::rw- mask::rw- other::r-- 下面通过 -b 选项一次性删除 aclfile 上所有的 ACL 权限：\n$ setfacl -b aclfile getfacl aclfile # file: aclfile # owner: nick # group: nick user::rw- group::rw- other::r-- 备份和恢复 常见的文件操作命令 cp 和 mv 等都支持 ACL 权限，只是 cp 命令需要加上 -p 参数。但是 tar 等常见的备份工具不会保留目录和文件的 ACL 权限信息。如果希望备份和恢复带有 ACL 权限的文件和目录，可以先把 ACL 权限信息备份到一个文件里，然后再用 -restore 选项来恢复这些信息。\n使用下面的命令导出 acldir 目录的 ACL 权限信息并保存到文件 acldir.acl 文件中：\n$ getfacl -R acldir \u0026gt; acldir.acl 通过下面的命令把它们的 ACL 权限都恢复回来：\n$ setfacl --restore acldir.acl 实现原理 ACL 条目\n进程权限 ugo 权限信息是文件的属性，它指明了用户与文件之间的关系。但是真正操作文件的却是进程，也就是说用户所拥有的文件访问权限是通过进程来体现的。\n概念：\n  用户 对于支持多任务的 Linux 系统来说，用户就是获取资源的凭证。\n  权限 权限用来控制用户对计算机资源(CPU、内存、文件等)的访问，一般会分为认证和授权两步。比如用户先经过认证机制(authentication)登录系统，然后由授权系统(authorization)对用户的操作进行授权。\n  进程 进程是任何支持多道程序设计的操作系统中的基本概念。通常把进程定义为程序执行时的一个实例。因此，如果有 10 个用户同时运行 vi，就会有 10 个独立的进程(尽管它们共享同一份可执行代码)。\n实际上，是进程在帮助我们完成各种任务。进程就是用户访问计算机资源的代理，用户执行的操作其实是带有用户身份信息的进程执行的操作。\n  进程权限 既然是进程在为用户执行具体的操作，那么当用户要访问系统的资源时就必须给进程赋予权限。也就是说进程必须携带发起这个进程的用户的身份信息才能够进行合法的操作。\n  登陆过程 在 Linux 系统启动后，init 系统会 fork 出子进程执行 /sbin/getty 程序等待用户登录。当用户进行登录操作时，该子进程通过 exec 函数开始执行 /bin/login 程序(此时该进程已经变成了 login 进程)。由 login 进程验证我们的用户名和密码并查询 /etc/passwd 和 /etc/shadow 确定其合法性。如果是合法的用户，该进程再次通过 exec 函数执行用户的默认 shell 程序，此时的 login 进程就变成了 shell 进程(笔者机器上是 bash 进程)。并且**该 shell 进程的有效身份被设置成为该用户的身份，之后 fork 此 shell 进程的子进程都会继承该有效身份。**我们可以通过下图来理解用户从 tty 登录系统的过程：\n简单点说就是：用户登录后， shell 进程的有效用户就是该用户。\nuser id 通过 cat /proc/\u0026lt;PID\u0026gt;/status 命令，我们可以查看到进程所属的用户和组相关的信息：\nUid: 1000 1000 1000 1000 Gid: 1000 1000 1000 1000 通过 man proc 可以查询到第一行的四个数字分别是 real user id, effective user id, saved set user id 和 filesystem UID，第二行则是对应的组 ID。\nreal user id\nreal user id 是执行进程者的 user id，一般情况下就是用户登录时的 user id。子进程的 real user id 从父进继承。通常这个是不更改的，也不需要更改。比如我以用户 nick 登录 Linux 系统，我接下来运行的所有命令的进程的 real user id 都是 nick 的 user id。\neffective user id\n如果要判断一个进程是否对某个文件有操作权限，验证的是进程的 effective user id，而不是 real user id。\n通常不建议直接使用 root 用户进行操作的，但是在很多情况下，程序可能需要特殊的权限。比如 passwd 程序需要 root 权限才能够为普通用户修改密码，一些 services 程序的操作也经常需要特殊的权限。为此，Linux 中设计了一些特殊的权限（SUID/SGID/SBIT）。这里我们以 passwd 程序为例，为二进制可执行文件 /usr/bin/passwd 设置 set-user-id bit=ON，这个可执行文件被用 exec 启动之后的进程的 effective user id 就是这个可执行文件的 owner id，而并非父进程的 real user id。如果 set-user-id bit=OFF 的时候，这个被 exec 起来的进程的 effective user id 应该是等于进程的 user id 的。\n其实我们通过 ps aux 查看的结果中，第一列显示的就是进程的 effective user。\nsaved set user id\nsaved set user id 相当于是一个 buffer，在 exec 函数启动之后，它会拷贝 effective user id 位的信息覆盖自己。\n对于非 root 用户来说，可以在未来使用 setuid() 函数将 effective user id 设置成为 real user id 或 saved set user id 中的任何一个。但是不允许非 root 用户用 setuid() 函数把 effective user id 设置成为任何第三个 user id。\n对于 root 用户来说，调用 setuid() 的时候，将会设置所有的这三个 user id。\n外部命令 在 shell 中执行的命令分为内部命令和外部命令两种。\n 内部命令：内建的，相当于 shell 的子函数 外部命令：在文件系统的某个路径下的一个可执行文件  外部命令的执行过程如下：\n Shell 通过 fork() 函数建立一个新的子进程，新的子进程为当前 shell 进程的一个副本。 在新的进程里，从 PATH 变量所列出的目录中寻找指定的命令程序。当命令名称包含有斜杠(/)符号时，将略过路径查找步骤。 在新的进程里，通过 exec 系列函数，以所找到的新程序替换 shell 程序并执行。 子进程退出后，最初的 shell 会接着从终端读取并执行下一条命令。  我们通过下面的例子来理解在 shell 中执行外部命令的过程，例子很简单就是通过 cat 命令查看一个文本文件 test.log：\n$ cat test.log 我们先来检查一下当前用户以及相关文件的权限：\n$ uid=1000(nick) gid=1000(nick) groups=1000(nick),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),120(lpadmin),132(lxd),133(sambashare) $ ll /bin/cat -rwxr-xr-x 1 root root 43K Sep 5 2019 /bin/cat $ ll test.log -rw-rw-r-- 1 nick nick 0 Mar 2 23:25 test.log 当前用户 nick 的 real user id 为 1000，/bin/cat 文件的所有者为 root，但是所有人都有执行权限，test.log 文件的所有者为 nick。我们结合下图来介绍 cat test.log 命令的执行过程：\n当我们在 shell 中执行一个外部程序的时候，默认情况下进程的 effective user ID 等于 real user ID，进程的 effective group ID 等于 real group ID(接下来的介绍中省略 group ID)。当我们以用户 nick 登录系统，并在 bash 中键入 cat test.log 命令并回车后。Bash 先通过 fork() 建立一个新的子进程，这个新的子进程是当前 bash 进程的一个副本。新的进程在 PATH 变量指定的路径中搜索 cat 程序，找到 /bin/cat 程序后检查其权限。/bin/cat 程序的所有者为 root，但是其他人具有读和执行的权限，所以新进程可以通过 exec 函数用 cat 程序的代码段替换当前进程中的代码段(把 /bin/cat 程序加载到了内存中，此时的进程已经变成了 cat 进程，cat 进程会从 _start 函数开始执行)。由于 cat 进程是由用户 nick 启动的，所以 cat 进程的 effective user ID 是 1000(nick)。同时 cat 进程的 effective user ID 和 test.log 文件的 owner ID 相同(都是 1000)，所以 cat 进程拥有对此文件的 rw- 权限，那么顺理成章地就可以读写 test.log 文件的内容了。\n脚本 在 shell 中执行脚本的方式和执行外部命令的方式差不多，比如我们要执行下面的脚本：\n$ /bin/bash ./test.sh 这时同样会 fork 出一个子进程。只不过脚本与程序相比没有代码段，也没有 _start 函数，此时 exec 函数就会执行另外一套机制。比如我们在 test.sh 文件的第一行通过 #!/bin/bash 指定了一个解释器，那么解释器程序的代码段会用来替换当前进程的代码段，并且从解释器的 _start 函数开始执行，而这个文本文件被当作命令行参数传给解释器。所以上面的命令执行过程为：Bash 进程 fork/exec 一个子 bash 进程用于执行脚本，子 bash 进程继承父进程的环境变量、用户信息等内容，父进程等待子 bash 进程终止。\n 权限 cgroub sudo fdisk 自动更新 LVM 进程  Capabilities 为了执行权限检查，Linux 区分两类进程：特权进程(其有效用户标识为 0，也就是超级用户 root)和非特权进程(其有效用户标识为非零)。 特权进程绕过所有内核权限检查，而非特权进程则根据进程凭证(通常为有效 UID，有效 GID 和补充组列表)进行完全权限检查。\n以常用的 passwd 命令为例，修改用户密码需要具有 root 权限，而普通用户是没有这个权限的。但是实际上普通用户又可以修改自己的密码，这是怎么回事？在 Linux 的权限控制机制中，有一类比较特殊的权限设置，比如 SUID(Set User ID on execution)。因为程序文件 /bin/passwd 被设置了 SUID 标识，所以普通用户在执行 passwd 命令时，进程是以 passwd 的所有者，也就是 root 用户的身份运行，从而修改密码。\nSUID 虽然可以解决问题，却带来了安全隐患。当运行设置了 SUID 的命令时，通常只是需要很小一部分的特权，但是 SUID 给了它 root 具有的全部权限。因此一旦 被设置了 SUID 的命令出现漏洞，就很容易被利用。也就是说 SUID 机制在增大了系统的安全攻击面。\nLinux 引入了 capabilities 机制对 root 权限进行细粒度的控制，实现按需授权，从而减小系统的安全攻击面。\n简介 从内核 2.2 开始，Linux 将传统上与超级用户 root 关联的特权划分为不同的单元，称为 capabilites。Capabilites 作为线程(Linux 并不真正区分进程和线程)的属性存在，每个单元可以独立启用和禁用。如此一来，权限检查的过程就变成了：在执行特权操作时，如果进程的有效身份不是 root，就去检查是否具有该特权操作所对应的 capabilites，并以此决定是否可以进行该特权操作。比如要向进程发送信号(kill())，就得具有 capability CAP_KILL；如果设置系统时间，就得具有 capability CAP_SYS_TIME。\n下面是从 capabilities man page 中摘取的 capabilites 列表：\n   capability 名称 描述     CAP_AUDIT_CONTROL 启用和禁用内核审计；改变审计过滤规则；检索审计状态和过滤规则   CAP_AUDIT_READ 允许通过 multicast netlink 套接字读取审计日志   CAP_AUDIT_WRITE 将记录写入内核审计日志   CAP_BLOCK_SUSPEND 使用可以阻止系统挂起的特性   CAP_CHOWN 修改文件所有者的权限   CAP_DAC_OVERRIDE 忽略文件的 DAC 访问限制   CAP_DAC_READ_SEARCH 忽略文件读及目录搜索的 DAC 访问限制   CAP_FOWNER 忽略文件属主 ID 必须和进程用户 ID 相匹配的限制   CAP_FSETID 允许设置文件的 setuid 位   CAP_IPC_LOCK 允许锁定共享内存片段   CAP_IPC_OWNER 忽略 IPC 所有权检查   CAP_KILL 允许对不属于自己的进程发送信号   CAP_LEASE 允许修改文件锁的 FL_LEASE 标志   CAP_LINUX_IMMUTABLE 允许修改文件的 IMMUTABLE 和 APPEND 属性标志   CAP_MAC_ADMIN 允许 MAC 配置或状态更改   CAP_MAC_OVERRIDE 覆盖 MAC(Mandatory Access Control)   CAP_MKNOD 允许使用 mknod() 系统调用   CAP_NET_ADMIN 允许执行网络管理任务   CAP_NET_BIND_SERVICE 允许绑定到小于 1024 的端口   CAP_NET_BROADCAST 允许网络广播和多播访问   CAP_NET_RAW 允许使用原始套接字   CAP_SETGID 允许改变进程的 GID   CAP_SETFCAP 允许为文件设置任意的 capabilities   CAP_SETPCAP 参考 capabilities man page   CAP_SETUID 允许改变进程的 UID   CAP_SYS_ADMIN 允许执行系统管理任务，如加载或卸载文件系统、设置磁盘配额等   CAP_SYS_BOOT 允许重新启动系统   CAP_SYS_CHROOT 允许使用 chroot() 系统调用   CAP_SYS_MODULE 允许插入和删除内核模块   CAP_SYS_NICE 允许提升优先级及设置其他进程的优先级   CAP_SYS_PACCT 允许执行进程的 BSD 式审计   CAP_SYS_PTRACE 允许跟踪任何进程   CAP_SYS_RAWIO 允许直接访问 /devport、/dev/mem、/dev/kmem 及原始块设备   CAP_SYS_RESOURCE 忽略资源限制   CAP_SYS_TIME 允许改变系统时钟   CAP_SYS_TTY_CONFIG 允许配置 TTY 设备   CAP_SYSLOG 允许使用 syslog() 系统调用   CAP_WAKE_ALARM 允许触发一些能唤醒系统的东西(比如 CLOCK_BOOTTIME_ALARM 计时器)    程序文件的 capabilities\n在可执行文件的属性中有三个集合来保存三类 capabilities，它们分别是：\n Permitted Inheritable Effective  在进程执行时，Permitted 集合中的 capabilites 自动被加入到进程的 Permitted 集合中。\nInheritable 集合中的 capabilites 会与进程的 Inheritable 集合执行逻辑与操作，以确定进程在执行 execve 函数后哪些 capabilites 被继承。\nEffective 只是一个 bit。如果设置为开启，那么在执行 execve 函数后，Permitted 集合中新增的 capabilities 会自动出现在进程的 Effective 集合中。\n进程的 capabilities\n进程中有五种 capabilities 集合类型，分别是：\n Permitted Inheritable Effective Bounding Ambient  相比文件的 capabilites，进程的 capabilities 多了两个集合，分别是 Bounding 和 Ambient。\n/proc/[pid]/status 文件中包含了进程的五个 capabilities 集合的信息，我们可以通过下面的命名查看当前进程的 capabilities 信息：\n$ cat /proc/$$/status | grep \u0026#39;Cap\u0026#39; CapInh: 0000000000000000 CapPrm: 0000000000000000 CapEff: 0000000000000000 CapBnd: 000003ffffffffff CapAmb: 0000000000000000 但是这中方式获得的信息无法阅读，我们需要使用 capsh 命令把它们转义为可读的格式：\n$ capsh --decode=0000003fffffffff 使用 getcap 命令和 setcap 命令分别用来查看和设置程序文件的 capabilities 属性。下面我们演示如何使用 capabilities 代替 ping 命令的 SUID。\n因为 ping 命令在执行时需要访问网络，这就需要获得 root 权限，常规的做法是通过 SUID 实现的(和 passwd 命令相同)：\n$ ll /bin/ping -rwsr-xr-x 1 root root 72K Jan 31 2020 /bin/ping $ ll /usr/bin/passwd -rwsr-xr-x 1 root root 67K Jul 15 2021 /usr/bin/passwd 红框中的 s 说明应用程序文件被设置了 SUID，这样普通用户就可以执行这些命令了。\n移除 ping 命令文件上的 SUID 权限：\n$ sudo chmod 755 /bin/ping $ ping baidu.com ping: socket: Operation not permitted 在移除 SUID 权限后，普通用户在执行 ping 命令时碰到了 \u0026ldquo;ping: socket: Operation not permitted\u0026rdquo; 错误。\n为 ping 命令文件添加 capabilities\n执行 ping 命令所需的 capabilities 为 cap_net_admin 和 cap_net_raw，通过 setcap 命令可以添加它们：\n$ sudo setcap cap_net_admin,cap_net_raw+ep /bin/ping $ getcap /bin/ping /bin/ping = cap_net_admin,cap_net_raw+ep $ ping baidu.com PING baidu.com (220.181.38.148) 56(84) bytes of data. 64 bytes from 220.181.38.148 (220.181.38.148): icmp_seq=1 ttl=46 time=33.3 ms 64 bytes from 220.181.38.148 (220.181.38.148): icmp_seq=2 ttl=46 time=40.9 ms 被赋予合适的 capabilities 后，ping 命令又可以正常工作了，相比 SUID 它只具有必要的特权，在最大程度上减小了系统的安全攻击面。\n如果要移除刚才添加的 capabilities，执行下面的命令：\n$ sudo setcap cap_net_admin,cap_net_raw-ep /bin/ping $ getcap /bin/ping /bin/ping = 命令中的 ep 分别表示 Effective 和 Permitted 集合，+ 号表示把指定的 capabilities 添加到这些集合中，- 号表示从集合中移除(对于 Effective 来说是设置或者清除位)。\n","permalink":"https://sakamotokurome.github.io/posts/ubuntup3system/","summary":"Package Management dpkg 管理软件包 dpkg 意即 Debian 包管理器（Debian PacKaGe manager）。dpkg 是一个可以安装、构建、删除及管理 Debian 软件包的命令行工具。 其它的一些工","title":"Ubuntu System"},{"content":"Wine 简介 Wine 是在x86、x86-64容许类Unix操作系统在X Window System运行Microsoft Windows程序的软件。另外，Wine也提供程序运行库（Winelib）来帮助计算机程序设计师将Windows程序移植到类Unix系统；也有不少软件经过Wine测试后发布，比如Picasa、uTorrent、MediaCoder。\nWine通过提供一个兼容层来将Windows的系统调用转换成与POSIX标准的系统调用。它还提供了Windows系统运行库的替代品和一些系统组件的替代品。为了避免著作权问题，Wine主要使用黑箱测试逆向工程来编写。\nWine最早是“Windows Emulator”，即Windows模拟器的缩写，但Wine现在为“Wine Is Not an Emulator”的递归缩写，即Wine不是模拟器。Wine的正确名称是“Wine”，而不是全大写或全小写。\nWine计划在1993年由Bob Amstadt及Eric Youngdale发起，最初目的是为了让16位Windows 3.1程序可以在Linux上执行，但随着电脑和时代的演进，Wine也一路支持到更新的Windows和64位的计算机体系结构。\n由于Windows的DLL为封闭源代码，所以程序员只能由最底层的设计开始，耗费大量的时间来编写和测试，最后达至兼容，这过程是困难且缓慢的。\n在1999年期间，当Corel加入这个计划后，Wine很快便能兼容WordPerfect Office，但Corel不久便停止支持这项计划，所以Wine的发展又逐渐趋缓，一直到2006年Google积极参与这个计划后，Wine的发展才又恢复起色，最后终于在2008年发布首个稳定版，其后便以每两周发布一个新版的速度发展着，除此之外，Google每年所举办的夏日代码大赛活动也对Wine有着不少贡献。\nWine虽然是从Linux开始发展，但现在已经支持多种平台，有BSD、Mac OS X与Solaris-x86，在2013年的自由及开源软件开发者欧洲会议上，Wine的项目领导人Alexandre Julliard（英语：Alexandre Julliard）表示目前将积极支持Android平台。\n在2008年，Wine已经能够完美运行很多知名程序，例如Lotus Notes及Microsoft Office 2007，Photoshop CS2，但其可靠性及稳定性仍有待改善。如果该程序包含本地的微软Windows系统的库，那样Wine便可很顺利运行该程序。\n有些Wine DLLs亦已能完美地取代Windows原来的DLLs，使得有些程序可完美运行。\n最晚到2006年，Wine上面已经可以完全基于Wine DLL完美地运行暴雪发行的多款3D游戏了，如魔兽世界、魔兽争霸等。\n注：以下如果使用zsh，~ 应替换为 $HOME才能正常使用\n安装 使用 Ubuntu 仓库版本\n$ sudo apt install wine 使用 wine 仓库安装最新版本\n如果您之前安装过来自其他仓库的 Wine 安装包，请在尝试安装 WineHQ 安装包之前删除它及依赖它的所有安装包（如：wine-mono、wine-gecko、winetricks），否则可能导致依赖冲突。\n如果您使用的是 64 位系统，请开启 32 bit 架构支持（如果您之前没有开启的话）：\n# Verifying you have 64-bit kernel architecture. $ dpkg --print-architecture # Verifying you have multi-arch support enabled.  $ dpkg --print-foreign-architectures # Enabling multi-arch support. $ sudo dpkg --add-architecture i386 $ sudo apt update 下载添加仓库密钥：\n$ wget -nc https://dl.winehq.org/wine-builds/winehq.key $ sudo apt-key add winehq.key 并添加 Ubuntu 20.04 仓库：\n$ sudo add-apt-repository \u0026#39;deb https://dl.winehq.org/wine-builds/ubuntu/ focal main\u0026#39; 安装：\n$ sudo apt update $ sudo apt install --install-recommends winehq-stable 配置 配置Wine的方式通常有：\n winecfg是Wine的图形界面配置程序。控制台下调用$ winecfg（或指定系统目录：$ WINEPREFIX=~/.系统目录 winecfg）即可启动 control.exe是Windows控制面板的Wine实现，通过$ wine control命令启动 regedit是Wine的注册表编辑器，比较前两者，该工具能配置更多东西。部分常用键值参见：WineHQ\u0026rsquo;s article on Useful Registry Keys  初始设置 通过全局菜单，应用程序 - \u0026gt;附件 - \u0026gt;终端 ，输入命令： winecfg 这将在你的家目录中创建一个隐藏文件夹（.wine），其中包含类似于在Windows中的虚拟C：驱动器以及注册表文件。一旦该目录中创建完，wine配置窗口将出现。该窗口将允许您定制wine的各种设置，其中包括Windows版本，DLL替换，显示设置，驱动器映射，以及应用程序的特定设置。单击OK按钮关闭该窗口。\nWINEPREFIX Wine默认将配置文件和安装的Windows程序保存在~/.wine。这样的目录称为一个\u0026quot;Wine prefix\u0026quot;或\u0026quot;Wine bottle\u0026quot;（下文称“系统目录”）。每次运行Windows程序（包括内置程序，如winecfg）时，系统目录会自动创建（如果缺失）或更新。系统目录中存放有文件夹 ~/.wine/drive_c 相当于Windows下C:\\C盘（更确切的说应是系统盘）。\n通过设置WINEPREFIX环境变量，可以更改Wine系统目录的位置。如果希望让不同的Windows程序使用不同的系统环境或配置，这一变量会非常有用。建议把你安装的不同的Windows程序分给不同的WINEPREFIX，便于打包和隔离。当你要启动这个Windows程序前也记得要设置WINEPREFIX。\n例如，如果您使用 $ env WINEPREFIX=~/.win-a wine-A程序.exe参数来运行一个程序。另一个使用 $ env WINEPREFIX=~/.win-b wine-B程序.exe参数，这两个程序将使用独立的C盘和注册表配置。\n以下命令会建立一个默认的系统目录，且不启动任何Windows程序：\n$ env WINEPREFIX=~/.customprefix wineboot -u WINEARCH 这个WINEARCH 决定了你模拟的Windows是32位或是64位的x86。对应的值为win32及win64，如果你的Unix系统是64位的它就默认是win64。\n发行版所提供的wine一般都有32位及64位两个包，直接对应所模拟的Windows位数，包里面的Unix二进制及运行库也都是对应位数。\n对于64位用户，默认创建的系统目录是64位环境的。若想使用纯32位环境，修改WINEARCH 变量win32为即可： $ WINEARCH=win32 winecfg这样就会生成32位Wine环境。若不设置WINEARCH得到的就是64位环境。\n通过WINEPREFIX变量，在不同的系统目录分别创建32位和64位环境：\n$ WINEARCH=win32 WINEPREFIX=~/win32 winecfg $ WINEPREFIX=~/win64 winecfg 注意： 系统目录创建过程中，64位版本的wine将视全部目录如同64位系统目录，也将不会在已存在的目录中创建任何32位的。创建32位系统目录，您必须让Wine创建指定的WINEPREFIX目录。\nwinetricks也接受WINEPREFIX变量，以安装Steam为例：\n$ WINEARCH=win32 WINEPREFIX=~/.local/share/wineprefixes/steam winetricks steam 编辑 ~/.bashrc，使得 WINEPREFIX 和 WINEARCH 永久生效\nexport WINEPREFIX=$HOME/.config/wine/ export WINEARCH=win32 图形驱动 你需要安装32位的显卡驱动。缺少或未能正确配置驱动的一个标志是 Wine 在终端窗口里报告如下内容：\nDirect rendering is disabled, most likely your OpenGL drivers have not been installed correctly 注意： 在安装对应的库以后，你可能需要重启 X\n声音 Wine程序有可能遇到某些声音问题。首先，确保winecfg中只启用了一种声卡驱动。目前，Wine对Alsa的支持最好。\nMIDI 支持\nMIDI 是九十年代非常流行的游戏声音系统。如果你尝试运行老一点的游戏，音乐无法开箱即用的情况并不罕见。 Wine 拥有非常优秀的 MIDI 支持。但是首先你需要确保 Wine 会使用正确的 MIDI 输出。详细设置参考 Wine Wiki\n字体 中文乱码\n将中文字体copy到对应wine的目录（本地安装的wine是~/.wine，playonlinux是.PlayOnLinux/wineprefix/对应目录）下的drive_c/windows/Fonts/。\n在wine目录下任意位置添加modify_font.reg文件：\nREGEDIT4 [HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows NT\\CurrentVersion\\FontLink\\SystemLink] \u0026#34;Lucida Sans Unicode\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;Microsoft Sans Serif\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;MS Sans Serif\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;Tahoma\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;Tahoma Bold\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;msyh\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;Arial\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;Arial Black\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; 将SourceHanSans.ttc改成自己想改的中文字体。\n在wine命令提示符运行：\n$ regedit modify_font.reg 语言区域\n如果安装的系统LANG不为zh-CN，那么wine运行程序的默认语种也不会是中文，这可能导致一部分乱码。解决这个问题，用\n$ env LANG=zh_CN.UTF-8 wine example.exe 运行程序\n启动器和菜单 Wine不会为内置程序（如winecfg、winebrowser）创建桌面启动器和菜单项。但手动安装的Windows程序通常会自动创建启动器和菜单项。在Windows下，安装程序（如setup.exe）通常会在桌面和开始菜单建立快捷方式，而Wine下会创建遵循freedesktop.org规范的.desktop文件（即启动器，相当于快捷方式）。\n提示： 如果启动器没有自动创建，或者这些文件丢失了，可以尝试使用winemenubuilder修复。\nGnome3 中清理 Wine 菜单启动项\n系统全局的菜单启动器安装在 /usr/share/applications/，清除相应程序的“.desktop”文件即可从整个系统删除该启动器。\n如果这样还是无法解决问题，那么很可能 Wine 的启动器存放在用户级别的 ~/.local/share/applications/wine/Programs/ 目录中。删除相应的“.desktop”文件即可清理对应启动项。删除整个 Programs 文件夹将清理所有 Wine 程序的启动项。\n安装/运行/卸载 Windows 程序 警告： 千万不要以root身份运行Wine！详情参见本文。\n使用wine安装应用程序，可以按照以下步骤：\n 从某个地址下载Windows应用程序.exe（可执行文件）. 把它放在一个方便的目录（例如，桌面或个人文件夹） 打开终端，并且切换到.exe文件所在的目录。 输入命令 wine application-name.exe 。  这将使用Wine启动.EXE。如果它是一个安装程序，它应该像在windows一样的运行。如果应用程序要求目录来安装应用程序，选择把它放在 C:\\Program Files 。\n运行Windows程序格式为 WINEPREFIX=\u0026quot;wine配置文件存放地\u0026quot; wine [路径]程序.exe 参数 ，如：\n$ wine notepad.exe c:/abc.txt $ wine notepad.exe ~/.wine/drive_c/abc.txt 路径可以是Unix路径，也可以是（在有WINEPREFIX情况下的）Windows路径，wine会自动判断。\n对wine来说，你Unix系统里的其他文件（即模拟的C盘之外的文件）的Windows路径都以Z盘开头：\n$ wine notepad.exe z:/home/username/.wine/drive_c/abc.txt 内置的msiexec程序可以运行MSI安装包：\n$ [wine] msiexec /i path_to_msi 还可以通过在终端运行 winefile 使用 Wine 文件浏览器。\n在某些情况下，应用程序需要被从一个特定位置上运行。在这种情况下创建命令启动\n$ sh -c \u0026#34;cd /home/USER/.wine/drive_c/Program Files/APPDIR; wine game.exe\u0026#34; wine uninstaller 这将打开一个类似于Windows的程序“添加/删除程序”控制面板，让您卸载wine安装的应用程序。通过 wine 直接运行卸载程序也应该正常工作。或者，您也可以简单地删除应用程序的文件夹。\n技巧 提示： 此外您可能会感兴趣以下文章的开始所提供的链接\n Wine程序数据库 (Wine Application Database, AppDB) —— 特定Windows程序的Wine兼容情况（运行时的已知问题、用户评分、指南等等），Rating一列由运行结果好到坏为Platinum、Gold、Silver、Bronze、Garbage，无近期结果或近期仍然Silver以下的就放弃吧。 WineHQ论坛 —— 要是看完上述网页还有问题，可以到这里咨询  OpenGL 模式 很多游戏（比如魔兽争霸啦）都支持OpenGL模式，在Wine下可能比默认DirectX模式性能更好。一般添加-opengl启动程序即可，但不同程序可能有所不同：\n$ wine /path/to/3d_game.exe -opengl 请参考AppDB，了解特定程序的相关信息。\nWine 控制台 有些时候，可能需要运行.exe给游戏打补丁，比如给古董游戏添加宽屏支持。这时直接通过Wine运行可能没有用。那么，打开终端，运行一下命令：\n$ wineconsole cmd 将进入一个和Windows下cmd一样的命令行环境。在该环境下试试也许就可以了。\nwinetricks 使用Winetricks快速脚本，能够方便地安装许多Windows组件，包括DirectX、msxml（被Office 2007、IE浏览器依赖）visual运行库还有其他更多的。\n使用 Ubuntu 仓库版本\n$ sudo apt install winetricks 使用 Github 安装最新版本\n$ cd \u0026#34;${HOME}/.local/bin\u0026#34; $ wget https://raw.githubusercontent.com/Winetricks/winetricks/master/src/winetricks $ chmod u+x winetricks 可以用winetricks list-all来看看它支持什么。\nUsing winetricks\n获得 winetricks 后，您只需在控制台输入sh winetricks即可运行它。如果你先chmod +x winetricks ，你也可以使用./winetricks。如果不带参数运行，winetricks 会显示一个带有可用包列表的 GUI。如果您知道要安装的软件包的名称，可以将它们附加到 winetricks 命令，它将立即开始安装过程。例如，\n$ sh winetricks corefonts vcrun6 将安装 corefonts 和 vcrun6 软件包。\n所有 Wine 命令一样，winetricks 知道 WINEPREFIX 环境变量。\n$ env WINEPREFIX=~/.winetest sh winetricks mfc40 拥有多个 Wine 版本的用户可以指定 winetricks 应该使用哪个版本\n$ env WINE=~/wine-git/wine sh winetricks mfc40 使用 ~/wine-git 目录中的 Wine 安装 mfc40 包。\nMono \u0026amp; Gecko Mono 是 .NET Framework 的开源和跨平台实现。Wine 可以使用 Windows 构建的 Mono 来运行 .NET 应用程序。\nWine 实现了自己的 Internet Explorer 版本。该实现基于Mozilla 的 Gecko Layout Engine的自定义版本。\n在 USTC MIRROR 分别下载对应的版本，放入~/.cache/wine就可以了。\nCrossOver CrossOver是Wine的付费、商业化版本，提供更全面的终端用户支持。它包括脚本、补丁、GUI和可能永远不会被Wine项目接受的第三方软件。这种组合使得那些不太懂技术的人运行Windows程序变得相当容易。\n首先在 CrossOver 下载 .bin 安装包，然后要把 .bin 文件设置成可执行的：chmod u+x crossover.bin，接下来运行该文件：./crossover.bin。\n无限试用\ncrossover 有15天的试用期，crossover的时间验证信息写在每一个winebottle容器中，相互是完全隔离（不是写在全局配置中）。即使一个容器过期了，依然可以创建新的容器，并重新计算试用期，所以不需要重装软件本身。\n即使重装程序，已经过期的容器依旧不能用，不过可以删除该容器，或者删除容器下的.eval文件。\n$ rm ~/.cxoffice/**/.eval Tutorials 相对于 wine 而言，CrossOver 更加简洁方便，全程使用 GUI。\n在 Select Application 的时候，即使列表中没有列出你需要安装的 Windows 软件，依旧可以尝试使用默认的 Unlisted application，如一些 roguelike、galgame 游戏是可以直接运行的。\n如果无法运行：\n 确保已安装破解补丁。有的破解组安装程序不会自动或者提供选择框来安装，需要手动覆盖。 如果报错缺少dll，这时就在网上查找一下，比如 sskin.dll，如果教程使用的 winetricks，则可以在 winetricks/files/verbs/all.txt 找到具体的依赖名称，如 Visual C++ 6 SP4 libraries，然后可以在 Select Application 输入依赖名来安装，如果下载慢，也可以通过软件显示的下载链接直接下载。 如果什么错也没报，那么就需要参考 Unsupported Troubleshooting 安装依赖或配置 winecfg，确保在安装游戏的时候没有选择升级依赖（比如 DirectX ）并且之后安装了必要的依赖项。推荐游戏自带的 CommonRedist 或在 WineHQ - Browse Applications、PlayOnLinux、PCGamingWiki 上找依赖，可以但不推荐在虚拟机中运行一下看报错。 如果先是正常运行，之后 wine 报错 page fault 退出，那么可以参考 Gathering debug logs in Crossover Linux 创建 crash log。  凡是依赖解决了，游戏一般是能够运行了，但是运行的好不好，有没有bug就不敢保证了，比如 Skul - The Hero Slayer 是可以直接运行的，但是无法正常显示血量，即使重新安装依赖也是如此。\n以下测试的是运行游戏所必须的依赖：\n  Sekiro Shadows Die Twice\n Microsoft Visual C++ 6.0 (4.2 \u0026amp; 6.0) Redistributable    The Elder Scrolls V Skyrim Special Edition\n DirectX for Modern Games 使用 SkyrimSELauncher.exe 配置，使用 SkyrimSE.exe 启动    Life is Strange - Before the Storm\n 先安装下面两个依赖，如果 FitGirl 报 Getting unarc.dll returned an error code -6，就 try using the set memory limit to 2 gb option；如果是 Miss files，那么就重装。 Microsoft Visual C++ 6.0 (4.2 \u0026amp; 6.0) Redistributable DirectX for Modern Games 游戏需要加载一会儿，这个时候屏幕没反应。    NieR - Automata\n DirectX for Modern Games 如果 unable to input name for profile creation，可以尝试将 CrossOver 升级到最新版本。    Dead Cells\n 参考 [playonlinux/dead cells](playonlinux/dead cells) 的 SourceCode 安装依赖后能够运行 DirectX for Modern Games OpenAL，安装后要在 Wine Configuration \u0026gt; Libraries 中添加 openal32（不加，点击无反应、闪退）（Libraries 中是运行时自动加载进来的库，而需要的 openal32 没有自动加载进来，因此手动添加） Microsoft Visual C++ 6.0 (4.2 \u0026amp; 6.0) Redistributable    The Binding of Isaac Rebirth Repentance\n 要在 Wine Configuration \u0026gt; Libraries 中添加 openal32（不加，点击无反应、闪退） 《以撒的結合：重生》給新玩家的基本攻略    Valiant Hearts The Great War\n Copy over the cracked content from the /Crack directory on the image to your game install directory manually.    DARK SOULS REMASTERED\n 更改语言：In the game installation folder find the \u0026ldquo;steam_emu.ini\u0026rdquo;, open it and find the line with language, change it to schinese.（在 font 目录可以找到所有语言）    Braid\n DirectX for Modern Games    Dying Light Platinum Edition\n Microsoft Visual C++ 6.0 (4.2 \u0026amp; 6.0) Redistributable    Hearth Stone\n DXVK    DXVK 游戏使用 Vulkan 将获取更好的性能，为使用 Vulkan，需启用 DXVK。DXVK provides a Vulkan-based translation layer for DXGI, D3D10 and D3D11, which can be used on Linux with Wine.\n打开 System Information，如果在属性下找到了 \u0026ldquo;vulkan.present\u0026rdquo;=\u0026ldquo;yes\u0026rdquo;，则表示支持 vulkan 并可以安装 DXVK。\n首先安装驱动程序\n$ sudo apt install mesa-vulkan-drivers mesa-vulkan-drivers:i386 libvulkan1 libvulkan1:i386 vulkan-utils 然后像安装普通软件那样，在 Select an Application to install 搜索并选择 DXVK (Upstream) 安装——DXVK (Builtin) 可能会导致游戏无法运行。安装后就自动启用了，也可以通过右键一个 Bottle\u0026gt;Settings\u0026gt;DXVK Vulkan backand for D3D11(Custom) 启用。\nEsync 注：Some Windows applications will not work correctly which ESync enabled. 例如 My Friend Pedro 开了后闪退，应该先保证正确运行，再考虑提升性能。\nWhat is \u0026ldquo;wine esync\u0026rdquo; and how should I set it up?\nthe thing with Far Cry 4, 3 and Primal also Dirt Rally in wine is that it massively loads wineserver and synchronizing all the time, so it is stuck at around 20 fps on ryzen, all those games mentioned. with esync, wineserver is skipped for synchronizing and eventfd is being used, thus increasing performance that much. Games that are CPU bound with wineserver having huge load (wineserver is singlethreaded) benefit the most of this\nWhat is the function of esync? Why most games need it disabled?\nThe function of esync is to provide lightweight thread synchronization facilities (events/semaphores/mutexes) so that game code that uses them heavily will run faster.\nIt does this using a linux-specific facility called eventfd, which is built around file descriptors. These are a limited resource normally not needed in large quantities, and therefore traditionally made available to a process only in moderate quantities. This helps prevent runaway processes and malicious code from consuming so many descriptors that none are left for other processes (a denial of service).\nTherefore, when a game that uses tens of thousands of thread synchronization objects is run with esync, it will fail unless the system\u0026rsquo;s per-process file descriptor limit is much higher than the traditional default. Some linux distributions have already adopted a high default, while others still default to a thousand or so. That\u0026rsquo;s why these games run fine with esync on some distributions but fail on others unless the system\u0026rsquo;s DefaultLimitNOFILE setting is increased.\nEdit: If you\u0026rsquo;re interested in esync technical issues that are not distribution-specific, check out this comment.\nHowToEsync What is Esync?\nEsync removes wineserver overhead for synchronization objects. This increases performance for a lot of games, especially ones that rely heavily on multithreading.\nA more detailed explanation can be found here.\nHow to check Esync compatibility\nSystems using Systemd 240 and newer are already compatible with Esync.\nIf you\u0026rsquo;re unsure that your system is compatible, run the ulimit -Hn command. If the value printed is equal to or greater than 524288, then your system is Esync-compatible.\nHow to make your system Esync compatible\nIf your system is not Esync-compatible (ulimit -Hn, which prints the limit for number of opened files for a process, prints a value lower than 524288, like 4096), you have 2 different methods of solving this problem. Which method is preferable depends on the distribution currently in use. Applying both methods should have no negative side effect.\n Modifying Systemd configuration  This method applies to Ubuntu and other systems using systemd. You (with root privileges or sudo) need to edit both /etc/systemd/system.conf and /etc/systemd/user.conf by adding DefaultLimitNOFILE=524288. If DefaultLimitNOFILE= already exists in both system.conf and user.conf, add 524288 after = and make sure to uncomment the line (remove the # in the beginning of the line) to make it functional.\nOnce the files are edited, restart your computer for the changes to take effect. To verify if the limits were applied, run ulimit -Hn to see 524288 being reported.\nIf the value printed still says something like 4096, try the ulimits method below.\nModifying ulimits.conf  On Linux distributions not using Systemd or distributions using pam-limits.conf (Arch Linux, Fedora, Solus,\u0026hellip; ), you (with root privileges or sudo) need to edit /etc/security/limits.conf.\nChange username to your actual username. Once the file is edited, reboot for the changes to take effect, and verify by running ulimit -Hn to see the new limit (524288).\nusername hard nofile 524288 中文乱码 注：某些游戏会因为语言设置而无法运行。\n修改步骤：打开容器 C:Drive，返回到顶层文件夹（即容器名称），即可找到cxbottle.conf，在文件最后面添加如下内容：\n[EnvironmentVariables] \u0026#34;LANG\u0026#34; = \u0026#34;zh_CN.UTF-8\u0026#34; 也可以像安装软件那样，在搜索框里搜索 “chinese”，然后选择 “Setting bottle\u0026rsquo;s language to Simplifiled Chinese”\nThird-party apps Bottles Proton How To Use Steam Proton To Play Windows Games On Linux?\nEnabling the Proton\n  Fire up the Steam app from the app menu.\n  In the top-left corner of the app, click on Steam and then click on Settings.\n  In the sidebar, find and click on Steam Play.\n  Click Enable Steam Play for supported titles and Enable Steam Play for all other title options.\n  Can I Install Non-Steam Games Using Proton?\n Download the official launcher \u0026ldquo;Add non-Steam game\u0026hellip;\u0026rdquo; -\u0026gt; Show all files -\u0026gt; Select the launcher executable -\u0026gt; Done Setup proton (if not done using global settings)  Navigate: Gear icon -\u0026gt; \u0026ldquo;Settings\u0026rdquo; -\u0026gt; \u0026ldquo;Compatibility\u0026rdquo; Check \u0026ldquo;Force compatibility layer \u0026hellip;\u0026rdquo; Select Proton 5.13 or newer   Update the target. Gear icon -\u0026gt; \u0026ldquo;Settings\u0026rdquo;:  Target: explorer.exe Execution directory: /path/to/your/gi/installation/ Start options: /desktop=anyname,1920x1080 cmd /c launcher.bat Adjust the screen resolution above, if necessary.    PlayOnLinux Lutris 可以参考其安装脚本。\n实例 Office 2013 Pro 注：在安装前先在 AppDB 中查找要安装的应用，在 Test Results 部分有相关教程，如 Microsoft Office 2013 Test Results\n注：要提高安装成功率，第一，不同 wine 版本安装结果是不同的，AppDB 有相应的信息；第二，winetricks 如果提供安装镜像的话，一定要用该镜像，winetrics 是一个很大的脚本，打开脚本搜索 office2013pro 即可找到官方镜像下载链接；第三，如果第一次安装失败，可以再尝试安装一次。\nI installed office 2013 and I used to get a black window after starting it up. I fixed the black screen by following the solution posted in the [WineHQ-Forum](https://forum.winehq.org/viewtopic.php?f=8\u0026amp;t=28446\u0026amp;p=109296\u0026amp;hilit=office 2013#p109284).\nHere\u0026rsquo;s what I did:\nInstall Components\n$ sudo apt install winbind cabextract Create Clean 32bit Prefix for Win7\nCrete a clean 32 bit prefix and start up winecfg:\n$ env WINEPREFIX=~/.wine-office2013pro WINEARCH=win32 winecfg In the winecfg applications tab select \u0026ldquo;Windows version: Windows 7\u0026rdquo; Close wine config and install winetricks\nInstall Libraries\nThen start winetricks for your prefix\n$ env WINEPREFIX=~/.wine-office2013pro WINEARCH=win32 winetricks accept \u0026ldquo;select the default wineprefix\u0026rdquo; with OK. Now, select \u0026ldquo;Install Windows DLL components\u0026rdquo; and go and install msxml6（这个时候会下载 msxml6，可以手动下载后移动到~/.cache/winetricks中）\nTo fix the problem in PowerPoint (not enough memory), I added two overrides with winecfg in Library section: \u0026ldquo;riched20\u0026rdquo; and \u0026ldquo;usp10\u0026rdquo;.\n如果是中文软件需安装中文字体。\n在这里我直接使用 winetrics 成功安装 office2013pro（wine 6）：\n$ env WINEPREFIX=~/.wine-office2013pro WINEARCH=win32 winetricks office2013pro 这样下面步骤不需要了。\nFix Black Window\nIn order to fix the black window that impedes Office 13 to be used, add the HKCU\\Software\\Wine\\Direct3D\\MaxVersionGL new DWORD value 30002 (hexa) to the registry.\nHere\u0026rsquo;s how to do this: In Winetricks select Run regedit and wait for the Registry Editor window to open. In the folder tree expand HKEY_CURRENT_USER - Software - Wine and create a new key in the Wine folder. To do so, right click, select new\u0026ndash;\u0026gt;key and name it Direct3D. Now create new\u0026ndash;\u0026gt;DWORD Value, rename the file to MaxVersionGL and set the value data to 30002 (hexadecimal). Close the Registry Editor window.\nClose the winetricks window and run installer:\nInstall Office 2013\n$ env LANG=zh_CN.UTF-8 WINEPREFIX=~/.wine-office2013pro WINEARCH=win32 wine ~/PathTo/Office2013Setup.x86.exe From here, the install runs and completes 100%.\n安装后可以在 ~/.local/share/applications/wine 下找到 微信、QQ 的 .desktop 文件，右键编辑，将 Exec=env 行改为 Exec=env LANG=zh_CN.utf8\nGenshin Impact GI-on-Linux（已验证可玩）or Play another game. Format: link, caveats (Proton/Wine rating)\n Blue Protocol, unreleased, 2022 (N/A) Tower of Fantasy, unreleased, 2022 (N/A) Wuthering Waves, unreleased, 20?? (N/A) Scarlet Nexus, singleplayer (Platinum) Little Witch Nobeta singleplayer (Gold) Ashen (Platinum) Tower Hunter: Erza\u0026rsquo;s Trial singleplayer, 2D scroller (Platinum) Haven PEGI 18 (Gold) Valheim no story (Native) Pine no story, singleplayer (Native)  darling Darling is a translation layer that lets you run macOS software on Linux\nAnbox Anbox 简介 Anbox 是 “Android in a box” 的缩写。Anbox 是一个基于容器的方法，可以在普通的 GNU/Linux 系统上启动完整的 Android 系统。\nAnbox 可以让你在 Linux 系统上运行 Android，而没有虚拟化的迟钝，因为核心的 Android 操作系统已经使用 Linux 命名空间（LXE）放置到容器中了。\nAndroid 容器不能直接访问到任何硬件，所有硬件的访问都是通过在主机上的守护进程进行的。\n每个应用程序将在一个单独窗口打开，就像其它本地系统应用程序一样，并且它可以显示在启动器中。\n安装使用 Anbox 也可作为 snap 软件包安装，请确保你已经在你的系统上启用了 snap 支持。\n为使 Anbox 工作，确保需要的内核模块已经安装在你的系统中。对于基于 Ubuntu 的用户，使用下面的 PPA 来安装它。\n$ sudo add-apt-repository ppa:morphis/anbox-support $ sudo apt update $ sudo apt install linux-headers-generic anbox-modules-dkms 在你安装 anbox-modules-dkms 软件包后，你必须手动重新加载内核模块，或需要系统重新启动。\n$ sudo modprobe ashmem_linux $ sudo modprobe binder_linux 安装 anbox。\n$ sudo apt install anbox 如果你已经在你的系统上安装 snap，其它的步骤可以忽略。\n$ sudo snap install --devmode --beta anbox 默认情况下，Anbox 并没有带有 Google Play Store。因此，我们需要手动下载每个应用程序（APK），并使用 Android 调试桥（ADB）安装它。\n$ sudo apt install android-tools-adb 既然我们不能使用 Play Store ，你就得从信得过的网站来下载 APK 软件包，像 APKMirror ，然后手动安装它。\n首先，你需要启动 ADB 服务。为做到这样，运行下面的命令。\n$ adb devices 安装语法格式：\n$ adb install Name-Of-Your-Application.apk QEMU KVM QEMU 的图形前端 与其他的虚拟化程序如 VirtualBox 和 VMware 不同, QEMU不提供管理虚拟机的GUI（运行虚拟机时出现的窗口除外），也不提供创建具有已保存设置的持久虚拟机的方法。除非您已创建自定义脚本以启动虚拟机，否则必须在每次启动时在命令行上指定运行虚拟机的所有参数。\nLibvirt提供了一种管理 QEMU 虚拟机的便捷方式。有关可用的前端，请参阅 libvirt 客户端列表。\n创建新虚拟系统 创建硬盘镜像 除非直接从 CD-ROM 或网络引导（并且不安装系统到本地），运行 QEMU 时都需要硬盘镜像。硬盘镜像是一个文件，存储虚拟机硬盘上的内容。\n一个硬盘镜像可能是 raw镜像, 和客户机器上看到的内容一模一样，并且将始终使用主机上的来宾硬盘驱动器的全部容量。此方法提供的I / O开销最小，但可能会浪费大量空间，因为guest虚拟机上未使用的空间无法在主机上使用。\n另外一种方式是qcow2 格式，仅当客户系统实际写入内容的时候，才会分配镜像空间。对客户机器来说，硬盘大小表现为完整大小，即使它可能仅占用主机系统上的非常小的空间。此映像格式还支持QEMU快照功能。但是，使用此格式而不是 raw 可能会影响性能。\nQEMU 提供 qemu-img命令创建硬盘镜像.例如创建一个 4 GB raw 格式的镜像:\n$ qemu-img create -f raw image_file 4G 您也可以用 -f qcow2 创建一个 qcow2 镜像。\n用 dd 或 fallocate 也可以创建一个 raw 镜像。\n警告： 如果硬盘镜像存储在 Btrfs 系统上，则应在创建任何映像之前考虑禁用该目录的写时复制。\n调整镜像大小 警告： 调整包含NTFS引导文件系统的镜像将无法启动已安装的操作系统，推荐在操作之前进行备份\n执行 qemu-img 带 resize 选项调整硬盘驱动镜像的大小.它适用于 raw 和 qcow2. 例如, 增加镜像 10 GB 大小, 运行:\n$ qemu-img resize disk_image +10G 在磁盘映像扩容后，必须使用虚拟机内部系统的分区工具对该镜像进行分区并格式化后才能真正开始使用新空间。 在收缩磁盘映像时，必须首先使用虚拟机内部系统的分区工具减少分该分区的大小，然后相应地收缩磁盘映像，否则收缩磁盘映像将导致数据丢失！\n安装操作系统 这是你第一次需要去启动模拟器的步骤，为了在磁盘镜像上安装操作系统，你必须同时将磁盘镜像与安装介质装载到虚拟机上，从安装介质中启动操作系统。\n以i386的客户机为例，为了从CD-ROM内的把可用于启动的ISO文件安装到磁盘镜像上，你需要：\n$ qemu-system-x86_64 -cdrom iso_image -boot order=d -drive file=disk_image,format=raw 在安装完操作系统后，就可以直接从QEMU镜像内启动了。\n注意： 默认情况下仅分配给虚拟机128MB的内存， 分配的内存大小可以通过 -m 调整， 比如 -m 512M 或 -m 2G。\n提示：\n 相较于指定 -boot order=x ，一部分用户感觉使用 -boot menu=on 启用boot菜单的体验更舒服些，至少在配置和实验时是这样的。 当使用无界面（headless）模式时， 将会默认在本地5900端口启动一个VNC服务器， 可以用 TigerVNC 连接到客户机的系统上: vncviewer :5900 若你在安装过程中需要替换软盘或CD，可以使用QEMU机器监视器（在虚拟机窗口中按Ctrl + Alt + 2）来删除存储设备并将其连接到虚拟机。使用info block查看块设备，然后使用change命令换出设备。按下Ctrl + Alt + 1返回虚拟机。  运行虚拟化的系统 qemu-system-* 程序 (例如 qemu-system-i386 或 qemu-system-x86_64, 取决于客户机架构)用来运行虚拟化的客户机. 用法是:\n$ qemu-system-i386 options disk_image 所有 qemu-system-*的选项是相同的。\n默认 QEMU会在窗口中显示虚拟机的视频输出。有一点要记住：当您单击QEMU窗口,鼠标指针被捕获。要放开，按 Ctrl+Alt+g.\n警告： QEMU 不应以 root 身份运行。如果必须以root身份在某个脚本中运行QEMU，那么你需要使用 -runas 选项让QEMU放弃root权限\n启用 KVM KVM 必须要您处理器和内核支持, 和必要的 kernel modules加载。更多信息参见 KVM。\n要在KVM模式中启动QEMU, 追加 -enable-kvm到启动选项. 要检查是否为正在运行的 VM 启用了 KVM，请使用 Ctrl+Alt+Shift+2 进入 QEMU Monitor，然后键入 info kvm。\n注意：\n -machine 选项中的 accel=kvm 参数与-enable-kvm 或 -accel kvm 选项是等价的。 CPU模型 host 需要 KVM。 如果你使用GUI工具去启动QEMU，但是性能体验极差，那么最好检查一下是否真的开启了KVM支持，因为QEMU可能选择了备用的模拟模式，即软件级模拟。 需要启用KVM才能正常启动windows7和windows8，否则会出现“蓝屏”.  宿主机和虚拟机数据交互 网络 我们可以利用任何支持文件传输的网络协议实现客户机和宿主机之间的数据交互, 例如 NFS, SMB, NBD, HTTP, FTP, 或 SSH, 当然这么做的前提是你已经配置好二者之间的网络，且在系统上启动了相应的服务程序。\n在默认情况下，用户模式的客户机能够通过10.0.2.2这个IP访问到宿主机。任何运行于宿主机上的服务端程序都可以通过这个地址被访问到，比如说我们可以通过这个IP访问到宿主机上的SSH服务器或SMB服务器。因此在这种情况下，客户机能够挂载宿主机通过SMB or NFS暴露出来的目录，也可以访问宿主机上的HTTP服务器等。 通常情况下宿主机无法访问客户机上的服务，不过你也可以通过一些特殊的网络配置达到这个目的 (参阅#Tap 网络)\nQEMU 端口转发 QEMU能够将宿主机的端口转发到客户机上以实现一些功能，例如从宿主机上访问客户机的SSH端口。\n举个例子，将宿主机上的10022端口与客户机上的22 (SSH) 端口进行绑定， 对应的QEMU命令如下：\n$ qemu-system-x86_64 disk_image -nic user,hostfwd=tcp::10022-:22 确认你客户机上的sshd程序正在运行，然后可以通过如下命令连接到客户机的SSH端口\n$ ssh guest-user@localhost -p 10022 你可以用 SSHFS 把客户机的整个文件系统都挂到宿主机上，这样就可以在宿主机上对客户机的文件系统进行读写了。\n想进行多端口转发的话, 只需要在-nic参数中指定多个hostfwd, 以VNC端口为例:\n$ qemu-system-x86_64 disk_image -nic user,hostfwd=tcp::10022-:22,hostfwd=tcp::5900-:5900 QEMU 的内置SMB服务器 QEMU的文档中指出它有一个内置的SMB服务器，但实际上，它只是在宿主机上加载一个自动生成的smb.conf配置文件 (位于/tmp/qemu-smb.random_string)，然后启动宿主机上的Samba，使得客户机能够通过一个IP地址进行访问 (默认的IP地址是10.0.2.4)。这个方法只适用于用户网络，在你不想在宿主机开启通常的Samba服务 (客户机同样能访问这类Samba服务) 时这个方法还挺好用的。\n宿主机上必须安装 Samba。通过如下QEMU命令启用这项特性:\n$ sudo apt install samba $ qemu-system-x86_64 disk_image -net nic -net user,smb=shared_dir_path shared_dir_path 就是你想要在宿主机和客户机之间共享的目录。\n接着，在客户机内，你应该能够通过10.0.2.4访问到名为qemu的共享文件夹。例如在Windows Explorer中前往 \\\\10.0.2.4\\qemu 这个地址。\n注意：\n 如果你像这样多次指定共享选项 -net user,smb=shared_dir_path1 -net user,smb=shared_dir_path2 or -net user,smb=shared_dir_path1,smb=shared_dir_path2 qemu只会共享参数中最后的一个目录。 如果你不能访问共享文件夹且客户机系统为 Windows, 请检查 NetBIOS 协议是否被启用 并确认防火墙没有屏蔽NetBIOS协议的 端口 如果你不能访问共享文件夹且客户机系统为 Windows 10 Enterprise 或 Education 或 Windows Server 2016, 请启用游客访问.  打开 本地组策略编辑器 (gpedit.msc)。 在控制台树中，依次选择“计算机配置” \u0026gt; “管理模板” \u0026gt; “网络” \u0026gt; “Lanman 工作站”。 对于设置，右键单击“启用不安全的来宾登录”，然后选择“编辑”。 选择“启用”，然后选择“确定”。    共享多个文件夹并在运行时增删文件夹的一个方法是：共享一个空目录，然后在其中创建指向其余共享目录的符号链接。可以用下面的脚本修改SMB服务器的配置，这个脚本还能使宿主机上不允许执行的文件在客户机内拥有执行权限。\n#!/bin/bash eval $(ps h -C smbd -o pid,args | grep /tmp/qemu-smb | gawk \u0026#39;{print \u0026#34;pid=\u0026#34;$1\u0026#34;;conf=\u0026#34;$6}\u0026#39;) echo \u0026#34;[global] allow insecure wide links = yes [qemu] follow symlinks = yes wide links = yes acl allow execute always = yes\u0026#34; \u0026gt;\u0026gt; $conf # in case the change is not detected automatically: smbcontrol --configfile=$conf $pid reload-config 仅当客户机第一次访问到网络驱动后，才能将该脚本启用，并作用于qemu启动的SMB服务器。共享多文件的另一个方法是在配置文件里加入额外的共享路径，就像下面这样\n$ echo \u0026#34;[myshare] path=another_path read only=no guest ok=yes force user=username\u0026#34; \u0026gt;\u0026gt; $conf 这个共享文件夹可以在客户机内通过\\\\10.0.2.4\\myshare访问。\n挂载qcow2镜像内的分区 我们将使用 qemu-nbd 完成这一功能, 同时它也能让我们使用 NBD (network block device) 协议共享该磁盘镜像。\n首先，我们需要加载nbd模块：\n$ sudo modprobe nbd max_part=16 接着，共享该磁盘并创建设备条目：\n$ sudo qemu-nbd -c /dev/nbd0 /path/to/image.qcow2 进行分区发现检测：\n$ sudo partprobe /dev/nbd0 fdisk 可以获取 nbd0 内各分区的相关信息 :\n$ sudo fdisk -l /dev/nbd0 Disk /dev/nbd0: 25.2 GiB, 27074281472 bytes, 52879456 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0xa6a4d542 Device Boot Start End Sectors Size Id Type /dev/nbd0p1 * 2048 1026047 1024000 500M 7 HPFS/NTFS/exFAT /dev/nbd0p2 1026048 52877311 51851264 24.7G 7 HPFS/NTFS/exFAT 接下来可以挂载镜像的任意分区了，比如说我们要挂载分区2：\n$ sudo mount /dev/nbd0p2 mountpoint 完成任务后，切记卸载镜像文件，然后根据之前的操作一步步还原，即分区并断开与nbd设备的连接：\n$ sudo umount mountpoint $ sudo qemu-nbd -d /dev/nbd0 网络 采用TAP设备（tun 与 tap 设备，都是虚拟网络设备，tun 设备用来实现三层隧道（三层 ip 数据报），tap 设备用来实现二层隧道（二层以太网数据帧）。）和网桥（使用网桥可以将多个接口连接到同一网段内，这一功能等同于交换式集线器。）的虚拟网络的性能应该会比使用用户模式网络或VDE要好，原因在于TAP设备和网桥是在内核中实现的。\n此外，虚拟网络的性能可以通过将网络设备直接注册到虚拟机中改善，这比默认情况下模拟e1000 NIC的性能表现要更好，参阅 [安装 virtio 驱动](#安装 virtio 驱动) 获得更多相关信息。\n关于链路层地址的限制 若在QEMU启动中指定了 -net nic 参数，QEMU将会为虚拟机注册一块虚拟网卡，其链路层地址为 52:54:00:12:34:56 。然而，当在多台虚拟机之间搭建桥接网络时，每台虚拟机在tap设备的虚拟机端都需要拥有一个独一无二的链路层地址 (MAC)，否则网桥会因为收到多个不同源却拥有相同MAC地址的数据包而无法正常工作。即使你为多个tap设备配置了不同的MAC地址也依旧会出现这个问题，因为当数据包通过tap设备时，tap设备并不会改写包内的链路层地址。\n因此请确保每个虚拟机拥有自己独一无二的网卡地址, 并且它们都以 52:54: 开头。 可以通过如下命令手动设置虚拟机的MAC地址, 下面的\u0026rsquo;X\u0026rsquo;可以替换成任何16进制字符:\n$ qemu-system-x86_64 -net nic,macaddr=52:54:XX:XX:XX:XX -net vde disk_image 用户模式 默认情况下，没有任何-netdev参数，QEMU将使用带有内置DHCP服务器的用户模式网络。当您的虚拟机运行其DHCP客户端时，将为其分配IP地址，它们将能够通过QEMU伪装的IP来访问物理主机的网络。\n警告： 仅适用于TCP和UDP协议，因此ICMP协议（包括ping）将不起作用。 请勿使用ping测试网络连接。\n如果主机已连接Internet，则此默认配置可以使您的虚拟机轻松访问Internet。但是如果您同时启动多个虚拟机，则虚拟机将无法在外部网络上直接看到，虚拟机也将无法相互通信。\nQEMU的用户模式网络可以提供更多功能，例如内置TFTP或SMB服务器，将主机端口重定向到虚拟机（例如，允许SSH连接到虚拟机）或将虚拟机连接到VLAN（vlan 全程 virtual lan，能够用来虚拟分配以太网。归属于不同的 VLAN ID 的设备之间需要一个路由才能够通信，这意味这不同的 VLAN ID 将以太网划分成了不同的分组。），以便它们可以彼此通信。 有关更多详细信息，请参见-net user标志上的QEMU文档。\n但是，用户模式网络在效用和性能上都有局限性。更高级的网络配置需要使用TAP设备或其他方法。\nTap 网络 Tap devices是一个Linux内核特性，允许您创建作为真实网络接口的虚拟网络接口。发送到tap接口的包将被传递到一个用户空间程序(如QEMU)，该程序将自己绑定到该接口。\nQEMU可以为虚拟机使用tap网络，因此发送到tap接口的包将被发送到虚拟机，并显示为来自虚拟机中的网络接口(通常是以太网接口)。相反，虚拟机通过其网络接口发送的所有内容都将出现在tap接口上。\nLinux桥接驱动程 序支持Tap设备，因此可以将Tap设备彼此桥接在一起，也可以连接其他主机接口，如eth0。如果您希望您的虚拟机能够相互通信，或者希望LAN上的其他机器能够与虚拟机通信，那么这是非常理想的方案。\n警告： 如果您将tap设备和一些主机接口桥接在一起，例如eth0，您的虚拟机将直接出现在外部网络上，这将使它们遭受攻击的可能。根据您的虚拟机可以访问的资源，您可能需要采取所有precautions来保护您的虚拟机。如果风险太大,虚拟机没有资源或您设置多个虚拟机,一个更好的解决方案可能是使用host-only networking建立NAT。在这种情况下，您只需要在主机上安装一个防火墙，而不是为每个虚拟机安装多个防火墙。\n正如在用户模式网络部分中指出的，tap设备提供比用户模式具有更高的网络性能。如果虚拟机中的操作系统支持virtio网络驱动程序，那么网络性能也会显著提高。假设使用tap0设备，virtio驱动程序在客户端上使用，并且没有使用脚本来帮助启动/停止网络，使用下面的qemu命令：\n-net nic,model=virtio -net tap,ifname=tap0,script=no,downscript=no 但是，如果已经使用带有virtio网络驱动程序的Tap设备，则甚至可以通过启用vhost来提高网络性能，例如：\n-net nic,model=virtio -net tap,ifname=tap0,script=no,downscript=no,vhost=on 仅主机网络\n如果为网桥提供了IP地址，并且使能发往该网桥的流量允许，但没有实际接口（例如eth0）连接到网桥，则虚拟机与虚拟机间，虚拟机与主机间能够相互通信。但是，如果您没有在物理主机上设置IP掩蔽，则他们将无法与外部网络进行通信。 此配置被其他虚拟化软件（例如VirtualBox）称为“仅主机网络模式”。\n提示：\n  如果你想设置IP掩蔽，例如虚拟机的NAT，请查看Internet sharing#Enable NAT页面。\n  您也许想在网桥接口上运行一个DHCP服务器来服务虚拟网络。例如，使用172.20.0.1/16子网，dnsmasq作为DHCP服务器:\n# ip addr add 172.20.0.1/16 dev br0 # ip link set br0 up # dnsmasq --interface=br0 --bind-interfaces --dhcp-range=172.20.0.2,172.20.255.254   内部网络\n如果您不为网桥提供IP地址并在iptables添加INPUT规则链，将所有流向网桥中的数据丢弃，则虚拟机将能够彼此通信，但无法与物理主机或外部网络通信。此配置被其他虚拟化软件（例如VirtualBox）称为“内部网络”。您将需要为虚拟机分配静态IP地址，或在其中一个虚拟机上运行DHCP服务器。\n在默认情况下，iptables将丢弃桥接网络中的数据包。您可能需要使用这样的iptables规则来允许桥接网络中的数据包:\n# iptables -I FORWARD -m physdev --physdev-is-bridged -j ACCEPT 使用 qemu-bridge-helper 桥接网络\n这种方法不需要启动脚本，并且很容易适应多个tap和多个桥。它使用/usr/lib/qemu/qemu-bridge-helper，允许在现有桥上创建tap设备。\n提示： 参见 Network bridge 获取创建网桥的信息.\n首先，创建一个配置文件，包含QEMU使用的所有网桥的名称:\n/etc/qemu/bridge.conf allow bridge0 allow bridge1 ... 现在启动虚拟机：\n$ qemu-system-i386 -net nic -net bridge,br=bridge0 [...] 在多个TAP设备的情况下，最基本的用法是要为所有NIC指定VLAN：\n$ qemu-system-i386 -net nic -net bridge,br=bridge0 -net nic,vlan=1 -net bridge,vlan=1,br=bridge1 [...] 手工创建网桥\n将虚拟机连接到主机接口，如eth0，这可能是最常见的配置。这种配置使虚拟机看起来直接位于外部网络，与物理主机位于同一以太网段。\n物理设备和Tap设备之间通过iptables进行网络共享\n桥接网络能在有线接口(例如eth0)之间工作，并且很容易设置。但是，如果主机通过无线设备连接到网络，则无法进行桥接。\n解决这个问题的一种方法是，给tap设备设置一个静态IP，使linux自动处理它的路由，然后通过iptables规则转发tap接口和连接到网络的设备之间的通信。\n通过 VDE2 配置网络 VDE全称为Virtual Distributed Ethernet，作为uml_switch的一个扩展，是一个用于管理虚拟网络的工具包\n其基本的思想是创建一个虚拟的开关，就如插座那样，允许虚拟机和物理机通过\u0026quot;插入\u0026quot;连接彼此。下面的配置非常简单，然而，VDE的功能远比展示的更强大，其能够接入虚拟开关，在不同的主机上运行它们并监听开关上的通信。\n本方法的优点在于无需sudo特权，普通用户一般没有运行modprobe的权限。\nVDE2 网桥 任何连接到vde上的虚拟机都会暴露给外部。举个例子，每台虚拟机都能直接从ADSL路由器那收到DHCP的配置信息。\n简化配置参数 如果你经常需要以不同的网络配置选项运行QEMU，就会发现时常得输入大量的-netdev和-device选项组合，这些是大量重复性的劳动。可以用-nic选项将二者结合，就如下面这样，底下这些参数：\n-netdev tap,id=network0,ifname=tap0,script=no,downscript=no,vhost=on -device virtio-net-pci,netdev=network0 可简化为:\n-nic tap,script=no,downscript=no,vhost=on,model=virtio-net-pci 要注意的是缺失了网络ID，因此将会以model=创建这些设备。{ic|-nic}}命令的前半部分参数正是-netdev的参数，而后半部分参数（model=之后的部分）则与设备有关，原本设备所提供的参数同样可以在此使用（例如，可以指定smb=）。若要完全禁用网络，可以用-nic none。\n图形 QEMU 可以使用一下几个图形输出：std, cirrus, vmware, qxl, xenfs 和 vnc。使用 vnc 选项，你可以单独运行客户机，并且通过 VNC 连接。\n  std：使用 -vga std 你可以得到最高 2560 x 1600 像素的分辨率。从 QEMU 2.2 开始是默认选项。\n  qxl：QXL是一个支持2D的并行虚拟化图形驱动。需要在客户机中安装驱动并在启动QEMU时设置-vga qxl选项。你可能也会想使用SPICE优化QXL的图形表现。\n在Linux客户机中，需要加载qxl和bochs_drm这两个内核模块，以获得一个比较好的效果。\nQXL设备的默认VGA内存大小为16M，这样的内存大小最高支持QHD (2560x1440)的分辨率，如果想要一个更高的分辨率，请增加vga_memmb。\n  virtio：virtio-vga / virtio-gpu 是一个基于virgl的3D并行虚拟化图形驱动。目前依旧处于开发中，仅支持最近的（\u0026gt;= 4.4）的Linux客户机，且需要以gallium-drivers=virgl选项编译mesa (\u0026gt;=11.2)。\n若要在客户机上启用3D加速，那么需要用-vga virtio选项选择此vga，并用-display sdl,gl=on或-display gtk,gl=on在显示设备上启用opengl上下文，这两个选项分别适用于sdl输出和gtk输出。如果配置成功了，那么在客户机的kernel log里可以看到：\n# dmesg | grep drm [drm] pci: virtio-vga detected [drm] virgl 3d acceleration enabled   none：这就像一台完全没有VGA卡的PC，无法通过-vnc访问它。另外，这种情况与使用-nographic选项不同，-nographic会让QEMU模拟VGA卡，只是关闭了SDL输出。\n  VNC 可以用-vnc :X选项将QEMU的VGA输出重定向至VNC会话中。将X替换为输出目标的编号（0代表之后监听在5900，1代表监听在5901\u0026hellip;）。\n$ qemu-system-x86_64 -vnc :0 警告： 默认的VNC服务器没有使用任何验证手段，用户可以从任何主机上连接到VNC。\n基本的口令验证 可以通过使用password选项很容易地设置访问口令。必须在QEMU Monitor中指定口令，仅当用户提供口令时才有可能连接到VNC。\n$ qemu-system-x86_64 -vnc :0,password -monitor stdio 在QEMU Monitor中设置口令需使用change vnc password命令，然后指定一个口令。\n底下的命令将在启动VNC时直接为其设置口令：\n$ printf \u0026#34;change vnc password\\n%s\\n\u0026#34; MYPASSWORD | qemu-system-x86_64 -vnc :0,password -monitor stdio 注意： 口令被限制在8个字符内，可以用暴力破解的方式猜到口令。因此在公网上推荐使用更细致的保护措施。\n音频 -audiodev标识用于设定后端音频驱动及其相关选项。最简单的情况下，你需要选择一个驱动并设置一个id。\n-audiodev pa,id=snd0 使用音频设备 Intel HD Audio\n模拟Intel HD Audio需要添加控制器和编解码器设备。可以用如下命令列出可用的Intel HDA Audio设备：\n$ qemu-system-x86_64 -device help | grep hda 添加音频控制器：\n-device ich9-intel-hda 添加音频编解码器并将其映射到宿主机的音频后端id上。\n-device hda-output,audiodev=snd0 Intel 82801AA AC97\n模拟AC97需要添加声卡设备并将其映射到宿主机的一个音频后端id上。\n-device AC97,audiodev=snd0 无音频设备 通过如下命令获取支持模拟的音频驱动列表：\n$ qemu-system-x86_64 -soundhw help 比如，要在客户机上模拟hda驱动，需要使用-device intel-hda -device hda-duplex选项启动QEMU。\n注意： 客户机的显卡模拟驱动可能也会导致客户机中的音频质量出现问题，需要一个个进行排查。使用qemu-system-x86_64 -h | grep vga列出可用的选项\n安装 virtio 驱动 QEMU为用户提供并行虚拟化块设备和网络设备的能力，其是借助virtio驱动实现的，拥有更好的性能表现以及更低的开销。\nvirtio块设备需要使用-drive指定一个disk image的参数，且需要带上if=virtio参数：\n$ qemu-system-x86_64 -boot order=c -drive file=disk_image,if=virtio 网络配置也是类似的：\n$ qemu-system-x86_64 -nic user,model=virtio-net-pci 注意： 仅有当客户机有virtio设备对应的驱动时该方法才能起效，Linux是有这方面支持的，不过无法保证这些驱动能够兼容其他操作系统。\n以下以windows为例。\n块设备驱动 Windows没有自带virtio驱动，因此需要在安装时加载该驱动。镜像文件可以从Fedora 仓库下载。\n通过ISO加载只对Windows Vista和Windows Server 2008及其之后的版本有效。这个方法的具体操作是在主磁盘设备和Windows安装盘外挂载一个额外的cdrom设备，将系统镜像与virtio驱动一同加载：\n$ qemu-system-x86_64 ... \\ -drive file=windows_disk_image,index=0,media=disk,if=virtio \\ -drive file=windows.iso,index=2,media=cdrom \\ -drive file=virtio.iso,index=3,media=cdrom \\ ... 在安装过程中，Windows Installer会询问你“Where do you want to install Windows?”，其会返回一个警告表示没有找到任何磁盘设备。接下来跟着如下示例中的步骤进行操作（基于Windows Server 2012 R2 with Update）：\n Select the option Load Drivers. Uncheck the box for Hide drivers that are not compatible with this computer\u0026rsquo;s hardware. Click the browse button and open the CDROM for the virtio iso, usually named \u0026ldquo;virtio-win-XX\u0026rdquo;. Now browse to E:\\viostor\\[your-os]\\amd64, select it, and confirm.  现在应该能看到virtio磁盘出现在列表中了，等待着被选中、格式化并安装。\n网络驱动 安装virtio网络驱动程序要容易一些，只需如上所述添加-net参数即可。\n$ qemu-system-i386 -m 4G -vga std -drive file=windows_disk_image,if=virtio -net nic,model=virtio-net-pci -cdrom virtio-win-0.1-185.iso Windows将检测网络适配器并尝试为其找到驱动程序。如果失败，请转到“设备管理器”，找到带有感叹号图标的网络适配器（双击打开），切换到驱动程序并单击“更新驱动程序”，然后选择虚拟CD-ROM。别忘了选中显示要递归搜索目录的复选框。\nBalloon 驱动 如果想要追踪客户机内存状态（比如通过virsh的dommemstat命令）或者在运行时改变客户机内存大小（尽管依然无法改变实际的内存大小，不过可以通过inflating balloon驱动限制内存的使用），那么请在客户机上安装balloon驱动吧。\nQEMU 监视器 QEMU运行时会提供一个监视器console界面以方便用户同虚拟机进行交互。QEMU监视器提供了许多有趣的功能，例如获取当前虚拟机的信息，热插拔设备，创建快照等。在QEMU监视器console中运行help或?命令获得完整的命令列表。\n访问QEMU监视器Console 图形化界面\n当使用默认的std图形选项时，可以通过按下Ctrl+Alt+2组合键或从QEMU窗口上的View \u0026gt; compatmonitor0访问到QEMU监视器。若要返回到虚拟机的图形界面，那么按下Ctrl+Alt+1或者View \u0026gt; VGA就行。\n然而，这种标准的访问方式不够方便，而且并不是在QEMU的所有图形化输出方式中都适用。\nTelnet\n启动QEMU时带上-monitor telnet:127.0.0.1:*port*,server,nowait参数可以启用telnet。虚拟机启动后可以通过telnet访问到监视器：\n$ telnet 127.0.0.1 port 注意： 如果指定 127.0.0.1 作为监听地址，那么只能在运行QEMU的宿主机上连接到该监视器。如果想要远程访问，QEMU需要在0.0.0.0上进行监听：-monitor telnet:0.0.0.0:*port*,server,nowait。还要记住的是，最好对firewall进行配置，该连接是完全不进行认证和加密的，因此需要通过防火墙确保本地网络环境是可信的。\nUNIX socket\n通过-monitor unix:*socketfile*,server,nowait参数运行QEMU，之后就可以通过socat或openbsd-netcat连接到监视器上。\n例如，如果QEMU是通过如下命令启动：\n$ qemu-system-x86_64 [...] -monitor unix:/tmp/monitor.sock,server,nowait [...] 就可以像这样连接到监视器上：\n$ socat - UNIX-CONNECT:/tmp/monitor.sock 或者通过这种方式:\n$ nc -U /tmp/monitor.sock TCP\n可以使用-monitor tcp:127.0.0.1:*port*,server,nowait参数将监视器暴露于TCP端口上，然后用netcat（openbsd-netcat或gnu-netcat都可）进行连接：\n$ nc 127.0.0.1 port 注意： 为了能够从其它设备上通过TCP socket访问到监视器，而不仅仅从运行QEMU的主机上连接，需要像前面Telnet中描述的那样，在0.0.0.0地址上进行监听。\n标准 I/O\n如果以-monitor stdio参数运行QEMU，那么其实是可以在运行QEMU的终端下访问到监视器的。\n在Monitor conosle下向虚拟机发送按键行为 由于在某些配置下，宿主机可能会拦截一些按键组合另作他用，这导致要在虚拟机中触发一些特定按键组合变得有些困难（一个显然的例子就是Ctrl+Alt+F*组合，该组合用于改变当前的tty）。我们采用在monitor console下发送按键组合的方式解决该问题。只需切换到monitor console下，然后使用sendkey命令，即可将按键转发至虚拟机中，例如：\n(qemu) sendkey ctrl-alt-f2 通过 monitor console 创建快照和管理快照 注意： 该特性\u0026quot;只\u0026quot;支持qcow2格式的虚拟机磁盘镜像，对于raw是无效的。\n有时候我们很需要将虚拟机的当前状态进行保存，或是将虚拟机重置到之前的快照状态，而且最好是随时能进行这些操作。QEMU monitor console为用户提供了必要的功能，进行快照创建，快照管理，以及快照恢复。\n Use savevm name 用于创建一个名为name的快照。 Use loadvm name 用于将虚拟机状态恢复至快照name。 Use delvm name 用于删除快照name。 Use info snapshots 用于查看保存的快照列表，这些快照由一个自增长的ID和标签名（用户创建快照时赋予）进行标识。  以冻结模式运行虚拟机 QEMU支持以冻结态运行虚拟机（需使用-snapshot参数），换句话说，虚拟机关闭时，对于虚拟机的一切修改都会丢弃。当用户对磁盘镜像写入时，这些变动最终写入的位置是/tmp目录下的一个临时文件，QEMU关机时将会把他们丢弃。\n不过，即使虚拟机运行于冻结状态下，依旧可以通过monitor console将这些变化写入磁盘镜像（如果你想的话）。使用下面的命令：\n(qemu) commit all 另外如果在冻结状态下创建快照，这些快照在QEMU退出时都会被丢弃，除非你显式地commit了他们。\nmonitor console中的开机和暂停命令 在QEMU monitor console下也可以模拟对物理机的一些操作：\n system_powerdown 会向虚拟机发送ACPI关机信号，效果就类似物理机上按下电源按钮。 system_reset 会重置虚拟机，类似物理机上的重置按钮。该操作可能导致数据丢失或文件系统的损坏，这是因为虚拟机并不是\u0026quot;干净地\u0026quot;重启的。 stop 会暂停虚拟机。 cont 使暂停的虚拟机恢复运行。  虚拟机截屏 可以在monitor console下运行该命令，获取PPM格式的截屏图片：\n(qemu) screendump file.ppm PCI passthrough via OVMF 笔记本 Optimus MUXless 下的 Intel 和 NVIDIA 虚拟机显卡直通 受到MUXless架构本身的限制，显卡直通有非常大的局限，例如很多游戏无法调用独显、操作麻烦、显示性能仍然较低等。因此，现阶段可以为了折腾而尝试，但不建议用于实用用途。\nOptimus MUXed 笔记本上的 NVIDIA 虚拟机显卡直通 技巧 改善虚拟机的性能表现 底下是一些可以改善虚拟机性能表现的技术，例如：\n  启用#启用 KVM：QEMU的启动命令加上-enable-kvm选项。\n  通过-cpu host选项让QEMU模拟宿主机上的特定CPU，如果没有该选项QEMU尝试模拟的是一个更为通用的CPU。\n  特别的，如果客户机是Windows，启用Hyper-V enlightenments可以改善性能：-cpu host,hv_relaxed,hv_spinlocks=0x1fff,hv_vapic,hv_time.\n  如果宿主机有多个核心，可以用-smp选项为客户机分配更多核心。\n  检查是否为虚拟机分配的足够的内存。默认情况下，QEMU仅仅为每台虚拟机分配128MiB的内存，可以使用-m选项分配更多的内存。例如，-m 1024代表启动一台内存为1024MiB的虚拟机。\n  如果客户机操作系统支持相关的驱动，可以使用virtio创建网络设备或块设备。\n  使用TAP设备代替user-mode网络，参阅#Tap 网络。\n  如果客户机需要进行大量的磁盘写工作，在宿主机文件系统上设置合适的挂载选项可以优化该工作。例如，可以用barrier=0选项挂载一个ext4 file system。在使用这些性能强化选项之前最好阅读相关文档，因为性能上的提升通常伴随着数据完整性下降的代价。\n  如果有一块原始磁盘镜像，你可能会想要禁用cache：\n$ qemu-system-x86_64 -drive file=disk_image,if=virtio,cache=none   使用原生的Linux AIO：\n$ qemu-system-x86_64 -drive file=disk_image,if=virtio,aio=native,cache.direct=on   如果正同时运行多台虚拟机，而它们拥有同样的操作系统，可以通过启用内核页归并节省内存。参阅#开启KSM。\n  在一些情况下，可以在运行时从安装了balloon驱动的客户机上回收内存，这需要QEMU启动该客户机时使用-device virtio-balloon选项。\n  允许使用一个ICH-9 AHCI控制器的仿真层，尽管它并不稳定。AHCI的仿真模拟支持NCQ，因此可以同时处理多个读写请求：\n$ qemu-system-x86_64 -drive id=disk,file=disk_image,if=none -device ich9-ahci,id=ahci -device ide-drive,drive=disk,bus=ahci.0   参阅 https://www.linux-kvm.org/page/Tuning_KVM 获取更多信息\n开机时启动QEMU虚拟机 通过libvirt实现\n如果虚拟机是通过libvirt设置的，可以用virsh autostart将其配置为开机自启，或者通过virt-managerGUI中虚拟机的Boot Options，选择\u0026quot;Start virtual machine on host boot up\u0026quot;实现开机自启。\n通过systemd service实现\n可以用如下的systemd unit和config配置开机时启动QEMU VM。\n/etc/systemd/system/qemu@.service [Unit] Description=QEMU virtual machine [Service] Environment=\u0026quot;haltcmd=kill -INT $MAINPID\u0026quot; EnvironmentFile=/etc/conf.d/qemu.d/%i ExecStart=/usr/bin/qemu-system-x86_64 -name %i -enable-kvm -m 512 -nographic $args ExecStop=/bin/bash -c ${haltcmd} ExecStop=/bin/bash -c 'while nc localhost 7100; do sleep 1; done' [Install] WantedBy=multi-user.target 注意： 为了方便地结束任务，该service会等待至console端口被释放（这意味着VM已被关闭）。\n接着创建per-VM配置文件，命名为/etc/conf.d/qemu.d/*vm_name*，在其中设置好args和haltcmd变量，配置示例：\n/etc/conf.d/qemu.d/one args=\u0026quot;-hda /dev/vg0/vm1 -serial telnet:localhost:7000,server,nowait,nodelay \\ -monitor telnet:localhost:7100,server,nowait,nodelay -vnc :0\u0026quot; haltcmd=\u0026quot;echo 'system_powerdown' | nc localhost 7100\u0026quot; # or netcat/ncat /etc/conf.d/qemu.d/two args=\u0026quot;-hda /srv/kvm/vm2 -serial telnet:localhost:7001,server,nowait,nodelay -vnc :1\u0026quot; haltcmd=\u0026quot;ssh powermanager@vm2 sudo poweroff\u0026quot; 对该变量的描述如下：\n args - 使用的QEMU命令行参数。 haltcmd - 安全关闭虚拟机的命令，在第一个例子中，QEMU monitor是通过-monitor telnet:..选项暴露至telnet，因而关闭虚拟机是通过nc命令在monitor console中发送system_powerdown，完成ACPI关机的工作。在另一个例子里，使用的则是SSH。  若要设置启动时运行哪个虚拟机，enable qemu@*vm_name*.service这个systemd单元\n鼠标整合 添加-usb -device usb-tablet选项以避免点击客户机系统的窗口时鼠标被捕获。该选项代表QEMU能够在不捕获鼠标的情况下，向系统报告鼠标的位置，该选项启用时还会覆盖PS/2鼠标模拟功能。 命令示例：\n$ qemu-system-x86_64 -hda disk_image -m 512 -usb -device usb-tablet 宿主机的USB设备传递至虚拟机 从客户机访问连接到宿主机USB口的设备是可能的，首先需要识别设备连接的位置，可以用lsusb命令找到设备连接位置，例如：\n$ lsusb ... Bus 003 Device 007: ID 0781:5406 SanDisk Corp. Cruzer Micro U3 上面以显示的数字分别用于标识\n 003 host_bus 007 host_addr 0781 vendor_id 5406 product_id  基本的思想是在QEMU中-device usb-ehci,id=ehci或-device qemu-xhci,id=xhci分别对EHCI (USB 2)或XHCI (USB 3)（在win7无法自动安装 USB3 驱动，因此应用 USB2）控制器进行模拟，然后将物理设备通过-device usb-host,..选项进行添加。\n识别出该设备，并将其连接至任一总线以及宿主机上的地址，通用的语法如下：\n-device usb-host,bus=controller_id.0,vendorid=0xvendor_id,productid=0xproduct_id 应用于上面例子中使用的设备，它变成：\n-device usb-ehci,id=ehci -device usb-host,bus=ehci.0,vendorid=0x0781,productid=0x5406 运行QEMU时会遇到 libusb couldn't open USB device Permission denied 权限错误，可以通过 udev 为设备设定合适的权限。\n$ vi /etc/udev/rules.d/50-usbtinyisp.rules SUBSYSTEMS==\u0026#34;usb\u0026#34;, ATTRS{idVendor}==\u0026#34;0781\u0026#34;, ATTRS{idProduct}==\u0026#34;5406\u0026#34;, GROUP=\u0026#34;vane\u0026#34;, MODE=\u0026#34;0660\u0026#34; $ ls -al /dve/bus/usb/003/007 crw-rw---- 1 root vane 189, 11 Nov 7 12:37 /dev/bus/usb/003/007 使用SPICE进行USB重定向 使用SPICE时可以将USB设备从客户端重定向至虚拟机中，无需使用QEMU命令。还支持为配置USB重定向插槽数（插槽数将决定可同时重定向的最大设备数）。相比于前面那种使用-usbdevice进行重定向的方法，SPICE方法的优势在于可以在虚拟机启动后USB设备热插拔，移除或添加USB设备时无需停机。这个方法还允许通过网络将客户端的USB设备重定向至服务端。总之，其是在QEMU虚拟机中使用USB设备最灵活的方法。\n开启KSM Kernel Samepage Merging (KSM) 是Linux内核的一个特性，允许应用程序向内核申请同其他申请页归并的进程进行页归并，KSM机制允许客户虚拟机之间进行页共享。当许多客户机运行相似的操作系统时，这个机制可以节省客观的内存。\n多屏支持 Linux的QXL驱动支持默认支持四头（虚拟屏幕），可以通过qxl.heads=N这一内核参数进行变更。\n复制和粘贴 在宿主机和客户机之间共享剪贴板的方法之一是使用SPICE远程桌面协议，通过SPICE客户端访问客户机，你需要遵照SPICE节中描述的步骤，通过该方式运行的客户机将支持与宿主机进行复制粘贴的操作。\nlibvirt Libvirt 是一组软件的汇集，提供了管理虚拟机和其它虚拟化功能（如：存储和网络接口等）的便利途径。这些软件包括：一个长期稳定的 C 语言 API、一个守护进程（libvirtd）和一个命令行工具（virsh）。Libvirt 的主要目标是提供一个单一途径以管理多种不同虚拟化方案以及虚拟化主机，包括：KVM/QEMU，Xen，LXC，OpenVZ 或 VirtualBox hypervisors。\nLibvirt 的一些主要功能如下：\n VM management（虚拟机管理）：各种虚拟机生命周期的操作，如：启动、停止、暂停、保存、恢复和迁移等；多种不同类型设备的热插拔操作，包括磁盘、网络接口、内存、CPU等。 Remote machine support（支持远程连接）：Libvirt 的所有功能都可以在运行着 libvirt 守护进程的机器上执行，包括远程机器。通过最简便且无需额外配置的 SSH 协议，远程连接可支持多种网络连接方式。 Storage management（存储管理）：任何运行 libvirt 守护进程的主机都可以用于管理多种类型的存储：创建多种类型的文件镜像（qcow2，vmdk，raw，\u0026hellip;），挂载 NFS 共享，枚举现有 LVM 卷组，创建新的 LVM 卷组和逻辑卷，对裸磁盘设备分区，挂载 iSCSI 共享，以及更多\u0026hellip;\u0026hellip; Network interface management（网络接口管理）：任何运行 libvirt 守护进程的主机都可以用于管理物理的和逻辑的网络接口，枚举现有接口，配置（和创建）接口、桥接、VLAN、端口绑定。 Virtual NAT and Route based networking（虚拟 NAT 和基于路由的网络）：任何运行 libvirt 守护进程的主机都可以管理和创建虚拟网络。Libvirt 虚拟网络使用防火墙规则实现一个路由器，为虚拟机提供到主机网络的透明访问。  安装 基于守护进程/客户端的架构的 libvirt 只需要安装在需要要实现虚拟化的机器上。注意，服务器和客户端可以是相同的物理机器。\n服务端\n安装 libvirt 以及至少一个虚拟运行环境（hypervisor）：libvirt 的 KVM/QEMU 驱动 是 libvirt 的首选驱动，如果 KVM 功能已启用，则支持全虚拟化和硬件加速的客户机。\n$ sudo apt update $ sudo apt install qemu-kvm libvirt-daemon-system 安装 libvirt-daemon-system 后，需要将用于管理虚拟机的用户添加到libvirt组中。这对于 sudo 组的成员是自动完成的，但对于应该访问系统范围的 libvirt 资源的其他任何人，都需要另外完成。这样做将授予用户访问高级网络选项的权限。\n在终端中输入：\n$ sudo adduser $USER libvirt 如果选择的用户是当前用户，您需要注销并重新登录才能使新的组成员身份生效。\n客户端\n客户端是用于管理和访问虚拟机的用户界面。\n virsh — virsh 是用于管理和配置域（虚拟机）的命令行程序。 Virtual Machine Manager — 使用libvirt对KVM，Xen，LXC进行管理的图形化工具。  配置 对于系统 级别的管理任务（如：全局配置和镜像卷 位置），libvirt 要求至少要设置授权和启动守护进程。\n注意： 对于用户会话 级别的管理任务，守护进程的安装和设置不是 必须的。授权总是仅限本地，前台程序将启动一个 libvirtd 守护进程的本地实例。\n设置授权 自 libvirt：连接授权：Libvirt 守护进程允许管理员分别为客户端连接的每个网络 socket 选择不同授权机制。这主要是通过 libvirt 守护进程的主配置文件 /etc/libvirt/libvirtd.conf 来实现的。每个 libvirt socket 可以有独立的授权机制配置。目前的可选项有 none、polkit 和 sasl。\n由于 libvirt 在安装时将把 polkit 作为依赖一并安装，所以 polkit 通常是 unix_sock_auth 参数的默认值。但基于文件的权限仍然可用。\n使用 polkit\n注意： 为使 polkit 认证工作正常，应该重启一次系统。\nlibvirt 守护进程在 polkit 策略配置文件（/usr/share/polkit-1/actions/org.libvirt.unix.policy）中提供了两种策略：\n org.libvirt.unix.manage 面向完全的管理访问（读写模式后台 socket），以及 org.libvirt.unix.monitor 面向仅监视察看访问（只读 socket）。  默认的面向读写模式后台 socket 的策略将请求认证为管理员。这点类似于 sudo 认证，但它并不要求客户应用最终以 root 身份运行。默认策略下也仍然允许任何应用连接到只读 socket。\n基于文件的权限授权\n为了给 libvirt 组用户定义基于文件的权限以管理虚拟机，取消下列行的注释：\n$ vim /etc/libvirt/libvirtd.conf #unix_sock_group = \u0026#34;libvirt\u0026#34; #unix_sock_ro_perms = \u0026#34;0777\u0026#34; # set to 0770 to deny non-group libvirt users #unix_sock_rw_perms = \u0026#34;0770\u0026#34; #auth_unix_ro = \u0026#34;none\u0026#34; #auth_unix_rw = \u0026#34;none\u0026#34; 有些资料提到可以通过改变某些特定 libvirt 目录的权限以简化管理。需要记住的是：包更新时，这些变更会丢失。如要修改这些系统目录的权限，需要 root 用户权限。\n守护进程 libvirtd.service 和 virtlogd.service这两个服务单元都要启动。可以把 libvirtd.service 设置为启用，这时系统将同时启用 virtlogd.service 和 virtlockd.socket 两个服务单元，因此后二者不必再设置为启用。\n测试 测试 libvirt 在系统级工作是否正常：\n$ virsh -c qemu:///system 测试 libvirt 在用户会话级工作是否正常：\n$ virsh -c qemu:///session 管理 绝大部分的 libvirt 管理可以通过三个工具实现：virt-manager（图形界面）、virsh 和 guestfish（它是 libguestfs 的一部分）。\nvirsh Visrsh 用于管理客户域（虚拟机），在脚本式虚拟化管理环境中工作良好。由于需要通过通讯管道与虚拟运行环境通讯，绝大部分 virsh 命令需要管理员权限。尽管如此，一些典型的管理操作如域的创建、运行等也可以像VirtualBox 那样以普通用户身份执行。\nVirsh 允许带命令行选项执行。如果不带则进入其内置的交互式终端：virsh。交互式终端支持 tab 键命令补全。\n从命令行执行：\n$ virsh [可选项] \u0026lt;命令\u0026gt; [参数]... 在交互式终端里运行：\nvirsh # \u0026lt;命令\u0026gt; [参数]... 帮助也是可用的：\n$ virsh help [option*] or [group-keyword*] 存储池 存储池是指保存卷的位置。Libvirt 中卷的定义相当于其他系统中虚拟磁盘或虚拟机镜像的概念。存储池应该是一个目录、一个网络文件系统或一个分区（此处包括 LVM）。存储池可以在活动与不活动之间切换，可以为其分配存储空间。\n以下示例为添加存储池、目录和 LVM 卷的方法：\n$ virsh pool-define-as name type [source-host] [source-path] [source-dev] [source-name] [\u0026lt;target\u0026gt;] [--source-format format] $ virsh pool-define-as poolname dir - - - - /home/username/.local/libvirt/images $ virsh pool-define-as poolname fs - - /dev/vg0/images - mntpoint 上述示例仅仅定义了存储池的信息，下面创建它：\n$ virsh pool-build poolname $ virsh pool-start poolname $ virsh pool-autostart poolname 删除它的命令：\n$ virsh pool-undefine poolname 提示： 对于 LVM 存储池而言：\n 最佳实践是仅把一个卷组分配给一个存储池。 请为存储池选择一个与 LVM 卷组不同的名字。否则当存储池被删除时，该卷组也将被删除。  用 virt-manager 新建存储池\n首先，连接到虚拟运行环境（例如QEMU/KVM的系统/用户会话）。然后，右键点击一个连接（例如QEMU/KVM）选择详情，切换到存储选项卡，点击左下角的**+**，按照向导操作。\n存储卷 存储池被创建之后，就可以在存储池中创建存储卷。如果你想新建一个域（虚拟机），那么这一步可以跳过，因为这一步可以在创建域的过程中完成。\n用 virsh 新建卷\n新建卷，列出卷，变更卷大小，删除卷：\n$ virsh vol-create-as poolname volumename 10GiB --format aw|bochs|raw|qcow|qcow2|vmdk $ virsh vol-upload --pool poolname volumename volumepath $ virsh vol-list poolname $ virsh vol-resize --pool poolname volumename 12GiB $ virsh vol-delete --pool poolname volumename $ virsh vol-dumpxml --pool poolname volumename # for details. 域 虚拟机被称作“域”。如果你想在命令行下操作，使用virsh列出，创建，暂停，关闭……域。virt-viewer可以用来查看使用virsh启动的域。域的创建通常以图形化的virt-manager或者命令行下的virt-install完成。 创建新域通常需要安装媒介，例如存储池中的iso文件或是直接从光驱安装。\n列出活动的和不活动的域：\n# virsh list --all 用 virt-install 新建域\n对于很详细的域（虚拟机）配置，可以用 virt-manager 新建域更简单地完成。但是，基础配置同样可以用virt-install完成并且同样运行顺利。至少要配置--name, --memory, 存储(--disk, --filesystem,或--nodisks),和安装方法（通常来说是.iso文件或CD）。查看virt-install(1)得到未列出的选项和更多的详情。\nWindows:\n$ virt-install \\  --name=windows7 \\  --memory 2048 \\  --cdrom /dev/sr0 \\  --os-variant=win7 \\  --disk /mnt/storage/domains/windows7.qcow2,size=20GiB \\  --network network=vm-net \\  --graphics spice 导入现有的卷：\n$ virt-install \\  --name demo \\  --memory 512 \\  --disk /home/user/VMs/mydisk.img \\  --import 用 virt-manager 新建域\n首先，连接到虚拟运行环境（例如 QEMU/KVM system 或用户 session，在连接上右击并选择 新建，然后跟随向导完成。\n 在第四[步中取消选中立即分配全部虚拟磁盘空间会加快创建过程并节省实际虚拟磁盘空间占用；然而，这将导致将来花费额外的磁盘整理时间。 在第五步中打开高级选项并确认虚拟化类型设为 kvm（这通常是首选模式）。如果要求附加的硬件配置，选中安装前定制选项。  管理域\n启动域：\n$ virsh start domain $ virt-viewer --connect qemu:///session domain 正常关闭域；强制关闭域:\n$ virsh shutdown domain $ virsh destroy domain 在libvirtd启动时自动启动域:\n$ virsh autostart domain $ virsh autostart domain --disable 在宿主机关闭时自动关闭域:\n使用libvirt-guests.serviceSystemd服务，运行中的域可以在宿主机关闭时自动挂起/关闭。同时这个服务还可以让挂起/休眠的域在宿主机启动的时候自动恢复。查看/etc/conf.d/libvirt-guests并设置相关选项。\n编辑一个域的XML配置：\n$ virsh edit domain 注意： 直接被QEMU启动的虚拟机不被libvirt管理。\n网络 这里是有关 libvirt 网络的一个正宗的概述。\n默认情况下，当 libvirtd 服务启动后，即创建了一个名为 default 的 NAT 网桥与外部网络联通（仅 IPv4）。对于其他的网络连接需求，可创建下列四种类型的网络以连接到虚拟机：\n bridge — 这是一个虚拟设备，它通过一个物理接口直接共享数据。使用场景为：宿主机有 静态 网络、不需与其它域连接、要占用全部进出流量，并且域运行于 系统 层级。有关如何在现有默认网桥时增加另一个网桥的方法，请参阅 网桥。网桥创建后，需要将它指定到相应客户机的 .xml 配置文件中。 network — 这是一个虚拟网络，它可以与其它虚拟机共用。使用场景为：宿主机有 动态 网络（例如：NetworkManager）或使用无线网络。 macvtap — 直接连接到宿主机的一个物理网络接口。 user — 本地网络，仅用于用户 会话。  绝大多数用户都可以通过 virsh 的各种可选项创建具有各种功能的网络，一般来说比通过 GUI 程序（像 virt-manager 之类）更容易做到。也可以按用 virt-install 新建域 所述实现。\n注意： libvirt 通过 dnsmasq 处理 DHCP 和 DNS 请求，以启动每个虚拟网络的不同实例。也会为特定的路由添加 iptables 规则并启用 ip_forward 内核参数。这也意味着宿主机上已运行的dnsmasq并不是libvirt所必须的（并可能干扰到libvirt的dnsmasq实例）。\nUEFI 支持 Libvirt 可以通过 qemu 和 OVMF 来支持 UEFI 虚拟机。 安装 ovmf 。 添加下面的内容到 /etc/libvirt/qemu.conf 。\n$ vim /etc/libvirt/qemu.conf nvram = [ \u0026#34;/usr/share/ovmf/x64/OVMF_CODE.fd:/usr/share/ovmf/x64/OVMF_VARS.fd\u0026#34; ] 重启 libvirtd\n现在你可以创建一个 UEFI 虚拟机了。 你可以通过 virt-manager 来创建。当你进行到向导的最后一步时：\n 勾选在安装前自定义配置，之后点击完成。 在概况屏幕, 将固件改为\u0026rsquo;UEFI x86_64'。 点击开始安装 在启动屏幕，你需要使用linuxefi命令来启动安装程序，并且你需要在系统中运行efibootmgr验证确实运行在UEFI模式下。  virt-manager: Shared folders with Linux Guest Create a future share folder on your host and set up the permissions (for the purpose of this article I will grand all permissions):\nroot@host# mkdir /share root@host# chmod 777 /share Afterwards shut down the guest if it’s running and attach the new filesystem in virt-manager:\n Switch the view to detail hardware view: View \u0026gt; Details Go to Attach hardware \u0026gt; Filesystem Fill in the name of the source path (/share in our case) and virtual target path (anything you like, I will go with /sharepoint) Switch mode to Mapped if you need to have write access from the guest Confirm and start the VM again  Now you can mount your shared folder from the VM:\nroot@guest# mkdir /share root@guest# mount -t 9p -o trans=virtio /sharepoint /share Or permanently add it to /etc/fstab file:\nroot@guest# cat /etc/fstab ... /sharepoint /share 9p trans=virtio,version=9p2000.L,rw 0 0 virt-manager: Shared folders with Windows Guest You can not add a shared folder in virt-manager like it is described in your article because the filesystem passthrough doesn\u0026rsquo;t work well with a windows guest.\nTo solve your problem you have several options:\n You can share a folder in the local network at your linux host system via SAMBA and access it over the windows filesystem directly. You can use spice-webdav to share a folder like it is described in this article from Guy Rutenberg. This is not recommend for transferring large files. If you only want to transfer data one or two times instead of having a permanent shared folder you can pack the data in your host system into a .iso file and add it in virt-manager as a disc to access it in the windows guest system.  virt-manager: Change Default Storage Pool Location 在Create a new virtual machine 的 Setp4 of 5 的时候，选择 Selec or create custom sorage 就行。\nQEMU-KVM Win7 环境准备   安装QEMU：sudo apt install qemu-kvm samba\n  下载 Windows virtio driver iso：https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/archive-virtio/virtio-win-0.1.102/，因为要将磁盘挂接为 virtio 磁盘。\n需使用 virtio-win-0.1.102，我使用 latest 的 virtio-win-0.1.208.iso，Windows安装程序会提示驱动没有包含签名错误No signed device drivers were found. Make sure that the installation media contains the correct drivers, and then click OK\n  创建系统盘 qemu-img create -f qcow2 Windows7-VM.img 30G，这将作为Win7的操作系统盘。\n  创建启动脚本\n$ vi start_Windows7_VM.sh #!/bin/bash DISKIMG=$HOME/.vm/Windows7-VM.img exec qemu-system-x86_64 --enable-kvm \\  -cpu host,hv_relaxed,hv_spinlocks=0x1fff,hv_vapic,hv_time \\  -drive file=${DISKIMG},if=virtio \\  -net nic,model=virtio-net-pci -net user,smb=$HOME/Downloads \\  -m 8192 \\  -smp sockets=1,cores=4,threads=2 \\  -monitor stdio \\  -vnc :0 \\  -audiodev pa,id=snd0 -device ich9-intel-hda -device hda-output,audiodev=snd0 \\  -usb -device usb-tablet \\  -rtc base=localtime,clock=host \\  -name \u0026#39;Windows7 VM\u0026#39; \\  $@ $ chmod u+x start_Windows7_VM.sh   ./start_Windows7_VM.sh -boot d -cdrom $HOME/Downloads/cn_windows_7_ultimate_x64_dvd_x15-66043.iso -drive file=$HOME/Downloads/virtio-win-0.1.102.iso,index=3,media=cdrom\n  smp,socket,cores,threads几个参数的理解\n结合physical server上lscpu命令的输出，对它们的关系梳理了一番\n[root@pqsfc018 ~]# lscpu ... CPU(s): 32 ... Thread(s) per core: 2 Core(s) per socket: 8 Socket(s): 2 ...  socket就是主板上插cpu的槽的数目，也就是可以插入的物理CPU的个数。 core就是我们平时说的“核“，每个物理CPU可以双核，四核等等。 thread就是每个core的硬件线程数，即超线程  具体例子，上面这台服务器的CPU配置是2个socket，每个socket是8个core，每个core是超线程（2），这样，整台机器的对外的core就是282=32\nSMP，对称多处理器（Symmetric Multi-Processors，简称SMP）是指在一个计算机上汇集了一组处理器(多CPU),各CPU之间共享内存子系统以及总线结构。在这种技术的支持下，一个服务器系统可以同时运行多个处理器，并共享内存和其他的主机资源。像双至强，也就是我们所说的二路，这是在对称处理器系统中最常见的一种（至强MP可以支持到四路，AMD Opteron可以支持1-8路）。也有少数是16路的。但是一般来讲，SMP结构的机器可扩展性较差，很难做到100个以上多处理器，常规的一般是8个到16个，不过这对于多数的用户来说已经够用了。在高性能服务器和工作站级主板架构中最为常见，像UNIX服务器可支持最多256个CPU的系统，其实qemu从代码设计上也是最大支持256个virtual cpu。\n安装 Win 7  选择 Custom（advanced）  选择 CD Drive (E:) virtio-win  选择 viostor  安装 Win7 Virtio SCSI Driver  安装好以后，就可以看到安装的目标磁盘了  进入常规的 Win7 安装流程  安装 Virtio 网络驱动 但是安装失败：\n尝试 device manager 安装：\n[QEMU 的内置SMB服务器](#QEMU 的内置SMB服务器) 宿主机的USB设备传递至虚拟机 Questions 各种缺dll，好烦。\nwin7 64位安装wamp缺失vcruntime140.dll和api-ms-win-crt-runtime-l1-1-0.dll 等\n安装VC redit.exe程序解决，链接：\n https://download.microsoft.com/download/9/3/F/93FCF1E7-E6A4-478B-96E7-D4B285925B00/vc_redist.x86.exe https://download.microsoft.com/download/9/3/F/93FCF1E7-E6A4-478B-96E7-D4B285925B00/vc_redist.x64.exe  Microsoft Visual C++ Install Error 0x80240017\n右键 =\u0026gt; 兼容性疑难解答\nQEMU-KVM WinXP SP3 太太太老了，很多软件都不支持了。\nwindows_xp.sh #!/bin/bash DISKIMG=$HOME/.vm/WindowsXP-VM.img exec qemu-system-x86_64 --enable-kvm \\  -cpu host,hv_relaxed,hv_spinlocks=0x1fff,hv_vapic,hv_time \\  -drive file=${DISKIMG} \\  -net nic,model=rtl8139 -net user,smb=$HOME/Downloads \\  -m 4096 \\  -cpu Nehalem \\  -rtc base=localtime,clock=host \\  -usb -device usb-tablet \\  -monitor stdio \\  -vga std \\  $@ Windows XP cannot connect to samba share You have \u0026lsquo;client min protocol = NT1\u0026rsquo; set, there is another similar setting \u0026lsquo;server min protocol\u0026rsquo; which from Samba 4.11.0 is set to SMBv2. Your XP is probably only using SMBv1, so it will not be able to see or connect to your Samba server.\nSo you have to edit the [global] section in the /etc/samba/smb.conf and add the server min protocol = NT1 option here. Then restart the Samba service.\n例如：\n$ ps h -C smbd -o pid,args 1707 /usr/sbin/smbd --foreground --no-process-group $ vim /tmp/qemu-smb.SL95F1/smb.conf [global] server min protocol = NT1 $ sudo smbcontrol 1707 reload-config 或者编写如下脚本\n#!/bin/bash echo \u0026#34;[global] server min protocol = NT1\u0026#34; \u0026gt;\u0026gt; /tmp/**/smb.conf sudo smbcontrol $(ps h -C smbd -o pid) reload-config Windows XP 上网提示：您的时钟快了/慢了 此时，无论你怎么调整日期和时间，都不能解决上网问题。即使把日期从2020年调整到2015年，此时虽然不在提示 “您的时钟快了”，也有证书期限等异常。\n出现这种问题的原因，是因为 Windows XP 确实太老了，Google Chrome、Mozilla Firefox 及其内核的浏览器已经不支持了。\nVirtual Machine Manager 键盘不能输入的问题\n在 Display 中，设定 keymap，比如 en-us\n无网络\n在 NIC 中，将 Device model 设置为 rtl8139\nQEMU-KVM Gentoo Configuration Host To create a disk image for the virtual machine, run:\n$ qemu-img create -f qcow2 Gentoo-VM.img 30G Download a minimal Gentoo LiveCD from here.\nSince QEMU requires a lot of options, it would be a good idea to put them into a shell script, e.g.:\n$ vim start_Gentoo_VM.sh #!/bin/bash DISKIMG=$HOME/VirtualMachine/Gentoo-VM.img exec qemu-system-x86_64 -enable-kvm \\  -bios /usr/share/edk2-ovmf/OVMF_CODE.fd \\  -cpu host \\  -drive file=${DISKIMG},if=virtio \\  -netdev user,id=vmnic,hostname=Gentoo-VM,hostfwd=tcp::10022-:22,smb=$HOME/Downloads \\  -device virtio-net,netdev=vmnic \\  -device virtio-rng-pci \\  -m 4G \\  -smp sockets=1,cores=4,threads=2 \\  -monitor stdio \\  -vnc :0 \\  -audiodev pa,id=snd0 -device ich9-intel-hda -device hda-output,audiodev=snd0 \\  -rtc base=localtime,clock=host \\  -name \u0026#34;Gentoo VM\u0026#34; \\  $@ $ chmod u+x start_Gentoo_VM.sh Change the path to your disk image Gentoo-VM.img in the script. You can add more options when calling the script. To boot the disk image, run:\n$ ./start_Gentoo_VM.sh -boot d -cdrom $HOME/Downloads/install-amd64-minimal-20211107T170547Z.iso Install the guest per the Gentoo Handbook. See the guest section for optimum support. After the installation start the script without the additional options.\nUsing UEFI with QEMU UEFI for x86 QEMU/KVM VMs is called OVMF (Open Virtual Machine Firmware). It comes from EDK2 (EFI Development Kit), which is the UEFI reference implementation.\n$ sudo apt-get install ovmf 检查是否安装，命令为：\n$ dpkg -L ovmf | grep OVMF.fd /usr/share/ovmf/ OVMF.fd /usr/share/qemu/ OVMF.fd 要在虚拟机中运行操作系统的映像文件，添加 -bios /usr/share/ovmf/OVMF.fd。该代码调用名为 OVMF.fd 的文件，该文件是 Qemu 的 UEFI 固件。\n$ qemu-system-x86_64 -bios /usr/share/ovmf/OVMF.fd -cdrom ubuntu-21.04-desktop-amd64.iso 这个名为ovmf的包其实就是名为TianoCore的程序。该名称本身代表开放虚拟机固件)。\n\u0026ldquo;BdsDxe: failed to load Boot0001\u0026rdquo;\nsolution: Try hitting F2 to enter the OVMF settings during guest boot and manually pick a new boot drive option.\nVirtualBox 执行 .vbs 文件\n$ cscript test.vbs 删除备份\n删除虚拟机备份，当前状态前一个备份删除得快，两个备份之间的备份删除得慢。\n共享文件夹\n固定分配的共享文件夹对于定义共享文件夹的虚拟机是永久存在的；\n临时分配的共享文件夹在虚拟机运行时添加/删除，虚拟机关闭后消失。\n把img系统镜像转为VDI或VMDK格式文件\n$ VBoxManage convertdd *.img *.vdi 在 virtualbox 新建虚拟机时指定 vdi 硬盘文件，就可以安装系统\n启动本地磁盘上的其它系统\n增加现有虚拟机的磁盘大小 下面是你迟早会遇到的情况。\n你在 VirtualBox 中安装了一个或多个操作系统。在创建这些虚拟操作系统的同时，你还在 VirtualBox 中为它们创建了虚拟硬盘。\n你指定了虚拟磁盘的最大大小，比如说 15 或 20GB，但现在使用了一段时间后，你发现你的虚拟机已经没有空间了。\n虽然在 Ubuntu 和其他操作系统上有释放磁盘空间的方法，但更稳健的处理方式是增加 VirtualBox 中创建的虚拟机的磁盘大小。\n是的，你可以在 VirtualBox 中扩大虚拟硬盘，即使在创建之后也可以。虽然这是一个安全且经过测试的过程，但我们强烈建议你在执行这样的操作之前，先创建一个虚拟机的备份。\n我将向你展示如何在 VirtualBox 中以图形和命令行（对于 Linux 极客）方式调整磁盘大小。这两种方法都很简单直接。\n方法 1：在 VirtualBox 中使用虚拟媒体管理器\nVirtualBox 6 增加了一个调整虚拟磁盘大小的图形化选项。你可以在 VirtualBox 主页的文件选项卡中找到它。\n进入 “File -\u0026gt; Virtual Media Manager”：\n在列表中选择一个虚拟机，然后使用 “Size” 滑块或输入你需要的大小值。完成后点击 “Apply”。\n请记住，虽然你增加了虚拟磁盘的大小，但如果你的空间是动态分配的，那么实际的分区大小仍然不变。\n方法 2：使用 Linux 命令行增加 VirtualBox 磁盘空间\n如果你使用 Linux 操作系统作为宿主机，在宿主机中打开终端并输入以下命令来调整 VDI 的大小：\nVBoxManage modifymedium \u0026quot;/path_to_vdi_file\u0026quot; --resize \u0026lt;megabytes\u0026gt; 在你按下回车执行命令后，调整大小的过程应该马上结束。\n 注意事项\nVirtualBox 早期版本命令中的 *modifyvdi 和 modifyhd 命令也支持，并在内部映射到 modifymedium 命令。\n 如果你不确定虚拟机的保存位置，可以在 VirtualBox 主页面点击 “Files -\u0026gt; Preferences” 或使用键盘快捷键 Ctrl+G 找到默认位置。\nSeamless Mode 虚拟机通常在一个窗口中运行来宾操作系统及其程序。但是，VirtualBox和VMware都有一些功能，允许您在主机桌面上运行虚拟化程序，从而将它们从监狱中释放出来。\u0026hellip;\n这意味着您可以在不使用虚拟机窗口和来宾操作系统桌面的情况下使用程序。如果使用多个监视器，甚至可以将虚拟机中的不同窗口放置在不同的监视器上。\n工作原理\n所有这些特性都同样工作。启动虚拟机，启动您想要使用的程序，然后启用“无缝模式”或“统一模式”。来宾操作系统的桌面和虚拟机窗口将消失，将来宾操作系统的窗口留在桌面上。它们看起来正在运行，好像它们在您的主机操作系统上运行，但虚拟机仍在后台运行。程序仍然是沙盒，因此它们无法访问主机操作系统的文件——它们似乎正在主机操作系统上运行。\n无论您使用的是Windows、Linux还是Mac，这些技巧都有效。您可以在Linux桌面上无缝运行Windows程序，也可以在Windows桌面上运行Linux软件。\n使用virtualbox的无缝模式\n请注意，VirtualBox只允许您在Windows、Linux和Solaris客户机上使用此功能。如果你设法让MacOSX在VirtualBox虚拟机上运行，或者你正在使用像俳句这样的小众操作系统，你将无法使用这个功能。\n在使用此功能之前，必须在要使用的来宾虚拟机内安装VirtualBox来宾添加软件包。如果您还没有这样做，请启动虚拟机，单击“设备”菜单，然后选择“安装来宾添加”。系统将提示您安装软件。\n要使用此功能，请同时按“主机键”（通常是右Ctrl键，但它显示在虚拟机窗口的右下角）和“L”。也可以单击“视图”菜单，然后选择“切换到无缝模式”。\nVirtualBox将隐藏来宾操作系统的桌面背景，使其看起来好像来宾操作系统的程序正在主机操作系统的桌面上运行。但是，正在运行的应用程序不会出现在操作系统的标准任务栏上。\n要退出无缝模式，只需按主机键，然后再次按L。您还可以在任务栏上方找到VirtualBox菜单，您可以将鼠标悬停在上面查看。单击查看并再次选择切换到无缝模式以禁用无缝模式。\n使用vmware的unity模式\nVMware有一个类似的功能，名为Unity mode。它可以在免费的VMware Player、VMware Workstation和VMware的其他付费应用程序上使用。与VirtualBox一样，VMware的Unity模式适用于Windows和Linux客户机。\nVBox+WinXP SP3 Windows XP; Guest Additions installation stuck; Virtualbox 6.1.18\nDisconnect network. It helps me.\nVS VMWare 工具是用来解决问题的，没必要看到开源就意识形态附体\n虚拟机网络模式 桥接\n桥接网络是指本地物理网卡和虚拟网卡通过VMnet0虚拟交换机进行桥接，物理网卡和虚拟网卡在拓扑图上处于同等地位，那么物理网卡和虚拟网卡就相当于处于同一个网段，虚拟交换机就相当于一台现实网络中的交换机,所以两个网卡的IP地址也要设置为同一网段。\n所以当我们要在局域网使用虚拟机，对局域网其他pc提供服务时，例如提供ftp，提供ssh，提供http服务，那么就要选择桥接模式。\n例如大学宿舍里有一个路由器，宿舍里四个人连接这个路由器，路由器的wanip就不理会了，这个ip是动态获取的，而lanip默认是192.168.1.1,子网掩码是255.255.255.0。而其他四个人是自动获取ip，假设四个人的ip是:\nA:192.168.1.100/255.255.255.0,\nB:192.168.1.101/255.255.255.0\nC:192.168.1.102/255.255.255.0\nD:192.168.1.103/255.255.255.0\n那么虚拟机的ip可以设置的ip地址是192.168.1.2-192.168.1.99,192.168.1.104-192.168.1.254 (即网络地址全0和全1的除外，再除去ABCD四个人的ip地址)\n那么虚拟机的ip地址可以设置为192.168.1.98/255.255.255.0，设置了这个ip地址，ABCD这四个人就可以通过192.168.1.98访问虚拟机了，如果虚拟机需要上外网，那么还需要配置虚拟机的路由地址，就是192.168.1.1了，这样，虚拟机就可以上外网了，但是，上网我们一般是通过域名去访问外网的，所以我们还需要为虚拟机配置一个dns服务器，我们可以简单点，把dns服务器地址配置为google的dns服务器:8.8.8.8,到此，虚拟机就可以上网了。\nNAT\nNAT模式中，就是让虚拟机借助NAT(网络地址转换)功能，通过宿主机器所在的网络来访问公网。\nNAT模式中，虚拟机的网卡和物理网卡的网络，不在同一个网络，虚拟机的网卡，是在vmware提供的一个虚拟网络。\nNAT和桥接的比较:\n NAT模式和桥接模式虚拟机都可以上外网。 由于NAT的网络在vmware提供的一个虚拟网络里，所以局域网其他主机是无法访问虚拟机的，而宿主机可以访问虚拟机，虚拟机可以访问局域网的所有主机，因为真实的局域网相对于NAT的虚拟网络，就是NAT的虚拟网络的外网。 桥接模式下，多个虚拟机之间可以互相访问；NAT模式下，多个虚拟机之间也可以相互访问。  如果你建一个虚拟机，只是给自己用，不需要给局域网其他人用，那么可以选择NAT，毕竟NAT模式下的虚拟系统的TCP/IP配置信息是由VMnet8(NAT)虚拟网络的DHCP服务器提供的，只要虚拟机的网路配置是DHCP，那么你不需要进行任何其他的配置，只需要宿主机器能访问互联网即可，就可以让虚拟机联网了。\n例如你想建多个虚拟机集群，作为测试使用，而宿主机可能是一个笔记本，ip不固定。这种应用场景，我们需要采用nat模式了，但是我们要考虑一个问题，虚拟机之间是需要互访的，默认采用dhcp，虚拟机的ip每次重启，ip都是不固定的，所以我们需要手工设置虚拟机的ip地址。\nHost-Only\n在Host-Only模式下，虚拟网络是一个全封闭的网络，它唯一能够访问的就是主机。其实Host-Only网络和NAT网络很相似，不同的地方就是Host-Only网络没有NAT服务，所以虚拟网络不能连接到Internet。主机和虚拟机之间的通信是通过VMware Network Adepter VMnet1虚拟网卡来实现的。\nHost-Only的宗旨就是建立一个与外界隔绝的内部网络，来提高内网的安全性。这个功能或许对普通用户来说没有多大意义，但大型服务商会常常利用这个功能。\nVMware 用 VMware 的坑：我用普通账户创建虚拟机，然后它安装 vmware tools 需要 root 权限，用 root 权限开启 VMWare 的话，就没有之前的虚拟机了。所以，最好一开始，就用 root 权限运行 VMWare。\nErrors- vmware unable to install all modules vmmon vmnet\nIn case you get Gcc not found and Kernel modules compiling error upon starting the Vmware, then you have to install them. For that, first, close the Vmware Player window and then run the below two commands:\n$ sudo apt install gcc $ sudo apt-get install build-essential After that start the Vmware player again and start installing the modules. If you still have the error then follow the further steps.\n Download the latest vmware-host-modules – VMMON and VMNET  Visit: https://github.com/mkubecek/vmware-host-modules\nThere as per your Vmware Player station, download the module file. For example– while doing this article the version of Workstation was 16.2.3, hence we download the same module file in zip format.\nThe file we download using the browser goes to the Downloads directory. Hence, switch to that.\n$ cd Downloads $ sudo apt install unzip $ unzip vmware-host-modules-w16.2.3-k5.18.zip $ cd vmware-host-modules-w16.2.3-k5.18 $ tar -cf vmmon.tar vmmon-only $ tar -cf vmnet.tar vmnet-only $ sudo cp -v vmmon.tar vmnet.tar /usr/lib/vmware/modules/source/ $ sudo vmware-modconfig --console --install-all Uninstall or Remove Vmware Linux\n$ cd /usr/bin $ sudo ./vmware-installer -u vmware-player 反虚拟机检测 在开发测试中，不少人会选择使用虚拟机环境来进行，以避免对主机产生影响，特别是一些软件类测试，比如病毒分析等VMWare等。在实际测试中会发现，相当一部分软件或代码也在进行反虚拟机来逃避分析，这种技术可以检测自己是否运行在虚拟机中，如果探测到自己在虚拟机中运行，它就会执行与其本身行为不同的行为，这时候就无法达到我们测试的目的了。因此我们可以考虑通过修改配置来达到让虚拟机内运行的软件无法探测到虚拟机环境的目标。\n探测方向 不管是通过 VMware 还是 Oracle VirtualBox 抑或是 Microsoft Hyper-V，只要是虚拟出来的环境，都或多或少会有痕迹存在，目前用来探测的比较多的痕迹有以下几个。\nMAC 地址\n这是最明显的特征。通常 MAC 地址的前三个字节标识一个提供商。以 00:05:69、00:0c:29 和00:50:56 开始的 MAC 地址与 VMware 相对应；以 00:03:ff 开始的 MAC 地址与 virtualpc 对应；以 08:00:27 开始的 MAC 地址与 VirtualBox 对应。\n其他硬件信息\n虚拟机环境中，主板序列号、主机型号、系统盘所在磁盘名称等硬件信息，以及这些硬件采用的驱动，通常都会带有 VMware、VirtualBox、VBOX、Virtual Machine 等字眼。\n特定的进程信息\n为方便使用，比如自动捕获鼠标、分辨率自适应等，我们会安装 VMware Tools 或者 VBoxGuestAdditions 等增强包，这也是虚拟机环境非常明显的一个特征。通过进程快照读取当前进程信息，查找是否存在虚拟机中特有的进程，如 VMware 中的 vmware.exe 和 VirtualBox 中的 VBoxService.exe。\n特定的文件夹或文件信息\n通过查找磁盘中是否存在特定的文件夹或文件，判断当前是否在虚拟机中。VMware 虚拟机中通常会有路径 C:\\Program Files\\VMware\\VMware Tools\\；VirtualBox 虚拟机中通常会有路径 C:\\Program Files\\Oracle\\VirtualBox Guest Additions\\。\n特定的注册表信息\n通过读取主机具有虚拟机特性的注册表位置来判断是否处于虚拟机环境中。针对 VMware 可以判断注册表项 HKEY_CLASSES_ROOT\\Applications\\VMwareHostOpen.exe；针对 VirtualBox 可以判断注册表项 HKEY_LOCAL_MACHINE\\SOFTWARE\\Oracle\\VirtualBox Guest Additions。当然，注册表中能被检测出的位置很多，这里只是举个例子。\n特定的服务名\n通过获取主机当前具有虚拟机特性的服务信息，判断当前主机是否为虚拟机。在 VMware 中通常会存在 VMware 物理磁盘助手服务和VMware Tools服务等；在 VirtualBox 中通常会存在VirtualBox Guest Additions Service服务等。\n时间差\n由于在虚拟机中，代码的运行速度通常不如真实主机。所以通过运行一段特定的代码来比较这段代码在虚拟机和真实主机之中的相对运行时间，以此来判断是否处于虚拟机之中。\n其他\n上面说的几种方法都能够检测虚拟机，但检测的方法却不仅限于此，有兴趣的可以再深入研究。\n反探测 近年来，随着虚拟化技术的使用不断增加，采用反虚拟机技术的软件数量逐渐下降，编写者已经开始意识到，目标主机是虚拟机，也并不意味着它就没有攻击价值，特别在于目前云计算产业正在如火如荼地发展中。\n以 VMware 为例，我们可以通过下面的方法来解决上文探测方向中的大部分痕迹。由于修改信息可能会导致系统激活状态失效，或者修改后配置不生效，故建议在创建虚拟机时就修改好。\n修改软件信息\n VMTools 接口  直接将下面的代码贴到虚拟配置文件 .vmx 中（如果是 EXSi，建议通过 WEB 控制面板来修改配置），屏蔽 VMware 特定信息的探测：\nisolation.tools.getPtrLocation.disable = \u0026quot;TRUE\u0026quot; isolation.tools.setPtrLocation.disable = \u0026quot;TRUE\u0026quot; isolation.tools.setVersion.disable = \u0026quot;TRUE\u0026quot; isolation.tools.getVersion.disable = \u0026quot;TRUE\u0026quot; monitor_control.disable_directexec = \u0026quot;TRUE\u0026quot; monitor_control.disable_chksimd = \u0026quot;TRUE\u0026quot; monitor_control.disable_ntreloc = \u0026quot;TRUE\u0026quot; monitor_control.disable_selfmod = \u0026quot;TRUE\u0026quot; monitor_control.disable_reloc = \u0026quot;TRUE\u0026quot; monitor_control.disable_btinout = \u0026quot;TRUE\u0026quot; monitor_control.disable_btmemspace = \u0026quot;TRUE\u0026quot; monitor_control.disable_btpriv = \u0026quot;TRUE\u0026quot; monitor_control.disable_btseg = \u0026quot;TRUE\u0026quot; monitor_control.restrict_backdoor = \u0026quot;TRUE\u0026quot; 驱动信息\n主要是显卡，先安装 VMware Tools 装好驱动，备份出显卡驱动，然后修改驱动中的安装文件 *.inf，将 STRING 一节中的相关字眼修改掉，再还原驱动。\nDiskID = \u0026quot;NVIDIA Windows Driver Library Installation\u0026quot; CompanyName = \u0026quot;NVIDIA\u0026quot; SVGA = \u0026quot;GeForce GTX 660\u0026quot; 在这一步中，需要安装 VMware Tools 才会有显卡驱动，但是上面修改了配置，将无法安装 VMware Tools，会提示“只应安装在虚拟机内”。由于安装 VMware Tools 将会是一个非常明显的特征，因此不建议安装。且虚拟机驱动其实都是一样的，因此可以从其他虚拟机中导出来直接使用。\n修改硬件信息\n 主板信息  下面的代码表示延用实体机的主板信息：\nSMBIOS.reflecthost = \u0026quot;TRUE\u0026quot; SMBIOS.noOEMStrings = \u0026quot;TRUE\u0026quot; SMBIOS.addHostVendor = \u0026quot;TRUE\u0026quot; hw.model.reflectHost = \u0026quot;TRUE\u0026quot; serialNumber.reflectHost = \u0026quot;TRUE\u0026quot; board-id.reflectHost = \u0026quot;TRUE\u0026quot; 也可以自己编一个，比如在黑苹果中会用到的：\nsmbios.reflectHost = \u0026quot;FALSE\u0026quot; smbios.vendor = \u0026quot;Apple Computer, Inc.\u0026quot; smbios.version = \u0026quot;MBA51.88Z.0055.B08.0610121\u0026quot; smbios.family =\u0026quot;MacBook Pro\u0026quot; smbios.model = \u0026quot;MacBookPro1.1\u0026quot; smbios.date =\u0026quot;10/12/06\u0026quot; smbios.manufacturer = \u0026quot;Apple Computer, Inc.\u0026quot; smbios.systemversion = \u0026quot;1.0\u0026quot;  磁盘信息  如果在 scsi0 插槽上有 SCSI 虚拟磁盘作为系统驱动器，可以添加：\nscsi0:0.productID = \u0026quot;WDC_____WD10EZEX-57WN4D11\u0026quot; scsi0:0.vendorID = \u0026quot;WDC\u0026quot; scsi0:0 表示第一个插槽，其他硬件也可以类似指定 ID。\n 网卡信息  参考实体机 MAC 地址信息，自行编一个：\nethernet0.checkMACAddress = \u0026quot;FALSE\u0026quot; ethernet0.address = \u0026quot;BC:30:5B:DD:D2:E8\u0026quot; 以上的方法能够解决大部分的虚拟机探测，但是一些使用寄存器值、任务状态段（Task Status Segment, TSS）、I/O 接口等检测方法的软件，仍然骗不过。\n参考文章：\n1、《反虚拟机技术总结》 2、《过虚拟机检测》 3、《解决VMware Tools提示 \u0026ldquo;只应安装在虚拟机内\u0026quot;的问题》 4、《VM反虚拟机检测》 5、《那些年病毒用过的损招——反虚拟机技术》\n相关文章：\n1、《VMware Workstation Pro 最新版下载及永久激活 KEY 激活码序列号》 2、《重制：VMware 15 Pro 安装黑苹果 macOS10.13.5 图文教程：流畅、好用！》\nQuestions piix4_smbus Host SMBus controller not enabled\n从内核的说明文档来看，这个 piix4 实际上是 Intel 82371AB 南桥芯片，多功能总线控制器，而在 VMware 里面并没有这个真实的芯片组，但在启动时最会尝试载入这个驱动模块，所以会报错，但对系统没有任何影响。\nOthers 通过 Qemu 安装 Windows 到硬盘 双系统新思路。今天装windows, 在linux上先用虚拟机，把硬盘直通进去，在raw盘上装好，然后更新grub, 再重启就可以直接接进去了。\n这样可以避免装机还要做启动盘，装机过程中的重启也可以避免了。\nwin的安装过程中驱动都是按照虚拟机的配置安装的，但是win10是自动装驱动的，重启进去后过了一会显卡驱动自动都装好了。\nLooking Glass Looking Glass 讓 Linux 可完美玩 Windows 遊戲 超低延遲不掉格\n當用戶安裝了虛擬電腦（VM）實行 Windows，並執行遊戲時，它採用的 KVM frame relay 技術可將 Windows 顯示記憶體，透過 PCI pass-through 直接由 Windows VM 被配置的顯示卡，複製到 Linux 被配置的顯示卡，這樣 Linux 便可在極為低延遲的情況下，接近完美顯示 Windows 遊戲的內容。\n簡單來說，就是一部 Linux 電腦裡面裝有虛擬電腦運行的 Windows，Windows 遊戲實行時，在被配置的顯示卡記憶體資料，在主機板 PCI 通道直接複製到 Linux 被配置的顯示卡。即是說 Windows 遊戲原本畫面，可高速反映到 Liunx 的虛擬電腦軟件上。這樣 Linux 用戶就算不 Dual boot 或使用兩個熒幕，在 Linux 上都可得到接近相同的打機體驗。\nxrdp xrdp 使用 RDP（Microsoft 远程桌面协议）为远程计算机提供图形登录。xrdp 接受来自各种 RDP 客户端的连接：FreeRDP、rdesktop、NeutrinoRDP 和 Microsoft 远程桌面客户端（适用于 Windows、macOS、iOS 和 Android）。\n正如 Windows 到 Windows 远程桌面一样，xrdp 不仅支持图形远程处理，还支持\n 双向剪贴板传输（文本、位图、文件） 音频重定向 驱动器重定向（在远程机器上安装本地客户端驱动器）  RDP 传输默认使用 TLS 加密。\nQEMU/KVM VS Virtualbox Linux 系统上的虚拟化解决方案 – KVM 和 VirtualBox\nKVM 提供了一些 VirtualBox 没有的功能，反之亦然。IT 世界中没有通用工具，因此使用适合您需求的工具非常重要。基本思想是：如果你想安装二进制 Linux 发行版作为来宾，使用 KVM。它速度更快，并且它的驱动程序包含在官方内核树中。如果您的客户涉及大量编译并且需要一些更高级的功能，并且/或者不是 Linux 系统，那么最好使用 VirtualBox。\n技术原因很简单：KVM 更好地与 Linux 集成，它更小更快，虽然你可以在 Linux 以外的其他客户机上使用它，但我们发现体验相当麻烦：BSD 的 I/O 和 Solaris 往往很慢（确切地说，是 OpenIndiana）在引导安装 ISO 后会立即出现恐慌。由于我们使用当前版本的 BSD（并且经常从源代码编译/更新系统）并且还需要 Solaris，我们发现 VirtualBox 是一个更好的选择。Oracle VirtualBox 的另一个优点是它支持挂起，即您可以将机器状态保存在主机的硬盘上并关闭 VirtualBox，当（重新)启动时，系统将从它离开的地方恢复。这就是为什么我们提到源代码编译：如果你有一台嘈杂的机器，你不想一夜之间离开，但你的 Gentoo 虚拟机只是编译一个新的 gcc 版本，暂停机器状态，关闭主机，明天继续。\n桌面虚拟化、KVM 还是 Virtualbox？\n这两者中的哪一个更适合在 Linux 台式机/笔记本电脑上运行 Windows 10 虚拟机？\n  带有virt-manager 的QEMU/KVM应该可以与 Virtualbox 媲美。\nVirtualbox 没问题，特别是如果跨主机操作系统使用相同的虚拟化很重要，但 QEMU/KVM 是更好的投资。QEMU/HAXM 也应该可以在 Mac 和 Windows 上运行，尽管它目前还不够成熟。\n  KVM, obviously. You\u0026rsquo;re probably going to need to learn how to manage it, but it is a much better system and allows abstraction on completely unexposed CPU hardware so you can easily take your image and put it onto another KVM. Windows doesn\u0026rsquo;t like to have it\u0026rsquo;s CPUs exchange on it very often.\n  KVM 与 VirtualBox\n  表现\n这是要考虑的最重要的领域之一，即管理程序的性能将如何影响您的基础架构。KVM 是 1 类管理程序（这些虚拟机管理程序直接运行在宿主机的硬件上来控制硬件和管理客操作系统），而 VirtualBox 是 2 类管理程序（这些虚拟机管理程序运行在传统的操作系统上，就像其他计算机程序那样运行），这意味着 KVM 应该优于 VirtualBox。\n根据SPECvirt_sc2013 基准测试，VirtualBox 通常比 KVM 需要更多时间来创建和启动服务器，而 KVM 以接近本机的速度运行应用程序，比其他行业管理程序更快。尽管对于典型负载，差异可能微不足道。\n  管理程序管理\n这两个给定的应用程序都可以通过 GUI 进行管理。Virtualbox 相对来说有更好的 GUI，但 KVM 的当前 GUI 使其管理比以往任何时候都更容易。”\n如果您更喜欢命令行，那么 KVM 中有各种命令行选项。Virtualbox 也提供了一个命令行界面，但它不如 KVM virsh 全面。您不能直接从 bash 启动 Virtualbox VM。\n  可扩展性\nKVM 继承了 Linux 的性能，如果来宾机器和请求的数量增加，可以扩展以匹配需求负载。KVM 允许对要求最苛刻的应用程序工作负载进行虚拟化，并且是许多企业虚拟化设置的基础，例如数据中心和私有云。\nVirtualBox 可以为每个 VM 提供多达 32 个虚拟 CPU，而不管主机上物理存在多少 CPU 内核。还可以为具有多达 1024 个 CPU 的主机提供支持。\n  安全\nKVM 提供增强的安全性，因为它结合使用 SELinux 和安全虚拟化 (sVirt)。VirtualBox 可以执行虚拟机的安全实时迁移和磁盘映像加密。它还包括远程桌面协议 (RDP) 身份验证和用于创建进一步身份验证要求以帮助提高安全性的 SDK。您可以在此页面上看到 Virtualbox 的安全功能列表。\n  成本和定价\nKVM 是一个开源的免费平台，由 Red Hat 等供应商提供有偿支持。虽然 Virtualbox 在限制范围内是免费的。一旦您超过一定的使用水平，您必须获得产品许可。\n  支持\n对于 KVM，您需要依赖开源社区和您自己的 IT 组织或受支持的供应商（如红帽）的支持。Oracle 正在积极开发 Virtualbox，您可以从他们那里获得任何支持。\n  Android-x86 android x86 是一个自由而开源的项目，将谷歌制作的安卓系统从 ARM 架构移植到了 x86 架构，可以让用户在他们的桌面电脑上运行安卓系统来享受所有的安卓功能和应用程序及游戏。\n首次启动运行该安卓系统，运行：\n$ qemu-img create -f qcow2 Android8-VM.img 30G $ gedit start_Android8_VM.sh #!/bin/bash DISKIMG=/media/kurome/Ventoy/QemuKVM/Android8-VM.img exec qemu-system-x86_64 --enable-kvm \\  -hda ${DISKIMG} \\  -net nic -net user \\  -m 4096 \\  -smp cores=2,threads=4 \\  -monitor stdio \\  -vga std \\  -soundhw es1370 \\  -usb -device usb-tablet \\  -name \u0026#39;Andriod8 VM\u0026#39; \\  $@ $ chmod u+x start_Android8_VM.sh $ ./start_Android8_VM.sh -boot d -cdrom ~/Downloads/android-x86_64-9.0-r2.iso 在，安卓系统已经完全安装在你的 android.img 文件中，你应该使用下面的 QEMU 命令来启动它，而不是前面的命令：\n$ ./start_Android8_VM.sh Waydroid Waydroid是一个基于lxc容器技术，用以启动完整安卓系统的方案。\nGenymotion Android Virtual Devices for all your development \u0026amp; testing needs\nLibVF.IO Commodity GPU Multiplexing Driven By VFIO \u0026amp; YAML.\nOSX-KVM macOS VM in QEMU\nquickemu Quickly create and run optimised Windows, macOS and Linux desktop virtual machines.\n","permalink":"https://sakamotokurome.github.io/posts/ubuntup2virtualization/","summary":"Wine 简介 Wine 是在x86、x86-64容许类Unix操作系统在X Window System运行Microsoft Windows程序的软件。另外，Wine也提供","title":"Ubuntu Virtualization"},{"content":"GUI Utilities Chrome 因为 Chrome 安装包的时候会自动添加 gpg，因此可以参考 Bypass GPG signature checks only for a single repository 执行如下操作\n$ sudo sh -c \u0026#39;echo \u0026#34;deb [arch=amd64 trusted=yes] https://dl.google.com/linux/chrome/deb/ stable main\u0026#34; \u0026gt; /etc/apt/sources.list.d/google-chrome.list\u0026#39; $ sudo apt update $ sudo apt install google-chrome-stable PS：之前直接複製網上的，結果一直報錯，原因在於要寫 https 而非 http。\nImport Passwords\n Launch Chrome on your computer. Type the following in the address bar and pressEnter: chrome://flags On the flags screen, put your cursor in the search box and type Password import. You should see the Password import flag in the search results. To enable this flag, click the dropdown menu next to the flag and select Enabled. Click Relaunch at the bottom to relaunch Chrome. This will restore all of your open tabs. When Chrome opens, click the three dots in the top-right corner, and select Settings \u0026gt; Passwords on the following screen. Click the three dots next to Saved Passwords and select Import. Navigate to your CSV passwords file and select it to import it into Chrome.  User Data Directory\n [user data dir] ~/.config/google-chrome [profile dir] ~/.config/google-chrome/Default [user cache dir] ~/.cache/google-chrome/Default  Dark Mode\n注意：以下设置部分在 Android 端依然有效。\n设置：\n Appearance =\u0026gt; Use GTK：在系统启用 Dark 模式下，会使窗口，标签页等浏览器上部分变黑暗 启用 chrome://flags/#enable-force-dark：会使设置页，网页黑暗；在Google 搜索页面，设置 =\u0026gt; 外观 =\u0026gt; 深色主题，可以使搜索结果词条访问过的与没有访问过的相区别（如果没有设置就会呈现一个颜色而无法区分）。有些网页也无效，并且完全看不清文字了，解决办法是启用 Enable with increased text contrast，例如依云的博客。  其他：\n Dark reader 插件：会使网页黑暗。有些页面不起作用，比如 chrome web store、chrome 的设置页、插件、一些网站（即使该网站有黑暗模式，并且跟随系统，依旧显示为 light 模式）。除了无效的，不会使网页变得更难看。 开发工具的暗黑设置：按F12 =\u0026gt; 按F1 ，设置主题为 Dark。  断点续传\n含义：\nPause it with the option built-in to Chrome, and hibernate the computer. If the SERVER that is providing the download supports resuming downloads, then after you resume from hibernation, you should have no issues resuming the download.\nAfter you pause the download, there is no need to touch Chrome. Just pause, and hibernate. By that I mean, don\u0026rsquo;t close Chrome. Don\u0026rsquo;t kill it or edit anything. Just pause the download, leave Chrome up and running, and hibernate.\n明确需求：我要的不是“断点续传”（即 Pause \u0026amp; Resume），而是类似aria2 的“始终断点续传”，前面一种在下载失败后会重新开始下载，而后面一种从失败的地方继续下载。\n方案如下：\n 旧版chrome://flags/#enable-download-resumption，新版内置 Chrono Download Manager 扩展 支持断点续传的下载器，如 wge -c link  Live Caption\nChrome 浏览器内置了实时字幕功能，同步将语音转成文字，显示在网页上，对于看英文视频、听英文播客很有用。\nPWA\nPWA（Progressive Web Apps，渐进式 Web 应用）运用现代的 Web API 以及传统的渐进式增强策略来创建跨平台 Web 应用程序。这些应用无处不在、功能丰富，使其具有与原生应用相同的用户体验优势。\nSpotify、抖音、 微博等都有 PWA 版，只需打开网页，点击搜索栏中右侧电脑图标安装就行了。\nTranslate\n每次打开页面，都弹出翻译来，真得很烦，可以在 Language 中关闭 Offer to translate pages that aren\u0026rsquo;t in a language you read，之后再通过右键\nRemove history of input in Chrome\nTo remove autofill data in chrome. You will have to Clear your auto fill data.\n Open the chrome menu using the three dots in the top, right side of your window and click settings, or navigate to chrome://settings in your address bar. Scroll to the bottom and go into the \u0026lsquo;Advanced\u0026rsquo; section Under \u0026lsquo;Privacy and security\u0026rsquo; select \u0026lsquo;Clear browsing data\u0026rsquo; Then make sure only \u0026lsquo;Auto-fill\u0026rsquo; form data is selected and press the Clear data button Chrome has now removed your auto fill data.  Extensions   阅读模式\n Reader View：Access Firefox\u0026rsquo;s built in reader view from right click context menu Reader Mode    PixelZoomer：测量设计图中图片的尺寸、像素\n  Download All Images：下载网页所有图片\n  uBlock Origin：禁广告\n  沙拉查词：聚合词典专业划词翻译\n  Infinity New Tab：Chrome Extension，解决 Chrome new tab 加载后会清空搜索栏问题\n  DeepL Translate：评论家对于它的评价普遍正面，认为它的翻译比起Google翻译更为准确自然。\n  用户脚本管理器 桌面端\n Chrome：Tampermonkey 或 Violentmonkey Firefox：Greasemonkey、Tampermonkey 或 Violentmonkey Safari：Tampermonkey 或 Userscripts Microsoft Edge：Tampermonkey Opera：Tampermonkey 或 Violentmonkey Maxthon：Violentmonkey AdGuard：（不需要其他软件）  脚本\n FastGithub 镜像加速访问、克隆和下载 秒传链接提取：用于提取和生成百度网盘秒传链接 知乎增强：移除登录弹窗 网页复制限制解除 解锁视频  Chromium Chromium 是一款来自 \u0026ldquo;The Chromium Project\u0026rdquo; 的开源图形网络浏览器，基于 Blink 渲染引擎。它也是商业软件 Google Chrome 浏览器得以组成的基础。\n在这里你可以看到 Google Chrome 与 Chromium 浏览器的区别。此外，还有一点重要的不同：2021年3月2日发布的 Chromium 89 及其以后版本不再支持 Google 账户同步功能。\n注意： 目前，可以通过 使用 Chrome 的OAuth2 凭证或者 申请一个属于自己的凭证来恢复同步功能, 但是请注意，这不一定是一个长期的解决方案。长期来讲，最好考虑使用 xbrowsersync 来同步书签数据。\nFirefox 设置\n Sign In =\u0026gt; Sync Settings =\u0026gt; Proxy =\u0026gt; no proxy Settings =\u0026gt; Search =\u0026gt; Bing Settings =\u0026gt; Home =\u0026gt; Firefox Home Add-ons =\u0026gt; Dark Reader  Multimedia Codecs\n主要用于 Firefox，安装媒体解码器来播放 MP3、MPEG4 和其他格式媒体文件。由于各个国家的版权问题， Ubuntu 在默认情况下不会安装它。\n$ sudo proxychains apt install ubuntu-restricted-extras -y GoldenDict 人一生离不开词典。无论是生活、学习还是工作，当我们遇到不懂的词语时，大部分人的解决方法是使用搜索引擎或者查词软件。作为学习者，我认为查词软件更好用，而且一本或几本好词典能让我们学习事半功倍。而免费查词软件我推荐 GoldenDict。\nGoldenDict 的优点：\n 免费 纯净无广告 == 专注 跨平台：Windows / Mac / Linux 支持多种词典格式 支持查维基百科 / 支持在线查词 / 支持在线翻译（需配置） 支持屏幕取词 == 划词释义 支持听取 forvo.com 上的发音 详见 GoldenDict 官网 的权威说明。  GoldenDict 的缺点：\n 无 OCR 屏幕取词 / 无截屏翻译 无单词本。  知道 GoldenDict 的优缺点后，充分利用其优点的同时，我们想办法补齐短板。\nGoldenDict 擅长查词，不擅长文本翻译，可是查词和文本翻译是分不开的，都是我们学习第二语言时经常需要的功能。为此，我引入两个文本翻译程序：CopyTranslator / Saladict。\n无论你用什么电脑操作系统，都能利用它们进行高效率的查词和文本翻译。我认为这对用户很重要。只要我在系统里，我就能随时查词和文本翻译。\n GoldenDict 擅长查词：\n意味着你可以管理多个词典，并利用好的词典对单词进行深度学习。你把 GoldenDict 想成一个书架，上面放了多本纸质词典供你查阅。\nCopyTranslator / Saladict 擅长文本翻译：\n意味着能极大提高你在文本翻译时的效率。比如拥有多个翻译引擎（Google，Baidu，Youdao 等），方便复制翻译结果等。当然，职业译者肯定使用专业的 CAT 软件。\n 好，下面开始学习使用 GoldenDict。\n安装  **Windows：**下载安装最新版，当前为 [GoldenDict-1.5.0-RC2-372-*.exe（2019-04-27）](https://sourceforge.net/projects/goldendict/files/early access builds/)。 **macOS：**下载安装最新版，当前为 [GoldenDict-1.5.0-RC2-372-*.dmg（2019-04-27）](https://sourceforge.net/projects/goldendict/files/early access builds/MacOS/)。 Linux ：终端上执行安装命令  # Ubuntu / Debian sudo apt install goldendict -y 下面我在 Linux 上做演示操作。（Windows / macOS 大同小异）\n打开 GoldenDict 如果你一直用鼠标点击软件图标打开软件，我强烈建议你用更高效的方式——搜索打开应用。按 Super（Win） 键搜索 gold 再按 Enter 键打开程序：\n第一次使用，建议阅读两遍 欢迎说明。\n 为什么搜索打开应用更高效？这就考验你有没有「搜商」了。搜索只依赖键盘，不依赖鼠标，所以能盲开应用。\n 修改语言 菜单栏选择**【编辑】\u0026gt;【首选项】**：根据需要修改界面语言和显示风格。\n管理词典 下载词典 我选了 4 部体积小的词典进行快速演练：\n词典来源：星际译王词库 词典下载\n Oxford Advanced Learner\u0026rsquo;s Dictionary oxford-gb dictionary (en - zh_CN) 牛津现代英汉双解词典 朗道汉英字典 新华字典  存放词典 根据个人情况选择存放位置。我这里放在 /DATA/Software/GoldenDict/dic/ 下。\n导入词典 菜单栏选择**【编辑】\u0026gt;【词典】\u0026gt;【词典来源】\u0026gt;【文件】\u0026gt; 添加** 选择上一步的词典位置打开，点击 重新扫描 完成后 Apply 应用，切换到**【群组】**选项卡接着完成下一步词典分组。\n词典分组 刚才下载了「四类」词典：英汉、英英、汉英、汉语，需要将它们按类分组。（这里的英汉包括英汉词典和英汉双解词典，同样，汉英包括汉英词典和汉英双解词典。）\n选择**【群组】\u0026gt; 添加群组**，然后在左边 可用词典 中选中，点击中间 \u0026gt; 添加到分组，最后 OK 确认：\n 英汉（En - 中）（自定义快捷键：Ctrl-1）：牛津现代英汉双解词典 英英（En - En）（自定义快捷键：Ctrl-2）：Oxford Advanced Learner\u0026rsquo;s Dictionary 汉英（中 - En）（自定义快捷键：Ctrl-3）：朗道汉英字典 汉语（Chinese）（自定义快捷键：Ctrl-4）：新华字典\n  为什么需要分组？当词典很多时，提高检索速度和分类检索。所以，你也可以按使用频率进行分组，比如分一个 最常用 群组。你喜欢就好。\n 使用 复制查词 最笨最原始的方式，就是复制词语再跑到 GoldenDict 窗口粘贴查询。怎么样才叫不笨呢？\n菜单栏选择**【编辑】\u0026gt;【首选项】\u0026gt;【热键】**可以看到。\n热键 Ctrl+C+C 的意思是，选中需要翻译的词句，按住 Ctrl 再按两下 C 键 ，就能呼唤 GoldenDict 帮你翻译。\n所以正确的查词姿势是：选中词句，Ctrl+C+C。\n下面我列了两个场景现场操练一下（需要完成前面的步骤）：\n 英文场景： 此时你正趴在屏幕前哭逼地学习英文。\nQ：What do I need to plant a flower? A：I need fresh soil and a trowel to dig a hole.\n 我们可以猜出 Trowel 的意思，现在假设你不知道，赶紧选中 Trowel，Ctrl+C+C，在 牛津现代英汉双解词典 里查到是小铲子的意思。\n 中文场景： 此时你正趴在屏幕前读苏轼的《赤壁赋》。\n客有吹洞箫者，倚歌而和之。 其声呜呜然，如怨如慕，如泣如诉；余音袅袅，不绝如缕。 舞幽壑之潜蛟，泣孤舟之嫠妇。\n 假设你不知道 嫠 字怎么读，这时候赶紧选中 嫠，Ctrl+C+C，马上就查出来了读嫠（lí）专指寡妇。\n取词窗口 上有一些按钮，鼠标悬停在上面会弹出解释，常用的是导航栏中的 查询框 、**将词条发送到主窗口（alt-W）**以及 添加收藏（ctrl-E）。 默认在 全部 群组中查询，可以切换到特定群组进行查询。不要怕，不要懒，多点点看看，就能用好这款神器了。\n手动查词：模糊匹配 在查询框中，利用通配符进行词目（headwords）的模糊匹配，可以查询一个记忆模糊的单词。\n通配符：？ （匹配任意一个字符），*（匹配任意字符数字）。\n比如，我要查一下 philosophy 的用法，但是忘记了拼写，我可以搜 ph*phy。使用方法非常简单，不做过多介绍。\n如果实在想不起来英文单词，就查查汉英词典。\n前面四部词典是为了快速演练。下面我将使用我喜欢的词典进行展示，这些词典内容丰富（体积很大），会有更好的展示效果。这些词典在下文 英语词典推荐 部分有介绍。\n调整界面 我们要记住快捷键 Ctrl+M，显示 / 隐藏菜单栏（Menu）。程序窗口中 7 个面板都可以被隐藏，从上到下，从左到右依次为：\n 菜单栏 查询面板 导航栏 词典栏 查询结果导航面板 收藏面板 历史面板  在面板标题上右键，可以选择是否显示该面板。还可以左键拖拽面板调整其位置。我喜欢隐藏菜单栏显示查询面板：\n按住 Ctrl 后滑动鼠标滚轮，可以缩放显示界面。也可以使用导航栏上的放大镜按钮调节。\n我的这部词典有发音，所以可以点击喇叭图标听发音。如果点击喇叭图标没有声音，菜单栏选择**【编辑】\u0026gt;【首选项】\u0026gt;【音频】\u0026gt; 播放 \u0026gt; 设置播放器**，我这里使用了内部播放器： Qt Multimedia 。当然也可以使用外部播放器：mplayer 。(前提是安装了 mplayer ：sudo apt -y install mplayer)\n排序词典 查找单词时，会按照词典栏的词典顺序进行检索，现在我想把 The little dict 放到第一的位置：菜单栏选择**【编辑】\u0026gt;【词典】\u0026gt;【词典】**，把 The little dict 拖到第一位。\n这里调整的是默认群组 全部 中的词典顺序，要调整自定义群组的词典顺序，切换到【群组】选项卡，拖拽群组中的条目进行排序。\n屏幕取词 / 划词释义 Ctrl+C+C 是大多数时候的正常查词姿势，不过在特定场景下，比如阅读生词较多的英文文章、英文书籍时， 打开屏幕取词会使效率提升。点击导航栏中魔法棒图标开启屏幕取词，或者右键托盘图标勾选「屏幕取词」。Windows 上是真的屏幕取词，即鼠标悬停取词；而 Linux 上为划词释义，需要手动选择。\n按 F4 打开【首选项】，在屏幕取词选项卡可以对「屏幕取词」进行设置。除非 Ctrl-C-C 快捷键冲突，否则，保持默认就行。\n LCinux 上，如果你觉得经常按 Ctrl+C+C 麻烦，更喜欢用C鼠标控制取词，你可以勾选「单词被选中时显示扫描旗标」，通过点击旗标进行查词。（Windows 版本没有此选项）\n 一起看看 GoldenDict 与浏览器翻译扩展程序之间的差别：\n 统一入口，使用同一个程序 / 使用自己喜欢的词典来学习； 利用英汉词典快速查看释义，同时可利用其他词典深入学习，边学边用学习效率高（前提是时间允许）； 有些人说扩展更快速，我没感觉出来； 可以跨浏览器、跨软件使用； 离线使用，你可以愉快地看电脑上的英文（DOC、PPT、TXT、PDF、EPUB、HTML 等任何电子文档格式）；  查词：在线词典 本地词典可以灵活选择适合自己的词典，非常惬意！但是本地词库收词有限，如果你遇到一个没有收录的单词，怎么办？\n只能查在线词典了！\n为 GoldenDict 添加在线词典非常简单。\n菜单栏选择**【编辑】\u0026gt;【词典】\u0026gt;【词典来源】\u0026gt;【网站】\u0026gt; 添加 \u0026gt; 启用** ：\n# 欧路 https://dict.eudic.net/dicts/en/%GDWORD% # 有道词典 / 翻译 http://dict.youdao.com/search?q=%GDWORD%\u0026amp;ue=utf8 # Collins Online Dictionary https://www.collinsdictionary.com/dictionary/english/%GDWORD% 切换到【群组】选项卡，添加到名为 Online Dictionary 的群组（自定义快捷键：Ctrl-5）。\n其他在线词典，可通过浏览器访问使用：\n 牛津在线词典 朗文在线词典 剑桥在线词典 韦氏在线词典 Vocabulary.com Dictionary.com 沪江小D在线词典 漢典  查词：维基百科 维基百科绝对是个好东西！\n由于国内无法访问到 English Wikipedia，所以这里取消显示。（除非你在【首选项】\u0026gt;【网络】中通过代理访问）\n菜单栏选择**【编辑】\u0026gt;【词典】\u0026gt;【词典来源】\u0026gt;【维基百科】**，取消勾选。\n查词：搜索引擎 是的，聪明的你一定会想，我可以直接添加搜索引擎吗？可以的。下面是谷歌 / 搜狗 / 百度 / 必应的搜索串：\n# Bing 中国： http://cn.bing.com/search?q=%GDWORD% # Bing 美国： http://www.bing.com/search?q=%GDWORD% # 搜狗 http://www.sogou.com/web?query=%GDWORD% # 百度搜索 http://www.baidu.com/s?wd=%GDWORD% # Google https://google.com/search?q=%GDWORD% 菜单栏选择**【编辑】\u0026gt;【词典】\u0026gt;【词典来源】\u0026gt;【网站】\u0026gt; 添加 \u0026gt; 启用**。切换到【群组】选项卡，将其添加到 Online Dictionary 群组。\n这里我添加必应搜索并查询 蜗牛，然后双击结果 snails 进行英文搜索，可查看搜索引擎里的图片，帮助我们理解记忆单词。因为词典里面配图一般比较少，搜索引擎将使你获得更多相关信息，辅助学习（警惕浪费时间）。\n文本翻译：谷歌翻译 （Linux 上做演示）：如果不显示翻译，可能是代理之类的问题，可以先在终端运行一下 goldendict，之后便没问题了（原因未知）\ntranslate-shell 支持谷歌翻译或者必应翻译，我们可以在 GoldenDict 上利用其进行文本翻译。\n第一步：安装 translate-shell\nLinux\n# Ubuntu $ sudo apt install translate-shell -y macOS\n# Homebrew $ brew install translate-shell # MacPorts $ sudo port install translate-shell Windows\n 配置比较繁琐，推荐使用 xinebf/google-translate-for-goldendict（使用方法见后面）。或者使用 CopyTranslator。  第二步：菜单栏选择**【编辑】\u0026gt;【词典】\u0026gt;【词典来源】\u0026gt;【程序】\u0026gt; 添加**，进行如下配置（类型为纯文本）：\n# Google Translate -\u0026gt; [Chinese] trans -e google -s auto -t zh-CN -show-original n -show-original-phonetics n -show-translation n -show-translation-phonetics n -show-prompt-message n -show-languages n -show-original-dictionary n -show-dictionary n -show-alternatives n -no-ansi \u0026#34;%GDWORD%\u0026#34; # Google Translate -\u0026gt; [English] trans -e google -s auto -t en-US -show-original n -show-original-phonetics n -show-translation n -show-translation-phonetics n -show-prompt-message n -show-languages n -show-original-dictionary n -show-dictionary n -show-alternatives n -no-ansi \u0026#34;%GDWORD%\u0026#34;  -show-original Show original text or not. (default: yes) -show-original-phonetics Show phonetic notation of original text or not. (default: yes) -show-translation Show translation or not. (default: yes) -show-translation-phonetics Show phonetic notation of translation or not. (default: yes) -show-prompt-message Show prompt message or not. (default: yes) -show-languages Show source and target languages or not. (default: yes) -show-original-dictionary Show dictionary entry of original text or not. (default: no) This option is enabled in dictionary mode. -show-dictionary Show dictionary entry of translation or not. (default: yes) -show-alternatives Show alternative translations or not. (default: yes) -no-ansi Do not use ANSI escape codes.  第三步：切换到**【群组】\u0026gt; 添加群组 \u0026gt; Translate**，并添加 图标，设置群组快捷键为 Shift+T（可选）\n第四步：实践一下，在终端中 Ctrl+C+C，查询框处选择 Translate 群组，就看到翻译结果啦\n添加在线翻译后，GoldenDict 就能跨软件快速翻译。无论你是在浏览网页，还是在阅读英文书籍，或者看软件英文手册， Ctrl+C+C 快速查看翻译。你还可以收藏你翻译过的短语。\nWindows 上使用 google-translate-for-goldendict：\n到 Python 官网下载最新版安装包，当前为 python-3.8.2-amd64.exe，安装时勾选 Add Python 3.8 to PATH 就行。\n打开 CMD 运行：\n\u0026gt; python -m pip install --upgrade pip \u0026gt; pip3 install google-translate-for-goldendict  先升级 pip 至最新版，然后再安装。\n 按 F3 打开 GoldenDict 词典配置界面， 进入【程序】选项卡：\n   key value     Enabled ✓   Type Html   Name Google Translate   Command Line python -m googletranslate.googletranslate zh-CN %GDWORD% -s \u0026ldquo;translate.google.cn\u0026rdquo;   Icon H:\\PathTo\\google_translate.png    切换到**【群组】\u0026gt; 添加群组 \u0026gt; Translate**，并添加 图标，设置群组快捷键为 Shift+T。\n文本翻译：有道翻译 在 Linux 上，利用 easeflyer 开发的 gd_plugin 添加有道翻译。\n将项目克隆下来：\n$ cd ~ $ git clone git@github.com:easeflyer/gd_plugin.git 按 F3 打开 GoldenDict 词典配置界面， 进入【程序】选项卡（路径替换为自己的绝对路径）：\n   key value     Enabled ✓   Type Html   Name Youdao Translate   Command Line /home/YOUR_USER_NAME/gd_plugin/youdao/youdao_get.py %GDWORD%   Icon /home/YOUR_USER_NAME/gd_plugin/youdao/youdao.svg    下载图标 Youdao icons。\n切换到【群组】选项卡，将其添加到 Translate 群组。\n文本翻译：CopyTranslator CopyTranslator 是复制即翻译的外文辅助阅读翻译解决方案，支持 Windows、Mac、Linux 三大平台，翻译引擎包括 Google，Baidu，Youdao，Sogou，Caiyun，Tencent。\n下载 CopyTranslator 安装包 进行安装后，使用方法请阅读 CopyTranslator 官方文档。\nCopyTranslator 擅长文本翻译，可是与 GoldenDict 交互使用时不够高效。所以，使用 GoldenDict 能满足需求时，就没必要打开 CopyTranslator。\n 有一款叫做 多译 的软件与 CopyTranslator 有相同功能，但是有字数限制，有兴趣可以了解一下。\n 文本翻译：Saladict Saladict 沙拉查词（Chrome / Firefox）插件天生适合浏览器，Saladict 插件可以在线翻译、在线查词、在线语音朗读、添加单词本、页面翻译等。\n使用方法参阅官方文档 沙拉查词使用方式。以及：\n 别找了，这才是你要的英文文献翻译神器！ 文献翻译利器：沙拉查词 + Quicker，这或许是 Windows 上最强的聚合翻译方案  OCR 屏幕取词 / 截屏翻译 GoldenDict 默认无 OCR 屏幕取词，无截屏翻译。先介绍一种三个平台都通用的方法，使用 Utools + 扩展：讯飞 OCR + 扩展：沙拉查词。步骤为，将要翻译的文本截图粘贴到 Utools 中，然后选择「讯飞 OCR」识别内容，最后点击翻译按钮调用「沙拉查词」进行翻译。操作起来还是比较快的。\n或者使用其他软件：\nWindows\n 使用 Quicker 效率神器。（与 Utools 相似） 使用 nonwill 发布的 GoldenDict OCR 划词版。  macOS\n 使用有道词典 Mac 版。打开取词（CTRL + 鼠标取词）。 欧路词典。  Linux\n 利用 words-picker 进行截屏翻译。在 GNOME 桌面环境中，打开 words-picker 程序，然后使用系统截图快捷键 shift-ctrl-Print 将区域复制到剪贴板，完成截屏翻译。 使用有道词典 Linux 版。打开取词（CTRL + 鼠标取词）。 使用 CuteTranslation 进行截屏翻译。  对于那些无法复制的单词，如果查词频率高，就使用具有 OCR 屏幕取词的软件；如果偶尔查询，手动输入也不是什么坏事。\n文本语音朗读 你可能会说：我不需要语音朗读。那是因为你没意识到它的用处或者说你忽略了它。你一定很喜欢词典中的例句发音，对听力和练习口语都有帮助。例句发音 = 句子 + 语音朗读，发散一下你的思维，当你翻译一个句子时，出于学习目的，你是不是同样希望能够听到它的语音朗读。而且学习英语不能太依赖眼睛，要多用耳朵听。\nWindows 上按 F3 打开词典配置， 在【语音合成】选项卡进行配置；Linux 版本暂时没有 text-to-speech (TTS) 功能。Saladict 够用，我就不折腾了。\n这里再推荐两款优秀的浏览器插件：\n Natural Reader Text to Speech Read Aloud: 文本语音朗读助理  还有一个 灵云语音云服务：\n 它可以 文字转音频 / 录音转文字。 它更加侧重于应用场景，不过现在已经收费了。  总之，根据自己的需求，去寻找好资源。\n背单词 GoldenDict 无单词本，意味着你不能像欧路词典那样，将单词添加到单词本中进行背诵。所以，只能「曲线救国」，将单词添加到收藏，隔一段时间（星期 / 月）就将收藏 导出至列表，然后放到 Anki 或 欧路词典中进行背诵复习。如有必要，付钱换取方便远离折腾。\n将收藏 导入欧路词典单词本：菜单栏选择**【帮助】\u0026gt;【配置文件夹】**，可以看到收藏文件：favorites。\nAnki 神器的使用，有兴趣可以深入了解。 干货 / 百科\n备份配置文件 换机或者重装系统时，需要备份你的 GoldenDict 配置文件。否则，一切将从头再来，你会很痛苦。\n菜单栏选择**【帮助】\u0026gt;【配置文件夹】**，直接将整个文件夹进行备份。\n新机或者新系统上，将整个文件夹拷贝到原来的位置，完成配置恢复。\n恭喜！你会使用 GoldenDict 了！ 前面主要介绍了 GoldenDict 的使用方法。为提高文本翻译效率，引入了 CopyTranslator / Saladict 两款程序。为补足 GoldenDict OCR 屏幕取词和截屏翻译的缺失，也引入了相应的软件。我们期望有那么一款软件能聚合这些功能，但这样的软件我还没发现，或者说还没有。\n现在的 GoldenDict 具备了离线查词、在线查词和在线翻译的能力，完全能满足我们的需求。而且 GoldenDict 的离线词库拥有最强的学习效果，所以你应该主要使用 GoldenDict 进行查词和文本翻译，而 CopyTranslator / Saladict 作为备用软件，主要用于增强文本翻译。同时也是为了统一入口，避免分散你的学习精力。具体怎么配合，多多使用，慢慢摸索。\n细心的你不难发现，查词和文本翻译里面最核心的是词典和翻译引擎。\n这里我们讨论一下词典。选用什么词典？我们需要做功课来回答。\n我不打算直接甩几本词典放这里，对于新手，看了一定是云里雾里。\n因为词典是每个人必须会用的东西，所以值得深入学习。\nEnglish Dictionary = 英语词典\n字典和词典是两个不同的概念，不要乱叫。中国正式使用“字典”一词始于《康熙字典》。根据《说文解字》，典是五帝的书本，神圣尊贵的大册。\n字典和词典的区别：\n 字典是为单字提供音韵、意思解释、例句、用法等等的工具书。使用字母文字作为文字的人群没有字典这个概念。字典收字为主，亦会收词。 词典（Dictionary），或称辞典，是为词语提供音韵、释义、例句用法等等的工具书。在东方社会中，词典收词为主，也会收字。为了配合社会发展需求，词典收词数量激增并发展出不同对象、不同行业及不同用途的词典。随着吸收百科全书的元素，更有百科辞典的出现。  如果你把 English Dictionary 翻译成「英语字典」，我只能安慰你：没文化不是你的错！\n掌握词典行情，便于做出选择\n通过了解词典的行情，了解词典应该为学习者提供哪些东西，我们就能选择适合自己的词典。如果同学 / 同事 / 朋友 / 小孩需要词典，也能轻松推荐。做「以其昏昏，使人昭昭」的事，心理没底不说还会被内行笑话。\n下面主要讨论一下英语词典，对于汉语词典或者其他外语词典（日语、法语、德语、俄语或西班牙语等），自行了解。\n提醒：后面的内容可能需要阅读多遍。\n浅谈英语词典版本 我们主要以 出身、体例、功用 以及 规模 四个方面对英语词典进行分类。\n一、出身 从出身上讲，英语词典大致可分为本土词典和引进词典两类。\n 本土词典主要是中国人编给中国人用的英汉词典，典型如译文社《英汉大词典》（陆谷孙主编）、《新英汉词典》（第4版）、商务《新时代英汉大词典》（张柏然主编）等。 引进词典又分为英系和美系两大类。目前英系词典占据中国市场的主导地位，著名的品牌如牛津、朗文、剑桥、麦克米伦、柯林斯，简称“牛朗剑麦柯”（谐音“牛郎见迈克”）合称“英国五虎”，除此还有一部词典叫做“钱伯斯”，对英国人意义非凡。美系词典主要有《美国传统词典》（The American Heritage Dictionary）和“韦氏词典”两大品牌。  二、体例 以体例划分，英语词典可分为英汉、英英、英汉双解、汉英、汉英双解以及其他类别等五种。\n 英汉词典 一般为（wéi）中国人所编写，如译文社《新英汉词典》； 英英词典 都是原版引进词典，如《牛津高阶英语词典》（OALD）、《朗文当代高级英语辞典》（Longman Dictionary of Contemporary English，简称 LDOCE）； 英汉双解词典 是目前英语学习词典的主流，最重要的即是牛朗两部词典，英汉双解词典都译自英语原版词典，但并非真正全文翻译，大多数词目的英语释义以对应的汉语词语。 汉英词典 大多是本土词典，如外研社《新世纪汉英词典》、商务《新时代汉英词典》； 汉英双解词典 比较特殊，它是以国内原版的汉语词典编译而成，据我所知，目前只有外研社《现代汉语词典（双语版）》以及商务印书馆国际有限公司《新华字典（双语版）》两种； 除此以外，其他类别指的是国内引进少量英语与其他语种词典，如译文社引进的兰登系列词典《德英—英德小词典》（Random House Webster\u0026rsquo;s Pocket German Dictionary）以及外教社引进的《柯林斯英德—德英词典》等。  注：所谓双解词典,是一个英文单词,用英文解释一遍意思,再用中文解释一遍意思;用英文来解释是最准确的,中文可以辅助你去理解。 如果想通过中文查英文,需要一本汉英词典。\n三、功用 首先从功用方面，将英语词典分为描述型、学习型和中和型三大类。\n 描述型  描述型英语词典又称为学术型英语词典，实际上描述型英语词典是最常见的英语词典，换作汉语工具书，诸如《新华字典》《现代汉语词典》都属于描述型词典，相反汉语工具书真正缺乏的学习型词典，除了一些给低幼学童使用的学习词典外，也就只有吕叔湘先生主编的《现代汉语八百词》等寥寥几部辞书。\n我们进一步将描述型英语词典分为一般性、百科性和专业性三种。一般性描述词典典型如《牛津简明英语词典》《英汉大词典》，这类词典收词详备并且释义简明；百科性描述词典则有《牛津当代百科大词典》《牛津英美文化词典》等，主要收录文化百科类词条；专业性描述词典则是局限于某一学科或行业的词典，如《牛津哲学词典》和《牛津商务英语词典》。\n学习型  学习型英语词典是专为英语学习者（多为非英语母语人士）设计的，注重英语实际应用时的用法说明，第一部学习型词典始于 1948 年由牛津大学出版社出版、霍恩比（A S Hornby）主编的《现代英语学习词典》（A Learner\u0026rsquo;s Dictionary of Current English），此即如今闻名于世的《牛津高阶英语词典》（OALD）的前身。\n我们进一步将学习型英语词典分为一般性、多功能和专门性三种。\n一般性英语学习型词典是我们最熟悉的品种，著名的“英国五虎”——“牛朗剑麦柯”都有自己品牌的学习型词典。（划重点）\n 最新版次，出版年份，出版社\n 《牛津高阶英汉双解词典》第 9 版，2018，商务 Oxford Advanced Learner\u0026rsquo;s Dictionary (OALD) 9th Edition , 2015 , Oxford 《朗文当代高级英语辞典》第 6 版，2019，外研社 Longman Dictionary of Contemporary English (LDOCE) 6th Edition , 2015 , Pearson 《剑桥高阶英汉双解词典》第 2? 版 ， 2008，外研社 Cambridge Advanced Learner\u0026rsquo;s Dictionary (CALD) 4th Edition , 2013 , Cambridge 《麦克米伦高阶英汉双解词典》第 1 版，2018，外研社 MacMillan English Dictionary for Advanced Learners (MED) 2nd Edition , 2012 , MacMillan 《柯林斯高阶英汉双解学习词典》第 8 版，2017，外研社 Collins COBUILD Advanced Learner\u0026rsquo;s Dictionary (CCALD) 9th Edition , 2018 , Collins   注： 关于书籍版次：第一次出版印刷的书写有“某年某月第一版，第一次印刷”，这叫初版，如内容不变动，第二次印就注明第一版第二次印刷，这种书叫重印书。如第三次印刷发行时内容经过重大修改，版次就要重新算，要称为：“第二版第三次印刷”。不过这个问题一般人不用想那么多，只需看自己是否喜欢这本词典，喜欢的话买国内最新版即可，毕竟每家词典各有特色。英语水平好的话，直接购买英文原版就行了。\n中和型  中和型词典兼具学习型词典和描述型词典的部分特点，是当前英语词典编纂的新趋势，典型代表为《朗文当代英语大辞典》，在 2000 词限定释词的基础上收录了 15,000 百科词条，是融合释义、用法说明、文化注释以及百科知识于一体的文化学习词典。与此相类的另有《美国传统词典》。\n四、规模 这是对英语词典最直观的分类，一般而言我们可以根据收词量和总字数将英语词典简单分为巨、大、中、小、微型五大类。\n 巨型词典  英语世界中的巨型词典主要有两部，一部即是由英国语言学家默里（James A.H.Murray）主编的久负盛名的《牛津英语词典》（The Oxford English Dictionary，简称 OED），另一部则是最初由美国词典编纂家韦伯斯特（Noah.Webster）主编的《韦氏新世界词典》（Webster Third New International Dictionary，简称 WTNID）。这两部词典是其他各类英语词典的母本，但却因其规模过大并不适合学习者案头使用。\n大型词典  因此 20 世纪下半叶英语国家出版了大量单卷本供高阶学习者案头使用的大型词典，典型的有《牛津简明英语词典》（Concise Oxford Dictionary，简称 COD）、《柯林斯COBUILD英语词典》（Collins COBUILD English Dictionary，简称 CCED）以及《朗文当代英语大辞典》（Longman Dictionary of English Language \u0026amp; Culture，简称 LDELC）；\n中型词典  后来又有供中阶学习者使用的中型词典，主要有《牛津袖珍英语词典》（Pocket Oxford Dictionary，简称 POD）、《朗文活用英语词典》（Longman Active Study Dictionary，简称 LASD）；\n小型词典  其实除了案头常备的大中型词典，人们更为喜爱和常用的或许是那些便携的小型词典，如《牛津英语小词典》（Little Oxford Dictionary，简称 LOD）；\n微型词典  除此以外，还有一种更其小巧的微型词典，释义极尽简洁，如《牛津英语微型词典》（The Oxford Minidictionary，简称 OMD），但这类词典一般用于速查，不适合英语学习者日常使用。\n词典应该为学习者提供哪些东西 用一本好词典你可以做到以下几点：\n 查找你看到或听到的英语单词的意思 找出如何说一个词 用你的语言找到一个单词的英文翻译 检查单词的拼写 检查动词的名词或过去时态的复数形式 找出一个单词的其他语法信息 找出一个词的同义词或反义词 查找单词的搭配 检查单词的词性 找出单词的语域 查找自然语言中单词的用法示例 听到例句的真人发音 查看配图学习单词 查看单词错误用法 观看单词在线教学视频（想象一下，当你查一个单词，一位美女 / 帅哥马上跳出来教你。恐怕你要天天抱着词典睡觉喽。）  所以，按照类型我们需要四种电子词典：英汉、英汉双解、英英、汉英。\n英汉词典：\n英汉词典主要是快速查看英语单词的中文释义。\n英汉双解词典：\n英汉双解词典对中级学习者当然非常友好，可以借助汉语翻译快速理解。如果查询一个单词需要耗费大量时间阅读英文解释，有时候是不明智的做法，并且，如果查一个单词里面又出现一大堆不认识的单词，太打击学习积极性了！另外，英汉双解词典是双向的，一般人是借助汉语理解英文，也有情况是借助英文查看对应的汉语翻译。所以，每个人必须有一本英汉双解词典。\n英英词典：\n当你英语到了一定水平（中高级水平）后，就应该主要使用英英词典。\n英英词典分两种：ESL 词典（ESL: English as a second language）以及 Non-ESL 词典（又称母语词典）。Non-ESL 词典是指英美国家人士使用的词典，特点是收词量大，释义用词精确，范围广，无上限，很多词典例句很少或没有，有点类似于我们用的《新华字典》和《汉语大词典》 。ESL 词典就是上小节提到的学习型英语词典，专为英语学习者（多为非英语母语人士）设计，其优点是简单易懂，但其缺点也比较明显，由于释义用词所限，部分单词的解释比较啰嗦或者不精确，理解起来也不顺畅。\n至于使用 ESL 词典还是 Non-ESL 词典，或者两者混合使用，就看你的需求了。\n汉英词典：\n使用汉语查找英文翻译或英文表达。\n 翻译软件的词库就来自于这些「英汉词典」和「汉英词典」。\n 有了上面的介绍，我可以推荐几本词典了。\n英语词典推荐 1. 英汉词典：The Little Dict 用来提供快速翻译，还能聆听多个发音以及查看词频。「硬核之作，真香推荐，居家旅行沉迷学习必备，建议日常置顶食用。」下载\n2. 英英·英汉双解词典（ESL）  朗文当代高级英语辞典（释义用词 2000 个） 柯林斯高阶英语学习词典（释义用词 2500 个） 牛津高阶英语词典（释义用词 3000 个）  2.1 朗文当代高级英语辞典\n英英原版\n Longman Dictionary of Contemporary English 6th Edition (En-En)，En-En_LDOCE6。 《朗文当代高级英语辞典（英英）（第六版）》，包含英式发音、美式发音、大部分例句朗读，带图片详解。这本词典收录单词量最大，例句最多，搭配和用法也最全。例句是真人原声，非常自然。 英语老师都会倡导学生尽量使用英英词典，营造英语环境，用英文解释英文，用英文理解英文，用英文对世界编码，有利于养成英语思维，对听说读写都有帮助。全英文解释，不会因为英汉差别而导致理解上的偏差。当然，英汉双解词典我们也是需要的。  英汉双解版\n En-Cn_LDOCE5++ V1.35 / V2.15。下载 《朗文当代高级英语辞典（英英·英汉双解）（第五版）》 这本词典默认是英英版，可以通过点击轻松查看汉语翻译。对于直接使用英英有些吃力的同学，可以设置默认展开汉语，立马就是一本英汉双解词典。释义用词仅 2000 个，让你轻松看懂。大量例句都有真人发音，让你爱上听例句。  PDF 版\n 《朗文当代高级英语辞典（英汉双解）（第五版）》。下载  朗文在线词典\n www.ldoceonline.com  2.2 柯林斯高阶英语学习词典\n英英原版\n Collins COBUILD Advanced Learner\u0026rsquo;s Dictionary 9th Edition (En-En)，En-En_CCALD9。  英汉双解版\n Collins COBUILD advanced learner’s English-Chinese dictionary 8th Edition。 《柯林斯COBUILD高阶英汉双解学习词典》（第8版）中的全部释义、例证及专栏均基于收词规模达 45 亿词的柯林斯英语语料库；所有单词及短语均采用整句释义，凸显词汇在典型语境中的典型用法。 强烈推荐！可以直接背诵单词及短语的整句释义，这就好比一个外国人在跟你交谈，对英语思维以及口语表达都有莫大的帮助。  柯林斯在线词典\n www.collinsdictionary.com  2.3 牛津高阶英语词典\n英英原版\n Oxford Advanced Learner’s Dictionary 9th edition (En-En)，En-En_OALD9。下载 包含英式发音、美式发音，例句发音，带图片详解等。  英汉双解版\n Oxford Advanced Learner’s English-Chinese Dictionary 9th Edition，En-zh_CN_OALD9。下载 《牛津高阶英语词典》为世所公认的权威英语学习词典，惠及世界各地一代又一代学子。到第九版编者将会话与写作功能融入学习型词典。 释义简明，义项划分清晰；提供系统的语法信息，如搭配模式、用法说明框等；提供插图及主题图片，直观释义。新加牛津口语指南，详解日常及应试等场景会话用语。 纸质版配套光盘中提供 iWriter + iSpeaker 互动式写作和口语指导学习程序。  牛津在线词典\n www.lexico.com www.oxfordlearnersdictionaries.com  3. 汉英词典（任选一部）  汉英大词典（第3版） 新汉英大辞典  一般人上面几部词典基本够用。如果链接失效，可以试试 网盘搜索（超能搜 等）或者 逛论坛。\n英语构词法规则 GoldenDict 安装的时候没有附带 构词法规则，查找一些单词的复数等变位变格形式的单词有时会查不到（比如有些词典查不到 Books，不会自动跳转到 Book），为了让 GoldenDict 更好地工作，我们添加 英语构词法规则库。\n进入 SourceForge 上 GoldenDict 的项目地址，依次选择 Files \u0026gt; [better morphologies](https://sourceforge.net/projects/goldendict/files/better morphologies/) \u0026gt; [1.0](https://sourceforge.net/projects/goldendict/files/better morphologies/1.0/) \u0026gt; [en_US_1.0.zip](https://sourceforge.net/projects/goldendict/files/better morphologies/1.0/en_US_1.0.zip/download) 下载英语构词法规则库。\n菜单栏选择**【编辑】\u0026gt;【词典】\u0026gt;【词典来源】\u0026gt;【构词法规则库】**，添加 英语构词法规则库。\n朗文5 ++：自动展开音节（Syllable）及汉语（Chinese） 我是 En-Cn_LDOCE5++ 和 En-En_LDOCE6 一起使用，所以把 LDOCE5++ 设置为自动展开音节及汉语。\n下面介绍一下设置方法，适用于 En-Cn_LDOCE5++（V1.35 / V2.00 / V2.15）。\n自动展开音节（Syllable）\n打开文件 LM5style.css 搜索 show/hide syllable 注释掉以下代码块：\n/* -------------- show/hide syllable ------------- .HWD .HYP { display: none; }*/ 调整手机中悬浮球高度\n手机欧路词典中 LDOCE5++ 的悬浮球会与控制按钮重叠，需要调整其高度。搜索 .mobile .lm5pp_popup 设置距离底部为 90px：\n.mobile .lm5pp_popup { bottom: 90px; right: 10px; } 自动展开汉语（Chinese）\n打开 LM5style_switch.css 注释掉以下代码块：\n/*.EXAMPLE .cn_txt, .Error .cn_txt,.cn_txt { display: none; }*/ 可以偷懒直接删除 LM5style_switch.css（或者重命名为 LM5style_switch.css.bak）。但是，你将不能在悬浮球上控制隐藏/显示汉语。\n 如果你直接修改手机中的 CSS 文件，需要清除软件缓存再重启 App 才能生效。 如果你在电脑上修改，Ctrl+F5 可以快速刷新词典查看效果。 更多调整参见 FF朗文5++重排 DIY / 改版 fearfare 大的朗文。\n GoldenDict 进阶技巧 效率提升：快捷键 除了全局热键外，GoldenDict 还支持许多程序快捷键。按 F1 快捷键打开 GoldenDict 帮助， 查看 13 Shortcuts。\n第一次使用，按照快捷键列表操作一遍。主要是感受一下快捷键的功能，不要求强行记忆它们，当你经常进行某项操作时，再翻阅一下 13 Shortcuts，用几次就记住了。\n常用快捷键：\n   Shortcut Action     Alt+Left (In main and popup windows) history navigation: show previous founded results   Alt+Right (In main and popup windows) history navigation: show next founded results   Alt+Down Jump to article from next dictionary   Alt+Up Jump to article from previous dictionary   Alt+S (In main and popup windows) playback pronunciation for current word   Alt+W (In popup window) transfer word from search line to main window   Alt+PgDown (In main and popup windows) switch to next dictionaries group   Alt+PgUp (In main and popup windows) switch to previous dictionaries group   Ctrl++ Increase articles font size   Ctrl+– Decrease articles font size   Ctrl+0 Set default articles font size   Ctrl+E Add current tab to Favorites   Ctrl+F (In main and popup windows) search in page / (In dictionaries dialog) go to filter line   Ctrl+M Show/hide main menu   Ctrl+Q (In main window) close GoldenDict   Ctrl+S Show/hide search pane   Ctrl+Shift+F Open/switch to full-text search dialog   Esc (In main window) go to search line (the action for Esc key can be changed in preferences) / (in popup window) close popup window   F1 GoldenDict reference   F3 Dictionaries dialog   F4 GoldenDict preferences    查句：全文搜索 按 F1 打开 GoldenDict 帮助， 查看 09 Full-text search。\n可以通过菜单“搜索”或按“Ctrl+Shift+F”键来调用全文搜索对话框。通过全文搜索，可以在当前词典组的词典文本中而不是在词典 headwords（词目）中搜索单词和表达式。\n **提醒：**如果 GoldenDict 占用 CPU (%) 超高，请关闭全文搜索索引。看一下文章 GoldenDict 全文搜索几例。\n 利用「全文搜索」查找英文表达，显然比直接将一句中文放到翻译软件中翻译更靠谱，比如下面这句摘自 牛津高阶英汉双解词典（第 9 版） 的例句：\n I\u0026rsquo;ll ask my boss if I can have the day off. 我要问一下老板我能不能请一天假。\n现在我复制中文到谷歌翻译中翻译，结果如下： I have to ask the boss if I can take a day off.\n 很显然翻译出来的英文枯燥无味。\n  下面举例简单介绍一下，使用「全文搜索」查找地道的英文表达。\n 例子：我想知道请假的的英文表达，包括日假周假年假。我该如何搜索？\n 快捷键 Ctrl+Shift+F 打开全文搜索，模式选择 正则表达式。\n如果直接检索 请假 这个关键词，会因范围太大，需要更多检索时间，最后还会出来很多无用结果，所以我们需要缩小检索范围。\n先检索日假。直接输入 请一天假，这个地球人都会，但「请两天假」的表达式就搜不到。现在，我们要一次检索出「请天假」的表达式，输入正则表达式：请.{1,3}天假（中间匹配 1-3 个字符）。\n理论上，我们可以匹配出：请一天假 请两天假 请几天假 请过一天假 请了十五天假 ...\n .：一个点，匹配任意单字符（不包括换行符） {n,m}：m 和 n 均为非负整数，其中 n \u0026lt;= m。最少匹配 n 次且最多匹配 m 次。例如，\u0026ldquo;o{1,3}\u0026rdquo; 将匹配 \u0026ldquo;fooooood\u0026rdquo; 中的前三个 o。\u0026lsquo;o{0,1}\u0026rsquo; 等价于 \u0026lsquo;o?'。请注意在逗号和两个数之间不能有空格。\n 现在，我们要把请日假 / 周假 / 年假的表达式一次搜出来。 给搜索框写入正则表达式：请.{1,3}(天|周|年)假，就查出来了。\n ()：标记一个子表达式的开始和结束位置。()? 匹配前面的子表达式零次或一次，()+ 匹配前面的子表达式一次或多次。 |：代表 或\n 正则表达式学习资源：\n 正则表达式 – 语法 _ 菜鸟教程 油管最受欢迎的+正则表达式教程【11集】 练习正则表达式的网站：RegExr  多读几遍 GoldenDict 帮助，掌握更多使用技巧。\n其他  GoldenDict 界面显示风格、字体、背景等的修改 GoldenDict 专贴！  参考文章  GoldenDict 中文用户手册 新手上路：GoldenDict——英语爱好者必备词典 [使用教程] Linux 上最好用的词典 GoldenDict 在 GoldenDict 中添加谷歌翻译 Ubuntu 安装 GoldenDict 英语词典版本浅谈（讲稿版） Linux 下非常好用的字典 GoldenDict！ GoldenDict 添加构词法规则库 GoldenDict 词典的超级实用高级玩法——全文搜索功能  Dark Theme GoldenDict Dark Theme\n官方教程。\nGoldenDict-Full-Dark-Theme\n这个主题有个全黑暗模式，即显示词典结果部分也会黑暗，但是效果不好，看不清。\nDownload GoldenDict-Full-Dark-Theme Move styles and fonts folders to the GD Configuration Folder. If GoldenDict is installed by default, the GD Configuration Folder is located at the ~/.goldendict Move the icons folder to the GoldenDict program folder /usr/share/goldendict Open GoldenDict menu \u0026ldquo;Preferences\u0026hellip; → Interface\u0026rdquo;: set \u0026ldquo;Add-on style\u0026rdquo; to dark-theme; set \u0026ldquo;Display style\u0026rdquo; to Lingoes. set \u0026ldquo;Display style\u0026rdquo; to Default.  startup \u0026amp; silent start   startup：将 goldendict 添加到 gnome-session-properties，默认生成的是\n$ cat ~/.config/autostart/goldendict.desktop [Desktop Entry] Type=Application Terminal=false Categories=Office;Dictionary; Name=GoldenDict GenericName=Multiformat Dictionary Comment=A feature-rich dictionary lookup program Icon=goldendict Exec=goldendict   silent start：Edit =\u0026gt; Preferences =\u0026gt; start to system tray 就是静默启动\n  crow-translate Flameshot Powerful, yet simple to use open-source screenshot software.\n   Keys Description     ←, ↓, ↑, → Move selection 1px   Shift + ←, ↓, ↑, → Resize selection 1px   Esc Quit capture   Ctrl + C Copy to clipboard   Ctrl + S Save selection as a file   Ctrl + Z Undo the last modification   Right Click Show color picker   Mouse Wheel Change the tool\u0026rsquo;s thickness    Add a new Shortcuts\n On \u0026lsquo;Name\u0026rsquo;, name it \u0026lsquo;Flameshot\u0026rsquo; Define the command as \u0026lsquo;flameshot gui\u0026rsquo;. Select \u0026lsquo;Define shortcut\u0026hellip;\u0026lsquo;and click your keyboard win + shift + Prt Sc key.  PPSSPP A PSP emulator.\n$ sudo add-apt-repository ppa:ppsspp/stable $ sudo apt-get update $ sudo apt install ppsspp Graphics:\n Rendering Mode  set the Backend from OpenGL to Vulkan.   Framework Control  Frameskipping is Off Auto-Frameskip is Off set the Alternative Speed to Unlimited   Postprocessing effects  Postprocessing shader should be off.   Performance  If your Device is Powerful, high rendering resolution will work. Its recommended to first try with 2x Rendering resolution as It brings impressive graphics and supports stable gameplay too Hardware transform, Software skinning, Vertex cache and Lazy texture caching should be checked. Retain changed textures should be unchecked while keeping Disable slower effects and Hardware Installation checked.   Overlay Information  Select FPS in Show FPS counter.    System:\n Make sure Fast memory is checked Set I/O timing method, to Simulate UMD delays or Fast  Cemu Cemu: Experimental software to emulate Wii U applications.（已开源）\n对于Ubuntu（Linux）：参考 Current State Of Linux Builds安装\n对于Windows 平台：为避免闪退等问题，到Cemu 官网下载最新版本软件和 Microsoft Visual C++ 2017 X64 Redistributable。\n安装游戏：导航到 Options \u0026gt; General settings \u0026gt; General，在 Game Paths 中添加游戏 .rpx 文件所在目录，游戏就会显示在列表之中。\nCemu vs Yuzu (Zelda BOTW) 说：At this moment, the Wii U version played on Cemu is the superior one in both performance and quality.\n根据 Zelda BOTW runs way better for me on Yuzu than on Cemu 讨论，为更好性能，需要安装并启用 Graphic packs。导航到 Options \u0026gt; Graphic packs，启用对应游戏的（保持默认配置就行）：\n Enhancements Graphics Mods.Extended Memory Mods.FPS++  运行游戏会发现，在实时编译 shaders 和 vkpipeline 时会卡顿。\nshaders 通过 transferable shader cache 解决。首先需要在网上找对应游戏他人分享的 Shader caches，不同地区（日版、美版、欧版）的shader cache 是通用的，Shader caches 越全越好（越大越好）。先运行一下游戏，会在 cemu\\shaderCache\\transferable 建立两个 bin 文件，如 xxx_shaders.bin 和 xxx_vkpipeline.bin，将下载解压后的 bin 文件重命名为游戏创建的 xxx_shaders.bin 文件并替换该文件。再次运行游戏，如果显示 complie cache shader 并且 cemu\\shaderCache\\transferable\\xxx_shaders.bin 大小没有变为 0 的话，说明成功了。\nvkpipeline 通过启用 Options \u0026gt; General settings \u0026gt; Graphics \u0026gt; Async shader complie 解决。启用该功能可能需要安装最新 NVIDIA 显卡驱动（看报不报错）。\n你会发现不能推出游戏 go back to the Cemu main menu，这是可能原因：I would think they did it that way for easeof development. For example on yuzu if you exit to main menu it will not allocate the ram correctly. Meaning if you launch a game and it uses 8gb of ram then exit to a new one, without fully closing yuzu, yuzu would use and extra 8gb of ram on top of that.\n在 [汉化] 【91Wii索引】WiiU游戏汉化补丁及中文游戏资源索引帖 下载解压汉化包后，覆盖掉原游戏根目录中对应的原文件就可以使用了。\n攻略本（Strategy guide），或称攻略，是指收录特定电子游戏提示或完整解的说明书，内容环绕一款或多款电子游戏的过关方法、注意点等。\n游戏模组，这个游戏术语源自英文缩略词“MOD”、“Mod”（全称“Modification”，本意为“修改”），多指游戏厂商或者热心玩家对于原版电子游戏在功能方面的修改。\nyuzu yuzu 是 Citra的制作者写的一个开源NS模拟器，用C++编写，特点包括Vulkan API的支持、灵活的模拟器配置以及游戏配置等等。\n玩了 super mario odyssey，过场动画很卡顿，可以软配置的很少，主要看硬件配置，我的配置玩 BOTW 是不可能了。\n安装   选择 File -\u0026gt; Open yuzu Folder\n  在打开的目录下，新建keys文件夹（如果没有），然后进入keys文件夹，放入key文件prod.keys，内容如下\naes_kek_generation_source = 4d870986c45d20722fba1053da92e8a9 aes_key_generation_source = 89615ee05c31b6805fe58f3da24f7aa8 bis_kek_source = 34c1a0c48258f8b4fa9e5e6adafc7e4f bis_key_00 = 374e0e2ab275141f811badcb0fefd881b71d6af540de58895901aa0c01663bc8 bis_key_01 = 0b08f19a42ac5ae590b3373ad9698344a571f35165663536dae0842b5221b31c bis_key_02 = 38f0936f33bacedc0c0a159ffbbeee0f40bb08386915bdd0c6730349b99081ec bis_key_03 = 38f0936f33bacedc0c0a159ffbbeee0f40bb08386915bdd0c6730349b99081ec bis_key_source_00 = f83f386e2cd2ca32a89ab9aa29bfc7487d92b03aa8bfdee1a74c3b6e35cb7106 bis_key_source_01 = 41003049ddccc065647a7eb41eed9c5f44424edab49dfcd98777249adc9f7ca4 bis_key_source_02 = 52c2e9eb09e3ee2932a10c1fb6a0926c4d12e14b2a474c1c09cb0359f015f4e4 device_key = bd16c45b2647d842c5ee3c869e3a9607 device_key_4x = 2078900c6bb36fff1fdad57a7dd1b66e eticket_rsa_kek = 19c8b441d318802bad63a5beda283a84 eticket_rsa_kek_source = dba451124ca0a9836814f5ed95e3125b eticket_rsa_kekek_source = 466e57b74a447f02f321cde58f2f5535 header_kek_source = 1f12913a4acbf00d4cde3af6d523882a header_key = aeaab1ca08adf9bef12991f369e3c567d6881e4e4a6a47a51f6e4877062d542d header_key_source = 5a3ed84fdec0d82631f7e25d197bf5d01c9b7bfaf628183d71f64d73f150b9d2 key_area_key_application_00 = ef979e289a132c23d39c4ec5a0bba969 key_area_key_application_01 = cdedbab97b69729073dfb2440bff2c13 key_area_key_application_02 = 75716ed3b524a01dfe21456ce26c7270 key_area_key_application_03 = f428306544cf5707c25eaa8bc0583fd1 key_area_key_application_04 = 798844ec099eb6a04b26c7c728a35a4d key_area_key_application_05 = a57c6eecc5410ada22712eb3ccbf45f1 key_area_key_application_06 = 2a60f6c4275df1770651d5891b8e73ec key_area_key_application_07 = 32221bd6ed19b938bec06b9d36ed9e51 key_area_key_application_08 = fb20aa9e3dbf67350e86479eb431a0b3 key_area_key_application_09 = ce8d5fa79e220d5f48470e9f21be018b key_area_key_application_0a = 38b865725adcf568a81d2db3ceaa5bcc key_area_key_application_0b = bbddfd40a59d0ff555c0954239972213 key_area_key_application_0c = 3fee7204e21c6b0ff1373226c0c3e055 key_area_key_application_source = 7f59971e629f36a13098066f2144c30d key_area_key_ocean_00 = b33813e4c9c4399c75fabc673ab4947b key_area_key_ocean_01 = c54166efa8c9c0f6511fa8b580191677 key_area_key_ocean_02 = 3061ce73461e0b0409d6a33da85843c8 key_area_key_ocean_03 = 06f170025a64921c849df168e74d37f2 key_area_key_ocean_04 = dc857fd6dc1c6213076ec7b902ec5bb6 key_area_key_ocean_05 = 131d76b70bd8a60036d8218c15cb610f key_area_key_ocean_06 = 17d565492ba819b0c19bed1b4297b659 key_area_key_ocean_07 = 37255186f7678324bf2b2d773ea2c412 key_area_key_ocean_08 = 4115c119b7bd8522ad63c831b6c816a6 key_area_key_ocean_09 = 792bfc652870cca7491d1685384be147 key_area_key_ocean_0a = dfcc9e87e61c9fba54a9b1c262d41e4d key_area_key_ocean_0b = 66fe3107f5a6a8d8eda2459d920b07a1 key_area_key_ocean_0c = b79b6bf3d6cdc5ec10277fc07a4fec93 key_area_key_ocean_source = 327d36085ad1758dab4e6fbaa555d882 key_area_key_system_00 = 6dd02aa15b440d6231236b6677de86bc key_area_key_system_01 = 4ab155e7f29a292037fd147592770b12 key_area_key_system_02 = b7a74adeaf89c2a198c327bdff322d7d key_area_key_system_03 = d5aab1acd23a8aec284a316df859d377 key_area_key_system_04 = 9b44b45b37de9d14754b1d22c2ca742c key_area_key_system_05 = 0012e957530d3dc7af34fbbe6fd44559 key_area_key_system_06 = 01744e3b0818445cd54ee9f89da43192 key_area_key_system_07 = d0d30e46f5695b875f11522c375c5a80 key_area_key_system_08 = bd06cb1b86bd5c433667470a09eb63de key_area_key_system_09 = e19f788f658eda8bbf34a1dd2a9503a9 key_area_key_system_0a = 7070e7ff5cfe448630143a9874903c38 key_area_key_system_0b = 3fa471d4483e58b8f7756fcb64f63890 key_area_key_system_0c = 7bfd381df3369407ab1c6bdd9fabf522 key_area_key_system_source = 8745f1bba6be79647d048ba67b5fda4a keyblob_00 = f759024f8199101dddc1ef91e6eecf37e24b95ac9272f7ae441d5d8060c843a48322d21cdd06d4fc958c68d3800eb4db939ffbec930177f77d136144ff615aa8835e811bb958deda218f8486b5a10f531b30cb9d269645ac9fc25c53fc80525e56bd3602988a9fcf06bbf99ca910ad6530791d512c9d57e17abf49220de6419bf4eca1685c1e4df77f19db7b44a985ca keyblob_01 = bd27264ae07e979756411d0c66e679e3c50851f3e902d9c2cd1a438b948159a517ec1566c10570326ea2697ee62da46f14bb5d581bfc06fd0c9387ea33d2d4dc63e7809ba90f03dd2c7112ffbfa548951b9b8c688b5e4f2951d24a73da29c668154a5d4838dba71ee068ace83fe720e8c2a495c596f73525dc3c05994b40ad27f8c60322f75cd548b821af9162e16f76 keyblob_02 = a3d4a8e153b8e6ae6e6aef3e8f219cb4b7790f47856accc76268f9afa99a1ff8b1a72f63d1f99f480a3c1532078bb59abdd25203cfb12a38b33e9ba6a09afb6f24283b3ba76a0161230a73669ddf5493c2b7919d094fd795b484794854f71e4f4c672245d7770e29397722444d111b4229cdbf35707b70634ea8f140766e884cc580cb1e2d9aa9866ffef920010fc409 keyblob_03 = 1558f525ae8c5be9243fb6d8a8b0a8ee0e886a59035668740a936619b7a5c83e821198b171d18e51445054df68688e45703b936818a827d8e540dd6bef2e11ec9ddc6cfe5fc736dd769b9f6e0a23a62e2e5f49e86143646a04ec3a23f828373a336a5c224a91f8a0c6c6a7b5844dd6415804209f83c943aeca9cfd856db6bd4ec32009c8cb268ed053052c9237dfd8bc keyblob_04 = 9fbeb1957fc1629e08b753a9086d6e01ffb4f11466b7417e3fa7f5f1efb754406704fd75afaf91a408a0b524c1fc80d36c2046fa4757412efe4c11e382f72e8a10d90ed580017d9deb87af2549b6b02661af48ff94f6072c0fef7fc2833b8bdae503898e2e927ac0663e8b6391dd4f1d685313935e2c48ece7d177c88bc9c883ede36c3677495784b838d7265c6ba7a1 keyblob_05 = 94a92da1d73c2b3e165c891ced5607fc6628ca2a0654f3fbc05711c063377c6e9c96a9d0192e530dd510e4fd41aa62ef4213c5f6e059e7e21db098a9b22d1e6c29bee148aaef15c52549d9165de96e85b0d029ecdc5843e2f32cb18be707eec61909cf3385d45bc2a4c8d76e9bfad5a40c4b92dcb982aa50d474897ac9ebb5351a7015dcc277a08f1214ad41384d7941 keyblob_key_00 = 839944c8a38df6791020b38147e906b0 keyblob_key_01 = b9e6fbde828b5f42c897ade8fd14c625 keyblob_key_02 = b6988a0795d294ef522908692d5db7ca keyblob_key_03 = 0e57d7777171d125d3fe3af5b397d009 keyblob_key_04 = b55a282d698fabeb4e03c67ff2026bc5 keyblob_key_05 = fdb542c1f1bdf134ec20b1fda02bc9e1 keyblob_key_source_00 = df206f594454efdc7074483b0ded9fd3 keyblob_key_source_01 = 0c25615d684ceb421c2379ea822512ac keyblob_key_source_02 = 337685ee884aae0ac28afd7d63c0433b keyblob_key_source_03 = 2d1f4880edeced3e3cf248b5657df7be keyblob_key_source_04 = bb5a01f988aff5fc6cff079e133c3980 keyblob_key_source_05 = d8cce1266a353fcc20f32d3b517de9c0 keyblob_mac_key_00 = 604422526723e541a849fa4c18660e0b keyblob_mac_key_01 = 279481456b1dc259d35599e6392e01e5 keyblob_mac_key_02 = dbbfb8096b676c2a54b5d9c61b423a94 keyblob_mac_key_03 = 48b7aef6d9b1edb132b8901a245a7750 keyblob_mac_key_04 = 544c082e9f8602c736dc0732d4319f88 keyblob_mac_key_05 = a540ec8ba84bd31eaaa9ce9f95226875 keyblob_mac_key_source = 59c7fb6fbe9bbe87656b15c0537336a5 mariko_master_kek_source_05 = 77605ad2ee6ef83c3f72e2599dac5e56 mariko_master_kek_source_06 = 1e80b8173ec060aa11be1a4aa66fe4ae mariko_master_kek_source_07 = 940867bd0a00388411d31adbdd8df18a mariko_master_kek_source_08 = 5c24e3b8b4f700c23cfd0ace13c3dc23 mariko_master_kek_source_09 = 8669f00987c805aeb57b4874de62a613 mariko_master_kek_source_0a = 0e440cedb436c03faa1daebf62b10982 mariko_master_kek_source_0b = e541acecd1a7d1abed0377f127caf8f1 mariko_master_kek_source_0c = 52719bdfa78b61d8d58511e48e4f74c6 master_kek_00 = f759024f8199101dddc1ef91e6eecf37 master_kek_01 = bd27264ae07e979756411d0c66e679e3 master_kek_02 = a3d4a8e153b8e6ae6e6aef3e8f219cb4 master_kek_03 = 1558f525ae8c5be9243fb6d8a8b0a8ee master_kek_04 = 9fbeb1957fc1629e08b753a9086d6e01 master_kek_05 = 94a92da1d73c2b3e165c891ced5607fc master_kek_08 = e42f1ec8002043d746575ae6dd9f283f master_kek_09 = cec2885fbeef5f6a989db84a4cc4b393 master_kek_0a = dd1a730232522b5cb4590cd43869ab6a master_kek_0b = fc6f0c891d42710180724ed9e112e72a master_kek_0c = 43f7fc20fcec22a5b2a744790371b094 master_kek_source_06 = 374b772959b4043081f6e58c6d36179a master_kek_source_07 = 9a3ea9abfd56461c9bf6487f5cfa095c master_kek_source_08 = dedce339308816f8ae97adec642d4141 master_kek_source_09 = 1aec11822b32387a2bedba01477e3b67 master_kek_source_0a = 303f027ed838ecd7932534b530ebca7a master_kek_source_0b = 8467b67f1311aee6589b19af136c807a master_kek_source_0c = 683bca54b86f9248c305768788707923 master_key_00 = c2caaff089b9aed55694876055271c7d master_key_01 = 54e1b8e999c2fd16cd07b66109acaaa6 master_key_02 = 4f6b10d33072af2f250562bff06b6da3 master_key_03 = 84e04ec20b9373818c540829cf147f3d master_key_04 = cfa2176790a53ff74974bff2af180921 master_key_05 = c1dbedcebf0dd6956079e506cfa1af6e master_key_06 = 0aa90e6330cdc12d819b3254d11a4e1e master_key_07 = 929f86fbfe4ef7732892bf3462511b0e master_key_08 = 23cfb792c3cb50cd715da0f84880c877 master_key_09 = 75c93b716255319b8e03e14c19dea64e master_key_0a = 73767484c73088f629b0eeb605f64aa6 master_key_0b = 8500b14bf4766b855a26ffc614097a8f master_key_0c = b3c503709135d4b35de31be4b0b9c0f7 master_key_source = d8a2410ac6c59001c61d6a267c513f3c package1_key_00 = f4eca1685c1e4df77f19db7b44a985ca package1_key_01 = f8c60322f75cd548b821af9162e16f76 package1_key_02 = c580cb1e2d9aa9866ffef920010fc409 package1_key_03 = c32009c8cb268ed053052c9237dfd8bc package1_key_04 = ede36c3677495784b838d7265c6ba7a1 package1_key_05 = 1a7015dcc277a08f1214ad41384d7941 package2_key_00 = a35a19cb14404b2f4460d343d178638d package2_key_01 = a0dd1eacd438610c85a191f02c1db8a8 package2_key_02 = 7e5ba2aafd57d47a85fd4a57f2076679 package2_key_03 = bf03e9889fa18f0d7a55e8e9f684323d package2_key_04 = 09df6e361e28eb9c96c9fa0bfc897179 package2_key_05 = 444b1a4f9035178b9b1fe262462acb8e package2_key_06 = 442cd9c21cfb8914587dc12e8e7ed608 package2_key_07 = 70c821e7d6716feb124acbac09f7b863 package2_key_08 = 8accebcc3d15a328a48365503f8369b6 package2_key_09 = f562a7c6c42e3d4d3d13ffd504d77346 package2_key_0a = 0803167ec7fc0bc753d8330e5592a289 package2_key_0b = 341db6796aa7bdb8092f7aae6554900a package2_key_0c = 4e97dc4225d00c6ae33d49bddd17637d package2_key_source = fb8b6a9c7900c849efd24d854d30a0c7 per_console_key_source = 4f025f0eb66d110edc327d4186c2f478 retail_specific_aes_key_source = e2d6b87a119cb880e822888a46fba195 rsa_oaep_kek_generation_source = a8ca938434127fda82cc1aa5e807b112 rsa_private_kek_generation_source = ef2cb61a56729b9157c38b9316784ddd save_mac_kek_source = d89c236ec9124e43c82b038743f9cf1b save_mac_key = 71a917f1bac8f4f04d732e734c90e2ec save_mac_key_source = e4cd3d4ad50f742845a487e5a063ea1f save_mac_sd_card_kek_source = 0489ef5d326e1a59c4b7ab8c367aab17 save_mac_sd_card_key_source = 6f645947c56146f9ffa045d595332918 sd_card_custom_storage_key_source = 370c345e12e4cefe21b58e64db52af354f2ca5a3fc999a47c03ee004485b2fd0 sd_card_kek_source = 88358d9c629ba1a00147dbe0621b5432 sd_card_nca_key_source = 5841a284935b56278b8e1fc518e99f2b67c793f0f24fded075495dca006d99c2 sd_card_save_key_source = 2449b722726703a81965e6e3ea582fdd9a951517b16e8f7f1f68263152ea296a sd_seed = fdb479221c43741a118fb5475374d2f7 secure_boot_key = 208de9b9de94ff698d00657a6a82a973 ssl_rsa_kek = b011100660d1dccbad1b1b733afa9f95 ssl_rsa_kek_source_x = 7f5bb0847b25aa67fac84be23d7b6903 ssl_rsa_kek_source_y = 9a383bf431d0bd8132534ba964397de3 titlekek_00 = 62a24d6e6d0d0e0abf3554d259be3dc9 titlekek_01 = 8821f642176969b1a18021d2665c0111 titlekek_02 = 5d15b9b95a5739a0ac9b20f600283962 titlekek_03 = 1b3f63bcb67d4b06da5badc7d89acce1 titlekek_04 = e45c1789a69c7afbbf1a1e61f2499459 titlekek_05 = ddc67f7189f4527a37b519cb051eee21 titlekek_06 = b1532b9d38ab036068f074c0d78706ac titlekek_07 = 81dc1b1783df268789a6a0edbf058343 titlekek_08 = 47dfe4bf0eeda88b17136b8005ab08ea titlekek_09 = adaa785d90e1a9c182ac07bc276bf600 titlekek_0a = 42daa957c128f75bb1fda56a8387e17b titlekek_0b = d08903363f2c8655d3de3ccf85d79406 titlekek_0c = be2682599db34caa9bc7ebb2cc7c654c titlekek_source = 1edc7b3b60e6b4d878b81715985e629b tsec_key = 53ec4ac7c6c32ff2abff3eeff4f84f36 tsec_root_key_02 = 4b4fbcf58e23cf4902d478b76c8048ec yuzu以及Ryujinx都需要prod.keys，里面包含了NS设备需要的key，需要通过 Hekate等一些列工具生成。yuzu不需要单独安装固件，只要把key文件放好就可以启动游戏了。\n  关闭模拟器，重新打开 yuzu ，若没有弹窗，则配置成功\n  设置 General\n确保勾选 Multicore CPU Emulation 和 Confirm exit while emulation is runing。\nLimit Speed percent：游戏运行速度，默认即可，可加快或限速\nPause emulation when inbackground：退到后台模拟器暂停运行\nHide mouse inactivity：运行时鼠标隐藏\nPrompt for user for game boot：游戏启动时选择哪个账户游玩\nWeb\nyuzu web service：填了用户名和令牌以后可以向官网报告游戏兼容性\nTelemetry：开了以后能让yuzu开发者查看你的使用情况，以便改善模拟器\nDiscord Presence：在discord中显示你的游戏状态\n系统\nSystem 页面，Language 选择 Simplified Chinese，Region 选择 China。这个设置的是系统语言，很多游戏会根据系统语言自动切换游戏内显示的语言。当然前提是游戏本身包含中文，如果游戏本身无中文只能通过打补丁的方式显示中文。\nCustom RTC：修改系统时间，可以触发某些游戏的特定彩蛋之类的功能。\nRNG seed：随机数种子，一般情况别改改。\nProfile Manager：这里可以改switch用户名称、头像。可以设置多个用户\nCPU\n图形\n API设置：支持OpenGL和Vulkan。 Use disk shader cache：磁盘着色器缓存，建议开启，这样就不用每次都重新编译，而是直接从磁盘加载到内存 Use asynchronous GPU emulation：GPU异步模拟，yuzu重写了GPU显存管理器，加速了缓存机制，使得帧数得到明显提示，同时性能提升40%-400%（来自BSoD Gaming的测试数据） Use NVDEC emulation：NVDEC是一项硬件转码技术，能减少转码期间计算密集型任务中CPU的负担，这是Nvidia的一个技术，有了它，过场动画的播放会畅顺很多  Advanced\n Accuracy Level：即模拟器左下角状态栏的 GPU NORMAL。是处理图形绘制精确度，开启High可能会修复一些图形错误，但是速度可能会变慢，一般选默认Normal即可 Use Vysnc (OpenGL Only)：开启垂直同步 Use Fast GPU time： 使用GPU加速渲染 Anisotropic Filtering：是各项异性过滤，是用来处理图形纹理错误的，可以选2x-16x  声音\n默认。\n控制\n连接手柄，选择该设备。\n管理 游戏格式分为两种，.xci 格式和 .nsp 格式。简单一点说，.xci 格式是卡带版，.nsp 格式是数字版。因此基本上所有的 DLC 基本都是 .nsp 格式，但也有 .xci 里集成了 DLC 的情况。\n添加游戏\n双击模拟器中间，添加游戏目录，游戏目录也不要有中文。添加完就可以看到游戏了。\n安装Update和DLC\n选择File -\u0026gt;Install Files to NAND\u0026hellip;，选中 Update和DLC文件，Update 安装最新就行，DLC 需要全部安装（可以不按顺序）。\n安装 Mod\nMod 用于修改游戏，如解决一些bug以及优化性能等。右键单击要为其添加模组的游戏。然后将整个mod文件夹粘贴到那里。你可以从 Switch Mods 获得一些基本的 yuzu 模组。\n注意：您可以通过右键单击游戏并单击属性来检查您拥有的游戏模组。\n放入着色器缓存\n放入着色器缓存（shader cache）可以明显提升游戏的流畅性，建议找找别人的着色器缓存。\n具体放入步骤：右键某个游戏，选择打开可转移着色器缓存，即可弹出缓存所在文件夹，然后放入你下载的别人的缓存就行了，比如 vulkan.bin 和 opengl.bin\nrubick 基于 electron 的开源工具箱，自由集成丰富插件。\nuTools uTools 是一个极简、插件化的现代桌面软件，通过自由选配丰富的插件，打造得心应手的工具集合。\nAlbert Linux 下的快捷启动工具。\n   应用 / 功能 查找应用 查找文件 查找网页 扩展程序     Albert ✓ ✓ ✓ -   Synapse ✓ ✓ - -   Utools ✓ ✗ ✓ ✓   Ulauncher ✓ ✓ ✓ ✓   FSearch ✗ ✓ ✗ ✗    简单说，Albert 最好用，Ulauncher 综合能力强，而 FSearch 严重偏科。\nCalibre calibre is a powerful and easy to use e-book manager. Users say it’s outstanding and a must-have. It’ll allow you to do nearly everything and it takes things a step beyond normal e-book software. It’s also completely free and open source and great for both casual users and computer experts.\nConvert Epub to PDF\nOpen terminal and run the following command to install Calibre.\n$ sudo apt update $ sudo apt install calibre Calibre software is referred to as ebook-convert command. Here is the command to convert epub file to pdf file.\nebook-convert \u0026lt;file\u0026gt;.epub \u0026lt;file\u0026gt;.pdf If your PDF doesn’t appear to be properly readable, try converting the epub file again using –enable-heuristics option.\n$ ebook-convert /home/ubuntu/test.epub /home/ubuntu/test.pdf --enable-heuristics FBReader 中文乱码需要在 Options =\u0026gt; CSS 中启用 Always Use My Own Fonts\nVentoy 简单来说，Ventoy是一个制作可启动U盘的开源工具。\n有了Ventoy你就无需反复地格式化U盘，你只需要把 ISO/WIM/IMG/VHD(x)/EFI 等类型的文件直接拷贝到U盘里面就可以启动了，无需其他操作。\nbalenaEtcher Supported Operating Systems\n Linux (most distros) macOS 10.10 (Yosemite) and later Microsoft Windows 7 and later  UNetbootin UNetbootin installs Linux/BSD distributions to a partition or USB drive\nWoeUSB-ng WoeUSB-ng is a simple tool that enable you to create your own usb stick windows installer from an iso image or a real DVD. This is a rewrite of original WoeUSB.\nTimeshift System restore tool for Linux.\nTodoist Plank Plank is meant to be the simplest dock on the planet.\nlatte-dock Steam $ sudo apt install steam 在 Windows 上运行神秘代码： Win + R，输入 steam://install/2026560。等同于在 Ubuntu 终端敲：xdg-open steam://install/2026560\n`YACReader Tachidesk 快速配置指南：\nTachidesk 是一个免费的开源漫画阅读器，可运行为 Tachiyomi 构建的扩展。Tachidesk 是独立的，但与 Tachiyomi 兼容的开源软件，它不是 Tachiyomi 的下游分支。你可以在任何支持 Java 的设备上运行这个软件。\n如果你熟悉 Tachiyomi，那你也会对 Tachidesk 的用户界面倍感熟悉。\nTachidesk 主要分为两部分：Tachidesk-server （后端）和 Tachidesk 图形化前端。Tachidesk 有多个图形化前端。直接从下文的 GitHub 链接下载的文件会自动集成一个 Tachidesk-WebUI。\nhakuneko work_crawler Download comics novels\ndingtalk 钉钉桌面版，基于electron和钉钉网页版开发\nhowdy Windows Hello™ style facial authentication for Linux\n向日葵 向日葵远程控制软件是一款免费的集远程控制电脑手机、远程桌面连接、远程开机、远程管理、支持内网穿透的一体化远程控制管理工具软件。\nKeePassXC words-picker 有OCR功能的开源取词软件\nCopyQ Clipboard manager with advanced features\nXnViewMP 图片浏览器。速度快，并且可以进行一些简单的图片操作，比如图片压缩、图片格式转换、图片剪裁等等。\nZeal 离线 API 文档查找阅读工具。\nXMind XMind 是一款全功能的思维导图和头脑风暴软件。像大脑的瑞士军刀一般，助你理清思路，捕捉创意。已成为上亿用户喜爱的全平台效率工具。\n快捷键：\n shift：左右移动 tab：subtopic del：delete topic blank：input text  完全免费的脑图软件推荐\n如果平时没有导出需求的话, 可以选用xmind和mindmaster, 如果突然需要导出pdf了, 可以将xmind和mindmaster的文件导出为mindmanager文件, 然后导入到freeplane中, 稍作调整与美化, 然后导出成pdf就可以了.\nAdd new file extension to existing (MIME) type\n问题描述：将 zip 文件默认打开设置为File，点击xmind文件会被解压；设置xmind默认打开 .xmind 文件，zip文件会被xmind打开，xmind 的mime类型为zip，那么要如何区分zip文件与xmind文件呢？\nUse freedesktop\u0026rsquo;s unified system to define a new association. Write a new source xml file e.g.\n$ gedit ~/.local/share/mime/packages/x-xmind.xml with the following content:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;mime-info xmlns=\u0026#39;http://www.freedesktop.org/standards/shared-mime-info\u0026#39;\u0026gt; \u0026lt;mime-type type=\u0026#34;application/x-xmind\u0026#34;\u0026gt; \u0026lt;comment\u0026gt;XMind mindmap\u0026lt;/comment\u0026gt; \u0026lt;generic-icon name=\u0026#34;package-x-generic\u0026#34;/\u0026gt; \u0026lt;glob pattern=\u0026#34;*.xmind\u0026#34;/\u0026gt; \u0026lt;/mime-type\u0026gt; \u0026lt;/mime-info\u0026gt; then update your mime database\n$ update-mime-database ~/.local/share/mime or you can register a new MIME entry by using xdg-mime instead of update-mime-database:\n# register $ xdg-mime install x-xmind.xml # unregister $ xdg-mime uninstall x-xmind.xml Query:\n$ xdg-mime query filetype my.xmind application/x-xmind 给XMind脑图文件添加Gnome缩略图显示 [Ubuntu]\nCLI Utilities PostgreSQL 是 macOS Server 的默认数据库。\n安装 $ sudo apt install postgresql postgresql-contrib postgresql-contrib 或者说 contrib 包，包含一些不属于 PostgreSQL 核心包的实用工具和功能。\n通过 service 命令，你可以启动、关闭或重启 postgresql。输入 service postgresql 并按回车将列出所有选项\n默认情况下，PostgreSQL 会创建一个拥有所权限的特殊用户 postgres。要实际使用 PostgreSQL，你必须先登录该账户，使用 psql 来启动 PostgreSQL Shell：\n$ sudo -i -u postgres # sudo -login -user postgres $ psql 使用 \\l 用于查看已经存在的数据库\npostgres=# \\l 使用 \\c + 数据库名 来进入数据库\npostgres=# \\c shop \\d 查看表格信息\npostgres=# \\d [TableName] 查找配置文件 select name, setting from pg_settings where category=\u0026#39;File Locations\u0026#39; ; Questions psql: error: FATAL: Peer authentication failed for user \u0026ldquo;postgres\u0026rdquo;\npsql的连接建立于Unix Socket上默认使用peer authentication（对等体认证；对等实体认证），所以必须要用和数据库用户相同的系统用户进行登录。\n# su - postgres  # psql 或者将peer authentiction 改为 md5，需先做上面步骤，更改密码：\npostgres=# ALTER USER db_user with password \u0026#39;db_password\u0026#39;; $ find / -name \u0026#39;pg_hba.conf\u0026#39; 2\u0026gt;/dev/null $ sudo vi /etc/postgresql/12/main/postgresql.conf local all postgres md5 $ systemctl restart postgresql.service $ psql -U postgres -d shop Ansible 安装Ansible之后,不需要启动或运行一个后台进程,或是添加一个数据库.只要在一台电脑(可以是一台笔记本)上安装好,就可以通过这台电脑管理一组远程的机器.在远程被管理的机器上,不需要安装运行任何软件,因此升级Ansible版本不会有太多问题.\nfdupes You can call it like fdupes -r /dir/ect/ory and it will print out a list of dupes. fdupes has also a simple Homepage and a Wikipedia article, which lists some more programs.\ndigiKam 可用于查找重复相片，然后根据需要删除重复内容。\nbypy bypy info 认证特别慢，而授权码又只有10分钟，导致后面授权码过期 Heroku server 认证失败失败。\n如此，可以通过手动认证。\n  通过 bypy -dv 查看详细输出，得到 Full URL，如 https://bypyoauth.herokuapp.com/auth?code=...\u0026amp;bypy_version=1.7.2\u0026amp;redirect_uri=oob，在浏览器中打开，获得token。\n  将其放在 ~/.bypy/bypy.json 中。\n  源码仓库也有示例。\n我下载一个大文件，总共12G左右，已用了两个晚上，中途没关（由于不是立马就要的东西，就用时间换金钱了），一次看进度时，Terminal 就卡退了，重新运行后，bypy会继续上次下载，而不是重新开始（这样话太可怕了）。\nFRP frp 是一个专注于内网穿透的高性能的反向代理应用，支持 TCP、UDP、HTTP、HTTPS 等多种协议。可以将内网服务以安全、便捷的方式通过具有公网 IP 节点的中转暴露到公网。\n其他内网穿透工具\n ngrok ZeroTier N2N Dog Tunnel Tinc  Git sync-repos #!/usr/bin/bash TIME=\u0026#34;$(date \u0026#39;+%Y%m%d%H%M%S\u0026#39;)\u0026#34; SAMATOMO_SOURCE=$HOME/Documents/SakamotoKuromeSource SAKAMOTO_PUBLIC=$SAMATOMO_SOURCE/public VNOTEBOOK=$HOME/Documents/vNotebook function Git_Sync() { cd $1 echo \u0026#39;## STATUS ##\u0026#39; git status echo \u0026#39;\u0026#39; echo \u0026#39;## PULL ##\u0026#39; git pull echo \u0026#39;\u0026#39; echo \u0026#39;## PUSH ##\u0026#39; echo \u0026#39;### Ignore files larger than 100MB\u0026#39; cat .gitignore_default \u0026gt; .gitignore find . -size +100M | sed \u0026#39;s|^./||g\u0026#39; | cat \u0026gt;\u0026gt; .gitignore git add . git commit -m \u0026#34;Update-${TIME}\u0026#34; git push -v echo \u0026#39;\u0026#39; echo \u0026#39;\u0026#39; echo \u0026#39;\u0026#39; } function Sync_All() { echo \u0026#39;# PUSH SAMATOMO_SOURCE #\u0026#39; Git_Sync $SAMATOMO_SOURCE echo \u0026#39;# PUSH SAKAMOTO_PUBLIC #\u0026#39; rm -rf $SAKAMOTO_PUBLIC/* hugo Git_Sync $SAKAMOTO_PUBLIC echo \u0026#39;# PUSH vNotebook #\u0026#39; Git_Sync $VNOTEBOOK } Sync_All exit 0  A collection of useful .gitignore templates Ignore files \u0026gt;100MB in your Git repos About large files on GitHub  GitHub Desktop Focus on what matters instead of fighting with Git. Whether you\u0026rsquo;re new to Git or a seasoned user, GitHub Desktop simplifies your development workflow.\nGitHub520 # GitHub520 Host Start 140.82.113.26 alive.github.com 140.82.113.26 live.github.com 185.199.108.154 github.githubassets.com 140.82.112.22 central.github.com 185.199.108.133 desktop.githubusercontent.com 185.199.108.153 assets-cdn.github.com 185.199.108.133 camo.githubusercontent.com 185.199.108.133 github.map.fastly.net 199.232.69.194 github.global.ssl.fastly.net 140.82.114.4 gist.github.com 185.199.108.153 github.io 140.82.113.4 github.com 192.0.66.2 github.blog 140.82.114.5 api.github.com 185.199.108.133 raw.githubusercontent.com 185.199.108.133 user-images.githubusercontent.com 185.199.108.133 favicons.githubusercontent.com 185.199.108.133 avatars5.githubusercontent.com 185.199.108.133 avatars4.githubusercontent.com 185.199.108.133 avatars3.githubusercontent.com 185.199.108.133 avatars2.githubusercontent.com 185.199.108.133 avatars1.githubusercontent.com 185.199.108.133 avatars0.githubusercontent.com 185.199.108.133 avatars.githubusercontent.com 140.82.114.10 codeload.github.com 52.217.201.185 github-cloud.s3.amazonaws.com 54.231.132.81 github-com.s3.amazonaws.com 52.217.225.9 github-production-release-asset-2e65be.s3.amazonaws.com 52.217.161.97 github-production-user-asset-6210df.s3.amazonaws.com 52.216.134.35 github-production-repository-file-5c1aeb.s3.amazonaws.com 185.199.108.153 githubstatus.com 64.71.144.202 github.community 23.100.27.125 github.dev 140.82.112.22 collector.github.com 13.107.42.16 pipelines.actions.githubusercontent.com 185.199.108.133 media.githubusercontent.com 185.199.108.133 cloud.githubusercontent.com 185.199.108.133 objects.githubusercontent.com # Update time: 2022-03-19T14:06:28+08:00 # Update url: https://raw.hellogithub.com/hosts # Star me: https://github.com/521xueweihan/GitHub520 # GitHub520 Host End libguestfs libguestfs 支持几乎所有类型的磁盘镜像。\n在基于 Debian 的系统上：\n$ apt-get install libguestfs-tools 我们可以像下面这样挂载一个 qcow2 格式的磁盘镜像：\n$ guestmount -a /path/to/qcow2/image -m \u0026lt;device\u0026gt; /path/to/mount/point 要卸载它，则执行：\n$ guestunmount qcow2_mount_poin Oracle JDK   解压缩到目录\n$ tar -zxv -f jdk-7u60-linux-x64.gz -C dir   修改环境变量\n$ vi ~/.bashrc export JAVA_HOME=/usr/lib/jvm/jdk1.7.0_60 # 这里换成自己解压的jdk 目录 export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib export PATH=${JAVA_HOME}/bin:$PATH   使环境变量生效\n$ source ~/.bashrc   Snapper Snapper 是一个由 openSUSE 的 Arvin Schnell 开发的工具，用于管理 Btrfs 子卷和 LVM 精简配置(thin-provisioned)卷。它可以创建和比较快照，在快照间回滚，并支持自动按时间序列创建快照。\n列出子卷列表\n$ sudo btrfs subvolume list -p / ID 256 gen 7746 parent 5 top level 5 path @ ID 258 gen 7746 parmount -n -o remount,rw /ent 5 top level 5 path @home 安装 snapper\n$ sudo apt install snapper 创建配置文件，启用自动快照\n$ sudo snapper -c root create-config / Snapshots on boot\n$ sudo systemctl status snapper-boot.timer 管理 snapshot\n$ sudo snapper-gui grub-btrfs Booting into snapshots.\nInclude btrfs snapshots at boot options. (Grub menu)\n教程：Install Ubuntu 21.04 with btrfs + snapper + grub-btrfs\nFail2Ban Fail2Ban 是一款入侵防御软件，可以保护服务器免受暴力攻击。 它是用 Python 编程语言编写的。 Fail2Ban 基于auth 日志文件工作，默认情况下它会扫描所有 auth 日志文件，如 /var/log/auth.log、/var/log/apache/access.log 等，并禁止带有恶意标志的IP，比如密码失败太多，寻找漏洞等等标志。\n通常，Fail2Ban 用于更新防火墙规则，用于在指定的时间内拒绝 IP 地址。 它也会发送邮件通知。 Fail2Ban 为各种服务提供了许多过滤器，如 ssh、apache、nginx、squid、named、mysql、nagios 等。\nFail2Ban 能够降低错误认证尝试的速度，但是它不能消除弱认证带来的风险。 这只是服务器防止暴力攻击的安全手段之一。\nSyncthing Syncthing是一款开源免费跨平台的文件同步工具，是基于P2P技术实现设备间的文件同步，所以它的同步是去中心化的，即你并不需要一个服务器，故不需要担心这个中心的服务器给你带来的种种限制，而且类似于torrent协议，参与同步的设备越多，同步的速度越快。针对隐私问题，Syncthing软件只会将数据存储于个人信任的设备上，不会存储到服务器上。设备之间的通信均通过TLS进行，Syncthing还使用了完全正向保密技术来进一步保障你的数据安全。对于处于不同局域网之中的设备之间的文件同步，Syncthing也提供了支持。\nmasscan Masscan号称是最快的互联网端口扫描器，最快可以在六分钟内扫遍互联网。\nImageMagick Use ImageMagick to create, edit, compose, or convert digital images. It can read and write images in a variety of formats (over 200) including PNG, JPEG, GIF, WebP, HEIC, SVG, PDF, DPX, EXR and TIFF. ImageMagick can resize, flip, mirror, rotate, distort, shear and transform images, adjust image colors, apply various special effects, or draw text, lines, polygons, ellipses and Bézier curves.\nFred\u0026rsquo;s ImageMagick Scripts\np7zip 7-Zip is a file archiver with a high compression ratio.\np7zip 是 7-Zip 的 POSIX 系统移植，支持 Linux。\n警告： 不要将7z格式用于备份目的，因为它不会保存文件的所有者/组。有关更多详细信息，请参见7z(1)。\n添加文件或目录至已有的存档（或创建一个新的存档）：\n$ 7z a \u0026lt;archive name\u0026gt; \u0026lt;file name\u0026gt; 也可以通过参数-p设置密码，并通过标志-mhe = on隐藏存档的结构：\n$ 7z a \u0026lt;archive name\u0026gt; \u0026lt;file name\u0026gt; -p -mhe=on 更新存档内已有的文件或添加新文件：\n$ 7z u \u0026lt;archive name\u0026gt; \u0026lt;file name\u0026gt; 列出存档内容：\n$ 7z l \u0026lt;archive name\u0026gt; 从存档中解压文件至当前文件夹，不使用存档内的目录结构：\n$ 7z e \u0026lt;archive name\u0026gt; 如果需要恢复存档内的目录结构，使用：\n$ 7z x \u0026lt;archive name\u0026gt; 解压至新的目录：\n$ 7z x -o\u0026lt;folder name\u0026gt; \u0026lt;archive name\u0026gt; 校验存档完整性：\n$ 7z t \u0026lt;archive name\u0026gt; Differences between 7z, 7za and 7zr binaries The package includes three binaries, /usr/bin/7z, /usr/bin/7za, and /usr/bin/7zr. Their manual pages explain the differences:\n 7z(1) uses plugins to handle archives. 7za(1) is a stand-alone executable that handles fewer archive formats than 7z. 7zr(1) is a stand-alone executable. It is a \u0026ldquo;light-version\u0026rdquo; of 7za that only handles 7z archives. In contrast to 7za, it cannot handle encrypted archives.  分卷压缩与解压缩 rar # rar a -vSIZE 压缩后的文件名 被压缩的文件或者文件夹 # 最大限制为 12M $ rar a -m5 -v12m myarchive myfiles #解压 $ rar e myarchive.part1.rar zip How to unzip a multipart (spanned) ZIP on Linux?\nThe Linux unzip utility doesn\u0026rsquo;t really support multipart zips. From the manual:\n Multi-part archives are not yet supported, except in conjunction with zip. (All parts must be concatenated together in order, and then zip -F (for zip 2.x) or zip -FF (for zip 3.x) must be performed on the concatenated archive in order to “fix” it. Also, zip 3.0 and later can combine multi-part (split) archives into a combined single-file archive using zip -s- inarchive -O outarchive. See the zip 3 manual page for more information.)\n So you need to first concatenate the pieces, then repair the result. cat test.zip.* concatenates all the files called test.zip.* where the wildcard * stands for any sequence of characters; the files are enumerated in lexicographic order, which is the same as numerical order thanks to the leadings zeroes. \u0026gt;test.zip directs the output into the file test.zip.\ncat test.zip.* \u0026gt; test.zip zip -FF test.zip --out test-full.zip unzip test-full.zip If you created the pieces by directly splitting the zip file, as opposed to creating a multi-part zip with the official Pkzip utility, all you need to do is join the parts.\ncat test.zip.* \u0026gt; test.zip unzip test.zip 总结：使用 zip -s- inarchive -O outarchive，例如：\n$ ls archive.zip archive.z01 archive.z02 archive.z03 $ zip -s- archive.zip -O archive-full.zip $ unzip archive-full.zip tar 要将目录logs打包压缩并分割成多个1M的文件，可以用下面的命令：\n$ tar cjf - logs/ | split -b 1m - logs.tar.bz2. 完成后会产生下列文件：\nlogs.tar.bz2.aa, logs.tar.bz2.ab, logs.tar.bz2.ac 要解压的时候只要执行下面的命令就可以了：\n$ cat logs.tar.bz2.a* | tar xj 7z 压缩：\n$ 7z a name.7z filename -v10m 这里a是添加文件到压缩卷，name.7z是压缩后文件,然后filename可以是文件夹或文件，-v10m是限制每个包大小不超过10m.\n解压到当前目录：\n$ 7z x film.7z.001 Wudao-dict 有道词典的命令行版本，支持英汉互查和在线查询。\nascii-image-converter ttyd Share your terminal over the web\nprogress Linux tool to show progress for cp, mv, dd, \u0026hellip; (formerly known as cv)\nvosk-api Offline speech recognition API for Android, iOS, Raspberry Pi and servers with Python, Java, C# and Node\nconvert MP3 to text The software you can use is Vosk-api, a modern speech recognition toolkit based on neural networks. It supports 7+ languages and works on variety of platforms including RPi and mobile.\nFirst you convert the file to the required format and then you recognize it:\n$ ffmpeg -i file.mp3 -ar 16000 -ac 1 file.wav Then install vosk-api with pip:\n$ pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple vosk Then use these steps:\n$ git clone https://github.com/alphacep/vosk-api $ cd vosk-api/python/example $ curl -O http://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip $ unzip vosk-model-small-en-us-0.15.zip $ mv vosk-model-small-en-us-0.15 model $ python3 ./test_simple.py test.wav \u0026gt; result.json The result will be stored in json format.\nThe same directory also contains an srt subtitle output example, which is easier to evaluate and can be directly useful to some users:\n$ python3 -m pip install srt $ python3 ./test_srt.py test.wav The example given in the repository says in perfect American English accent and perfect sound quality three sentences which I transcribe as:\none zero zero zero one nine oh two one oh zero one eight zero three The \u0026ldquo;nine oh two one oh\u0026rdquo; is said very fast, but still clear. The \u0026ldquo;z\u0026rdquo; of the before last \u0026ldquo;zero\u0026rdquo; sounds a bit like an \u0026ldquo;s\u0026rdquo;.\nThe SRT generated above reads:\n1 00:00:00,870 --\u0026gt; 00:00:02,610 what zero zero zero one 2 00:00:03,930 --\u0026gt; 00:00:04,950 no no to uno 3 00:00:06,240 --\u0026gt; 00:00:08,010 cyril one eight zero three so we can see that several mistakes were made, presumably in part because we have the understanding that all words are numbers to help us.\nNext I also tried with the vosk-model-en-us-0.22.zip which was a 1.8G download compared to 40M of vosk-model-small-en-us-0.15 and is listed at https://alphacephei.com/vosk/models:\n$ mv model vosk-model-small-en-us-0.15 $ curl -O http://alphacephei.com/vosk/models/vosk-model-en-us-0.22.zip $ unzip vosk-model-en-us-0.22.zip $ mv vosk-model-en-us-0.22 model and the result was:\n1 00:00:00,840 --\u0026gt; 00:00:02,610 one zero zero zero one 2 00:00:04,026 --\u0026gt; 00:00:04,980 i know what you window 3 00:00:06,270 --\u0026gt; 00:00:07,980 serial one eight zero three which got one more word correct.\ninxi inix 是一个用于获取 Linux 系统信息的终端命令。能够获取软件和硬件的详细信息，比如计算机型号、内核版本、发行版号以及桌面环境等信息，甚至可以读取主存模块占用主板的哪块 RAM 卡槽等详细信息。\ninxi 还可以用于监控系统中正在消耗 CPU 或者内存资源的进程。\n在 Ubuntu/Debian 发行版系统中，安装命令：\nsudo apt install inxi 用 -F 参数可以获取详细的系统信息。几乎囊括了所有层次的系统信息。\ninxi -F BusyBox BusyBox 是一个开源（GPL）项目，提供了近 400 个常用命令的简单实现，包括 ls、mv、ln、mkdir、more、ps、gzip、bzip2、tar 和 grep。它还包含了编程语言 awk、流编辑器 sed、文件系统检查工具 fsck、软件包管理器rpm 和 dpkg ，当然还有一个可以方便的访问所有这些命令的 shell（sh）。简而言之，它包含了所有 POSIX 系统需要的基本命令，以执行常见的系统维护任务以及许多用户和管理任务。\n事实上，它甚至包含一个 init 命令，可以作为 PID 1 启动，以作为所有其它系统服务的父进程。换句话说，BusyBox 可以作为 systemd、OpenRC、sinit、init 和其他初始化系统的替代品。\nBusyBox 非常小。作为一个可执行文件，它不到 1MB，所以它在嵌入式、边缘计算 和物联网领域很受欢迎，因为这些场景的存储空间是很宝贵的。在容器和云计算的世界里，它作为精简的 Linux 容器镜像的基础镜像也很受欢迎。\n极简主义 BusyBox 的部分魅力在于它的极简主义。它的所有命令都被编译到一个二进制文件里（busybox），它的手册只有 81 页（根据我对 man 送到 pr 管道的计算），但它涵盖了近 400 条命令。\n作为一个例子的比较，这是 “原版” 的 useradd —help 的输出：\n-b, --base-dir BASE_DIR base directory for home -c, --comment COMMENT GECOS field of the new account -d, --home-dir HOME_DIR home directory of the new account -D, --defaults print or change the default config -e, --expiredate EXPIRE_DATE expiration date of the new account -f, --inactive INACTIVE password inactivity -g, --gid GROUP name or ID of the primary group -G, --groups GROUPS list of supplementary groups -h, --help display this help message and exit -k, --skel SKEL_DIR alternative skeleton dir -K, --key KEY=VALUE override /etc/login.defs -l, --no-log-init do not add the user to the lastlog -m, --create-home create the user's home directory -M, --no-create-home do not create the user's home directory -N, --no-user-group do not create a group with the user's name -o, --non-unique allow users with non-unique UIDs -p, --password PASSWORD encrypted password of the new account -r, --system create a system account -R, --root CHROOT_DIR directory to chroot into -s, --shell SHELL login shell of the new account -u, --uid UID user ID of the new account -U, --user-group create a group with the same name as a user 而这是是同一命令的 BusyBox 版本：\n-h DIR Home directory -g GECOS GECOS field -s SHELL Login shell -G GRP Group -S Create a system user -D Don't assign a password -H Don't create home directory -u UID User id -k SKEL Skeleton directory (/etc/skel) 这种差异是一种特性还是一种限制，取决于你是喜欢你的命令拥有 20 个选项还是 10 个选项。对于一些用户和某些用例来说，BusyBox 的极简主义刚刚满足所需。对于其他人来说，它是一个很好的最小化环境，可以作为一个后备工具，或者作为安装更强大的工具的基础，比如 Bash、Zsh、GNU Awk 等等。\nLynis  使用这个全面的开源安全审计工具检查你的 Linux 机器的安全性。\n 你有没有想过你的 Linux 机器到底安全不安全？Linux 发行版众多，每个发行版都有自己的默认设置，你在上面运行着几十个版本各异的软件包，还有众多的服务在后台运行，而我们几乎不知道或不关心这些。\n要想确定安全态势（指你的 Linux 机器上运行的软件、网络和服务的整体安全状态），你可以运行几个命令，得到一些零碎的相关信息，但你需要解析的数据量是巨大的。\n如果能运行一个工具，生成一份关于机器安全状况的报告，那就好得多了。而幸运的是，有一个这样的软件：Lynis。它是一个非常流行的开源安全审计工具，可以帮助强化基于 Linux 和 Unix 的系统。根据该项目的介绍：\n “它运行在系统本身，可以进行深入的安全扫描。主要目标是测试安全防御措施，并提供进一步强化系统的提示。它还将扫描一般系统信息、易受攻击的软件包和可能的配置问题。Lynis 常被系统管理员和审计人员用来评估其系统的安全防御。”\n 安装 Lynis 你的 Linux 软件仓库中可能有 Lynis。如果有的话，你可以用以下方法安装它：\n$ sudo apt install lynis 然而，如果你的仓库中的版本不是最新的，你最好从 GitHub 上安装它。事实上，Lynis 主要是用 shell 脚本来实现的。\n运行 Lynis 通过给 Lynis 一个 -h 选项来查看帮助部分，以便有个大概了解：\n$ sudo lynis -h 你会看到一个简短的信息屏幕，然后是 Lynis 支持的所有子命令。\n接下来，尝试一些测试命令以大致熟悉一下。要查看你正在使用的 Lynis 版本，请运行：\n$ sudo lynis show version 3.0.0 要查看 Lynis 中所有可用的命令：\n$ sudo lynis show commands Commands: lynis audit lynis configure lynis generate lynis show lynis update lynis upload-only 审计 Linux 系统 要审计你的系统的安全态势，运行以下命令：\n$ sudo lynis audit system 这个命令运行得很快，并会返回一份详细的报告，输出结果可能一开始看起来很吓人，但我将在下面引导你来阅读它。这个命令的输出也会被保存到一个日志文件中，所以你可以随时回过头来检查任何可能感兴趣的东西。\nLynis 将日志保存在这里：\nFiles: - Test and debug information : /var/log/lynis.log - Report data : /var/log/lynis-report.dat 你可以验证是否创建了日志文件。它确实创建了：\n$ ls -l /var/log/lynis.log -rw-r-----. 1 root root 341489 Apr 30 05:52 /var/log/lynis.log $ ls -l /var/log/lynis-report.dat -rw-r-----. 1 root root 638 Apr 30 05:55 /var/log/lynis-report.dat 探索报告 Lynis 提供了相当全面的报告，所以我将介绍一些重要的部分。作为初始化的一部分，Lynis 做的第一件事就是找出机器上运行的操作系统的完整信息。之后是检查是否安装了什么系统工具和插件：\n[+] Initializing program ------------------------------------ - Detecting OS... [ DONE ] - Checking profiles... [ DONE ] --------------------------------------------------- Program version: 3.0.0 Operating system: Linux Operating system name: Red Hat Enterprise Linux Server 7.8 (Maipo) Operating system version: 7.8 Kernel version: 3.10.0 Hardware platform: x86_64 Hostname: example --------------------------------------------------- \u0026lt;\u0026lt;截断\u0026gt;\u0026gt; [+] System Tools ------------------------------------ - Scanning available tools... - Checking system binaries... [+] Plugins (phase 1) ------------------------------------ Note: plugins have more extensive tests and may take several minutes to complete - Plugin: pam [..] - Plugin: systemd [................] 接下来，该报告被分为不同的部分，每个部分都以 [+] 符号开头。下面可以看到部分章节。（哇，要审核的地方有这么多，Lynis 是最合适的工具！）\n[+] Boot and services [+] Kernel [+] Memory and Processes [+] Users, Groups and Authentication [+] Shells [+] File systems [+] USB Devices [+] Storage [+] NFS [+] Name services [+] Ports and packages [+] Networking [+] Printers and Spools [+] Software: e-mail and messaging [+] Software: firewalls [+] Software: webserver [+] SSH Support [+] SNMP Support [+] Databases [+] LDAP Services [+] PHP [+] Squid Support [+] Logging and files [+] Insecure services [+] Banners and identification [+] Scheduled tasks [+] Accounting [+] Time and Synchronization [+] Cryptography [+] Virtualization [+] Containers [+] Security frameworks [+] Software: file integrity [+] Software: System tooling [+] Software: Malware [+] File Permissions [+] Home directories [+] Kernel Hardening [+] Hardening [+] Custom tests Lynis 使用颜色编码使报告更容易解读。\n 绿色。一切正常 黄色。跳过、未找到，可能有个建议 红色。你可能需要仔细看看这个  在我的案例中，大部分的红色标记都是在 “Kernel Hardening” 部分找到的。内核有各种可调整的设置，它们定义了内核的功能，其中一些可调整的设置可能有其安全场景。发行版可能因为各种原因没有默认设置这些，但是你应该检查每一项，看看你是否需要根据你的安全态势来改变它的值：\n[+] Kernel Hardening ------------------------------------ - Comparing sysctl key pairs with scan profile - fs.protected_hardlinks (exp: 1) [ OK ] - fs.protected_symlinks (exp: 1) [ OK ] - fs.suid_dumpable (exp: 0) [ OK ] - kernel.core_uses_pid (exp: 1) [ OK ] - kernel.ctrl-alt-del (exp: 0) [ OK ] - kernel.dmesg_restrict (exp: 1) [ DIFFERENT ] - kernel.kptr_restrict (exp: 2) [ DIFFERENT ] - kernel.randomize_va_space (exp: 2) [ OK ] - kernel.sysrq (exp: 0) [ DIFFERENT ] - kernel.yama.ptrace_scope (exp: 1 2 3) [ DIFFERENT ] - net.ipv4.conf.all.accept_redirects (exp: 0) [ DIFFERENT ] - net.ipv4.conf.all.accept_source_route (exp: 0) [ OK ] - net.ipv4.conf.all.bootp_relay (exp: 0) [ OK ] - net.ipv4.conf.all.forwarding (exp: 0) [ OK ] - net.ipv4.conf.all.log_martians (exp: 1) [ DIFFERENT ] - net.ipv4.conf.all.mc_forwarding (exp: 0) [ OK ] - net.ipv4.conf.all.proxy_arp (exp: 0) [ OK ] - net.ipv4.conf.all.rp_filter (exp: 1) [ OK ] - net.ipv4.conf.all.send_redirects (exp: 0) [ DIFFERENT ] - net.ipv4.conf.default.accept_redirects (exp: 0) [ DIFFERENT ] - net.ipv4.conf.default.accept_source_route (exp: 0) [ OK ] - net.ipv4.conf.default.log_martians (exp: 1) [ DIFFERENT ] - net.ipv4.icmp_echo_ignore_broadcasts (exp: 1) [ OK ] - net.ipv4.icmp_ignore_bogus_error_responses (exp: 1) [ OK ] - net.ipv4.tcp_syncookies (exp: 1) [ OK ] - net.ipv4.tcp_timestamps (exp: 0 1) [ OK ] - net.ipv6.conf.all.accept_redirects (exp: 0) [ DIFFERENT ] - net.ipv6.conf.all.accept_source_route (exp: 0) [ OK ] - net.ipv6.conf.default.accept_redirects (exp: 0) [ DIFFERENT ] - net.ipv6.conf.default.accept_source_route (exp: 0) [ OK ] 看看 SSH 这个例子，因为它是一个需要保证安全的关键领域。这里没有什么红色的东西，但是 Lynis 对我的环境给出了很多强化 SSH 服务的建议：\n[+] SSH Support ------------------------------------ - Checking running SSH daemon [ FOUND ] - Searching SSH configuration [ FOUND ] - OpenSSH option: AllowTcpForwarding [ SUGGESTION ] - OpenSSH option: ClientAliveCountMax [ SUGGESTION ] - OpenSSH option: ClientAliveInterval [ OK ] - OpenSSH option: Compression [ SUGGESTION ] - OpenSSH option: FingerprintHash [ OK ] - OpenSSH option: GatewayPorts [ OK ] - OpenSSH option: IgnoreRhosts [ OK ] - OpenSSH option: LoginGraceTime [ OK ] - OpenSSH option: LogLevel [ SUGGESTION ] - OpenSSH option: MaxAuthTries [ SUGGESTION ] - OpenSSH option: MaxSessions [ SUGGESTION ] - OpenSSH option: PermitRootLogin [ SUGGESTION ] - OpenSSH option: PermitUserEnvironment [ OK ] - OpenSSH option: PermitTunnel [ OK ] - OpenSSH option: Port [ SUGGESTION ] - OpenSSH option: PrintLastLog [ OK ] - OpenSSH option: StrictModes [ OK ] - OpenSSH option: TCPKeepAlive [ SUGGESTION ] - OpenSSH option: UseDNS [ SUGGESTION ] - OpenSSH option: X11Forwarding [ SUGGESTION ] - OpenSSH option: AllowAgentForwarding [ SUGGESTION ] - OpenSSH option: UsePrivilegeSeparation [ OK ] - OpenSSH option: AllowUsers [ NOT FOUND ] - OpenSSH option: AllowGroups [ NOT FOUND ] 我的系统上没有运行虚拟机或容器，所以这些显示的结果是空的：\n[+] Virtualization ------------------------------------ [+] Containers ------------------------------------ Lynis 会检查一些从安全角度看很重要的文件的文件权限：\n[+] File Permissions ------------------------------------ - Starting file permissions check File: /boot/grub2/grub.cfg [ SUGGESTION ] File: /etc/cron.deny [ OK ] File: /etc/crontab [ SUGGESTION ] File: /etc/group [ OK ] File: /etc/group- [ OK ] File: /etc/hosts.allow [ OK ] File: /etc/hosts.deny [ OK ] File: /etc/issue [ OK ] File: /etc/issue.net [ OK ] File: /etc/motd [ OK ] File: /etc/passwd [ OK ] File: /etc/passwd- [ OK ] File: /etc/ssh/sshd_config [ OK ] Directory: /root/.ssh [ SUGGESTION ] Directory: /etc/cron.d [ SUGGESTION ] Directory: /etc/cron.daily [ SUGGESTION ] Directory: /etc/cron.hourly [ SUGGESTION ] Directory: /etc/cron.weekly [ SUGGESTION ] Directory: /etc/cron.monthly [ SUGGESTION ] 在报告的底部，Lynis 根据报告的发现提出了建议。每项建议后面都有一个 “TEST-ID”（为了下一部分方便，请将其保存起来）。\nSuggestions (47): ---------------------------- * If not required, consider explicit disabling of core dump in /etc/security/limits.conf file [KRNL-5820] https://cisofy.com/lynis/controls/KRNL-5820/ * Check PAM configuration, add rounds if applicable and expire passwords to encrypt with new values [AUTH-9229] https://cisofy.com/lynis/controls/AUTH-9229/ Lynis 提供了一个选项来查找关于每个建议的更多信息，你可以使用 show details 命令和 TEST-ID 号来访问：\n$ sudo lynis show details TEST-ID 这将显示该测试的其他信息。例如，我检查了 SSH-7408 的详细信息：\n$ sudo lynis show details SSH-7408 2020-04-30 05:52:23 Performing test ID SSH-7408 (Check SSH specific defined options) 2020-04-30 05:52:23 Test: Checking specific defined options in /tmp/lynis.k8JwazmKc6 2020-04-30 05:52:23 Result: added additional options for OpenSSH \u0026lt; 7.5 2020-04-30 05:52:23 Test: Checking AllowTcpForwarding in /tmp/lynis.k8JwazmKc6 2020-04-30 05:52:23 Result: Option AllowTcpForwarding found 2020-04-30 05:52:23 Result: Option AllowTcpForwarding value is YES 2020-04-30 05:52:23 Result: OpenSSH option AllowTcpForwarding is in a weak configuration state and should be fixed 2020-04-30 05:52:23 Suggestion: Consider hardening SSH configuration [test:SSH-7408] [details:AllowTcpForwarding (set YES to NO)] [solution:-] 试试吧 如果你想更多地了解你的 Linux 机器的安全性，请试试 Lynis。如果你想了解 Lynis 是如何工作的，可以研究一下它的 shell 脚本，看看它是如何收集这些信息的。\nHow can I protect against single user mode Potential Attacks\nSingle User Mode\nThis is the easiest way to gain unauthorised access to a Linux system is to boot the server into Single User Mode because it does not, by default, require a root password to gain root level access. Single User Mood can be accessed by power cycling the machine and interrupting the boot process. To boot into single user mode where the GRUB bootloader is used perform the following; interrupt the boot process, press e to edit the boot configuration file, append to the line starting Linux one of either s, S, 1 or systemd. unit=[rescue.target, emergency.target, rescue] to change the argument being passed to the kernel during boot to boot into Single User Mode, then press ctrl+x.\nProtecting Against Single User Mode\nFor a traditional init based system\nAs root edit the file /etc/sysconfig/init then on the line SINGLE=/sbin/sushell change sushell TO sulogin.\nFor a systemd based system\nThe target configuration need to be altered for the root password to be prompted for. The targets are located in /lib/systemd/system the files which need alteration are emergency.service and rescue.service. Alter the line starting ExecStart=-/bin/sh –c “/usr/sbin/sushell; ……” and change the /usr/sbin/sushell to/usr/sbin/sulogin in both emergency.service and rescue.service.\nTo check this has taken affect\nThen save changes and reboot to confirm the alteration has taken affect, if the alteration was success when booting into single user mode it shall ask for the root password.\nRoot Password\nBy default, some Linux distributions do not have root password sets, this can be checked by running the command head -1 /etc/shadow and if the second column, using a colon as a delimiter, is an exclamation mark then no password has been set. If no root password is set, then regardless of if the system is set to prompt for a password for Single User Mode or not it will just load root access.\nSecuring Bootloader\nInsecure bootloaders can result in the bootloader being bypassed completely and a shell being used to gain direct root level access to the system. This is done by interrupting the GRUB boot process and appending init=/bin/bas to the line beginning linux16. This will tell the kernel to use bash instead of init.\nProtecting against bootloader side loading\nThe GRUB bootloader can be password protected by placing the configuration in /etc/grub.d/40_custom file because this file will remain un touched by updates and upgrades to the boot loader. In /etc/grub.d/40_custom add set superusers=”admin” then password admin after that save and exit the file and run the following command grub2-mkpasswd-… (allow tab completion to finish this command so that the system compatible script is run) the output of this command from grub2. Onwards need to be added to the end of the line password admin in /etc/grub.d/40_custom. After that the grub file need to be recompiled by running the command grub2-mkconfig –o /boot/grub2/grub.cfg for centos or update-grub¬ on debian.\nTo check this has taken affect\nThen save changes and reboot to confirm the alteration has taken affect, if the alteration was success when booting and wanting to change the grub setting you will need to supply the username admin and the encrypted password.\nProtecting Against Recovery Attack\nThese measures can aid in protection however, if a disk is used the recover Linux feature on the disk can be used to mount the file system and alter the GRUB setting from the disk. To protect against make any removable media have a lower boot priority than the boot drive and password protect the BIOS and boot option menu to stop someone who hasn’t got access altering the boot order and booting into a disk to make changes to the system.\nCheckInstall 如果你已经从它的源码运行“make install”安装了linux程序。想完整移除它将变得真的很麻烦，除非程序的开发者在Makefile里提供了uninstall的目标设置。否则你必须在安装前后比较你系统里文件的完整列表，然后手工移除所有在安装过程中加入的文件。\n这时候Checkinstall就可以派上使用。Checkinstall会跟踪install命令行所创建或修改的所有文件的路径(例如：“make install”、“make install_modules”等)并建立一个标准的二进制包，让你能用你发行版的标准包管理系统安装或卸载它，请参考其官方文档。\n安装Checkinstall：\n# apt install checkinstall  一旦checkinstall安装好，你就可以用下列格式创建一个特定的软件包\n# checkinstall \u0026lt;install-command\u0026gt;  如果没有参数，默认安装命令“make install”将被使用。\n在这个例子里，我们将创建一个htop包，这是一个linux交互式文本模式进程查看器（类似 top）。\n首先，让我们从项目的官方网站下载源代码，作为一个好的习惯，我们存储源码包到/usr/local/src下，并解压它。\n# cd /usr/local/src # wget http://hisham.hm/htop/releases/1.0.3/htop-1.0.3.tar.gz # tar xzf htop-1.0.3.tar.gz # cd htop-1.0.3  让我们看看htop的安装命令是什么，以便我们能用Checkinstall命令调用它，如下面所示，htop用“make install”命令安装。\n# ./configure # make install  因此，要创建一个htop安装包，我们可以不带任何参数的调用checkinstall，这将使用“make install”命令创建一个包。在这个过程中， checkinstall命令会问你几个问题。\n简而言之，如下命令会创建一个htop包：\n# ./configure # checkinstall  然后checkinstall将根据你的linux系统是什么，自动地创建一个.rpm或者.deb包。\ngksudo/kdesudo Taken from here:\n You should never use normal sudo to start graphical applications as root. You should use gksudo (kdesudo on Kubuntu) to run such programs. gksudo sets HOME=/root, and copies .Xauthority to a tmp directory. This prevents files in your home directory becoming owned by root.\n Please note that this is primarily about configuration files. If you run Nautilus as root, even with gksu/gksudo, and you create a file or folder anywhere with it (including in your home directory), that file or folder will be owned by root. But if you run Nautilus (or most other graphical applications) as root with sudo, they may save their configuration files in your home directory (rather than root\u0026rsquo;s home directory). Those configuration files may be owned by root and inaccessible when you\u0026rsquo;re not running as root, which can severely mess up your settings, and may even keep some applications from working altogether.\nThe solution, once you have made this mistake, is to find the configuration files and delete them or chown them back to belonging your non-root user. Many such files start with a . or are contained in a directory that starts with a .. Some are located inside the .config folder in your home directory. To see files and folders that start with a . in Nautilus, press Ctrl+H (this shows hidden files.) To see them with ls, use the -a (or -A) flag.\nTo find if there are files not owned by you in your home directory, you can use the following command in a terminal:\nfind $HOME -not -user $USER -exec ls -lad {} \\; which will list all files under the home directory not owned by the user.\nman 手册页（man pages），即参考手册页（reference manual pages）的简称，是你进入 Linux 的钥匙。你想知道的一切都在那里，包罗万象。这套文档永远不会赢得普利策奖，但这套文档是相当准确和完整的。手册页是主要信源，其权威性是众所周知的。\n虽然它们是源头，但阅读起来并不是最令人愉快的。有一次，在很久以前的哲学课上，有人告诉我，阅读 亚里士多德 是最无聊的阅读。我不同意：说到枯燥的阅读，亚里士多德远远地排在第二位，仅次于手册页。\n乍一看，这些页面可能看起来并不完整，但是，不管你信不信，手册页并不是为了隐藏信息 —— 只是因为信息量太大，这些页面必须要有结构，而且信息是以尽可能简短的形式给出的。这些解释相当简略，需要一些时间来适应，但一旦你掌握了使用它们的技巧，你就会发现它们实际上是多么有用。\n入门 这些页面是通过一个叫做 man 的工具查看的，使用它的命令相当简单。在最简单的情况下，要使用 man，你要在命令行上输入 man，后面加一个空格和你想查询的命令，比如 ls 或 cp，像这样：\nman ls man 会打开 ls 命令的手册页。\n你可以用方向键上下移动，按 q 退出查看手册页。通常情况下，手册页是用 less 打开的，所以 less 命令的键盘快捷键在 man 中也可以使用。\n例如，你可以用 /search_term 来搜索一个特定的文本，等等。\n有一个关于手册页的介绍，这是一篇值得阅读介绍。它非常详细地说明了手册页是如何布局和组织的。\n要看这个页面，请打开一个终端，然后输入：\nman man 节 在你开始更深入地研究手册页之前，知道手册页有一个固定的页面布局和一个归档方案会有帮助。这可能会让新手感到困惑，因为我可以说：“看手册页中关于 ls 的 NAME 节（section）”，我也可以说：“看第 5 节（section）中的 passwd 的手册页。”\n这个词，“节（section）” 被用于两种不同的方式，但并不总是向新人解释其中的区别。\n我不确定为什么会出现这种混淆，但我在培训新用户和初级系统管理员时看到过几次这种混淆。我认为这可能是隧道视野，专注于一件事会使一个人忘记另一件事。一叶障目，不见泰山。\n对于那些已经知道其中的区别的人，你可以跳过这一小节。这一部分是针对那些刚接触到手册页的人。\n这就是区别：\n对于手册页\n单独的手册页是用来显示信息块的。例如，每个手册页都有一个“NAME”节，显示命令的名称和简短的描述。还会有另一个信息块，称为“SYNOPSIS”，显示该命令是如何使用的，以此类推。\n每个手册页都会有这些，以及其他的标题。这些在各个手册页上的节，或者说标题，有助于保持事情的一致性和信息的分工。\n对于手册\n使用“节”，如 “查看第 5 节中的 passwd 的手册页”，是指整个手册的内容。当我们只看一页时，很容易忽略这一点，但是 passwd 手册页是同一本手册的一部分，该手册还有 ls、rm、date、cal 等的手册页。\n整个 Linux 手册是巨大的；它有成千上万的手册页。其中一些手册页有专门的信息。有些手册页有程序员需要的信息，有些手册页有网络方面的独特信息，还有一些是系统管理员会感兴趣的。\n这些手册页根据其独特的目的被分组。想想看，把整个手册分成几个章节 —— 每章有一个特定的主题。有 9 个左右的章节（非常大的章节）。碰巧的是，这些章节被称为“节”。\n总结一下：\n 手册中单页（我们称之为“手册页”）的节是由标题定义的信息块。 这个大的手册（所有页面的集合）中的章节，刚好被称为“节”。  现在你知道区别了，希望本文的其余部分会更容易理解。\n手册页的节 你将会看到不同的手册页，所以让我们先研究一下各个页面的布局。\n手册页被分成几个标题，它们可能因提供者不同而不同，但会有相似之处。一般的分类如下：\n NAME（名称） SYNOPSIS（概要） DESCRIPTION（描述） EXAMPLES（例子） DIAGNOSTICS（诊断） FILES（文件） LIMITS（限制） PORTABILITY（可移植性） SEE ALSO（另见） HISTORY（历史） WARNING（警告）或BUGS（错误） NOTES（注意事项）  NAME - 在这个标题下是命令的名称和命令的简要描述。\nSYNOPSIS - 显示该命令的使用方法。例如，这里是 cal 命令的概要：\ncal [Month] [Year] 概要以命令的名称开始，后面是选项列表。概要采用命令行的一般形式；它显示了你可以输入的内容和参数的顺序。方括号中的参数（[]）是可选的；你可以不输入这些参数，命令仍然可以正常工作。不在括号内的项目必须使用。\n请注意，方括号只是为了便于阅读。当你输入命令时，不应该输入它们。\nDESCRIPTION - 描述该命令或工具的作用以及如何使用它。这一节通常以对概要的解释开始，并说明如果你省略任何一个可选参数会发生什么。对于长的或复杂的命令，这一节可能会被细分。\nEXAMPLES - 一些手册页提供了如何使用命令或工具的例子。如果有这一节，手册页会尝试给出一些简单的使用例子，以及更复杂的例子来说明如何完成复杂的任务。\nDIAGNOSTICS - 本节列出了由命令或工具返回的状态或错误信息。通常不显示不言自明的错误和状态信息。通常会列出可能难以理解的信息。\nFILES - 本节包含了 UNIX 用来运行这个特定命令的补充文件的列表。这里，“补充文件”是指没有在命令行中指定的文件。例如，如果你在看 passwd 命令的手册，你可能会发现 /etc/passwd 列在这一节中，因为 UNIX 是在这里存储密码信息。\nLIMITS - 本节描述了一个工具的限制。操作系统和硬件的限制通常不会被列出，因为它们不在工具的控制范围内。\nPORTABILITY - 列出其他可以使用该工具的系统，以及该工具的其他版本可能有什么不同。\nSEE ALSO - 列出包含相关信息的相关手册页。\nHISTORY - 提供命令的简要历史，如它第一次出现的时间。\nWARNING - 如果有这个部分，它包含了对用户的重要建议。\nNOTES - 不像警告那样严重，但也是重要的信息。\n同样，并不是所有的手册都使用上面列出的确切标题，但它们足够接近，可以遵循。\n手册的节 整个 Linux 手册集合的手册页传统上被划分为有编号的节：\n 第 1 节：Shell 命令和应用程序 第 2 节：基本内核服务 - 系统调用和错误代码 第 3 节：为程序员提供的库信息 第 4 节：网络服务 - 如果安装了 TCP/IP 或 NFS 设备驱动和网络协议 第 5 节：文件格式 - 例如：显示 tar 存档的样子 第 6 节：游戏 第 7 节：杂项文件和文档 第 8 节：系统管理和维护命令 第 9 节：不知名的内核规格和接口  将手册页分成这些组，可以使搜索更有效率。在我工作的地方，我有时会做一些编程工作，所以我花了一点时间看第 3 节的手册页。我也做一些网络方面的工作，所以我也知道要涉足网络部分。作为几个实验性机器的系统管理员，我在第 8 节花了很多时间。\n将手册网归入特定的节（章节），使搜索信息更加容易 —— 无论是对需要搜索的人，还是对进行搜索的机器。\n你可以通过名称旁边的数字来判断哪个手册页属于哪个部分。例如，如果你正在看 ls 的手册页，而页面的最上面写着。 LS(1)，那么你正在浏览第 1 节中的 ls 页面，该节包含关于 shell 命令和应用程序的页面。\n下面是另一个例子。如果你在看 passwd 的手册页，页面的顶部显示: PASSWD(1)，说明你正在阅读第 1 节中描述 passwd 命令如何更改用户账户密码的手册页。如果你看到 PASSWD(5)，那么你正在阅读关于密码文件和它是如何组成的的手册页。\npasswd 恰好是两个不同的东西：一个是命令的名称，一个是文件的名称。同样，第 1 节描述了命令，而第 5 节涉及文件格式。\n括号中的数字是重要的线索 —— 这个数字告诉你正在阅读的页面来自哪一节。\n搜索一个特定的节 基本命令：\nman -a name 将在每一节中搜索由 name 标识的手册页，按数字顺序逐一显示。要把搜索限制在一个特定的部分，请在 man 命令中使用一个参数，像这样：\nman 1 name 这个命令将只在手册页的第 1 节中搜索 name。使用我们前面的 passwd 例子，这意味着我们可以保持搜索的针对性。如果我想阅读 passwd 命令的手册页，我可以在终端输入以下内容：\nman 1 passwd man 工具将只在第 1 节中搜索 passwd 并显示它。它不会在任何其他节中寻找 passwd。\n这个命令的另一种方法是输入: man passwd.1。\n搜索包含某个关键词的所有手册页 如果你想获得包含某个关键词的手册页的列表，man 命令中的 -k 选项（通常称为标志或开关）可以派上用场。例如，如果你想看一个关于 ftp 的手册列表，你可以通过输入以下内容得到这个列表：\nman -k ftp 在接下来的列表中，你可以选择一个特定的手册页来阅读。\n在某些系统上，在 man -k 工作之前，系统管理员需要运行一个叫做 catman 的工具。\n了解手册的各个节 有两个有趣的工具可以帮助你搜索信息：whatis和 whereis。\nwhatis\n有的时候，我们完全可以得到我们需要的信息。我们需要的信息有很大的机会是可以找到的 —— 找到它可能是一个小问题。\n例如，如果我想看关于 passwd 文件的手册页，我在终端上输入：\nman passwd 我就会看到关于 passwd 命令所有信息的手册页，但没有关于 passwd 文件的内容。我知道 passwd 是一个命令，也有一个 passwd 文件，但有时，我可能会忘记这一点。这时我才意识到，文件结构在手册页中的不同节，所以我输入了：\nman 4 passwd 我得到这样的答复：\nNo manual entry for passwd in section 4 See 'man 7 undocumented' for help when manual pages are not available. 又是一次健忘的失误。文件结构在 System V UNIX 页面的第 4 节中。几年前，当我建立文件时，我经常使用 man 4 ...；这仍然是我的一个习惯。那么它在 Linux 手册中的什么地方呢？\n现在是时候调用 whatis 来纠正我了。为了做到这一点，我在我的终端中输入以下内容：\nwhatis passwd 然后我看到以下内容：\npasswd (1) - change user password passwd (1ssl) - compute password hashes passwd (5) - the password file 啊！passwd 文件的页面在第 5 节。现在没问题了，可以访问我想要的信息了：\nman 5 passwd 然后我被带到了有我需要的信息的手册页。\nwhatis 是一个方便的工具，可以用简短的一句话告诉你一个命令的作用。想象一下，你想知道 cal 是做什么的，而不想查看手册页。只要在命令提示符下键入以下内容。\nwhatis cal 你会看到这样的回应：\ncal (1) - displays a calendar and the date of Easter 现在你知道了 whatis 命令，我可以告诉你一个秘密 —— 有一个 man 命令的等价物。为了得到这个，我们使用 -f 开关：man -f ...。\n试试吧。在终端提示下输入 whatis cal。执行后就输入：man -f cal。两个命令的输出将是相同的。\nwhereis\nwhereis 命令的名字就说明了这一点 —— 它告诉你一个程序在文件系统中的位置。它也会告诉你手册页的存放位置。再以 cal 为例，我在提示符下输入以下内容：\nwhereis cal 我将看到这个：\ncal: /usr/bin/cal /usr/share/man/man1/cal.1.gz 仔细看一下这个回答。答案只在一行里，但它告诉我两件事：\n /usr/bin/cal 是 cal 程序所在的地方，以及 /usr/share/man/man1/cal.1.gz 是手册页所在的地方（我也知道手册页是被压缩的，但不用担心 —— man 命令知道如何即时解压）。  whereis 依赖于 PATH 环境变量；它只能告诉你文件在哪里，如果它们在你的 PATH 环境变量中。\n你可能想知道是否有一个与 whereis 相当的 man 命令。没有一个命令可以告诉你可执行文件的位置，但有一个开关可以告诉你手册页的位置。在这个例子中使用 date 命令，如果我们输入：\nwhereis date 在终端提示符下，我们会看到：\ndate: /usr/bin/date /usr/share/man/man1/date.1.gz 我们看到 date 程序在 /usr/bin/ 目录下，其手册页的名称和位置是：/usr/share/man/man1/date.1.gz。\n我们可以让 man 像 whereis 一样行事，最接近的方法是使用 -w 开关。我们不会得到程序的位置，但我们至少可以得到手册页的位置，像这样：\nman -w date 我们将看到这样的返回：\n/usr/share/man/man1/date.1.gz 你知道了 whatis 和 whereis，以及让 man 命令做同样（或接近）事情的方法。我展示了这两种方法，有几个不同的原因。\n多年来，我使用 whatis 和 whereis，因为它们在我的培训手册中。直到最近我才了解到 man -f ... 和 man -w ...。我确信我看了几百次 man 的手册页，但我从未注意到 -f 和 -w 开关。我总是在看手册页的其他东西（例如：man -k ...）。我只专注于我需要找到的东西，而忽略了其他的东西。一旦我找到了我需要的信息，我就会离开这个页面，去完成工作，而不去注意这个命令所提供的其他一些宝贝。\n这没关系，因为这部分就是手册页的作用：帮助你完成工作。\n直到最近我向别人展示如何使用手册页时，我才花时间去阅读 —— “看看还有什么可能” —— 我们才真正注意到关于 man 命令的 -f 和 -w 标记可以做什么的信息。\n不管你使用 Linux 多久了，或者多么有经验，总有一些新东西需要学习。\n手册页会告诉你在完成某项任务时可能需要知道的东西 —— 但它们也有很多内容 —— 足以让你看起来像个魔术师，但前提是你要花时间去读。\n结论 如果你花一些时间和精力在手册页上，你将会取得胜利。你对手册页的熟练程度，将在你掌握 Linux 的过程中发挥巨大作用。\ntldr Collaborative cheatsheets for console commands\n“TLDR” 是流行的互联网行话，意思是“太长不读（to long didn\u0026rsquo;t read）”。这就是他们创建 tldr 的想法。如果你觉得手册页太长而不想阅读，tldr 通过提供命令的实际例子而将其简化了。\n$ sudo apt install tldr $ tldr -u $ tldr tldr ls ls 命令可以列出一个 POSIX 系统上的文件。这是一个简单的命令，但它经常被低估，不是它能做什么（因为它确实只做了一件事），而是你该如何优化对它的使用。\nGNU 还是 BSD？ 在了解 ls 的隐藏能力之前，你必须确定你正在运行哪个 ls 命令。有两个最流行的版本：包含在 GNU coreutils 包中的 GNU 版本，以及 BSD 版本。如果你正在运行 Linux，那么你很可能已经安装了 GNU 版本的 ls。如果你正在运行 BSD 或 MacOS，那么你有的是 BSD 版本。本文会介绍它们的不同之处。\n你可以使用 --version 选项找出你计算机上的版本：\n$ ls --version 如果它返回有关 GNU coreutils 的信息，那么你拥有的是 GNU 版本。如果它返回一个错误，你可能正在运行的是 BSD 版本（运行 man ls | head 以确定）。\n你还应该调查你的发行版可能具有哪些预设选项。终端命令的自定义通常放在 $HOME/.bashrc 或 $HOME/.bash_aliases 或 $HOME/.profile 中，它们是通过将 ls 别名化为更复杂的 ls 命令来完成的。例如：\nalias ls=\u0026#39;ls --color\u0026#39; 发行版提供的预设非常有用，但它们确实很难分辨出哪些是 ls 本身的特性，哪些是它的附加选项提供的。你要是想要运行 ls 命令本身而不是它的别名，你可以用反斜杠“转义”命令：\n$ \\ls 分类 单独运行 ls 会以适合你终端的列数列出文件：\n$ ls ~/example bunko jdk-10.0.2 chapterize otf2ttf.ff despacer overtar.sh estimate.sh pandoc-2.7.1 fop-2.3 safe_yaml games tt 这是有用的信息，但所有这些文件看起来基本相同，没有方便的图标来快速表示出哪个是目录、文本文件或图像等等。\n使用 -F（或 GNU 上的长选项 --classify）以在每个条目之后显示标识文件类型的指示符：\n$ ls ~/example bunko jdk-10.0.2/ chapterize* otf2ttf.ff* despacer* overtar.sh* estimate.sh pandoc@ fop-2.3/ pandoc-2.7.1/ games/ tt* 使用此选项，终端中列出的项目使用简写符号来按文件类型分类：\n 斜杠（/）表示目录（或“文件夹”）。 星号（*）表示可执行文件。这包括二进制文件（编译代码）以及脚本（具有可执行权限的文本文件）。 符号（@）表示符号链接（或“别名”）。 等号（=）表示套接字。 在 BSD 上，百分号（%）表示涂改whiteout（某些文件系统上的文件删除方法）。 在 GNU 上，尖括号（\u0026gt;）表示门door（Illumos 和 Solaris上的进程间通信）。 竖线（|）表示 FIFO 管道。 这个选项的一个更简单的版本是 -p，它只区分文件和目录。  （LCTT 译注：在支持彩色的终端上，使用 --color 选项可以以不同的颜色来区分文件类型，但要注意如果将输出导入到管道中，则颜色消失。）\n长列表 从 ls 获取“长列表”的做法是如此常见，以至于许多发行版将 ll 别名为 ls -l。长列表提供了许多重要的文件属性，例如权限、拥有每个文件的用户、文件所属的组、文件大小（以字节为单位）以及文件上次更改的日期：\n$ ls -l -rwxrwx---. 1 seth users 455 Mar 2 2017 estimate.sh -rwxrwxr-x. 1 seth users 662 Apr 29 22:27 factorial -rwxrwx---. 1 seth users 20697793 Jun 29 2018 fop-2.3-bin.tar.gz -rwxrwxr-x. 1 seth users 6210 May 22 10:22 geteltorito -rwxrwx---. 1 seth users 177 Nov 12 2018 html4mutt.sh [...] 如果你不想以字节为单位，请添加 -h 标志（或 GNU 中的 --human）以将文件大小转换为更加人性化的表示方法：\n$ ls --human -rwxrwx---. 1 seth users 455 Mar 2 2017 estimate.sh -rwxrwxr-x. 1 seth seth 662 Apr 29 22:27 factorial -rwxrwx---. 1 seth users 20M Jun 29 2018 fop-2.3-bin.tar.gz -rwxrwxr-x. 1 seth seth 6.1K May 22 10:22 geteltorito -rwxrwx---. 1 seth users 177 Nov 12 2018 html4mutt.sh 要看到更少的信息，你可以带有 -o 选项只显示所有者的列，或带有 -g 选项只显示所属组的列：\n$ ls -o -rwxrwx---. 1 seth 455 Mar 2 2017 estimate.sh -rwxrwxr-x. 1 seth 662 Apr 29 22:27 factorial -rwxrwx---. 1 seth 20M Jun 29 2018 fop-2.3-bin.tar.gz -rwxrwxr-x. 1 seth 6.1K May 22 10:22 geteltorito -rwxrwx---. 1 seth 177 Nov 12 2018 html4mutt.sh 也可以将两个选项组合使用以显示两者。\n时间和日期格式 ls 的长列表格式通常如下所示：\n-rwxrwx---. 1 seth users 455 Mar 2 2017 estimate.sh -rwxrwxr-x. 1 seth users 662 Apr 29 22:27 factorial -rwxrwx---. 1 seth users 20697793 Jun 29 2018 fop-2.3-bin.tar.gz -rwxrwxr-x. 1 seth users 6210 May 22 10:22 geteltorito -rwxrwx---. 1 seth users 177 Nov 12 2018 html4mutt.sh 月份的名字不便于排序，无论是通过计算还是识别（取决于你的大脑是否倾向于喜欢字符串或整数）。你可以使用 --time-style 选项和格式名称更改时间戳的格式。可用格式为：\n full-iso：ISO 完整格式（1970-01-01 21:12:00） long-iso：ISO 长格式（1970-01-01 21:12） iso：iso 格式（01-01 21:12） locale：本地化格式（使用你的区域设置） posix-STYLE：POSIX 风格（用区域设置定义替换 STYLE）  你还可以使用 date 命令的正式表示法创建自定义样式。\n按时间排序 通常，ls 命令按字母顺序排序。你可以使用 -t 选项根据文件的最近更改的时间（最新的文件最先列出）进行排序。\n例如：\n$ touch foo bar baz $ ls bar baz foo $ touch foo $ ls -t foo bar baz 列出方式 ls 的标准输出平衡了可读性和空间效率，但有时你需要按照特定方式排列的文件列表。\n要以逗号分隔文件列表，请使用 -m：\nls -m ~/example bar, baz, foo 要强制每行一个文件，请使用 -1 选项（这是数字 1，而不是小写的 L）：\n$ ls -1 ~/bin/ bar baz foo 要按文件扩展名而不是文件名对条目进行排序，请使用 -X（这是大写 X）：\n$ ls bar.xfc baz.txt foo.asc $ ls -X foo.asc baz.txt bar.xfc 隐藏杂项 在某些 ls 列表中有一些你可能不关心的条目。例如，元字符 . 和 .. 分别代表“本目录”和“父目录”。如果你熟悉在终端中如何切换目录，你可能已经知道每个目录都将自己称为 .，并将其父目录称为 ..，因此当你使用 -a 选项显示隐藏文件时并不需要它经常提醒你。\n要显示几乎所有隐藏文件（. 和 .. 除外），请使用 -A 选项：\n$ ls -a . .. .android .atom .bash_aliases [...] $ ls -A .android .atom .bash_aliases [...] 有许多优秀的 Unix 工具有保存备份文件的传统，它们会在保存文件的名称后附加一些特殊字符作为备份文件。例如，在 Vim 中，备份会以在文件名后附加 ~ 字符的文件名保存。\n这些类型的备份文件已经多次使我免于愚蠢的错误，但是经过多年享受它们提供的安全感后，我觉得不需要用视觉证据来证明它们存在。我相信 Linux 应用程序可以生成备份文件（如果它们声称这样做的话），我很乐意相信它们存在 —— 而不用必须看到它们。\n要隐藏备份文件，请使用 -B 或 --ignore-backups 隐藏常用备份格式（此选项在 BSD 的 ls 中不可用）：\n$ ls bar.xfc baz.txt foo.asc~ foo.asc $ ls -B bar.xfc baz.txt foo.asc 当然，备份文件仍然存在；它只是过滤掉了，你不必看到它。\n除非另有配置，GNU Emacs 在文件名的开头和结尾添加哈希字符（＃）来保存备份文件（#file＃）。其他应用程序可能使用不同的样式。使用什么模式并不重要，因为你可以使用 --hide 选项创建自己的排除项：\n$ ls bar.xfc baz.txt #foo.asc# foo.asc $ ls --hide=\u0026#34;#*#\u0026#34; bar.xfc baz.txt foo.asc 递归地列出目录 除非你在指定目录上运行 ls，否则子目录的内容不会与 ls 命令一起列出：\n$ ls -F example/ quux* xyz.txt $ ls -R quux xyz.txt ./example: bar.xfc baz.txt #foo.asc# foo.asc 使用别名使其永久化 ls 命令可能是 shell 会话期间最常使用的命令。这是你的眼睛和耳朵，为你提供上下文信息和确认命令的结果。虽然有很多选项很有用，但 ls 之美的一部分就是简洁：两个字符和回车键，你就知道你到底在哪里以及附近有什么。如果你不得不停下思考（更不用说输入）几个不同的选项，它会变得不那么方便，所以通常情况下，即使最有用的选项也不会用了。\n解决方案是为你的 ls 命令添加别名，以便在使用它时，你可以获得最关心的信息。\n要在 Bash shell 中为命令创建别名，请在主目录中创建名为 .bash_aliases 的文件（必须在开头包含 .）。 在此文件中，列出要创建的别名，然后是要为其创建别名的命令。例如：\nalias ls=\u0026#39;ls -A -F -B --human --color\u0026#39; 这一行导致你的 Bash shell 将 ls 命令解释为 ls -A -F -B --human --color。\n你不必仅限于重新定义现有命令，还可以创建自己的别名：\nalias ll=\u0026#39;ls -l\u0026#39; alias la=\u0026#39;ls -A\u0026#39; alias lh=\u0026#39;ls -h\u0026#39; 要使别名起作用，shell 必须知道 .bash_aliases 配置文件存在。在编辑器中打开 .bashrc 文件（如果它不存在则创建它），并包含以下代码块：\nif [ -e $HOME/.bash_aliases ]; then source $HOME/.bash_aliases fi 每次加载 .bashrc（这是一个新的 Bash shell 启动的时候），Bash 会将 .bash_aliases 加载到你的环境中。你可以关闭并重新启动 Bash 会话，或者直接强制它执行此操作：\n$ source ~/.bashrc 如果你忘了你是否有别名命令，which 命令可以告诉你：\n$ which ls alias ls=\u0026#39;ls -A -F -B --human --color\u0026#39; /usr/bin/ls 如果你将 ls 命令别名为带有选项的 ls 命令，则可以通过将反斜杠前缀到 ls 前来覆盖你的别名。例如，在示例别名中，使用 -B 选项隐藏备份文件，这意味着无法使用 ls 命令显示备份文件。 可以覆盖该别名以查看备份文件：\n$ ls bar baz foo $ \\ls bar baz baz~ foo 做一件事，把它做好 ls 命令有很多选项，其中许多是特定用途的或高度依赖于你所使用的终端。在 GNU 系统上查看 info ls，或在 GNU 或 BSD 系统上查看 man ls 以了解更多选项。\n你可能会觉得奇怪的是，一个以每个工具“做一件事，把它做好”的前提而闻名的系统会让其最常见的命令背负 50 个选项。但是 ls 只做一件事：它列出文件，而这 50 个选项允许你控制接收列表的方式，ls 的这项工作做得非常、非常好。\nexa A modern replacement for ‘ls’.\ndu (Disk Usage) 在 Linux 中使用 ls 命令 列出的目录内容中，目录的大小仅显示 4KB。这是一个默认的大小，是用来存储磁盘上存储目录的元数据的大小。\ndu 命令 表示 磁盘使用率。这是一个标准的 Unix 程序，用于估计当前工作目录中的文件空间使用情况。\n它使用递归方式总结磁盘使用情况，以获取目录及其子目录的大小。\n$ du -hs --max-depth=0 /path/dir  du – 这是一个命令 -h – 以易读的格式显示大小 (例如 1K 234M 2G) -s – 仅显示每个参数的总数 --max-depth=N – 目录的打印深度  NCurses Disk Usage Ncdu is a disk usage analyzer with an ncurses interface.\nncdu 命令旨在提供一份关于你在硬盘上使用的空间的交互式报告。\ngdu Fast disk usage analyzer with console interface written in Go\nDiff diff是Unix系统的一个很重要的工具程序。\n它用来比较两个文本文件的差异，是代码版本管理的基石之一。你在命令行下，输入：\n$ diff \u0026lt;变动前的文件\u0026gt; \u0026lt;变动后的文件\u0026gt; diff就会告诉你，这两个文件有何差异。它的显示结果不太好懂，下面我就来说明，如何读懂diff。\n三种格式 由于历史原因，diff有三种格式：\n 正常格式（normal diff） 上下文格式（context diff） 合并格式（unified diff）  我们依次来看。\n示例文件 为了便于讲解，先新建两个示例文件。\n第一个文件叫做f1，内容是每行一个a，一共7行。\na a a a a a a 第二个文件叫做f2，修改f1而成，第4行变成b，其他不变。\na a a b a a a 正常格式 现在对f1和f2进行比较：\n$ diff f1 f2 这时，diff就会显示正常格式的结果：\n4c4 \u0026lt; a --- \u0026gt; b 第一行是一个提示，用来说明变动位置。\n4c4 它分成三个部分：前面的\u0026quot;4\u0026quot;，表示f1的第4行有变化；中间的\u0026quot;c\u0026quot;表示变动的模式是内容改变（change），其他模式还有\u0026quot;增加\u0026quot;（a，代表addition）和\u0026quot;删除\u0026quot;（d，代表deletion）；后面的\u0026quot;4\u0026quot;，表示变动后变成f2的第4行。\n第二行分成两个部分。\n\u0026lt; a 前面的小于号，表示要从f1当中去除该行（也就是第4行），后面的\u0026quot;a\u0026quot;表示该行的内容。\n第三行用来分割f1和f2。\n--- 第四行，类似于第二行。\n\u0026gt; b 前面的大于号表示f2增加了该行，后面的\u0026quot;b\u0026quot;表示该行的内容。\n最早的Unix（即AT\u0026amp;T版本的Unix），使用的就是这种格式的diff。\n上下文格式 上个世纪80年代初，加州大学伯克利分校推出BSD版本的Unix时，觉得diff的显示结果太简单，最好加入上下文，便于了解发生的变动。因此，推出了上下文格式的diff。\n它的使用方法是加入c参数（代表context）。\n$ diff -c f1 f2 显示结果如下：\n*** f1 2012-08-29 16:45:41.000000000 +0800 --- f2 2012-08-29 16:45:51.000000000 +0800 *************** *** 1,7 **** a a a !a a a a --- 1,7 ---- a a a !b a a a 这个结果分成四个部分。\n第一部分的两行，显示两个文件的基本情况：文件名和时间信息。\n*** f1 2012-08-29 16:45:41.000000000 +0800 --- f2 2012-08-29 16:45:51.000000000 +0800 ***表示变动前的文件，---表示变动后的文件。\n第二部分是15个星号，将文件的基本情况与变动内容分割开。\n*************** 第三部分显示变动前的文件，即f1。\n*** 1,7 **** a a a !a a a a 这时不仅显示发生变化的第4行，还显示第4行的前面三行和后面三行，因此一共显示7行。所以，前面的*** 1,7 ****就表示，从第1行开始连续7行。\n另外，文件内容的每一行最前面，还有一个标记位。如果为空，表示该行无变化；如果是感叹号（!），表示该行有改动；如果是减号（-），表示该行被删除；如果是加号（+），表示该行为新增。\n第四部分显示变动后的文件，即f2。\n--- 1,7 ---- a a a !b a a a 除了变动行（第4行）以外，也是上下文各显示三行，总共显示7行。\n合并格式 如果两个文件相似度很高，那么上下文格式的diff，将显示大量重复的内容，很浪费空间。1990年，GNU diff率先推出了\u0026quot;合并格式\u0026quot;的diff，将f1和f2的上下文合并在一起显示。\n它的使用方法是加入u参数（代表unified）。\n$ diff -u f1 f2 显示结果如下：\n--- f1 2012-08-29 16:45:41.000000000 +0800 +++ f2 2012-08-29 16:45:51.000000000 +0800 @@ -1,7 +1,7 @@ a a a -a +b a a a 它的第一部分，也是文件的基本信息。\n--- f1 2012-08-29 16:45:41.000000000 +0800 +++ f2 2012-08-29 16:45:51.000000000 +0800 ---表示变动前的文件，+++表示变动后的文件。\n第二部分，变动的位置用两个@作为起首和结束。\n@@ -1,7 +1,7 @@ 前面的\u0026quot;-1,7\u0026quot;分成三个部分：减号表示第一个文件（即f1），\u0026ldquo;1\u0026quot;表示第1行，\u0026ldquo;7\u0026quot;表示连续7行。合在一起，就表示下面是第一个文件从第1行开始的连续7行。同样的，\u0026quot;+1,7\u0026quot;表示变动后，成为第二个文件从第1行开始的连续7行。\n第三部分是变动的具体内容。\na a a -a +b a a a 除了有变动的那些行以外，也是上下文各显示3行。它将两个文件的上下文，合并显示在一起，所以叫做\u0026quot;合并格式\u0026rdquo;。每一行最前面的标志位，空表示无变动，减号表示第一个文件删除的行，加号表示第二个文件新增的行。\ngit格式 版本管理系统git，使用的是合并格式diff的变体。\n$ git diff 显示结果如下：\ndiff --git a/f1 b/f1 index 6f8a38c..449b072 100644 --- a/f1 +++ b/f1 @@ -1,7 +1,7 @@ a a a -a +b a a a 第一行表示结果为git格式的diff。\ndiff --git a/f1 b/f1 进行比较的是，a版本的f1（即变动前）和b版本的f1（即变动后）。\n第二行表示两个版本的git哈希值（index区域的6f8a38c对象，与工作目录区域的449b072对象进行比较），最后的六位数字是对象的模式（普通文件，644权限）。　index 6f8a38c..449b072 100644 第三行表示进行比较的两个文件。\n--- a/f1 +++ b/f1 ---表示变动前的版本，+++表示变动后的版本。\n后面的行都与官方的合并格式diff相同。\n@@ -1,7 +1,7 @@ a a a -a +b a a a Crontab 使用 crontab 命令来执行定时任务。所谓定时任务，就是未来的某个或多个时点，预定要执行的任务，比如每五分钟收一次邮件、每天半夜两点分析一下日志等等。\nInstalling $ sudo apt install cronie Running $ systemctl enable crond.service $ systemctl start crond.service 命令详解 crontab 命令通过 /etc/cron.allow 和 /etc/cron.deny 文件来限制某些用户是否可以使用 crontab 命令：\n 当系统中有 /etc/cron.allow 文件时，只有写入此文件的用户可以使用 crontab 命令，没有写入的用户不能使用 crontab 命令。 当系统中只有 /etc/cron.deny 文件时，写入此文件的用户不能使用 crontab 命令，没有写入文件的用户可以使用 crontab 命令。 /etc/cron.allow 文件比 /etc/cron.deny 文件的优先级高，Linux 系统中默认只有 /etc/cron.deny 文件。  crontab 命令的基本格式如下：\ncrontab [选项] [file] 注意，这里的 file 指的是命令文件的名字，表示将 file 作为 crontab 的任务列表文件并载入 crontab，若在命令行中未指定文件名，则此命令将接受标准输入（键盘）上键入的命令，并将它们键入 crontab。\n常用选项    选项 功能     -u user 用来设定某个用户的 crontab 服务，例如 \u0026ldquo;-u demo\u0026rdquo; 表示设备 demo 用户的 crontab 服务，此选项一般有 root 用户来运行。   -e 编辑某个用户的 crontab 文件内容。如果不指定用户，则表示编辑当前用户的 crontab 文件。   -l 显示某用户的 crontab 文件内容，如果不指定用户，则表示显示当前用户的 crontab 文件内容。   -r 从 /var/spool/cron 删除某用户的 crontab 文件，如果不指定用户，则默认删除当前用户的 crontab 文件。   -i 在删除用户的 crontab 文件时，给确认提示。    crontab 文件格式 * * * * * 执行的任务 执行的任务字段既可以定时执行系统命令，也可以定时执行某个 Shell 脚本。\n执行时间\n   项目 含义 范围     第一个\u0026rdquo;*\u0026quot; 一小时当中的第几分钟（minute） 0~59   第二个\u0026quot;*\u0026quot; 一天当中的第几小时（hour） 0~23   第三个\u0026quot;*\u0026quot; 一个月当中的第几天（day） 1~31   第四个\u0026quot;*\u0026quot; 一年当中的第几个月（month） 1~12   第五个\u0026quot;*\u0026quot; 一周当中的星期几（week） 0~7（0和7都代表星期日）    时间特殊符号\n   特殊符号 含义     *（星号） 代表任何时间。比如第一个\u0026quot;*\u0026ldquo;就代表一小时种每分钟都执行一次的意思。   ,（逗号） 代表不连续的时间。比如\u0026quot;0 8，12，16***命令\u0026quot;就代表在每天的 8 点 0 分、12 点 0 分、16 点 0 分都执行一次命令。   -（中杠） 代表连续的时间范围。比如\u0026quot;0 5 ** 1-6命令\u0026rdquo;，代表在周一到周六的凌晨 5 点 0 分执行命令。   /（正斜线） 代表每隔多久执行一次。比如\u0026quot;*/10****命令\u0026quot;，代表每隔 10 分钟就执行一次命令。    当“crontab -e”编辑完成之后，一旦保存退出，那么这个定时任务实际就会写入 /var/spool/cron/ 目录中，每个用户的定时任务用自己的用户名进行区分。而且 crontab 命令只要保存就会生效，只要 crond 服务是启动的。\ncrontab举例\n   时间 含义     45 22 ***命令 在每天 22 点 45 分执行命令   0 17 ** 1命令 在每周一的 17 点 0 分执行命令   0 5 1，15**命令 在每月 1 日和 15 日的凌晨 5 点 0 分执行命令   40 4 ** 1-5命令 在每周一到周五的凌晨 4 点 40 分执行命令   */10 4 ***命令 在每天的凌晨 4 点，每隔 10 分钟执行一次命令   0 0 1，15 * 1命令 在每月 1 日和 15 日，每周一 0 点 0 分都会执行命令    注意事项\n 6 个选项都不能为空，必须填写。如果不确定，则使用“*”代表任意时间。 crontab 定时任务的最小有效时间是分钟，最大有效时间是月。像 2018 年某时执行、3 点 30 分 30 秒这样的时间都不能被识别。 在定义时间时，日期和星期最好不要在一条定时任务中出现，因为它们都以天为单位，非常容易让管理员混淆。 在定时任务中，不管是直接写命令，还是在脚本中写命令，最好都使用绝对路径。有时使用相对路径的命令会报错。  run a script on startup Put the script in the appropriate user\u0026rsquo;s cron table (i. e. the crontab) with a schedule of @reboot.\nA user can edit its cron table with crontab -e.\nAn example which will run /path/to/script.sh at startup:\n@reboot /path/to/script.sh If you need to run it as root, don\u0026rsquo;t use @reboot sudo /path/to/script.sh; use sudo crontab -eu root to edit root\u0026rsquo;s crontab.\nps 简介 要对进程进行监测和控制，首先必须要了解当前进程的情况，也就是需要查看当前进程，而 ps 命令（Process Status）就是最基本同时也是非常强大的进程查看命令。使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等等。总之大部分信息都是可以通过执行该命令得到的。ps命令列出的是当前那些进程的快照，就是执行ps命令的那个时刻的那些进程，如果想要动态的显示进程信息，就可以使用top命令。\nlinux上进程有5种状态：\n  就绪状态和运行状态\n就绪状态的状态标志state的值为TASK_RUNNING。此时，程序已被挂入运行队列，处于准备运行状态。一旦获得处理器使用权，即可进入运行状态。\n当进程获得处理器而运行时 ，state的值仍然为TASK_RUNNING，并不发生改变；但Linux会把一个专门用来指向当前运行任务的指针current指向它，以表示它是一个正在运行的进程。\n  可中断等待状态\n状态标志state的值为TASK_INTERRUPTIBL。此时，由于进程未获得它所申请的资源而处在等待状态。一旦资源有效或者有唤醒信号，进程会立即结束等待而进入就绪状态。\n  不可中断等待状态\n状态标志state的值为TASK_UNINTERRUPTIBL。此时，进程也处于等待资源状态。一旦资源有效，进程会立即进入就绪状态。这个等待状态与可中断等待状态的区别在于：处于TASK_UNINTERRUPTIBL状态的进程不能被信号量或者中断所唤醒，只有当它申请的资源有效时才能被唤醒。\n这个状态被应用在内核中某些场景中，比如当进程需要对磁盘进行读写，而此刻正在DMA中进行着数据到内存的拷贝，如果这时进程休眠被打断（比如强制退出信号）那么很可能会出现问题，所以这时进程就会处于不可被打断的状态下。\n  停止状态\n状态标志state的值为TASK_STOPPED。当进程收到一个SIGSTOP信号后，就由运行状态进入停止状态，当受到一个SIGCONT信号时，又会恢复运行状态。这种状态主要用于程序的调试，又被叫做“暂停状态”、“挂起状态”。\n  中止状态\n状态标志state的值为TASK_DEAD。进程因某种原因而中止运行，进程占有的所有资源将被回收，除了task_struct结构（以及少数资源）以外，并且系统对它不再予以理睬，所以这种状态也叫做“僵死状态”，进程成为僵尸进程。\n  ps 标识进程状态对应的 5 种状态码：\n R：就绪状态和运行状态 runnable (on run queue) S：可中断等待状态 sleeping D：不可中断等待状态 uninterruptible sleep (usually IO) T：停止状态 traced or stopped Z：中止状态 a defunct (”zombie”) process  ps 标识进程的其他状态码：\n X：死掉的进程 Dead （应该不会出现） W：内存交互状态Paging （从 2.6 内核开始无效） N：高优先级 \u0026lt;：低优先级 s：包含子进程 L：被锁入内存 l：多线程状态 +：前台进程  命令参数 在不同的 Linux 发行版上，ps 命令的语法各不相同，为此，Linux 采取了一个折中的方法，即融合各种不同的风格，兼顾那些已经习惯了其它系统上使用 ps 命令的用户。ps命令支持三种使用的语法格式：\n UNIX 风格，选项可以组合在一起，并且选项前必须有“-”连字符； BSD 风格，选项可以组合在一起，但是选项前不能有“-”连字符； GNU 风格的选项，选项前有两个“-”连字符；  ps 命令常用的参数：\nps -a 显示所有终端下执行的进程，包含其他用户的进程 ps -A 显示所有进程 ps -e 和-A功能一样 ps -H 显示树状结构，表示程序间的相互关系 ps -f 全格式显示进程 ps a 显示当前终端下执行的进程 ps c 显示进程的真实名称 ps e 列出程序所使用的环境变量 ps f 用ASCII字符显示树状结构，表达程序间的相互关系 ps x 显示所有进程，无论是否运行在终端上 ps u 显示用户相关的进程或者与用户相关的属性 ps r 只显示正在运行的进程 使用实例 大家如果执行 man ps 命令，则会发现 ps 命令的帮助为了适应不同的类 UNIX 系统，可用格式非常多，不方便记忆。所以，我建议大家记忆几个固定选项即可。\nps aux 查看系统中所有的进程\n# ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.2 2872 1416 ? Ss Jun04 0:02 /sbin/init root 2 0.0 0.0 0 0 ? S Jun04 0:00 [kthreadd] root 3 0.0 0.0 0 0 ? S Jun04 0:00 [migration/0] root 4 0.0 0.0 0 0 ? S Jun04 0:00 [ksoftirqd/0] …省略部分输出… 输出信息中各列的具体含义：\n   表头 含义     USER 该进程是由哪个用户产生的。   PID 进程的 ID。   %CPU 该进程占用 CPU 资源的百分比，占用的百分比越高，进程越耗费资源。   %MEM 该进程占用物理内存的百分比，占用的百分比越高，进程越耗费资源。   VSZ 该进程占用虚拟内存的大小，单位为 KB。   RSS 该进程占用实际物理内存的大小，单位为 KB。   TTY 该进程是在哪个终端运行的。其中，tty1 ~ tty7 代表本地控制台终端（可以通过 Alt+F1 ~ F7 快捷键切换不同的终端），tty1~tty6 是本地的字符界面终端，tty7 是图形终端。pts/0 ~ 255 代表虚拟终端，一般是远程连接的终端，第一个远程连接占用 pts/0，第二个远程连接占用 pts/1，依次増长。   STAT 进程状态。   START 该进程的启动时间。   TIME 该进程占用 CPU 的运算时间，注意不是系统时间。   COMMAND 产生此进程的命令名。    ps -le 查看系统中所有的进程\nps aux 命令可以看到系统中所有的进程，ps -le 命令也能看到系统中所有的进程。由于 -l 选项的作用，所以 ps -le 命令能够看到更加详细的信息，比如父进程的 PID、优先级等。但是这两个命令的基本作用是一致的，掌握其中一个就足够了。\n# ps -le F S UID PID PPID C PRI Nl ADDR SZ WCHAN TTY TIME CMD 4 S 0 1 0 0 80 0 - 718 - ? 00:00:02 init 1 S 0 2 0 0 80 0 - 0 - ? 00:00:00 kthreadd 1 S 0 3 2 0 -40 - - 0 - ? 00:00:00 migration/0 1 S 0 4 2 0 80 0 - 0 - ? 00:00:00 ksoflirqd/0 1 S 0 5 2 0 -40 - - 0 - ? 00:00:00 migration/0 …省略部分输出… 输出信息中各列的含义：\n   表头 含义     F 进程标志，说明进程的权限，常见的标志有两个: 1：进程可以被复制，但是不能被执行；4：进程使用超级用户权限；   S 进程状态。具体的状态和\u0026quot;psaux\u0026quot;命令中的 STAT 状态一致；   UID 运行此进程的用户的 ID；   PID 进程的 ID；   PPID 父进程的 ID；   C 该进程的 CPU 使用率，单位是百分比；   PRI 进程的优先级，数值越小，该进程的优先级越高，越早被 CPU 执行；   NI 进程的优先级，数值越小，该进程越早被执行；   ADDR 该进程在内存的哪个位置；   SZ 该进程占用多大内存；   WCHAN 该进程是否运行。\u0026quot;-\u0026ldquo;代表正在运行；   TTY 该进程由哪个终端产生；   TIME 该进程占用 CPU 的运算时间，注意不是系统时间；   CMD 产生此进程的命令名；    ps -l 查看当前 Shell 产生的进程\n# ps -l F S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD 4 S 0 18618 18614 0 80 0 - 1681 - pts/1 00:00:00 bash 4 R 0 18683 18618 4 80 0 - 1619 - pts/1 00:00:00 ps top 简介 top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。\ntop显示系统当前的进程和其他状况，是一个动态显示过程，即可以通过用户按键来不断刷新当前状态。如果在前台执行该命令，它将独占前台，直到用户终止该程序为止。\n比较准确的说，top命令提供了实时的对系统处理器的状态监视。它将显示系统中CPU最“敏感”的任务列表。该命令可以按CPU使用、内存使用和执行时间对任务进行排序；而且该命令的很多特性都可以通过交互式命令或者在个人定制文件中进行设定。\n命令参数 top 命令的基本格式如下：\n#top [选项] 选项：\n -d 秒数：指定 top 命令每隔几秒更新。默认是 3 秒； -b：使用批处理模式输出。一般和\u0026rdquo;-n\u0026quot;选项合用，用于把 top 命令重定向到文件中； -n 次数：指定 top 命令执行的次数。一般和\u0026quot;-b\u0026quot;选项合用； -p 进程PID：仅查看指定 ID 的进程； -s：使 top 命令在安全模式中运行，避免在交互模式中出现错误； -u 用户名：只监听某个用户的进程；  交互操作指令 在 top 命令的显示窗口中，还可以使用如下按键，进行一下交互操作：\n ? 或 h：显示交互模式的帮助 P：按照 CPU 的使用率排序，默认就是此选项 M：按照内存的使用率排序 N：按照 PID 排序 T：按照 CPU 的累积运算时间排序，也就是按照 TIME+ 项排序 k：按照 PID 给予某个进程一个信号。一般用于中止某个进程，信号 9 是强制中止的信号 r：按照 PID 给某个进程重设优先级（Nice）值 \u0026lt;Space\u0026gt;：立即刷新 s：设置刷新时间间隔 c：显示命令完全模式 t:：显示或隐藏进程和CPU状态信息 m：显示或隐藏内存状态信息 l：显示或隐藏uptime信息 f：增加或减少进程显示标志 S：累计模式，会把已完成或退出的子进程占用的CPU时间累计到父进程的TIME+ u：指定显示用户进程 i：只显示正在运行的进程 W：保存对top的设置到文件 ~/.toprc，下次启动将自动调用toprc文件的设置。 q：退出  使用实例 # top top - 12:26:46 up 1 day, 13:32, 2 users, load average: 0.00, 0.00, 0.00 Tasks: 95 total, 1 running, 94 sleeping, 0 stopped, 0 zombie Cpu(s): 0.1%us, 0.1%sy, 0.0%ni, 99.7%id, 0.1%wa, 0.0%hi, 0.1%si, 0.0%st Mem: 625344k total, 571504k used, 53840k free, 65800k buffers Swap: 524280k total, 0k used, 524280k free, 409280k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 19002 root 20 0 2656 1068 856 R 0.3 0.2 0:01.87 top 1 root 20 0 2872 1416 1200 S 0.0 0.2 0:02.55 init 2 root 20 0 0 0 0 S 0.0 0.0 0:00.03 kthreadd 第一行为任务队列信息\n   内 容 说 明     12:26:46 系统当前时间   up 1 day, 13:32 系统的运行时间.本机己经运行 1 天 13 小时 32 分钟   2 users 当前登录了两个用户   load average: 0.00,0.00，0.00 系统在之前 1 分钟、5 分钟、15 分钟的平均负载。如果 CPU 是单核的，则这个数值超过 1 就是高负载：如果 CPU 是四核的，则这个数值超过 4 就是高负载 （这个平均负载完全是依据个人经验来进行判断的，一般认为不应该超过服务器 CPU 的核数）    第二行为进程信息\n   内 容 说 明     Tasks: 95 total 系统中的进程总数   1 running 正在运行的进程数   94 sleeping 睡眠的进程数   0 stopped 正在停止的进程数   0 zombie 僵尸进程数。如果不是 0，则需要手工检查僵尸进程    第三行为 CPU 信息\n   内 容 说 明     Cpu(s): 0.1 %us 用户模式占用的 CPU 百分比   0.1%sy 系统模式占用的 CPU 百分比   0.0%ni 改变过优先级的用户进程占用的 CPU 百分比   99.7%id 空闲 CPU 占用的 CPU 百分比   0.1%wa 等待输入/输出的进程占用的 CPU 百分比   0.0%hi 硬中断请求服务占用的 CPU 百分比   0.1%si 软中断请求服务占用的 CPU 百分比   0.0%st st（steal time）意为虚拟时间百分比，就是当有虚拟机时，虚拟 CPU 等待实际 CPU 的时间百分比    第四行为物理内存信息\n   内 容 说 明     Mem: 625344k total 物理内存的总量，单位为KB   571504k used 己经使用的物理内存数量   53840k free 空闲的物理内存数量。我们使用的是虚拟机，共分配了 628MB内存，所以只有53MB的空闲内存   65800k buffers/cache 作为缓冲的内存数量    缓冲（buffer）和缓存（cache）的区别：\n 缓存（cache）是在读取硬盘中的数据时，把最常用的数据保存在内存的缓存区中，再次读取该数据时，就不去硬盘中读取了，而在缓存中读取。 缓冲（buffer）是在向硬盘写入数据时，先把数据放入缓冲区,然后再一起向硬盘写入，把分散的写操作集中进行，减少磁盘碎片和硬盘的反复寻道，从而提高系统性能。  简单来说，缓存（cache）是用来加速数据从硬盘中\u0026quot;读取\u0026quot;的，而缓冲（buffer）是用来加速数据\u0026quot;写入\u0026quot;硬盘的。\n第五行为交换分区（swap）信息\n   内 容 说 明     Swap: 524280k total 交换分区（虚拟内存）的总大小   Ok used 已经使用的交换分区的大小   524280k free 空闲交换分区的大小   409280k cached 作为缓存的交换分区的大小    第六行为系统进程信息\n再来看 top 命令的第二部分输出，主要是系统进程信息，各个字段的含义如下：\n PID：进程的 ID。 USER：该进程所属的用户。 PR：优先级，数值越小优先级越高。 NI：优先级，数值越小、优先级越高。 VIRT：该进程使用的虚拟内存的大小，单位为 KB。 RES：该进程使用的物理内存的大小，单位为 KB。 SHR：共享内存大小，单位为 KB。 S：进程状态。 %CPU：该进程占用 CPU 的百分比。 %MEM：该进程占用内存的百分比。 TIME+：该进程共占用的 CPU 时间。 COMMAND：进程的命令名。  htop htop 是一个 Linux 下的交互式的进程浏览器，可以用来替换Linux下的top命令。\n与Linux传统的top相比，htop更加人性化。它可让用户交互式操作，支持颜色主题，可横向或纵向滚动浏览进程列表，并支持鼠标操作。\nbpytop Linux/OSX/FreeBSD resource monitor\nlsof 简介 lsof 命令，“list opened files”的缩写，直译过来，就是列举系统中已经被打开的文件。通过 lsof 命令，我们就可以根据文件找到对应的进程信息，也可以根据进程信息找到进程打开的文件。\n在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。\n在终端下输入lsof即可显示系统打开的文件，因为 lsof 需要访问核心内存和各种文件，所以必须以 root 用户的身份运行它才能够充分地发挥其功能。\n$ sudo lsof | less COMMAND PID TID TASKCMD USER FD TYPE DEVICE SIZE/OFF NODE NAME systemd 1 root cwd DIR 8,2 4096 2 / systemd 1 root rtd DIR 8,2 4096 2 / systemd 1 root txt REG 8,2 1620224 2491035 /usr/lib/systemd/systemd systemd 1 root mem REG 8,2 1369352 2498532 /usr/lib/x86_64-linux-gnu/libm-2.31.so systemd 1 root mem REG 8,2 178528 2490726 /usr/lib/x86_64-linux-gnu/libudev.so.1.6.17 输出各列信息的意义如下：\n  COMMAND：进程的名称\n  PID：进程标识符\n  PPID：父进程标识符（需要指定-R参数）\n  USER：进程所有者\n  PGID：进程所属组\n  FD：文件描述符（filedescriptor，简称 fd），应用程序通过文件描述符识别该文件类型。\n例如 cwd 表示current work dirctory，即应用程序的当前工作目录，这是该应用程序启动的目录，除非它本身对这个目录进行更改。txt 表示该类型的文件是程序代码，如应用程序二进制文件本身或共享库，如上列表中显示的 /usr/lib/systemd/systemd 程序。\n  TYPE：文件类型，如DIR、REG等，常见的文件类型:\n DIR：目录 REG：普通文件 CHR：字符 BLK：块设备类型 UNIX： UNIX 域套接字 FIFO：先进先出 (FIFO) 队列 IPv4：网际协议 (IP) 套接字    DEVICE：指定磁盘的名称\n  SIZE：文件的大小\n  NODE：索引节点（文件在磁盘上的标识）\n  NAME：打开文件的确切名称\n  命令参数    参数 含义     -a 列出打开文件存在的进程   -c \u0026lt;进程名\u0026gt; 列出指定进程名所打开的文件   -g 列出GID号进程详情   -d \u0026lt;文件号\u0026gt; 列出占用该文件号的进程   +d \u0026lt;目录\u0026gt; 列出目录下被打开的文件   +D \u0026lt;目录\u0026gt; 递归列出目录下被打开的文件   -n \u0026lt;目录\u0026gt; 列出使用NFS的文件   -i \u0026lt;条件\u0026gt; 列出符合条件的进程   -p \u0026lt;进程号\u0026gt; 列出指定进程号所打开的文件   -u 列出UID号进程详情   -h 显示帮助信息   -v 显示版本信息    使用实例 查询某个文件被哪个进程调用\n$ lsof /bin/bash 查询某个目录下所有的文件是被哪些进程调用的\n$ lsof +d /usr/lib 查看以httpd开头的进程调用了哪些文件\n$ lsof -c httpd 查询PID是1的进程调用的文件\n$ lsof -p 1 按照用户名查询某个用户的进程调用的文件\n$ lsof -u username 列出某个用户以及某个进程所打开的文件信息\n$ lsof -u test -c mysql 列出所有的网络连接\n$ lsof -i 列出所有tcp 网络连接信息\n$ lsof -i tcp 列出谁在使用某个端口\n$ lsof -i :3306 列出某个用户的所有活跃的网络端口\n$ lsof -a -u test -i 根据文件描述列出对应的文件信息\n$ lsof -d txt 列出被进程号为1234的进程所打开的所有 IPV4 network files\n$ lsof -i 4 -a -p 1234 列出目前连接主机nf5260i5-td上端口为：20，21，80相关的所有文件信息，且每隔3秒重复执行\n$ lsof -i @nf5260i5-td:20,21,80 -r 3 write 在服务器上，有时会有多个用户同时登录，一些必要的沟通就显得尤为重要。比如,我必须关闭某个服务，或者需要重启服务器，当然需要通知同时登录服务器的用户，这时就可以使用 write 命令。\nwrite 命令的信息如下：\n 命令名称：write。 英文原意：send a message to another user。 所在路径：/usr/bin/write。 执行权限：所有用户。 功能描述：向其他用户发送信息。  write 命令的基本格式如下:\n$ write 用户名 [终端号] write 命令没有多余的选项，我们要向在某个终端登录的用户发送信息，就可以这样来执行命令：\n# 向在pts/1 (远程终端1)登录的user1用户发送信息，使用\u0026#34;Ctrl+D\u0026#34;快捷键保存发送的数据 $ write user1 pts/1 hello I will be in 5 minutes to restart, please save your data 这时，user1 用户就可以收到你要在 5 分钟之后重启系统的信息了。\nxargs 标准输入与管道命令 Unix 命令都带有参数，有些命令可以接受\u0026quot;标准输入\u0026quot;（stdin）作为参数。\n$ cat /etc/passwd | grep root 上面的代码使用了管道命令（|）。管道命令的作用，是将左侧命令（cat /etc/passwd）的标准输出转换为标准输入，提供给右侧命令（grep root）作为参数。\n因为grep命令可以接受标准输入作为参数，所以上面的代码等同于下面的代码。\n$ grep root /etc/passwd 但是，大多数命令都不接受标准输入作为参数，只能直接在命令行输入参数，这导致无法用管道命令传递参数。举例来说，echo命令就不接受管道传参。\n$ echo \u0026#34;hello world\u0026#34; | echo 上面的代码不会有输出。因为管道右侧的echo不接受管道传来的标准输入作为参数。\nxargs 命令的作用 xargs命令的作用，是将标准输入转为命令行参数。\n$ echo \u0026#34;hello world\u0026#34; | xargs echo hello world 上面的代码将管道左侧的标准输入，转为命令行参数hello world，传给第二个echo命令。\nxargs命令的格式如下。\n$ xargs [-options] [command] 真正执行的命令，紧跟在xargs后面，接受xargs传来的参数。\nxargs的作用在于，大多数命令（比如rm、mkdir、ls）与管道一起使用时，都需要xargs将标准输入转为命令行参数。\n$ echo \u0026#34;one two three\u0026#34; | xargs mkdir 上面的代码等同于mkdir one two three。如果不加xargs就会报错，提示mkdir缺少操作参数。\nxargs 的单独使用 xargs后面的命令默认是echo。\n$ xargs # 等同于 $ xargs echo 大多数时候，xargs命令都是跟管道一起使用的。但是，它也可以单独使用。\n输入xargs按下回车以后，命令行就会等待用户输入，作为标准输入。你可以输入任意内容，然后按下Ctrl d，表示输入结束，这时echo命令就会把前面的输入打印出来。\n$ xargs hello (Ctrl + d) hello 再看一个例子。\n$ xargs find -name \u0026#34;*.txt\u0026#34; ./foo.txt ./hello.txt 上面的例子输入xargs find -name以后，命令行会等待用户输入所要搜索的文件。用户输入\u0026quot;*.txt\u0026quot;，表示搜索当前目录下的所有 TXT 文件，然后按下Ctrl d，表示输入结束。这时就相当执行find -name *.txt。\n-d 参数与分隔符 默认情况下，xargs将换行符和空格作为分隔符，把标准输入分解成一个个命令行参数。\n$ echo \u0026#34;one two three\u0026#34; | xargs mkdir 上面代码中，mkdir会新建三个子目录，因为xargs将one two three分解成三个命令行参数，执行mkdir one two three。\n-d参数可以更改分隔符。\n$ echo -e \u0026#34;a\\tb\\tc\u0026#34; | xargs -d \u0026#34;\\t\u0026#34; echo a b c 上面的命令指定制表符\\t作为分隔符，所以a\\tb\\tc就转换成了三个命令行参数。echo命令的-e参数表示解释转义字符。\n-p 参数，-t 参数 使用xargs命令以后，由于存在转换参数过程，有时需要确认一下到底执行的是什么命令。\n-p参数打印出要执行的命令，询问用户是否要执行。\n$ echo \u0026#39;one two three\u0026#39; | xargs -p touch touch one two three ?... 上面的命令执行以后，会打印出最终要执行的命令，让用户确认。用户输入y以后（大小写皆可），才会真正执行。\n-t参数则是打印出最终要执行的命令，然后直接执行，不需要用户确认。\n$ echo \u0026#39;one two three\u0026#39; | xargs -t rm rm one two three -0 参数与 find 命令 由于xargs默认将空格作为分隔符，所以不太适合处理文件名，因为文件名可能包含空格。\nfind命令有一个特别的参数-print0，指定输出的文件列表以null分隔。然后，xargs命令的-0参数表示用null当作分隔符。\n$ find /path -type f -print0 | xargs -0 rm 上面命令删除/path路径下的所有文件。由于分隔符是null，所以处理包含空格的文件名，也不会报错。\n还有一个原因，使得xargs特别适合find命令。有些命令（比如rm）一旦参数过多会报错\u0026quot;参数列表过长\u0026quot;，而无法执行，改用xargs就没有这个问题，因为它对每个参数执行一次命令。\n$ find . -name \u0026#34;*.txt\u0026#34; | xargs grep \u0026#34;abc\u0026#34; 上面命令找出所有 TXT 文件以后，对每个文件搜索一次是否包含字符串abc。\n-L 参数 如果标准输入包含多行，-L参数指定多少行作为一个命令行参数。\n$ xargs find -name \u0026#34;*.txt\u0026#34; \u0026#34;*.md\u0026#34; find: paths must precede expression: `*.md\u0026#39; 上面命令同时将\u0026quot;*.txt\u0026quot;和*.md两行作为命令行参数，传给find命令导致报错。\n使用-L参数，指定每行作为一个命令行参数，就不会报错。\n$ xargs -L 1 find -name \u0026#34;*.txt\u0026#34; ./foo.txt ./hello.txt \u0026#34;*.md\u0026#34; ./README.md 上面命令指定了每一行（-L 1）作为命令行参数，分别运行一次命令（find -name）。\n下面是另一个例子。\n$ echo -e \u0026#34;a\\nb\\nc\u0026#34; | xargs -L 1 echo a b c 上面代码指定每行运行一次echo命令，所以echo命令执行了三次，输出了三行。\n-n 参数 -L参数虽然解决了多行的问题，但是有时用户会在同一行输入多项。\n$ xargs find -name \u0026#34;*.txt\u0026#34; \u0026#34;*.md\u0026#34; find: paths must precede expression: `*.md\u0026#39; 上面的命令将同一行的两项作为命令行参数，导致报错。\n-n参数指定每次将多少项，作为命令行参数。\n$ xargs -n 1 find -name 上面命令指定将每一项（-n 1）标准输入作为命令行参数，分别执行一次命令（find -name）。\n下面是另一个例子。\n$ echo {0..9} | xargs -n 2 echo 0 12 34 56 78 9 上面命令指定，每两个参数运行一次echo命令。所以，10个阿拉伯数字运行了五次echo命令，输出了五行。\n-I 参数 如果xargs要将命令行参数传给多个命令，可以使用-I参数。\n-I指定每一项命令行参数的替代字符串。\n$ cat foo.txt one two three $ cat foo.txt | xargs -I file sh -c \u0026#39;echo file; mkdir file\u0026#39; one two three $ ls one two three 上面代码中，foo.txt是一个三行的文本文件。我们希望对每一项命令行参数，执行两个命令（echo和mkdir），使用-I file表示file是命令行参数的替代字符串。执行命令时，具体的参数会替代掉echo file; mkdir file里面的两个file。\n\u0026ndash;max-procs 参数 xargs默认只用一个进程执行命令。如果命令要执行多次，必须等上一次执行完，才能执行下一次。\n--max-procs参数指定同时用多少个进程并行执行命令。--max-procs 2表示同时最多使用两个进程，--max-procs 0表示不限制进程数。\n$ docker ps -q | xargs -n 1 --max-procs 0 docker kill 上面命令表示，同时关闭尽可能多的 Docker 容器，这样运行速度会快很多。\nawk awk是处理文本文件的一个应用程序，几乎所有 Linux 系统都自带这个程序。\n它依次处理文件的每一行，并读取里面的每一个字段。对于日志、CSV 那样的每行格式相同的文本文件，awk可能是最方便的工具。\nawk其实不仅仅是工具软件，还是一种编程语言。不过，本文只介绍它的命令行用法，对于大多数场合，应该足够用了。\n基本用法 awk的基本用法就是下面的形式。\n# 格式 $ awk 动作 文件名 # 示例 $ awk \u0026#39;{print $0}\u0026#39; demo.txt 上面示例中，demo.txt是awk所要处理的文本文件。前面单引号内部有一个大括号，里面就是每一行的处理动作print $0。其中，print是打印命令，$0代表当前行，因此上面命令的执行结果，就是把每一行原样打印出来。\n下面，我们先用标准输入（stdin）演示上面这个例子。\n$ echo \u0026#39;this is a test\u0026#39; | awk \u0026#39;{print $0}\u0026#39; this is a test 上面代码中，print $0就是把标准输入this is a test，重新打印了一遍。\nawk会根据空格和制表符，将每一行分成若干字段，依次用$1、$2、$3代表第一个字段、第二个字段、第三个字段等等。\n$ echo \u0026#39;this is a test\u0026#39; | awk \u0026#39;{print $3}\u0026#39; a 上面代码中，$3代表this is a test的第三个字段a。\n下面，为了便于举例，我们把/etc/passwd文件保存成demo.txt。\nroot❌0:0:root:/root:/usr/bin/zsh daemon❌1:1:daemon:/usr/sbin:/usr/sbin/nologin bin❌2:2:bin:/bin:/usr/sbin/nologin sys❌3:3:sys:/dev:/usr/sbin/nologin sync❌4:65534:sync:/bin:/bin/sync 这个文件的字段分隔符是冒号（:），所以要用-F参数指定分隔符为冒号。然后，才能提取到它的第一个字段。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{ print $1 }\u0026#39; demo.txt root daemon bin sys sync 变量 除了$ + 数字表示某个字段，awk还提供其他一些变量。\n变量NF表示当前行有多少个字段，因此$NF就代表最后一个字段。\n$ echo \u0026#39;this is a test\u0026#39; | awk \u0026#39;{print $NF}\u0026#39; test $(NF-1)代表倒数第二个字段。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{print $1, $(NF-1)}\u0026#39; demo.txt root /root daemon /usr/sbin bin /bin sys /dev sync /bin 上面代码中，print命令里面的逗号，表示输出的时候，两个部分之间使用空格分隔。\n变量NR表示当前处理的是第几行。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{print NR \u0026#34;) \u0026#34; $1}\u0026#39; demo.txt 1) root 2) daemon 3) bin 4) sys 5) sync 上面代码中，print命令里面，如果原样输出字符，要放在双引号里面。\nawk的其他内置变量如下。\n FILENAME：当前文件名 FS：字段分隔符，默认是空格和制表符。 RS：行分隔符，用于分割每一行，默认是换行符。 OFS：输出字段的分隔符，用于打印时分隔字段，默认为空格。 ORS：输出记录的分隔符，用于打印时分隔记录，默认为换行符。 OFMT：数字输出的格式，默认为％.6g。  函数 awk还提供了一些内置函数，方便对原始数据的处理。\n函数toupper()用于将字符转为大写。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{ print toupper($1) }\u0026#39; demo.txt ROOT DAEMON BIN SYS SYNC 上面代码中，第一个字段输出时都变成了大写。\n其他常用函数如下。\n tolower()：字符转为小写。 length()：返回字符串长度。 substr()：返回子字符串。 sin()：正弦。 cos()：余弦。 sqrt()：平方根。 rand()：随机数。  awk内置函数的完整列表，可以查看手册。\n条件 awk允许指定输出条件，只输出符合条件的行。\n输出条件要写在动作的前面。\n$ awk \u0026#39;条件 动作\u0026#39; 文件名 请看下面的例子。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;/usr/ {print $1}\u0026#39; demo.txt root daemon bin sys 上面代码中，print命令前面是一个正则表达式，只输出包含usr的行。\n下面的例子只输出奇数行，以及输出第三行以后的行。\n# 输出奇数行 $ awk -F \u0026#39;:\u0026#39; \u0026#39;NR % 2 == 1 {print $1}\u0026#39; demo.txt root bin sync # 输出第三行以后的行 $ awk -F \u0026#39;:\u0026#39; \u0026#39;NR \u0026gt;3 {print $1}\u0026#39; demo.txt sys sync 下面的例子输出第一个字段等于指定值的行。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;$1 == \u0026#34;root\u0026#34; {print $1}\u0026#39; demo.txt root $ awk -F \u0026#39;:\u0026#39; \u0026#39;$1 == \u0026#34;root\u0026#34; || $1 == \u0026#34;bin\u0026#34; {print $1}\u0026#39; demo.txt root bin if 语句 awk提供了if结构，用于编写复杂的条件。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{if ($1 \u0026gt; \u0026#34;m\u0026#34;) print $1}\u0026#39; demo.txt root sys sync 上面代码输出第一个字段的第一个字符大于m的行。\nif结构还可以指定else部分。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{if ($1 \u0026gt; \u0026#34;m\u0026#34;) print $1; else print \u0026#34;---\u0026#34;}\u0026#39; demo.txt root --- --- sys sync find find 命令由 POSIX 规范 定义，它创建了一个用于衡量 POSIX 系统的开放标准，这包括 Linux、BSD 和 macOS。简而言之，只要你运行的是 Linux、BSD 或 macOS，那么 find 已经安装了。\n但是，并非所有的 find 命令都完全相同。例如，GNU 的 find 命令有一些 BSD、Busybox 或 Solaris 上 find 命令可能没有或有但实现方式不同的功能。本文使用 findutils 包中的 GNU find，因为它很容易获得且非常流行。本文演示的大多数命令都适用于 find 的其他实现，但是如果你在 Linux 以外的平台上尝试命令并得到非预期结果，尝试下载并安装 GNU 版本。\nman文档中给出的find命令的一般形式为：\nfind [-H] [-L] [-P] [-D debugopts] [-Olevel] [path...] [expression] 其实[-H] [-L] [-P] [-D debugopts] [-Olevel]这几个选项并不常用（至少在我的日常工作中，没有用到过），上面的find命令的常用形式可以简化为：\nfind [path...] [expression]   path：find命令所查找的目录路径。例如用.来表示当前目录，用/来表示系统根目录\n  expression：expression可以分为——“-options [-print -exec -ok \u0026hellip;]”\n   -options，指定find命令的常用选项 -print，find命令将匹配的文件输出到标准输出 -exec，find命令对匹配的文件执行该参数所给出的shell命令。相应命令的形式为'command' { } \\;，注意{ }和\\；之间的空格 find ./ -size 0 -exec rm {} \\; 删除文件大小为零的文件 （还可以以这样做：rm -i find ./ -size 0 或 find ./ -size 0 | xargs rm -f \u0026amp;）  为了用ls -l命令列出所匹配到的文件，可以把ls -l命令放在find命令的-exec选项中：find . -type f -exec ls -l { } \\; 在/logs目录中查找更改时间在5日以前的文件并删除它们：find /logs -type f -mtime +5 -exec rm { } \\; -ok，和-exec的作用相同，只不过以一种更为安全的模式来执行该参数所给出的shell命令，在执行每一个命令之前，都会给出提示，让用户来确定是否执行。 find . -name \u0026quot;*.conf\u0026quot; -mtime +5 -ok rm { } \\; 在当前目录中查找所有文件名以.LOG结尾、更改时间在5日以上的文件，并删除它们，只不过在删除之前先给出提示    也有人这样总结find命令的结构：\nfind start_directory options criteria_to_match action_to_perform_on_results 常用选项  -name  按照文件名查找文件。 find /dir -name filename  在/dir目录及其子目录下面查找名字为filename的文件 find . -name \u0026quot;*.c\u0026quot; 在当前目录及其子目录（用“.”表示）中查找任何扩展名为“c”的文件 -perm 按照文件权限来查找文件。 find . -perm 755 –print 在当前目录下查找文件权限位为755的文件，即文件属主可以读、写、执行，其它用户可以读、执行的文件 -prune  使用这一选项可以使find命令不在当前指定的目录中查找，如果同时使用-depth选项，那么-prune将被find命令忽略。 find /apps -path \u0026quot;/apps/bin\u0026quot; -prune -o –print 在/apps目录下查找文件，但不希望在/apps/bin目录下查找 find /usr/sam -path \u0026quot;/usr/sam/dir1\u0026quot; -prune -o –print 在/usr/sam目录下查找不在dir1子目录之内的所有文件 -user  按照文件属主来查找文件。 find ~ -user sam –print 在$HOME目录中查找文件属主为sam的文件 -group  按照文件所属的组来查找文件。 find /apps -group gem –print 在/apps目录下查找属于gem用户组的文件 -mtime -n +n  按照文件的更改时间来查找文件， - n表示文件更改时间距现在n天以内，+ n表示文件更改时间距现在n天以前。 find / -mtime -5 –print 在系统根目录下查找更改时间在5日以内的文件 find /var/adm -mtime +3 –print 在/var/adm目录下查找更改时间在3日以前的文件 -nogroup  查找无有效所属组的文件，即该文件所属的组在/etc/groups中不存在。 find / –nogroup -print -nouser  查找无有效属主的文件，即该文件的属主在/etc/passwd中不存在。 find /home -nouser –print -newer file1 ! file2  查找更改时间比文件file1新但比文件file2旧的文件。 -type  查找某一类型的文件，诸如： b - 块设备文件。 d - 目录。 c - 字符设备文件。 p - 管道文件。 l - 符号链接文件。 f - 普通文件。 find /etc -type d –print 在/etc目录下查找所有的目录 find . ! -type d –print 在当前目录下查找除目录以外的所有类型的文件 find /etc -type l –print 在/etc目录下查找所有的符号链接文件 -size n：[c] 查找文件长度为n块的文件，带有c时表示文件长度以字节计。 find . -size +1000000c –print 在当前目录下查找文件长度大于1 M字节的文件 find /home/apache -size 100c –print 在/home/apache目录下查找文件长度恰好为100字节的文件 find . -size +10 –print 在当前目录下查找长度超过10块的文件（一块等于512字节） -depth：在查找文件时，首先查找当前目录中的文件，然后再在其子目录中查找。 find / -name \u0026quot;CON.FILE\u0026quot; -depth –print 它将首先匹配所有的文件然后再进入子目录中查找 -mount：在查找文件时不跨越文件系统mount点。 find . -name \u0026quot;*.XC\u0026quot; -mount –print 从当前目录开始查找位于本文件系统中文件名以XC结尾的文件（不进入其它文件系统） -follow：如果find命令遇到符号链接文件，就跟踪至链接所指向的文件。  按名称查找文件 你可以借助正则表达式使用完整或部分的文件名来定位文件。find 命令需要你给出想搜索的目录；指定搜索属性选项，例如，-name 用于指定区分大小写的文件名；然后是搜索字符串。默认情况下，搜索字符串按字面意思处理：除非你使用正则表达式语法，否则 find 命令搜索的文件名正是你在引号之间输入的字符串。\n假设你的 Documents 目录包含四个文件：Foo、foo、foobar.txt 和 foo.xml。以下是对 foo 的字面搜索：\n$ find ~ -name \u0026#34;foo\u0026#34; /home/tux/Documents/examples/foo 你可以使用 -iname 选项使其不区分大小写来扩大搜索范围：\n$ find ~ -iname \u0026#34;foo\u0026#34; /home/tux/Documents/examples/foo /home/tux/Documents/examples/Foo 通配符 你可以使用基本的 shell 通配符来扩展搜索。例如，* 表示任意数量的字符：\n$ find ~ -iname \u0026#34;foo*\u0026#34; /home/tux/Documents/examples/foo /home/tux/Documents/examples/Foo /home/tux/Documents/examples/foo.xml /home/tux/Documents/examples/foobar.txt ? 表示单个字符：\n$ find ~ -iname \u0026#34;foo*.???\u0026#34; /home/tux/Documents/examples/foo.xml /home/tux/Documents/examples/foobar.txt 这不是正则表达式语法，因此 . 在示例中只表示字母“点”。\n正则表达式 你还可以使用正则表达式。与 -iname 和 -name 一样，也有区分大小写和不区分大小写的选项。但不一样的是，-regex 和 -iregex 搜索应用于整个路径，而不仅仅是文件名。这意味着，如果你搜索 foo，你不会得到任何结果，因为 foo 与 /home/tux/Documents/foo 不匹配。相反，你必须要么搜索整个路径，要么在字符串的开头使用通配符：\n$ find ~ -iregex \u0026#34;.*foo\u0026#34; /home/tux/Documents/examples/foo /home/tux/Documents/examples/Foo 查找近一周修改过的文件 要查找近一周修改的文件，使用 -mtime 选项以及过去的天数（负数）：\n$ find ~ -mtime -7 /home/tux/Documents/examples/foo /home/tux/Documents/examples/Foo /home/tux/Documents/examples/foo.xml /home/tux/Documents/examples/foobar.txt 查找近几天修改的文件 你可以结合使用 -mtime 选项来查找近几天范围内修改的文件。对于第一个 -mtime 参数，表示上一次修改文件的最近天数。第二个参数表示最大天数。例如，搜索修改时间超过 1 天但不超过 7 天的文件：\n$ find ~ -mtime +1 -mtime -7 按文件类型限制搜索 指定查找文件的类型来优化 find 的结果是很常见的。如果你不确定要查找的内容，则不应该使用此选项。但如果你知道要查找的是文件而不是目录，或者是目录而不是文件，那么这可能是一个很好的过滤器。选项是 -type，它的参数是代表不同类型数据的字母代码。最常见的是：\n d - 目录 f - 文件 l - 链接文件 s - 套接字 p - 命名管道（用于 FIFO） b - 块设备（通常是硬盘）  下面是一些例子：\n$ find ~ -type d -name \u0026#34;Doc*\u0026#34; /home/tux/Documents $ find ~ -type f -name \u0026#34;Doc*\u0026#34; /home/tux/Downloads/10th-Doctor.gif $ find /dev -type b -name \u0026#34;sda*\u0026#34; /dev/sda/dev/sda1 调整范围 find 命令默认是递归的，这意味着它会在指定的目录中层层搜索结果。这在大型文件系统中可能会变得不堪重负，但你可以使用 -maxdepth 选项来控制搜索深度：\n$ find /usr -iname \u0026#34;*xml\u0026#34; | wc -l 15588 $ find /usr -maxdepth 2 -iname \u0026#34;*xml\u0026#34; | wc -l 15 也可以使用 -mindepth 设置最小递归深度：\n$ find /usr -mindepth 8 -iname \u0026#34;*xml\u0026#34; | wc -l 9255 与 xargs 在使用find命令的-exec选项处理匹配到的文件时， find命令将所有匹配到的文件一起传递给exec执行。但有些系统对能够传递给exec的命令长度有限制，这样在find命令运行几分钟之后，就会出现溢出错误。错误信息通常是“参数列太长”或“参数列溢出”。这就是xargs命令的用处所在，特别是与find命令一起使用。\nfind命令把匹配到的文件传递给xargs命令，而xargs命令每次只获取一部分文件而不是全部，不像-exec选项那样。这样它可以先处理最先获取的一部分文件，然后是下一批，并如此继续下去。\n在有些系统中，使用-exec选项会为处理每一个匹配到的文件而发起一个相应的进程，并非将匹配到的文件全部作为参数一次执行；这样在有些情况下就会出现进程过多，系统性能下降的问题，因而效率不高；\n而使用xargs命令则只有一个进程。另外，在使用xargs命令时，究竟是一次获取所有的参数，还是分批取得参数，以及每一次获取参数的数目都会根据该命令的选项及系统内核中相应的可调参数来确定。\n来看看xargs命令是如何同find命令一起使用的，并给出一些例子。\nfind . -type f -print | xargs file 查找系统中的每一个普通文件，然后使用xargs命令来测试它们分别属于哪类文件\nfind / -name \u0026quot;core\u0026quot; -print | xargs echo \u0026quot;\u0026quot; \u0026gt;/tmp/core.log 在整个系统中查找内存信息转储文件(core dump) ，然后把结果保存到/tmp/core.log 文件中：\nfind . -type f -print | xargs grep \u0026quot;hostname\u0026quot; 用grep命令在所有的普通文件中搜索hostname这个词\nfind ./ -mtime +3 -print|xargs rm -f –r 删除3天以前的所有东西 （find . -ctime +3 -exec rm -rf {} \\;）\nfind ./ -size 0 | xargs rm -f \u0026amp; 删除文件大小为零的文件\nfind命令配合使用exec和xargs可以使用户对所匹配到的文件执行几乎所有的命令。\nfd fd 命令是一个流行的、用户友好的 find 命令的替代品。\nFind files by file type find . -type f -exec bash -c \u0026#39; [[ \u0026#34;$( file -bi \u0026#34;$1\u0026#34; )\u0026#34; == */x-shellscript* ]]\u0026#39; bash {} \\; -print 基于正则表达式匹配文件路径 find . -regex \u0026#34;.*\\(\\.txt\\|\\.pdf\\)$\u0026#34; 同上，但忽略大小写\nfind . -iregex \u0026#34;.*\\(\\.txt\\|\\.pdf\\)$\u0026#34; grep grep (global search regular expression(RE) and print out the line，全面搜索正则表达式并把行打印出来)是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。\ngrep 这个名字，来源于一个 Unix/Linux 中的古老的行编辑器 ed 中执行相似操作的命令：\ng/re/p 语法如下所示:\ngrep [OPTIONS] PATTERN [FILE...] grep [OPTIONS] [-e PATTERN | -f FILE] [FILE...] grep命令用于搜索由Pattern参数指定的模式，并将每个匹配的行写入标准输出中。这些模式是具有限定的正则表达式，它们使用ed或egrep命令样式。\n如果在File参数中指定了多个名称，grep命令将显示包含匹配行的文件的名称。\n对 shell 有特殊含义的字符 ($, *, [, |, ^, (, ), \\ ) 出现在 Pattern参数中时必须带双引号。如果 Pattern参数不是简单字符串，通常必须用单引号将整个模式括起来。在诸如 [a-z], 之类的表达式中，-（减号）cml 可根据当前正在整理的序列来指定一个范围。整理序列可以定义等价的类以供在字符范围中使用。\n如果未指定任何文件，grep会假定为标准输入。\n基本集 grep正则表达式元字符集：\n ^ 锚定行的开始 如：'^grep'匹配所有以grep开头的行。 $ 锚定行的结束 如：'grep$'匹配所有以grep结尾的行。 . 匹配一个非换行符的字符 如：'gr.p'匹配gr后接一个任意字符，然后是p。 * 匹配零个或多个先前字符 如：' *grep'匹配所有一个或多个空格后紧跟grep的行。 .*一起用代表任意字符。 [] 匹配一个指定范围内的字符，如'[Gg]rep'匹配Grep和grep。 [^]  匹配一个不在指定范围内的字符，如：'[^A-FH-Z]rep'匹配不包含A-F和H-Z的一个字母开头，紧跟rep的行。 \\(..\\) 标记匹配字符，如：'\\(love\\)'，love被标记为1。 \\\u0026lt; 锚定单词的开始，如：'\\\u0026lt; \\\u0026gt; 锚定单词的结束，如grep\\\u0026gt;'匹配包含以grep结尾的单词的行。 x\\{m\\} 连续重复字符x，m次，如：'o\\{5\\}'匹配包含连续5个o的行。 x\\{m,\\} 连续重复字符x,至少m次，如：'o\\{5,\\}'匹配至少连续有5个o的行。 x\\{m,n\\} 连续重复字符x，至少m次，不多于n次，如：'o\\{5,10\\}'匹配连续5\u0026ndash;10个o的行。 \\w 匹配一个文字和数字字符，也就是[A-Za-z0-9]，如：'G\\w*p'匹配以G后跟零个或多个文字或数字字符，然后是p。 \\W  w的反置形式，匹配一个非单词字符，如点号句号等。\\W*则可匹配多个。 \\b 单词锁定符，如: '\\bgrep\\b'只匹配grep，即只能是grep这个单词，两边均为空格。  常用选项 -? 同时显示匹配行上下的？行，如：grep -2 pattern filename同时显示匹配行的上下2行。\n-b，--byte-offset 打印匹配行前面打印该行所在的块号码。\n-c,--count 只打印匹配的行数，不显示匹配的内容。\n-f File，--file=File 从文件中提取模板。空文件中包含0个模板，所以什么都不匹配。\n-h，--no-filename 当搜索多个文件时，不显示匹配文件名前缀。\n-i，--ignore-case 忽略大小写差别。\n-q，--quiet 取消显示，只返回退出状态。0则表示找到了匹配的行。\n-l，--files-with-matches 打印匹配模板的文件清单。\n-L，--files-without-match 打印不匹配模板的文件清单。\n-n，--line-number 在匹配的行前面打印行号。\n-s，--silent 不显示关于不存在或者无法读取文件的错误信息。\n-v，--revert-match 反检索，只显示不匹配的行。\n-w，--word-regexp 如果被\\引用，就把表达式做为一个单词搜索。\n-V，--version 显示软件版本信息。\n怎么样使用 grep 来搜索一个文件 搜索 /etc/passwd 文件下的 boo 用户,输入:\n$ grep boo /etc/passwd 输出内容:\nfoo❌1000:1000:foo,,,:/home/foo:/bin/ksh 可以使用 grep 去强制忽略大小写。例如，使用 -i 选项可以匹配 boo, Boo, BOO 和其他组合：\n$ grep -i \u0026quot;boo\u0026quot; /etc/passwd 递归使用 grep 你可以递归地使用 grep 进行搜索。例如，在文件目录下面搜索所有包含字符串“192.168.1.5”的文件\n$ grep -r \u0026quot;192.168.1.5\u0026quot; /etc/ 或者是：\n$ grep -R \u0026quot;192.168.1.5\u0026quot; /etc/ 示例输出:\n/etc/ppp/options:# ms-wins 192.168.1.50/etc/ppp/options:# ms-wins 192.168.1.51/etc/NetworkManager/system-connections/Wired connection 1:addresses1=192.168.1.5;24;192.168.1.2; 你会看到搜索到 192.168.1.5 的结果每一行都前缀以找到匹配的文件名（例如：/etc/ppp/options）。输出之中包含的文件名可以加 -h 选项来禁止输出：\n$ grep -h -R \u0026quot;192.168.1.5\u0026quot; /etc/ 或者\n$ grep -hR \u0026quot;192.168.1.5\u0026quot; /etc/ 示例输出:\n# ms-wins 192.168.1.50# ms-wins 192.168.1.51addresses1=192.168.1.5;24;192.168.1.2; 使用 grep 去搜索文本 当你搜索 boo 时，grep 命令将会匹配 fooboo，boo123, barfoo35 和其他所有包含 boo 的字符串，你可以使用 -w 选项去强制只输出那些仅仅包含那个整个单词的行（LCTT译注：即该字符串两侧是英文单词分隔符，如空格，标点符号，和末端等，因此对中文这种没有断字符号的语言并不适用。）。\n$ grep -w \u0026quot;boo\u0026quot; file 使用 grep 命令去搜索两个不同的单词 使用 egrep 命令如下:\n$ egrep -w 'word1|word2' /path/to/file （LCTT 译注：这里使用到了正则表达式，因此使用的是 egrep 命令，即扩展的 grep 命令。）\n统计文本匹配到的行数 grep 命令可以通过加 -c 参数显示每个文件中匹配到的次数：\n$ grep -c 'word' /path/to/file 传递 -n 选项可以输出的行前加入匹配到的行的行号：\n$ grep -n 'root' /etc/passwd 示例输出:\n1:root:x:0:0:root:/root:/bin/bash1042:rootdoor:x:0:0:rootdoor:/home/rootdoor:/bin/csh3319:initrootapp:x:0:0:initrootapp:/home/initroot:/bin/ksh 反转匹配（不匹配） 可以使用 -v 选项来输出不包含匹配项的内容，输出内容仅仅包含那些不含给定单词的行，例如输出所有不包含 bar 单词的行：\n$ grep -v bar /path/to/file UNIX/Linux 管道与 grep 命令 grep 常常与管道一起使用，在这个例子中，显示硬盘设备的名字：\n# dmesg | egrep '(s|h)d[a-z]' 显示 CPU 型号：\n# cat /proc/cpuinfo | grep -i 'Model' 然而，以上命令也可以按照以下方法使用，不使用管道:\n# grep -i 'Model' /proc/cpuinfo 示例输出:\nmodel : 30model name : Intel(R) Core(TM) i7 CPU Q 820 @ 1.73GHzmodel : 30model name : Intel(R) Core(TM) i7 CPU Q 820 @ 1.73GHz 仅仅显示匹配到内容的文件名 使用 -l 选项去显示那些文件内容中包含 main() 的文件名：\n$ grep -l 'main' *.c 最后，你可以强制 grep 以彩色输出：\n$ grep --color vivek /etc/passwd 查找文件内容 从根目录开始查找所有扩展名为 .log 的文本文件，并找出包含 \u0026ldquo;ERROR\u0026rdquo; 的行：\n$ find / -type f -name \u0026#34;*.log\u0026#34; | xargs grep \u0026#34;ERROR\u0026#34; 例子：\n#!/usr/bin/bash  IREGEX=\u0026#34;.*\\(\\.txt\\|\\.md\\|\\.yaml\\)$\u0026#34; find . \\  -type f \\  -regex $IREGEX \\ \t-print0 | xargs -0 grep -in \u0026#34;$1\u0026#34; 2\u0026gt;/dev/null only matching Print only the matched (non-empty) parts of a matching line, with each such part on a separate output line.\n$ grep -oh \u0026#34;\\w*th\\w*\u0026#34; * cat bat A cat(1) clone with wings.\n添加了语法高亮和 Git 集成等功能，并且还提供了分页选项。\nip linux的ip命令和ifconfig类似，但前者功能更强大，并旨在取代后者。使用ip命令，只需一个命令，你就能很轻松地执行一些网络管理任务。ifconfig是net-tools中已被废弃使用的一个命令，许多年前就已经没有维护了。iproute2套件里提供了许多增强功能的命令，ip命令即是其中之一。\n设置和删除Ip地址 要给你的机器设置一个IP地址，可以使用下列ip命令：\n$ sudo ip addr add 192.168.0.193/24 dev wlan0 请注意IP地址要有一个后缀，比如/24。这种用法用于在无类域内路由选择（CIDR）中来显示所用的子网掩码。在这个例子中，子网掩码是255.255.255.0。\n在你按照上述方式设置好IP地址后，需要查看是否已经生效。\n$ ip addr show wlan0 你也可以使用相同的方式来删除IP地址，只需用del代替add。\n$ sudo ip addr del 192.168.0.193/24 dev wlan0 列出路由表条目 ip命令的路由对象的参数还可以帮助你查看网络中的路由数据，并设置你的路由表。第一个条目是默认的路由条目，你可以随意改动它。\n在这个例子中，有几个路由条目。这个结果显示有几个设备通过不同的网络接口连接起来。它们包括WIFI、以太网和一个点对点连接。\n$ ip route show 假设现在你有一个IP地址，你需要知道路由包从哪里来。可以使用下面的路由选项（译注：列出了路由所使用的接口等）：\n$ ip route get 10.42.0.47 更改默认路由 要更改默认路由，使用下面ip命令：\n$ sudo ip route add default via 192.168.0.196 显示网络统计数据 使用ip命令还可以显示不同网络接口的统计数据。\n当你需要获取一个特定网络接口的信息时，在网络接口名字后面添加选项ls即可。使用多个选项**-s**会给你这个特定接口更详细的信息。特别是在排除网络连接故障时，这会非常有用。\n$ ip -s -s link ls p2p1 ARP条目 地址解析协议（ARP）用于将一个IP地址转换成它对应的物理地址，也就是通常所说的MAC地址。使用ip命令的neigh或者neighbour选项，你可以查看接入你所在的局域网的设备的MAC地址。\n$ ip neighbour 监控netlink消息 也可以使用ip命令查看netlink消息。monitor选项允许你查看网络设备的状态。比如，所在局域网的一台电脑根据它的状态可以被分类成REACHABLE或者STALE。使用下面的命令：\n$ ip monitor all 激活和停止网络接口 你可以使用ip命令的up和down选项来激某个特定的接口，就像ifconfig的用法一样。\n在这个例子中，当ppp0接口被激活和在它被停止和再次激活之后，你可以看到相应的路由表条目。这个接口可能是wlan0或者eth0。将ppp0更改为你可用的任意接口即可。\n$ sudo ip link set ppp0 down $ sudo ip link set ppp0 up 获取帮助 当你陷入困境，不知道某一个特定的选项怎么用的时候，你可以使用help选项。man页面并不会提供许多关于如何使用ip选项的信息，因此这里就是获取帮助的地方。\n比如，想知道关于route选项更多的信息：\n$ ip route help 小结 对于网络管理员们和所有的Linux使用者们，ip命令是必备工具。是时候抛弃ifconfig命令了，特别是当你写脚本时。\ndig 使用 dig 来进行 DNS 查询。\n参数类型：查询和格式化 有两种主要的参数可以传递给 dig：\n 告诉 dig 要进行什么 DNS 查询的参数。 告诉 dig 如何 格式化响应的参数。  首先，让我们看一下查询选项。\n主要的查询选项 你通常想控制 DNS 查询的 3 件事是：\n 名称（如 jvns.ca）。默认情况下，查询的是空名称（.）。 DNS 查询类型（如 A 或 CNAME）。默认是 A。 发送查询的 服务器（如 8.8.8.8）。默认是 /etc/resolv.conf 中的内容。  其格式是：\ndig @server name type 这里有几个例子：\n dig @8.8.8.8 jvns.ca 向谷歌的公共 DNS 服务器（8.8.8.8）查询 jvns.ca。 dig ns jvns.ca 对 jvns.ca 进行类型为 NS 的查询。  -x：进行反向 DNS 查询\n我偶尔使用的另一个查询选项是 -x，用于进行反向 DNS 查询。下面是输出结果的样子。\n$ dig -x 172.217.13.174 174.13.217.172.in-addr.arpa. 72888 IN PTR yul03s04-in-f14.1e100.net。 -x 不是魔术。dig -x 172.217.13.174 只是对 174.13.217.172.in-addr.arpa. 做了一个 PTR 查询。下面是如何在不使用 `-x’ 的情况下进行完全相同的反向 DNS 查询。\n$ dig ptr 174.13.217.172.in-addr.arpa. 174.13.217.172.in-addr.arpa. 72888 IN PTR yul03s04-in-f14.1e100.net。 我总是使用 -x，因为它可以减少输入。\nDNS反向查询大概的一个定义就是：\n从 IP 地址获取 PTR 记录。也就是说，通过使用一些网络工具可以将 IP 地址转换为主机名。 实际上，PRT 代表 POINTER，在 DNS 系统有唯一性，将 IP 地址与规范化的主机名联系起来。PTR 记录其实是 NDS 系统的一部分，但是由专门的区域文件组成的，使用的是传统的 in-addr.arpa 格式。\n格式化响应的选项 现在，让我们讨论一下你可以用来格式化响应的参数。\n我发现 dig 默认格式化 DNS 响应的方式对初学者来说是很难接受的。下面是输出结果的样子：\n; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.16.20 \u0026lt;\u0026lt;\u0026gt;\u0026gt; -r jvns.ca ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 28629 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096 ; COOKIE: d87fc3022c0604d60100000061ab74857110b908b274494d (good) ;; QUESTION SECTION: ;jvns.ca. IN A ;; ANSWER SECTION: jvns.ca. 276 IN A 172.64.80.1 ;; Query time: 9 msec ;; SERVER: 192.168.1.1#53(192.168.1.1) ;; WHEN: Sat Dec 04 09:00:37 EST 2021 ;; MSG SIZE rcvd: 80 如果你不习惯看这个，你可能需要花点时间来筛选，找到你要找的 IP 地址。而且大多数时候，你只对这个响应中的一行感兴趣（jvns.ca. 180 IN A 172.64.80.1）。\n下面是我最喜欢的两种方法，可以使 dig 的输出更容易管理：\n方式 1 : +noall +answer\n这告诉 dig 只打印 DNS 响应中的“答案”部分的内容。下面是一个查询 google.com 的 NS 记录的例子：\n$ dig +noall +answer ns google.com google.com. 158564 IN NS ns4.google.com. google.com. 158564 IN NS ns1.google.com. google.com. 158564 IN NS ns2.google.com. google.com. 158564 IN NS ns3.google.com. 这里的格式是：\nNAME TTL TYPE CONTENT google.com 158564 IN NS ns3.google.com. 顺便说一下：如果你曾经想知道 IN 是什么意思，它是指“查询类”，代表“互联网internet”。它基本上只是上世纪 80、90 年代的遗物，当时还有其他网络与互联网竞争，如“混沌网络chaosnet”。\n方式 2：+short\n这就像 dig +noall +answer，但更短：它只显示每条记录的内容。比如说：\n$ dig +short ns google.com ns2.google.com. ns1.google.com. ns4.google.com. ns3.google.com. digrc 如果你不喜欢 dig 的默认格式（我就不喜欢！），你可以在你的主目录下创建一个 .digrc 文件，告诉它默认使用不同的格式。\n我非常喜欢 +noall +answer 格式，所以我把 +noall +answer 放在我的 ~/.digrc 中。下面是我使用该配置文件运行 dig jvns.ca 时的情况。\n$ dig jvns.ca jvns.ca. 255在172.64.80.1中 这样读起来就容易多了！\n如果我想回到所有输出的长格式（我有时会这样做，通常是因为我想看响应的权威部分的记录），我可以通过运行再次得到一个长答案。\n$ dig +all jvns.ca dig +trace 我使用的最后一个 dig 选项是 +trace。dig +trace 模仿 DNS 解析器在查找域名时的做法 —— 它从根域名服务器开始，然后查询下一级域名服务器（如 .com），以此类推，直到到达该域名的权威域名服务器。因此，它将进行大约 30 次 DNS 查询。（我用 tcpdump 检查了一下，对于每个根域名服务器的 A / AAAA 记录它似乎要进行 2 次查询，所以这已经是 26 次查询了。我不太清楚它为什么这样做，因为它应该已经有了这些 IP 的硬编码，但它确实如此。）\n我发现这对了解 DNS 的工作原理很有用，但我不认为我用它解决过问题。\n为什么要用 dig 尽管有一些更简单的工具来进行 DNS 查询（如 dog 和 host），我发现自己还是坚持使用 dig。\n我喜欢 dig 的地方实际上也是我 不喜欢 dig 的地方 —— 它显示了大量的细节！\n我知道，如果我运行 dig +all，它将显示 DNS 响应的所有部分。例如，让我们查询 jvns.ca 的一个根名称服务器。响应有 3 个部分，我可能会关心：回答部分、权威部分和附加部分。\n$ dig @h.root-servers.net. jvns.ca +all ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 18229 ;; flags: qr rd; QUERY: 1, ANSWER: 0, AUTHORITY: 4, ADDITIONAL: 9 ;; WARNING: recursion requested but not available ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 1232 ;; QUESTION SECTION: ;jvns.ca. IN A ;; AUTHORITY SECTION: ca. 172800 IN NS c.ca-servers.ca. ca. 172800 IN NS j.ca-servers.ca. ca. 172800 IN NS x.ca-servers.ca. ca. 172800 IN NS any.ca-servers.ca. ;; ADDITIONAL SECTION: c.ca-servers.ca. 172800 IN A 185.159.196.2 j.ca-servers.ca. 172800 IN A 198.182.167.1 x.ca-servers.ca. 172800 IN A 199.253.250.68 any.ca-servers.ca. 172800 IN A 199.4.144.2 c.ca-servers.ca. 172800 IN AAAA 2620:10a:8053::2 j.ca-servers.ca. 172800 IN AAAA 2001:500:83::1 x.ca-servers.ca. 172800 IN AAAA 2620:10a:80ba::68 any.ca-servers.ca. 172800 IN AAAA 2001:500:a7::2 ;; Query time: 103 msec ;; SERVER: 198.97.190.53#53(198.97.190.53) ;; WHEN: Sat Dec 04 11:23:32 EST 2021 ;; MSG SIZE rcvd: 289 dog 也显示了 “附加” 部分的记录，但它没有明确指出哪个是哪个（我猜 + 意味着它在附加部分？） ，但它似乎没有显示“权威”部分的记录。\n$ dog @h.root-servers.net. jvns.ca NS ca. 2d0h00m00s A \u0026#34;c.ca-servers.ca.\u0026#34; NS ca. 2d0h00m00s A \u0026#34;j.ca-servers.ca.\u0026#34; NS ca. 2d0h00m00s A \u0026#34;x.ca-servers.ca.\u0026#34; NS ca. 2d0h00m00s A \u0026#34;any.ca-servers.ca.\u0026#34; A c.ca-servers.ca. 2d0h00m00s + 185.159.196.2 A j.ca-servers.ca. 2d0h00m00s + 198.182.167.1 A x.ca-servers.ca. 2d0h00m00s + 199.253.250.68 A any.ca-servers.ca. 2d0h00m00s + 199.4.144.2 AAAA c.ca-servers.ca. 2d0h00m00s + 2620:10a:8053::2 AAAA j.ca-servers.ca. 2d0h00m00s + 2001:500:83::1 AAAA x.ca-servers.ca. 2d0h00m00s + 2620:10a:80ba::68 AAAA any.ca-servers.ca. 2d0h00m00s + 2001:500:a7::2 而 host 似乎只显示“答案”部分的记录（在这种情况下没有得到记录）：\n$ host jvns.ca h.root-servers.net Using domain server: Name: h.root-servers.net Address: 198.97.190.53#53 Aliases: 总之，我认为这些更简单的 DNS 工具很好（我甚至自己做了一个 简单的网络 DNS 工具），如果你觉得它们更容易，你绝对应该使用它们，但这就是为什么我坚持使用 dig 的原因。drill 的输出格式似乎与 dig 的非常相似，也许 drill 更好！但我还没有真正试过它。\nSamba Samba 是 SMB/CIFS 网络协议的重新实现, 可以在 Linux 和 Windows 系统间进行文件、打印机共享，和 NFS 的功能类似。\n安装 $ sudo apt install samba $ sudo systemctl enable --now smbd.service Samba 服务的配置文件是 /etc/samba/smb.conf，smb.conf(5)提供了详细的文档。\n如果使用了 防火墙，请记得打开需要的端口(通常是 137-139 + 445)。完整列表请查看 Samba 端口使用。\n$ sudo ufw allow Samba $ sudo ufw reload 创建共享 创建的目录即之后能够在Windows主机上直接访问的目录。例如：在用户samba_user的主目录下新建share文件夹为共享目录，由于Windows下的文件夹需可读可写可执行，需更改权限为777\n$ mkdir /home/samba_user/smbshare $ sudo chmod 777 /home/samba_user/smbshare 修改 /etc/samba/smb.conf，在smb.conf文件最后加上以下内容\n$ sudo vim /etc/samba/smb.conf [share] path = /home/samba_user/smbshare public = yes writable = yes valid users = samba_user create mask = 0644 force create mode = 0644 directory mask = 0755 force directory mode = 0755 available = yes  [share]表示共享文件夹的别名，之后将直接使用这个别名 force create mode 与 force directory mode的设置是因为Windows下与Linux下文件和文件夹的默认权限不同造成的，Windows下新建的文件是可执行的，必须强制设定其文件权限。 valid users 设置为你当前的Linux用户名，例如我的是samba_user，因为第一次打开共享文件夹时，需要验证权限。  用户管理 Samba 需要 Linux 账户才能使用 - 可以使用已有账户或创建新用户。\n虽然用户名可以和 Linux 系统共享，Samba 使用单独的密码管理，将下面的 samba_user 替换为上面设置的 valid users:\n$ sudo smbpasswd -a samba_user 根据服务器角色的差异，可能需要修改已有的文件权限和属性。\nWhich is faster-Samba or scp? Depends on the machines. Machines with really fast CPU may do SCP or SFTP faster.\nOtherwise, Samba will probably be faster because it doesn\u0026rsquo;t have to encrypt.\nConnect to servers with nautilus Step 1: find the “Other Locations” button on the left-hand side of the Gnome file manager and click on the mouse.\nStep 2: make your way to the “Connect to Server” text box and tap on it with the mouse.\nStep 3: write out smb:// followed by the IP address of the Samba file server. Alternatively, write out the hostname of the file server, as that works as well. Confused? Copy the examples below.\n# ip address smb://ip.address.of.samba.file.server # hostname smb://MyExampleSambaShare ftp://ip.address.of.ftp.server nfs://ip.address.of.nfs.server Step 4: click on the “Connect” button to send out a new Samba connection. Assuming your file server has no user-name setup and is public, you’ll instantly see the files and be able to interact with the server.\nHowever, if your server requires a username/password, you must fill out the username/password before using Samba.\nMount Samba Share in Linux List available shares on server:\nInstall the samba client library:\n$ sudo apt install smbclient Then list the shares:\n$ smbclient -L //\u0026lt;your-ip-address\u0026gt; You will then be prompted to enter a password (assuming your share requires one) and then will output something like this:\nSharename Type Comment --------- ---- ------- folder-mount-1 Disk Description 1 folder-mount-2 Disk Description 2 folder-mount-3 Disk Description 3 IPC$ IPC IPC Service (Server Name) Note the share name that you want to mount for later.\n Temp mount the share to a folder:\nInstall the cifs-utils package:\n$ sudo apt install cifs-utils Create the mount-point (folder) and then mount the share:\n$ sudo mkdir /mnt/myFolder $ sudo mount -t cifs -o username=serverUserName //myServerIpAdress/sharename /mnt/myFolder/ (Note: this will unmount upon reboot.)\n Permanently mount the share to a folder:\nInstall the cifs-utils package:\n$ sudo apt install cifs-utils Create the mount-point (folder):\n$ sudo mkdir /mnt/myFolder Modify your fstab file:\n$ sudo vi /etc/fstab Place the following line at or near the bottom of the file:\n$ //\u0026lt;your-ip-address\u0026gt;/\u0026lt;mount-name\u0026gt; /mnt/myFolder/ cifs username=YOURUSERNAME,password=YOURPASSWORD,iocharset=utf8,file_mode=0777,dir_mode=0777 (be sure to swap in your info into the line above)\nReboot your server and you should be off to the races. To confirm that it is still mounted, type df -h and look found your mount in the list.\nsudo 简单的说，sudo 是一种权限管理机制，管理员可以授权于一些普通用户去执行一些 root 执行的操作，而不需要知道 root 的密码。\n严谨些说，sudo 允许一个已授权用户以超级用户或者其它用户的角色运行一个命令。当然，能做什么不能做什么都是通过安全策略来指定的。sudo 支持插件架构的安全策略，并能把输入输出写入日志。第三方可以开发并发布自己的安全策略和输入输出日志插件，并让它们无缝的和 sudo 一起工作。默认的安全策略记录在 /etc/sudoers 文件中。而安全策略可能需要用户通过密码来验证他们自己。也就是在用户执行 sudo 命令时要求用户输入自己账号的密码。如果验证失败，sudo 命令将会退出。\n命令语法 $ sudo [-bhHpV][-s ][-u \u0026lt;用户\u0026gt;][指令] $ sudo [-klv] 参数：\n -b 在后台执行指令。 -h 显示帮助。 -H 将HOME环境变量设为新身份的HOME环境变量。 -k 结束密码的有效期限，也就是下次再执行sudo时便需要输入密码。 -l 列出目前用户可执行与无法执行的指令。 -p 改变询问密码的提示符号。 -s 执行指定的shell。 -u \u0026lt;用户\u0026gt; 以指定的用户作为新的身份。若不加上此参数，则预设以root作为新的身份。 -v 延长密码有效期限5分钟。 -V 显示版本信息。 -S 从标准输入流替代终端来获取密码  基本配置 系统默认创建了一个名为 sudo 的组。只要把用户加入这个组，用户就具有了 sudo 的权限。\n至于如何把用户加入 sudo 组，您可以直接编辑 /etc/group 文件，当然您得使用一个有 sudo 权限的用户来干这件，在 sudo 组中加入新的用户，要使用逗号分隔多个用户。\n或者您可以使用 usermod 命令把用户添加到一个组中：\n$ sudo usermod -a -G sudo jack 上面的设置中我们把用户 jack 添加到了 sudo 组中，所以当用户 jack 登录后就可以通过 sudo 命令以 root 权限执行命令了！\n详细配置 在前面的配置中我们只是把用户 jack 加入了 sudo 组，他就具有了通过 root 权限执行命令的能力。\n现在我们想问一下，这是怎么发生的？是时候介绍如何配置 sudo 命令了！\nsudo 命令的配置文件为 /etc/sudoers。\n编辑这个文件是有单独的命令的 visudo，这个文件我们最好不要使用 vim 命令来打开，是因为一旦你的语法写错会造成严重的后果，这个工具会替你检查你写的语法，这个文件的语法遵循以下格式：\nwho where whom command 说白了就是哪个用户在哪个主机以谁的身份执行那些命令，那么这个 where, 是指允许在那台主机 ssh 连接进来才能执行后面的命令，文件里面默认给 root 用户定义了一条规则：\nroot ALL=(ALL:ALL) ALL  root 表示 root 用户。 ALL 表示从任何的主机上都可以执行，也可以这样 192.168.100.0/24。 (ALL:ALL) 是以谁的身份来执行，ALL:ALL 就代表 root 可以任何人的身份来执行命令。 ALL 表示任何命令。  那么整条规则就是 root 用户可以在任何主机以任何人的身份来执行所有的命令。\n现在我们可以回答 jack 为什么具有通过 root 权限执行命令的能力了。打开 /etc/sudoers 文件：\n%sudo ALL=(ALL:ALL) ALL sudo 组中的所有用户都具有通过 root 权限执行命令的能力！\n再看个例子：\nnick 192.168.10.0/24=(root) /usr/sbin/useradd 上面的配置只允许 nick 在 192.168.10.0/24 网段上连接主机并且以 root 权限执行 useradd 命令。\n设置 sudo 时不需要输入密码\n只需要在配置行中添加 NOPASSWD: 就可以了：\n%sudo ALL=(ALL:ALL) NOPASSWD:ALL 日志 在 ubuntu 中，sudo 的日志默认被记录在 /var/log/auth.log 文件中。当我们执行 sudo 命令时，相关日志都是会被记录下来的。\n与输出重定向 如果当前用户没有某个文件的写权限，又要通过输出重定向往该文件中写入内容。结果只能是 \u0026ldquo;Permission denied\u0026rdquo;。\n比如当前用户为 nick，下面的命令试图查询 /root 目录下的文件并把结果写入到 /root/test.txt 文件中，注意用户 nick 没有对 /root/test.txt 文件的写权限：\n$ sudo ls -al /root/test.txt -rw-r--r-- 1 root root 0 Jan 10 05:19 /root/test.txt $ sudo ls -al /root \u0026gt; /root/test.txt -bash: /root/test.txt: Premission denied 不工作的原因是：虽然 ls 命令是以 sudo 方式执行的，但是输出重定向操作是由当前 shell 执行的，它(当前 shell)没有 /root/test.txt 文件的权限，所以最终失败。\n搞清楚了原因，就可以通过不同的方式来解决这个问题了，下面介绍四种方式。\n以 sudo 方式运行 shell\n既然是 shell 进程没有权限，那就用 sudo 的方式执行 shell：\n$ sudo bash -c \u0026#39;ls -al /root \u0026gt; /root/test.txt\u0026#39; 把命令写入脚本，以 sudo 方式执行脚本\n把下面的代码保存到脚本文件 test.sh 中：\n#!/bin/bash ls -al /root \u0026gt; /root/test.txt 然后通过下面的方式执行：\n$ chmod +x test.sh $ sudo ./test.sh 如果觉着创建脚本麻烦的话还可以使用变通的方式：\n$ sudo bash \u0026lt;\u0026lt;EOF \u0026gt; ls -al /root \u0026gt; /root/test.txt \u0026gt; EOF 或者是下面的写法：\n$ echo \u0026#39;ls -al /root \u0026gt; /root/test.txt\u0026#39; | sudo bash 先通过 sudo -s 启动 shell，然后执行命令\n先通过 sudo -s 命令切换到 root 用户再执行命令，最后 ctrl + d 退出。\n通过 sudo tee 命令实现\nTee 命令用于将数据重定向到文件，另一方面还可以提供一份重定向数据的副本作为后续命令的 stdin。简单的说就是把数据重定向到给定文件和屏幕上：\n面的命令中通过 sudo tee 把 ls 命令的输出写入文件：\n$ sudo ls -al /root | sudo tee /root/test.txt \u0026gt; /dev/null 其中的 \u0026gt; /dev/null 阻止 tee 把内容输出到终端。\nfdisk Linux 系统中所有的硬件设备都是通过文件的方式来表现和使用的，我们将这些文件称为设备文件，硬盘对应的设备文件一般被称为块设备文件。\n磁盘分类 比较常见的磁盘类型有消费类市场中的 SATA 硬盘和服务器中使用的 SCSI 硬盘、SAS 硬盘，当然还有当下大热的各种固态硬盘。\nSATA 硬盘\nSATA(Serial ATA)口的硬盘又叫串口硬盘，Serial ATA 采用串行连接方式，串行 ATA 总线使用嵌入式时钟信号，具备了更强的纠错能力，与以往相比其最大的区别在于能对传输指令(不仅仅是数据)进行检查，如果发现错误会自动矫正，这在很大程度上提高了数据传输的可靠性。串行接口还具有结构简单、支持热插拔的优点。SATA 硬盘主要用于消费类市场和一些低端服务器：\nSCSI 硬盘\nSCSI 硬盘即采用 SCSI 接口的硬盘。它由于性能好、稳定性高，因此在服务器上得到广泛应用。同时其价格也不菲，正因它的价格昂贵，所以在普通PC上很少见到它的踪迹。SCSI 硬盘使用 50 针接口，外观和普通硬盘接口有些相似(下图来自互联网)：\nSAS 硬盘\nSAS 是 Serial Attached SCSI 的缩写，即串行连接的 SCSI，其目标是定义一个新的串行点对点的企业级存储设备接口。串行接口减少了线缆的尺寸，允许更快的传输速度。SAS 硬盘与相同转速的 SCSI 硬盘相比有相同或者更好的性能。SAS 硬盘一般用于比较高端的服务器。\n固态硬盘\n固态硬盘(Solid State Disk)，一般称之为 SSD 硬盘，固态硬盘是用固态电子存储芯片阵列而制成的硬盘，由控制单元和存储单元(FLASH芯片、DRAM芯片)组成。其主要特点是没有传统硬盘的机械结构，读写速度非常快(下图来自互联网)：\n表示方法 在 Linux 系统中磁盘设备文件的命名规则为：\n主设备号 + 次设备号 + 磁盘分区号 对于目前常见的磁盘，一般表示为：\nsd[a-z]x  主设备号代表设备的类型，相同的主设备号表示同类型的设备。当前常见磁盘的主设备号为 sd。 次设备号代表同类设备中的序号，用 \u0026ldquo;a-z\u0026rdquo; 表示。比如 /dev/sda 表示第一块磁盘，/dev/sdb 表示第二块磁盘。 x 表示磁盘分区编号。在每块磁盘上可能会划分多个分区，针对每个分区，Linux 用 /dev/sdbx 表示，这里的 x 表示第二块磁盘的第 x 个分区。  磁盘分区 创建磁盘分区大概有下面几个目的：\n 提升数据的安全性(一个分区的数据损坏不会影响其他分区的数据) 支持安装多个操作系统 多个小分区对比一个大分区会有性能提升 更好的组织数据  本文以常见的 MBR 分区为例介绍磁盘分区中的一些常见概念。MBR 磁盘的分区由主分区、扩展分区和逻辑分区组成。在一块磁盘上，主分区的最大个数是 4，其中扩展分区也是一个主分区，并且最多只能有一个扩展分区，但可以在扩展分区上创建多个逻辑分区。因此主分区(包括扩展分区)的范围是 1-4，逻辑分区从 5 开始。对于逻辑分区，Linux 规定它们必须建立在扩展分区上，而不是建立在主分区上。\n主分区的作用是用来启动操作系统的，主要存放操作系统的启动或引导程序。\n扩展分区只不过是逻辑分区的 \u0026ldquo;容器\u0026rdquo;。实际上只有主分区和逻辑分区是用来进行数据存储的，因而可以将数据集中存放在磁盘的逻辑分区中。\n我们可以通过 fdisk 命令来查看磁盘分区的信息：\n$ sudo fdisk -l /dev/sda 分区信息：\n Device 显示了磁盘分区对应的设备文件名。 Boot 显示是否为引导分区，是引导分区就有一个 \u0026lsquo;*\u0026rsquo; 号。 Start 表示磁盘分区的起始位置。 End 表示磁盘分区的结束位置。 Sectors 表示分区占用的扇区数目。 Size 显示分区的大小。 Id/Type 显示的内容相同，分别是数值 ID 及其文字描述。 Id 列显示了磁盘分区对应的 ID，根据分区的不同，分区对应的 ID 号也不相同。Linux 下用 83 表示主分区和逻辑分区，5 表示扩展分区，8e 表示 LVM 分区，82 表示交换分区，7 表示 NTFS 分区。  划分磁盘分区 fdisk 是 Linux 系统中一款功能强大的磁盘分区管理工具，可以观察硬盘的使用情况，也可以用来管理磁盘分区。\n假设我们的 Linux 系统中增加了一块新的磁盘，系统对应的设备名为 /dev/sdd，下面我们通过 fdisk 命令对这个磁盘进行分区：\n$ (echo n; echo p; echo 1; echo ; echo ; echo w) | sudo fdisk /dev/sdd  命令 n 来创建新分区 p 来创建主分区 主分区的编号为 1- 4，这里我们输入了 1。 分区的大小是通过设置分区开始处的扇区和结束处的扇区设置的。这里如果回车两次会把整个磁盘划分为一个分区，也就是整个磁盘的容器都分给了一个分区。 注意此时的分区信息还没有写入到磁盘中，在这里还可以反悔，如果确认执行上面的分区，执行 w 命令就行了。  这时分区操作已经完成了，我们可以通过下面的命令查看分区的结果：\n$ sudo fdisk -l /dev/sdd 分区是使用磁盘的基础，在分区完成后还需要对分区进行格式化，并把格式化后的文件系统挂载到 Linux 系统之后才能存储文件。\n更改分区的类型\n创建的分区类型默认为 83(Linux)，如果想要一个 8e(Linux LVM)类型的分区，在 fdisk 输入 t 命令来修改分区的类型。\nfuser 当使用umount命令卸载挂载点时，会遇到“device is busy”提示，这时fuser就能查出谁在使用这个资源。\n描述 fuser可以显示出当前哪个程序在使用磁盘上的某个文件、挂载点、甚至网络端口，并给出程序进程的详细信息。\n每个进程 ID 后面跟有一个字母代码。字母代码的解释如下所述。\n c：表示此进程正在使用该文件作为其当前目录。 e：将此文件作为程序的可执行对象使用 f：打开的文件。默认不显示。 F：打开的文件，用于写操作。默认不显示。 r：表示此进程正在将该文件用作其根目录。 m：指示进程使用该文件进行内存映射，抑或该文件为共享库文件，被进程映射进内存。 s：将此文件作为共享库（或其他可装载对象）使用  对于具有已挂载文件系统的块特殊设备，将列出使用该设备上的任何文件的所有进程。对于所有类型的文件（文本文件、可执行文件、目录、设备，等等），只会报告使用该文件的进程。\n对于所有类型的设备，fuser 还会显示打开设备的任何已知内核使用者。内核使用者显示为下列格式之一：\n[module_name] [module_name,dev_path=path] [module_name,dev=(major,minor)] [module_name,dev=(major,minor),dev_path=path] 如果指定了多组文件，可能需要为其他每个文件组重新指定选项。单个短划线可取消当前施行的选项。\n各个进程 ID 输出到标准输出中的单个行上，并以空格分隔。所有其他输出（包括单个终止换行符）均被写入到标准错误。\n任何用户都可以运行 fuser，但只有超级用户可以终止其他用户的进程。\n选项 支持以下选项：\n -a：显示所有命令行中指定的文件，默认情况下被访问的文件才会被显示。 -c：和-m一样，用于POSIX兼容。 -k：杀掉访问文件的进程。如果没有指定-signal就会发送SIGKILL信号。 -i：杀掉进程之前询问用户，如果没有-k这个选项会被忽略。 -l：列出所有已知的信号名称。 -m：name 指定一个挂载文件系统上的文件或者被挂载的块设备（名称name）。这样所有访问这个文件或者文件系统的进程都会被列出来。如果指定的是一个目录会自动转换成\u0026quot;name/\u0026quot;,并使用所有挂载在那个目录下面的文件系统。 -n：space 指定一个不同的命名空间(space).这里支持不同的空间文件(文件名，此处默认)、tcp(本地tcp端口)、udp(本地udp端口)。对于端口， 可以指定端口号或者名称，如果不会引起歧义那么可以使用简单表示的形式，例如：name/space (即形如:80/tcp之类的表示)。 -s：静默模式，这时候-u,-v会被忽略。-a不能和-s一起使用。 -signal：使用指定的信号，而不是用SIGKILL来杀掉进程。可以通过名称或者号码来表示信号(例如-HUP,-1),这个选项要和-k一起使用，否则会被忽略。 -u：在每个PID后面添加进程拥有者的用户名称。 -v：详细模式。输出似ps命令的输出，包含PID,USER,COMMAND等许多域,如果是内核访问的那么PID为kernel. -V 输出版本号。 -4：使用IPV4套接字,不能和-6一起应用，只在-n的tcp和udp的命名存在时不被忽略。 -6：使用IPV6套接字,不能和-4一起应用，只在-n的tcp和udp的命名存在时不被忽略。 -：重置所有的选项，把信号设置为SIGKILL.  示例 示例 1 显示使用某个文件的进程信息\n这个命令在umount的时候很有用，可以找到还有哪些用到这个设备了。\n$ fuser -um /dev/sda2 /dev/sda2: 6378c(quietheart) 6534c(quietheart) 6628(quietheart) 6653c(quietheart) 7429c(quietheart) 7549c(quietheart) 7608c(quietheart) 示例 2 杀掉打开readme文件的程序\n这里，会在kill之前询问是否确定。最好加上-v以便知道将要杀那个进程。\n$ fuser -m -k -i readme 示例 3 查看那些程序使用tcp的80端口\n$ fuser -v -n tcp 80 # or $ fuser -v 80/tcp tcpdump tcpdump 是一款 Linux 平台的抓包工具。它可以抓取涵盖整个 TCP/IP 协议族的数据包，支持针对网络层、协议、主机、端口的过滤，并提供 and、or、not 等逻辑语句来过滤无用的信息。\ntcpdump 是一个非常复杂的工具，掌握它的方方面面实属不易，也不推荐，能够用它来解决日常工作问题才是关系。\n命令选项 tcpdump 有很多命令选项，想了解所有选项可以 Linux 命令行输入 tcpdump -h，man tcpdump 查看每个选项的意思。\n下面列举一些常用选项：\n -A 只使用 ASCII 打印报文的全部数据，不要和 -X 一起使用，获取 http 可以用 tcpdump -nSA port 80 -b 在数据链路层上选择协议，包括 ip, arp, rarp, ipx 等 -c 指定要抓取包的数量 -D 列出操作系统所有可以用于抓包的接口 -e 输出链路层报头 -i 指定监听的网卡，-i any 显示所有网卡 -n 表示不解析主机名，直接用 IP 显示，默认是用 hostname 显示 -nn 表示不解析主机名和端口，直接用端口号显示，默认显示是端口号对应的服务名 -p 关闭接口的混杂模式 -P 指定抓取的包是流入的包还是流出的，可以指定参数 in, out, inout 等，默认是 inout -q 快速打印输出，即只输出少量的协议相关信息 -s len 设置要抓取数据包长度为 len，默认只会截取前 96bytes 的内容，-s 0 的话，会截取全部内容。 -S 将 TCP 的序列号以绝对值形式输出，而不是相对值 -t 不要打印时间戳 -vv 输出详细信息（比如 tos、ttl、checksum等） -X 同时用 hex 和 ascii 显示报文内容 -XX 同 -X，但同时显示以太网头部  过滤器 网络报文是很多的，很多时候我们在主机上抓包，会抓到很多我们并不关心的无用包，然后要从这些包里面去找我们需要的信息，无疑是一件费时费力的事情，tcpdump 提供了灵活的语法可以精确获取我们关心的数据，这些语法说得专业点就是过滤器。\n过滤器简单可分为三类：协议（proto）、传输方向（dir）和类型（type）。\n一般的 表达式格式 为：\n 关于 proto：可选有 ip, arp, rarp, tcp, udp, icmp, ether 等，默认是所有协议的包 关于 dir：可选有 src, dst, src or dst, src and dst，默认为 src or dst 关于 type：可选有 host, net, port, portrange（端口范围，比如 21-42），默认为 host  常用操作 测试环境 IP：172.18.82.173\n抓取某主机的数据包 抓取主机 172.18.82.173 上所有收到（DST_IP）和发出（SRC_IP）的所有数据包\n$ tcpdump host 172.18.82.173 抓取经过指定网口 interface ，并且 DST_IP 或 SRC_IP 是 172.18.82.173 的数据包\n$ tcpdump -i eth0 host 172.18.82.173 筛选 SRC_IP，抓取经过 interface 且从 172.18.82.173 发出的包\n$ tcpdump -i eth0 src host 172.18.82.173 筛选 DST_IP，抓取经过 interface 且发送到 172.18.82.173 的包\n$ tcpdump -i eth0 dst host 172.18.82.173 抓取主机 200.200.200.1 和主机 200.200.200.2 或 200.200.200.3 通信的包\n$ tcpdump host 200.200.200.1 and \\(200.200.200.2 or 200.200.200.3\\) 抓取主机 200.200.200.1 和除了主机 200.200.200.2 之外所有主机通信的包\n$ tcpdump ip host 200.200.200.1 and ! 200.200.200.2 抓取某端口的数据包 抓取所有端口，显示 IP 地址\n$ tcpdump -nS 抓取某端口上的包\n$ tcpdump port 22 抓取经过指定 interface，并且 DST_PORT 或 SRC_PORT 是 22 的数据包\n$ tcpdump -i eth0 port 22 筛选 SRC_PORT\n$ tcpdump -i eth0 src port 22 筛选 DST_PORT\n$ tcpdump -i eth0 dst port 22 比如希望查看发送到 host 172.18.82.173 的网口 eth0 的 22 号端口的包\n$ tcpdump -i eth0 -nnt dst host 172.18.82.173 and port 22 -c 1 -vv 抓取某网络（网段）的数据包 抓取经过指定 interface，并且 DST_NET 或 SRC_NET 是 172.18.82 的包\n$ tcpdump -i eth0 net 172.18.82 筛选 SRC_NET\n$ tcpdump -i eth0 src net 172.18.82 筛选 DST_NET\n$ tcpdump -i eth0 dst net 172.18.82 抓取某协议的数据包 $ tcpdump -i eth0 icmp $ tcpdump -i eth0 ip $ tcpdump -i eth0 tcp $ tcpdump -i eth0 udp $ tcpdump -i eth0 arp 复杂的过滤条件 抓取经过 interface eth0 发送到 host 200.200.200.1 或 200.200.200.2 的 TCP 协议 22 号端口的数据包\n$ tcpdump -i eth0 -nntvv -c 10 \u0026#39;((tcp) and (port 22) and ((dst host 200.200.200.1) or (dst host 200.200.200.2)))\u0026#39; 对于复杂的过滤器表达式，为了逻辑清晰，可以使用 ()，不过默认情况下，tcpdump 会将 () 当做特殊字符，所以必须使用 '' 来消除歧义。\n抓取经过 interface eth0， DST_MAC 或 SRC_MAC 地址是 00:16:3e:12:16:e7 的 ICMP 数据包\n$ tcpdump -i eth0 \u0026#39;((icmp) and ((ether host 00:16:3e:12:16:e7)))\u0026#39; -nnvv 抓取经过 interface eth0，目标网络是 172.18 但目标主机又不是 172.18.82.173 的 TCP 且非 22 号端口号的数据包\n$ tcpdump -i eth0 -nntvv \u0026#39;((dst net 172.18) and (not dst host 172.18.82.173) and (tcp) and (not port 22))\u0026#39; 抓取流入 interface eth0，host 为 172.18.82.173 且协议为 ICMP 的数据包\n$ tcpdump -i eth0 -nntvv -P in host 172.18.82.173 and icmp 抓取流出 interface eth0，host 为 172.18.82.173 且协议为 ICMP 的数据包\n$ tcpdump -i eth0 -nntvv -P out host 172.18.82.173 and icmp 与其他工具的配合 tcpdump 抓包的时候，默认是打印到屏幕输出，如果是抓取包少还好，如果包很多，很多行数据，刷刷刷从眼前一闪而过，根本来不及看清内容。不过，tcpdump 提供了将抓取的数据保存到文件的功能，查看文件就方便分析多了，而且还能与其他图形工具一起配合分析，比如 wireshark、Snort 等。\n -w 选项表示把数据报文输出到文件  $ tcpdump -w capture_file.pcap port 80  -r 选项表示读取文件里的数据报文，显示到屏幕上  $ tcpdump -nXr capture_file.pcap host host1 .pcap 格式的文件需要用 wireshark、Snort 等工具查看，使用 vim 或 cat 会出现乱码。\ntcpdump 的输出格式 tcpdump 的输出格式总体上为：\n系统时间 源主机.端口 \u0026gt; 目标主机.端口 数据包参数 比如下面的例子，显示了 TCP 的三次握手过程：\n21:27:06.995846 IP (tos 0x0, ttl 64, id 45646, offset 0, flags [DF], proto TCP (6), length 64) 192.168.1.106.56166 \u0026gt; 124.192.132.54.80: Flags [S], cksum 0xa730 (correct), seq 992042666, win 65535, options [mss 1460,nop,wscale 4,nop,nop,TS val 663433143 ecr 0,sackOK,eol], length 0 21:27:07.030487 IP (tos 0x0, ttl 51, id 0, offset 0, flags [DF], proto TCP (6), length 44) 124.192.132.54.80 \u0026gt; 192.168.1.106.56166: Flags [S.], cksum 0xedc0 (correct), seq 2147006684, ack 992042667, win 14600, options [mss 1440], length 0 21:27:07.030527 IP (tos 0x0, ttl 64, id 59119, offset 0, flags [DF], proto TCP (6), length 40) 192.168.1.106.56166 \u0026gt; 124.192.132.54.80: Flags [.], cksum 0x3e72 (correct), ack 2147006685, win 65535, length 0 第一条是 SYN 报文，通过 Flags[S] 看出。第二条是 [S.]，表示 SYN-ACK 报文。常见的 TCP 报文的 Flags 如下：\n [S]： SYN（开始连接） [.]: 没有 Flag [P]: PSH（推送数据） [F]: FIN （结束连接） [R]: RST（重置连接）  GPG 前两篇文章，我介绍了RSA算法。\n今天，就接着来看，现实中怎么使用这个算法，对信息加密和解密。这要用到GnuPG软件（简称GPG），它是目前最流行、最好用的加密工具之一。\n什么是GPG 要了解什么是GPG，就要先了解PGP。\n1991年，程序员Phil Zimmermann为了避开政府监视，开发了加密软件PGP。这个软件非常好用，迅速流传开来，成了许多程序员的必备工具。但是，它是商业软件，不能自由使用。所以，自由软件基金会决定，开发一个PGP的替代品，取名为GnuPG。这就是GPG的由来。\nGnuPG 是完整实现了 RFC4880 （即PGP） 所定义的 OpenPGP 标准的自由软件。\nGnuPG 可以加密和签名你的数据和通讯信息，包含一个通用的密钥管理系统以及用于各种公钥目录的访问模块。\nGnuPG 是一个易于与其它程序整合的命令行工具，拥有很多前端程序和函数库。\nGnuPG 还支持 S/MIME 和 Secure Shell (ssh)。\nGPG有许多用途，本文主要介绍文件加密。至于邮件的加密，不同的邮件客户端有不同的设置，请参考Ubuntu网站的介绍。\n本文的使用环境为Linux命令行。如果掌握了命令行，Windows 或 Mac OS 客户端，就非常容易掌握。GPG并不难学，学会了它，从此就能轻松传递加密信息。建议读者一步步跟着教程做，对每条命令都自行测试。\n安装 GPG有两种安装方式。可以下载源码，自己编译安装。\n$ ./configure $ make $ make install 也可以安装编译好的二进制包。\n$ sudo apt-get install gnupg 安装完成后，键入下面的命令：\n$ gpg --help 如果屏幕显示GPG的帮助，就表示安装成功。\n配置 目录位置 GnuPG 用环境变量 $GNUPGHOME 定位配置文件的位置，默认情况下此变量并未被设置，会直接使用 $HOME，所以默认的配置目录是 ~/.gnupg。\n要改变默认位置，执行 $ gpg --homedir path/to/file 或在 startup files 中设置 GNUPGHOME。\n配置文件 默认的配置文件是 ~/.gnupg/gpg.conf 和 ~/.gnupg/dirmngr.conf.\ngnupg 目录的默认 权限 是 700，其中文件的权限是 600. 仅目录的所有者有权读写，访问这些文件。这是基于安全考虑，请不要变更。如果不使用这样的安全权限设置，会收到不安全文件的警告。\n在文件中附加需要的文件：/usr/share/gnupg 包含基本架构文件. gpg，第一次运行时，如果配置文件不存在，会自动复制文件到 ~/.gnupg。\n新用户的默认选项 要给新建用户设定一些默认选项，把配置文件放到 /etc/skel/.gnupg/。系统创建新用户时，就会把文件复制到 GnuPG 目录。还有一个 addgnupghome 命令可以为已有用户创建新 GnuPG 主目录：\n# addgnupghome user1 user2 此命令会将对检查 /home/user1/.gnupg 和 /home/user2/.gnupg，如果用户的 GnuPG 主目录不存在，就会从 skeleton 目录复制文件过去。\n生成密钥 安装成功后，使用 --full-generate-key 参数生成自己的密钥。\n$ gpg --full-generate-key 或用 gpg --gen-key 快速生成。以下使用 gpg2 --full-generate-key 演示。\n回车以后，会跳出一大段文字：\ngpg (GnuPG) 2.2.19; Copyright (C) 2019 Free Software Foundation, Inc. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Please select what kind of key you want: (1) RSA and RSA (default) (2) DSA and Elgamal (3) DSA (sign only) (4) RSA (sign only) (14) Existing key from card Your selection? 第一段是版权声明，然后让用户自己选择加密算法。默认选择第一个选项，表示加密和签名都使用RSA算法。\n然后，系统就会问你密钥的长度。\nRSA keys may be between 1024 and 4096 bits long. What keysize do you want? (3072) 密钥越长越安全。\n接着，设定密钥的有效期。\nPlease specify how long the key should be valid. 0 = key does not expire \u0026lt;n\u0026gt; = key expires in n days \u0026lt;n\u0026gt;w = key expires in n weeks \u0026lt;n\u0026gt;m = key expires in n months \u0026lt;n\u0026gt;y = key expires in n years Key is valid for? (0) 如果密钥只是个人使用，并且你很确定可以有效保管私钥，建议选择第一个选项，即永不过期。回答完上面三个问题以后，系统让你确认。\nIs this correct? (y/N) 输入y，系统就要求你提供个人信息。\nGnuPG needs to construct a user ID to identify your key. Real name: Email address Comment: \u0026ldquo;真实姓名\u0026quot;填入你姓名的英文写法，\u0026ldquo;电子邮件地址\u0026quot;填入你的邮件地址，\u0026ldquo;注释\u0026quot;这一栏可以空着。\n然后，你的\u0026quot;用户ID\u0026quot;生成了。\nYou selected this USER-ID: \u0026#34;Vane Hsiung \u0026lt;1664548605@qq.com\u0026gt;\u0026#34; 系统会让你最后确认一次。\nChange (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? 输入O表示\u0026quot;确定\u0026rdquo;。\n接着，系统会要求你做一些随机的举动，以生成一个随机数。同时系统会让你设定一个私钥的密码。这是为了防止误操作，或者系统被侵入时有人擅自动用私钥。\nWe need to generate a lot of random bytes. It is a good idea to performsome other action (type on the keyboard, move the mouse, utilize thedisks) during the prime generation; this gives the random numbergenerator a better chance to gain enough entropy. 然后，系统就开始生成密钥了，\n几分钟以后，系统提示密钥已经生成了。\ngpg: key B893B73ABC92D2CA marked as ultimately trusted gpg: revocation certificate stored as \u0026#39;\u0026#39;public and secret key created and signed. 请注意上面的字符串\u0026quot;B893B73ABC92D2CA\u0026rdquo;，这是\u0026quot;用户ID\u0026quot;的Hash字符串，可以用来替代\u0026quot;用户ID\u0026rdquo;。\n这时，最好再生成一张\u0026quot;撤销证书\u0026quot;，以备以后密钥作废时，可以请求外部的公钥服务器撤销你的公钥。\n$ gpg --gen-revoke [用户ID] 上面的\u0026quot;用户ID\u0026quot;部分，可以填入你的邮件地址或者Hash字符串（以下同）。\n密钥管理 列出密钥\nlist-keys参数列出系统中已有的密钥．\n$ gpg --list-keys 显示结果如下：\ngpg: checking the trustdb gpg: marginals needed: 3 completes needed: 1 trust model: pgp gpg: depth: 0 valid: 1 signed: 0 trust: 0-, 0q, 0n, 0m, 0f, 1u /home/vane/.gnupg/pubring.kbx ----------------------------- pub rsa3072 2021-10-17 [SC] BC158F7500033355B5324CF14C701F8BF2E03463 uid [ultimate] Vane Hsiung \u0026lt;1664548605@qq.com\u0026gt; sub rsa3072 2021-10-17 [E] 第一行显示公钥文件名（pubring.gpg），第二行显示公钥特征（4096位，Hash字符串和生成时间），第三行显示\u0026quot;用户ID\u0026quot;，第四行显示私钥特征。\n如果你要从密钥列表中删除某个密钥，可以使用如下参数。\n$ gpg --delete-secret-keys [用户ID] $ gpg --delete-key [用户ID] 输出密钥\n公钥文件（.gnupg/pubring.gpg）以二进制形式储存，armor参数可以将其转换为ASCII码显示。\n$ gpg --armor --output public-key.txt --export [用户ID] \u0026ldquo;用户ID\u0026quot;指定哪个用户的公钥，output参数指定输出文件名（public-key.txt）。\n类似地，export-secret-keys参数可以转换私钥。\n$ gpg --armor --output private-key.txt --export-secret-keys 上传公钥\n公钥服务器是网络上专门储存用户公钥的服务器。send-keys参数可以将公钥上传到服务器。\n$ gpg --send-keys [用户ID] --keyserver hkp://subkeys.pgp.net 使用上面的命令，你的公钥就被传到了服务器subkeys.pgp.net，然后通过交换机制，所有的公钥服务器最终都会包含你的公钥。\n由于公钥服务器没有检查机制，任何人都可以用你的名义上传公钥，所以没有办法保证服务器上的公钥的可靠性。通常，你可以在网站上公布一个公钥指纹，让其他人核对下载到的公钥是否为真。fingerprint参数生成公钥指纹。\n$ gpg --fingerprint [用户ID] 输入密钥\n除了生成自己的密钥，还需要将他人的公钥或者你的其他密钥输入系统。这时可以使用import参数。\n$ gpg --import [密钥文件] 为了获得他人的公钥，可以让对方直接发给你，或者到公钥服务器上寻找。\n$ gpg --keyserver hkp://subkeys.pgp.net --search-keys [用户ID] 正如前面提到的，我们无法保证服务器上的公钥是否可靠，下载后还需要用其他机制验证．\n加密和解密 加密\n假定有一个文本文件demo.txt，怎样对它加密呢？\nencrypt参数用于加密。\n$ gpg --recipient [用户ID] --output demo.en.txt --encrypt demo.txt recipient参数指定接收者的公钥，output参数指定加密后的文件名，encrypt参数指定源文件。运行上面的命令后，demo.en.txt就是已加密的文件，可以把它发给对方。\n解密\n对方收到加密文件以后，就用自己的私钥解密。\n$ gpg --output demo.de.txt --decrypt demo.en.txt output 指定解密后生成的文件，decrypt参数指定需要解密的文件。运行上面的命令，demo.de.txt就是解密后的文件。\nGPG允许省略decrypt参数。\n$ gpg demo.en.txt 签名 对文件签名\n有时，我们不需要加密文件，只需要对文件签名，表示这个文件确实是我本人发出的。sign参数用来签名。\n$ gpg --sign demo.txt 运行上面的命令后，当前目录下生成demo.txt.gpg文件，这就是签名后的文件。这个文件默认采用二进制储存，如果想生成ASCII码的签名文件，可以使用clearsign参数。\n$ gpg --clearsign demo.txt 运行上面的命令后 ，当前目录下生成demo.txt.asc文件，后缀名asc表示该文件是ASCII码形式的。\n如果想生成单独的签名文件，与文件内容分开存放，可以使用detach-sign参数。　$ gpg --detach-sign demo.txt 运行上面的命令后，当前目录下生成一个单独的签名文件demo.txt.sig。该文件是二进制形式的，如果想采用ASCII码形式，要加上armor参数。　$ gpg --armor --detach-sign demo.txt 签名+加密\n上一节的参数，都是只签名不加密。如果想同时签名和加密，可以使用下面的命令。\n$ gpg --local-user [发信者ID] --recipient [接收者ID] --armor --sign --encrypt demo.txt local-user参数指定用发信者的私钥签名，recipient参数指定用接收者的公钥加密，armor参数表示采用ASCII码形式显示，sign参数表示需要签名，encrypt参数表示指定源文件。\n验证签名\n我们收到别人签名后的文件，需要用对方的公钥验证签名是否为真。verify参数用来验证。\n$ gpg --verify demo.txt.asc demo.txt 举例来说，openvpn网站就提供每一个下载包的gpg签名文件。你可以根据它的说明，验证这些下载包是否为真。\nOthers Ubuntu Packages Search List of applications:Arch Recommended applications: Gentoo 常用软件:openSUSE Awesome-Linux-Software 应用下载-优麒麟 国内应用 wine 版 deb 包。\nAUR 抄安装脚本。\nGentoo Portage Overlays 抄安装脚本。\n铜豌豆软件生态  铜豌豆 Linux 收集整理制作了大量中国人常用的应用软件，丰富 Linux 桌面系统软件生态。 大家可以在添加铜豌豆软件源后，来安装使用这些软件包。 铜豌豆软件源不但支持 铜豌豆 Linux 系统，还支持 Debian 系的所有 Linux 发行版。Debian、Armbian、Ubuntu、深度、优麒麟、红旗等。T  ","permalink":"https://sakamotokurome.github.io/posts/ubuntup1applications/","summary":"GUI Utilities Chrome 因为 Chrome 安装包的时候会自动添加 gpg，因此可以参考 Bypass GPG signature checks only for a single repository 执行如下操作 $ sudo sh -c \u0026#39;echo \u0026#34;deb [arch=amd64 trusted=yes] https://dl.google.com/linux/chrome/deb/ stable main\u0026#34; \u0026gt; /etc/apt/sources.list.d/google-chrome.list\u0026#39; $ sudo apt update $ sudo apt install google-chrome-stable PS：之前直","title":"Ubuntu Applications"},{"content":"友邦拓 乌班图\n During the first ten years of this HOWTO\u0026rsquo;s life, I reported that from a new user\u0026rsquo;s point of view, all Linux distributions are almost equivalent. But in 2006-2007, an actual best choice emerged: Ubuntu. While other distros have their own areas of strength, Ubuntu is far and away the most accessible to Linux newbies. Beware, though, of the hideous and nigh-unusable \u0026ldquo;Unity\u0026rdquo; desktop interface that Ubuntu introduced as a default a few years later; the Xubuntu or Kubuntu variants are better.\nEric Steven Raymond - How To Become A Hacker\n 学习 Linux 几点忠告 不要當“傳教士”\n(這點有一個重大弊端：開放軟體沒有商業軟件那樣的宣傳，如果使用者都如此低調，用戶群不會大幅擴展。)\n很多人在討論區不斷的引起的Linux對比Windows之類的討論，甚至爭的面紅耳赤，這是沒有必要的\n這種爭論是浪費時間而沒有任何用處的。對，你花了一下午，用許多事實“捍衛”了Linux比Windows好這個說法。但是Windows的支持者並不會喜歡上Linux的，他們只是稍微退縮一下，然後找一些新的證據來跟你辯論。\n世界上的人們都在利用Linux的研究最前沿的科學，我們還在這裡討論“要不要用Linux的這種無聊的問題，什麼時候才能趕上時代前進的步伐？\n什麼叫做Window支持者，什麼叫做Linux的支持者？我們為什麼要支持某一個而反對另外一個？你不需要為 Linux的護法，不需要成為 Linux的支持者“或者”GNU的傳教士“ GNU / Linux的已經用事實向世界證明了它們的威力，已經被大多數人接受。你只需要安安靜靜享受的GNU / Linux的給你的樂趣和自由。\n你需要關心的不是你的工具是什麼，而是你用它做了什麼。精通的Linux並不說明任何問題，因為它只是一個工具而已。如果你用的Windows能很好的完成你的任務，那你就沒有必要費時間去熟悉Linux操作系統。直到有一天你發現一項任務只有Linux操作系統才能完成的時候再換也不遲，因為你身邊的的Linux的愛好者一定會很樂意的幫助你。\n如果你在使用Linux操作系統的過程中對它產生了感情，那麼你應該明白那些習慣於使用Windows的人也會對Windows產生依賴。類似的爭論還有很多：微軟 Office Word和TeX，Emacs和Vim，Wolfram Mathematica和Maple，侏儒，fvwm的和KDE的時候，狗派\u0026hellip; \u0026hellip;和冷靜地對自己說：“我不站在它們任何一邊。”儘管這有些不容易辦到。\n各人的需要不同，生活的環境不同。對你來說好的東西，對別人來說不一定好，我們需要尊重別人的選擇。如果你當面說別人正在用的程序不好，沒有必要。\n不要強迫自己\n喜歡電腦的人總是有某些心理強迫傾向。有的人說：“鍵盤比滑鼠快。我不要用滑鼠。這樣才有高效率。”所以他在編輯器裡無論什麼時候總是用20W的，大於 10J這樣的命令到達目的點。他甚至覺得圖形界面是多餘的，乾脆都不裝 Xwindow。\n全部用鍵盤看起來的確比讓手離開鍵盤去拿鼠標，再回來“快”多了，但是快的擊鍵頻率不等於工作的高效率，對你的健康更沒有什麼好處。這只能把你變成打鍵盤的機器。\n當你正在檢查你的文章或者程序，思維正在隨著字符的含義流動，突然為 20W，大於 10J這樣的東西出現在你的腦子裡，是不是會打斷思路？不？那說明你當時思考的問題比較簡單，這些干擾還不會起到副作用。\n其實很多人用電腦的時候，思想都受到某種教學的束縛，上面這個只是教多數種類中的一種。某些人創造了很多這種數學，用他的工作方式來要求別人，嘲笑方式跟他不一樣的人。比如有的人嘲笑其它人寫程序不按ç 8字符縮進，嘲笑別人在六裡用方向鍵，嘲笑別人不知道是什麼增值稅，嘲笑其它人用在Java，C＃這種由地方選區回收內存語言 \u0026hellip; \u0026hellip;\n你不用管各種各樣的教學，電腦只是你的工具，你想怎麼用就怎麼用。沒有人能夠約束你，沒有人可以嘲笑你的工作方式。電腦明天就不再是這個樣子，所以今天你不用完全了解它。你沒有必要知道別人創造的一切，因為你需要留點時間自己創造些東西。只要有樂趣！\n當你下次修改文章的時候，不妨試試悠閒的用滑鼠在你眼睛看到的地方輕輕點一下。\n 如果你發現自己有類似的強迫症，建議去諮詢一下心理醫生。\n 不要“玩”Linux\nLinux的很多人用的時候會感覺很迷茫，該用哪個發行版本呢？是不是我少裝了什麼？怎麼升級這麼快啊！怎麼這麼不穩定！每當遇到新的軟件他就想試用，每當新的版本出現，他就更新，然後用鼠標在新的菜單裡選擇從來沒見過的程序來用用。\n其實你是為了玩Linux而使用Linux操作系統的，而沒有找到正確的理由來利用Linux操作系統。你首先要明確用電腦的目的，你用它是為了解決你的實際問題，而不是為了學習安裝操作系統，不是為了測試哪個版本好用，不是為了“趕上潮流，更不是因為你硬盤太大了，你想多佔點空間。\n如果你啟動了電腦之後不知道應該幹什麼，那麼最好先不要用電腦，因為你可能有更重要的事情需要做。這沒什麼說的。\n不用挑剔發行版本\n很多人剛開始用linux的時候，總是在懷疑別的發行版本是否比自己正在用的這個好，總是懷疑自己以後什麼時候會失去支持，不得不換用別的發行。所以很多人今天是紅帽，明天又換成了Debian的，一會兒又是巴布亞\u0026hellip; \u0026hellip;甚至有的人在一台機器上裝了兩個版本的Linux操作系統，然後比較哪一個好。\n其實你完全沒有必要這樣做，任何發行，只要你熟悉了，你在上面的工作方式幾乎不會受到任何影響。我以前一直用的紅帽，當我有一天在我的一台新機器上安裝Debian時，我發現使用紅帽的經驗完全沒有浪費。我用了一個下午就配置好了Debian，使它服服貼貼的聽我的話，就跟沒有換發行版本一樣。\nDebian，拓林思，SuSE，紅帽，Gentoo\u0026hellip; \u0026hellip;任何一個版本都是不錯的。很多人認為自己攢一個 LFS的是高水平黑客的象徵，但是不是每個人都有精力去了解所有細節。\n不要盲目升級\n不知道這是心理作用還是什麼，有的人看到比較大的版本號，就會很想換成那個。很多人的Redhat的本來配置的很舒服了，可是一旦Redhat的發行新的版本，他們就會盡快下載過來，然後選擇升級安裝。結果很多時候把自己原來修改得很好的配置文件給沖掉了。新的軟件又帶來了新的問題，比如有一次我的rxvt的就升級到2.7.8跟miniChinput衝突了，升級到Redhat的8.0，xmms的發現居然缺省不能放了MP3播放，XFree86的是i810的模塊在啟動上有新的漏洞，Mozilla中，會導致突然退出。\n如果你已經配置好了一切，千萬別再整體升級了，這會浪費你很多很多時間的，不值得。有句話說得好：“如果沒有打破，不解決它。”如果你的程序能夠完成你需要做的事情，你何必升級呢？？？？\n 是的，不論是從論壇還是其他的地方反映出來的大部分都是這個問題，要么比较SUSE和Ubuntu的好，要么比Ubuntu或者Mandriva的好等等的言論。很多人還是把Linux操作系統看成了一個表面的東西。並沒有塌下心來學習 Linux系統。\n 不要配置你不需要的東西\n如果你只想做一個像我這樣的普通用戶，主要目的是用的Linux來完成自己的科研任務和日常工作，那就可以不用系統管理員或者網絡管理員的標準來要求自己，因為當一個系統和網絡管理員確實很辛苦。普通用戶學習那些不經常用到的複雜的維護系統的工具，其實是浪費時間，學了不用是會很快忘記的！\n我不是一個合格的網絡管理員，我的服務器都只設置了我自己需要的功能，設置好ssh連接的ftp已經足夠了，那樣可以省去我很多麻煩。我從來不過度考慮“安全，因為 Linux操作系統缺省已經很安全了。我沒有磁帶機，就不用管tar的那些稀奇古怪的參數了，czf，xzf，ztf已經可以滿足我所有的需要。桑達，awk的，\u0026hellip;我也只會幾種常用的命令行。\n不要習慣的使用根帳號。在需要的時候才用！\n這是很多剛接觸的UNIX類操作系統的人常見的現象，他們不喜歡在管理系統的時候才用，而是一直用根帳號幹所有事情，配置系統，安裝程序，瀏覽網頁，玩遊戲，編程 \u0026hellip; \u0026hellip;\n結果有一天，他不小心在某個系統目錄使用了del * \u0026hellip;後果不堪設想 \u0026hellip; \u0026hellip;\n不要用商業的眼光來看待Linux\nLinux不是商業軟件，所以不要用要求Solaris操作系統，視窗那樣的眼光來看 Linux操作系統。自由軟件的作者們從來不拉攏用戶，他們對用戶不負有任何責任。實際上在自由軟件的世界裡，開發者“和”用戶“並沒有明確的界限，大家是朋友。\n自由軟件很可能只是滿足作者和他的朋友的需要，甚至是為了好玩而創造的。自由軟件不是完美的，自由軟件承認自己有缺點，它不會自吹自擂，蒙蔽“用戶”的耳目。這種對作者責任的解脫激發了作者的創造力，他們不用過分考慮“向上兼容，他們往往比背上重重包袱的商業軟件結構更合理，技術更先進。\n所以當你用某個自由軟件遇到困難的時候，不應該埋怨軟件的作者，因為他們對你並沒有義務。你不應該把自己當成一個挑剔的顧客，而要把自己作為這個軟件的顧問和一個和藹的建議者，這樣你才能理解作者寫這個程序時的快樂，在遇到問題時向作者反映，幫助他完善這個軟件，成為一個快樂的參與者。就像你的哥哥送你一個他用舊了的自行車，你應該珍惜這份友情，而不要在車壞了，或者騎車摔了一跤的時候大罵你的哥哥。如果你真的不能使用這種合作的心態，那麼最好不要使用這個軟件。\n這是一種先進的文化，它包含了互相合作，科學創新的精神。理解這一點不是很容易，很多人往往是因為不能理解這種文化而離開自由軟件。這對於作者來說並沒有什麼損失。\n幹你的正事去\n很多人跟我說，你的網頁浪費我好多時間來配置這配置那，一會兒是fvwm的，一會兒是Mutt中\u0026hellip; \u0026hellip;\n嗯\u0026hellip; \u0026hellip;那些東西都是我有空的時候一點一點積累的，如果你想一次性搞定所有那些東西，恐怕得花你幾個星期甚至幾個月的時間！並不是一定要搞定所有這些東西你才能正常工作的。除非你真的非得利用某個程序，或者你閒著沒事，否則你可以不管這些東西。\n上面幾條僅供參考\n以上只是個人意見，不一定適合所有人。取捨由你了！\nSettings gnome-control-center\nDNS 最近经常出现 Firefox 可以打开 GitHub 网站，但是命令行 Git 无法拉取/推送代码的情况。甚至开了 VPN 也不行。运行 ping 命令发现 github.com 被解析到了 127.0.0.1，这是 DNS 被劫持了。是谁搞的鬼，相信你一定懂得。\n为啥 Firefox 可以打开 GitHub 最新的 Firefox 桌面版默认启用了 DoH（DNS over HTTPS），通过向特定的服务器发送 HTTPS 请求获取域名的 IP 地址。这就绕过了电信/联通/移动等提供的有毒 DNS 服务器。因为 DoH 采用 HTTPS 协议，不容易被劫持。另外国内用 Firefox 的很少，这个技术并不普及，所以暂时没有被老大哥盯上。\n但是很可惜，DoH 目前无法在 Linux 系统层面支持，运行命令行仍然是使用 ISP 提供的 DNS 服务器。电信/联通/移动经常抽风，甚至某些路由器都会给你下毒，让你打不开网页或者直接跳到某网址导航。\n为啥开了 VPN 也不行 因为通常是先连接本地网络，这时候已经从 ISP 获取了一个 DNS 服务器。再连接 VPN，（以 OpenVPN 为例）仍然是用的这个 DNS 服务器。\n某些商业 VPN 客户端是会在连接上 VPN 之后自动更换 DNS 服务器的。但是 Linux 自带的网络管理是没这个能力的。\n因此，如果你只用 Linux 自带的网络管理，最好的解决方法依然是手动设置一个可靠的 DNS 服务器。\nDNS 服务器哪家强 如果你去网上搜，很多老的文章会推荐这两个：\n Google 的 8.8.8.8 Cloudflare 的 1.1.1.1  这两个 DNS 还是能用的，但是在有些地方不太稳定，甚至直接连不上。\n目前还是推荐国内正规企业提供的 DNS 服务器：\n DNSPod/腾讯云 119.29.29.29 阿里云 223.5.5.5  并不能保证腾讯和阿里的 DNS 百分之百可靠，但是比电信/联通/移动好太多。起码 GitHub 是可以正常解析的。\n如何设置 DNS 这里就只介绍普通桌面用户用 NetworkManager 和 KDE 的用法。GNOME 基本类似。用 Wicked 的都是技术大佬，相信也不用看下面这些了。\n 从系统托盘网络图标右击，打开“网络设置”。 选择你的有线或者 WiFi 链接，进行编辑。 切换到 IPv4 标签页。 将“方法”从“自动”改成“自动（仅网络地址）”。 将“DNS服务器”改成“119.29.29.29”。 点“应用”并关闭“网络设置”窗口。 点击系统托盘的网络图标，打开网络列表，断开并重新链接。  注意，如果需要频繁更换不同的 WiFi 链接，则需要对不同的 WiFi 配置添加自己的 DNS 服务器。\n如果是自己家的网络，可以在路由器上配置，方法和上面类似，都是配置 IPv4 方法和 DNS 服务器。（注意，路由器的 WAN 互联网和 LAN 局域网设置都要配一下）这样家里的设备就不用单独配置了。\nCLI\n# 显示当前网络连接 $ nmcli connection show # 修改当前网络连接对应的DNS服务器，这里的网络连接可以用名称或者UUID来标识 $ nmcli con mod ens160 ipv4.dns \u0026#34;114.114.114.114 8.8.4.4\u0026#34; # 配置生效 $ nmcli con up ens160 或者\n# Config File $ vi /etc/netplan/01-network-manager-all.yaml network: version: 2 renderer: NetworkManager ethernets: ens3: dhcp4: no addresses: - 192.168.100.199/24 gateway4: 192.168.100.1 nameservers: address: [114.114.114.114, 8.8.4.4] wifis: ... # Apply the changes you made in the config file $ sudo netplan apply # To check if the system successfully applied the changes $ systemd-resolve --status | grep \u0026#39;DNS Servers\u0026#39; -A2 DNS Servers: 114.114.114.114 8.8.8.8 8.8.4.4 注意：您系统上的文件可能缺少整个以太网或 wifi 部分。 在这种情况下，添加缺少的行，确保遵守示例中提供的缩进。\nTesting the Domain Name Resolution Speed\n$ time dig @114.114.114.114 清空 DNS 缓存 因为 DNS 记录是有本地缓存的，即使你更换了 DNS 服务器，依然会优先从缓存里取 IP 地址。所以更换 DNS 之后，需要清空 DNS 缓存。\n这是一个比较头疼的问题，因为各家 Linux 发行版用来管理 DNS 的方式不一样，清空 DNS 缓存的方法也不一样。最通用的方法：重启系统。\n如果不想重启系统，那么可以参考这篇How to flush the DNS cache on Linux 。我大概总结一下，就是逐个试下面的命令：\n$ sudo systemd-resolve --flush-caches $ sudo systemctl restart nscd $ sudo systemctl restart named 如果没有用的话，还是重启系统吧。\n测试 DNS 解析 首先用 nslookup 测试一下 DNS 服务器是否能解析，如果解析出来的 Server 是你之前配的地址，Address 不是 127.0.0.1 或者 0.0.0.0 这种，应该就是好的。\n$ nslookup github.com Server: 119.29.29.29 Address: 119.29.29.29##53 Non-authoritative answer: Name: github.com Address: 20.205.243.166 但是 nslookup 能解析，并不意味着就能连上。实际连接还要看 ping 命令。注意 github.com 并不回应 ping 请求，也就是数据包都会 lost，这是正常的。只要 ping 能解析到 IP 地址就行了。\n$ ping github.com PING github.com (20.205.243.166) 56(84) 字节的数据。 ^C --- github.com ping 统计 --- 已发送 3 个包， 已接收 0 个包, 100% packet loss, time 2049ms 如果 ping 没问题，最后再试一下 git pull 命令。如果不能访问，则需要试试 VPN 了。\nOthers  Bluetooth: OFF Formats: United States Night Light: ON Blank screen: 10 Touchpad: OFF Fractional Scaling  SoftWare\u0026amp;Updates software-properties-gtk or software-properties-kde (Kubuntu) and update-manager (Software Updator)\n  Ubuntu Software 栏 Download from 选择 USTC MIRRORS。\n  Other Software 栏下开启 Canonical Partner Repositories (The partner repositories offer access to proprietary and closed-source software)。\n  Ubuntu 自动下载并安装对你的系统至关重要的安全更新。而这个自动更新经常导致你“无法锁定管理目录”错误。在 Updates 栏下选择\n For other packages, subscribe to: All updates Automatically check for updates: Every two weeks When there are security updates: Download and Install automatically When there are other updates: Display immediately Notify me of a new Ubuntu version: For long-term support versions    更新系统:\n$ sudo apt update $ sudo apt upgrade $ sudo apt autoremove   Livepatch: 更新内核不需要 Reboot required 了\n$ sudo ua attach \u0026lt;subscription\u0026gt;   Ubuntu Software \u0026amp; Update 卡在 cache refresh\n通过 apt update 可以看见是 Connecting to security.ubuntu.com Failed，解决办法是更改 /etc/hosts 文件添加其 IP，可通过 EASYCOUNTER 查找：\n## security.ubuntu.com 91.189.88.142 security.ubuntu.com 91.189.88.152 security.ubuntu.com 91.189.91.38 security.ubuntu.com 91.189.91.39 security.ubuntu.com ## archive.canonical.com 91.189.92.150 archive.canonical.com 91.189.92.191 archive.canonical.com 91.189.91.15 archive.canonical.com ## downloads.sourceforge.net 216.105.38.13 downloads.sourceforge.net ubuntu下如何获取源码包和源码\n  在 Software \u0026amp; Updates 中选中 Source code，不要 Reload，因为很慢，在命令行中 update。或者在软件源配置文件 /etc/apt/sources.list 中添加 deb-src 项。\n  获取 xxx 源码包的详细信息\n$ sudo apt-cache showsrc xxx   获取源码包，并将源码包解压到同名目录\n$ sudo apt-get source xxx   Upgrade Ubuntu version\n 打开 Software Updater 更新软件 打开 Software \u0026amp; Updates 选择 Updates 栏，在 Notify me of a new Ubuntu Version 中选择 For any new version 。 打开 Software Updater 更新到新 Ubuntu 版本。 使用 lsb_release -a 确认 Ubuntu 版本。  Input Method Editor 首先在 Language Support (gnome-language-selector，注意不要在终端中运行这个命令，因为环境不一样) 中下载语言包\nIBus ubuntu libpinyin 输入法支持云拼音，只需要开启就可以了。\nEmoji input\nIBus supports the input of emoji icons. Type Ctrl+. or Ctrl+; and you will see the input prompt change to an underlined e character. You can then type the symbol or name of the emoji you want (e.g. :) or face) and press Space to render it. If you are satisfied with the result press Enter to submit it and exit emoji input mode, or press Space for a second time to open a dialog where you can further customize your desired emoji.\nSee ibus-emoji(7) for more information.\nUnicode input\nIBus supports the input of complex Unicode characters. Type Ctrl+Shift+u and you will see the input prompt change to an underlined u character. You can then type the code of the Unicode character you want and press Space or Enter to render and submit it.\n 間隔號「·」U+00B7  搜狗细胞词库\n到hslinuxextra下载sougou-phrases-full.7z。\n经过与ibus开发者协商，ibus-pinyin的词库查找规则做了一些更改，只要在词库目录（就是有一个.db文件的那个目录，一般是/usr/share/ibus-libpinyin/db/目录）把新词库复制过来并改名为local.db就可以使用了，如果感觉词库不好，直接删除掉local.db，就可以让ibus使用原来的词库。\n覆盖以后，你把ibus重启一下ibus-daemon -d -x -r，如果你能打出下面的这个词组，说明生效了：\n弗雷德霍姆行列式 这个词库，基于ibus原有的android词库文件，另外增加了搜狗的细胞词库。\nFcitx 4 在Ubuntu Wayland 桌面中使用fictx管理中文输入法\n$ sudo apt install fcitx -y 设置 fcitx：\n  在 Language Support 中选择 fcitx，全局应用，并恢复 ibus 自定义切换语言快捷键设置。\n  (可选）wayland桌面默认不读取/etc/profile中的环境变量，而是从/etc/environment文件中读取，这是导致fcitx不能正常工作的原因。\n$ sudo vim /etc/environment INPUT_METHOD=fcitx GTK_IM_MODULE=fcitx QT_IM_MODULE=fcitx XMODIFIERS=@im=fcitx   输入法框架：\n 搜狗输入法 for Linux 百度输入法Linux版 Google拼音  其他：\n 百度输入法不能安装用于更换皮肤的 fcitx-ui-qimpanel，否则乱码。需要手动安装 fcitx-libs，否则开机不自动启动。 在 fcitx 与 sogoupinyin 安装完之后，需要重启才能使用。  皮肤：\n fcitx 皮肤：/usr/share/fcitx/skin sogoupinyin 皮肤：/usr/share/sogou-qimpanel/skin。  旧：可以改名为 zip 解压 新：受版权保护    Fcitx 5 安装 配置工具 KDE 下使用 kde-config-fcitx5， Gnome 下使用 fcitx5-config-qt。\n20.04 (20220122) 官方仓库里没有 Gnome 的配置工具 kcm-fcitx5（内含 fcitx5-config-qt），因此通过 ppa:zhsj/fcitx5 来安装\n$ sudo add-apt-repository ppa:zhsj/fcitx5 $ sudo apt-get update $ sudo apt install fcitx5 fcitx5-chinese-addons 或者也可以通过**通过 flatpak 安装**。\n安装后在 Ubuntu 在 Language Support 里修改输入法系统为 fcitx5，记得点击 Apply System-Wide。\n安装报如下错\nE: Failed to fetch http://103.95.217.6/ppa.launchpad.net/zhsj/fcitx5/ubuntu/pool/main/f/fcitx5-chinese-addons/fcitx5-module-cloudpinyin_5.0.4-1~ubuntu20.04.1~ppa1_amd64.deb 503 Service Unavailable [IP: 103.95.217.6 80] E: Aborting install. 可以在浏览器中打开链接直接下载。\n肥猫百万大词库 Download latest version of \u0026ldquo;zhwiki.dict\u0026rdquo; from https://github.com/felixonmars/fcitx5-pinyin-zhwiki/releases\nCopy into ~/.local/share/fcitx5/pinyin/dictionaries/ (create the folder if it does not exist)\n可以在设置中看到是否启用，或者输入 “jinjinjin” 会出现 “鑫”。\nfcitx5 皮肤绘制简易教程 Tips 通过 Fcitx5 输入特殊字符\n将光标定位到任意一个输入框内，然后按下 Ctrl + Alt + Shift + U，然后输入 circle one，您将会看到多种形式的 ①。alpha, beta, sigma 等同理。\nemoji表情\nfcitx输入法自带的表情名都是英文的，而且以两个:包含住的，例如🌹（玫瑰rose），按下;后，输入🌹即可打出玫瑰的图标（更多内置图标名字见 Fcitx Configuration =\u0026gt; Addons =\u0026gt; Quick Phrase =\u0026gt; Editor =\u0026gt; emoji-eac)。\nRIME RIME/中州韵输入法引擎（Rime Input Method Engine），是一个跨平台的可高度定制的输入法算法框架。基于这个算法框架，Rime 開發者與其他開源社區的參與者在 Windows、macOS、Linux、Android 等平臺上創造了不同的輸入法前端實現。每个平台都有各自的名称：\n 【中州韵】 ibus_rime → Linux 【小狼毫】 Weasel → Windows 【鼠须管】 Squirrel → Mac OS X  在 Linux 下有两大主要的输入法支持框架：fcitx 和 IBus。\n fcitx 是 Free Chinese Input Toy for X 的简称。 IBus 是 Intelligent Input Bus 的简称。  Rime 二者都支持，有 ibus rime 和 fcitx-rime 两个版本。值得注意的是，基于 Fcitx 输入法框架的 fcitx-rime 是第三方软件，由 Fcitx 团队开发和维护。\n# ibus $ sudo apt install ibus-rime # fcitx4 $ sudo apt install fcitx-rime # fcitx5〔方案選單〕  $ sudo apt install fcitx5-rime 按组合键 Ctrl+` 或 F4 键唤出输入方案选单，由此调整 Rime 输入〔方案選單〕 法最常用的选项。您可通过方案选单切换已经安装的输入方案。\n更多中州韵输入法配置，请阅读晦涩的官方文档：\n 用户指南 · rime/home Wiki 配置指南 · rime/home Wiki 方案設計書 · rime/home Wiki  必知必会  输入法代号：ibus_rime ibus 用户资料夹： ~/.config/ibus/rime/ fcitx 用户资料夹：~/.config/fcitx/rime fcitx5 用户资料夹：~/.local/share/fcitx5/rime 共享资料夹： /usr/share/rime-data/  共享资料夹包含预设输入方案的源文件。 这些文件属于 Rime 所发行软件的一部份，在访问权限控制较严格的系统上对用户是只读的，因此谢绝软件版本更新以外的任何修改—— 一旦用户修改这里的文件，很可能影响后续的软件升级或在升级时丢失数据。\n在「部署 Rime」操作时，将用到这里的输入方案源文件、并结合用户定制的内容来编译预设输入方案。\n「用户资料夹」数据说明\n用户资料夹则包含为用户准备的内容，如\n 〔全局設定〕 default.yaml 〔發行版設定〕 ibus_rime.yaml：定制外观一般情况下会在 \u0026lt;发行版\u0026gt;.custom.yaml 文件中进行配置，Linux 下就是 ibus_rime.custom.yaml，macOS 下是 squirrel.custom.yaml，windows 下就是 weasel.custom.yaml 〔預設輸入方案副本〕 \u0026lt;方案标识\u0026gt;.schema.yaml ibus_rime.schema.yaml ※〔安裝信息〕 installation.yaml ※〔用戶狀態信息〕 user.yaml  编译输入方案所产出的二进制文件：\n 〔Rime 棱鏡〕 \u0026lt;方案标识\u0026gt;.prism.bin 〔Rime 固態詞典〕 \u0026lt;词典名\u0026gt;.table.bin：由系统文本词库（一般以xxx.dict.yaml结尾）通过「重新部署/deploy」生成的固态词典（一般以xxx.table.bin结尾），这部份词库因为在输入过程是固定不変的，所以存在用大量的词彚，也不允许用戸来直接删除。 〔Rime 反查詞典〕 \u0026lt;词典名\u0026gt;.reverse.bin  记录用户写作习惯的文件：\n ※〔用戶詞典〕 \u0026lt;词典名\u0026gt;.userdb.kct：记录我们用戸输入习惯的用戸词典（一般以xxx.userdb.kct）结尾。这部份词库的词彚，正常情况下是由用戸输入的时候随时生成的；其词彚可以动态调整，数量理论上来说不会特别多，也允许用戸自行删除（shift+delete）。 ※〔用戶詞典快照〕 \u0026lt;词典名\u0026gt;.userdb.txt、\u0026lt;词典名\u0026gt;.userdb.kct.snapshot 見於同步文件夾  以及用户自己设定的：\n ※〔用戶對全局設定的定製信息〕 default.custom.yaml ※〔用戶對預設輸入方案的定製信息〕 \u0026lt;方案标识\u0026gt;.custom.yaml ※〔用戶自製輸入方案〕及配套的詞典源文件  注：以上标有 ※ 号的文件，包含用户资料，您在清理文件时要注意备份！\n关于配置的位置问题\n要更改輸入方案裏面的選項，給輸入方案打補靪；\n要更改全局選項，給 default.yaml 打補靪；\n要更改「小狼毫」專屬的選項，如界面樣式，給 weasel.yaml 打補靪。\n總地來說規則是：要修改的配置項在 x(.schema).yaml 裏，就編輯 x.custom.yaml 打補靪。\n定制 定制指南 当用户需要对 Rime 中的各种设定做小幅的调节，最直接、但不完全正确的做法是：编辑「共享资料夹」中那些 .yaml 文档（/usr/share/rime-data/ ）。\n这种方法有很大缺陷：\n 当 Rime 软件升级时，也会升级各种设定档、预设输入方案。用户编辑过的文档会被覆盖为更高版本，所做调整也便丢失了。 软件升级后，你不能将备份文件直接覆盖升级后的文件。这将失去本次升级所新增和修复的功能。唯一的方法是，重新编辑升级后的文件。  因此，对于随 Rime 发行的设定档及预设输入方案，推荐的定制方法是：\n在「用户资料夹」下创建 .yaml 定制文档；比如\n default.yaml 的定制文件名为 default.custom.yaml luna_pinyin 的定制文件名为 luna_pinyin.custom.yaml luna_pinyin_simp 的定制文件名为 luna_pinyin_simp.custom.yaml symbols.yaml 的定制文件名为 symbols.custom.yaml  规范为在文件名主体（ID）和 .yaml 之间增加次级扩展名 .custom。定制文档的书写格式为：\npatch: \u0026#34;一级设定项/二级设定项/三级设定项\u0026#34;: 新的设定值 \u0026#34;另一个设定项\u0026#34;: 新的设定值 \u0026#34;再一个设定项\u0026#34;: 新的设定值 \u0026#34;含列表的设定项/@n\u0026#34;: 列表第n个元素新的设定值，从0开始计数 \u0026#34;含列表的设定项/@last\u0026#34;: 列表最后一个元素新的设定值 \u0026#34;含列表的设定项/@before 0\u0026#34;: 在列表第一个元素之前插入新的设定值（不建议在补丁中使用） \u0026#34;含列表的设定项/@after last\u0026#34;: 在列表 \u0026#34;一级设定项/二级设定项/三级设定项\u0026#34;: 新的设定值最后一个元素之后插入新的设定值（不建议在补丁中使用） \u0026#34;含列表的设定项/@next\u0026#34;: 在列表最后一个元素之后插入新的设定值（不建议在补丁中使用） 就是这样：patch 定义了一组「补丁」，以源文件中的设定为基础，写入新的设定项、或以新的设定值取代现有设定项的值。\n每次修改配置文件，你需要重新部署来生效。\n重新部署的操作方法\n  点击输入法的程序指示器，选择「部署」\n  点击输入法状态栏上的 ⟲ (Deploy) 按钮。如果找不到状态栏，在终端输入以下命令，可触发自动部署：\n# ibus $ rm ~/.config/ibus/rime/default.yaml; ibus-daemon -drx   定制每页候选数 Rime 中，默认每页至多显示 5 个候选项，而允许的范围是 1〜9（个别 Rime 发行版可支持 10 个候选）。\n设定每页候选个数的默认值为 9，在用户目录建立定制文档 ：\n$ vi ~/.config/ibus/rime/default.custom.yaml patch: \u0026#34;menu/page_size\u0026#34;: 9 重新部署即可生效。\n注意！ 如果 default.custom.yaml 里面已经有其他设定内容，只要以相同的缩进方式添加 patch: 以下的部分，不可重复 patch: 这一行。\n定制方案选单 $ vi ~/.config/ibus/rime/default.custom.yaml patch: # 對於列表類型，現在無有辦法指定如何添加、消除或單一修改某項，於是要在定製檔中將整個列表替換！ schema_list: - schema: luna_pinyin - schema: cangjie5 - schema: luna_pinyin_fluency - schema: luna_pinyin_simp # 這樣就啓用了未曾有過的高級輸入方案！其實這麼好的方案應該排在最前面哈。 - schema: my_coolest_ever_schema 调整方案候选顺序，增加输入法方案，或者通过 # 注释内容将不用的方案移除候选菜单。\n重新部署生效。\n定制字体字号 GNOME 桌面可以使用扩展 IBus Tweaker。\n$ vi ~/.config/fcitx/rime/default.custom.yaml patch: # 字體名稱，從記事本等處的系統字體對話框裏能看到 \u0026#34;style/font_face\u0026#34;: \u0026#34;明兰\u0026#34; # 字號，只認數字的，不認「五號」、「小五」這樣的 \u0026#34;style/font_point\u0026#34;: 16 横排与竖排候选码 在ibus_rime.custom.yaml添加如下内容：\npatch: style/horizontal: true 定制皮肤 注：ibus用户 ibus_rime.custom.yaml 不包含控制配色、字體字號等外觀樣式的設定項。\nRime 中，输入法的显示效果称为「颜色主题」(color scheme)。在网上看到一个有趣的主题，如何添加到 Rime 中使用呢？假如我们要加入这里提供的「丹青」主题，在系统 custom 设置文件中加入以下配置即可：\n# 在配色方案列表裏加入標識爲 tantsing 的新方案 \u0026#34;preset_color_schemes/tantsing\u0026#34;:  author: Mijiag back_color: 0xE3E3E3 border_color: 0x000000 candidate_text_color: 0x000000 comment_text_color: 0x474747 hilited_back_color: 0x1A0791 hilited_candidate_back_color: 0x6F0B73 hilited_candidate_text_color: 0xE3E3E3 hilited_text_color: 0xE3E3E3 name: \u0026#34;丹青/Tantsing\u0026#34; text_color: 0x000000 引用该主题的时候，使用名字 tantsing：\n# squirrel.custom.yaml patch: style: color_scheme: tantsing horizontal: true inline_preedit: true font_point: 16 corner_radius: 5 candidate_format: \u0026#34;%c\\u2005%@ \\u2005\u0026#34; 如果要自己制作 Rime 主题，「Rime 西米」是一款网页端工具，可以辅助制作，实时渲染颜色，便于查看最终显示效果。这里有一些预定义的主题可供使用。\n输入符号 符号文件 /usr/share/rime-data/symbols.yaml 开头已经说明了使用方法：\n# Usage: patch your Rime schema to enable /X symbols: # patch: # punctuator/import_preset: symbols # recognizer/patterns/punct: \u0026#39;^/([0-9]0?|[A-Za-z]+)$\u0026#39; 想在朙月拼音·简化字 luna_pinyin_simp 方案下输入符号，就新建 luna_pinyin_simp.custom.yaml：\npatch: punctuator/import_preset: symbols recognizer/patterns/punct: \u0026#39;^/([0-9]0?|[A-Za-z]+)$\u0026#39; 重新部署生效。\n输入符号请键入识别码：\n 星号 /xh 箭头 /jt 數字 /1 更多符号参阅文件 symbols.yaml。  其他方案下输入符号，照葫芦画瓢。\n符号自定义 拷贝 /usr/share/rime-data/symbols.yaml 为 ~/.config/ibus/rime/symbols.custom.yaml。在末尾添加自定义符号：\n# 个人常用信息 \u0026#39;/yx\u0026#39;: [ xiaoming@gmail.com, xiaoming@163.com, 1234567910 ] # 快速输入勾和叉  \u0026#39;/gc\u0026#39;: [ ✓, ☑, ✗, ☒ ] 想在朙月拼音·简化字 luna_pinyin_simp 方案下输入符号，就修改 luna_pinyin_simp.custom.yaml 文件内容为：\npatch: punctuator/import_preset: symbols.custom recognizer/patterns/punct: \u0026#39;^/([0-9]0?|[A-Za-z]+)$\u0026#39; 重新部署生效。\n然后在中文模式下，输入 /gc，就会显示出自定义的符号，输入对应的数字，符号就会上屏。\n输入直角引号 有的人喜欢在写作的时候使用直角引号：「」和『』，Rime 在 symbols.yaml 里面，已经提供了这个功能，不过是在 [ 和 ] 按键上提供的，中文输入法状态下，按下[ (])，返回的结果中包含 「 (」)，如果按住 Shift 键，按下 [ (])，返回的结果中包含 『 (』)。\n但是因为这毕竟是引号，最好是按下引号的时候，能够输出直角引号，在symbols.custom.yaml 中，找到 punctuator 部分下的 hafl_shape (半角的意思)下面，把下面的映射\n\u0026#39;\u0026#39;\u0026#39;\u0026#39; : { pair: [ \u0026#39;‘\u0026#39;, \u0026#39;’\u0026#39; ] } \u0026#39;\u0026#34;\u0026#39; : { pair: [ \u0026#39;“\u0026#39;, \u0026#39;”\u0026#39; ] } 改成\n\u0026#39;\u0026#39;\u0026#39;\u0026#39; : { pair: [ \u0026#39;『\u0026#39;, \u0026#39;』\u0026#39; ] } \u0026#39;\u0026#34;\u0026#39; : { pair: [ \u0026#39;「\u0026#39;, \u0026#39;」\u0026#39; ] } 这样就可以直接输入直角引号了，另外一种方式就是在词典中添加直角引号映射，在jdhao.dict.yaml 中加入下面的映射即可：\n「」\tsyh\t1000 『』\tdyh\t1000 扩展词库 下载Rime 擴充詞庫：\nluna_pinyin.hanyu.dict.yaml luna_pinyin.cn_en.dict.yaml luna_pinyin.extended.dict.yaml luna_pinyin.poetry.dict.yaml 接着将四个文件移动到用户资料夹 ~/.config/ibus/rime 下。\n新增一個自訂的 luna_pinyin_simp.extended.dict.yaml 檔案：\n# 以下禁用了默认词库同时不启用默认的“八股文”词库及词频系统,如果您不希望候选词中的出现繁体字、方框字的话 --- name: luna_pinyin_simp.extended version: \u0026#34;2022.08.21\u0026#34; sort: by_weight use_preset_vocabulary: false #是否启用默认的“八股文”词库及词频系统,如需启用请设为 true  import_tables: #在此导入词库 #- luna_pinyin - luna_pinyin.hanyu - lluna_pinyin.cn_en - luna_pinyin.extended - luna_pinyin.poetry ... 接着再於 luna_pinyin_simp.custom.yaml 中將 translator/dictionary 設置成此字典檔即可\npatch: translator/dictionary: luna_pinyin_simp.extended # 词典名字可自定义，保持一致即可 重新部署生效。\n其他扩展词库：\n  ssnhd/rime 1.5k（🗸）\n  wongdean/rime-settings 1.3k\n  fkxxyz/rime-cloverpinyin 1.1k（用过）\n  thunlp/THUOCL 610\n  ayaka14732/awesome-rime 383\n  LoganJC/rime-dict 289\n  xiaoTaoist/rime-dict 226（用过）\n  yangshann/rime-dict 48（用过）\n  增加自己的词库 我们可以仿照上一步的词典文件建立自己额外的词典，增加自己的词汇。例如，建立名为 my.dict.yaml 的文件，然后参照 luna_pinyin_simp.cn_en.dict.yaml 添加几个自己常用的词汇，文件内容如下：\n# my.dict.yaml 文件内容 # Rime dictionary # encoding: utf-8 # --- name: my version: \u0026#34;2020.05.28\u0026#34; sort: by_weight use_preset_vocabulary: true ... GitHub\tgithub\t100 Stack Overflow\tso\t1000 词典的格式为: 词汇\u0026lt;Tab\u0026gt;编码\u0026lt;Tab\u0026gt;词频，各个项目之间必须用 Tab（也就是制表符 ）分割。一个最保险的方法就是，复制粘贴。词频部分可以不要。\n然后在 luna_pinyin_simp.extended.dict.yaml 的 import_tables 中加上自己建立的词汇。\nimport_tables: - my 一切添加妥当之后，重新部署生效。\n默认英文 如果经常和英语打交道，偶尔输入汉字，可以把朙月拼音初始状态设为英语，需要时再切回中文。参考 这里 给出的说明，在 luna_pinyin_simp.custom.yaml 文件中加入下面的设置：\npatch: \u0026#34;switches/@0/reset\u0026#34;: 1 # 初始的 ascii mode 设置为「西文」 意思就是將 switcher 列表中的第一個元素（即 ascii_mode 開關）的初始值重設爲狀態1（即「英文」）。\n模糊拼音 这里是官方给的一个模板 （朙月拼音）。将模板剪贴进 ~/.config/ibus/rime/luna_pinyin_simp.custom.yaml 文件中，然后需要哪组就去掉那一行前面的 # 即可。\n# luna_pinyin.custom.yaml # # 【朙月拼音】模糊音定製模板 # 佛振配製 :-) # # 位置： # ~/.config/ibus/rime (Linux) # ~/Library/Rime (Mac OS) # %APPDATA%\\Rime (Windows) # # 於重新部署後生效 # patch: \u0026#39;speller/algebra\u0026#39;: - erase/^xx$/ # 第一行保留 # 模糊音定義 # 需要哪組就刪去行首的 # 號，單雙向任選 #- derive/^([zcs])h/$1/ # zh, ch, sh =\u0026gt; z, c, s #- derive/^([zcs])([^h])/$1h$2/ # z, c, s =\u0026gt; zh, ch, sh #- derive/^n/l/ # n =\u0026gt; l #- derive/^l/n/ # l =\u0026gt; n # 這兩組一般是單向的 #- derive/^r/l/ # r =\u0026gt; l #- derive/^ren/yin/ # ren =\u0026gt; yin, reng =\u0026gt; ying #- derive/^r/y/ # r =\u0026gt; y # 下面 hu \u0026lt;=\u0026gt; f 這組寫法複雜一些，分情況討論 #- derive/^hu$/fu/ # hu =\u0026gt; fu #- derive/^hong$/feng/ # hong =\u0026gt; feng #- derive/^hu([in])$/fe$1/ # hui =\u0026gt; fei, hun =\u0026gt; fen #- derive/^hu([ao])/f$1/ # hua =\u0026gt; fa, ... #- derive/^fu$/hu/ # fu =\u0026gt; hu #- derive/^feng$/hong/ # feng =\u0026gt; hong #- derive/^fe([in])$/hu$1/ # fei =\u0026gt; hui, fen =\u0026gt; hun #- derive/^f([ao])/hu$1/ # fa =\u0026gt; hua, ... # 韻母部份 #- derive/^([bpmf])eng$/$1ong/ # meng = mong, ... #- derive/([ei])n$/$1ng/ # en =\u0026gt; eng, in =\u0026gt; ing #- derive/([ei])ng$/$1n/ # eng =\u0026gt; en, ing =\u0026gt; in # 樣例足夠了，其他請自己總結…… # 反模糊音？ # 誰說方言沒有普通話精確、有模糊音，就能有反模糊音。 # 示例爲分尖團的中原官話： #- derive/^ji$/zii/ # 在設計者安排下鳩佔鵲巢，尖音i只好雙寫了 #- derive/^qi$/cii/ #- derive/^xi$/sii/ #- derive/^ji/zi/ #- derive/^qi/ci/ #- derive/^xi/si/ #- derive/^ju/zv/ #- derive/^qu/cv/ #- derive/^xu/sv/ # 韻母部份，只能從大面上覆蓋 #- derive/^([bpm])o$/$1eh/ # bo =\u0026gt; beh, ... #- derive/(^|[dtnlgkhzcs]h?)e$/$1eh/ # ge =\u0026gt; geh, se =\u0026gt; sheh, ... #- derive/^([gkh])uo$/$1ue/ # guo =\u0026gt; gue, ... #- derive/^([gkh])e$/$1uo/ # he =\u0026gt; huo, ... #- derive/([uv])e$/$1o/ # jue =\u0026gt; juo, lve =\u0026gt; lvo, ... #- derive/^fei$/fi/ # fei =\u0026gt; fi #- derive/^wei$/vi/ # wei =\u0026gt; vi #- derive/^([nl])ei$/$1ui/ # nei =\u0026gt; nui, lei =\u0026gt; lui #- derive/^([nlzcs])un$/$1vn/ # lun =\u0026gt; lvn, zun =\u0026gt; zvn, ...  #- derive/^([nlzcs])ong$/$1iong/ # long =\u0026gt; liong, song =\u0026gt; siong, ... # 這個辦法雖從拼寫上做出了區分，然而受詞典制約，候選字仍是混的。 # 只有真正的方音輸入方案纔能做到！但「反模糊音」這個玩法快速而有效！ # 模糊音定義先於簡拼定義，方可令簡拼支持以上模糊音 - abbrev/^([a-z]).+$/$1/ # 簡拼（首字母） - abbrev/^([zcs]h).+$/$1/ # 簡拼（zh, ch, sh） # 以下是一組容錯拼寫，《漢語拼音》方案以前者爲正 - derive/^([nl])ve$/$1ue/ # nve = nue, lve = lue - derive/^([jqxy])u/$1v/ # ju = jv, - derive/un$/uen/ # gun = guen, - derive/ui$/uei/ # gui = guei, - derive/iu$/iou/ # jiu = jiou, # 自動糾正一些常見的按鍵錯誤 - derive/([aeiou])ng$/$1gn/ # dagn =\u0026gt; dang  - derive/([dtngkhrzcs])o(u|ng)$/$1o/ # zho =\u0026gt; zhong|zhou - derive/ong$/on/ # zhonguo =\u0026gt; zhong guo - derive/ao$/oa/ # hoa =\u0026gt; hao - derive/([iu])a(o|ng?)$/a$1$2/ # tain =\u0026gt; tian # 分尖團後 v =\u0026gt; ü 的改寫條件也要相應地擴充： #\u0026#39;translator/preedit_format\u0026#39;: # - \u0026#34;xform/([nljqxyzcs])v/$1ü/\u0026#34; 同步用户资料 默认地，词典快照备份到 ~/.config/ibus/rime/sync/UUID 这个地方。我们可以设定同步的目标文件夹，直接编辑 ~/.config/ibus/rime/installation.yaml：\nsync_dir: \u0026#39;/DATA/Backup/RimeSync\u0026#39; 然后，点击输入法程序指示器选择「同步」。你的 用户配置、用户词库 等都会被放在目标文件夹。\n 注意！可能有些你自己添加的文件不会被备份，注意下就行。\n 我们可以借助移动存储设备，或在线存储服务如百度网盘、坚果云等，在多台电脑及不同系统之间同步用户词典和用户设定。在新电脑上配置一下 installation.yaml 文件，执行 部署 -\u0026gt; 同步 -\u0026gt; 部署 ，你的 用户配置、用户词库 都回来了。\n新世纪五笔 参阅 https://github.com/GuoBinyong/wubixinshiji。Rime输入法之五笔自动上屏。\n后续配置来自视频 rime 中的小狼毫输入法的安装和基础自定义 所分享的文件： https://www.lanzous.com/ia2g86h。\nEasy english 用于输入英文。拷贝下面两个文件到「用户资料夹」：\n easy_en.schema.yaml easy_en.dict.yaml  vim default.custom.yaml 添加输入方案：\nschema_list: - schema: wubixinshiji  # 新世纪五笔 - schema: wubixinshiji_pinyin  # 新世纪五笔·拼音 - schema: luna_pinyin_simp  # 朙月拼音·简化字 - schema: easy_en - schema: pinyin_simp  # 袖珍简化字拼音 输入日期 将文件 rime.lua 拷贝到 ~/.config/ibus/rime/ 下，在方案配置文件比如 wubi86.schema.yaml 的 engine\\translators: 下面添加滤镜引用：\ntranslators: - lua_translator@date_translator - lua_translator@week_translator rime-emoji  下載opencc檔案夾內容，將完整檔案夾放入Rime用戶檔案夾內 將emoji_suggestion.yaml內的內容加入至想添加Emoji的方案custom檔中  我安装后，没有显示emoji，所以还是用 gnome-characters 好了。\n切换中英文 切换中英文，rime在默认情况下，输入中文时按shift键会切换为英文，但字符还在，需要按回车输出字符，有的用户可能不习惯shift这个键位，或者不习惯按shift不直接上屏，还要按一下回车，对此，我们可以做出修改 default.custom.yaml：\npatch: ascii_composer/good_old_caps_lock: true ascii_composer/switch_key: Caps_Lock: clear Shift_L: commit_code Shift_R: inline_ascii Control_L: noop Control_R: noop 注意换行前空格以及冒号后的空格，还有字母大小写，前两行代码先不看，下面五行分别代表：\n caps_lock即为大写键，shift_L即为左shift，R是右，control_L即为左ctrl键，R为右 冒号后的字符即为这个键位的操作  clear表示按下此键后已输入的字符清除，同时rime输入状态切换为英文，大写键一定不能改为noop，否则大写英文将会无法输出，很多教程里都改为了noop，这点值得注意 commit_code即为提交代码，就是将已输入的字符上屏，同时输入法切换为英文 inline_ascii即为插入字符，就是已输入的字符为上屏前，按此键后输入法转为英文，可以接着输入，回车键再上屏 noop就是这个键在输入法里不会有任何操作    各个键位和代码的意思已经介绍完了，可以按自己的喜好，自行修改。\n不过仍有部分用户从win7开始是用的ctrl键+空格键切换中英文，且习惯输入法为默认英文。RIME的快捷键是在“default.yaml”文档中定义的，我们可以将“default.yaml”文档中相关代码直接复制过来，接上面代码：\nkey_binder: bindings: - {accept: \u0026#34;Control+Shift+2\u0026#34;, toggle: ascii_mode, when: always} 注意到ascii_mode了吗，“字符模式”即为我们需要的中英文切换快捷键，默认快捷键为ctrl+shift+2，我们可以将其代码修改为Control+space即为ctrl+空格，注意大小写，这样我们就能让输入法默认英文同时用回习惯的操作\n至此，关于default.custom.yaml的设置基本完成，样例如下：\npatch: ascii_composer/good_old_caps_lock: true ascii_composer/switch_key: Caps_Lock: clear Shift_L: noop Shift_R: noop Control_L: noop Control_R: noop key_binder/bindings: - { when: always, accept: Control+space, toggle: ascii_mode } - { when: has_menu, accept: minus, send: Page_Up } - { when: has_menu, accept: equal, send: Page_Down } 注意：如果没有Page_Up，Page_Down两行，就没办法用 + 与 - 进行翻页了。\n清空候选词 我使用ibus-rime，有一个很大的缺点是如果输入没有完成的情况下，移动鼠标，其他的输入法未完成的内容都会被清空，而只有rime不会，而且会重复输出未完成的内容，这点很烦人，也不知道哪里能够设置。\n  定制快捷键\npatch: key_binder/bindings: - { when: composing, accept: Control+g, send: Escape }   使用 Sitch input sources individually for each window\n  Wallpapers Gnome Background 圖形使用者介面程式\n可以透過「圖形使用者介面程式」，來更改「桌面圖片」。在桌面，按下「滑鼠右鍵」，就會出現一個選單，選擇「Change Background…」。就會出現設定更改「桌面圖片」的操作介面。\n也就是「Settings / Background」。\n$ gnome-control-center background 指令操作\n也可以透過「gsettings」這個指令，來更改「桌面圖片」。\n$ gsettings set org.gnome.desktop.background picture-uri \u0026#39;file:///usr/share/backgrounds/Blue_flower_by_Elena_Stravoravdi.jpg\u0026#39; 在測試的過程中發現，若使用「暗色系」的「佈景主題」，則要執行下面指令\n$ gsettings set org.gnome.desktop.background picture-uri-dark \u0026#39;file:///usr/share/backgrounds/Blue_flower_by_Elena_Stravoravdi.jpg\u0026#39; 小技巧\n切換顯示桌面的按鍵組合是「Win + d」。\n$ gsettings get org.gnome.desktop.wm.keybindings show-desktop [\u0026#39;\u0026lt;Primary\u0026gt;\u0026lt;Super\u0026gt;d\u0026#39;, \u0026#39;\u0026lt;Primary\u0026gt;\u0026lt;Alt\u0026gt;d\u0026#39;, \u0026#39;\u0026lt;Super\u0026gt;d\u0026#39;] Apps  Shotwell：在侧边栏 Photos 中 Ctrl + A，在菜单栏 File 中选择 Set as Desktop SlideShow\u0026hellip;；这会把图片复制到 .local/share/shotwell/wallpaper，并在该目录生成 wallpaper.xml，wallpaper.xml 定义自动切换壁纸动画。 替代软件：BingWall 等。 脚本分享：styli.sh、lswc、setwall 动态壁纸：komorebi、LiveWallpaper、PlasmaVideoWallpaper\u0026amp;org.kde.video、dynamic-wallpaper\u0026amp;pywal  Variety 默认仓库版本可能较低，导致一些 Bug，因此最好用 PPA\n$ sudo add-apt-repository ppa:variety/stable $ sudo apt update $ sudo apt install variety -y 支持 wallhaven，添加 keywords 就可以使用了，配置文件在 ~/.config/variety/variety.conf ：\n Touhou Azur Lane Genshin Impact anime girls cosplay GUWEIZ WLOP  unsplash.sh 添加脚本\n$ vi $HOME/Pictures/unsplash.sh #!/usr/bin/bash UNSPLASH_DIR=$HOME/Pictures/Unsplash if [ ! -d ${UNSPLASH_DIR} ]; then mkdir -p ${UNSPLASH_DIR} fi URL_LOCATION=$(curl -I https://source.unsplash.com/daily | grep Location | cut -d\u0026#39; \u0026#39; -f 2) WALLPAPER_NAME=$(echo $URL_LOCATION | egrep -o \u0026#39;photo[a-z0-9-]+\u0026#39;) WALLPAPER_FORMAT=$(echo $URL_LOCATION | egrep -o \u0026#39;fm=[a-z]+\u0026#39; | cut -d\u0026#39;=\u0026#39; -f 2) wget --no-proxy -O ${UNSPLASH_DIR}/${WALLPAPER_NAME}.${WALLPAPER_FORMAT} ${URL_LOCATION}  在 Unsplash Source 查看更多 API。 Curl to grab remote filename after following location 关于 cut 获取子字符串：Extract substring in Bash  可以使用 Crontab 定时切换壁纸：\n$ crontab -e 0 12 * * * /home/vane/Pictures/unsplash.sh 除了使用 crontab 外，还可以使用 Startup Applications Preferences 添加一个启动项。\nwallhaven.sh wallhaven图片右键下载的是原图，不是缩略图。\n$ vi $HOME/.wallhaven/wallhaven.sh #!/bin/bash WORK_DIR=$HOME/.wallhaven SAVE_DIR=$HOME/Pictures/wallhaven IMG_URL=https://w.wallhaven.cc/full function GetListing() { echo \u0026#39;get listing\u0026#39; listing=$(curl https://wallhaven.cc/api/v1/search?apikey=\u0026lt;API KEY\u0026gt;\u0026amp;categories=010\u0026amp;purity=111\u0026amp;atleast=1920x1080\u0026amp;ratios=16x9\u0026amp;sorting=random\u0026amp;order=desc\u0026amp;page=1) echo \u0026#39;save listing\u0026#39; echo $listing | jq -r \u0026#39;.data[].path\u0026#39; | awk -F \u0026#39;/\u0026#39; \u0026#39;{print $NF}\u0026#39; \u0026gt; $WORK_DIR/listing echo \u0026#39;save res\u0026#39; cat $WORK_DIR/listing | wc -l \u0026gt; $WORK_DIR/res SetWallpaper } function SetWallpaper() { if [ -a $WORK_DIR/res ]; then echo \u0026#39;read res\u0026#39; read res \u0026lt; $WORK_DIR/res if [ $res -ne 0 ]; then echo \u0026#39;get img\u0026#39; img=$(cat $WORK_DIR/listing | tail -${res} | head -1) echo \u0026#34;down $imgfrom $IMG_URL/${img:10:2}/$img\u0026#34; curl -o $SAVE_DIR/$img $IMG_URL/${img:10:2}/$img if [ $? -eq 0 ]; then echo \u0026#39;set wallpaper\u0026#39; cp $SAVE_DIR/$img $HOME/Wallpaper echo \u0026#39;res-1\u0026#39; echo $(($res - 1)) \u0026gt; $WORK_DIR/res echo \u0026#39;exit\u0026#39; exit 0 else echo \u0026#39;download error\u0026#39; SetWallpaper fi else echo \u0026#39;res=0\u0026#39; GetListing fi else echo \u0026#39;no res\u0026#39; GetListing fi } SetWallpaper 使用 Shell 脚本来处理 JSON，jq Manual，wallhaven API v1 Documentation\n一般文件内容开头都会有一个文件类型的标记，根据文件名后缀只是一个快捷的方法，不用读取文件内容就判断文件类型，但不是唯一的方法。\n$ crontab -e 0 12 * * * /home/vane/.wallhaven/wallhaven.sh Gsettings 无法在 Cron 中使用：出现此问题是因为 cron 仅使用一组非常有限的环境变量。 唯一一个负责在将其设置为 cron 作业时以正确方式运行问题脚本的环境变量是 DBUS_SESSION_BUS_ADDRESS。\nastronomy.sh #!/bin/bash API_KEY=zTL5rJmctXwHcsjfCSalfDRNFTeaVYa9FxgINVVU HTTP_REQUEST=https://api.nasa.gov/planetary/apod?api_key=$API_KEY HTTP_RESPONSE=$(curl $HTTP_REQUEST) IMG_HDURL=$(echo $HTTP_RESPONSE | jq -r \u0026#39;.hdurl\u0026#39;) IMG_FILENAME=$(echo ${IMG_HDURL##*/}) curl -o $HOME/DataOne/Images/Astronomy/$IMG_FILENAME $IMG_HDURL cp -av $HOME/DataOne/Images/Astronomy/$IMG_FILENAME $HOME/Wallpaper Wallpaper Slideshows 2018-04-23 18:53\n 使用一个简单的 XML，你就可以设置 GNOME 能够在桌面上显示一个幻灯片。\n 在 GNOME 中，一个非常酷、但却鲜为人知的特性是它能够将幻灯片显示为墙纸。你可以从 GNOME 控制中心的 “背景设置” 面板中选择墙纸幻灯片。在预览的右下角显示一个小时钟标志，可以将幻灯片的墙纸与静态墙纸区别开来。\n一些发行版带有预装的幻灯片壁纸。 例如，Ubuntu 包含了库存的 GNOME 定时壁纸幻灯片，以及 Ubuntu 壁纸大赛胜出的墙纸。\n如果你想创建自己的自定义幻灯片用作壁纸怎么办？虽然 GNOME 没有为此提供一个用户界面，但是在你的主目录中使用一些简单的 XML 文件来创建一个是非常容易的。 幸运的是，GNOME 控制中心的背景选择支持一些常见的目录路径，这样就可以轻松创建幻灯片，而不必编辑你的发行版所提供的任何内容。\n开始 使用你最喜欢的文本编辑器在 $HOME/.local/share/gnome-background-properties/ 创建一个 XML 文件。 虽然文件名不重要，但目录名称很重要（你可能需要创建该目录）。 举个例子，我创建了带有以下内容的 /home/ken/.local/share/gnome-background-properties/osdc-wallpapers.xml：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE wallpapers SYSTEM \u0026#34;gnome-wp-list.dtd\u0026#34;\u0026gt; \u0026lt;wallpapers\u0026gt; \u0026lt;wallpaper deleted=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;name\u0026gt;Opensource.com Wallpapers\u0026lt;/name\u0026gt; \u0026lt;filename\u0026gt;/home/ken/Pictures/Wallpapers/osdc/osdc.xml\u0026lt;/filename\u0026gt; \u0026lt;options\u0026gt;zoom\u0026lt;/options\u0026gt; \u0026lt;/wallpaper\u0026gt; \u0026lt;/wallpapers\u0026gt; 每一个你需要包含在 GNOME 控制中心的 “背景面板”中的每个幻灯片或静态壁纸，你都要在上面的 XML 文件需要为其增加一个 \u0026lt;wallpaper\u0026gt; 节点。\n在这个例子中，我的 osdc.xml 文件看起来是这样的：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; ?\u0026gt; \u0026lt;background\u0026gt; \u0026lt;static\u0026gt; \u0026lt;!-- Duration in seconds to display the background --\u0026gt; \u0026lt;duration\u0026gt;30.0\u0026lt;/duration\u0026gt; \u0026lt;file\u0026gt;/home/ken/Pictures/Wallpapers/osdc/osdc_2.png\u0026lt;/file\u0026gt; \u0026lt;/static\u0026gt; \u0026lt;transition\u0026gt; \u0026lt;!-- Duration of the transition in seconds, default is 2 seconds --\u0026gt; \u0026lt;duration\u0026gt;0.5\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/home/ken/Pictures/Wallpapers/osdc/osdc_2.png\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/home/ken/Pictures/Wallpapers/osdc/osdc_1.png\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;static\u0026gt; \u0026lt;duration\u0026gt;30.0\u0026lt;/duration\u0026gt; \u0026lt;file\u0026gt;/home/ken/Pictures/Wallpapers/osdc/osdc_1.png\u0026lt;/file\u0026gt; \u0026lt;/static\u0026gt; \u0026lt;transition\u0026gt; \u0026lt;duration\u0026gt;0.5\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/home/ken/Pictures/Wallpapers/osdc/osdc_1.png\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/home/ken/Pictures/Wallpapers/osdc/osdc_2.png\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;/background\u0026gt; 上面的 XML 中有几个重要的部分。 XML 中的 \u0026lt;background\u0026gt; 节点是你的外部节点。 每个背景都支持多个 \u0026lt;static\u0026gt; 和 \u0026lt;transition\u0026gt; 节点。\n \u0026lt;static\u0026gt; 节点定义用 \u0026lt;file\u0026gt; 节点要显示的图像以及用 \u0026lt;duration\u0026gt; 显示它的持续时间。 \u0026lt;transition\u0026gt; 节点定义 \u0026lt;duration\u0026gt;（变换时长），\u0026lt;from\u0026gt; 和 \u0026lt;to\u0026gt; 定义了起止的图像。  全天更换壁纸 另一个很酷的 GNOME 功能是基于时间的幻灯片。 你可以定义幻灯片的开始时间，GNOME 将根据它计算时间。 这对于根据一天中的时间设置不同的壁纸很有用。 例如，你可以将开始时间设置为 06:00，并在 12:00 之前显示一张墙纸，然后在下午和 18:00 再次更改。\n这是通过在 XML 中定义 \u0026lt;starttime\u0026gt; 来完成的，如下所示：\n\u0026lt;starttime\u0026gt; \u0026lt;!-- A start time in the past is fine --\u0026gt; \u0026lt;year\u0026gt;2017\u0026lt;/year\u0026gt; \u0026lt;month\u0026gt;11\u0026lt;/month\u0026gt; \u0026lt;day\u0026gt;21\u0026lt;/day\u0026gt; \u0026lt;hour\u0026gt;6\u0026lt;/hour\u0026gt; \u0026lt;minute\u0026gt;00\u0026lt;/minute\u0026gt; \u0026lt;second\u0026gt;00\u0026lt;/second\u0026gt; \u0026lt;/starttime\u0026gt; 上述 XML 文件定义于 2017 年 11 月 21 日 06:00 开始动画，时长为 21,600.00，相当于六个小时。 这段时间将显示你的早晨壁纸直到 12:00，12:00 时它会更改为你的下一张壁纸。 你可以继续以这种方式每隔一段时间更换一次壁纸，但确保所有持续时间的总计为 86,400 秒（等于 24 小时）。\nGNOME 将计算开始时间和当前时间之间的增量，并显示当前时间的正确墙纸。 例如，如果你在 16:00 选择新壁纸，则GNOME 将在 06:00 开始时间之后显示 36,000 秒的适当壁纸。\n实用程序  gnome-backearth-generator Dynamic Wallpaper Editor  macOS Dynamic Wallpaper 实例 \u0026lt;!-- Instructions: - Download and unzip Mojave dynamic background here: https://files.rb.gd/mojave_dynamic.zip - Rename the extracted folder as \u0026#34;mojave-background\u0026#34; (Excuse the trouble but I renamed it on my machine and already use that path in the XML file) - Save this xml file next to the Mojave background files - Fix the path to the background images below (better using absolute path) - Lastly, either: + GNOME: Use gnome-tweaks tool to select this XML as wallpaper (as default wallpaper settings won\u0026#39;t let you choose wallpaper from custom path) + MATE: Go to background setting (in Appearance) \u0026gt; Choose +Add... \u0026gt; make sure **All files** filter is selected at the bottom right \u0026gt; Then choose mojave.xml --\u0026gt; \u0026lt;background\u0026gt; \u0026lt;starttime\u0026gt; \u0026lt;year\u0026gt;2014\u0026lt;/year\u0026gt; \u0026lt;month\u0026gt;01\u0026lt;/month\u0026gt; \u0026lt;day\u0026gt;11\u0026lt;/day\u0026gt; \u0026lt;hour\u0026gt;0\u0026lt;/hour\u0026gt; \u0026lt;minute\u0026gt;00\u0026lt;/minute\u0026gt; \u0026lt;second\u0026gt;00\u0026lt;/second\u0026gt; \u0026lt;/starttime\u0026gt; \u0026lt;!-- 00:00 --\u0026gt; \u0026lt;static\u0026gt; \u0026lt;duration\u0026gt;10795.0\u0026lt;/duration\u0026gt; \u0026lt;file\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_15.jpeg\u0026lt;/file\u0026gt; \u0026lt;/static\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;5.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_15.jpeg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_16.jpeg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;!-- 03:00 --\u0026gt; \u0026lt;static\u0026gt; \u0026lt;duration\u0026gt;10795.0\u0026lt;/duration\u0026gt; \u0026lt;file\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_16.jpeg\u0026lt;/file\u0026gt; \u0026lt;/static\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;5.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_16.jpeg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_1.jpeg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;!-- 05:00 --\u0026gt; \u0026lt;static\u0026gt; \u0026lt;duration\u0026gt;3595.0\u0026lt;/duration\u0026gt; \u0026lt;file\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_1.jpeg\u0026lt;/file\u0026gt; \u0026lt;/static\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;5.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_1.jpeg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_2.jpeg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;!-- 06:00 --\u0026gt; \u0026lt;static\u0026gt; \u0026lt;duration\u0026gt;3595.0\u0026lt;/duration\u0026gt; \u0026lt;file\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_2.jpeg\u0026lt;/file\u0026gt; \u0026lt;/static\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;5.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_2.jpeg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_3.jpeg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;!-- 07:00 --\u0026gt; \u0026lt;static\u0026gt; \u0026lt;duration\u0026gt;3595.0\u0026lt;/duration\u0026gt; \u0026lt;file\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_3.jpeg\u0026lt;/file\u0026gt; \u0026lt;/static\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;5.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_3.jpeg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_4.jpeg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;!-- 08:00 --\u0026gt; \u0026lt;static\u0026gt; \u0026lt;duration\u0026gt;3595.0\u0026lt;/duration\u0026gt; \u0026lt;file\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_4.jpeg\u0026lt;/file\u0026gt; \u0026lt;/static\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;5.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_4.jpeg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_5.jpeg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;!-- 09:00 --\u0026gt; \u0026lt;static\u0026gt; \u0026lt;duration\u0026gt;3595.0\u0026lt;/duration\u0026gt; \u0026lt;file\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_5.jpeg\u0026lt;/file\u0026gt; \u0026lt;/static\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;5.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_5.jpeg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_6.jpeg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;!-- 10:00 --\u0026gt; \u0026lt;static\u0026gt; \u0026lt;duration\u0026gt;3595.0\u0026lt;/duration\u0026gt; \u0026lt;file\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_6.jpeg\u0026lt;/file\u0026gt; \u0026lt;/static\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;5.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_6.jpeg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_7.jpeg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;!-- 11:00 --\u0026gt; \u0026lt;static\u0026gt; \u0026lt;duration\u0026gt;7195.0\u0026lt;/duration\u0026gt; \u0026lt;file\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_7.jpeg\u0026lt;/file\u0026gt; \u0026lt;/static\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;5.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_7.jpeg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_8.jpeg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;!-- 13:00 --\u0026gt; \u0026lt;static\u0026gt; \u0026lt;duration\u0026gt;3595.0\u0026lt;/duration\u0026gt; \u0026lt;file\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_8.jpeg\u0026lt;/file\u0026gt; \u0026lt;/static\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;5.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_8.jpeg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_9.jpeg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;!-- 14:00 --\u0026gt; \u0026lt;static\u0026gt; \u0026lt;duration\u0026gt;3595.0\u0026lt;/duration\u0026gt; \u0026lt;file\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_9.jpeg\u0026lt;/file\u0026gt; \u0026lt;/static\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;5.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_9.jpeg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_10.jpeg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;!-- 15:00 --\u0026gt; \u0026lt;static\u0026gt; \u0026lt;duration\u0026gt;3595.0\u0026lt;/duration\u0026gt; \u0026lt;file\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_10.jpeg\u0026lt;/file\u0026gt; \u0026lt;/static\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;5.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_10.jpeg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_11.jpeg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;!-- 16:00 --\u0026gt; \u0026lt;static\u0026gt; \u0026lt;duration\u0026gt;3595.0\u0026lt;/duration\u0026gt; \u0026lt;file\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_11.jpeg\u0026lt;/file\u0026gt; \u0026lt;/static\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;5.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_11.jpeg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_12.jpeg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;!-- 17:00 --\u0026gt; \u0026lt;static\u0026gt; \u0026lt;duration\u0026gt;3595.0\u0026lt;/duration\u0026gt; \u0026lt;file\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_12.jpeg\u0026lt;/file\u0026gt; \u0026lt;/static\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;5.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_12.jpeg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_13.jpeg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;!-- 18:00 --\u0026gt; \u0026lt;static\u0026gt; \u0026lt;duration\u0026gt;7195.0\u0026lt;/duration\u0026gt; \u0026lt;file\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_13.jpeg\u0026lt;/file\u0026gt; \u0026lt;/static\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;5.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_13.jpeg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_14.jpeg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;!-- 20:00 --\u0026gt; \u0026lt;static\u0026gt; \u0026lt;duration\u0026gt;10795.0\u0026lt;/duration\u0026gt; \u0026lt;file\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_14.jpeg\u0026lt;/file\u0026gt; \u0026lt;/static\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;5.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_14.jpeg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/home/thanh/Pictures/wallpapers/mojave-background/mojave_dynamic_15.jpeg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;/background\u0026gt;  最好先根据图片数量，将时间段划分出来，之后再编写代码。时间段划分可以参考日出日落时间表。 ~~更进一步，用 ffmpeg 创建足够多的帧，Dynamic Wallpaper 或许可以变成 Video Wallpaper 了，~~经过测试，时间精度也限定为 0.1s，所以并不适合做为 Video Wallpaper。 overlay 和 5.0 的使得过渡非常自然。  Light and Dark Wallpaper 2022-04-13 23:38\n 一份简单的指南：如何针对 GNOME 桌面环境来创建你的自定义的深色和浅色壁纸。\n GNOME 42 将备受期待的深浅主题带到 GNOME 桌面环境。它也带来壁纸的深色和浅色版本，当你切换深色或浅色主题时，它会自动地转换。\n因此，默认情况下，GNOME 给予你一套预配置的深色和浅色壁纸。但是如果你想要在主题更改时自动地转换成另一种不同的壁纸要怎么做呢？\n下面是如何在 GNOME 中配置和创建你自己的深浅壁纸的方法。\n自定义的深浅壁纸   确保你手边有两个版本的壁纸。一般来说，它们应该是标准的 PNG 或 JPG 图像文件。\n  我们需要为我们自己创建一个模式文件。壁纸的自动更换是由 XML 文件处理的，它定义了特定的深色和浅色的背景标记。因此，我们将为壁纸创建我们自己的 XML 文件。\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE wallpapers SYSTEM \u0026#34;gnome-wp-list.dtd\u0026#34;\u0026gt; \u0026lt;wallpapers\u0026gt; \u0026lt;wallpaper deleted=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;name\u0026gt;Default Background\u0026lt;/name\u0026gt; \u0026lt;filename\u0026gt;@BACKGROUNDDIR@/adwaita-l.webp\u0026lt;/filename\u0026gt; \u0026lt;filename-dark\u0026gt;@BACKGROUNDDIR@/adwaita-d.webp\u0026lt;/filename-dark\u0026gt; \u0026lt;options\u0026gt;zoom\u0026lt;/options\u0026gt; \u0026lt;shade_type\u0026gt;solid\u0026lt;/shade_type\u0026gt; \u0026lt;pcolor\u0026gt;#3071AE\u0026lt;/pcolor\u0026gt; \u0026lt;scolor\u0026gt;#000000\u0026lt;/scolor\u0026gt; \u0026lt;/wallpaper\u0026gt; \u0026lt;/wallpapers\u0026gt; 你能够会在这个文件中看到两个标记 – filename 和 filename-dark。这两个 XML 标记包含这两个壁纸的完整的限定的路径（绝对路径）。现在，在这两个标记下添加你的图像文件的路径。\n  把这个文件保存到 /home/\u0026lt;your_name\u0026gt;/.local/share/gnome-background-properties，文件名任意。\n  这样，你就准备好了所有的东西。最后，打开 “设置Settings” 并转到 “外观” 标签页，你应该会看到一个新的壁纸选项。\n选择你自己的自定义的深浅壁纸，尽情享受。\n获取动态壁纸 当然，你必然会想，谁有时间去查找和创建壁纸的日夜版本？这里有一些网站来向你提供预制好的动态壁纸，你可以轻松地下载和安装。\nHow to find and make dynamic Mac wallpapers:\n Dynamic Wallpaper Club 24 Hour Wallpaper Dynwalls  此外，如果你打算从上述网站下载，请记住该网站的图像文件是 heic 格式的，因为这个网站是针对 macOS 的。高效视频编码High-Efficiency Video Coding（HEIC）是苹果的专有的 HEIF（高效图像文件High-Efficiency Image File）专有版本。\n那么，如何在 Linux 系统中转换它们? 好吧，在 Ubuntu 中，你需要一个驱动程序来查看和转换动态的 heic 图像文件。打开一个终端，运行下面的命令开安装驱动程序。\n$ sudo apt install heif-gdk-pixbuf 针对使用 KDE Plasma 的用户（没有这个插件的帮助，Plasma 应用程序就不能打开 heic 格式的图像文件）：\n$ sudo apt install qt-heif-image-pluginsudo dnf install qt-heif-image-plugin Convert HEIC   using heif-convert\n$ sudo apt install libheif-examples $ heif-convert input.HEIC output.JPG 后面发现解压文件的序号与图片的播放顺序不一致，因此需要预览图来对照调整顺序——图片少也不难，图片多的话，也不是全部都打乱了，只是一两张顺序而已。\n  using ImageMagick：\n22.04.1 仓库 ImageMagick 6.9.11 版本低了，只能转换成一张 png，因此使用官网 portable 版本：\n$ ./magick convert burst.heic output.jpg convert: no decode delegate for this image format `HEIC\u0026#39; @ error/constitute.c/ReadImage/741. convert: no images defined `output.jpg\u0026#39; @ error/convert.c/ConvertImageCommand/3342. 需要手动编译以支持HEIC\n  HEIF metadata   使用 libheif(depend by heif-gdk-pixbuf package) 提供的 heif-info 工具，heif-info file.heif 可以列出每个图片简略信息（没啥用），heif-info -d file.heif 可以列出 low-level 信息：\n 每个 item_type: grid 就是照片起始位置，会发现其 item_ID 与 heif-info file.heif 输出一致。    参考 wallutils 的 issue：Support macOS dynamic wallpapers\nYou can inspect this metadata with the following steps:\n$ sudo apt install libimage-exiftool-perl $ exiftool wallpaper.heic Under the key \u0026ldquo;Solar\u0026rdquo; there\u0026rsquo;s a base64 encoded plist file. You can decode this with:\n$ sudo apt install libplist-utils $ echo \u0026#34;[Base64 string]\u0026#34; | base64 -d - | plistutil 所谓 Solar，参考制作 MacOS Dynamic Wallpaper 的开源项目 wallpapper 的博客文章 macOS Mojave dynamic wallpapers (II)：Thanks to altitude and azimuth w exactly know where the Sun was when image was taken. This idea is brilliant, because thanks to this information macOS can change images differently during Summer and during Winter. System knows where the Sun is and it will choose image which was taken in similar conditions. Brilliant.（即，计算机以拍照者的视角展示照片）\n最终 wallutils 是部分完成了这个功能了，使用了 xyproto/heic 这个库，实现在这里，可以解析 H24 时间格式，但是不能解析 Solar 格式的。其实就是乘个 24 就得出时钟了。我的方法是 24 乘以最小的数值，得出初始时间放入 \u0026lt;starttime\u0026gt;，以该时间对应的照片开头（合理即可），按照照片数量等分 24 小时放入 \u0026lt;duration\u0026gt;。\nSolar 话我这里我简单地计算（复杂的不会啊！😂）：观察 azimuth，找到第一个 0°～180°的数值（天体上升，180°～360° 天体下降），将其乘以 24 / 360，得出其初始时间，放入 \u0026lt;starttime\u0026gt;，然后以该时间对应的照片开头（合理即可），按照照片数量等分 24 小时放入 \u0026lt;duration\u0026gt;。\n  Real world examples\nmojave-timed.xml：还可以这样写，全部都是 transition，没有 static 部分\n\u0026lt;background\u0026gt; \u0026lt;starttime\u0026gt; \u0026lt;year\u0026gt;2000\u0026lt;/year\u0026gt; \u0026lt;month\u0026gt;01\u0026lt;/month\u0026gt; \u0026lt;day\u0026gt;01\u0026lt;/day\u0026gt; \u0026lt;hour\u0026gt;01\u0026lt;/hour\u0026gt; \u0026lt;minute\u0026gt;00\u0026lt;/minute\u0026gt; \u0026lt;second\u0026gt;00\u0026lt;/second\u0026gt; \u0026lt;/starttime\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;14400.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-0100.jpg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-0500.jpg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;3600.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-0500.jpg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-0600.jpg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;3600.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-0600.jpg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-0700.jpg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;3600.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-0700.jpg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-0800.jpg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;3600.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-0800.jpg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-0900.jpg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;3600.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-0900.jpg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-1000.jpg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;3600.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-1000.jpg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-1100.jpg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;3600.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-1100.jpg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-1200.jpg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;4800.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-1200.jpg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-1320.jpg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;4800.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-1320.jpg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-1440.jpg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;4800.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-1440.jpg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-1600.jpg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;4800.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-1600.jpg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-1720.jpg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;4800.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-1720.jpg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-1840.jpg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;4800.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-1840.jpg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-2000.jpg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;3600.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-2000.jpg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-2100.jpg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;transition type=\u0026#34;overlay\u0026#34;\u0026gt; \u0026lt;duration\u0026gt;14400.0\u0026lt;/duration\u0026gt; \u0026lt;from\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-2100.jpg\u0026lt;/from\u0026gt; \u0026lt;to\u0026gt;/usr/share/backgrounds/gnome/mojave/mojave_dynamic-0100.jpg\u0026lt;/to\u0026gt; \u0026lt;/transition\u0026gt; \u0026lt;/background\u0026gt; 視頻動壁紙 1 Feb, 2022\n日常使用的話，我是不會去碰動態壁紙之類的東西，因爲這些東西很影響我的注意力，而且這也沒多大的必要。但你十分喜歡這種十分炫酷的視頻動態壁紙的話，希望這篇東西可能可以幫到你吧。\n舉個例子：我的屏幕大小是 3440 x 1440 ，使用 這個視頻 作爲動態壁紙\n命令如下:（參數就看你需求改就是了這裏只是演示一下）\n$ xwinwrap -g 3440x1440 -ni -s -nf -b -un -ov -fdt -argb -- mpv -wid WID --ao=null --loop=inf --stop-screensaver=no --script-opts=ytdl_hook-ytdl_path=yt-dlp \u0026#34;https://www.youtube.com/watch?v=n9w_hZkbfoo\u0026#34; 注：因爲 youtube-dl 下載太慢這裏使用 youtube-dl 的一個 fork yt-dlp\n如果你是要播放本地視頻，那麼改爲：\n$ xwinwrap -g 3440x1440 -ni -s -nf -b -un -ov -fdt -argb -- mpv -wid WID --ao=null --loop=inf --stop-screensaver=no $VIDEO_PATH Social Telegram 先通过手机登录，再在电脑端登录。电脑先登录，手机老是收不到验证码。\n简介   Telegram —— 中文名又称\u0026quot;电报\u0026quot;，或简称\u0026quot;TG\u0026quot;。\n  Telegram 是跨平台的即时通信软件，其客户端是自由及开放源代码软件，但服务器是专有软件。\n  Telegram 在中国大陆境内无法直接连接，注册和使用都需要科学上网，请自备节点和工具。\n  下载：Telegram 有官方版和第三方版本，但出于安全和隐私的考虑，推荐大家使用 Telegram 官方版客户端\n  推荐设置  Privacy and Security  Phone Number  谁能看见我的手机号码：Nobody 谁能通过手机号码找到我：My Contacts   Forwarded Messages：Nobody Calls：Nobody Groups：My Contacts   Local Passcode：本地密码只是本设备打开 Telegram 的应用密码 Two-Step Verification：为了账号安全，强烈推荐您设置两步验证密码。 Delete my account：推荐您设置为一年  隐私保护注意事项  资料设置  昵称及用户名：避免使用与其他社交平台相同或相似的昵称及用户名 手机号码：在\u0026quot;设置——隐私——电话号码\u0026quot;中设置\u0026quot;不允许任何人查看我的手机号码\u0026quot;和\u0026quot;仅允许联系人通过手机号码找到我\u0026quot;。   群组聊天：Telegram 的群聊是\u0026quot;不安全\u0026quot;的。 公开群组的所有聊天内容都可被其他人查看，即使他人并未注册 Telegram； 对于群组内的机器人，它们可以收集群组内的绝大部分消息。 媒体文件：在分享照片时，请注意使用专业修图软件打码处理关键信息，并清除照片包含的地理位置信息 分享链接：从其他平台分享内容至 Telegram 时，请注意清除分享链接中的用户 UserID 识别信息，他人完全有可能从您的分享链接中获取您的用户信息。 第三方客户端：如无特殊需要，请使用官方 Telegram 客户端。第三方客户端有能力获取和控制您的账户，读取您全部的聊天记录，收集您设备的可识别信息，包括但不限于：手机号、设备型号、IMEI码、MAC码等。  常见问题及解答  无法给他人发送私聊：“Sorry, you can only send messages to mutual contacts at the momet.”  @SpamBot But I can\u0026rsquo;t message non-contacts！ No，I\u0026rsquo;ll never do any of this   群组和频道有什么类型？有什么特点？  群组(Group)或者频道(Channel)有两种类型。  一种是公开群组(Public Group/Channel) 一种是私有群组(Private Group/Channel)   公开群组(Public Group/Channel) 有自定义设置的ID，所有人可以通过搜索功能，输入id查询到相应的群组。公开群组的历史消息对所有人可见，即使没加入公开群组，也可以查看群组历史消息。 私有群组(Private Group/Channel) 没有自定义的ID，要加入只能通过点击邀请链接或者被邀请入群， 在私有群组，群主可以设定历史消息的可见性。而对于没有加入群组的人，则不可以查看群组的消息。   Telegram 用户名是什么？  其他用户可以通过用户名找到您，您将出现在“全局结果”下的联系人搜索中。这样人们就可以在不知道您的电话号码的情况下通过 Telegram 与您联系。 由于用户名的唯一性，可以防止他人盗用你的头像和昵称冒充你。   如何添加联系人？：添加和删除联系人都是单向操作，对方设备并不会同步。 添加非手机号码联系人后，对方能知道自己的手机号码吗？：如果想取消分享你的手机号，请到隐私设置(Privacy and Security)中找到手机号码(Phone Number)的设置，在里面移除对方即可。 不登陆 Telegram 如何查看频道消息？：Telegram 公开频道可以直接通过浏览器输入 https://t.me/s/频道id 访问，不需要拥有TG账号。  进阶知识 什么是 MTProxy 代理？\n MTProxy 是 Telegram 的官方项目，仅能用于代理 Telegram 软件 MTP 代理是在 Telegram 中内置的代理程序，可以直接在软件内配置，而不需要下载任何其他 App 来配置代理  主题与美化 美化主题频道\n 官方 Desktop 桌面版主题频道 @themes 官方 Android 安卓主题频道 @Androidthemes  Sticker Pack 用现成的图片集来制作 stickers pack。Linux 可以方便地使用 ImageMagick 来操作。\nTelegram 要求 Sticker 图片为 PNG 格式，并且要有透明层，至少一边为 512 像素，另一边则不超过 512 像素。最大文件大小为 350KB。透明层就算了，我不会玩 PS。那么直接偷懒(死)来批量把当前目录下 JPG 和 PNG 混杂的图片们统一转换为 PNG 好了。\n几条命令发给 stickers bot：\n /newstickerpack 发送表情包的名字… 在内置的 emoji 中发送一个最符合你要发送图片的表情… 然后把对应的图片作为文件发送 如果还有其他图片的话重复 3-4 全部表情图片设置完毕，发送 /publish 命令 为你的 stickers pack 取一个短名字 (用于 URL)  使用EFB推送QQ与微信消息 导出 Telegram 贴图 教程：不能导出动态sticker。\n这只 bot 在这里（新的@ygmxstickersetbot），源码在这里。\n默认 Desktop [Desktop Entry] Version=1.5 Name=Telegram Desktop Comment=Official desktop version of Telegram messaging app TryExec=/home/kurome/.telegram/Telegram Exec=/home/kurome/.telegram/Telegram -workdir /home/kurome/.local/share/TelegramDesktop/ -- %u Icon=telegram Terminal=false StartupWMClass=TelegramDesktop Type=Application Categories=Chat;Network;InstantMessaging;Qt; MimeType=x-scheme-handler/tg; Keywords=tg;chat;im;messaging;messenger;sms;tdesktop; Actions=Quit; SingleMainWindow=true X-GNOME-UsesNotifications=true X-GNOME-SingleWindow=true [Desktop Action Quit] Exec=/home/kurome/.telegram/Telegram -workdir /home/kurome/.local/share/TelegramDesktop/ -quit Name=Quit Telegram Icon=application-exit xdg-open xdg-open opens a file or URL in the user's preferred application. If a URL is provided the URL will be opened in the user's preferred web browser. If a file is provided the file will be opened in the preferred application for files of that type. xdg-open supports file, ftp, http and https URLs. 在设置了默认 desktop 文件后，在浏览器中点击 JOIN GROUP 依旧打不开 Telegram，有如下报错：\n$ xdg-open tg://join?invite=xxxx gio: tg://join?invite=xxxx: The specified location is not supported 参考xdg-open doesn\u0026rsquo;t recognize custom protocol解决：\n$ xdg-mime default telegram.desktop x-scheme-handler/tg Telegram 充當雲端筆記 Telegram本身有非常多的新闻、咨询以及网友们非常有深度的讨论，因此可以通过Saved Message或者建立群组频道来转存感兴趣的信息。farseerfc 的小窝 就有一个。\n中文搜索 问题在哪 Telegram 群组和频道越来越多，消息也越来越多，但是搜索中文的消息却是一个很大的问题。\n主要原因\nTelegram 的搜索是以”词”为基础单位的，是以英文标点符号或空格作为”词”的间隔。\n这是以英文为基础的搜索方式，这样的方式对于英文的搜索就很方便，比如”hello”，用”he”就搜索不到，必须用”hello”，这就符合英文的语境，当我想要找”he”消息时并不想看到有”hello”的消息。\n但是这种方式对于中文等语言来说就很不方便，中文是以字为单位的，按照上面的方式，比如消息内容”动态贴纸不能用这个bot导出”用”贴纸”或”导出”就不能搜索到此消息。\n如何解决 知道问题出在哪儿？那又如何解决呢？ 解决方案：\n 发消息时以英文标点符号或空格作为间隔，比如消息”动态贴纸不能用这个bot导出”，可以用”动态 贴纸 不能 用这个 bot 导出”方法发出，这样就可以用”动态”“贴纸”“不能”“导出”关键词搜索到此消息。 发消息时可以加’tag’，比如想发送消息”ABCDEFG”，可以发送”#tag ABCDEFG”，下次可以用”#tag”关键词搜索找到都有这个标签的消息。 已发的消息，以标点符号或空格作为间隔单位搜索，比如”好像国区是没有，点链接提示转到国区，关掉就好了，账号可以在不同地区购买”，可以用”好像国区是没有”“点链接提示转到国区”“关掉就好了”“账号可以在不同地区购买”关键词搜索到此消息。  冻屏 Alex Fish, [17/08/2022 3:55 PM] 就点击不了，就拖动啊，super+鼠标拉，虽然快捷键也能操作就是了\nAlex Fish, [17/08/2022 3:58 PM] 虽然快捷键也能操作就是了\nBig V, [17/08/2022 3:58 PM] Advanced =\u0026gt; Use system window frame Qt窗口绘制的锅\nProfile Videos 20220820 暂时只有手机支持。\nMutt Mutt 是一个基于文本的邮件客户端，因其强大的功能而闻名。 Mutt虽然已诞生二十多年了，但仍然是大量用户的首选邮件客户端。\nMutt主要侧重于作为邮件用户代理（MUA），最初是为了查看邮件而编写的。 与其他邮件应用程序相比，稍后实现的功能（检索，发送和过滤邮件）比较简单，因此用户可能希望使用外部应用程序来扩展Mutt的功能。\n模块搭配方案 就像穿衣搭配一样，收件发件过滤邮件转发邮件各种功能都有很多种程序可以用，mutt怎么搭配呢？\n常用选项有这些(User/Transport/Delivery)：\n MUA 收件：fetchmail或getmail或OfflineIMAP MTA 发件：sendmail或msmtp或postfix。其中msmtp兼容强，postfix对国内不友好 MDA 分类: procmail或maildrop 邮件编辑：VIM。  一般搭配是：\n 老式搭配：mutt + getmail + sendmail + procmail 新式搭配：mutt + fetchmail + msmtp + maildrop  这里我们用：mutt + fetchmail + msmtp + procmail\n安装：\n$ sudo apt install mutt fetchmail msmtp procmail -y Mutt或各个写协作程序在配置前都是不能使用的，学习曲线还是比较陡峭的，所以要做好准备去花好一段去了解和学习各个部件。\n大概的配置流程是：\n 配置收件：~/.fetchmailrc 配置过滤：~/.procmailrc 配置发件：~/.msmtprc 配置mutt框架本身：~/.muttrc  注意：初学过程中，不要一上来就配置mutt。最好是先从各个部件开始：收件-\u0026gt;过滤邮件-\u0026gt;阅读邮件-\u0026gt;发件-\u0026gt;mutt界面，按照这种顺序。\n收件：配置Fetchmail  Fetchmail是由著名的《大教堂与集市》作者 Eric Steven Raymond 编写的。\n Fetchmail是一个非常简单的收件程序，而且是前台运行、一次性运行的，意思是：你每次手动执行fetchmail命令，都是在前台一次收取完，程序就自动退出了，不是像一般邮件客户端一直在后台运行。\n注意：fetchmail只负责收件，而不负责存储！所以它是要调用另一个程序如procmail来进行存储的。\nfetchmail的配置文件为~/.fetchmailrc。然后文件权限最少要设置chmod 600 ~/.fetchmailrc\n比如我们要设置多个邮箱账户同时收取，那么配置如下：\npoll pop.AAA.com protocol POP3 user \u0026#34;me@AAA.com\u0026#34; password \u0026#34;123\u0026#34; poll pop.BBB.com protocol POP3 user \u0026#34;me\u0026#34; there with password \u0026#34;123\u0026#34; is falko here fetchall poll pop.CCC.com protocol POP3 user \u0026#34;me\u0026#34; there with password \u0026#34;123\u0026#34; is till here keep poll pop.DDD.com protocol POP3 user \u0026#34;me\u0026#34; password \u0026#34;123\u0026#34; ## QQ 邮箱 poll pop.qq.com port 995 protocol POP3 user \u0026#34;1664548605@qq.com\u0026#34; password [授权码] ssl keep # 全局选项 mimedecode # 不加 -d %T 就会报 ~/Mail/inbox is not a mailbox. 错误 mda \u0026#34;/usr/bin/procmail -d %T\u0026#34; 其中：\n 各种参数可以不按顺序，也可以不在一行。 空格隔开每个参数，poll隔开每个账户。 here, there, with, is等等，都不是关键词，随便写不影响参数。 以下是必填  poll后面是邮件服务器的地址，一般是pop.xxx.com protocol后面是收件协议，一般是pop或pop3 user后面是用户名，可以是username，也可以是邮箱地址 password后面是密码   sslproto：可能会报错 fetchmail: pop.qq.com: upgrade to TLS failed.，故可以禁掉SSL，同 man 手册查到  加上option --nosslcertck，虽然有报错，但至少可以收邮件了。 加--sslprotocl '', 注意要用空字符串   四选一：  nofetchall ：仅检索新消息（默认）。 fetchall ：获取所有消息，无论是否看到。 keep ：不要从服务器上删除看到的消息。 nokeep ：从服务器中删除看到的消息。   mimedecode用来自动解码MIME mda后面指定本机安装的邮件过滤分类程序。如果不填，则收取的邮件在本地不会保存。注意用which procmail查一下路径。 Outlook 邮件客户端设置 Gmail 邮件客户端设置 QQ 邮件客户端设置 163 邮件客户端设置  配置完成后，可以运行fetcmail -v来看看是否有错误信息，如果能够正常显示很多行的收取信息，那么就能正确登录邮箱收取了。\n一般收取的命令如下：\n# 只收取未读邮件 $ fetchmai # 收取所有邮件 $ fetchmail -a # （重要）收取新邮件，但不在服务器端删除已经收取的邮件 $ fetchmail -k 但是fetchmail只负责收取，不负责“下载”部分，你找不到邮件存在哪了。 所以还需要配置MDA分类器，如procmail，才能看到下载后的邮件。\n注意：Fetch其实不是在Mutt“里”使用的，而是脱离mutt之外的！也就是说，Mutt只负责读取本地存储邮件的文件夹更新，而不会自动帮你去执行fetchmail命令。\n你必须自己手动执行，或者用Crontab定期收取，或者设为Daemon守护进程，还可以在Mutt中设置快捷键执行Shell命令：\n  要使fetchmail作为守护进程运行，我们必须编辑/etc/default/fetchmail并将START_DAEMON设置为yes\n$ vi /etc/default/fetchmail START_DAEMON=yes xxxxxxxxxx yum -y install tigervnc-servershell\n  设置Mutt快捷键收取邮件的方法是在~/.muttrc中加入macro：\nmacro index,pager I \u0026#39;\u0026lt;shell-escape\u0026gt; fetchmail -vk\u0026lt;enter\u0026gt;\u0026#39; 这样的话，你就可以在index邮件列表中按I执行外部shell命令收取邮件了。\n  邮件过滤：配置Procmail Procmail是单纯负责邮件的存储、过滤和分类的，一般配合fetchmail收件使用。\n在Pipline中，fetchmail把收到的邮件全部传送到Procmail进行过滤筛选处理，然后Procmail就会把邮件存到本地形成文件，然后给邮件分类为工作、生活、重要、垃圾等。\n当然，分类规则是自己可以指定的。可以根据发信人、主题、长度以及关键字 等对邮件进行排序、分类、整理。\nProcmail 的配置文件是 ~/.procmailrc ，记得改权限：chmod 600 ~/.procmailrc。\n内容也非常简单，前面是邮件位置、日志等默认选项，后面则是一块一块的过滤规则。\n基本配置：\n# 邮件存储地址 MAILDIR=$HOME/Mail # 默认：收件箱 DEFAULT=$MAILDIR/inbox VERBOSE=off LOGFILE=/tmp/procmaillog # 某个垃圾邮件规则 :0 * ^From: webmaster@st\\.zju\\.edu\\.cn # 垃圾文件的存储位置 /dev/null # 其它所有都存到收件箱中 :0: inbox/ 其中，$HOME/Mail是设定的邮件存储位置。\n我们需要手动创建mkdir ~/Mail，否则程序会报错。\n配置好后，我们再测试一下就会看到：\n$ fetchmail -a 78 messages for 1664548605@qq.com at pop.qq.com (2843793 octets). reading message 1664548605@qq.com@pop.qq.com:1 of 78 (36692 octets) not flushed ... $ tree ~/Mail /home/vane/Mail └── inbox 0 directories, 1 file $ du -h Mail/inbox 2.1M Mail/inbox 可以看到，所有邮件都保存在了inbox这个单一文件中。这个文件可以打开看到MIME格式(协议)的邮件源码。就像HTML一样，展示给我们的和背后的源码不一样。\n那么怎么把这个类似HTML的MIME格式邮件解析为我们人能读懂的内容呢？——这个我们就要靠mutt自己了，mutt自身具备基本的MIME邮件解析功能（不包括HTML格式邮件读取）。\n发件：配置msmtp msmtp是作为sendmail发邮件程序更好的替代品。\nmsmtp的配置文件为~/.msmtprc，记得改权限：chmod 600 ~/.msmtprc\n配置内容比收件还简单，因为发件永远比收件简单。\n基本配置：\naccount default auth login host smtp.XXX.com port 587 from ME@XXX.com user ME password passwd # 关于tls，如果是阿里云则不用写，如果是Outlook的话，必须写 tls on tls_starttls off tls_certcheck off # QQ 邮箱例子 account default # QQ邮箱这里必须是 on，否则会 535 Login Fail auth on host smtp.qq.com port 587 from 1664548605@qq.com # user 必须是 @ 之前的部分，不能自定义，否则会 535 Login Fail user 1664548605 password [授权码] tls on tls_starttls off tls_certcheck off logfile /tmp/msmtp.log QQ 邮箱例子：使用mutt+msmtp在Linux命令行界面下发邮件。\n总之，哪怕QQ 邮箱设置对了，也要多试几次才能发送成功。\n主界面：配置Mutt Mutt的配置文件为~/.muttrc，记得改权限：chmod 600 ~/.muttrc\n另外：mutt的配置文件还可以放在~/.mutt/muttrc。这种方法有一个好处，即~/.mutt/目录下可以放很多主题、插件等文件。\n基本配置：\n# 通用设定 set use_from=yes set envelope_from=yes #移动已读邮件 set move=yes #回复的时候调用原文 set include set charset=\u0026#34;utf-8\u0026#34; #自动显示HTML auto_view text/html # 发送者账号 set realname=\u0026#34;Vane Hsiung\u0026#34; set from=\u0026#34;1664548605@qq.com\u0026#34; # 分类邮箱 #Mail box type set mbox_type = Maildir set folder = \u0026#34;$HOME/Mail\u0026#34; #INBOX set spoolfile = \u0026#34;$HOME/Mail/inbox\u0026#34; #Seen box set mbox=\u0026#34;$HOME/Mail/seen\u0026#34; #Sent box set record=\u0026#34;$HOME/Mail/sent\u0026#34; #Draft box set postponed=\u0026#34;$HOME/Mail/draft\u0026#34; # 关联程序（需要自己用which命令确定一下） # 默认使用 nano set editor=\u0026#34;vim\u0026#34; set sendmail=\u0026#34;/usr/bin/msmtp\u0026#34; 以上如果有什么问题，可参考etchmail + proc + msmtp + mutt configuration samples。\n确认邮箱服务器 即使上面配置一切OK，也不一定能正常收发邮件。因为你用的Gmail、QQ、网易、阿里云等等，后台都有一系列的第三方收取设置。这是各不相同的。\n除了第三方客户端的允许，我们还要设置POP。最好放开全部邮件或者最近30天，然后禁止客户端删信。这是什么意思呢？POP默认客户端在收件后，服务器上的邮件就自动删除了！这个不太合适，所以必须要禁止。\n基本操作 邮件列表操作：\n 基本：q:Quit, d:删除当前邮件, s:将邮件移动至指定文件夹, m:创建新邮件, r:回复当前邮件, ?:帮助 移动：j/k 上下移动邮件, z/Z上下翻页, \u0026lt;Number\u0026gt; 跳至序号处（不进入邮件） \u0026lt;Enter\u0026gt; 打开选中的邮件 /在当前文件夹搜索 d 将选中邮件标记为删除, N 将选中邮件标记为未读, $ 让标记的东西生效，如删除、未读等。 f 转发选中邮件, e 编辑选中邮件 c切换文件夹(inbox/seen/draft等), 需要输入文件夹名称，或按?在列表里选择，j/k上下移动。  在邮件中的操作：\n j/k 上一封／下一封邮件, \u0026lt;Space\u0026gt;: 向下翻页, \u0026lt;Enter\u0026gt;: 向下滚动 e 编辑当前邮件, t编辑TO，c编辑CC，b编辑BCC，y发送邮件，a添加附件，Return查看附件，E编辑附件，D删除附件  使用命令操作：\nMutt如同Vim一样，不光可以把命令绑定为快捷键，还能直接输入:直接输入命令。 但是稍有不同的是，Mutt称之为Action，而且需要用:exec \u0026lt;命令\u0026gt;这样格式执行。\n比如sidebar侧边栏的移动，命令是：sidebar-next, sidebar-prev。 那么我们可以直接输入:exec sidebar-next，按下回车执行。\nIRC 简介 芬兰人雅尔可·欧伊卡利宁（Jarkko Oikarinen）于1988年8月创造了IRC来取代一个叫做MUT的程序。\n IRC（Internet Relay Chat的缩写，“因特网中继聊天”）是一个位于应用层的协议。 其主要用于群体聊天，但同样也可以用于个人对个人的聊天。 一个IRC服务器可以连接其他的IRC服务器以扩展为一个IRC网络。 IRC 不强制注册；但如果你注册了，就可以强制把占用自己唯一 ID 的人踢下线。 IRC 协议简单，开源实现多，其第三方机器人程序非常众多，几乎每种语言都有一个实现。 IRC 是开源社区会议标准；因此，许多开源世界的技术大牛混在那里。  irchelp：一个致力于帮助用户了解IRC的网站。\nIRC：Linux文档项目的IRC HOWTO\n服务器 首先要区分一些概念：\n Networks：是指的互相隔离的网络，如Freenode和DALnet这些是世界知名的网络，但互相隔离，频道不共享。 Servers：Network网络中的某一台电脑服务器，你加入世界上任何一个server都能加入这个Network。IRC是一个分布式的客户端/服务器结构。通过连接到一个IRC服务器，我们可以访问这个服务器以及它所连接的其他服务器上的频道（即这个 Network 中所有频道）。  频道存在于一个IRC服务器上。一个频道类似于一个聊天室，频道名称必须以#符号开始，例如#irchelp。\n要使用IRC，必须先登录到一个IRC服务器上，最常见的为irc.freenode.net——最大的IRC网络，为免费和开源软件社区，非营利组织和相关社区提供讨论设施。\nFreenode 用户模式。\nIRC使用的服务器端口有:\n 6667（明文传输，如irc://irc.freenode.net） 6697（SSL加密传输，如ircs://irc.freenode.net:6697）。  IRCD: 简称互联网中继聊天守护，是服务器软件实现了IRC 协议，使人们通过上网彼此交谈（交换文本即时消息）。\n客户端 IRC用户透过客户端软件和服务器相连。\n Internet Relay Chat客户端的比较 IRCv3 Client Support  常用客户端：\n   Client Homepage 描述     HexChat https://hexchat.github.io/ 基于XChat的图形化IRC客户端。   Irssi https://irssi.org/ 支持IPv6的模块化文本UI IRC客户端。   Pidgin https://pidgin.im/ 具有GTK +界面的流行即时消息客户端。   WeeChat https://weechat.org/ 便携式和多接口（文本，Web和GUI）IRC客户端。   Konversation https://konversation.kde.org/ 基于KDE框架的用户友好型IRC客户端。   Polari https://wiki.gnome.org/Apps/Polari GNOME的IRC客户端   ircii http://eterna.com.au/ircii/ 在大多数UNIX平台下运行的IRC和ICB客户端。   kvirc http://www.kvirc.net/ 使用Qt GUI工具包的便携式IRC客户端。   Quassel https://quassel-irc.org/ Qt5 IRC客户端支持远程守护进程以实现全天候连接    Irssi 安装\n$ apt install irssi 命令行输入irssi即进入了聊天室。\n和一般Linux程序的一般命令、格式都不同，IRC客户端一般有自己的命令。窗口右下方[(status)]是输入命令的地方。\n一般命令(不区分大小写)：\n /quit，退出程序。一般的ctrl-c, ctrl-d, esc, q之类的都不管用 /help，帮助 /network list 查看已保存的服务器列表 /connect xxx.xxx.xxx 连接某服务器。连接 freenode，需要到 https://irc.com/login/sso 注册，然后按照 https://freenode.net/kb/answer/sasl 进行设置。 /join xxx 加入某channel /leave或/part 离开当前channel /normal或/n 查看当前channel的人数 /list -YES 查看当前服务器的所有chennels (慎用) /nick NewNickName 更改当前昵称 /msg NickName Content 给某人发送消息，一般都是给/msg nickserv管理人NPC发送消息  常用快捷键：\n Alt + 1/2/3/4...，切换window窗口，一般一个channel一个窗口 Alt + n/p，上下滚动屏幕  IRC 常用缩写词\n配置\n如果想长期保存、备份一个固定的程序配置，那么就需要修改配置文件。\nirssi默认的配置文件为~/.irssi/config。\n配置中，会在第一次运行时就自动设置了一些，包括根据当前电脑账户的用户名设置nickname等。整个配置，是一直“类似”JSON的格式。\nsettings ：记录自己的名字：nick, real_name, user_name\nservers ：这是指的Network而不是具体某台server，如Freenode、Dal、ESPer、EFnet等大型网络。服务器配置案例：\nservers = ( { address = \u0026#34;irc.dal.net\u0026#34;; chatnet = \u0026#34;DALnet\u0026#34;; port = \u0026#34;6667\u0026#34;; }, { address = \u0026#34;路径\u0026#34;; chatnet = \u0026#34;下面chatnet对应的名称\u0026#34;; port = \u0026#34;端口\u0026#34;; autoconnect = true; use_ssl = \u0026#34;yes\u0026#34;; password = \u0026#34;用户名:密码\u0026#34;; } ); chatnets：记录各个网络的登录信息，也可以作为“别名”，这样每次/connect不用输入全路径了。配置完每个服务器后，还要配置相应的chatnets，每一条的名称都要与servers中的对应。\nchatnets = { DALnet = { type = \u0026#34;IRC\u0026#34;; max_kicks = \u0026#34;4\u0026#34;; max_msgs = \u0026#34;20\u0026#34;;max_whois = \u0026#34;30\u0026#34;; }; Freenode = { type = \u0026#34;IRC\u0026#34;; max_kicks = \u0026#34;4\u0026#34;; max_msgs = \u0026#34;20\u0026#34;;max_whois = \u0026#34;30\u0026#34;; autosendcmd = \u0026#34;/msg nickserv identify MyName MyPassword\u0026#34;; }; }; channels ：记录自己收藏的频道名。RC的频道不是用URL之类很复杂的东西，全都是用#tag这种简单一个标签来区分的，非常好记。\nchannels = ( { name = \u0026#34;#lobby\u0026#34;; chatnet = \u0026#34;EsperNet\u0026#34;; autojoin = \u0026#34;No\u0026#34;; }, { name = \u0026#34;#freenode\u0026#34;; chatnet = \u0026#34;Freenode\u0026#34;; autojoin = \u0026#34;No\u0026#34;; }, ); statusbar：界面美化的设置。目前IRSSI的世界里，唯一知名的主题只有weed。\nMultimedia GStreamer GStreamer 入门概念 Overview GStreamer是一个多媒体框架，它可以允许你轻易地创建、编辑与播放多媒体文件，这是 通过创建带有很多特殊的多媒体元素的管道来完成的。\n管道-pipeline GStreamer的工作方式非常简单，你只需创建一个包含很多元素的管道，这与Linux命令行 的管道非常类似，例如，一般命令行的管道是这样的:\n$ ps ax | grep \u0026#34;apache\u0026#34; | wc -l 这个命令首先捕获一个进程列表然后返回名字包含 “apache” 的进程并传递给 wc 命令并 统计出行数。我们可以看出每一个使用 | 连接，并且 | 左边的命令的输出传递 给其右边的命令作为输入。\nGStreamer的工作方式与此类似，GStreamer中你将很多元素串联起来，每一个元素都完成 某些特定的事。我们来演示一下:\ngst-launch-1.0 filesrc location=越单纯越幸福.mp3 ! decodebin ! audioconvert ! alsasink 运行这条命令你就可以听到动听的音乐了，当然前提是你的当前目录有这个音乐文件。\ngst-launch-1.0 可以用来运行 GStreamer 管道，你只需要将需要使用的元素一个一个 传递给它就可以了，每一个命令使用 ! 来连接。此处你可以把 ! 当作命令行里 的 | 。上面那条命令包含了几个元素，我们简单解释一下：\n filesrc：这个元素从本地磁盘加载了一个文件，使用该元素时你设置了 location 属性指向了音乐文件，关于属性我们后边聊。 decodebin：我们需要从 filesrc 解码，因此我们使用了这个元素。这个元素是一个 聪明的小家伙，它会自动检测文件的类型并在后台构造一些GStreamer元素来解码。因此， 此处对于 mp3 你可以使用 mad 代替之试一下。 audioconvert：一个声音文件中有各种各样的信息，每种信息传递到喇叭都是不同的， 因此要使用此元素来做一下转换。 alsasink：这个元素做的事很简单，就是把你的音频使用ALSA传递给你的声卡。  文章写到这里，我们就可以使用管道来做各种试验了，但首先我们要知道有那些元素可以 使用啊:\n$ gst-inspect-1.0 这个命令列出了可用的元素，你也可以使用该命令查看某一元素的详细信息，例如 filesrc 元素:\n$ gst-inspect-1.0 filesrc 下面介绍一些GStreamer的相关术语，一些人可能很快就会对 pad, cap 这些术语搞晕， 就不要说 bin 和 ghost pad 了。其实这些术语都相当的简单。。。\n元素element 其实我们已经讨论了管道，而元素就在管道上。每一个元素都有很多属性用来设置该元素。 例如， volume 元素（设置管道的音量）有一个熟悉 volume 可以设置音量或者静音。 当你创建自己的管道时就要给很多的元素设置属性。\npad 每一个元素都有虚拟的插头供数据流入和流出，即pad。如果你把元素看作一个对输入的 数据做一些处理的黑盒。在盒子的左右两边就是插孔了，你可以插入电缆向盒子传入信息， 这就是pad要做的事。绝大多数元素有一个输入pad（叫做sink）和一个输出pad(叫做src)。 因此，我们上面的管道看起来是这样的:\n[src] ! [sink src] ! [sink src] ! [sink] 最左边的元素只有一个src pad用来提供信息（如filesrc）。接下来的几个元素接收信息并 做一些处理，因此他们有sink和src pad（例如decodebin和audiocovert），最后一个元素 只接收信息（例如alsasink）。当你使用 gst-inspect-1.0 命令查看一个元素的详细 信息时，就会列出该元素的pad信息。\n注意可能与平时大家认为的概念有些不同的是，src pad是用来发送数据的端点，即数据的 输出端；而sink pad是用来接收数据的端点，即数据的输入端。\n而且，一般来说，src pad只能连接到sink pad。当然，没有例外的规则是不存在的， ghost pad两端就要连接相同类型的pad，具体请参考后面的例子吧。\ncap 我们已经了解了pad和从管道第一个元素到最后一个元素的数据流是怎么回事了，那么我们 来讨论下 cap 。每一个元素都有特定的cap，cap是指该元素可以接收什么样的信息（ 例如是接收音频还是视频）。你可以把cap看成是电源插座上其可以接受什么范围电压的规则。\nbin 很多人不理解bin，其实它很简单。bin就是一种便捷的方式，可以把很多个元素放进一个 容器中。例如你有很多个元素用来解码视频并对其使用一些效果。要使事情变得简单一些， 你可以把这些元素放进一个bin（就像一个容器）中，以后你就可以使用bin来引用这些元素了。 这样其实bin变成了一个元素，例如你的管道是 a ! b ! c ! d ，你可以把他们放进 mybin，这样当你使用mybin时其实是引用了 a ! b ! c ! d 。\nghost pad 当你创建了一个bin并在里面放置了很多元素时，该bin变成了你自定义的元素，该元素按 顺序调用里面的元素。要做到这样，你的bin很自然地需要它自己的pad，它自己的pad会挂接 到bin里面元素的pad上，这就是 ghost pad 了。当你创建一个bin时，你创建了ghost pad 并告诉他们要去挂接里面哪一个元素。\nGStreamer 系列 FFmpeg  powershell 执行与在 cmd 执行不一样，poweshell 某些 -c:v 会报错 ffmpeg 输出参数含义  frame: 编码的帧数量 fps：每秒编码的帧数 q：质量因子 size/ Lsize：视频和音频编码后的大小，即基本等于视频和音频 之和 time：输出帧的显示时间 bitrate：输出视频的比特率 dup：输入帧重复（duplicate）的数量 drop：输入帧丢弃（drop）的个数 speed：编码速度    视频文件本身其实是一个容器（container），里面包括了视频和音频，也可能有字幕等其他内容。\n视频和音频都需要经过编码，才能保存成文件。不同的编码格式（CODEC），有不同的压缩率，会导致文件大小和清晰度的差异。\n编码器（encoders）是实现某种编码格式的库文件。只有安装了某种格式的编码器，才能实现该格式视频/音频的编码和解码。\nFFmpeg 的命令行参数非常多，可以分成五个部分：\n$ ffmpeg [全局参数] [输入文件参数] -i 输入文件 [输出文件参数] [输出文件] 常用参数  -c：指定编码器 -c copy：直接复制，不经过重新编码（这样比较快） -c:v：指定视频编码器 -c:a：指定音频编码器 -i：指定输入文件 -an：去除音频流 -vn： 去除视频流 -preset：指定输出的视频质量，会影响文件的生成速度，有以下几个可用的值 ultrafast, superfast, veryfast, faster, fast, medium, slow, slower, veryslow。 -y：不经过确认，输出时直接覆盖同名文件。  查看视频文件的元信息 $ ffmpeg -i input.mp4 -hide_banner 转换编码格式 $ ffmpeg -i [input.file] -c:v libx264 output.mp4 转成 H.264 编码，一般使用编码器 libx264\n转换容器格式 $ ffmpeg -i input.mp4 -c copy output.mkv 改变分辨率 $ ffmpeg -i input.mp4 -vf scale=720:-1 output.mp4 提取视频 $ ffmpeg -i input.mp4 -an -c:v copy ouput.mp4 -vcodec codec 强制使用codec编解码方式。如果用copy表示原始编解码数据必须被拷贝。\n提取音频 $ ffmpeg -i input.mp4 -vn -c:a copy output.aac -c:a copy表示不改变音频编码，直接拷贝。\n添加音轨 $ ffmpeg -i input.aac -i input.mp4 output.mp4 音视频合成 $ ffmpeg -i video.mp4 -i audio.aac -c:v copy -c:a copy output.mp4 截图 从指定时间开始，连续对1秒钟的视频进行截图\n$ ffmpeg -y -i input.mp4 -ss 00:01:24 -t 00:00:01 output_%3d.jpg 指定只截取一帧\n$ ffmpeg -ss 01:23:45 -i input.mp4 -vframes 1 -q:v 2 output.jpg -vframes 1指定只截取一帧，-q:v 2表示输出的图片质量，一般是1到5之间（1 为质量最高）。\n裁剪 $ ffmpeg -ss [start] -i [input] -t [duration] -c copy [output] $ ffmpeg -ss [start] -i [input] -to [end] -c copy [output] 裁剪（cutting）指的是，截取原始视频里面的一个片段，输出为一个新视频。可以指定开始时间（start）和持续时间（duration），也可以指定结束时间（end）。\n添加字幕  外挂字幕：一个单独的外部字幕文件，格式类型一般有srt、vtt、ass等等。播放视频时，需要把外挂字幕和视频放在同一目录下，并在播放器中选择字幕文件才可以在视频中看到字幕。 软字幕：也叫内挂字幕、封装字幕、内封字幕，字幕流等，就是把前面的外挂字幕的字幕文件嵌入到视频中作为流的一部分，如果一个视频有多个字幕流那么播放视频是还得选择对应的字幕流 硬字幕：是嵌入到视频帧里面的字幕，它就像视频水印一样作为视频帧的一分部分了，不管再任何平台字幕看起来都是一样的，而且也不再要求播放器单独对字母进行渲染  常见的字幕格式有：\n SRT（标准外挂字幕格式）：只包含文字和时间码，没有样式，显示效果由播放器决定，不同的播放器显示出的效果可能差别很大。 ASS（高级外挂字幕格式）：支持样式、字体、字幕定位、淡入淡出、简单的特效。如果不缺字体，不同的播放器显示效果基本一致。  ffmpeg字幕处理流程(容器是否支持字幕流指的是输出容器)\n添加软字幕：\n$ ffmpeg -i video.mp4 -i subtitle.srt -c copy output.mkv 软字幕只有部分容器格式比如(mkv)才支持，MP4/MOV等不支持，而且也只有部分播放器支持软字幕或者外挂字幕(如VLC播放器)。\n添加多个字幕：\nffmpeg -i input.mp4 -i zh_CN.srt -i en_US.srt -map 0:v -map 0:a -map 1 -map 2 -c:v copy -c:a copy -metadata:s:s:0 language=chn -metadata:s:s:1 language=eng \u0026#34;output.mp4\u0026#34;  -map 是轨道参数，如果只有一个字幕，就不需要这个参数。-map 0:v 表示第一个文件输入视频轨道，-map 0:a 表示第二个轨道是第一个文件输入的音频轨道，-map 1 建立第三个轨道，-map 2 建立第四个轨道。如果没添加 map 参数，默认就只有一个字幕轨道，第二个英文字幕会覆盖第一个中文字幕轨道。 -metadata:s:s:0 language=chn 第一条字幕的语言设置为中文，-metadata:s:s:1 language=eng 第二条字幕的语言设置为英文。 language 不能自定义，只能设置成固定的缩写。  添加硬字幕：\n$ ffmpeg -i video.mkv -vf subtitles=subtitle.srt out.mp4 下载 m3u8 现在比较常见的视频流媒体，大部分都是 m3u8 格式的，而对于 m3u8 格式的视频而言，如果你下载过，你会发现它就是一个文本文件，大概也就只有几十 kb，从磁盘大小来看，应该也知道它并不是一个直接的视频文件。\n什么是 m3u8\n说到 m3u8 就要先说说 HLS（HTTP Live Streaming）。HLS 是 Apple 公司针对 iPhone、iPod、iTouch 等移动设备，而研发的基于 HTTP 协议的流媒体解决方案。在 HLS 技术中，Web 服务器可以向客户端提供接近实时的音视频流，但是它又是使用的标准的 HTTP 协议。所以基本上，比较大型的点播直播类服务，都是基于 HLS 的。\n而该技术的原理，就是将视频文件或者视频流，进行切片（ts文件），并建立索引文件（m3u8），它支持的视频流编码为 H.264，音频流编码为 AAC。\n简单来说，基于 HLS 的视频流，会将完整的视频，切割成一个个比较小的视频片段（ts 文件），然后根据协议组合成一个 m3u8 文件。这些比较小的 ts 文件，是可以单独播放的。而视频播放器，拿到 m3u8 文件之后，根据对其内 ts 片段的索引，连续播放不同的视频片段，来达到流畅的播放效果。\n下载的 m3u8 文件\n说这些概念都没用，我们来看两个真实的被下载的 m3u8 文件。\n这种 m3u8 文件就还是比较清晰的，能看到它一个个的片段。但是需要注意的是，这里的片段，全部是基于域名的相对地址，也就是说，这样一个 m3u8 文件，你丢到播放器里，是无法播放的，但是如果你记录了原始下载这个 m3u8 的链接，它在播放器里是可以正常播放的。\n当然，如果你修改这个 m3u8 文件，将它相对路径拼接上域名地址，也是可以达到播放的效果的。\n再来看看另外一种 m3u8 文件，它其内的 ts 片段，都是完整地址。\n像这种具有完整地址的 ts 片段，哪怕你将它保存成一个本地的文件，播放器依然是可以直接播放的，不过这里本质上依然是在在线播放。\n这两中 m3u8 文件，虽然有细微的差别，但是它们都是基于标准的协议。\n简单总结一下：\n m3u8 不是视频内容的文件，它占用的磁盘空间非常的小。 m3u8 文件，如果其内的 ts 片段，是完整地址，则可以保存后播放，否者只能在线播放。 播放器播放 m3u8 文件的时候，实际上，还是在线从线上获取的视频流进行播放，所以是存在失效的情况的。  暂时知道这三点就可以了，接下来我们再看如何将一个 m3u8 文件，下载成一个 mp4 视频文件。\n使用 fmpeg 下载 m3u8\nffmpeg 是一套可以用来记录、转换音视频，并将其转化为流的开源程序，采用 LGPL 或 GPL 协议许可证书，很多大型的音视频软件，内部都是基于 ffmpeg 的。\n$ ffmpeg -i \u0026#34;m3u8_file_uri\u0026#34; \u0026#34;save_video.mp4\u0026#34; 到此，如果 m3u8 的链接正确可播放，就会开始下载，等待下载完成就可以了，最终会在指定目录下，保存 save_video.mp4 文件，它就是最终我们下载的离线视频文件。\nblob url\n想下载淘宝上一个视频，打开控制台审查元素定位到video标签发现视频地址是blob:https开头，不能直接下载，可能是网站为了防止下载使用这种方式做了保护，用这种的大部分原始视频都是m3u8格式。\n获取blob真实地址：控制台单击network filter里输入.m3u8 刷新浏览器重新拉取资源，出现的就是m3u8地址，把他复制下来用 ffmpeg 下载就可以了\nwebm to gif $ ffmpeg -i input.webm -pix_fmt rgb8 output.gif MKVToolNix MKVToolNix is a set of tools to create, alter and inspect Matroska(mkv) files under Linux, other Unices and Windows.\n轨道提取模式：\nmkvextract 输入文件名 tracks [选项] TID1:目标文件名1 [TID2:目标文件名2 ...] TID:输出文件名 如果输入文件中存在 ID 为 TID 的轨道，则将其提取为文件 输出文件名。轨道 ID 与 mkvmerge --identify 文件 选项所输出的相同。\n$ mkvextract \u0026#34;Another Movie.mkv\u0026#34; tracks 0:video.h265 \u0026#34;1:main audio.aac\u0026#34; Rhythmbox Music 搜 \u0026ldquo;无损音乐\u0026rdquo; \u0026ldquo;车载音乐\u0026rdquo; 打包下载。\n將音樂從計算機上的文件夾導入\n為了使用Rhythmbox，您需要創建一個音樂庫。要做到這一點，請點擊“導入”按鈕。點擊“選擇位置”下拉菜單，然後在計算機上選擇一個包含音樂的文件夾。\nProdcast/播客 通过 feed 链接订阅，查看播客 Feed 订阅：\n 哈喽怪谈：http://rss.lizhi.fm/rss/21628.xml 黑水公园：https://www.ximalaya.com/album/3558668.xml  喜马拉雅的播客feed是 https://www.ximalaya.com/album/[ID].xml，即在播客url后添加.xml就行，但是只限于免费的。\nRadio/电台 互聯網廣播\n廣播電台列表將出現在Ambient到Underground的各種類別中。 選擇您想收聽的電台並點擊播放圖標。\n如果您希望收聽的廣播電台沒有出現，請點擊“添加”並輸入廣播電台供稿的URL。\n其他收听方式\n一种方式是通过传统的无线电收音机收听，一般手机上带有 Radio 软件，需插上有线耳机才能收听。\n另一种方式是通过各种平台收听，例如喜马拉雅、蜻蜓FM、央广的云听等，这种收听方式可以在浏览器 DevTool 中得 Network 栏中获取播放链接。\n电台推荐\n 有哪些地方广播电台值得推荐？：央广中国之声、国广环球资讯、国广Hit FM、央广音乐之声、北京Metro Radio、上海KFM、国广EZFM 中国有哪些值得推荐的音乐电台？：上海动感101、国广HitFM、央广音乐之声、广东怀集音乐之声、北京Metro Radio、北京动听调频、河北音乐广播、浙江音乐调频、厦门音乐广播  中國電台直播源列表\n中國國際廣播電台（CRI）\n 中文環球：http://sk.cri.cn/hyhq.m3u8 世界華聲：http://sk.cri.cn/hxfh.m3u8 南海之聲：http://sk.cri.cn/nhzs.m3u8 英语资讯广播：http://sk.cri.cn/am846.m3u8 環球資訊：http://sk.cri.cn/905.m3u8 輕鬆調頻：http://sk.cri.cn/915.m3u8 劲曲调频：http://sk.cri.cn/887.m3u8  中國中央人民廣播電台（CNR）\n 中國之聲：http://ngcdn001.cnr.cn/live/zgzs/index.m3u8 經濟之聲：http://ngcdn002.cnr.cn/live/jjzs/index.m3u8 音樂之聲 ：http://ngcdn003.cnr.cn/live/yyzs/index.m3u8 經典音樂廣播：http://ngcdn004.cnr.cn/live/dszs/index.m3u8 中華之聲：http://ngcdn005.cnr.cn/live/zhzs/index.m3u8 神州之聲：http://ngcdn006.cnr.cn/live/szzs/index.m3u8 大湾区之声：http://ngcdn007.cnr.cn/live/hxzs/index.m3u8 香港之聲：http://ngcdn008.cnr.cn/live/xgzs/index.m3u8 民族之聲：http://ngcdn009.cnr.cn/live/mzzs/index.m3u8 文藝之聲：http://ngcdn010.cnr.cn/live/wyzs/index.m3u8 老年之聲：http://ngcdn011.cnr.cn/live/lnzs/index.m3u8 藏語廣播：http://ngcdn012.cnr.cn/live/zygb/index.m3u8 維吾爾語廣播：http://ngcdn013.cnr.cn/live/wygb/index.m3u8 阅读之声：http://ngcdn014.cnr.cn/live/ylgb/index.m3u8 中國交通廣播：http://ngcdn016.cnr.cn/live/gsgljtgb/index.m3u8 中國鄉村之聲：http://ngcdn017.cnr.cn/live/xczs/index.m3u8 中國民樂：http://ngcdn021.cnr.cn/live/zgmy/index.m3u8 古典音樂：http://ngcdn022.cnr.cn/live/gdyy/index.m3u8 相聲小品：http://ngcdn023.cnr.cn/live/xsxp/index.m3u8 長篇聯播：http://ngcdn024.cnr.cn/live/cplb/index.m3u8 哈薩克語廣播：http://ngcdn025.cnr.cn/live/hygb/index.m3u8  香港电台（RTHK）\n RTHK1 第一台：https://rthkaudio1-lh.akamaihd.net/i/radio1_1@355864/master.m3u8 RTHK2 第二台：https://rthkaudio2-lh.akamaihd.net/i/radio2_1@355865/master.m3u8 RTHK3 第三台：https://rthkaudio3-lh.akamaihd.net/i/radio3_1@355866/master.m3u8 RTHK4 第四台：https://rthkaudio4-lh.akamaihd.net/i/radio4_1@355867/master.m3u8，古典音乐台 RTHK5 第五台：https://rthkaudio5-lh.akamaihd.net/i/radio5_1@355868/master.m3u8 RTHK6 第六台：https://rthkaudio6cnr-lh.akamaihd.net/i/radio6cnr_1@575604/master.m3u8 ，转播 CNR-香港之声 RTHK 普通话台：https://rthkaudio6-lh.akamaihd.net/i/radiopth_1@355869/master.m3u8  其他直播源\n AsiaFM亚洲热歌台：https://live.ximalaya.com/radio-first-page-app/live/1908/64.m3u8 上海KFM：https://lhttp.qtfm.cn/live/5022023/64k.mp3 上海动感101：https://lhttp.qingting.fm/live/274/64k.mp3 怀集音乐之声：https://lhttp.qingting.fm/live/4804/64k.mp3 北京动听调频Metro Radio：https://lhttp.qingting.fm/live/5022463/64k.mp3 河北音乐广播：https://lhttp.qingting.fm/live/1649/64k.mp3 动听968·浙江音乐调频：https://lhttp.qingting.fm/live/4866/64k.mp3 厦门音乐广播：https://lhttp.qingting.fm/live/1739/64k.mp3 亚洲电台：https://stream.rcs.revma.com/xpgtqc74hv8uv 亚太电台：https://stream.rcs.revma.com/kydend74hv8uv 飞扬调频：https://stream.rcs.revma.com/e0tdah74hv8uv  International\n Al Jazeera English: https://live-hls-audio-web-aje.getaj.net/VOICE-AJE/01.m3u8 BBC World Service: http://vprbbc.streamguys.net/vprbbc24-nopreroll Learning English: https://voa-ingest.akamaized.net/hls/live/2035234/160_342L/playlist.m3u8  相关资源\n 中华人民共和国广播电台列表(收听波段)  2009年旧方法\n很多电台是基于Microsoft Media Server (MMS) streaming protocol的，如果rhythmbox无法播放mms协议的电台，则需要安装支持mms协议的gstreamer插件——因为rhymbox使用gstreamer做后台解码。支持mms协议的插件为gstreamer-bad插件，所以执行命令：\n$ sudo apt-get install gstreamer0.10-plugins-bad 同样的，如果需要播放mp3文件则安装ugly插件，需要播放wma文件则安装ffmpeg插件。\n 电视台和电台MMS地址 分享Rhythmbox电台列表  播客和电台  播客和电台的区别是什么？  播客和电台的区别比较明显，一句话概括：播客是通过互联网承载的声音内容；电台则通过传统的广告媒介运营，现在也在互联网上分发拷贝。\n播客，中文圈对“Podcast”的翻译，而Podcast是苹果公司的产品，是由“iPod”和“broadcast”（广播）的混成词，将数码产品和内容产品合二为一。Podcast和itunes一样都对声音内容的生产和商业化产生了深远影响。\n电台，准确来讲是指电台广播（Radio broadcasting），和苹果公司的定义相比，那就是不需要通过他家“iPod”就可以听的广播咯。\n 为什么现在的平台上（例如喜马拉雅、网易云音乐）都把播客划分为电台？  最核心的原因是，现在国内大的声音内容服务平台，声音内容是极其丰富的，例如直播、录播、有声书……（儿童、历史的分类法是按题材/内容划分）从节目录制和播放形式上来看，电台和播客本来都属广播（broadcasting），自然被放到一起了。\n另外，独立播客的的分发方式是在服务器中把一系列的音频档通过RSS消息来源列出，你可以通过任意一种泛用性podcast工具进行RSS订阅收听。现在也仍然有很多泛用性podcast平台提供类似服务，而国内的声音内容平台例如喜马，荔枝也为播客主提供托管服务，但更多是一种延伸服务，显然不是主打。\n最后，播客之所以往往是在各个频道里跟其他内容混装在一起，是因为播客主按自己节目内容类型进行分类，被归入了各个频道。比如我们做的[2082FM]选择的类型标签是“文化”，其实我挺没文化的。\nMissing plugin Rhythmbox-Message: 16:22:38.404: Missing plugin: gstreamer|1.0|rhythmbox|application/x-hls decoder|decoder-application/x-hls 解决方法：The element missing is named hlsdemux and lives in gst-plugins-bad.\n$ sudo apt install gstreamer1.0-plugins-bad 所有 GStreamer Plugins\nFeelUOwn FeelUOwn 是一个稳定、用户友好以及高度可定制的音乐播放器。支持全平台。\nClementine Clementine is a modern music player and library organizer for Windows, Linux and macOS.\ncmus Small, fast and powerful console music player for Unix-like operating systems.\n官方教程翻译版\nDeaDBeeF DeaDBeeF (as in 0xDEADBEEF) is a modular cross-platform audio player which runs on GNU/Linux distributions, macOS, Windows, *BSD, OpenSolaris, and other UNIX-like systems.\njellyfin The Free Software Media System\nAudacious Audacious is an open source audio player.\nKDE elisa/amarok elisa: Simple music player aiming to provide a nice experience for its users\namarok: Powerful music player that lets you rediscover your music\nElisa 在播放文件不可用的时候会迅速的删光所有歌曲，它的播放列表经常被破坏\nosdlyrics Standalone lyrics fetcher/displayer (windowed and OSD mode).\nZonyLrcToolsX ZonyLrcToolsX 是一个能够方便地下载歌词的小软件。（ps：一点也不见得方便）\nNeteaseMusic Linux 下官方只发布了 deb 包，flatpak 直接安装\nYesPlayMusic 高颜值的第三方网易云播放器\nNetEase-MusicBox 网易云音乐命令行版\nlx-music-desktop 一个基于 electron 的音乐软件\nlisten1_desktop one for all free music in china\nQQMusic Spotify 作为世界上最大的音乐流媒体服务商，Spotify 因优秀的设计和精准的音乐推荐算法让不少人为之倾心。\n在正式注册 Spotify 之前，我们先来看一看曲库的问题。由于不同地区的歌曲版权差异，Spotify 在不同地区提供服务时，其相应的曲库也有所不同。例如港区的曲库中，粤语歌就要比美区多，相反美区的英文歌就要比港区多。同理，若你喜欢听其他语种的歌，注册当地的 Spotify 则是最好的选择。\n注册后要是发现当前的地区选择并不是很理想，想要换区也是可行的。首先要挂上自己想要换到地区的代理，然后进入自己的「Profile/资料」界面，点击「Edit Profile/修改资料」，「Country/国家」这个选项就会出现你当前所挂代理地区，保存更改即可换区成功。\n登录的话，需要先在登录界面设置Proxy重启。登录后在设置里改回来，不再需要Proxy了。\nSpotifyd An open source Spotify client running as a UNIX daemon.\nMPV MPV 是基于 MPlayer 和 mplayer2 的开源极简全能播放器。支持各种视频格式、音频解码、支持特效字幕（电影动漫的ass特效字幕都没啥问题），不仅支持本地播放，同样支持网络播放（mpv 集成了 youtube-dl）。重点是 MPV 具有多系统平台支持、命令行、自定义、GPU 解码、脚本支持等特点……\n更多请阅读官方参考手册，及其中文版。\n快捷键 虽然 MPV 并没有提供官方的 GUI 界面，没有菜单，但它提供 OSC 操作界面和快捷键用于操作，只要关联好文件格式，使用 mpv 打开视频后，使用上其实也非常的简单方便。\n鼠标操作\n   快捷键 作用说明     鼠标左键双击 进入/退出全屏   鼠标右键单击 暂停/继续播放   鼠标滚轮 快进/快退    播放控制\n   快捷键  作用说明     p Space 暂停、继续播放   / * 减少/增加音量   9 0 减少/增加音量（数字键盘区的9、0不可用）   m  静音   ← → 快退/快进5秒   ↑ ↓ 快进/快退1分钟   \u0026lt; \u0026gt; 上一个/下一个（播放列表中）   Enter  下一个（播放列表中）   F8  播放列表   l  设定/清除 A-B循环点   L  循环播放   s  截屏   q  停止播放并退出   Q  保存当前播放进度并退出，播放同样文件从上次保存进度继续播放。    视频控制\n   快捷键 作用说明     _(下划线) 循环切换可用视频轨   A 循环切换视频画面比例   Alt+0 0.5倍源视频画面大小   Alt+1 1倍源视频画面大小   Alt+2 2倍源视频画面大小   Ctrl+h 在运行时切换硬解码。它在 auto 和 no 之间切换这个选项。    音频控制\n   快捷键  作用说明     #  循环切换可用音频轨   Ctrl + Ctrl - 音轨延迟+/- 0.1秒    字幕控制\n   快捷键  作用说明     V  关闭/开启字幕   j J 循环切换可用字幕轨   x z 字幕延迟 +/- 0.1秒   r t 上移/下移字幕位置    窗口控制\n   快捷键 作用说明     T 窗口始终置顶   f 进入/退出全屏   ESC 退出全屏    配置 因为mpv本身不具有图形化前端，绝大多数的设置选项都是靠在主设置文件 ~/.config/mpv/mpv.conf 中输入参数实现的。可以参考 官方的内建方案 跟 懒人包版：\n## 基本说明： ## 注释内容解释 —— # \u0026lt;可选值\u0026gt; [条件要求] 参数意义说明 （补充） ## 部分选项之间有关联作用，MPV读取参数时由上往下读，所以注意书写通用参数的顺序 # 追加读取额外的设置文件，在默认设置文件之后进行解析。 # ~~ 意思是 mpv config dir，例如 ~/.config/mpv/ # include=\u0026#34;~~/profiles.conf\u0026#34;  # 在将要播放的文件的同一目录下查找针对该文件的设置文件 use-filedir-conf=yes # 打开给定的路径进行写入，并输出日志信息到其中。 # ~~desktop 是桌面 # log-file=\u0026#34;~~desktop/mpv.log\u0026#34;  log-file=\u0026#34;~~/mpv.log\u0026#34; ######## # 基础 # ######## # 指定一个要使用的视频输出驱动的优先级列表。 # gpu 通用的可定制的、GPU加速的视频输出驱动。 # gpu-next 基于 libplacebo 的实验性视频渲染器。它几乎支持与 gpu 相同的功能集。 # 许多渲染相关的选项也只能在这两项下正常工作。首选gpu。 vo=gpu # 选择用于FBOs的纹理的内部格式。该格式可以影响视频输出的性能和质量。 fbo-format=auto # 如果可能的话，指定应该使用的视频硬件解码API。 # 硬解码是否实际完成取决于视频编码。如果硬件解码不可能，mpv将回退到软件解码。 # 如果希望硬件解码在默认情况下被启用，可以使用 auto-safe  hwdec=auto-safe # 只允许对一个给定的编码列表进行硬件解码。特殊值 all 总是允许所有的编码。 # 默认情况下，这被设置为 h264,vc1,hevc,vp8,vp9,av1,prores hwdec-codecs=all # 启用直接渲染（默认： yes）。 # 如果设置为 yes ，视频将被直接解码到GPU video memory（或暂存缓冲区）。 # 这可以加快视频上传速度，对高分辨率或慢速硬件可能有帮助。 vd-lavc-dr=yes ######## # 功能 # ######## # 让mpv在没有文件可以播放时空闲等待而不是退出。 idle=yes # 以暂停状态启动播放器 # pause=yes  # 循环一个文件N次，inf 表示永远，no 表示正常播放。 loop-file=no # 循环一个播放列表N次，inf 表示永远，no 表示正常播放。 loop-playlist=no # 允许视频解码器在跳转过程中丢帧，如果这些帧在跳转的目标之前。 hr-seek-framedrop=yes # 在退出时总是保存当前的播放位置。 save-position-on-quit=yes ## 窗口相关 # 全屏播放。 fullscreen=no # 窗口边框和装饰。 border=no # 将初始窗口尺寸设置为由 WxH 指定的最大尺寸，不改变窗口的长宽比。 autofit=70% # 将窗口尺寸锁定为视频长宽。 keepaspect-window=yes ## 缓存相关 # 播放网络视频时的向后缓存大小（KiB或MiB） # 该选项可以用来限制最大的预读数。 demuxer-max-bytes=50MiB ######## # 字幕 # ######## # 加载与视频文件名匹配的额外字幕文件。参数指定了外部字幕文件的匹配模式。 # fuzzy 加载包含媒体文件名的所有字幕 sub-auto=fuzzy ######## # 截图 # ######## # 设置用于保存屏幕截图的图像文件类型。 screenshot-format=png # 指定用于保存屏幕截图的文件名模板。 screenshot-template=\u0026#34;%{filename:MPV_Screenshot}_%P\u0026#34; # 存储屏幕截图在此目录中。 screenshot-directory= \u0026#34;~/Pictures/\u0026#34; 直播 直播源 播放方法\n$ mpv --playlist-start=1 --playlist=\u0026#34;https://raw.githubusercontent.com/zbefine/iptv/main/iptv.m3u\u0026#34; 稳定地址\n 我的播放源.m3u8 国内电视台直播源.m3u8 iptv 分享的 IPTV 频道 直播网站  CCTV直播 看看新闻高清 可通过 real-url 获取斗鱼\u0026amp;虎牙\u0026amp;哔哩哔哩\u0026amp;抖音\u0026amp;快手等直播平台的真实流媒体地址    IPTV提供商\n IPTV Shop - 超过6000个直播电视频道+ 4000个影视节目（VOD）。 BestBuyIPTV 超过38个国家/地区的7300个高清频道和9600 VOD 1080p。 LyngSat Stream 公共链接到互联网上传输的3018个线性电视频道和2963个线性无线电频道。 FreetuxTV WebTV Manager - WebTV和Web Radio的免费数据库。 CXTv 来自世界各地的1308个电视频道和287个摄像机。 Necro IPTV 提供所有优质的英国，爱尔兰，德国，土耳其，阿拉伯语，美国和加拿大频道。  电视频道信息\n LyngSat 卫星电视频道的数据库，其中包含捕获信号所必需的信息。 LyngSat Logo - 电视频道徽标的集合。 TV Address - 电视频道信息。  其他工具\n WebGrab + Plus 多站点增量XMLTV EPG采集器。 IPTV Checker — Node.js的IPTV播放列表检查器 Streamtest 免费且易于使用的基于Web的流测试器实用程序。  EPG 当我们过去看有线电视时，我们会依靠电视指南来了解接下来要播放什么节目或电影，或者我们在特定时间可以期待什么。 现在我们生活在一个更现代的世界中，具有相同功能的指南也发生了变化。 如今，在观看直播电视时依赖电子节目指南或 EPG。\n什么是IPTV？\n对于不知道或不熟悉的人来说，互联网协议电视或 IPTV 本质上是一种即使没有电缆也可以通过互联网观看直播电视频道的方式。 大多数时候，IPTV 订阅比有线电视便宜得多，这就是为什么许多剪线钳决定选择这种方式的原因，尤其是当他们想削减开支时。 此外，您无需订阅有线电视即可安装和使用 IPTV，因此您可以毫无问题地在任何受支持的设备上下载 IPTV 应用程序。\n有很多可用的 IPTV 服务，其中大多数提供数百或数千个频道可供浏览。 但是，无论您使用哪种 IPTV 服务，它通常都会附带一个 EPG，如果您正在寻找特定节目，您可以查看它。\nEPG怎么样？\n现在，让我们更多地讨论 EPG。 也称为电子服务指南 (ESG) 或交互式节目指南 (IPG)，您可以参考 EPG 以查看电视节目以及完整的详细信息列表。 这些详细信息包括节目网络、类型、放映时间、描述、预览等。\n话虽如此，EPG 的界面并不完全相同。 一些 EPG 只展示已经播放或正在播出的节目，而另一些则展示其他节目即将播出的时间表。\n如何为IPTV设置EPG？\n仅对于使用免费Internet访问中包含的M3U播放列表或自行创建它们的用户，才需要有关设置EPG的知识。对于只想通过网络收看电视频道而又不打算学习此主题的用户，可以按照自定义指南在Android或Windows上安装任何IPTV播放器。没有EPG的M3U文件如下所示：\n＃EXTM3U #EXTINF：0，Europa Plus电视#EXTGRP：音乐http://23acbfe8.ucomist.net/iptv/5K6RMPTM6L8S2Y/115/index.m3u8 #EXTINF：0，MUZ-TV #EXTGRP：音乐http://23acbfe8.ucomist.net/iptv/5K6RMPTM6L8S2Y/116/index.m3u8 #EXTINF：0，BRIDGE TV俄语热播#EXTGRP：音乐http://23acbfe8.ucomist.net/iptv/5K6RMPTM6L8S2Y/120/index.m3u8 #EXTINF：0，Bridge TV #EXTGRP：音乐http://23acbfe8.ucomist.net/iptv/5K6RMPTM6L8S2Y/122/index.m3u8 将标记为＃EXTM3U的第一行更改为：＃EXTM3U url-tvg=\u0026quot;http://iptvx.one/epg/epg_lite.xml.gz\u0026quot; 这样的形式。\nEPG 列表\n 提供EPG的频道列表，每日与EPG同步更新 EPG-电子节目单 EPG for IPTV - EPG服务提供商，为全球IPTV提供个性化的电子节目指南。 IPTVX|one 主要用于CIS频道的节目指南。 i.mjh.nz 来自澳大利亚，新西兰和南非的频道的节目指南。  VLC VLC is a free and open source cross-platform multimedia player and framework that plays most multimedia files, and various streaming protocols.\nSkins\n Put the downloaded VLT files in the following folder: ~/.local/share/vlc/skins2 Then open your VLC settings and change your interface from native to skins ( Tools =\u0026gt; Performances =\u0026gt; Interface =\u0026gt; Use custom skin =\u0026gt; Skin resource file =\u0026gt; Save ). You can choose your desired skin already there or change it when you are in the skins mode by rightclicking somewhere on the skin and going to Interface\u0026gt;Choose Skin. VLC needs to be restarted to change to skins mode.  有些主题只支持英文。\n管理流媒体\nVLC 的 Android 版本 与 Linux 桌面版本操作是不同的：\n  在 Android 上，选择 More，点击 New stream 添加添加流媒体，添加的流媒体会在Streams展示，可以将所有添加的流媒体分组到playlist，playlist可以备份成名为 vlc_media.db 的 sqlite db，详情看How to Backup and Restore Playlists\n  在 Linux 桌面端，需在 Media =\u0026gt; Open Network Stream\u0026hellip; 打开流媒体进行播放，打开的流媒体会在 Playlist 中展示，但是关闭 VLC 后就会清空 Playlist。要保存 Playlist，需右键 =\u0026gt; Save Playlist to File\u0026hellip; 保存为 xspf 文件，之后点击该文件播放 Playist 就行。Playlist 例子如下：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;playlist xmlns=\u0026#34;http://xspf.org/ns/0/\u0026#34; xmlns:vlc=\u0026#34;http://www.videolan.org/vlc/playlist/ns/0/\u0026#34; version=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Playlist\u0026lt;/title\u0026gt; \u0026lt;trackList\u0026gt; \u0026lt;track\u0026gt; \u0026lt;location\u0026gt;http://sk.cri.cn/915.m3u8\u0026lt;/location\u0026gt; \u0026lt;title\u0026gt;輕鬆調頻\u0026lt;/title\u0026gt; \u0026lt;duration\u0026gt;8950\u0026lt;/duration\u0026gt; \u0026lt;extension application=\u0026#34;http://www.videolan.org/vlc/playlist/0\u0026#34;\u0026gt; \u0026lt;vlc:id\u0026gt;0\u0026lt;/vlc:id\u0026gt; \u0026lt;vlc:option\u0026gt;network-caching=1000\u0026lt;/vlc:option\u0026gt; \u0026lt;/extension\u0026gt; \u0026lt;/track\u0026gt; \u0026lt;track\u0026gt; \u0026lt;location\u0026gt;http://sk.cri.cn/887.m3u8\u0026lt;/location\u0026gt; \u0026lt;title\u0026gt;劲曲调频\u0026lt;/title\u0026gt; \u0026lt;duration\u0026gt;8950\u0026lt;/duration\u0026gt; \u0026lt;extension application=\u0026#34;http://www.videolan.org/vlc/playlist/0\u0026#34;\u0026gt; \u0026lt;vlc:id\u0026gt;1\u0026lt;/vlc:id\u0026gt; \u0026lt;vlc:option\u0026gt;network-caching=1000\u0026lt;/vlc:option\u0026gt; \u0026lt;/extension\u0026gt; \u0026lt;/track\u0026gt; \u0026lt;/trackList\u0026gt; \u0026lt;extension application=\u0026#34;http://www.videolan.org/vlc/playlist/0\u0026#34;\u0026gt; \u0026lt;vlc:item tid=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;vlc:item tid=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;/extension\u0026gt; \u0026lt;/playlist\u0026gt; 手动编写的话\u0026lt;duration\u0026gt;可能是错的（不影响播放），可以在打开后 xspf 文件后再保存一次来覆盖该文件。\n  SMPlayer 多媒体播放器\nKodi 具有库支持的免费跨平台媒体播放器。\nShotcut Shotcut is a free, open source, cross-platform video editor.\nDaVinci Resolve 专业的剪辑、调色、特效和音频后期制作！\nDownload Aria2 Aria2是一款开源下载工具，可帮助简化不同设备和服务器之间的下载过程。它支持磁力链接、BT种子、http等类型的文件下载，与迅雷相比，Aria2有着优秀的性能及较低的资源占用，架构本身非常轻巧，通常只需要4兆字节（HTTP下载）到9兆字节（用于BitTorrent交互）之间。最重要的一点是Aria2完全免费！\n$ sudo apt-get install aria2 下载安装完成之后，可以通过输入 aria2c -v 来验证是否安装成功。\nUsage 命令行使用\n使用Aria2下载文件，只需在命令后附加地址即可：\n$ aria2c URL 下载后以其他名称保存文件\n$ aria2c -o fileName URL 下载多个文件\n$ aria2c -Z URL URL 从列表下载文件：\n$ aria2c -i URLs.txt 限制下载速度：\n# 单个文件 aria2c –max-download-limit=500k URL # 全局 aria2c –max-overall-download-limit=500k URL 断点续传：\n$ aria2c -c URL 下载磁力链接文件：要下载磁力链接文件，如果下载没有速度，可以添加--bt-tracker=选项，tracker 中用 , 隔开：\n$ aria2c --bt-tracker=tracker,tracker torrent tracker 服务器：\n  trackerslist：trackers_best (20 trackers) =\u0026gt; link / mirror / mirror 2\n  TrackersListCollection：BEST Tracker list (78 trackers)=\u0026gt; link / mirror\n  中国可用的 BT Tracker 服务器列表\n  将多行文本转换成一行并用逗号隔开\n$ cat tracker | xargs | tr \u0026#39; \u0026#39; \u0026#39;,\u0026#39;   分段下载：可以加快文件的下载速度，对于下载大文件时特别有用，-s 后面的参数值介于1~5之间，你可以根据实际情况选择。下面命令将使用2连接来下载该文件：\n$ aria2c -s 2 URL 后台下载：\n$ aria2c -D url $ aria2c –deamon=true url 验证文件：\n$ aria2c –checksum=md5=提供的md5 设置dht端口：\n$ aria2c –dht-listen-port=1234 torrent 下载需要引用页的文件：\n$ aria2c –referer=referurl URL 下载需要Cookie验证的文件：\n$ aria2c –essay-header=’Cookie:key=value’ URL $ aria2c –load-cookies=cookie文件 URL 从密码保护的网站下载一个文件：\n$ aria2c --http-user=xxx --http-password=xxx URL $ aria2c --ftp-user=xxx --ftp-password=xxx URL 注意：当源地址存在诸如\u0026amp;,*等shell的特殊字符，请使用单引号或双引号把URI包含起来。\n代理\n/usr/bin/aria2c --conf-path=/path/of/aria2.conf --{http,https,ftp,all}-proxy=\u0026#34;[http://][USER:PASSWORD@]HOST[:PORT]\u0026#34; 例如\n$ /usr/bin/aria2c --conf-path=/home/kurome/.opt/aria2/aria2.conf --http-proxy=\u0026#34;http://127.0.0.1:7890\u0026#34; 覆盖先前定义的代理, 使用 \u0026quot;\u0026quot;，例如：\n/usr/bin/aria2c --conf-path=/path/of/aria2.conf --all-proxy=\u0026#34;\u0026#34; RPC Server 模式\n该模式可以配合 Web UI 进行图形管理。默认启动是 6800 端口，怕别人盗用，可以设置用户名和密码(1.18.4以上版本支持密钥)。\n$ aria2c --enable-rpc --rpc-listen-all --rpc-allow-origin-all -c --dir ~/Download Configuration 默认情况下，aria2 检查旧路径 $HOME/.opt/aria2/aria2.conf 是否存在，否则它会将 $XDG_CONFIG_HOME/aria2/aria2.conf 解析为它的配置文件。 您可以使用 --conf-path 选项指定配置文件的路径。 如果您不想使用配置文件，请使用 --no-conf 选项。\n配置详解：\n# Description: Awesome Aria2 configuration file # Version: 2021.09.15 ## \u0026#39;#\u0026#39;开头为注释内容, 选项都有相应的注释说明, 根据需要修改 ## ## 被注释的选项填写的是默认值, 如为空则无默认设置，请自行选取需要更改的添加到你的配置文件中 ## ## 文件保存设置 ## # 下载路径(可使用绝对路径或相对路径), 默认: 当前启动位置 #dir= dir=/home/kurome/Downloads # 磁盘缓存 # 启用磁盘缓存. 如果设置为 0, 将禁用磁盘缓存. 此功能将下载的数据缓存在内存中, 最多占用此选项设置的字节数. 缓存存储由 aria2 实例创建并对所有下载共享. 由于数据以较大的单位写入并按文件的偏移重新排序, 所以磁盘缓存的一个优点是减少磁盘的 I/O. 如果调用哈希检查时并且数据缓存在内存中时, 将不需要从磁盘中读取. 大小可以包含 K 或 M (1K = 1024, 1M = 1024K). disk-cache=64M # 文件预分配方式, 可选：none, prealloc, trunc, falloc, 默认:prealloc # 预分配对于机械硬盘可有效降低磁盘碎片、提升磁盘读写性能、延长磁盘寿命。 # 机械硬盘使用 ext4（具有扩展支持），btrfs，xfs 或 NTFS（仅 MinGW 编译版本）等文件系统建议设置为 falloc # 若无法下载，提示 fallocate failed.cause：Operation not supported 则说明不支持，请设置为 none # prealloc 分配速度慢, trunc 无实际作用，不推荐使用。 # 固态硬盘不需要预分配，只建议设置为 none ，否则可能会导致双倍文件大小的数据写入，从而影响寿命。 file-allocation=none # 文件分配限制 # 不对比此参数设置大小小的分配文件. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). no-file-allocation-limit=64M # 断点续传 # 继续下载部分完成的文件. 启用此选项可以继续下载从浏览器或其他程序按顺序下载的文件. 此选项目前只支持 HTTP(S)/FTP 下载的文件. continue=true # 始终断点续传 # 始终断点续传. 如果设置为\u0026#34;是\u0026#34;, aria2 始终尝试断点续传, 如果无法恢复, 则中止下载. 如果设置为\u0026#34;否\u0026#34;, 对于不支持断点续传的 URI 或 aria2 遇到 N 个不支持断点续传的 URI (N 为 --max-resume-failure-tries 选项设置的值), aria2 会从头下载文件. 参见 --max-resume-failure-tries 参数. always-resume=false # 最大断点续传尝试次数 # 当 --always-resume 选项设置为\u0026#34;否\u0026#34;时, 如果 aria2 检测到有 N 个 URI 不支持断点续传时, 将从头开始下载文件. 如果 N 设置为 0, 当所有 URI 都不支持断点续传时才会从头下载文件. 参见 --always-resume 选项. max-resume-failure-tries=0 # 获取服务器文件时间 # 从 HTTP/FTP 服务获取远程文件的时间戳, 如果可用将设置到本地文件 remote-time=true ## 进度保存设置 ## # 从会话文件中读取下载任务 input-file=/home/kurome/.opt/aria2/aria2.session # 会话文件保存路径 # 当退出时保存错误及未完成的任务到指定的文件中. 必须用绝对路径 # 您可以在重启 aria2 时使用 --input-file 选项重新加载. 如果您希望输出的内容使用 GZip 压缩, 您可以在文件名后增加 .gz 扩展名. 请注意, 通过 aria2.addTorrent() 和 aria2.addMetalink() RPC 方法添加的下载, 其元数据没有保存到文件的将不会保存. 通过 aria2.remove() 和 aria2.forceRemove() 删除的下载将不会保存. #save-session= save-session=/home/kurome/.opt/aria2/aria2.session # 任务状态改变后保存会话的间隔时间（秒）, 0 为仅在进程正常退出时保存, 默认:0 # 为了及时保存任务状态、防止任务丢失，此项值只建议设置为 1 save-session-interval=1 # 自动保存任务进度到控制文件(*.opt/aria2)的间隔时间（秒），0 为仅在进程正常退出时保存，默认：60 # 不论设置的值为多少, aria2 会在任务结束时保存控制文件. 可以设置的值为 0 到 600. # 此项值也会间接影响从内存中把缓存的数据写入磁盘的频率 # 想降低磁盘 IOPS (每秒读写次数)则提高间隔时间 # 想在意外非正常退出时尽量保存更多的下载进度则降低间隔时间 # 非正常退出：进程崩溃、系统崩溃、SIGKILL 信号、设备断电等 auto-save-interval=20 # 强制保存，即使任务已完成也保存信息到会话文件, 默认:false # 即使任务完成或删除时使用 --save-session 选项时也保存该任务. 此选项在这种情况下还会保存控制文件. 此选项可以保存被认为已经完成但正在做种的 BT 任务. # 开启后会在任务完成后保留 .opt/aria2 文件，文件被移除且任务存在的情况下重启后会重新下载。 # 关闭后已完成的任务列表会在重启后清空。 force-save=false ## 下载连接设置 ## # 文件未找到重试次数 # 如果 aria2 从远程 HTTP/FTP 服务器收到 \u0026#34;文件未找到\u0026#34; 的状态超过此选项设置的次数后下载将会失败. 设置为 0 将会禁用此选项. 此选项仅影响 HTTP/FTP 服务器. 重试时同时会记录重试次数, 所以也需要设置 --max-tries 这个选项. max-file-not-found=10 # 最大尝试次数 # 设置最大尝试次数. 0 表示不限制，默认:5 max-tries=0 # 重试等待时间, 默认:0 (禁用) # 设置重试间隔时间(秒). 当此选项的值大于 0 时, aria2 在 HTTP 服务器返回 503 响应时将会重试. retry-wait=10 # 连接超时时间 # 设置建立 HTTP/FTP/代理服务器 连接的超时时间(秒). 当连接建立后, 此选项不再生效, 请使用 --timeout 选项. connect-timeout=10 # 超时时间。默认：60 timeout=10 # 最大同时下载任务数, 运行时可修改, 默认:5 max-concurrent-downloads=5 # 单服务器最大连接线程数, 任务添加时可指定, 默认:1 # 最大值为 16 (增强版无限制), 且受限于单任务最大连接线程数(split)所设定的值。 max-connection-per-server=16 # 单任务最大连接线程数, 任务添加时可指定, 默认:5 # 下载时使用 N 个连接. 如果提供超过 N 个 URI 地址, 则使用前 N 个地址, 剩余的地址将作为备用. 如果提供的 URI 地址不足 N 个, 这些地址多次使用以保证同时建立 N 个连接. 同一服务器的连接数会被 --max-connection-per-server 选项限制. split=64 # 文件最小分段大小, 添加时可指定, 默认:20M # aria2 不会分割小于 2*SIZE 字节的文件. 例如, 文件大小为 20MB, 如果 SIZE 为 10M, aria2 会把文件分成 2 段 [0-10MB) 和 [10MB-20MB), 并且使用 2 个源进行下载 (如果 --split \u0026gt;= 2). 如果 SIZE 为 15M, 由于 2*15M \u0026gt; 20MB, 因此 aria2 不会分割文件并使用 1 个源进行下载. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). 可以设置的值为: 1M-1024M. # 理论上值越小使用下载分段就越多，所能获得的实际线程数就越大，下载速度就越快，但受限于所下载文件服务器的策略。 min-split-size=4M # 文件分片大小，最小值为 1M，默认：1M # 设置 HTTP/FTP 下载的分配大小. aria2 根据这个边界分割文件. 所有的分割都是这个长度的倍数. 此选项不适用于 BitTorrent 下载. 如果 Metalink 文件中包含分片哈希的结果此选项也不适用. piece-length=1M # 允许分片大小变化。默认：false # 如果设置为\u0026#34;否\u0026#34;, 当分片长度与控制文件中的不同时, aria2 将会中止下载. 如果设置为\u0026#34;是\u0026#34;, 您可以继续, 但部分下载进度将会丢失. allow-piece-length-change=true # 分片选择算法 # 指定 HTTP/FTP 下载使用的分片选择算法. 分片表示的是并行下载时固定长度的分隔段. 如果设置为\u0026#34;默认\u0026#34;, aria2 将会按减少建立连接数选择分片. 由于建立连接操作的成本较高, 因此这是合理的默认行为. 如果设置为\u0026#34;顺序\u0026#34;, aria2 将选择索引最小的分片. 索引为 0 时表示为文件的第一个分片. 这将有助于视频的边下边播. --enable-http-pipelining 选项有助于减少重连接的开销. 请注意, aria2 依赖于 --min-split-size 选项, 所以有必要对 --min-split-size 选项设置一个合理的值. 如果设置为\u0026#34;随机\u0026#34;, aria2 将随机选择一个分片. 就像\u0026#34;顺序\u0026#34;一样, 依赖于 --min-split-size 选项. 如果设置为\u0026#34;几何\u0026#34;, aria2 会先选择索引最小的分片, 然后会为之前选择的分片保留指数增长的空间. 这将减少建立连接的次数, 同时文件开始部分将会先行下载. 这也有助于视频的边下边播. #stream-piece-selector=default # 最小速度限制 # 当下载速度低于此选项设置的值(B/s) 时将会关闭连接. 0 表示不设置最小速度限制. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). 此选项不会影响 BT 下载. lowest-speed-limit=0 # 全局最大下载速度 # 设置全局最大下载速度 (字节/秒). 0 表示不限制. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). max-overall-download-limit=0 # 最大下载速度 # 设置每个任务的最大下载速度 (字节/秒). 0 表示不限制. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). max-download-limit=0 # 禁用 IPv6, 默认:false disable-ipv6=true # 支持 GZip # 如果远程服务器的响应头中包含 Content-Encoding: gzip 或 Content-Encoding: deflate , 将发送包含 Accept: deflate, gzip 的请求头并解压缩响应. http-accept-gzip=true # URI 复用 # 当所有给定的 URI 地址都已使用, 继续使用已经使用过的 URI 地址. reuse-uri=false # URI 选择算法 # 指定 URI 选择的算法. 可选的值包括 \u0026#34;按顺序\u0026#34;, \u0026#34;反馈\u0026#34; 和 \u0026#34;自适应\u0026#34;. 如果设置为\u0026#34;按顺序\u0026#34;, URI 将按列表中出现的顺序使用. 如果设置为\u0026#34;反馈\u0026#34;, aria2 将根据之前的下载速度选择 URI 列表中下载速度最快的服务器. 同时也将有效跳过无效镜像. 之前统计的下载速度将作为服务器状态文件的一部分, 参见 --server-stat-of 和 --server-stat-if 选项. 如果设置为\u0026#34;自适应\u0026#34;, 将从最好的镜像和保留的连接里选择一项. 补充说明, 其返回的镜像没有被测试过, 同时如果每个镜像都已经被测试过时, 返回的镜像还会被重新测试. 否则, 其将不会选择其他镜像. 例如\u0026#34;反馈\u0026#34;, 其使用服务器状态文件. #uri-selector=feedback # 禁用 netrc，默认:false no-netrc=true # .netrc 文件路径 #netrc-path=$(HOME)/.netrc # 允许覆盖 # 如果相应的控制文件不存在时从头重新下载文件. 参见 --auto-file-renaming 选项. allow-overwrite=false # 文件自动重命名。默认:true # 重新命名已经存在的文件. 此选项仅对 HTTP(S)/FTP 下载有效. 新的文件名后会在文件名后、扩展名 (如果有) 前追加句点和数字(1..9999). auto-file-renaming=true # 使用 UTF-8 处理 Content-Disposition，默认:false # 处理 \u0026#34;Content-Disposition\u0026#34; 头中的字符串时使用 UTF-8 字符集来代替 ISO-8859-1, 例如, 文件名参数, 但不是扩展版本的文件名. content-disposition-default-utf8=true # 最低 TLS 版本，可选：TLSv1.1、TLSv1.2、TLSv1.3 默认:TLSv1.2 #min-tls-version=TLSv1.2 ## BT/PT 下载设置 ## # BT 监听端口(TCP), 默认:6881-6999 # 设置 BT 下载的 TCP 端口. 多个端口可以使用逗号 \u0026#34;,\u0026#34; 分隔, 例如: 6881,6885. 您还可以使用短横线 \u0026#34;-\u0026#34; 表示范围: 6881-6999, 或可以一起使用: 6881-6889, 6999. # 直通外网的设备，比如 VPS ，务必配置防火墙和安全组策略允许此端口入站 # 内网环境的设备，比如 NAS ，除了防火墙设置，还需在路由器设置外网端口转发到此端口 listen-port=51413 # DHT 网络与 UDP tracker 监听端口(UDP), 默认:6881-6999 # 设置 DHT (IPv4, IPv6) 和 UDP 服务器使用的 UCP 端口. 多个端口可以使用逗号 \u0026#34;,\u0026#34; 分隔, 例如: 6881,6885. 您还可以使用短横线 \u0026#34;-\u0026#34; 表示范围: 6881-6999, 或可以一起使用: 6881-6889, 6999. # 因协议不同，可以与 BT 监听端口使用相同的端口，方便配置防火墙和端口转发策略。 dht-listen-port=51413 # 启用 DHT (IPv4), 默认:true # 启用 IPv4 DHT 功能. 此选项同时会启用 UDP 服务器支持. PT 下载(私有种子)会自动禁用 enable-dht=true # 启用 DHT (IPv6)，默认:false # 启用 IPv6 DHT 功能. 如果种子设置为私有, 即使此选项设置为\u0026#34;是\u0026#34;, aria2 也不会启用 DHT. 使用 --dht-listen-port 选项设置监听的端口. # 在没有 IPv6 支持的环境开启可能会导致 DHT 功能异常 enable-dht6=false # 外部 IP 地址 # 指定用在 BitTorrent 下载和 DHT 中的外部 IP 地址. 它可能被发送到 BitTorrent 服务器. 对于 DHT, 此选项将会报告本地节点正在下载特定的种子. 这对于在私有网络中使用 DHT 非常关键. 虽然这个方法叫外部, 但其可以接受各种类型的 IP 地址. # 使用场景：在家庭宽带没有公网 IP 的情况下可以把 BT 和 DHT 监听端口转发至具有公网 IP 的服务器，在此填写服务器的 IP ，可以提升 BT 下载速率。 #bt-external-ip= # DHT (IPv4) 文件，默认：$HOME/.opt/aria2/dht.dat # 修改 IPv4 DHT 路由表文件路径. dht-file-path=/home/kurome/.opt/aria2/dht.dat # DHT (IPv6) 文件，默认：$HOME/.opt/aria2/dht6.dat # 修改 IPv6 DHT 路由表文件路径. dht-file-path6=/home/kurome/.opt/aria2/dht6.dat # IPv4 DHT 网络引导节点 dht-entry-point=dht.transmissionbt.com:6881 # IPv6 DHT 网络引导节点 dht-entry-point6=dht.transmissionbt.com:6881 # 启用本地节点发现(LPD),PT 下载(私有种子)会自动禁用,默认:false bt-enable-lpd=true # 指定用于本地节点发现的接口，可能的值：接口，IP地址 # 如果未指定此选项，则选择默认接口。 #bt-lpd-interface= # 启用节点交换, 默认:true # 启用节点交换扩展. 如果种子设置为私有, 即使此选项设置为\u0026#34;是\u0026#34;, aria2 也不会启用此功能. enable-peer-exchange=true # BT 下载最大连接数（单任务），运行时可修改。0 为不限制，默认:55 # 理想情况下连接数越多下载越快，但在实际情况是只有少部分连接到的做种者上传速度快，其余的上传慢或者不上传。 # 如果不限制，当下载非常热门的种子或任务数非常多时可能会因连接数过多导致进程崩溃或网络阻塞。 # 进程崩溃：如果设备 CPU 性能一般，连接数过多导致 CPU 占用过高，因资源不足 Aria2 进程会强制被终结。 # 网络阻塞：在内网环境下，即使下载没有占满带宽也会导致其它设备无法正常上网。因远古低性能路由器的转发性能瓶颈导致。 bt-max-peers=128 # BT 下载期望速度值（单任务），运行时可修改。单位 K 或 M 。默认:50K # BT 下载速度低于此选项值时会临时提高连接数来获得更快的下载速度，不过前提是有更多的做种者可供连接。 # 实测临时提高连接数没有上限，但不会像不做限制一样无限增加，会根据算法进行合理的动态调节。 bt-request-peer-speed-limit=10M # 全局最大上传速度, 运行时可修改, 默认:0 (无限制) # 设置全局最大上传速度 (字节/秒). 0 表示不限制. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). # 设置过低可能影响 BT 下载速度 max-overall-upload-limit=2M # 单任务上传速度限制, 默认:0 (无限制) # 设置每个任务的最大上传速度 (字节/秒). 0 表示不限制. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). max-upload-limit=0 # 最小分享率, 0 为一直做种, 默认:1.0 # 指定分享率. 当分享率达到此选项设置的值时会完成做种. 强烈建议您将此选项设置为大于等于 1.0. 如果您想不限制分享比率, 可以设置为 0.0. 如果同时设置了 --seed-time 选项, 当任意一个条件满足时将停止做种. seed-ratio=1.0 # 最小做种时间（分钟） # 此选项设置为 0 时, 将在 BT 任务下载完成后不进行做种. seed-time=30 # 做种前检查文件哈希, 默认:true # 如果设置为\u0026#34;是\u0026#34;, 当使用 --check-integrity 选项完成哈希检查及文件完成后才继续做种. 如果您希望仅当文件损坏或未完成时检查文件, 请设置为\u0026#34;否\u0026#34;. 此选项仅对 BT 下载有效 bt-hash-check-seed=true # 继续之前的BT任务时, 无需再次校验, 默认:false # 不检查之前下载文件中每个分片的哈希值. bt-seed-unverified=false # BT tracker 服务器连接超时时间（秒）。默认：60 # 建立连接后，此选项无效，将使用 bt-tracker-timeout 选项的值 bt-tracker-connect-timeout=10 # BT tracker 服务器超时时间（秒）。默认：60 bt-tracker-timeout=10 # BT 服务器连接间隔时间。默认：0 (自动) # 设置请求 BT 服务器的间隔时间 (秒). 此选项将完全覆盖服务器返回的最小间隔时间和间隔时间, aria2 仅使用此选项的值.如果设置为 0, aria2 将根据服务器的响应情况和下载进程决定时间间隔. #bt-tracker-interval=0 # BT 下载优先下载文件开头或结尾 # 尝试先下载每个文件开头或结尾的分片. 此选项有助于预览文件. 参数可以包括两个关键词: head 和 tail. 如果包含两个关键词, 需要使用逗号分隔. 每个关键词可以包含一个参数, SIZE. 例如, 如果指定 head=SIZE, 每个文件的最前 SIZE 数据将会获得更高的优先级. tail=SIZE 表示每个文件的最后 SIZE 数据. SIZE 可以包含 K 或 M (1K = 1024, 1M = 1024K). bt-prioritize-piece=head=32M,tail=32M # 保存通过 WebUI(RPC) 上传的种子文件(.torrent)，默认:true # 在 dir 选项设置的目录中保存上传的种子文件或 Metalink 文件. 文件名包括 SHA-1 哈希后的元数据和扩展名两部分. 对于种子文件, 扩展名为 \u0026#39;.torrent\u0026#39;. 对于 Metalink 为 \u0026#39;.meta4\u0026#39;. 如果此选项设置为\u0026#34;否\u0026#34;, 通过 aria2.addTorrent() 或 aria2.addMetalink() 方法添加的下载将无法通过 --save-session 选项保存. # 所有涉及种子文件保存的选项都建议开启，不保存种子文件有任务丢失的风险。 # 通过 RPC 自定义临时下载目录可能不会保存种子文件。 rpc-save-upload-metadata=true # 下载种子文件(.torrent)自动开始下载, 默认:true，可选：false|mem # true：保存种子文件 # false：仅下载种子文件 # mem：将种子保存在内存中 # 如果设置为\u0026#34;是\u0026#34;或\u0026#34;仅内存\u0026#34;, 当后缀为 .torrent 或内容类型为 application/x-bittorrent 的文件下载完成时, aria2 将按种子文件读取并下载该文件中提到的文件. 如果设置为\u0026#34;仅内存\u0026#34;, 该种子文件将不会写入到磁盘中, 而仅会存储在内存中. 如果设置为\u0026#34;否\u0026#34;, 则 .torrent 文件会下载到磁盘中, 但不会按种子文件读取并且其中的文件不会进行下载. follow-torrent=true # 种子文件下载完后暂停任务，默认：false # 在开启 follow-torrent 选项后下载种子文件或磁力会自动开始下载任务进行下载，而同时开启当此选项后会建立相关任务并暂停。 pause-metadata=false # 保存磁力链接元数据为种子文件(.torrent), 默认:false # 保存种子文件为 \u0026#34;.torrent\u0026#34; 文件. 此选项仅对磁链生效. 文件名为十六进制编码后的哈希值及 \u0026#34;.torrent\u0026#34;后缀. 保存的目录与下载文件的目录相同. 如果相同的文件已存在, 种子文件将不会保存. bt-save-metadata=true # 加载已保存的元数据文件(.torrent)，默认:false # 当使用磁链下载时, 在从 DHT 获取种子元数据之前, 首先尝试加载使用 --bt-save-metadata 选项保存的文件. 如果文件加载成功, 则不会从 DHT 下载元数据. bt-load-saved-metadata=true # 删除 BT 下载任务中未选择文件，默认:false # 当 BT 任务完成后删除未选择的文件. 要选择需要下载的文件, 请使用 --select-file 选项. 如果没有选择, 则所有文件都默认为需要下载. 此选项会从磁盘上直接删除文件, 请谨慎使用此选项. bt-remove-unselected-file=true # BT强制加密, 默认: false # 启用后将拒绝旧的 BT 握手协议并仅使用混淆握手及加密。可以解决部分运营商对 BT 下载的封锁，且有一定的防版权投诉与迅雷吸血效果。 # 此选项相当于后面两个选项(bt-require-crypto=true, bt-min-crypto-level=arc4)的快捷开启方式，但不会修改这两个选项的值。 bt-force-encryption=true # BT加密需求，默认：false # 启用后拒绝与旧的 BitTorrent 握手协议(\\19BitTorrent protocol)建立连接，始终使用混淆处理握手。 #bt-require-crypto=true # BT最低加密等级，可选：plain（明文），arc4（加密），默认：plain # 设置加密方法的最小级别. 如果节点提供多种加密方法, aria2 将选择满足给定级别的最低级别. #bt-min-crypto-level=arc4 # 分离仅做种任务，默认：false # 从正在下载的任务中排除已经下载完成且正在做种的任务，并开始等待列表中的下一个任务。 # 统计当前活动下载任务(参见 -j 选项) 时排除仅做种的任务. 这意味着, 如果参数设置为 -j3, 此选项打开并且当前有 3 个正在活动的任务, 并且其中有 1 个进入做种模式, 那么其会从正在下载的数量中排除(即数量会变为 2), 在队列中等待的下一个任务将会开始执行. 但要知道, 在 RPC 方法中, 做种的任务仍然被认为是活动的下载任务. bt-detach-seed-only=true ## 客户端伪装 ## # 自定义 User Agent user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36 Edg/93.0.961.47 # BT 客户端伪装 # PT 下载需要保持 user-agent 和 peer-agent 两个参数一致 # 部分 PT 站对 Aria2 有特殊封禁机制，客户端伪装不一定有效，且有封禁账号的风险。 # 自定义 User Agent，默认：aria2/$VERSION #user-agent=Deluge 1.3.15 # Peer Agent # 指定 BT 扩展握手期间用于节点客户端版本的字符串. peer-agent=Deluge 1.3.15 # 节点 ID 前缀 # 指定节点 ID 的前缀. BT 中节点 ID 长度为 20 字节. 如果超过 20 字节, 将仅使用前 20 字节. 如果少于 20 字节, 将在其后不足随机的数据保证为 20 字节. peer-id-prefix=-DE13F0- ## 执行额外命令 ## # 下载停止后执行的命令 # 从 正在下载 到 删除、错误、完成 时触发。暂停被标记为未开始下载，故与此项无关。 #on-download-stop=/home/kurome/.opt/aria2/delete.sh # 下载完成后执行的命令 # 此项未定义则执行 下载停止后执行的命令 (on-download-stop) #on-download-complete=/home/kurome/.opt/aria2/clean.sh # 下载错误后执行的命令 # 此项未定义则执行 下载停止后执行的命令 (on-download-stop) #on-download-error= # 下载暂停后执行的命令 #on-download-pause= # 下载开始后执行的命令 #on-download-start= # BT 下载完成后执行的命令 #on-bt-download-complete= ## RPC 设置 ## # 启用 JSON-RPC/XML-RPC 服务器, 默认:false enable-rpc=true # 接受所有远程请求, 默认:false # 在 RPC 响应头增加 Access-Control-Allow-Origin 字段, 值为 * .web界面跨域权限需要 rpc-allow-origin-all=true # 允许外部访问, 默认:false rpc-listen-all=true # RPC 监听端口, 默认:6800 rpc-listen-port=6800 # RPC 密钥, v1.18.4新增功能, 取代 --rpc-user 和 --rpc-passwd 选项 rpc-secret=SetForYourself # RPC 最大请求大小 # 设置 JSON-RPC/XML-RPC 最大的请求大小. 如果 aria2 检测到请求超过设定的字节数, 会直接取消连接. rpc-max-request-size=10M # RPC 服务 SSL/TLS 加密, 默认：false # RPC 将通过 SSL/TLS 加密传输. RPC 客户端需要使用 https 协议连接服务器. 对于 WebSocket 客户端, 使用 wss 协议. 使用 --rpc-certificate 和 --rpc-private-key 选项设置服务器的证书和私钥. # 不推荐开启，建议使用 web server 反向代理，比如 Nginx、Caddy ，灵活性更强。 #rpc-secure= # 在 RPC 服务中启用 SSL/TLS 加密时的证书文件, # 使用 PEM 格式时，您必须通过 --rpc-private-key 指定私钥 #rpc-certificate=/path/to/certificate.pem # 在 RPC 服务中启用 SSL/TLS 加密时的私钥文件 #rpc-private-key=/path/to/certificate.key # 事件轮询方式, 可选：epoll, kqueue, port, poll, select, 不同系统默认值不同 # 设置事件轮训的方法. 对于 epoll, kqueue, port 和 poll, 只有系统支持时才可用. 最新的 Linux 支持 epoll. 各种 *BSD 系统包括 Mac OS X 支持 kqueue. Open Solaris 支持 port. 默认值根据您使用的操作系统不同而不同. #event-poll=select ## 高级选项 ## # 启用异步 DNS 功能。默认：true #async-dns=true # 指定异步 DNS 服务器列表，未指定则从 /etc/resolv.conf 中读取。 #async-dns-server=119.29.29.29,223.5.5.5,8.8.8.8,1.1.1.1 # 指定单个网络接口，可能的值：接口，IP地址，主机名 # 如果接口具有多个 IP 地址，则建议指定 IP 地址。 # 已知指定网络接口会影响依赖本地 RPC 的连接的功能场景，即通过 localhost 和 127.0.0.1 无法与 Aria2 服务端进行讯通。 #interface= # 指定多个网络接口，多个值之间使用逗号(,)分隔。 # 使用 interface 选项时会忽略此项。 #multiple-interface= ## 日志设置 ## # 日志文件保存路径，默认：不保存 # 如果设置为 \u0026#34;-\u0026#34;, 日志则写入到 stdout. 如果忽略或设置为空字符串(\u0026#34;\u0026#34;), 日志将不会记录到磁盘上. #log= # 日志级别，可选 debug, info, notice, warn, error 。默认：debug #log-level=warn # 控制台日志级别，可选 debug, info, notice, warn, error ，默认：notice console-log-level=notice # 安静模式，禁止在控制台输出日志，默认：false quiet=false # 下载进度摘要输出间隔时间（秒），0 为禁止输出。默认：60 summary-interval=0 ## BitTorrent trackers ## # BT 服务器地址 2022/02/26 # 逗号分隔的 BT 服务器地址. 如果服务器地址在 --bt-exclude-tracker 选项中, 其将不会生效. bt-tracker=udp://open.tracker.cl:1337/announce,udp://tracker.opentrackr.org:1337/announce,udp://9.rarbg.com:2810/announce,udp://www.torrent.eu.org:451/announce,udp://tracker2.dler.org:80/announce,udp://tracker.torrent.eu.org:451/announce,udp://tracker.moeking.me:6969/announce,udp://tracker.bitsearch.to:1337/announce,udp://tracker.0x.tf:6969/announce,udp://tracker-udp.gbitt.info:80/announce,udp://tr.cili001.com:8070/announce,udp://retracker.lanta-net.ru:2710/announce,udp://open.stealth.si:80/announce,udp://ipv4.tracker.harry.lu:80/announce,udp://explodie.org:6969/announce,udp://exodus.desync.com:6969/announce,udp://bt2.archive.org:6969/announce,udp://bt1.archive.org:6969/announce,https://tracker.nanoha.org:443/announce,https://tracker.lilithraws.org:443/announce 更多：Aria2 完美配置\nAria2 Web 控制台\nAira2 没有软件界面，程序员可以用代码执行任务，但普通用户怎样添加下载任务呢？——打开浏览器，输入网址aria2c.com（YAAW 的中文版）就可以打开 Aria2 Web 控制台。\nJSON-RPC Path 默认为: http://localhost:6800/jsonrpc，如果提示 “Aria2 RPC 服务器错误”，按照以下方法修改：\n 普通情况设置为: http://host:port/jsonrpc  host: 指运行 Aria2 所在机器的 IP 或者名字 port: 使用 --rpc-listen-port 选项设置的端口, 未设置则是 6800；可通过 lsof -i:6800 查看端口是否被占用   使用 --rpc-secret=xxxxxx 选项设置为: http://token:xxxxxx@host:port/jsonrpc 使用 --rpc-user=user --rpc-passwd=pwd 选项设置为: http://user:pwd@host:port/jsonrpc 以上JSON-RPC Path 中的 http 可以用 ws 替代, 代表使用 WebSocket 协议。换用 ws 也可能解决 “Aria2 RPC 服务器错误”。 当使用 https://aria2c.com 访问时, 可能需要使用 https 或 wss 协议。  在 Web UI 中对 Aria2 的设置会在 Aria2 重启后丢失,，必要的设置请写入配置文件。\n已经下载完成的任务会在 Aria2 重启后消失, 除非启用了 --force-save 选项。\n自启动 两个方案：\n  建立 desktop 文件放入 ~/.config/autostart 中：\n$ vim ~/.config/autostart/aria2.desktop [Desktop Entry] Type=Application Exec=/usr/bin/aria2c --conf-path=/home/kurome/.opt/aria2/aria2.conf -D --all-proxy=\u0026#34;\u0026#34; Hidden=false NoDisplay=false X-GNOME-Autostart-enabled=true Name[en_US]=Aria2 Daemon Name=Aria2 Daemon Comment[en_US]= Comment= 但这个就看桌面环境怎么操作了，比如我在 openSUSE KDE上的问题：开机登陆后，aria2 启动，但是 logout 后，aria2 就不启动了。\n  建议换 systemd，手写个 service\n$ sudo vim /usr/lib/systemd/system/aria2.service [Unit] Description=Aria2c download manager After=network.target [Service] Type=simple User=kurome ExecStart=/usr/bin/aria2c --conf-path=/home/kurome/.opt/aria2/aria2.conf --all-proxy=\u0026#34;\u0026#34; [Install] WantedBy=multi-user.target $ sudo systemctl enable --now aria2.service “systemd: Failed at step USER spawning /usr/sbin/opendkim: No such process”：注意 User 部分，首先必须按照如下写，其次必须是存在的用户\nUser=tadeusz   Others AriaNg\nAriaNg 是一个让 aria2 更容易使用的现代 Web 前端\n 使用很简单，将文件下载解压即可，可以本地打开 index.html 文件，也可上传到服务器。 如果您懒得部署 AriaNg ，可以直接访问现成的 http://a2.ssss.fun 。 打开后需要配置 AriaNg，打开 AriaNg 设置 - RPC，修改 Aria2 RPC 地址 和 Aria2 RPC 密钥 ，点击 重新加载 AriaNg 即可。  WebUI-Aria2\n这个项目的目标是创建世界上最好和最热门的界面来与 aria2 交互。\n使用非常简单，只需在任何网络浏览器中下载并打开 index.html。\nAria2 for \u0026hellip;.\n比如 YAAW for Chrome、Aria2 for Chrome 、Aria2 for Edge 之类的。\n在浏览器中直接内置一个 AriaNg，用于直接管理 Aria2。\nUsing Aria2 as a Daemon\n运行 gnome-session-properties打开应用程序首选项管理（即 Ubuntu 中的 Startup Applications），添加：\n Name: Aria2 Daemon Command: /usr/bin/aria2c --conf-path=/home/kurome/.opt/aria2/aria2.conf -D  会建立 .config/autostart/aria2c.desktop\n[Desktop Entry] Type=Application Exec=/usr/bin/aria2c --conf-path=/home/vane/.opt/aria2/aria2.conf -D Hidden=false NoDisplay=false X-GNOME-Autostart-enabled=true Name[en_US]=Aria2 Daemon Name=Aria2 Daemon Comment[en_US]= Comment= BT 下载预热 是这样滴，和很多BT客户端一样，Aria2有个dht.dat文件(开启ipv6还有个dht6.dat)，这玩意用于存储一种叫做DHT Routing Table的东西，DHT网络由无数节点组成，你接触到一个后能通过它接触到更多的节点，Aria2我记得是有内置的节点，但是！如果你在Aria2第一次运行的时候直接下载磁力链接或者冷门种子，你很可能遇到连MetaData都无法获取的情况，这就是因为第一次只是初始化dht.dat文件，你本地不存在DHT Routing Table的缓存，所以你无法从DHT网络中获取足够的数据。\n那么怎么办？我的建议是，找个热门种子(千万建议是种子，而不是磁力链接)，然后下一波，挂着做种，过几个小时后退出Aria2，或者等Aria2会话自动保存，你会发现dht.dat从空文件变成有数据了，这时候你下载就会正常很多。\n什么是 PT 答：PT（Private Tracker）下载其实也是Bt下载的一种，但有两个明显的改进：一是私密的小范围下载，二是进行流量统计，根据上载量决定你的权限。\nBT下载时，软件会分析.torrent种子文件得到Tracker地址，然后连接Tracker服务器，服务器返回其他下载者的IP，下载者再与这些IP联系进行下载，从而减轻了服务器的负担，BT下载的Tracker是公开的，而Private Tracker 下载(PT下载)的Tracker则是私有的，每个人的Tracker是不同的，即passkey不同，passkey对PT下载者很重要，所以不要轻易泄露出去。\n其实和通常BT相比，PT就是多了一个passkey验证，这样就能保证未注册的用户不能下载。所以passkey很重要，一旦发现有问题，就要到站点上去重置passkey。Tracker Server根据passkey把BT客户端上传量和下载量进行计算，从而算出分享率(上传量/下载量)。如果分享率太小，将会被删除帐号，从而不能下载。\n这样Private Tracker 下载(PT下载)是一种小范围的BT下载，通过禁用DHT有要求地选择并控制用户数量，这样，在有限的范围内，下载的用户基本上都可以达到自己的宽带上限，Private Tracker 下载(PT下载)下载还通过论坛等方式的约束机制将BT下载的理念现实化，真正让用户做到下载的过程中努力上传。因此，Private Tracker 下载(PT下载)的速度很快，能够让用户款待得到最大程度的使用。\nPT通过对做种时间和流量的要求在一定程度上避免了BT中存在的下完不做种的现象，因此在网络上，尤其是需要大文件（如高清）资源交换的时候广受欢迎，在PT站里，“水管”代表上传带宽的大小，大水管可以通过快速的上传获得积分，PT站点也会采取措施（比如做种时间，优惠等）使上传较慢的小水管能够参与贡献和共享资源。\nRPC 首先了解什么叫RPC，为什么要RPC，RPC是指远程过程调用，也就是说两台服务器A，B，一个应用部署在A服务器上，想要调用B服务器上应用提供的函数/方法，由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义和传达调用的数据。\n比如说，一个方法可能是这样定义的：\nEmployee getEmployeeByName(String fullName) 那么：\n 首先，要解决通讯的问题，主要是通过在客户端和服务器之间建立TCP连接，远程过程调用的所有交换的数据都在这个连接里传输。连接可以是按需连接，调用结束后就断掉，也可以是长连接，多个远程过程调用共享同一个连接。 第二，要解决寻址的问题，也就是说，A服务器上的应用怎么告诉底层的RPC框架，如何连接到B服务器（如主机或IP地址）以及特定的端口，方法的名称名称是什么，这样才能完成调用。比如基于Web服务协议栈的RPC，就要提供一个endpoint URI，或者是从UDDI服务上查找。如果是RMI调用的话，还需要一个RMI Registry来注册服务的地址。 第三，当A服务器上的应用发起远程过程调用时，方法的参数需要通过底层的网络协议如TCP传递到B服务器，由于网络协议是基于二进制的，内存中的参数的值要序列化成二进制的形式，也就是序列化（Serialize）或编组（marshal），通过寻址和传输将序列化的二进制发送给B服务器。 第四，B服务器收到请求后，需要对参数进行反序列化（序列化的逆操作），恢复为内存中的表达方式，然后找到对应的方法（寻址的一部分）进行本地调用，然后得到返回值。 第五，返回值还要发送回服务器A上的应用，也要经过序列化的方式发送，服务器A接到后，再反序列化，恢复为内存中的表达方式，交给A服务器上的应用  为什么RPC呢？就是无法在一个进程内，甚至一个计算机内通过本地调用的方式完成的需求，比如比如不同的系统间的通讯，甚至不同的组织间的通讯。由于计算能力需要横向扩展，需要在多台机器组成的集群上部署应用，\nRPC的协议有很多，比如最早的CORBA，Java RMI，Web Service的RPC风格，Hessian，Thrift，甚至Rest API。\n其他 BT 下载工具  qBittorrent Transmission rTorrent Deluge  有支持ed2k的计划吗？ 真是笑死我了，你们难道真的认为那所谓迅雷等国产BT下载软件会使用真正的eDonkey网络？\n非也！它们只不过通过ed2k链接所列出的哈希值 直接链接到它们服务器自身（如迅雷、百度）所存储的文件 或链接到BitTorrent协议的种子和磁力链接上。你们用的软件不是P2P（Peer to Peer），而是P2SP（Peer to Server and to Peer）！\n如果你们用过真正的ed2k下载器（如eMule、aMule）的话，你们会发现，真正的eDonkey网络早已消亡，截至目前全球用户也就50-60万的样子。\n最后，作为曾经的eMule老用户，我可以说明真正的eDonkey网络不仅有繁琐的排队机制，还有文件优先级网络优先级等复杂的设定，远比你们想像中难用的多。\n warez groups\n  RELOADED\nRELOADED成立于2004年，前身是传奇破解组DEVIANCE，曾经在2次重大的政府扫荡中生存下来，由于竞争对手HOODLUM和VENGEANCE被端掉，RELOADED从此称霸PC游戏破解圈，在新游的首发破解上，RELOADED能占据80%。\nRELOADED也是国内最常见的PC游戏破解组，你在各个资源站看到标题写着某某游戏“R组”破解，就是他们的“杰作”。\n高光时刻：\n1、各大破解组都在追求游戏发售前破解游戏，而RELOADED最著名的应该就是2008年对《刺客信条》的破解了，R组在游戏发售1个月之前就放出破解版。\n2、修复了《彩虹六号：维加斯2》数字版的BUG，育碧当年对《彩虹六号：维加斯2》数字版无法运行的BUG毫无办法，最终只能给玩家发放RELOADED的游戏破解补丁\u0026hellip;这次事件让育碧颜面扫地，却成就了RELOADED。\n3、打破《分裂细胞：混沌理论》424天不被破解的记录。\n  SKIDROW\nSKIDROW 是来自美国的游戏破解组，成立时间大概是上个世纪90年代，主要作品有《猎杀潜艇5》、《刺客信条2》等，之后由于人员解散，直到2007年 SKIDROW 才重新开始活跃。\nSKIDROW 在同行中的口碑一般，被RELOADED等破解组爆出过盗用其他破解组代码的料。\n1、 Skidrow成名于DRM事件，DRM是育碧的反破解系统，Skidrow破解组成功破解了育碧两袋DRM系统，最著名的作品是对《刺客信条2》的破解。\n2、2017年，继CPY之后，成功破解了最新的Denuvo64加密技术。并批评CPY只会用Emulation(仿真器)而不是真正的破解。\n  Razor1911\nRazor1911 是来自挪威的破解组，成立于1985年，最初由3个年轻的计算机爱好者组成，主要是破解Commodore64和amiga机种的游戏软件，名称中的1911是因为1991在16进制里写作777，代表不朽。\n作为老牌破解组之一， Razor1911在2001年和2004年的FBI两次反盗版行动中幸存下来，不知道是不是因为名字带来的好运。在业内，如果说RELOADED是以高产著称，那么Razor1911就是以技术见长。\nRazor1911破解组最著名的作品应该是《星际争霸：母巢之战》的硬盘版，间接导致了星际争霸在全世界的流行。\n1、制作《星际争霸：母巢之战》硬盘版，在这一版的星际争霸中，所有文件的体积加起来只有100m多一点，而最为经典的地方就在于他们把光盘版中两个600m左右的install.exe文件压缩到了只有22m的大小。\n2、破解《GTA4》和该游戏价值20万美元的SecuRom反破解系统。\n3、破解EA origin平台的加密技术。\n4、破解《孤岛危机》和《上古卷轴5：天际》。\n  CPY\nCPY全名 CONSPiR4CY，是来自于意大利的破解组，成立于1999年，相比上面的三大破解组成立较晚。但是最近几年，CPY在破解了Denuvo加密技术（D加密）后名声大噪，俨然已超越了上面三大破解组。\n在国内有CPY掌握核心技术的说法，Steam、EA origin、Denuvo等加密技术先后被CPY破解。\n高光时刻：\n1、2015年，继Steam平台后，EA origin平台加密技术被破解，宣布了这套加密系统彻底完蛋。\n2、破解D加密技术，随后一系列热门游戏遭到破解，包括：《合金装备5 幻痛》《古墓丽影 崛起》《毁灭战士4》《看门狗2》等等。\n  CODEX\n会破解D加密，如今几乎已经垄断破解业。并在.nfo文件招聘栏中提到CODEX什么都不要，只要竞争!\n2022年2月，CODEX宣告退休。\n PLAZA EMPRESS    STEAMPUNKS\n  youtube-dl youtube-dl 是一个命令行程序，用于从 YouTube.com 和更多其他网站下载视频。 基于 Python 实现，不限于特定平台。\n# 安装 $ pip install -i https://pypi.tuna.tsinghua.edu.cn/simple youtube-dl # 使用 $ youtube-dl [OPTIONS] URL [URL...] 当前版本（2021.06.06）不能下载哔哩哔哩播放列表，可以用类似软件如 you-get， annie 代替。\nUsage 下载视频或整个视频播放列表\n 要从 Youtube 下载视频或整个视频播放列表，只需直接使用 URL 即可：youtube-dl [url]。程序自动选择一个最清晰的格式下载。 如果要指定视频下载之后的名称，可以使用如下方式：youtube-dl -o '名称' [url]。 还可以在下载视频时附加更多详细信息，可用的参数有标题、上传者名称（频道名称）和视频上传日期等：youtube-dl -o '%(title)s by %(uploader)s on %(upload_date)s in %(playlist)s.%(ext)s' [ul]。  查看视频的所有类型，只看不下载\n命令：youtube-dl -F [url]或者youtube-dl --list-formats [url]。 这是一个列清单参数，执行后并不会下载视频，但能知道这个目标视频都有哪些格式存在，以便有选择的下载。\n下载指定质量的视频和音频并自动合并\n下载最佳/最差质量的音/视频文件：\n默认情况下，youtube-dl将自主选择最佳质量的视频下载。 但是，也可以以特定的质量或格式来下载视频或播放列表\nYoutube-dl 支持以下品质：\n best选择最佳质量的音/视频文件 worst选择质量最差的格式（视频和音频） bestvideo选择最佳质量的仅视频格式（例如DASH视频），可能无法使用。 worstvideo选择质量最差的纯视频格式，可能无法使用。 bestaudio选择最优质的音频格式，可能无法使用。 worstaudio选择质量最差的音频格式，可能无法使用。  例如，如果要自动选择并下载最佳质量格式（音频和视频），只需使用以下命令：youtube-dl -f best [url]。\n您还可以组合使用以下不同的格式选项：youtube-dl -f bestvideo+bestaudio [ul]。该命令将分别下载最高质量的仅视频和最高质量的纯音频格式，再用ffmpeg或avconv合并成一个最佳质量的mkv文件；如果您不想合并，请将+（加号）替换为,（逗号）即可分别得到最高质量的音频和视频（两个文件）：youtube-dl -f 'bestvideo,bestaudio' [url]。\n下载指定质量的音/视频文件：\n-F 获取的所有视频格式的清单，最左边一列就是编号对应着不同的格式。由于YouTube的1080p及以上的分辨率都是音视频分离的，所以我们需要分别下载视频和音频，可以使用137+140这样的组合。如果系统中安装了ffmpeg的话，youtube-dl 会自动合并下好的视频和音频，然后自动删除单独的音视频文件：youtube-dl -f [format code] [url]。\n从播放列表下载视频时，某些视频可能没有相同的格式。 在这种情况下，可以按首选顺序指定多个格式代码，例如：命令youtube-dl -f 22/17/18 \u0026lt;playlist_url\u0026gt;将以格式 22 下载视频（如果可用）；如果格式 22不可用，则它将下载格式 17（如果可用）；如果格式 22 和 17 都不可用，最后尝试下载格式 18。如果所有格式代码都不匹配，Youtube-dl 会报出提示。还需要注意的是，斜杠是左关联的，即最左侧的格式代码是首选。\n下载字幕\n youtube-dl --write-sub [url]这样会下载一个vtt格式的英文字幕和mkv格式的1080p视频下来 youtube-dl --write-sub --skip-download [url]下载单独的vtt字幕文件,而不会下载视频 youtube-dl --write-sub --all-subs [url]下载所有语言的字幕(如果有的话) youtube-dl --write-auto-sub [url]下载自动生成的字幕(YouTube only)  下载多个视频\n youtube-dl \u0026lt;url1\u0026gt; \u0026lt;url2\u0026gt;有时我们需要一次下载多个不同的视频，此时我们只需用空格将多个URL分隔开即可。 youtube-dl -a url.txt也可以将要下载视频的URL全部放在文本文件中，并将其作为参数传递给youtube-dl。此命令将下载url.txt文件中所有URL指向的视频。  只下载（视频中的）音频\n youtube-dl -x [url]仅从视频网站下载其音频。 youtube-dl -x --audio-format mp3 [ul]默认情况下，youtube-dl 将以Ogg （opus）格式保存音频。此命令将从给定的视频/播放列表下载音频，将其转换为 MP3 并将其保存在当前目录中。应注意：您应该安装 ffmpeg 或 avconv 将文件转换为 mp3 格式。  下载带有描述、元数据、注释、字幕和缩略图的视频\n要下载视频及其他详细信息，如：说明、元数据、注释、字幕和缩略图等，请使用以下命令： youtube-dl --write-description --write-info-json --write-annotations --write-sub --write-thumbnail [url]\n通过文件扩展名下载音/视频\n  以您的首选格式下载视频，例如 MP4，只需执行：youtube-dl --format mp4 [url]或者youtube-dl -f mp4 [url]。\n  某些视频可能无法以您的首选格式提供。 在这种情况下，youtube-dl 将下载其他最佳可用格式。例如： youtube-dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best' [ul] 此命令将下载最佳质量的MP4格式文件。如果 MP4 格式不可用，则它将下载其他最佳可用格式。\n限制下载视频的大小\n  从YouTube播放列表下载多个视频时，您可能只想下载特定大小的视频。例如：\n 此命令不会下载任何小于指定大小（例如100MB）的视频：youtube-dl --min-filesize 100M \u0026lt;playlist_url\u0026gt;。 如果您不想下载大于给定大小的视频，可以这样：youtube-dl --max-filesize 100M \u0026lt;playlist_url\u0026gt;。  我们还可以用组合格式，选择运算符来下载特定大小的视频。例如：\n 以下命令将下载最佳视频格式但不大于 100MB 的视频：youtube-dl -f 'best[filesize\u0026lt;100M]' [url]。  按日期下载视频\nYoutube-dl 允许我们按照上传日期来筛选和下载视频或播放列表，例如：\n 要下载 2019 年 8 月 1 日上传的视频，可以使用：youtube-dl --date 20190801 [URL]； 下载在特定日期或之前上传的视频：youtube-dl --datebefore 20190801 [URL]； 下载在特定日期或之后上传的视频：youtube-dl --dateafter 20190101 [URL]； 仅下载过去 6 个月内上传的视频：youtube-dl --dateafter now-6months [URL]； 下载特定时间段内（例如 2018 年 1 月 1 日至 2019 年 1 月 1 日）上传的视频：youtube-dl --dateafter 20180101 --datebefore 20190101 [URL]。  从播放列表下载特定的视频\n从播放列表下载特定的视频，是youtube-dl 的另一个非常有用的功能。例如：\n 要从播放列表下载第 10 个文件，可使用：youtube-dl --playlist-items 10 [playlist_url]； 要下载多个指定的文件，只需用逗号分隔：youtube-dl --playlist-items 2,3,7,10 [playlist_url]；  也可以按序号来指定要下载范围，例如：\n 从第 10 个开始，直接下载完整个列表：youtube-dl --playlist-start 10 [playlist_url]； 在播放列表中仅下载从第 2 到第 5 的文件：youtube-dl --playlist-start 2 --playlist-end 5 [playlist_url]。  Configuration 在 Linux 和 macOS 上，系统配置文件位于 /etc/youtube-dl.conf，用户配置文件位于 ~/.config/youtube-dl/config。\n# Continue on download errors, for example to skip unavailable videos in a playlist --ignore-errors # Time to wait before giving up, in seconds --socket-timeout 10 # Download only videos not listed in the archive file. Record the IDs of all downloaded videos in it. #--download-archive /path/archive.txt # Number of retries (default is 10), or \u0026#34;infinite\u0026#34;. --retries infinite # Give these arguments to the external downloader --external-downloader aria2c --external-downloader-args \u0026#34;--no-conf -c\u0026#34; # Output filename template, see the \u0026#34;OUTPUT TEMPLATE\u0026#34; for all the info -o \u0026#39;~/Videos/%(id)s.%(ext)s\u0026#39; # Write thumbnail image to disk #--write-thumbnail # download best 30hz mp4 file , h264+aac ,use http or https protocol,because we can use aria2c downloader to have a faster speed --format \u0026#39;(bestvideo[ext=mp4][fps\u0026lt;31]+bestaudio[ext=m4a]/best[ext=mp4]/bestvideo+bestaudio/best)[protocol^=http]\u0026#39; # Embed thumbnail in the audio as cover art #--embed-thumbnail # Write metadata to the video file --add-metadata curl 简介 curl 是常用的命令行工具，用来请求 Web 服务器。它的名字就是客户端（client）的 URL 工具的意思。\n它的功能非常强大，命令行参数多达几十种。如果熟练的话，完全可以取代 Postman 这一类的图形界面工具。\n本文介绍它的主要命令行参数，作为日常的参考，方便查阅。\n不带有任何参数时，curl 就是发出 GET 请求。\n$ curl https://www.example.com 上面命令向www.example.com发出 GET 请求，服务器返回的内容会在命令行输出。\n主要命令行参数 -A\n-A参数指定客户端的用户代理标头，即User-Agent。curl 的默认用户代理字符串是curl/[version]。\n$ curl -A \u0026#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36\u0026#39; https://google.com 上面命令将User-Agent改成 Chrome 浏览器。\n$ curl -A \u0026#39;\u0026#39; https://google.com 上面命令会移除User-Agent标头。\n也可以通过-H参数直接指定标头，更改User-Agent。\n$ curl -H \u0026#39;User-Agent: php/1.0\u0026#39; https://google.com -b\n-b参数用来向服务器发送 Cookie。\n$ curl -b \u0026#39;foo=bar\u0026#39; https://google.com 上面命令会生成一个标头Cookie: foo=bar，向服务器发送一个名为foo、值为bar的 Cookie。\n$ curl -b \u0026#39;foo1=bar;foo2=bar2\u0026#39; https://google.com 上面命令发送两个 Cookie。\n$ curl -b cookies.txt https://www.google.com 上面命令读取本地文件cookies.txt，里面是服务器设置的 Cookie（参见-c参数），将其发送到服务器。\n-c\n-c参数将服务器设置的 Cookie 写入一个文件。\n$ curl -c cookies.txt https://www.google.com 上面命令将服务器的 HTTP 回应所设置 Cookie 写入文本文件cookies.txt。\n-d\n-d参数用于发送 POST 请求的数据体。\n$ curl -d \u0026#39;login=emma＆password=123\u0026#39;-X POST https://google.com/login # 或者 $ curl -d \u0026#39;login=emma\u0026#39; -d \u0026#39;password=123\u0026#39; -X POST https://google.com/login 使用-d参数以后，HTTP 请求会自动加上标头Content-Type : application/x-www-form-urlencoded。并且会自动将请求转为 POST 方法，因此可以省略-X POST。\n-d参数可以读取本地文本文件的数据，向服务器发送。\n$ curl -d \u0026#39;@data.txt\u0026#39; https://google.com/login 上面命令读取data.txt文件的内容，作为数据体向服务器发送。\n\u0026ndash;data-urlencode\n--data-urlencode参数等同于-d，发送 POST 请求的数据体，区别在于会自动将发送的数据进行 URL 编码。\n$ curl --data-urlencode \u0026#39;comment=hello world\u0026#39; https://google.com/login 上面代码中，发送的数据hello world之间有一个空格，需要进行 URL 编码。\n-e\n-e参数用来设置 HTTP 的标头Referer，表示请求的来源。\ncurl -e \u0026#39;https://google.com?q=example\u0026#39; https://www.example.com 上面命令将Referer标头设为https://google.com?q=example。\n-H参数可以通过直接添加标头Referer，达到同样效果。\ncurl -H \u0026#39;Referer: https://google.com?q=example\u0026#39; https://www.example.com -F\n-F参数用来向服务器上传二进制文件。\n$ curl -F \u0026#39;file=@photo.png\u0026#39; https://google.com/profile 上面命令会给 HTTP 请求加上标头Content-Type: multipart/form-data，然后将文件photo.png作为file字段上传。\n-F参数可以指定 MIME 类型。\n$ curl -F \u0026#39;file=@photo.png;type=image/png\u0026#39; https://google.com/profile 上面命令指定 MIME 类型为image/png，否则 curl 会把 MIME 类型设为application/octet-stream。\n-F参数也可以指定文件名。\n$ curl -F \u0026#39;file=@photo.png;filename=me.png\u0026#39; https://google.com/profile 上面命令中，原始文件名为photo.png，但是服务器接收到的文件名为me.png。\n-G\n-G参数用来构造 URL 的查询字符串。\n$ curl -G -d \u0026#39;q=kitties\u0026#39; -d \u0026#39;count=20\u0026#39; https://google.com/search 上面命令会发出一个 GET 请求，实际请求的 URL 为https://google.com/search?q=kitties\u0026amp;count=20。如果省略--G，会发出一个 POST 请求。\n如果数据需要 URL 编码，可以结合--data--urlencode参数。\n$ curl -G --data-urlencode \u0026#39;comment=hello world\u0026#39; https://www.example.com -H\n-H参数添加 HTTP 请求的标头。\n$ curl -H \u0026#39;Accept-Language: en-US\u0026#39; https://google.com 上面命令添加 HTTP 标头Accept-Language: en-US。\n$ curl -H \u0026#39;Accept-Language: en-US\u0026#39; -H \u0026#39;Secret-Message: xyzzy\u0026#39; https://google.com 上面命令添加两个 HTTP 标头。\n$ curl -d \u0026#39;{\u0026#34;login\u0026#34;: \u0026#34;emma\u0026#34;, \u0026#34;pass\u0026#34;: \u0026#34;123\u0026#34;}\u0026#39; -H \u0026#39;Content-Type: application/json\u0026#39; https://google.com/login 上面命令添加 HTTP 请求的标头是Content-Type: application/json，然后用-d参数发送 JSON 数据。\n-i\n-i参数打印出服务器回应的 HTTP 标头。\n$ curl -i https://www.example.com 上面命令收到服务器回应后，先输出服务器回应的标头，然后空一行，再输出网页的源码。\n-I\n-I参数向服务器发出 HEAD 请求，然会将服务器返回的 HTTP 标头打印出来。\n$ curl -I https://www.example.com 上面命令输出服务器对 HEAD 请求的回应。\n--head参数等同于-I。\n$ curl --head https://www.example.com -k\n-k参数指定跳过 SSL 检测。\n$ curl -k https://www.example.com 上面命令不会检查服务器的 SSL 证书是否正确。\n-L\n-L参数会让 HTTP 请求跟随服务器的重定向。curl 默认不跟随重定向。\n$ curl -L -d \u0026#39;tweet=hi\u0026#39; https://api.twitter.com/tweet \u0026ndash;limit-rate4\n--limit-rate用来限制 HTTP 请求和回应的带宽，模拟慢网速的环境。\n$ curl --limit-rate 200k https://google.com 上面命令将带宽限制在每秒 200K 字节。\n-o\n-o参数将服务器的回应保存成文件，等同于wget命令。\n$ curl -o example.html https://www.example.com 上面命令将www.example.com保存成example.html。\n-O\n-O参数将服务器回应保存成文件，并将 URL 的最后部分当作文件名。\n$ curl -O https://www.example.com/foo/bar.html 上面命令将服务器回应保存成文件，文件名为bar.html。\n-s\n-s参数将不输出错误和进度信息。\n$ curl -s https://www.example.com 上面命令一旦发生错误，不会显示错误信息。不发生错误的话，会正常显示运行结果。\n如果想让 curl 不产生任何输出，可以使用下面的命令。\n$ curl -s -o /dev/null https://google.com -S\n-S参数指定只输出错误信息，通常与-s一起使用。\n$ curl -s -o /dev/null https://google.com 上面命令没有任何输出，除非发生错误。\n-u\n-u参数用来设置服务器认证的用户名和密码。\n$ curl -u \u0026#39;bob:12345\u0026#39; https://google.com/login 上面命令设置用户名为bob，密码为12345，然后将其转为 HTTP 标头Authorization: Basic Ym9iOjEyMzQ1。\ncurl 能够识别 URL 里面的用户名和密码。\n$ curl https://bob:12345@google.com/login 上面命令能够识别 URL 里面的用户名和密码，将其转为上个例子里面的 HTTP 标头。\n$ curl -u \u0026#39;bob\u0026#39; https://google.com/login 上面命令只设置了用户名，执行后，curl 会提示用户输入密码。\n-v\n-v参数输出通信的整个过程，用于调试。\n$ curl -v https://www.example.com --trace参数也可以用于调试，还会输出原始的二进制数据。\n$ curl --trace - https://www.example.com -x\n-x参数指定 HTTP 请求的代理。\n$ curl -x socks5://james:cats@myproxy.com:8080 https://www.example.com 上面命令指定 HTTP 请求通过myproxy.com:8080的 socks5 代理发出。\n如果没有指定代理协议，默认为 HTTP。\n$ curl -x james:cats@myproxy.com:8080 https://www.example.com 上面命令中，请求的代理使用 HTTP 协议。\n-X\n-X参数指定 HTTP 请求的方法。\n$ curl -X POST https://www.example.com 上面命令对https://www.example.com发出 POST 请求。\nHTTPie HTTPie（http）以一种更人性化的方式做同样的工作。你会看到彩色的、格式化的输出，这使得它更容易理解和调试。\naxel Lightweight CLI download accelerator\nUSENET 起源 简单地说，USENET是一个巨大无比的网上讨论组，一般也称为\u0026quot;新闻组\u0026quot;（newsgroups）。你可以将它想象成一个包罗万象、无所不有的网上论坛，但是它又不同于我们通常看到的普通论坛。这要从它的起源说起。\n上个世纪70年代末，当时还没有互联网和浏览器，它们都要在十多年后才会出现。那时所谓\u0026quot;上网\u0026quot;，就是用modem（调制解调器），拨一个电话号码，将自己的电脑连到另一台电脑（也称\u0026quot;主机\u0026quot;），收收邮件，看看上面系统管理员发的通告。如果想换一台主机看看，那就必须先挂断，再拨另外一个电话号码。\n这样的上网方式，很不利于开展多人的讨论。由于是拨号上网，只有地理位置相近的用户，才会登录同一台主机。很难想象，同一台机器的登录用户，既有东岸的纽约人，也有西岸的洛杉矶人。即使长途电话费不是问题，当时的主机也没有能力同时负担太多的远程终端。因此，迫切需要一种大规模的、分布式的、多中心的远程信息交换手段。\n1979年，Duke大学的两个研究生Tom Truscott和Jim Ellis，提出一种分布式的网上讨论组的构想。这种讨论组创建之初，主要是供UNIX爱好者协会（USENIX）的成员使用，因此就被定名为USENET。当然，后来全世界的用户都在使用它。\n运行机制 USENET的运行机制其实非常简单。对于用户来说，只有三步。\n1）网络服务提供商（ISP）在一个网络中，设定一台服务器作为USENET专用服务器，再将它的网址告诉用户。\n2）用户想要发言的时候，就向这个网址发送帖子（post），这与发送Email很相似，但是两者格式不一样，在USENET上发言必须使用专用的客户端。不过，现在大多数的Email客户端都带有新闻组功能，最常见的Outlook Express的设置可以参考网上的说明。\n3）查看其他人的发言时，就必须从服务器上下载其他人的帖子。下载完成后，如果想回复某人的帖子，就再重复第二步。\n可以看到，这个过程同邮件列表的运行几乎一模一样，不同之处在于，USENET服务器每天会同其他USENET服务器交换帖子。这就是说，全世界所有的USENET服务器最终都可以互相交换帖子，保持内容的同步。所以理论上，不管你的帖子是发到哪一台服务器上，最终全世界的人们都会看到，并且会从世界各地给你回复。\n因此，USENET就有一个其他交流机制所没有的优点，即这是一个真正的全世界参与的讨论组。\n内容结构 由于USENET中的讨论内容无所不包，所以必须根据主题分类。每一个主题就是一个\u0026quot;频道\u0026quot;，对这个主题感兴趣的用户就订阅这个频道。\nUSENET中的主题分类采用等级制（hierarchies），在形式上同域名很相似，即\u0026quot;一级主题.二级主题.三级主题\u0026hellip;.\u0026quot;，中间以小数点分隔。\n一级主题有9个。\n * comp.*: 与计算机相关的讨论。（computer-related discussions，比如comp.software, comp.sys.amiga）\n* misc.*: 各种不属于其他分类的主题。（Miscellaneous topics，比如misc.education, misc.forsale, misc.kids）\n* news.*: 对USENET本身的讨论（比如news.groups, news.admin）\n* rec.*: 休闲和娱乐（Recreation and entertainment，比如rec.music, rec.arts.movies）\n* sci.*: 与科学相关的讨论。（Science related discussions，比如sci.psychology, sci.research）\n* soc.*: 与社会相关的讨论。（Social discussions，比如soc.college.org, soc.culture.african）\n* talk.*: 各种争议性话题的讨论。（Talk about various controversial topics，比如talk.religion, talk.politics, talk.origins）\n* humanities.*: 艺术、文学、哲学方面的讨论。（Fine arts, literature, and philosophy，比如humanities.classics, humanities.design.misc）\n* alt.*: 自由讨论区。（alternative）\n 这9个一级主题中，除了alt.*以外，都不能自行设立讨论区。只有在alt主题区中，可以自己发起主题\u0026quot;频道\u0026quot;。\n二进制内容 USENET最初设计的时候，只打算用来传递文本信息，没有考虑传递二进制数据（也就是\u0026quot;文件\u0026quot;）。但是，随着互联网的发展，不传递二进制数据看上去是不可能的。\n于是，专门的编码方式被设计了出来，使得二进制文件可以转换成文本文件，在USENET上传递，用户下载以后再传换成原来的格式。这时，USENET就不仅是一个讨论组了，而成了传递文件的一种手段，图片、音频和视频都可以通过USENET传播。\n事实上，如今USENET上的流量，99%都已经是二进制文件了。它们大部分都在alt.binaries这个主题中传播。由于不受监管，所以各种各样的文件都有。\n收费服务 根据一项统计，2007年4月USENET上一天的流量为3.12TB，且还在快速增加中。这么大的流量，使得世界上提供USENET的服务商肯定不会很多。大家可以查看这个网页，上面有USENET提供商的不完全列表。\n这些服务商，又分为免费和收费两种。免费的USENET绝大多数都不提供二进制文件下载，查看alt.free.newsservers主题可以获得最新的免费USENET服务器的信息。\n在收费服务商中，名气比较大的是GIGANEWS，它提供多种收费账户供用户选择。其中白金用户每月费用为19.99美元，可以无限量下载，14天内不满意可以退款。如果你是一个狂热的下载爱好者，我强烈推荐去购买一个账户。\nGoogle Groups Google Groups也提供免费USENET服务。（当然，没有二进制文件下载。）我会另写文章专门介绍，这里就省略了。\n百度网盘 阿里云盘小白羊版 BaiduPCS-Go 坚果云 xdm Powerfull download accelerator and video downloader\nMotrix A full-featured download manager.\nThunder flatpak 版迅雷下载，用于下载 ed2k 链接。\nEditor 修改預設 editor visudo 等操作会打开默认编辑器，在linux中默认编辑器读取EDITOR环境变量，可通过一下命令设置\n$ export EDITOR=nano 可将其加入~/.bashrc文件，使得每次登录都可使用\n$ nano ~/.bashrc export EDITOR=nano $ . ~/.bashrc debian系统提供了一个管理工具来设置默认编辑器。執行下面的指令，就可以設定改用其他慣用的文字編輯器了。\n$ sudo update-alternatives --config editor 會出現一個類似如下的列表，選擇你預設要使用的文字編輯器就行了。\nThere are 5 choices for the alternative editor (providing /usr/bin/editor). Selection Path Priority Status ------------------------------------------------------------ * 0 /bin/nano 40 auto mode 1 /bin/ed -100 manual mode 2 /bin/nano 40 manual mode 3 /usr/bin/nvim 30 manual mode 4 /usr/bin/vim.basic 30 manual mode 5 /usr/bin/vim.tiny 15 manual mode Press \u0026lt;enter\u0026gt; to keep the current choice[*], or type selection number: 我輸入「3」，按下「Enter」。\n上面的操作完畢後驗證一下,看看是不是你想要預設使用的編輯器。\n執行下面的指令\n$ editor 或是執行下面的指令\n$ sensible-editor 另外也可以直接執行下面的指令，更改成你慣用的文字編輯器\n例如：\n慣用 vim.tiny\n$ sudo update-alternatives --set editor /usr/bin/vim.tiny VSCode Alternatively, the repository and key can also be installed manually with the following script:\n$ sudo apt-get install wget gpg $ wget -qO- https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor \u0026gt; packages.microsoft.gpg $ sudo install -D -o root -g root -m 644 packages.microsoft.gpg /etc/apt/keyrings/packages.microsoft.gpg $ sudo sh -c \u0026#39;echo \u0026#34;deb [arch=amd64,arm64,armhf signed-by=/etc/apt/keyrings/packages.microsoft.gpg] https://packages.microsoft.com/repos/code stable main\u0026#34; \u0026gt; /etc/apt/sources.list.d/vscode.list\u0026#39; $ rm -f packages.microsoft.gpg Then update the package cache and install the package using:\n$ sudo apt install apt-transport-https $ sudo apt update $ sudo apt install code # or code-insiders $ cat /usr/share/applications/code.desktop [Desktop Entry] Name=Visual Studio Code Comment=Code Editing. Redefined. GenericName=Text Editor Exec=/usr/share/code/code --unity-launch %F Icon=com.visualstudio.code Type=Application StartupNotify=false StartupWMClass=Code Categories=TextEditor;Development;IDE; MimeType=text/plain;inode/directory;application/x-code-workspace; Actions=new-empty-window; Keywords=vscode; [Desktop Action new-empty-window] Name=New Empty Window Exec=/usr/share/code/code --new-window %F Icon=com.visualstudio.code GitHub VS Code Web\n只要访问下面的网址，你就能在浏览器里面，使用 VS Code 编辑指定仓库。\nhttps://github.dev/[用户名]/[仓库名] 它实际上就是 VS Code 编辑器的 Web 版，并且与 Git 高度集成。\n国内下载速度慢\n使用 azure 中国 cdn 镜像地址加速下载 VSCode\n将默认下载地址替换为 vscode.cdn.azure.cn\ncode-server\nVS Code in the browser\n可以提高兼容性，解决输入法之类的问题。\n配置 Press CTRL+SHIFT+P, then search for\nOpen User Settings (JSON)\n{ // 每80和120行就显示一条线  \u0026#34;editor.rulers\u0026#34;: [ 80, 120 ], // 失去焦点后自动保存  \u0026#34;files.autoSave\u0026#34;: \u0026#34;onFocusChange\u0026#34;, // 每次保存的时候自动格式化  \u0026#34;editor.formatOnSave\u0026#34;: true, // 缩进  \u0026#34;editor.tabSize\u0026#34;: 4, \u0026#34;editor.insertSpaces\u0026#34;: true, \u0026#34;editor.detectIndentation\u0026#34;: false, // 自动换行  \u0026#34;editor.wordWrap\u0026#34;: \u0026#34;off\u0026#34; } Open Keyboard Shortcuts (JSON)\n// Place your key bindings in this file to override the defaults [ { \u0026#34;key\u0026#34;: \u0026#34;ctrl+shift+u\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;editor.action.transformToUppercase\u0026#34;, \u0026#34;when\u0026#34;: \u0026#34;editorTextFocus\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;ctrl+shift+l\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;editor.action.transformToLowercase\u0026#34;, \u0026#34;when\u0026#34;: \u0026#34;editorTextFocus\u0026#34; } ] 参考：\n How can I customize the tab-to-space conversion factor? Vertical rulers in Visual Studio Code Make selected block of text uppercase vscode.settings.json  快捷键 对于 行 的操作：\n 重开一行：光标在行尾的话，回车即可；不在行尾，ctrl + enter 向下重开一行；ctrl+ shift + enter 则是在上一行重开一行 删除一行：光标没有选择内容时，ctrl + x 剪切一行；ctrl + shift + k 直接删除一行 移动一行：alt + ↑ 向上移动一行；alt + ↓ 向下移动一行 复制一行：shift + alt + ↓ 向下复制一行；shift + alt + ↑ 向上复制一行 ctrl + z 回退  对于 词 的操作：\n 选中一个词：ctrl + d  搜索或者替换：\n ctrl + f ：搜索 ctrl + alt + f： 替换 ctrl + shift + f：在项目内搜索  通过 Ctrl + ` 可以打开或关闭终端\nCtrl+P 快速打开最近打开的文件\nCtrl+Shift+N 打开新的编辑器窗口\nCtrl+Shift+W 关闭编辑器\nHome 光标跳转到行头\nEnd 光标跳转到行尾\nCtrl + Home 跳转到页头\nCtrl + End 跳转到页尾\nCtrl + Shift + [ 折叠区域代码\nCtrl + Shift + ] 展开区域代码\nCtrl + / 添加关闭行注释\nShift + Alt +A 块区域注释\n插件  open in browser：运行html文件 Auto Rename Tag：自动修改匹配的 HTML 标签。 VS Code Hex Editor  Truste folders Using a single trusted folder to hold your projects\nIf you work with many projects that you trust and don\u0026rsquo;t want to be prompted about trusting each one individually, you can consider trusting their parent folder.\n Using Ctrl + Shift + P run the Workspaces: Manage Workspace Trust command Scroll down to the Trusted folders and workspaces section and click Add Folder Select the parent folder of all your trusted workspaces  Now any project you open under the parent folder will be trusted automatically.\nGoogle Keep web version.\nGoogle Keep键盘快捷键\n   hortcut Action     J/K Next/previous note   Shift + J/K Move note to next/previous position   N/P Next/previous list item   Shift + N/P Move list item to next/previous position   C New note   L New list   / Search   Ctrl + A Select all   E Archive   # Delete   F Pin/unpin   X Select   Ctrl + G Toggle list and grid view   Esc Close editor   Ctrl + Shift + 8 Toggle checkboxes   Ctrl + ] / [ Indent/dedent list item   ? Open shortcut list   @ Send feedback    Joplin $ wget -O - https://raw.githubusercontent.com/laurent22/joplin/dev/Joplin_install_and_update.sh | bash joplin.desktop\n[Desktop Entry] Encoding=UTF-8 Name=Joplin Comment=Joplin for Desktop Exec=${HOME}/.joplin/Joplin.AppImage ${SANDBOXPARAM} %u Icon=joplin StartupWMClass=Joplin Type=Application Categories=Office; MimeType=x-scheme-handler/joplin; X-GNOME-SingleWindow=true // should be removed eventually as it was upstream to be an XDG specification SingleMainWindow=true 为知笔记 notion 思源笔记 备份盘 \u0026amp; 同步盘  备份盘：\n同步盘：\nObsidian 闭源软件，但超好用。\n最适合程序员的笔记软件 程序员的笔记软件，应该满足下面几个条件。\n 跨平台，同时支持桌面电脑（Windows，Mac，Linux）和手机（Android，iOS）。 随时同步，打开任何一台机器，都能接着上一次的工作继续写。 实时存储，如果软件突然关闭，也不会丢失内容。 支持 Markdown 格式，便于后期直接发布。 支持推送到远程 Git 仓库，产生历史版本，同时作为远程备份。  Stackedit.io 和 HackMD.io，都不是很理想。\nGitHub 官方推出的 github.dev。只要访问 https://github.dev/[用户名]/[仓库名]，你就能在浏览器里面，使用 VS Code 编辑指定仓库。它实际上就是 VS Code 编辑器的 Web 版，并且与 Git 高度集成。GitHub 提供了一个快捷入口。 打开 GitHub 仓库主页，按一下小数点（.）这个键， 页面就会自动跳转到 VS Code 编辑环境。\n如果你更希望使用手机原生 App，我推荐 Obsidian。它有全平台的客户端，并且可以参考这篇文章设置 Git 集成。\n评论里还有很多推荐，选择一个合适的就行。\n安装 使用 AppImage 报 dlopen(): error loading libfuse.so.2 错误：\n$ sudo apt install libfuse2 自动同步 全平台同步使用 remotely-save，同时将文档备份到 Git。\n我希望在每次关闭 Obsidian 窗口（即编辑完毕后）自动同步内容到 Git 仓库\n  obsidian.desktop\n[Desktop Entry] Name=Obsidian GenericName=Markdown Editor Exec=/home/kurome/.opt/obsidian/obsidian Icon=obsidian Type=Application StartupNotify=true Categories=Office;WordProcessor; MimeType=x-scheme-handler/obsidian;text/html;text/markdown;text/x-markdown;   obsidian\n#!/usr/bin/bash TIME=\u0026#34;$(date \u0026#39;+%Y%m%d%H%M%S\u0026#39;)\u0026#34; NOTEON=$HOME/Documents/Note_ON function Git_Sync() { cd $NOTEON git pull echo \u0026#39;#Ignore files larger than 100MB\u0026#39; cat .gitignore_default \u0026gt; .gitignore find . -size +100M | sed \u0026#39;s|^./||g\u0026#39; | cat \u0026gt;\u0026gt; .gitignore git add . git commit -m \u0026#34;Update-${TIME}\u0026#34; git push -v } /home/kurome/.opt/obsidian/Obsidian-0.15.6.AppImage trap Git_Sync EXIT   Typora 安装：\n# sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys BA300B7755AFCFAE $ wget -qO - https://typora.io/linux/public-key.asc | $ sudo apt-key add - # add Typora\u0026#39;s repository $ sudo add-apt-repository \u0026#39;deb https://typora.io/linux ./\u0026#39; $ sudo apt-get update # install typora $ sudo apt-get install typora 如果安装的时二进制包，则建立 typora.desktop\n$ gedit ~/.local/share/applications/typora.desktop [Desktop Entry] Name=Typora Comment=a minimal Markdown reading \u0026amp; writing app. Change Log: (https://typora.io/windows/dev_release.html) GenericName=Markdown Editor Exec=/home/kurome/.opt/typora/Typora %U Icon=typora Type=Application StartupNotify=true Categories=Office;WordProcessor; MimeType=text/markdown;text/x-markdown; typora 有时会出现丢数据的现象，很困扰；特别是围栏代码块，失去了缩进，成了一行，完全不可阅读了。但是其他的 Markdown Editor 用的不习惯，例如 VSCode、Sublime、ghostwriter、marktext。因此最好通过 ppa 安装，获取 Typora 最新的版本。\n在Joplin下，菜单Tools-\u0026gt;Options-\u0026gt;General\u0026gt;Text editor command可以设置第三方编辑软件。\n配置 File \u0026gt; Preferences：\n General \u0026gt; Auto Save: on Editor \u0026gt; Spell Check: Disable Image \u0026gt; Use relative path if possible: on Markdown \u0026gt; Syntax Support \u0026gt; Inline Math: on  有时候标点符号没有与文字对齐，比如句号在右中，而不是右下，可以将语言设置为中文（it works for me）。\nCan I use Typora for free ?\nYou will have a 15-day free trial before the purchase. If you use the dev version or the Linux version, you will have much longer trial time if you keep Typora updated. However, we may show a “trial button”, disable certain features or shorten trial time in the future, but most functions will be kept.\nTypora’s pricing plan\nIt is one-time payment, not subscription.\nA Typora license is granted to the “user”, which can be activated on up to 3 devices from one person for one license with no expiration time.\nYou will have 15 days to evaluate Typora for free before purchasing a license code. If you’re not satisfied with Typora for any reason, you will be able to get a full refund within 30 days from the license purchase.\nRecover Unsaved Drafts\nPreferences =\u0026gt; General =\u0026gt; Save \u0026amp; Recover =\u0026gt; Recover Unsaved Drafts =\u0026gt; 选择要恢复的文档，打开后另存为到之前保存的地址覆盖它即可\nCtrl 5 of typora does not work\n不知道哪里覆盖了。重新定义一个快捷键。\nOpen Menu → Preference in Typora, then click “Open Advanced Settings”.\n\u0026#34;keyBinding\u0026#34;: { \u0026#34;Heading 5\u0026#34;: \u0026#34;Alt+5\u0026#34;, }, 主题推荐\nGitHub 主题，很习惯了：\n D42ker GitHub Github  MarkText Foxit PDF Reader Industry’s most powerful PDF reader.\nPortable PDF Unlocker/PDFCrack Print the Secured PDF in Google Chrome\n有的用户虽然记得PDF文档的密码，但由于经常使用这个PDF文档，为了方便使用也想将这个密码去除。而去除的方法也非常简单，用最常见的谷歌浏览器就可以做到。首先运行谷歌浏览器，将需要去除密码的PDF文档拖曳进浏览器窗口。这时会弹出一个对话框，输入相应的密码就可以看到内容。接着在文档内容中点击鼠标右键，选择菜单里面的“打印”命令。\n在弹出的打印窗口点击左侧“目标”中的“更改”按钮，在弹出的对话框中选择“本地目标”中的“另存为PDF”命令。返回到打印窗口后直接点击“保存”按钮，在弹出的对话框里面设置文档的保存位置，再点击“保存”按钮就会将当前的PDF文档另外存储一份，这样也就相当于去除了PDF文档的密码了。\nOnline PDF Password Remover\n https://smallpdf.com/unlock-pdf https://www.ilovepdf.com/unlock_pdf  **How to Unlock A PDF for Editing Without Password? [Five Methods]**\npdftk 给 pdf 电子书加目录\n对许多人来说 pdf 格式的电子书最头疼的两件事： → 1) 每页都是没经过 OCR 处理过的图片 2) 没有目录。\n以下这个批量加目录的方法我用好久了，见过我这么操作过的都想学一下，这里详细地记录以下，也方便以后有人再问的时候 :)\n用到的软件是 pdftk pdftk-java 。linux 发行版一般都有这个这个软件可以直接安装。\npdftk 的用法就是：输出 (dump_data) pdf 的元信息 (data.txt)，编辑以后，重新倒入 (update_info) 到 pdf 文件里面\n主要是这两条命令:\npdftk [my.pdf] dump_data \u0026gt; [data.txt] pdftk [my.pdf] update_info [data.txt] output my2.pdf 在第一条命令输出的 data.txt 里面加入如下的内容，然后通过第二条命令就可以创建新的目录条目\nBookmarkBegin BookmarkTitle: name BookmarkLevel: level BookmarkPageNumber: page number 另外电子书的第一页通常是封面，紧接着的是其它的东西。但是书里面标注的页码的第一页往往后面的某页。\nPDF 支持把页码标注成其它的格式 (page_labels)，第一页标注成 cover，第二到第十页标注成罗马数字，然后从第十一页标注成 1,2,3,4,5,6…\n# 把第一页标注成名字为 cover 的非数字 (NoNumber) PageLabelBegin PageLabelNewIndex: 1 PageLabelStart: 1 PageLabelPrefix: cover PageLabelNumStyle: NoNumber # 从第二页 (PageLabelNewIndex) 开始标注成小写罗马数字 (LowercaseRomanNumerals) PageLabelBegin PageLabelNewIndex: 2 PageLabelStart: 1 # 从数字 1 开始数，如果这里变成 3 =\u0026gt; 起始的罗马数字会是 iii PageLabelNumStyle: LowercaseRomanNumerals # 从 {true start page} 开始用普通的数字标注 PageLabelBegin PageLabelNewIndex: {true start page} PageLabelStart: 1 PageLabelNumStyle: DecimalArabicNumerals 对于一本书，这种手动添加的方法会很慢，下面是一个小脚本来半自动化。\n 由于电子书 100% 可以搜索到目录 编号 标题 页码。如果搜索不到，也可以直接从书里面复制。\n复制粘贴一下，调整成这种格式\n14 I: Reduction Semantics\t1 1 Semantics via Syntax\t5 2 Analyzing Syntactic Semantics\t13 3 The λ-Calculus\t23 4 ISWIM\t45 II: PLT Redex\t201 11 The Basics\t205 12 Variables and Meta-functions\t217 13 Layered Development\t227 14 Testing\t237 ...... 第一行是对于人类，而非 pdf 格式来说真正的第一页\n后面根据行首 tab 的数量来决定目录的层级\n每行后面的数字是页码\n然后用这个小脚本 toc-gen.py\n#!/usr/bin/env python3 # # Usage # toc-gen.py \u0026lt; edited-toc.txt # def make_offset(off: int): if off \u0026gt; 1: print(\u0026#34;\u0026#34;\u0026#34;PageLabelBegin PageLabelNewIndex: 1 PageLabelStart: 1 PageLabelPrefix: cover PageLabelNumStyle: NoNumber\u0026#34;\u0026#34;\u0026#34;) if off \u0026gt; 2: print(\u0026#34;\u0026#34;\u0026#34;PageLabelBegin PageLabelNewIndex: 2 PageLabelStart: 1 PageLabelNumStyle: LowercaseRomanNumerals\u0026#34;\u0026#34;\u0026#34;) print(f\u0026#34;\u0026#34;\u0026#34;PageLabelBegin PageLabelNewIndex: {off}PageLabelStart: 1 PageLabelNumStyle: DecimalArabicNumerals\u0026#34;\u0026#34;\u0026#34;) def make_bookmark(t: str, l: int, p: int): print(f\u0026#34;\u0026#34;\u0026#34;BookmarkBegin BookmarkTitle: {t}BookmarkLevel: {l}BookmarkPageNumber: {p}\u0026#34;\u0026#34;\u0026#34;) if __name__ == \u0026#39;__main__\u0026#39;: offset = int(input()) make_offset(offset) while True: try: line = input() if not line.strip(): break except EOFError: break title = \u0026#34; \u0026#34;.join(line.split()[0:-1]) n_of_tabs = len(line) - len(line.lstrip()) page = int(line.split()[-1]) make_bookmark(t=title, l=n_of_tabs + 1, p=page + offset) 来获取这些内容，把这些内容粘贴到 [data.txt] 后面，然后再用 pdftk 的第二条命令\nPageLabelBegin PageLabelNewIndex: 1 PageLabelStart: 1 PageLabelPrefix: cover PageLabelNumStyle: NoNumber PageLabelBegin PageLabelNewIndex: 2 PageLabelStart: 1 PageLabelNumStyle: LowercaseRomanNumerals PageLabelBegin PageLabelNewIndex: 14 PageLabelStart: 1 PageLabelNumStyle: DecimalArabicNumerals BookmarkBegin BookmarkTitle: Reduction Semantics BookmarkLevel: 1 BookmarkPageNumber: 15 BookmarkBegin BookmarkTitle: Semantics via Syntax BookmarkLevel: 2 BookmarkPageNumber: 19 BookmarkBegin BookmarkTitle: Analyzing Syntactic Semantics BookmarkLevel: 2 BookmarkPageNumber: 27 BookmarkBegin BookmarkTitle: The λ-Calculus BookmarkLevel: 2 BookmarkPageNumber: 37 BookmarkBegin BookmarkTitle: ISWIM BookmarkLevel: 2 BookmarkPageNumber: 59 BookmarkBegin BookmarkTitle: An Abstract Syntax Machine BookmarkLevel: 2 BookmarkPageNumber: 79 BookmarkBegin BookmarkTitle: Abstract Register Machines BookmarkLevel: 2 BookmarkPageNumber: 103 BookmarkBegin BookmarkTitle: Tail Calls and More Space Savings BookmarkLevel: 2 BookmarkPageNumber: 121 BookmarkBegin BookmarkTitle: Control: Errors, Exceptions, and Continuations BookmarkLevel: 2 BookmarkPageNumber: 129 BookmarkBegin BookmarkTitle: State: Imperative Assignment .............. Bingo! 这下舒服了 :)\nTesseract Tesseract Open Source OCR Engine\n更多 OCR 软件请看：Comparison of optical character recognition software\nEvaluation：An analysis of the accuracy and reliability of the OCR packages Google Docs OCR, Tesseract, ABBYY FineReader, and Transym, employing a dataset including 1227 images from 15 different categories concluded Google Docs OCR and ABBYY to be performing better than others.\nOCRmyPDF OCRmyPDF adds an OCR text layer to scanned PDF files, allowing them to be searched\nPandaOCR PandaOC/R - 多功能OCR图文识别+翻译+朗读+弹窗+公式+表格+图床+搜图+二维码\ngImageReader A Gtk/Qt front-end to tesseract-ocr.\nOCRfeeder 支持多个 OCR 后端，例如Tesseract、CuneiForm、GOCR、Ocrad\ntianruoocr 简介：基于天若幽心开源的代码进行完善制作而成，进行了简单重构，移除了更新的弹窗。\n已停止维护，欢迎使用新版跨平台 OCR 工具（树洞 OCR 文字识别），跟之前天若OCR使用习惯出入较大，且不支持翻译。\nmarguerite 答 ORC 我来告诉你什么是 OCR：\nOCR 说白了就是，把一个特定字体的某个字变成计算机可匹配的位置数据，比如在 50x50 像素的格子里，「儿」这个字的撇的黑色像素点落在大概 (30~45, 0~100) 这个范围内，然后把图片进行切割细分，得到许多个 50x50 的格子，在这个格子里 (30~45, 0~100) 它有黑色像素点，那么就非常可能是「儿」字。当然也可能是别的字，究竟是什么字，常用汉字就那么多个，这是概率问题。\n而 OCR 的重点是：\n 字体。你针对宋体的 OCR 训练数据拿到黑体上识别率不见得高。 训练。所谓的训练就是让计算机匹配时所遵守的概率无限趋近于现实。你可能需要拿出比如 3 万个字（一篇文章），先用默认的识别一遍（这涉及到了「如何根据某个特定字体制作出默认的数据」），然后逐字逐句去挑错，再改进默认数据（这涉及到了「你需要会编程，能够写出一个根据 tesseract 库改数据的软件」），最后越改这个数据越接近现实。  最后才是拿你训练过的数据去进行我上面做过的：\n$ tesseract ./test.png result -l chi_sim 参考、归纳、脑补自：http://miphol.com/muse/2013/05/tesseract-ocr.html\n这是 OCR 工作的基本原理和流程，这完全不可能是一个非程序员做的事情，程序员也懒得做这种事情，这是一种苦逼的体力劳动。\nWindows 下的 OCR 软件比如微软 word 自带的那个，ABBYY FineReader（这个最好，而且可以 wine）、以及汉王的软件，都是多少苦逼程序员一起，经历了这种枯燥乏味的流程后的结果。\nLinux 下的 OCR 软件都是开源的「框架」，比如 tesseract 和你之前问过的 ocropus，它们只是为在 Linux 下进行这种苦逼工作提供了一个基础，提供了可能性，并不是像你要求的那样拿来就能用的东西。因为没有训练过的数据，你安装的中文数据包只是可供你拿来训练的数据。\n何况在 Linux 下训练了也没用，OCR 最大的需求是 word 文档转出来的 PDF 和起点网站吧，那些用的字体可不是文泉驿。你现在能够得到的可供训练的数据估计就是 Google 根据 Droid Sans 弄出来的，训练 1 万年也只能识别 Droid Sans，问题是你能把纸面上的字体改了么。想要微软字体的数据？抱歉，微软是商业字体啊。\n所以我觉得现在是你对你需求的描述和理解就不对。钻进死胡同了。\nWPS WPS Office is a lightweight, feature-rich comprehensive office suite with high compatibility.\nttf-mscorefonts-installer\nttf-mscorefonts-installer is a Debian package that includes the following set of fonts, and with the help of this installer, you can easily download and use Microsoft’s True core fonts.\n Andale Mono Arial Black Arial (Bold, Italic, Bold Italic) Comic Sans MS (Bold) Courier New (Bold, Italic, Bold Italic) Georgia (Bold, Italic, Bold Italic) Impact Times New Roman (Bold, Italic, Bold Italic) Trebuchet (Bold, Italic, Bold Italic) Verdana (Bold, Italic, Bold Italic) Webdings  $ sudo proxychains apt install --reinstall ttf-mscorefonts-installer $ sudo fc-cache -vr ttf-wps-fonts\nThese are the symbol fonts required by wps-office. They are used to display math formulas. We have collected the fonts here to make things easier.\n$ cd /tmp $ git clone https://github.com/iamdh4/ttf-wps-fonts.git $ mkdir -p ~/.local/share/fonts/wps-fonts $ mv ttf-wps-fonts/* ~/.local/share/fonts/wps-fonts $ chmod 644 ~/.local/share/fonts/wps-fonts/* $ fc-cache -vfs $ rm -rf ttf-wps-fonts WPS 缺少中文\n最近发现了 flatpak 版 wps 没有中文的解决方案：\n 下载中文版 wps 的包，解压缩后找到里面的 mui 目录，复制到国际版 wps flatpak 的对应目录下，修改一下配置文件，你就得到了中文版 wps\n Sublime Text Atom Vim 安装 vim ycm 全能补全\n$ sudo apt install -y vim-gtk3 vim-addon-manager vim-youcompleteme vim-python-jedi $ vam install youcompleteme python-jedi 然后用 gvim 就有 ycm 智能补全和提示了\nvimtutor Start Vim on a copy of the tutor file.\nvi\u0026amp;vim.tiny $ whereis vi vi: /usr/bin/vi /usr/share/man/man1/vi.1.gz $ ls -al /usr/bin/vi lrwxrwxrwx 1 root root 20 Oct 26 20:31 /usr/bin/vi -\u0026gt; /etc/alternatives/vi $ ls -al /etc/alternatives/vi lrwxrwxrwx 1 root root 17 Oct 26 20:31 /etc/alternatives/vi -\u0026gt; /usr/bin/vim.tiny 可见，在Ubuntu上，vi是vim.tiny的软连接，但是执行命令vi与vim.tiny后是不一样，比如vi是：在编辑模式下使用方向键的时候，并不会使光标移动，而是在命令行中出现[A [B [C [D之类的字母；并且编辑错误的话，退格键(Backspace键)是使用不了的。\nMethods to find out which (configuration) files are read by executable when started-\u0026gt;\u0026lsquo;strace vim/nano\u0026rsquo; (Ubuntu)：\n$ strace -o $HOME/tracefile vi $ cat tracefile | grep vimrc stat(\u0026#34;/usr/share/vim/vimrc.tiny\u0026#34;, {st_mode=S_IFREG|0644, st_size=662, ...}) = 0 openat(AT_FDCWD, \u0026#34;/usr/share/vim/vimrc.tiny\u0026#34;, O_RDONLY) = 3 stat(\u0026#34;/home/vane/.vimrc\u0026#34;, 0x7fff3e755550) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/.vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/_vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) stat(\u0026#34;/home/vane/.vim/vimrc\u0026#34;, 0x7fff3e755550) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/.vim/vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) 可以看到 vi，加载的是 /usr/share/vim/vimrc.tiny\n$ strace -o $HOME/tracefile vim.tiny $ cat tracefile | grep vimrc stat(\u0026#34;/usr/share/vim/vimrc\u0026#34;, {st_mode=S_IFREG|0644, st_size=2266, ...}) = 0 openat(AT_FDCWD, \u0026#34;/usr/share/vim/vimrc\u0026#34;, O_RDONLY) = 3 stat(\u0026#34;/home/vane/.vimrc\u0026#34;, 0x7fff7c99cc30) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/.vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/_vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) stat(\u0026#34;/home/vane/.vim/vimrc\u0026#34;, 0x7fff7c99cc30) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/.vim/vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) 可以看到 vim.tiny，加载的是 /usr/share/vim/vimrc\n$ diff -u /etc/vim/vimrc /etc/vim/vimrc.tiny --- /etc/vim/vimrc 2020-01-30 19:11:47.000000000 +0800 +++ /etc/vim/vimrc.tiny 2020-04-15 14:40:31.000000000 +0800 @@ -1,55 +1,13 @@ ... +\u0026#34; Vim configuration file, in effect when invoked as \u0026#34;vi\u0026#34;. The aim of this +\u0026#34; configuration file is to provide a Vim environment as compatible with the +\u0026#34; original vi as possible. Note that ~/.vimrc configuration files as other +\u0026#34; configuration files in the runtimepath are still sourced. +\u0026#34; When Vim is invoked differently (\u0026#34;vim\u0026#34;, \u0026#34;view\u0026#34;, \u0026#34;evim\u0026#34;, ...) this file is +\u0026#34; _not_ sourced; /etc/vim/vimrc and/or /etc/vim/gvimrc are. ... 上面注释什么都说明白了。\nlink: The missing keybindings etc may be because you are running vim in vi compatible mode - you can turn that off by doing :set nocompatible in vim or adding set nocompatible to you .vimrc file.\nset nocompatible 参考 Fedora 默认/etc/virc配置：\nset fileencodings=ucs-bom,utf-8,latin1 set nocompatible set bs=indent,eol,start set ruler clear highlighting :noh vim.basic\u0026amp;vim.tiny 它们的区别：\nvim.basic is just plain vanilla Vim (as you can check with apt-file vim.basic or dpkg -S /usr/bin/vim.basic).\nWhile vim.tiny, as the name implies, is a trimmed-down version of Vim (this question explains it further).\n$ vim.tiny --version VIMRC The ultimate Vim configuration (vimrc)\ncopilot.vim Neovim plugin for GitHub Copilot\nNeovim Neovim 提出了将 Vim 扩展为一个 IDE 的想法。\n它增加了现代终端的功能，如光标样式、焦点事件、括号内粘贴等，并内置了一个终端模拟器。最重要的是，你不需要忘却 Vim 的习惯就可以开始使用 Neovim。\n现代化Neovim配置\ngit仓库。\n除此之外，目前一个比较好的配置是：https://github.com/LunarVim/LunarVim。\nvimplus 现代化的vim插件管理工具，开箱即用\nranger A VIM-inspired filemanager for the console\nShell Tmux Tmux 是一个终端复用器（terminal multiplexer），非常有用，属于常用的开发工具。\n简介 会话与进程\n命令行的典型使用方式是，打开一个终端窗口（terminal window，以下简称\u0026quot;窗口\u0026quot;），在里面输入命令。用户与计算机的这种临时的交互，称为一次\u0026quot;会话\u0026quot;（session） 。\n会话的一个重要特点是，窗口与其中启动的进程是连在一起的。打开窗口，会话开始；关闭窗口，会话结束，会话内部的进程也会随之终止，不管有没有运行完。\n一个典型的例子就是，SSH 登录远程计算机，打开一个远程窗口执行命令。这时，网络突然断线，再次登录的时候，是找不回上一次执行的命令的。因为上一次 SSH 会话已经终止了，里面的进程也随之消失了。\n为了解决这个问题，会话与窗口可以\u0026quot;解绑\u0026quot;：窗口关闭时，会话并不终止，而是继续运行，等到以后需要的时候，再让会话\u0026quot;绑定\u0026quot;其他窗口。\nTmux 的作用\nTmux 就是会话与窗口的\u0026quot;解绑\u0026quot;工具，将它们彻底分离。\n 它允许在单个窗口中，同时访问多个会话。这对于同时运行多个命令行程序很有用。 它可以让新窗口\u0026quot;接入\u0026quot;已经存在的会话。 它允许每个会话有多个连接窗口，因此可以多人实时共享会话。 它还支持窗口任意的垂直和水平拆分。  类似的终端复用器还有 GNU Screen。Tmux 与它功能相似，但是更易用，也更强大。\n基本用法 安装\nTmux 一般需要自己安装。\n$ sudo apt-get install tmux 启动与退出\n安装完成后，键入tmux命令，就进入了 Tmux 窗口。\n$ tmux Tmux 窗口，底部有一个状态栏。状态栏的左侧是窗口信息（编号和名称），右侧是系统信息。\n按下Ctrl+d或者显式输入exit命令，就可以退出 Tmux 窗口。\n$ exit 前缀键\nTmux 窗口有大量的快捷键。所有快捷键都要通过前缀键唤起。默认的前缀键是Ctrl+b，即先按下Ctrl+b，快捷键才会生效。\n举例来说，帮助命令的快捷键是Ctrl+b ?。它的用法是，在 Tmux 窗口中，先按下Ctrl+b，再按下?，就会显示帮助信息。\n然后，按下 ESC 键或q键，就可以退出帮助。\n会话管理 新建会话\n第一个启动的 Tmux 窗口，编号是0，第二个窗口的编号是1，以此类推。这些窗口对应的会话，就是 0 号会话、1 号会话。\n使用编号区分会话，不太直观，更好的方法是为会话起名。\n$ tmux new -s \u0026lt;session-name\u0026gt; 上面命令新建一个指定名称的会话。\n分离会话\n在 Tmux 窗口中，按下Ctrl+b d或者输入tmux detach命令，就会将当前会话与窗口分离。\n$ tmux detach 上面命令执行后，就会退出当前 Tmux 窗口，但是会话和里面的进程仍然在后台运行。\ntmux ls命令或Ctrl+b s可以查看当前所有的 Tmux 会话。\n$ tmux ls # or $ tmux list-session 接入会话\ntmux attach命令用于重新接入某个已存在的会话。\n# 使用会话编号 $ tmux attach -t 0 # 使用会话名称 $ tmux attach -t \u0026lt;session-name\u0026gt; 杀死会话\ntmux kill-session命令用于杀死某个会话。\n# 使用会话编号 $ tmux kill-session -t 0 # 使用会话名称 $ tmux kill-session -t \u0026lt;session-name\u0026gt; 切换会话\ntmux switch命令用于切换会话。\n# 使用会话编号 $ tmux switch -t 0 # 使用会话名称 $ tmux switch -t \u0026lt;session-name\u0026gt; 重命名会话\ntmux rename-session命令或Ctrl+b $用于重命名会话。\n$ tmux rename-session -t 0 \u0026lt;new-name\u0026gt; 上面命令将0号会话重命名。\n最简操作流程 综上所述，以下是 Tmux 的最简操作流程。\n 在服务器端新建会话tmux new -s my_session。 在 Tmux 窗口运行所需的程序。 按下快捷键Ctrl+b d将会话分离。 下次使用时，重新连接到会话tmux attach-session -t my_session。  窗格操作 Tmux 可以将窗口分成多个窗格（pane），每个窗格运行不同的命令。以下命令都是在 Tmux 窗口中执行。\n划分窗格\ntmux split-window命令用来划分窗格。\n# 划分上下两个窗格，或 Ctrl+b \u0026#34; $ tmux split-window # 划分左右两个窗格，或 Ctrl+b % $ tmux split-window -h 移动光标\ntmux select-pane命令或Ctrl+b \u0026lt;arrow key\u0026gt;用来移动光标位置。\n# 光标切换到上方窗格，或 Ctrl+b ; $ tmux select-pane -U # 光标切换到下方窗格，或 Ctrl+b o $ tmux select-pane -D # 光标切换到左边窗格 $ tmux select-pane -L # 光标切换到右边窗格 $ tmux select-pane -R  Ctrl+b x：关闭当前窗格。 Ctrl+b !：将当前窗格拆分为一个独立窗口。 Ctrl+b z：当前窗格全屏显示，再使用一次会变回原来大小。 Ctrl+b Ctrl+\u0026lt;arrow key\u0026gt;：按箭头方向调整窗格大小。 Ctrl+b q：显示窗格编号。  交换窗格位置\ntmux swap-pane命令用来交换窗格位置。\n# 当前窗格上移，或 Ctrl+b { $ tmux swap-pane -U # 当前窗格下移，或 Ctrl+b } $ tmux swap-pane -D  Ctrl+b Ctrl+o：所有窗格向前移动一个位置，第一个窗格变成最后一个窗格。 Ctrl+b Alt+o：所有窗格向后移动一个位置，最后一个窗格变成第一个窗格。  窗口管理 除了将一个窗口划分成多个窗格，Tmux 也允许新建多个窗口。\n新建窗口\ntmux new-window命令用来创建新窗口。\n$ tmux new-window # 新建一个指定名称的窗口 $ tmux new-window -n \u0026lt;window-name\u0026gt; Ctrl+b c：创建一个新窗口，状态栏会显示多个窗口的信息。\n切换窗口\ntmux select-window命令用来切换窗口。\n# 切换到指定编号的窗口 $ tmux select-window -t \u0026lt;window-number\u0026gt; # 切换到指定名称的窗口 $ tmux select-window -t \u0026lt;window-name\u0026gt;  Ctrl+b p：切换到上一个窗口（按照状态栏上的顺序）。 Ctrl+b n：切换到下一个窗口。 Ctrl+b \u0026lt;number\u0026gt;：切换到指定编号的窗口，其中的\u0026lt;number\u0026gt;是状态栏上的窗口编号。 Ctrl+b w：从列表中选择窗口。  重命名窗口\ntmux rename-window命令或Ctrl+b ,用于为当前窗口起名（或重命名）。\n$ tmux rename-window \u0026lt;new-name\u0026gt; 其他命令 下面是一些其他命令。\n# 列出所有快捷键，及其对应的 Tmux 命令 $ tmux list-keys # 列出所有 Tmux 命令及其参数 $ tmux list-commands # 列出当前所有 Tmux 会话的信息 $ tmux info # 重新加载当前的 Tmux 配置 $ tmux source-file ~/.tmux.conf Fish 命令行是程序员的必备技能。图形界面虽然好看，解决问题还是要靠命令行。\n命令行由 Shell 提供。各种命令通过 Shell，传递给操作系统的内核。学习命令行就是在学习 Shell。\nShell 有好几种，目前最常用是 Bash 和 zsh。但是，在我看来，它们都不如 Fish Shell 好用。\n五年前，我第一次尝试 Fish，感到很惊艳，一直用到现在。本文介绍 Fish 的主要特点，希望你也来尝试它。\n简介 Fish 是\u0026quot;the friendly interactive shell\u0026quot;的简称，最大特点就是方便易用。很多其他 Shell 需要配置才有的功能，Fish 默认提供，不需要任何配置。\n如果你想拥有一个方便好用的 Shell，又不想学习一大堆语法，或者花费很多时间配置，那么你一定要尝试一下 Fish。\n安装 Ubuntu 的安装方法。\n$ sudo apt install fish 其他系统的安装请参考官方网站。\n启动与帮助 安装完成后，就可以启动 Fish。\n$ fish 由于 Fish 的语法与 Bash 有很大差异，Bash 脚本一般不兼容。因此，我建议不要将 Fish 设为默认 Shell，而是每次手动启动它。\n使用过程中，如果需要帮助，可以输入help命令。浏览器就会自动打开，显示在线文档。\n$ help 彩色显示 进入 Fish 以后，你注意到的第一件事，可能就是它默认彩色显示。\n# 无效命令为红色 $ mkd # 有效命令为蓝色 $ mkdir 有效路径会有下划线。\n$ cat ~/somefi 上面代码表示，存在以~/somefi开头的路径。如果没有下划线，你就知道这个路径不存在。\n自动建议 Fish 会自动在光标后面给出建议，表示可能的选项，颜色为灰色。\n# 命令建议 $ /bin/hostname # 参数建议 $ grep --ignore-case # 路径建议 $ ls node_modules 如果采纳建议，可以按下→或Control + F。如果只采纳一部分，可以按下Alt + →。\n自动补全 输入命令时，Fish 会自动显示匹配的上一条历史记录。\n$ git commit -m \u0026#34;feat: first commit\u0026#34; 如果没有匹配的历史记录，Fish 会猜测可能的结果，自动补全各种输入。比如，输入pyt再按下Tab，就会自动补全为python命令。\n如果有多个可能的结果，Fish 会把它们都列出，还带有简要介绍。\n$ vi[按下 Tab 键] vi (Executable link, 2.7MB) view (Vi IMproved, 一个程序员的文本编辑器) viewer.py (Executable, 967B) viewres (Graphical class browser for Xt) ...and 12 more rows 这时，再按一次tab，就可以在这些命令之中选择。\n除了补全命令，Fish 还可以补全参数。比如，ls命令的-l参数后面按下Tab键，就会显示可以连用的其他参数。\n$ ls -l[按下 Tab 键] -l1 (List one file per line) -lA (Show hidden except . and ..) -la (Show hidden) -lB (Ignore files ending with ~) ...and 16 more rows``` Fish 还可以自动补全 Git 分支。\n$ git checkout master 易懂的语法 Fish 的语法非常自然，一眼就能看懂。\nif语句：\nif grep fish /etc/shells echo Found fish else if grep bash /etc/shells echo Found bash else echo Got nothing end switch语句：\nswitch (uname) case Linux echo Hi Tux! case Darwin echo Hi Hexley! case FreeBSD NetBSD DragonFly echo Hi Beastie! case \u0026#39;*\u0026#39; echo Hi, stranger! end while循环：\nwhile true echo \u0026#34;Loop forever\u0026#34; end for循环：\nfor file in *.txt cp $file $file.bak end 函数 Fish 的函数用来封装命令，或者为现有的命令起别名。\nfunction ll ls -lhG $argv end 上面代码定义了一个ll函数。命令行执行这个函数以后，就可以用ll命令替代ls -lhG。其中，变量$argv表示函数的参数。\n下面是另一个例子。\nfunction ls command ls -hG $argv end 上面的代码重新定义ls命令。注意，函数体内的ls之前，要加上command，否则会因为无限循环而报错。\n提示符 fish_prompt函数用于定义命令行提示符（prompt）。\nfunction fish_prompt set_color purple date \u0026#34;+%m/%d/%y\u0026#34; set_color FF0 echo (pwd) \u0026#39;\u0026gt;\u0026#39; set_color normal end 执行上面的函数以后，你的命令行提示符就会变成下面这样。\n02/06/13 /home/tutorial \u0026gt; 配置 Fish 的配置文件是~/.config/fish/config.fish，每次 Fish 启动，就会自动加载这个文件。\n我们可以在这个文件里面写入各种自定义函数，它们会被自动加载。比如，上面的fish_prompt函数就可以写在这个文件里面，这样每次启动 Fish，就会出现自定义的提示符。\nFish 还提供 Web 界面配置该文件。\n$ fish_config 输入上面的命令以后，浏览器就会自动打开本机的 8000 端口，用户可以在网页上对 Fish 进行配置，比如选择提示符和配色主题。\nZsh Oh My Zsh $ sh -c \u0026#34;$(wget https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)\u0026#34; oh-my-zsh应该对通配符作了限制，需要用跳脱字符\nsudo apt remove fcitx\\* Zsh theme：What\u0026rsquo;s the best theme for Oh My Zsh?\nzsh4humans Bash include local bin\n$ vim .bashrc export PATH=/home/kurome/.local/bin:$PATH bash-git-prompt $ git clone https://github.com/magicmonty/bash-git-prompt.git ~/.bash-git-prompt --depth=1 $ vim ~/.bashrc if [ -f \u0026#34;$HOME/.bash-git-prompt/gitprompt.sh\u0026#34; ]; then GIT_PROMPT_ONLY_IN_REPO=1 source $HOME/.bash-git-prompt/gitprompt.sh fi bash-completion 一般已经安装配置好了。\nawesome-bash Proxy v2ray 节点准备 简单来讲节点是形如如下的神秘链接：\nss://xxxxxxxxxxxxxxxxxxxxxxxxxxxx vmess://xxxxxxxxxxxxxxxxxxxxxxxxxxxx 如果你没有这些连接：\n 自行部署，你则需要自行购买处于自由互联网的服务器并进行节点搭建，这不在本文讨论范围内。如果你需要购买服务器，推荐一个 VPS 提供商：justhost.ru。 购买机场的订阅服务，可以参考它们的订阅流程以获取节点。需要提醒的是，机场服务属于灰色产业，随时有停止服务的可能，购买建议以月付进行购买以避免过大损失。关于机场审计规则，我们的观点是\u0026quot;我可以不看，但是你不可以封禁\u0026quot;。对于机场审计程度，读者可根据自身实际情况自行评估。 如果你不想花任何费用，可安装赛风这类软件。它是自由软件。如果你使用赛风，可以非常方便的发送空邮件到get@psiphon3.com以获取赛风下载链接。赛风应用目前只支持 Windows\\Android\\IOS\\MacOS 平台。当你在这些平台上能够访问自由互联网时，可以去各个渠道搜索可用的节点和代理资源。注意，使用公共节点需要自行承担可能的风险。  安装 v2ray/Xray-core 是使用 Qv2ray（原项目已停止开发） 以及 V2rayA 的前提，需要先进行安装。\nQv2ray 和 V2rayA 是两款非常优秀的在 Linux 上可用的科学上网通用客户端：\n Qv2ray：安装后在 Plugins 中，选择 V2ray Core Plugin，并进行 V2ray 的设置。现在你已经可以使用，你需要按照官方文档导入已有的链接或订阅。 V2rayA：2rayA 是一个浏览器客户端，使用非常方便。更多使用方法请看官方文档  代理配置 在经过上述步骤后，你应该已经有了 SOCKS5 代理以及 HTTP 代理的地址和端口。接下来进行设置：\n  系统代理：在节点链接后，你可在系统设置 -\u0026gt; 网络设置 -\u0026gt; 代理中设置代理。注意，系统设置中的代理配置在 KDE 桌面环境中并不是所有应用都会遵守。没有遵循系统设置代理的应用还需要单独进行代理配置。\n  终端\n可以通过 export 命令设置当前终端的代理方式。比如使用 tldr 或 github raw 等资源需要设置 https 代理。\nexport https_proxy=http://127.0.0.1:8889 export http_proxy=http://127.0.0.1:8889 export all_proxy=http://127.0.0.1:8889 不同终端命令所识别的环境变量名不同，如 all_proxy 对 curl 生效，而对 wget 则不生效，具体可查看各个命令的 man page。\n  proxychains/proxychains-ng\n如果对于一个应用，KDE 的系统代理不生效，在终端 export 了 ALL_PROXY 变量再用终端启动此应用代理也不生效，并且这个应用自身也没有配置代理的选项（即应用不支持代理）。此时可以使用 proxychains，它可以为单行命令配置代理，它是一个预加载的 hook，允许通过一个或多个 SOCKS 或 HTTP 代理重定向现有动态链接程序的 TCP 流量（即强制应用走代理）。\n$ sudo apt install proxychains $ sudo vim /etc/proxychains.conf socks5 127.0.0.1 1089   透明代理 全局代理，也即透明代理。之所以叫做透明代理，是因为这代理对于操作系统中的各个应用相当于是透明的，应用们感知不到代理的存在。之所以叫做全局代理，很明显意为全局所有流量都走代理。\n  在 Qv2ray 的“首选项-入站设置”的下方启用任意门设置选项。\n 监听 ipv4 地址可填127.0.0.1 或 0.0.0.0，建议前者。若需双栈代理，则在监听 ipv6 地址填上::1（如果监听 ipv4 填了 0.0.0.0 则可不填）。 嗅探选择 Full，Destination Override 的三项均勾选。 模式选择“tproxy”。    安装cgproxy软件，编辑/etc/cgproxy/config.json：\n 在cgroup_proxy中括号里加上\u0026quot;/\u0026quot;，port改为 Qv2ray 首选项里的透明代理的端口。 cgproxy默认配置是代理所有 tcp 和 udp，ipv4 和 ipv6 的流量，如果不希望代理其中的某种（些）流量，则将对应的enable_xxx改为 false。注意这里的配置要和 Qv2ray 选项里的配置一致，如 Qv2ray 选项里没有勾选 udp，则这里务必把enable_udp改为 false。 如果希望当本机作为网关设备时为连接到本机的其他设备（如连接到本机开设的 wifi 热点的设备）也提供透明代理，则把enable_gateway改为 true    透明代理的基本原理是拦截系统发出的所有流量，并将这些流量转到代理工具里，从而实现让系统所有流量都走代理的目的。此时，为了避免流量出现死循环（即代理工具发出的流量又转回到代理工具里），需要将代理工具排除在透明代理环境外面。有两种方式可以实现这一点：\n  通过execsnoop监控代理工具的启动，并自动将其移至透明代理环境外面：\n cgproxy软件自带execsnoop支持，以上cgproxy测试过的发行版均可支持。 编辑/etc/cgproxy/config.json，在program_noproxy中括号里加上\u0026quot;v2ray\u0026quot;、\u0026quot;qv2ray\u0026quot;，以使qv2ray和v2ray发出的流量不经过透明代理。如果你的v2ray或qv2ray不在PATH里，则需要填写它们的绝对路径。    在每次连接代理节点时，让qv2ray自己把自己移到透明代理环境外面：\n安装 Qvplugin-Command 插件，在插件设置里的“pre-connection”栏里加上一句\nsh -c \u0026#34;cgnoproxy --pid $(pgrep -x qv2ray)\u0026#34;     如果启用了 udp 的透明代理（dns 也是 udp），则给 v2ray 二进制文件加上相应的特权：\nsudo setcap \u0026#34;cap_net_admin,cap_net_bind_service=ep\u0026#34; /usr/bin/v2ray 否则 udp 的透明代理可能会出问题。如果每次更新了 v2ray 二进制文件，都需要重新执行此命令。\n  启动透明代理服务：systemctl start cgproxy.service或systemctl enable --now cgproxy.service。\n  以上步骤完成后，透明代理应该能正常使用了。\ndns\n如果勾选了“dns 拦截”，且启用了 dns 和 udp 的透明代理，则 v2ray 会拦截对系统 dns 的请求，并将其转发到 v2ray 的内置 dns 里，即让 v2ray 内置 dns 接管系统 dns。但 v2ray 内置 dns 是会遵循路由规则的。\n如果没勾选“dns 拦截”，则 v2ray 虽然不会让内置 dns 接管系统 dns，但如果启用了 dns 和 udp 的透明代理，则系统 dns 也会走透明代理进 v2ray，并遵循 v2ray 的路由规则。\n因此，在启用了 dns 和 udp 的透明代理时，若系统 dns 或 v2ray 的内置 dns 配置不当，可能导致 dns 请求发不出去，从而影响正常上网。\n由于 qv2ray 常见的路由规则是绕过国内 ip，国外 ip 均走代理。在这个情形中，以下两个配置是典型的有问题的 dns 配置方式：\n 配置了国外普通 dns 作为首选，但代理本身不支持 udp（此时 dns 查询的 udp 流量出不去，dns 无法查询） 配置了使用域名的 doh 作为首选。此时 doh 的域名无法被解析，从而 doh 也无法使用。  一般而言，如果并不在意将 dns 查询发给谁，那么，在绕过国内 ip 的情况下，只需要配置一个国内普通 dns 作为首选即可保证不会出问题。若代理本身不支持 udp，又希望使用国外 dns，则可以考虑使用使用 ip 的 doh（如https://1.1.1.1/dns-query等）。\n如果需要更复杂的 dns 配置，建议参考上游文档，并选择合适的不会影响正常上网的 dns 配置。\nClash 手动下载配置：\n$ wget -O config.yaml [订阅链接] $ curl -L -o config.yaml [订阅链接] 测试 clash：\n$ chmod u+x clash_premium $ sudo ./clash_premium -d . 设置系统代理：\n  Using GUI：打开 Gnome 系统设置，点击网络代理右边的 ⚙ 按钮，选择手动\n HTTP 和 HTTPS 代理为 127.0.0.1:7890 Socks 主机为 127.0.0.1:7891    Using CLI：\n$ gsettings set org.gnome.system.proxy.http host \u0026#39;127.0.0.1\u0026#39; $ gsettings set org.gnome.system.proxy.http port \u0026#39;7890\u0026#39; $ gsettings set org.gnome.system.proxy.https host \u0026#39;127.0.0.1\u0026#39; $ gsettings set org.gnome.system.proxy.https port \u0026#39;7890\u0026#39; $ gsettings set org.gnome.system.proxy.socks host \u0026#39;127.0.0.1\u0026#39; $ gsettings set org.gnome.system.proxy.socks port \u0026#39;7891\u0026#39; The basic usage of gsettings for reading and writing a particular Dconf setting is as follows.\n# To modify a DConf setting: $ gsettings set \u0026lt;schema\u0026gt; \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; # To read a DConf setting: $ gsettings get \u0026lt;schema\u0026gt; \u0026lt;key\u0026gt;   相关软件：glider/Lantern/Privoxy/openvpn/Shadowsocks/Tor/trojan：trojan教程\nclash.service $ sudo vi clash.service [Unit] Description=Clash daemon, A rule-based proxy in Go After=network.target [Service] Type=simple Restart=always RestartSec=10 ExecStart=/home/kurome/.opt/clash/clash_premium -d /home/kurome/.opt/clash/ [Install] WantedBy=multi-user.target 如果不想代理了，可以直接在 clash dashboard 的 Proxy 或者 Settting 里选择 DIRECT，而不是关闭 clash service。\nProviders 由于机场的订阅规则并不能完全满足自己的要求，因此自己通常会修改配置文件加上自己的规则。然而当使用机场订阅配置时，自动更新之后会覆盖掉自己配置的规则，又需要重新更改，非常麻烦。\n实际上clash在Premium版本中已经提供了proxy-providers的功能，能够完美的解决这个问题。类似的，也有rule-providers的功能，从指定url处获取别人提供的规则，而不用自己来制定。\nPremium 版本与普通版本区别是：Premium core is proprietary.\nproxy-providers原理是提取指定URL或者指定文件中的proxies字段中的所有内容，即指提取订阅节点的信息，到当前文件中供我们使用。详情看该部分的官方文档。如果订阅链接或文件没有该部分，则会报错：\n11:56:42 ERR [Config] configuration file test failed error=initial proxy provider tly error: file must have a `proxies` field path=/home/kurome/.opt/clash/config.yaml 这个时候就要注意看一下自己复制的订阅链接是否是用于 Clash 的，实在没有可以使用订阅转换。\nproxy-providers的格式为：\nproxy-providers: provider1: # provider的名称，后期会用到 type: http url: \u0026#34;url\u0026#34; # 机场给你的订阅链接 interval: 3600 # 每3600秒更新一次订阅 path: ./provider1.yaml health-check: enable: true # 是否自动进行latency-test interval: 600 url: http://www.gstatic.com/generate_204 test: type: file path: /test.yaml health-check: enable: true interval: 36000 url: http://www.gstatic.com/generate_204 相关资源：\n SS-Rule-Snippet：提供clash整体配置模版 clash-rules：主要提供 rule-providers，推荐使用其规则  Clash Dashboard 使用网页版 clash dashboard 会遇到跨源资源共享错误。可以 clone gh-pages 分支本地使用，直接打开index.html 是依然有错误的，正确的做法是使用 clash 的 external-ui。\n配置控制界面：在 /path/to/clash/config.yaml 中添加控制界面相关配置\nexternal-controller: 127.0.0.1:9090 external-ui: ./clash-dashboard secret: \u0026#34;5L2g5aW9Y2xhc2gK\u0026#34; 配置文件 Clash 是基于 Go 语言写的科学上网工具，目前支持 windows, mac, android, openwrt, linux 平台，支持 ss, trojan, vmess, snell 协议，支持分流规则。\nclash 配置文件格式为 yaml 格式，格式如下：\nport: 7890 socks-port: 7891 allow-lan: true mode: Rule log-level: info external-controller: :9090 proxies: - {name: cfmem.com - 🇭🇰 gq - 香港Amazon数据中心 20-1} proxy-groups: - name: 🔰 节点选择 type: select proxies: - ♻️ 自动选择 - 🎯 全球直连 - cfmem.com - 🇭🇰 gq - 香港Amazon数据中心 20-1 rules: - DOMAIN-SUFFIX,local,🎯 全球直连 怎么看呢？当你请求某个网页的时候，就会去匹配 rules，当匹配到某个 rule 后，就看它最后面的 proxy group，proxy group 定义在 proxy-groups 下，其根据不同的类型选择 proxies 中某个 proxy，最后通过该 proxy 打开网页。\nproxies proxies 代表节点数据，所有的分流规则都是按照这些节点数据来的，这里可以有很多个节点数据，可以是 trojan, ss, vmess 类型都可以，我们来看个例子：\n{name: cfmem.com - 🇭🇰 gq - 香港Amazon数据中心 20-1, server: xxxx, port: 59113, type: vmess, uuid: 1111111, alterId: 0, cipher: auto, tls: false} clash 用统一的格式来定义不同的节点类型，用 type 来进行区分，特有的属性只需要在这个结构体加上自己属性就可以， clash 客户端会根据 type 不同而来读数据\nproxy-groups 可以把 proxy-groups 理解为一道又道的过滤网，当你发出一个请求时，这个请求将会被在哪一层的过滤网给拦截下来，取决于你的 rules 与 请求匹配。我们来解析一下 proxy-groups 里面的参数。\nname\n代表组的名称，组的名称可以随意命名，但建议取有意义的名称，组的名称可以被其它的组引用，也可以放在规则里面\ntype\ntype 代表这个组的类型，有下面四种情况\n  select 手动选择，该组在节点列表上，手动选择列表或者 proxy-group\n  url-test 延迟最低节点，测试该组所有节点的延迟\n  fallback 回落，连接该组第一个节点，不可用时切换到下一个节点\n  load-balance 负载均衡，由该组2个以上的节点提供链接\n  proxies\n这里可以是组名称或者节点名称，依次从上到下进行选择，比如看下面这个\n- name: 🔰 节点选择 type: select proxies: - ♻️ 自动选择 - 🎯 全球直连 - cfmem.com - 🇭🇰 gq - 香港Amazon数据中心 20-1 - cfmem.com - 🇭🇰 gq - 香港Amazon数据中心 26-2 - cfmem.com - 🇭🇰 gq - 香港Amazon数据中心 28-3 - cfmem.com - 🇭🇰 香港-4 - cfmem.com - 🇭🇰 香港 2-5 - cfmem.com - 🇭🇰 香港 3-6 - cfmem.com - 🇭🇰 香港 4-7 - cfmem.com - 🇭🇰 香港 10-8 - cfmem.com - 🇭🇰 香港 11-9 - name: ♻️ 自动选择 type: url-test url: http://www.gstatic.com/generate_204 interval: 300 proxies: - cfmem.com - 🇭🇰 gq - 香港Amazon数据中心 20-1 - cfmem.com - 🇭🇰 gq - 香港Amazon数据中心 26-2 - cfmem.com - 🇭🇰 gq - 香港Amazon数据中心 28-3 - cfmem.com - 🇭🇰 香港-4 - cfmem.com - 🇭🇰 香港 2-5 - cfmem.com - 🇭🇰 香港 3-6 - cfmem.com - 🇭🇰 香港 4-7 - cfmem.com - 🇭🇰 香港 10-8 - cfmem.com - 🇭🇰 香港 11-9 - cfmem.com - 🇭🇰 香港 12-10 - name: 🌍 国外媒体 type: select proxies: - 🔰 节点选择 - ♻️ 自动选择 - 🎯 全球直连 - cfmem.com - 🇭🇰 gq - 香港Amazon数据中心 20-1 名称为自动选择的组会每间隔 300 毫秒去 ping 节点数据，测试的地址是：http://www.gstatic.com/generate_204\n而 国外媒体这一项是手动选择默认选择第一个 节点选择，节点选择的第一个是自动选择，所以默认是根据 ping 值来选择节点的\nrules rules 也就是具体的分发规则了，规则一般由 [规则前缀],[域名或地址],[组名] 组成。我们来看下，其中 no-resolve 表示不要解析这条规则，只处理直接 ip 访问请求\nrules: - DOMAIN-SUFFIX,local,🎯 全球直连 - IP-CIDR,192.168.0.0/16,🎯 全球直连,no-resolve - IP-CIDR,10.0.0.0/8,🎯 全球直连,no-resolve - IP-CIDR,172.16.0.0/12,🎯 全球直连,no-resolve - IP-CIDR,127.0.0.0/8,🎯 全球直连,no-resolve - IP-CIDR,100.64.0.0/10,🎯 全球直连,no-resolve - IP-CIDR6,::1/128,🎯 全球直连,no-resolve - IP-CIDR6,fc00::/7,🎯 全球直连,no-resolve - IP-CIDR6,fe80::/10,🎯 全球直连,no-resolve - IP-CIDR6,fd00::/8,🎯 全球直连,no-resolve - DOMAIN-KEYWORD,1drv,Ⓜ️ 微软服务 规则前缀有这些内容\n  DOMAIN-SUFFIX 表示包含什么后缀的域名\n  IP-CIDR IPV4匹配\n  IP-CIDR6 IPV6匹配\n  DOMAIN-KEYWORD,xxx 表示包含 xxx域名关键字的链接\n  DOMAIN abc.hello.com 表示包含完整的域名\n  PROCESS-NAME 表示进程名称\n  GEOIP 数据库（国家代码）匹配GeoIP 是 IP 地理位置数据库，可以根据 IP 地址 (支持 IPv4 和 IPv6), 定位该 IP 所在的地理位置和 ASN 等信息。\n  MATCH 全匹配（一般放在最后）\n  DNS污染 DNS服务器即是将用户请求的域名(网站URL)转换为IP地址的服务器。当年中国长城防火墙开始部署时就是通过DNS污染来屏蔽网站的。这项名为DNS污染的技术，就是对用户请求的域名回应一个错误的IP地址，使用户无法访问某个网站。至此，国内几乎所有的公共DNS服务器都被污染，用户无法请求到被屏蔽网站的正确IP地址。但是目前，防火墙的屏蔽功能早已不止DNS污染那么简单了，可以针对IP/域名直接阻断连接，甚至屏蔽了国外未受污染的DNS服务器，因此仅靠国内的DNS是不够翻墙的。\n对抗DNS劫持 早期的DNS服务器（我们日常使用的基本也是）都是明文传输数据的，这就意味着防火墙可以探测出你访问的网站，并且直接篡改DNS服务器回应的IP地址。这不仅仅存在于长城防火墙，还存在于某些无良网络运营商，把用户的请求的网站劫持到某个假的网站上。\n于是目前出现了DoH与DoT，可使用https/tls 加密传输DNS请求，这使得DNS不再容易被劫持了。国内的许多公共DNS也都提供了这项服务。以下是我所推荐的国内DNS。\n https://223.5.5.5/dns-query https://223.6.6.6/dns-query https://doh.pub/dns-query  或许可以参考 如何选择适合的公共 DNS？\n何时使用 Clash只会在域名匹配为直连时使用配置文件的DNS，其余时刻均交给节点进行远程解析。当然，节点域名也会使用配置文件的DNS。\n举个例子，访问 google.com 时，匹配到代理规则，那么这个流量将直接被发送至节点服务器，交给节点处理（通常是节点服务器的DNS解析，这个不用管了）。访问 microsoft.com 时，匹配到直连规则，Clash将使用配置文件的DNS设定进行解析。\nDNS配置 首先，打开你的 Clash 配置文件（如果你使用 Clash for Windows 或 Clash for Android, 可以使用软件自带的“覆写/Mixin”功能），添加以下段落：\ndns: enable: true listen: 0.0.0.0:53Copy 这一段的意思是启用 Clash 的 DNS 服务并让其在 53 端口（这是绝大多数操作系统将 DNS 解析报文发送到的端口）监听来自任意网络界面的 DNS 请求。如果你的设备并不需要向其他设备提供解析服务，或你的设备常常需要接入不安全的网络（如手机，笔记本电脑），应当将第三行的 0.0.0.0:53 改为 127.0.0.1:53 让 Clash 仅监听本机的 DNS 解析报文。\n（Clash 默认会同时监听 IPv4 和 IPv6 界面，如果你不需要后者，可以添加一行 ipv6: false）\n由于连接到加密 DNS 服务时，需要解析服务器本身的域名，因此需要指定一些相对干净的国内 明文 DNS 服务器地址。继续添加以下部分（注意缩进）：\n#--omitted-- default-nameserver: - 119.29.29.29 - 223.5.5.5Copy 当收到 DNS 解析请求时，Clash 会使用以上 DNS 服务器解析加密 DNS 服务器地址并建立连接。\n接下来，指定解析国内域名时使用的加密 DNS 服务器地址：\n#--omitted-- nameserver: - https://doh.pub/dns-query - https://dns.alidns.com/dns-queryCopy Clash 支持 DoH（https://domain.tld/dns-query 形式） 和 DoT（tls://domain.tld 形式）两种加密 DNS 协议，不支持 DoQ.（当然也支持在此指定备用的明文 DNS）\n然后，指定解析国外域名时使用的加密 DNS 服务器地址，并设置分流规则：\n#--omitted-- fallback: - https://1.1.1.1/dns-query - https://dns.google/dns-query fallback-filter: geoip: true geoip-code: CN ipcidr: - 240.0.0.0/4Copy “fallback” 字段指定的 DNS 服务器将被用于解析非国外域名，而 “fallback-filter” 字段则实现我们想要的分流规则——当请求解析的域名在 GeoIP 数据库内的国家代码不是 CN 时，或是域名在前文设置的 DNS 服务器内的解析结果位于 240.0.0.0/4 这一 IP 段内时（被屏蔽的域名解析常常会被污染到这一段），使用 “fallback” 字段指定的 DNS 服务器解析域名。\n最后，修改系统 DNS 服务器为 127.0.0.1 即可。\n代理环境中的 DNS 解析行为 虽然 Fake IP 这个概念早在 2001 年就被提出来了，但是到 Clash 提供 fake-ip 增强模式以后，依然有很多人对 Fake IP 这个概念以及其作用知之甚少。本文就简单谈谈在代理环境中，TCP 连接建立之前发生的事。由于移动设备操作系统中网络栈相对复杂，本文的例子也并不一定适用于移动端环境。文章中也许会存在很多错误，也希望各路大佬的勘误和斧正。\n不使用代理 如果在不使用任何代理的情况下，打开一个没有命中 DNS 缓存的网站（比如 blog.skk.moe）的时候，浏览器和操作系统大概会执行这么一些操作：\n 浏览器自己都有 DNS 缓存机制，因此浏览器会先开始寻找自己的缓存，不过没有找到 blog.skk.moe 的解析结果 浏览器通过调用操作系统的 getaddrinfo 方法，向操作系统寻求解析结果 操作系统自己也有一层 DNS 缓存，但是现在操作系统从自己的缓存中依然找不到这一结果 在系统的网络设置之中有设置上游 DNS 地址，假设操作系统中设置的是 119.29.29.29，那么操作系统会向 119.29.29.29 发起解析请求（UDP 流量）拿到 blog.skk.moe 的 IP 当然如果 119.29.29.29 自己没有 blog.skk.moe 的解析结果会找它的上游去要。不过我们不关心这一点，反正最后 119.29.29.29 会把 blog.skk.moe 的解析结果返回给设备的操作系统 现在，浏览器已经可以开始向 blog.skk.moe 的 IP 发起 HTTPS 连接了  以上是打开一个网页常见的 DNS 解析流程，对于其它非 HTTP 的 TCP 连接（比如 SMTP）也都差不多是这个流程——由于 TCP/IP 的协议特性，在应用发起 TCP 连接时，会先发出一个 DNS question（发一个 IP Packet），获取要连接的服务器的 IP 地址，然后直接向这个 IP 地址发起连接。\n设置代理并使用直连 现在，我们在应用程序（比如我们的浏览器、或者其它应用）中设置了代理，但是这个代理不涉及到任何远端服务器（直连模式）。接下来以设置了 SOCKS5 代理的浏览器为例。\n 浏览器不再需要从自己的 DNS 缓存中寻找 blog.skk.moe，因为已经有了 SOCKS5 代理，浏览器可以直接将域名封装在 SOCKS5 流量之中发往代理客户端 代理客户端从 SOCKS5 流量中抽出 blog.skk.moe 这个域名并设法获得解析结果 代理客户端将你的 SOCKS5 流量还原成标准的 TCP 请求 代理客户端将这个 TCP 连接建立起来，在这个例子之中 TCP 连接承载的是 HTTPS  之前由于获取解析结果是浏览器在操作，而大部分浏览器都会选择调用系统的 getaddrinfo 方法，因此如果你想要在 DNS 上做一些黑魔法就只能在操作系统层面实现，比如在本机或者别处架设一个带黑魔法的 DNS 服务器，然后你系统中设置使用这个 DNS 服务器。现在 DNS 解析是由代理客户端执行，因此在代理客户端上就可以实现一些黑魔法。比如 Surge 自己实现了一个 DNS Server 可以并发向多个上游同时发起查询、比如 V2Ray 可以实现不同域名的查询分流，等等。当然代理客户端也可以使用操作系统的 getaddrinfo 方法。\n设置代理并将流量转发到远端服务器 现在在上一步的基础之上，我们为代理服务器设置了一个远端服务器，这个代理会使用 某种协议 和远端服务器通信，并且这种协议和 SOCKS5 一样支持将域名封装在传输中。浏览器和代理客户端之间依然使用 SOCKS5 通信。\n 因为已经有了 SOCKS5 代理，浏览器可以直接将域名 blog.skk.moe 和整个请求封装在 SOCKS5 流量之中发往代理客户端 代理客户端从 SOCKS5 流量中抽出 blog.skk.moe 这个域名以及其它数据 代理客户端使用 某种协议 将浏览器发出的 SOCKS5 的流量重组并发给远端服务器 远端服务器使用相同的 某种协议 从流量中获得其中的域名 blog.skk.moe 远端服务器的代理服务端发起了一次 DNS 解析请求试图解析 blog.skk.moe。绝大部分情况下，代理的服务端都会直接使用操作系统的 getaddrinfo 方法、也就是由远端服务器的操作系统负责 DNS  这一次，不论是代理客户端还是你的浏览器都没有进行 DNS 解析，DNS 解析是在远端服务器上进行的。因为 某种协议 支持封装域名，然后这一次和 blog.skk.moe 连接的是远端服务器，考虑到针对 CDN 优化，DNS 解析自然需要在远端服务器上执行。\n现在我已经介绍了通过代理直连和通过代理发送给远端服务器了。但是毫无疑问，我相信本文所有的读者自己使用的上网方式都不会是全面直连或者全面代理。这就是接下来要讲的：\n设置代理并使用 IP 规则和域名规则进行分流 分流是一个麻烦事。一般情况下，你可能会需要使用域名进行分流（不论是白名单还是黑名单）。不过更多情况下你会使用到基于 IP 的规则来进行分流。\n先来看第一个例子：使用域名规则进行分流。\n 浏览器将带有域名 blog.skk.moe 的 HTTPS 请求封装在 SOCKS5 流量之中发往代理客户端 代理客户端从 SOCKS5 流量中抽取出域名 blog.skk.moe 代理客户端开始将blog.skk.moe 和域名规则列表开始比较。这个列表可以是白名单或黑名单，域名可能也没有匹配上。反正最终比较得出的结果就是 blog.skk.moe 是否需要走代理。 如果不需要走代理，代理客户端剩下会做的事情和本文第二部分「设置代理并使用直连」就完全一样了；同理，需要走代理的话就需要进行本文第三部分的那个流程  使用域名规则分流很简单，除非 blog.skk.moe 最终是直连，否则代理客户端不需要进行 DNS 解析。\n现在来看第二个例子：使用 IP 规则分流。\n 浏览器将带有域名 blog.skk.moe 的 HTTPS 请求封装在 SOCKS5 流量之中发往代理客户端 代理客户端从 SOCKS5 流量中抽取出域名 blog.skk.moe 代理客户端得到 blog.skk.moe 的解析结果 代理客户端开始将blog.skk.moe 的解析结果和 IP 规则列表开始比较。这个列表可以是 cnlist 或者 MaxMind IP 数据库。反正最终得出的结果就是 blog.skk.moe 解析结果的 IP 是否需要走代理。 如果不需要走代理，代理客户端剩下会做的事情和本文第二部分「设置代理并使用直连」就完全一样了；同理，需要走代理的话就需要进行本文第三部分的那个流程。  使用 IP 规则分流，前提首先你得有一个 IP 拿来比较。所以代理客户端必须先进行一次 DNS 解析。使用什么方法进行 DNS 解析并不重要，之前已经说过代理客户端甚至可以使用自己的黑魔法，而我们只需要关心最终代理客户端拿到了一个 IP 并且可以用于规则判定。\n此时需要注意的是，虽然代理客户端获得了一个 IP，但是你只有在直连的时候，代理客户端可能（并且基本上都会）复用这个 IP；如果是将流量交给远程服务器，由于 某种协议 支持封装域名，因此远程服务器拿到的还是域名不是 IP、还需要进行一次解析。也就是说，远端服务器连接的 IP 与 代理客户端解析得到的 IP 毫无关系。\n使用 redir / tun2socks 实现全局流量经过代理 在开始之前，我们先复习一下 TCP/IP 协议怎么说的——「在应用发起 TCP 连接时，会先发出一个 DNS question（发一个 IP Packet），获取要连接的服务器的 IP 地址，然后直接向这个 IP 地址发起连接」\n全局流量代理可能会出现在路由器上或者 TUN/TAP 型的支持全局代理客户端上。用户不再主动为每个应用程序设置代理。此时应用程序是不会感知到代理客户端的存在，它们会正常的发起 TCP 连接，并且由于 TCP/IP 协议，在拿到 DNS 解析结果之前，连接是不能建立的。\n 浏览器自己都有 DNS 缓存机制，因此浏览器会先开始寻找自己的缓存，不过没有找到 blog.skk.moe 的解析结果 浏览器通过调用操作系统的 getaddrinfo 方法，向操作系统寻求解析结果 操作系统自己也有一层 DNS 缓存，但是现在操作系统从自己的缓存中依然找不到这一结果 在系统的网络设置之中有设置上游 DNS 地址。代理客户端可能会修改系统设置中的 DNS 到 127.0.0.1 或者别的 IP、也可能保留用户之前的设置，这无所谓，因为\u0026hellip; 操作系统发出的 DNS 解析请求会经过代理客户端并最终被截获 代理客户端可以将这个解析请求原样发出去、或者用自己的黑魔法，总之代理客户端都会拿到一个解析结果 代理客户端将这个解析结果返回回去，操作系统拿到了这个解析结果并返回给浏览器 浏览器对这个解析结果的 IP 建立一个 TCP 连接并发送出去 这个 TCP 连接被代理客户端截获。由于之前代理客户端进行的 DNS 解析请求这一动作，代理客户端可以找到这个只包含目标 IP 的 TCP 连接原来的目标域名 如果是支持 redir 的代理客户端，那么代理客户端就会直接将域名和 TCP 连接中的其它数据封装成 某种协议 发给远端服务器；或者封装成 SOCKS5 后交给支持 SOCKS5 的代理客户端  如果代理客户端需要按照域名进行分流，一般会在第 6 步代理客户端解析出一个 IP 或者第 9 步代理客户端拿到域名以后。FancySS、KoolSS、SSTap 的流程大抵都是如此。\n和应用程序直接将流量封装成 SOCKS5 大有不同，在类似于透明代理的环境下浏览器和其它应用程序是正常地发起 TCP 连接。因此除非得到一个 DNS 解析结果，否则 TCP 连接不会建立；代理客户端也会需要通过这个 DNS 查询动作，才能找到之后的 TCP 连接的域名。 你大概能够发现，浏览器、应用程序直接设置 SOCKS5 代理的话，可以不在代理客户端发起 DNS 解析请求就能将流量发送给远端服务器；而在透明代理模式下，不论是否需要 IP 规则分流都需要先进行一次 DNS 解析才能建立连接。\n有没有办法能像直接设置 SOCKS5 代理一样省掉一次 DNS 解析呢？有，就是代理客户端自己不先执行查询动作，丢一个 Fake IP 回去让浏览器、应用程序立刻建立 TCP 连接：\n在 redir / tun2socks 中使用 Fake IP Fake IP 的定义出自 RFC3089。这个 RFC 定义了一种新的将 TCP 连接封装成 SOCKS 协议的方法。\n 浏览器自己都有 DNS 缓存机制，因此浏览器会先开始寻找自己的缓存，不过并没有找到 blog.skk.moe 的解析结果 浏览器通过调用操作系统的 getaddrinfo 方法，向操作系统寻求解析结果 操作系统自己也有一层 DNS 缓存，但是现在操作系统从自己的缓存中依然找不到这一结果 在系统的网络设置之中设置了一个专门的上游 DNS 地址，可能是用户手动设置的也可能是代理客户端设置的。不论如何，这个设置最终会使操作系统向代理客户端发起 DNS 请求 操作系统发出的 DNS 解析请求会经过代理客户端并最终被截获 代理客户端从解析请求中获得域名，从 Fake IP 池中选取一个 IP 建立映射 代理客户端将这个 Fake IP 返回回去，操作系统拿到了这个 Fake IP 并返回给浏览器 浏览器对 Fake IP 建立一个 TCP 连接并发送出去 这个 TCP 连接被代理客户端截获。代理客户端抽取出 Fake IP 并反查出这个 TCP 连接中对应的域名 有了 TCP 连接和域名，代理客户端可以轻易地将其使用 SOSCKS5 或者 某种协议 进行封装  有了 Fake IP，代理客户端无需进行 DNS 解析。最后不论是浏览器、代理客户端还是远端服务器都不会去和 Fake IP 进行连接，因为在代理客户端这里就已经完成了截获、重新封装。\n即使按照域名规则分流，代理客户端都没有进行 DNS 解析的需要。只有在遇到了按照 IP 进行分流的规则时，代理客户端才需要进行一次解析拿到一个 IP 用于判断。即便如此，这个 IP 只用于分流规则的匹配，不会被用于实际的连接。\nFancySS 和 Surge / Clash 的区别 FancySS 是使用的 redir，Surge 的增强模式使用的是 Fake IP，Clash 的增强模式既有 redir-host 也有 Fake IP。首先把 FancySS 等路由器上常见的代理客户端和 Clash 的 redir-host 分为一类，Surge 的增强模式和 Clash 的 fake-ip 模式分为另一类。\n路由器上常见的代理客户端一般内置了 dns2socks、dnscryp-proxy、PCap_DNSProxy 等等 DNS 方案、也支持按照一定的规则进行分流，但是都是用于答复应用程序的 DNS question 使其建立 TCP 连接的，除非直连，否则通过这些 DNS 方案拿到的解析结果的 IP 并不会被用上。 大部分路由器上的代理客户端，DNS 解析请求都是通过路由器本机发出（或转发到单一远端服务器进行解析），因此解析结果只能说「至少能用」（不一定是有 CDN 优化的，甚至有可能会有 DNS 污染），如果流量不经过代理客户端直接发往这些 IP 地址，一般也不会影响浏览器、应用程序的正常使用。因此路由器上的代理客户端可以实现通过 iptables 控制让某些端口、某些设备的流量不经过代理客户端。 而在 Fake IP 模式下，浏览器、应用程序都是对 Fake IP 发起连接，如果没有代理客户端对连接进行重新封转，那么这部分流量就不能被发往真实的目的 IP，因此所有流量都必须经过代理客户端，而根据端口、设备的分流就需要由代理客户端自己实现。\n如果操作系统或者浏览器缓存了 DNS 解析结果 之前的透明代理的两个例子中，我们都假定浏览器和操作系统都没有缓存 DNS 解析结果。但是，如果操作系统或者应用程序缓存了 DNS 解析结果会发生什么？\n如果是不使用 Fake IP 的 redir / tun2socks 情况下，由于操作系统、浏览器或者应用程序中的任何一个缓存了 DNS 解析结果，因此 TCP 连接可以直接根据缓存的解析结果的 IP 建立，代理客户端并没有预先收到对应的 DNS question。在这种情况下，代理客户端有可能直接将这个连接视为和 IP 连接而不是和域名连接，根据域名规则的分流可能就会因此失效，不过根据 IP 分流的规则没有失效。 如果为了避免域名分流规则失效，你可以设法阻止操作系统或者浏览器缓存 DNS 解析结果，这样每次建立 TCP 连接之前都会发送 DNS question 使代理客户端探测到域名。但是这意味着每次 TCP 连接建立都需要代理客户端进行一次 DNS 解析请求（当然代理客户端可以对 DNS 解析进行缓存避免出现延时激增）。\n而对于 Fake IP 模式来说，由于代理客户端内存储有 Fake IP 和真实域名之间的映射表，因此即使操作系统或应用程序缓存了 Fake IP，在之后的 TCP 连接中，代理客户端收到流量后依然可以抽取出 Fake IP 反查出域名，因此不受 DNS 缓存的影响。\n我在这里留几个问题给大家思考一下：\n 如果使用了 Fake IP，代理客户端不论域名是否真实存在都会返回一个 Fake IP 给浏览器，那么浏览器在试图访问一个不存在的域名时，错误信息应该是什么样的？会不会出现 DNS 解析失败的错误信息？ 如果操作系统或者浏览器缓存了 Fake IP，但是代理客户端中 Fake IP 和域名的映射表丢失以后，会出现什么状况？可能会出现什么错误信息？  第二个问题很有趣。因为如果你找到了第二个问题的答案，你就会意识到 Clash 在 Fake IP 模式下偶发的无法上网的原因了。\n参考资料  HTTP 代理原理及实现（一） - 我的文章中举得都是 SOCKS5 的例子，如果想了解一下在 HTTP 代理中流量是如何被封装的，可以看看屈屈的这篇博客 Surge 原理与实现 - Surge 开发者写的 Surge 早期版本的工作原理，可以了解一下 Surge 是怎么处理各种协议的流量的 漫谈各种黑科技式 DNS 技术在代理环境中的应用 - Kitsunebi 开发者写的文章，详细地介绍了在不同的 V2Ray 配置下的 DNS 行为，同时还有对移动端网络栈的一些介绍  CFW TUN 模式 “系统代理”一般只是桌面环境下的约定，需要 app 遵循约定才行。也就是说 HTTP_PROXY 这种环境变量只是约定俗成的，大家都从这里面读取代理地址，但是程序里必须要有读取这个变量的相关代码才行。\n因此某些软件\u0026amp;命令行软件不支持系统代理。\ntun 模式对全部 app 生效——对于不遵循系统代理的软件，TUN 模式可以接管其流量并交由 CFW 处理。启动 TUN 模式需要进行如下操作：\n  安装 nftables 和 iproute2 并重启\n$ sudo apt install nftables iproute2 $ sudo reboot   点击General中Service Mode右边Manage，在打开窗口中安装服务模式，安装完成应用会自动重启（某些系统需要手动重启 APP），Service Mode 右边地球图标变为绿色即安装成功\n  点击General中TUN Mode右边开关启动 TUN 模式\n  无法安装参考：\n$ curl https://gist.githubusercontent.com/Fndroid/2119fcb5ccb5a543a8f6a609418ae43f/raw/592eba4f480c7ccb4f29c9b8e80d24bfd5dda8cf/linux.sh \u0026gt; cfw-tun.sh \u0026amp;\u0026amp; chmod +x cfw-tun.sh \u0026amp;\u0026amp; sudo ./cfw-tun.sh install \u0026lt;cfw安装目录\u0026gt; 如要卸载则将 install 改为 uninstall，最后一部分位 CFW 安装目录\n  TProxy TProxy 含义：\n 透明代理：在正向代理中，一个软件如果想走 client 的代理服务，我们必须显式配置该软件，对该软件来说，有没有走代理是很明确的，大家都“心知肚明”。而透明代理则与正向代理相反，当我们设置好合适的防火墙规则（仅以 Linux 的 iptables 为例），我们将不再需要显式配置这些软件来让其经过代理或者不经过代理（直连），因为这些软件发出的流量会自动被 iptables 规则所处理，那些我们认为需要代理的流量，会被通过合适的方法发送到 client 进程，而那些我们不需要代理的流量，则直接放行（直连）。这个过程对于我们使用的软件来说是完全透明的，软件自身对其一无所知。这就叫做 透明代理。注意，所谓透明是对我们使用的软件透明，而非对 client、server 或目标网站透明，理解这一点非常重要。 内核模块：内核里支持上面描述的透明代理的模块，TProxy 模块工作在 mangle 表上。  Summary 执行下面的命令开启透明代理。由于使用了 TPROXY 方式的透明代理，所以 TCP 流量也是使用 mangle 表。以下命令中，以 # 开头的为注释。\n# 设置策略路由 ip rule add fwmark 1 table 100 ip route add local 0.0.0.0/0 dev lo table 100 # 代理局域网设备 iptables -t mangle -N V2RAY iptables -t mangle -A V2RAY -d 127.0.0.1/32 -j RETURN iptables -t mangle -A V2RAY -d 224.0.0.0/4 -j RETURN iptables -t mangle -A V2RAY -d 255.255.255.255/32 -j RETURN iptables -t mangle -A V2RAY -d 192.168.0.0/16 -p tcp -j RETURN # 直连局域网，避免 V2Ray 无法启动时无法连网关的 SSH，如果你配置的是其他网段（如 10.x.x.x 等），则修改成自己的 iptables -t mangle -A V2RAY -d 192.168.0.0/16 -p udp ! --dport 53 -j RETURN # 直连局域网，53 端口除外（因为要使用 V2Ray 的 DNS) iptables -t mangle -A V2RAY -m mark --mark 0xff -j RETURN # 直连 SO_MARK 为 0xff 的流量(0xff 是 16 进制数，数值上等同与上面V2Ray 配置的 255)，此规则目的是解决v2ray占用大量CPU（https://github.com/v2ray/v2ray-core/issues/2621） iptables -t mangle -A V2RAY -p udp -j TPROXY --on-ip 127.0.0.1 --on-port 12345 --tproxy-mark 1 # 给 UDP 打标记 1，转发至 12345 端口 iptables -t mangle -A V2RAY -p tcp -j TPROXY --on-ip 127.0.0.1 --on-port 12345 --tproxy-mark 1 # 给 TCP 打标记 1，转发至 12345 端口 iptables -t mangle -A PREROUTING -j V2RAY # 应用规则 # 代理网关本机 iptables -t mangle -N V2RAY_MASK iptables -t mangle -A V2RAY_MASK -d 224.0.0.0/4 -j RETURN iptables -t mangle -A V2RAY_MASK -d 255.255.255.255/32 -j RETURN iptables -t mangle -A V2RAY_MASK -d 192.168.0.0/16 -p tcp -j RETURN # 直连局域网 iptables -t mangle -A V2RAY_MASK -d 192.168.0.0/16 -p udp ! --dport 53 -j RETURN # 直连局域网，53 端口除外（因为要使用 V2Ray 的 DNS） iptables -t mangle -A V2RAY_MASK -m mark --mark 0xff -j RETURN # 直连 SO_MARK 为 0xff 的流量(0xff 是 16 进制数，数值上等同与上面V2Ray 配置的 255)，此规则目的是避免代理本机(网关)流量出现回环问题 iptables -t mangle -A V2RAY_MASK -p udp -j MARK --set-mark 1 # 给 UDP 打标记，重路由 iptables -t mangle -A V2RAY_MASK -p tcp -j MARK --set-mark 1 # 给 TCP 打标记，重路由 iptables -t mangle -A OUTPUT -j V2RAY_MASK # 应用规则 # 新建 DIVERT 规则，避免已有连接的包二次通过 TPROXY，理论上有一定的性能提升 iptables -t mangle -N DIVERT iptables -t mangle -A DIVERT -j MARK --set-mark 1 iptables -t mangle -A DIVERT -j ACCEPT iptables -t mangle -I PREROUTING -p tcp -m socket -j DIVERT 执行了以上 ip 和 iptables 命令后，局域网同网段的设备以及网关本身就可以直接翻墙了。\nOUTPUT\u0026amp;PREROUTING 从本机出去的数据包会经过 OUTPUT 链，而从外部发往本机的数据包会经过 PREROUTING 链（当然也会经过 INPUT 链，但因为 tproxy 只能工作在 PREROUTING 链，所以我们只关心 PREOUTING 链）。\n由于 tproxy 只能工作在 PREROUTING 链，从本机发出去的数据包会直接通过 OUTPUT 链出去了，本机数据包没有机会走一下 PREROUTING 链。为了让本机数据经过 PREROUTING，我们可以用的路由表解决。执行如下命令：\n# 设置策略路由 ip rule add fwmark 1 table 100 ip route add local 0.0.0.0/0 dev lo table 100 第一行添加一条 ip 规则，表示被标记为 1 的的数据包的走向要查表 100 。 第二行声明所有的 IPv4 地址在表 100 中均为 local（IP 数据包的目标IP与来源IP都为本机IP），大致是说对于表 100 的流量，都要发到本机（也就是说从 OUTPUT 链出去的包要回到 PREROUTING 链，原本 PREROUTING =\u0026gt; FORWARD 的包改为 PREROUTING =\u0026gt; INPUT =\u0026gt; Local Process）。\n我们来观察这张图。只要 OUTPUT 的最后我们的目标恰好是本机的话，那么这份数据报就会重新回到 iptables 的手中，也就和局域网的其他机器所发送的报文一样了。（clash/v2ray 都是通过域名而非 ip 进行代理的，所以IP 数据包的目标IP与来源IP随便改）\n在 OUTPUT 链上打标记命令如下：\niptables -t mangle -A OUTPUT -p tcp -j MARK --set-mark 1 iptables -t mangle -A OUTPUT -p udp -j MARK --set-mark 1 使用 Chain 上面的规则虽然完成了重回 PREROUTING 的能力，但有些数据包应当直接从 OUTPUT 链出去，比如访问网关管理页面（192.168.22.1），或者是 NAS 的 192.168.22.2。所以我们需要跳过一部分的数据包避免标记上 1。\niptables -t mangle -A OUTPUT -d 192.168.0.0/16 -j RETURN 这一条命令要在前面的 -j MARK 命令之前执行，匹配规则会根据创建的规则顺序按顺序执行。\n此时我们将编写 iptables 规则类比一下： 写 iptables 规则，就像写代码，OUTPUT 等链是程序内置的函数，它会在对应时机调用，我们需要做是填充这个函数的逻辑。所以，链 = 函数。这就清晰很多了。 iptables 还给我们提供了创建自定义链（函数）的能力，有了自定义链（函数）我们可以更好地管理规则。\n对于上面的 OUTPUT 管理，我们可以改写成：\niptables -t mangle -N V2RAY_MASK iptables -t mangle -A V2RAY_MASK -d 192.168.0.0/16 -p tcp -j RETURN iptables -t mangle -A V2RAY_MASK -d 192.168.0.0/16 -p udp -j RETURN iptables -t mangle -A V2RAY_MASK -p udp -j MARK --set-mark 1 iptables -t mangle -A V2RAY_MASK -p tcp -j MARK --set-mark 1 iptables -t mangle -A OUTPUT -j V2RAY_MASK 应用 tproxy 有了以上的内容，我们可以开始把数据发的 tproxy，tproxy 翻译过来就是内核提供的透明代理能力。假定我们设置的 tproxy 端口为 12345，如下命令可以将数据包通过 tproxy 发给代理client：\niptables -t mangle -A PREROUTING -p tcp -j TPROXY --on-port --tproxy-mark 1 iptables -t mangle -A PREROUTING -p udp -j TPROXY --on-port --tproxy-mark 1 因为这里TProxy 的目标地址不是本机。也就是说，如果不设置 mark，那么这份报文就会被转发（被 FORWARD 链处理）而不是被 INPUT 链处理。为了实现透明代理，这份报文必须被本机处理，因此 TProxy 就必须设置 --tproxy-mask，结合上文理解。\n然后创建自定义的链，上面的两行命令 PREROUTING 在增加更多的规则后会很难管理：\niptables -t mangle -N V2RAY iptables -t mangle -A V2RAY -d 192.168.0.0/16 -p tcp -j RETURN iptables -t mangle -A V2RAY -p udp -j TPROXY --on-port 12345 --tproxy-mark 1 iptables -t mangle -A V2RAY -p tcp -j TPROXY --on-port 12345 --tproxy-mark 1 iptables -t mangle -A PREROUTING -j V2RAY 解决回环问题 这里产生了一个回环：\n 本机发出来去往外网的数据包通过 mark 回到 PREROUTING 通过 tproxy 进入代理client 本机代理client发出来去往外网的数据包通过 mark 回到 PREROUTING 通过 tproxy 进入代理client 本机代理client发出来去往外网的数据包通过 mark 回到 PREROUTING \u0026hellip;..  我们需要解决掉，即让本机代理client发出来的数据包直接从 OUTPUT 链出去。\nmark 规避\n一种方式是对出站流量再打一个 mark，通过设置 iptables 规则对对应 mark 的流量直连，来规避代理client流量，防止回环。\n首先要在代理client的配置中给其包加一个 255 的 mark，这个 mark 与下文 iptables 命令配合，以直连代理client发出的 SO_MARK 为 0xff 的流量 (0xff 是 16 进制数，数值上等同与配置的 255)\n# OUTPUT # 此规则目的是避免代理本机(网关)流量出现回环问题 iptables -t mangle -A V2RAY_MASK -m mark --mark 0xff -j RETURN 这么做有以下几个问题：\n  莫名流量进入 PREROUTING 链，解决如下\n# PREROUTING # 此规则目的是解决v2ray占用大量CPU iptables -t mangle -A V2RAY -m mark --mark 0xff -j RETURN   安卓系统有自己的 mark 机制，该方案在安卓上不可用\n  gid/uid 规避\n思路：\n tproxy 流量只能被 root 权限用户(uid==0)或其他有 CAP_NET_ADMIN 权限的用户接收。 iptables 规则可以通过 uid(用户 id)和 gid(用户组 id)分流。 让代理client运行在一个 uid==0 但 gid!=0 的用户上，设置 iptables 规则不代理该 gid 的流量来规避 代理client流量。  使用以下命令可以创建一个名为 clash，uid 为 0，gid 为 23333 的用户，用户名和 gid 可以自己定，uid 必须为 0。\n# grep -qw clash /etc/passwd || echo \u0026#34;clash❌0:23333:::\u0026#34; \u0026gt;\u0026gt; /etc/passwd 使用如下命令可以验证创建的用户是否正常：\n$ sudo -u clash id 接下来我们使用这个用户启动 clash：\n$ sudo -u clash /usr/local/bin/clash -d /etc/clash iptables 执行在 OUTPUT 链改为如下命令：\n# OUTPUT iptables -t mangle -A V2RAY_MASK -m owner --gid-owner 23333 -j RETURN 劫持 DNS 使用 tproxy 能力时，需要让代理client接管 DNS 流量，有两种方式：\n  停掉本地的 DNS 服务，将代理client的 DNS 服务端口改为 53\n# PREROUTING iptables -t mangle -A V2RAY -d 192.168.0.0/16 -p udp ! --dport 53 -j RETURN # OUTPUT iptables -t mangle -A V2RAY_MASK -d 192.168.0.0/16 -p udp ! --dport 53 -j RETURN   将 DNS 查询数据包转发到代理client\n# PREROUTING iptables -t mangle -A V2RAY -d 192.168.0.0/16 -p udp ! --dport 53 -j RETURN iptables -t nat -A V2RAY -p udp --dport 53 -j REDIRECT --to-ports 10053 # OUTPUT iptables -t mangle -A V2RAY_MASK -d 192.168.0.0/16 -p udp ! --dport 53 -j RETURN iptables -t nat -A V2RAY_MASK -p udp --dport 53 -j REDIRECT --to-ports 10053 10053 是在代理client上设置的 DNS 服务端口。\n  WireGuard 官方文档：https://github.com/pirate/wireguard-docs\nWireGuard 是由 Jason Donenfeld 等人用 C 语言编写的一个开源 VPN 协议，被视为下一代 VPN 协议，旨在解决许多困扰 IPSec/IKEv2、OpenVPN 或 L2TP 等其他 VPN 协议的问题。它与 Tinc 和 MeshBird 等现代 VPN 产品有一些相似之处，即加密技术先进、配置简单。从 2020 年 1 月开始，它已经并入了 Linux 内核的 5.6 版本，这意味着大多数 Linux 发行版的用户将拥有一个开箱即用的 WireGuard。\n术语 Peer/Node/Device\n连接到 VPN 并为自己注册一个 VPN 子网地址（如 192.0.2.3）的主机。还可以通过使用逗号分隔的 CIDR 指定子网范围，为其自身地址以外的 IP 地址选择路由。\n中继服务器（Bounce Server）\n一个公网可达的对等节点，可以将流量中继到 NAT 后面的其他对等节点。Bounce Server 并不是特殊的节点，它和其他对等节点一样，唯一的区别是它有公网 IP，并且开启了内核级别的 IP 转发，可以将 VPN 的流量转发到其他客户端。\n子网（Subnet）\n一组私有 IP，例如 192.0.2.1-255 或 192.168.1.1/24，一般在 NAT 后面，例如办公室局域网或家庭网络。\nCIDR 表示法\nCIDR中文全称是无分类域间路由选择，英文全称是Classless Inter-Domain Routing，在平常，大家多称之为无分类编址，它也是构成超网的一种技术实现。CIDR在一定程度上解决了路由表项目过多过大的问题。CIDR之所以称为无分类编址，就是因为CIDR完全放弃了之前的分类IP地址表示法，它真正消除了传统的A类、B类、C类地址以及划分子网的概念，它使用如下的IP地址表示法：\nIP地址 ::= {\u0026lt;网络前缀\u0026gt;， \u0026lt;主机号\u0026gt;} / 网络前缀所占位数 CIDR仅将IP地址划分为网络前缀和主机号两个部分，可以说又回到了二级IP地址的表示，不过大家要注意，最后面用“/”斜线分隔，在其后写上了网络前缀所占的位数，这样就不需要告知路由器地址掩码，仅需要通过网络前缀所占的位数就可以得到地址掩码，为了统一，CIDR中的地址掩码依然称为子网掩码。\nNAT\n子网的私有 IP 地址由路由器提供，通过公网无法直接访问私有子网设备，需要通过 NAT 做网络地址转换。路由器会跟踪发出的连接，并将响应转发到正确的内部 IP。\n公开端点（Public Endpoint）\n节点的公网 IP 地址:端口，例如 123.124.125.126:1234，或者直接使用域名 some.domain.tld:1234。如果对等节点不在同一子网中，那么节点的公开端点必须使用公网 IP 地址。\n私钥（Private key）\n单个节点的 WireGuard 私钥，生成方法是：wg genkey \u0026gt; example.key。\n公钥（Public key）\n单个节点的 WireGuard 公钥，生成方式为：wg pubkey \u0026lt; example.key \u0026gt; example.key.pub。\nDNS\n域名服务器，用于将域名解析为 VPN 客户端的 IP，不让 DNS请求泄漏到 VPN 之外。\n工作原理 中继服务器工作原理\n中继服务器（Bounce Server）和普通的对等节点一样，它能够在 NAT 后面的 VPN 客户端之间充当中继服务器，可以将收到的任何 VPN 子网流量转发到正确的对等节点。事实上 WireGuard 并不关心流量是如何转发的，这个由系统内核和 iptables 规则处理。\n如果所有的对等节点都是公网可达的，则不需要考虑中继服务器，只有当有对等节点位于 NAT 后面时才需要考虑。\n*在 WireGuard 里，客户端和服务端基本是平等的，差别只是谁主动连接谁而已。*双方都会监听一个 UDP 端口，谁主动连接，谁就是客户端。主动连接的客户端需要指定对端的公网地址和端口，被动连接的服务端不需要指定其他对等节点的地址和端口。如果客户端和服务端都位于 NAT 后面，需要加一个中继服务器，客户端和服务端都指定中继服务器作为对等节点，它们的通信流量会先进入中继服务器，然后再转发到对端。\nWireGuard 是支持漫游的，也就是说，双方不管谁的地址变动了，WireGuard 在看到对方从新地址说话的时候，就会记住它的新地址（跟 mosh 一样，不过是双向的）。所以双方要是一直保持在线，并且通信足够频繁的话（比如配置 persistent-keepalive），两边的 IP 都不固定也不影响的。\n流量路由\n利用 WireGuard 可以组建非常复杂的网络拓扑，这里主要介绍几个典型的拓扑：\n 端到端直接连接  这是最简单的拓扑，所有的节点要么在同一个局域网，要么直接通过公网访问，这样 WireGuard 可以直接连接到对端，不需要中继跳转。\n一端位于 NAT 后面，另一端直接通过公网暴露  这种情况下，最简单的方案是：通过公网暴露的一端作为服务端，另一端指定服务端的公网地址和端口，然后通过 persistent-keepalive 选项维持长连接，让 NAT 记得对应的映射关系。\n两端都位于 NAT 后面，通过中继服务器连接  大多数情况下，当通信双方都在 NAT 后面的时候，NAT 会做源端口随机化处理，直接连接可能比较困难。可以加一个中继服务器，通信双方都将中继服务器作为对端，然后维持长连接，流量就会通过中继服务器进行转发。\n两端都位于 NAT 后面，通过 UDP NAT 打洞  上面也提到了，当通信双方都在 NAT 后面的时候，直接连接不太现实，因为大多数 NAT 路由器对源端口的随机化相当严格，不可能提前为双方协调一个固定开放的端口。必须使用一个信令服务器（STUN），它会在中间沟通分配给对方哪些随机源端口。通信双方都会和公共信令服务器进行初始连接，然后它记录下随机的源端口，并将其返回给客户端。这其实就是现代 P2P 网络中 WebRTC 的工作原理。有时候，即使有了信令服务器和两端已知的源端口，也无法直接连接，因为 NAT 路由器严格规定只接受来自原始目的地址（信令服务器）的流量，会要求新开一个随机源端口来接受来自其他 IP 的流量（比如其他客户端试图使用原来的通信源端口）。运营商级别的 NAT 就是这么干的，比如蜂窝网络和一些企业网络，它们专门用这种方法来防止打洞连接。更多细节请参考下一部分的 NAT 到 NAT 连接实践的章节。\n如果某一端同时连接了多个对端，当它想访问某个 IP 时，如果有具体的路由可用，则优先使用具体的路由，否则就会将流量转发到中继服务器，然后中继服务器再根据系统路由表进行转发。你可以通过测量 ping 的时间来计算每一跳的长度，并通过检查对端的输出（wg show wg0）来找到 WireGuard 对一个给定地址的路由方式。\n报文格式\nWireGuard 使用加密的 UDP 报文来封装所有的数据，UDP 不保证数据包一定能送达，也不保证按顺序到达，但隧道内的 TCP 连接可以保证数据有效交付。WireGuard 的报文格式如下图所示：\n性能\nWireGuard 声称其性能比大多数 VPN 协议更好，但这个事情有很多争议，比如某些加密方式支持硬件层面的加速。\nWireGuard 直接在内核层面处理路由，直接使用系统内核的加密模块来加密数据，和 Linux 原本内置的密码子系统共存，原有的子系统能通过 API 使用 WireGuard 的 Zinc 密码库。WireGuard 使用 UDP 协议传输数据，在不使用的情况下默认不会传输任何 UDP 数据包，所以比常规 VPN 省电很多，可以像 55 一样一直挂着使用，速度相比其他 VPN 也是压倒性优势。\n安全模型\nWireGuard 使用以下加密技术来保障数据的安全：\n 使用 ChaCha20 进行对称加密，使用 Poly1305 进行数据验证。 利用 Curve25519 进行密钥交换。 使用 BLAKE2 作为哈希函数。 使用 HKDF 进行解密。  WireGuard 的加密技术本质上是 Trevor Perrin 的 Noise 框架的实例化，它简单高效，其他的 VPN 都是通过一系列协商、握手和复杂的状态机来保障安全性。WireGuard 就相当于 VPN 协议中的 qmail，代码量比其他 VPN 协议少了好几个数量级。\n密钥管理\nWireGuard 通过为每个对等节点提供简单的公钥和私钥来实现双向认证，每个对等节点在设置阶段生成密钥，且只在对等节点之间共享密钥。每个节点除了公钥和私钥，不再需要其他证书或预共享密钥。\n在更大规模的部署中，可以使用 Ansible 或 Kubernetes Secrets 等单独的服务来处理密钥的生成、分发和销毁。\n如果你不想在 wg0.conf 配置文件中直接硬编码，可以从文件或命令中读取密钥，这使得通过第三方服务管理密钥变得更加容易：\n[Interface] ... PostUp = wg set %i private-key /etc/wireguard/wg0.key \u0026lt;(cat /some/path/%i/privkey) 从技术上讲，多个服务端之间可以共享相同的私钥，只要客户端不使用相同的密钥同时连接到两个服务器。但有时客户端会需要同时连接多台服务器，例如，你可以使用 DNS 轮询来均衡两台服务器之间的连接，这两台服务器配置相同。大多数情况下，每个对等节点都应该使用独立的的公钥和私钥，这样每个对等节点都不能读取到对方的流量，保障了安全性。\n搭建使用与配置详解 快速开始 安装\n# Ubuntu ≥ 18.04 $ apt install wireguard 在中继服务器上开启 IP 地址转发：\n$ echo \u0026#34;net.ipv4.ip_forward = 1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf $ echo \u0026#34;net.ipv4.conf.all.proxy_arp = 1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf $ sysctl -p /etc/sysctl.conf 添加 iptables 规则，允许本机的 NAT 转换：\n$ iptables -A INPUT -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT $ iptables -A FORWARD -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT $ iptables -A FORWARD -i wg0 -o wg0 -m conntrack --ctstate NEW -j ACCEPT $ iptables -t nat -A POSTROUTING -s 192.0.2.0/24 -o eth0 -j MASQUERADE 需要把 eth0 改成你实际使用的网卡接口名称。\n配置文件\n配置文件可以放在任何路径下，但必须通过绝对路径引用。默认路径是 /etc/wireguard/wg0.conf。\n生成密钥\n#生成私钥 $ wg genkey \u0026gt; example.key # 生成公钥 $ wg pubkey \u0026lt; example.key \u0026gt; example.key.pub 启动与停止\n$ wg-quick up /full/path/to/wg0.conf $ wg-quick down /full/path/to/wg0.conf # 启动/停止 VPN 网络接口 $ ip link set wg0 up $ ip link set wg0 down # 注册/注销 VPN 网络接口 $ ip link add dev wg0 type wireguard $ ip link delete dev wg0 # 注册/注销 本地 VPN 地址 $ ip address add dev wg0 192.0.2.3/32 $ ip address delete dev wg0 192.0.2.3/32 # 添加/删除 VPN 路由 $ ip route add 192.0.2.3/32 dev wg0 $ ip route delete 192.0.2.3/32 dev wg0 查看信息\n# 查看系统 VPN 接口信息 $ ip link show wg0 # 查看 VPN 接口详细信息 $ wg show all $ wg show wg0 # 查看 VPN 接口地址 $ ip address show wg0 路由\n# 查看系统路由表 $ ip route show table main $ ip route show table local # 获取到特定 IP 的路由 $ ip route get 192.0.2.3 一键安装\n一键安装请参考这个项目：WireGuard installer\n配置详解 WireGuard 使用 INI 语法作为其配置文件格式。配置文件可以放在任何路径下，但必须通过绝对路径引用。默认路径是 /etc/wireguard/wg0.conf。\n配置文件的命名形式必须为 ${WireGuard 接口的名称}.conf。通常情况下 WireGuard 接口名称以 wg 为前缀，并从 0 开始编号，但你也可以使用其他名称，只要符合正则表达式 ^[a-zA-Z0-9_=+.-]{1,15}$ 就行。\n你可以选择使用 wg 命令来手动配置 VPN，但一般建议使用 wg-quick，它提供了更强大和用户友好的配置体验，可以通过配置文件来管理配置。\n下面是一个配置文件示例：\n[Interface] # Name = node1.example.tld Address = 192.0.2.3/32 ListenPort = 51820 PrivateKey = localPrivateKeyAbcAbcAbc= DNS = 1.1.1.1,8.8.8.8 Table = 12345 MTU = 1500 PreUp = /bin/example arg1 arg2 %i PostUp = /bin/example arg1 arg2 %i PreDown = /bin/example arg1 arg2 %i PostDown = /bin/example arg1 arg2 %i [Peer] # Name = node2-node.example.tld AllowedIPs = 192.0.2.1/24 Endpoint = node1.example.tld:51820 PublicKey = remotePublicKeyAbcAbcAbc= PersistentKeepalive = 25 [Interface]\n这一节定义本地 VPN 配置。例如：\n本地节点是客户端，只路由自身的流量，只暴露一个 IP。\n[Interface] # Name = phone.example-vpn.dev Address = 192.0.2.5/32 PrivateKey = \u0026lt;private key for phone.example-vpn.dev\u0026gt; 本地节点是中继服务器，它可以将流量转发到其他对等节点（peer），并公开整个 VPN 子网的路由。\n[Interface] # Name = public-server1.example-vpn.tld Address = 192.0.2.1/24 ListenPort = 51820 PrivateKey = \u0026lt;private key for public-server1.example-vpn.tld\u0026gt; DNS = 1.1.1.1  Name  这是 INI 语法中的标准注释，用于展示该配置部分属于哪个节点。这部分配置会被 WireGuard 完全忽略，对 VPN 的行为没有任何影响。\nAddress  定义本地节点应该对哪个地址范围进行路由。如果是常规的客户端，则将其设置为节点本身的单个 IP（使用 CIDR 指定，例如 192.0.2.3/32）；如果是中继服务器，则将其设置为可路由的子网范围。\n例如：\n  常规客户端，只路由自身的流量：Address = 192.0.2.3/32\n  中继服务器，可以将流量转发到其他对等节点（peer）：Address = 192.0.2.1/24\n  也可以指定多个子网或 IPv6 子网：Address = 192.0.2.1/24,2001:DB8::/64\n  ListenPort  当本地节点是中继服务器时，需要通过该参数指定端口来监听传入 VPN 连接，默认端口号是 51820。常规客户端不需要此选项。\nPrivateKey  本地节点的私钥，所有节点（包括中继服务器）都必须设置。不可与其他服务器共用。\n私钥可通过命令 wg genkey \u0026gt; example.key 来生成。\nDNS  通过 DHCP 向客户端宣告 DNS 服务器。客户端将会使用这里指定的 DNS 服务器来处理 VPN 子网中的 DNS 请求，但也可以在系统中覆盖此选项。例如：\n  如果不配置则使用系统默认 DNS\n  可以指定单个 DNS：DNS = 1.1.1.1\n  也可以指定多个 DNS：DNS = 1.1.1.1,8.8.8.8\n  Table  定义 VPN 子网使用的路由表，默认不需要设置。该参数有两个特殊的值需要注意：\n Table = off : 禁止创建路由 Table = auto（默认值） : 将路由添加到系统默认的 table 中，并启用对默认路由的特殊处理。  例如：Table = 1234\nMTU  定义连接到对等节点（peer）的 MTU（Maximum Transmission Unit，最大传输单元），默认不需要设置，一般由系统自动确定。\nPreUp  启动 VPN 接口之前运行的命令。这个选项可以指定多次，按顺序执行。\n例如添加路由：PreUp = ip rule add ipproto tcp dport 22 table 1234\nPostUp  启动 VPN 接口之后运行的命令。这个选项可以指定多次，按顺序执行。\n例如：\n  从文件或某个命令的输出中读取配置值：\nPostUp = wg set %i private-key /etc/wireguard/wg0.key \u0026lt;(some command here)   添加一行日志到文件中：\nPostUp = echo \u0026#34;$(date +%s) WireGuard Started\u0026#34; \u0026gt;\u0026gt; /var/log/wireguard.log   调用 WebHook：\nPostUp = curl https://events.example.dev/wireguard/started/?key=abcdefg   添加路由：\nPostUp = ip rule add ipproto tcp dport 22 table 1234   添加 iptables 规则，启用数据包转发：\nPostUp = iptables -A FORWARD -i %i -j ACCEPT; iptables -A FORWARD -o %i -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE   强制 WireGuard 重新解析对端域名的 IP 地址：\nPostUp = resolvectl domain %i \u0026#34;~.\u0026#34;; resolvectl dns %i 192.0.2.1; resolvectl dnssec %i yes   PreDown  停止 VPN 接口之前运行的命令。这个选项可以指定多次，按顺序执行。\n例如：\n  添加一行日志到文件中：\nPreDown = echo \u0026#34;$(date +%s) WireGuard Going Down\u0026#34; \u0026gt;\u0026gt; /var/log/wireguard.log   调用 WebHook：\nPreDown = curl https://events.example.dev/wireguard/stopping/?key=abcdefg   PostDown  停止 VPN 接口之后运行的命令。这个选项可以指定多次，按顺序执行。\n例如：\n  添加一行日志到文件中：\nPostDown = echo \u0026#34;$(date +%s) WireGuard Going Down\u0026#34; \u0026gt;\u0026gt; /var/log/wireguard.log   调用 WebHook：\nPostDown = curl https://events.example.dev/wireguard/stopping/?key=abcdefg   删除 iptables 规则，关闭数据包转发：\nPostDown = iptables -D FORWARD -i %i -j ACCEPT; iptables -D FORWARD -o %i -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE   [Peer]\n定义能够为一个或多个地址路由流量的对等节点（peer）的 VPN 设置。对等节点（peer）可以是将流量转发到其他对等节点（peer）的中继服务器，也可以是通过公网或内网直连的客户端。\n中继服务器必须将所有的客户端定义为对等节点（peer），除了中继服务器之外，其他客户端都不能将位于 NAT 后面的节点定义为对等节点（peer），因为路由不可达。对于那些只为自己路由流量的客户端，只需将中继服务器作为对等节点（peer），以及其他需要直接访问的节点。\n举个例子，在下面的配置中，public-server1 作为中继服务器，其他的客户端有的是直连，有的位于 NAT 后面：\n  public-server1（中继服务器）\n[peer] : public-server2, home-server, laptop, phone\n  public-server2（直连客户端）\n[peer] : public-server1\n  home-server（客户端位于 NAT 后面）\n[peer] : public-server1, public-server2\n  laptop（客户端位于 NAT 后面）\n[peer] : public-server1, public-server2\n  phone（客户端位于 NAT 后面）\n[peer] : public-server1, public-server2\n  配置示例：\n  对等节点（peer）是路由可达的客户端，只为自己路由流量\n[Peer] # Name = public-server2.example-vpn.dev Endpoint = public-server2.example-vpn.dev:51820 PublicKey = \u0026lt;public key for public-server2.example-vpn.dev\u0026gt; AllowedIPs = 192.0.2.2/32   对等节点（peer）是位于 NAT 后面的客户端，只为自己路由流量\n[Peer] # Name = home-server.example-vpn.dev Endpoint = home-server.example-vpn.dev:51820 PublicKey = \u0026lt;public key for home-server.example-vpn.dev\u0026gt; AllowedIPs = 192.0.2.3/32   对等节点（peer）是中继服务器，用来将流量转发到其他对等节点（peer）\n[Peer] # Name = public-server1.example-vpn.tld Endpoint = public-server1.example-vpn.tld:51820 PublicKey = \u0026lt;public key for public-server1.example-vpn.tld\u0026gt; # 路由整个 VPN 子网的流量 AllowedIPs = 192.0.2.1/24 PersistentKeepalive = 25    Endpoint  指定远端对等节点（peer）的公网地址。如果对等节点（peer）位于 NAT 后面或者没有稳定的公网访问地址，就忽略这个字段。通常只需要指定中继服务器的 Endpoint，当然有稳定公网 IP 的节点也可以指定。例如：\n  通过 IP 指定：\nEndpoint = 123.124.125.126:51820   通过域名指定：\nEndpoint = public-server1.example-vpn.tld:51820   AllowedIPs  允许该对等节点（peer）发送过来的 VPN 流量中的源地址范围。同时这个字段也会作为本机路由表中 wg0 绑定的 IP 地址范围。如果对等节点（peer）是常规的客户端，则将其设置为节点本身的单个 IP；如果对等节点（peer）是中继服务器，则将其设置为可路由的子网范围。可以使用 , 来指定多个 IP 或子网范围。该字段也可以指定多次。\n当决定如何对一个数据包进行路由时，系统首先会选择最具体的路由，如果不匹配再选择更宽泛的路由。例如，对于一个发往 192.0.2.3 的数据包，系统首先会寻找地址为 192.0.2.3/32 的对等节点（peer），如果没有再寻找地址为 192.0.2.1/24 的对等节点（peer），以此类推。\n例如：\n  对等节点（peer）是常规客户端，只路由自身的流量：\nAllowedIPs = 192.0.2.3/32   对等节点（peer）是中继服务器，可以将流量转发到其他对等节点（peer）：\nAllowedIPs = 192.0.2.1/24   对等节点（peer）是中继服务器，可以转发所有的流量，包括外网流量和 VPN 流量，可以用来干嘛你懂得：\nAllowedIPs = 0.0.0.0/0,::/0   对等节点（peer）是中继服务器，可以路由其自身和其他对等节点（peer）的流量：\nAllowedIPs = 192.0.2.3/32,192.0.2.4/32   对等节点（peer）是中继服务器，可以路由其自身的流量和它所在的内网的流量：\nAllowedIPs = 192.0.2.3/32,192.168.1.1/24   PublicKey  对等节点（peer）的公钥，所有节点（包括中继服务器）都必须设置。可与其他对等节点（peer）共用同一个公钥。\n公钥可通过命令 wg pubkey \u0026lt; example.key \u0026gt; example.key.pub 来生成，其中 example.key 是上面生成的私钥。\n例如：PublicKey = somePublicKeyAbcdAbcdAbcdAbcd=\nPersistentKeepalive  如果连接是从一个位于 NAT 后面的对等节点（peer）到一个公网可达的对等节点（peer），那么 NAT 后面的对等节点（peer）必须定期发送一个出站 ping 包来检查连通性，如果 IP 有变化，就会自动更新Endpoint。\n例如：\n 本地节点与对等节点（peer）可直连：该字段不需要指定，因为不需要连接检查。 对等节点（peer）位于 NAT 后面：该字段不需要指定，因为维持连接是客户端（连接的发起方）的责任。 本地节点位于 NAT 后面，对等节点（peer）公网可达：需要指定该字段 PersistentKeepalive = 25，表示每隔 25 秒发送一次 ping 来检查连接。  Gnome GNOME 系统设置面板（gnome-control-center）和 GNOME 应用使用 dconf 配置系统存储设置。您可以使用 gsettings 或 dconf 命令行工具直接访问 dconf 数据库。这也可以让你修改用户界面不公开的设置。\nGNOME 桌面拥有强大的搜索功能，按 Super 键并搜索一些东西，可以进入“Settings-Search”中来设置可以搜索的内容和顺序。\nDo Not Disturb 使通知只在消息栏中，不会在桌面上弹出。\nGnome 3 自动切换的壁纸会有一个有时钟小图标。\n浏览 GNOME Shell cheat sheet 中解释了如何高效地使用 GNOME shell，它展示了 GNOME shell 的特色和快捷键，包括切换任务，使用键盘，窗口控制，面板，概览模式等等。以下是部分常用的快捷键：\n Super + m：显示消息托盘 Super + a：显示应用程序菜单 Alt- + Tab：切换当前使用的应用 Alt- + ` (美式键盘 Tab 上面的按键)：切换前台应用程序的窗口 Alt + F2，然后输入 r 或 restart：在图形界面出问题时重启界面（仅用于 X/传统 模式，不适用于 Wayland 模式）。也可通过此运行后台应用，如 cfw。  Gedit 编码\n直接打开gedit（非通过文件打开），点击左上角 Open，点击左下角 Automatically Detected，下拉选择 Add or Remove...，将简体中文编码都选上。\n或者：\n$ gsettings list-keys org.gnome.gedit.preferences.encodings candidate-encodings $ gsettings set org.gnome.gedit.preferences.encodings candidate-encodings \u0026#34;[\u0026#39;UTF-8\u0026#39;, \u0026#39;ISO-8859-15\u0026#39;, \u0026#39;UTF-16\u0026#39;, \u0026#39;GBK\u0026#39;, \u0026#39;GB18030\u0026#39;, \u0026#39;GB2312\u0026#39;]\u0026#34; 配置\n 在 Perferences =\u0026gt; View =\u0026gt; Text Wrapping，都启用。 在 Perferences =\u0026gt; Editor =\u0026gt; Tap Stops，把 Tab width 设置为 2，勾选 Insert spaces instead of tabs。  Nautilus Files 是 GNOME 桌面环境的默认文件管理器。文件试图提供一种简化的方法来管理文件和应用程序。Files 在 3.6 版之前被称为 Nautilus。该应用程序被赋予了新的描述性名称，每种受支持的语言都有一个名称。 Nautilus 这个名称仍然在许多地方使用，例如可执行文件名称，某些程序包名称，某些桌面条目和某些 GSettings 模式。\n快捷键 有时候鼠标操作效率低，比如新建标签页（汉堡菜单 \u0026gt; 新建标签页），我们要移动两次光标点两下，如果使用快捷键 Ctrl+T，一次就能迅速完成操作。所以，使用快捷键能提高效率。另一个让你多使用键盘快捷键的理由可能是，预防鼠标手。如果您经常使用某个软件，那么有必要学习它的快捷键，如果偶尔使用就没必要浪费时间。\nCtrl+F1，查看 Files 快捷键。建议您参考列表多加练习。一些常用快捷键：\n   快捷键 功能     Ctrl T New tab   Ctrl N New window   Ctrl W Close window or tab       Ctrl F Search   ~ Location bar with home location   / Location bar with root location   Ctrl L Enter location       Backspace Go Back to a Previous Folder   Ctrl + Zoom in   Ctrl - Zoom out   Ctrl 0 Reset zoom   Ctrl H Show/hide hidden files       F2 Rename   Delete Move to trash   Shift Delete Delete permanently   Ctrl C Copy   Ctrl V Paste   Ctrl X Cut   Ctrl Z Undo   Shift Ctrl Z Redo       Ctrl A Select all   Shift Ctrl I Invert selection       Ctrl Q Quit    从右键菜单创建新文档 只需要将模板文件放到用户根目录下的 Templates / 模板 文件夹里面。比如：\ntouch ~/Templates/sh.sh touch ~/Templates/python.py touch ~/Templates/Markdown.md 当你右键时，就可以直接以该模板新建文件。\nTemplates 目录可以在 ~/.config/user-dirs.dirs 中配置。默认为：\nXDG_TEMPLATES_DIR=\u0026#34;$HOME/Templates\u0026#34; 你可以设置为其他目录。比如我的为：\nXDG_TEMPLATES_DIR=\u0026#34;/DATA/Templates\u0026#34; /DATA 不在系统分区，是一个单独的分区，我专门用来存放个人数据。\n直接搜索匹配 常用的目录可以添加为书签，但访问其他目录时，我们经常是按路径逐个点击文件夹。对于文件夹路径较深或者周围有其他文件夹干扰的情况，操作起来其实非常低效。不知你是否意识到、思考过。\n人们习惯鼠标操作后，往往不会再去思考如何提升效率，一直呆在舒适区域：这个我已经会用了。但是，有一些你不知道的技巧能够提高办事效率。\n实际上，只要你身处 Files 中，直接输入英文字符即可搜索匹配。Files 像浏览器一样合并了搜索栏和地址栏，你可以直接输入 关键词 或者 路径 。但是，中文关键词需要在搜索栏（Ctrl+F）中输入。\n一个实例：打开 GNOME 桌面系统图标所在文件夹 /usr/share/icons。\n方法一：鼠标点击 / usr share 直接输入 icons 然后 Enter 打开。\n 这是目标文件夹周围有其他文件夹干扰的情况。\n 方法二：Files 中直接输入 /usr/share/icons（操作时可利用 Tab 自动补全）。\n 这是路径较深的情况。\n Gnome Tweaks GNOME 桌面有称为“扩展”的小插件或附加组件，学会使用 GNOME 扩展来扩展系统的可用性。安装必须的 packages：\n$ sudo apt install gnome-tweaks gnome-shell-extensions chrome-gnome-shell -y  gnome-tweaks: Graphical interface for advanced GNOME settings. 可以设置主题、字体等。 gnome-shell-extensions：管理附加组件，可以禁用桌面图标、Ubuntu Dock。 chrome-gnome-shell：GNOME Shell integration for Chrome，可从浏览器安装 GNOME Shell extensions。  主题相关目录：\n 主题目录： /usr/share/themes 或 ~/.themes 图标鼠标目录： /usr/share/icons 或 ~/.icons 壁纸： /usr/share/background , /usr/share/wallpapers  主题选择：Skeuomorphism vs Flat Design vs Material Design\n Papirus Icon Theme $ sudo add-apt-repository ppa:papirus/papirus $ sudo apt-get update $ sudo apt-get install papirus-icon-theme  Materia Theme $ sudo apt install materia-gtk-theme   Ubuntu Dock Ubuntu Dock 就是 Dash to Dock。安装：\n$ sudo apt-get install gnome-shell-extension-dashtodock 重启，在 Extension 中设置 Dash to Dock，Dash to Dock 与 Ubuntu Dock 只能开启一个，否则有两个 Dock，但是就算关闭 Dash to Dock，Dash to Dock 设置依旧起作用到 Ubuntu Dock。\n重新登录。\nGSConnect Files and links. Shared between devices.\nFirewall Blocking Port\n使用 ufw：\n$ sudo ufw allow proto tcp from 192.168.0.0/24 to any port 1714:1764 $ sudo ufw allow proto udp from 192.168.0.0/24 to any port 1714:1764 $ sudo ufw reload 有时候正确设置了防火墙，还是会发送文件失败，可以考虑重启应用。\nmounting does not work\n$ sftp -P 1740 kdeconnect@192.168.0.105 Unable to negotiate with 192.168.88.245 port 1740: no matching host key type found. Their offer: ssh-rsa Connection closed. Connection closed $ vim ~/.ssh/config Host 192.168.0.* HostkeyAlgorithms +ssh-rsa PubkeyAcceptedAlgorithms +ssh-rsa $ ssh kdeconnect@192.168.0.105 -p 1740 After that the mounting works again.\nGSConnect cannot send multiple files at once\nGSConnect cannot send multiple files at once. If I try sending multiple files to my phone, only one file is received by my phone.\nGSConnect shows \u0026ldquo;Transfer Successful\u0026rdquo; notification only for the first file, and \u0026ldquo;Transferring File\u0026rdquo; notifications for the other files remain.\nFiles Integration\n$ sudo apt install python3-nautilus gir1.2-nautilus-3.0 $ nautilus -q \u0026amp;\u0026amp; nautilus KDE Connect\n$ sudo apt install kdeconnect nautilus-kdeconnect Desktop Icons NG (DING) with these advantages:\n Drag\u0026rsquo;n\u0026rsquo;Drop, both inside the desktop, between desktop and applications, and nautilus windows Allows to use \u0026ldquo;Open with\u0026hellip;\u0026rdquo; option with several files When hovering or clicking on an icon with a name too large to fit, it shows the full name Doesn\u0026rsquo;t hang the compositor when there is too much activity in the desktop folder  Lunar Calendar 农历 $ sudo apt install gir1.2-lunar-date-2.0 $ sudo cp /usr/share/locale/zh_CN/LC_MESSAGES/lunar-date.mo /usr/share/locale/en/LC_MESSAGES/ 你正在必须把系统语言改成中文它才会显出来:-(\n其他扩展推荐  NetSpeed: Displays Internet Speed Clipboard Indicator: Clipboard Manager extension for Gnome-Shell - Adds a clipboard indicator to the top panel, and caches clipboard history. Coverflow Alt-Tab: Replacement of Alt-Tab, iterates through windows in a cover-flow manner. Bluetooth Quick Connect: Allow to connect to paired devices from gnome control panel. Frippery Move Clock: Move clock to left of status menu button Input Method Panel: Input Method Panel using KDE\u0026rsquo;s kimpanel protocol for Gnome-Shell Lock Keys: Numlock \u0026amp; Capslock status on the panel OpenWeather: Weather extension to display weather information from https://openweathermap.org/ or https://darksky.net for almost all locations in the world. 需设置 Location，Units 为公制单位，Layout为Right Panel Date Format: Allows to customize the date format on the panel. Refresh Wifi Connections: This extension adds a refresh button to the Wi-Fi connection selection dialog to manually request for a network scan. Screenshot Tool: Conveniently create, copy, store and upload screenshots. Please log out and log in again after updating. Sound Input \u0026amp; Output Device ChooserLivepatch: Shows a list of sound output and input devices (similar to gnome sound settings) in the status menu below the volume slider. Status Area Horizontal Spacing: Reduce the horizontal spacing between icons in the top-right status area Unite: Unite is a GNOME Shell extension which makes a few layout tweaks to the top panel and removes window decorations to make it look like Ubuntu Unity Shell. User Themes: Load shell themes from user directory. Vitals: A glimpse into your computer\u0026rsquo;s temperature, voltage, fan speed, memory usage, processor load, system resources, network speed and storage stats. This is a one stop shop to monitor all of your vital sensors. Uses asynchronous polling to provide a smooth user experience. Removable Drive Menu: A status menu for accessing and unmounting removable devices. Places Status Indicator: Add a menu for quickly navigating places in the system. This extension is part of Classic Mode and is officially supported by GNOME. Please do not report bugs using the form below, use GNOME\u0026rsquo;s GitLab instance instead. Recent Items gTile: Tile windows on a grid. Top Panel Workspace Scroll: Change workspaces by scrolling over the top panel Workspace Indicator: Put an indicator on the panel signaling in which workspace you are, and give you the possibility of switching to another one. Auto Move Windows: Move applications to specific workspaces when they create windows. Applications Menu: Add a category-based menu for applications. This extension is part of Classic Mode and is officially supported by GNOME. Please do not report bugs using the form below, use GNOME\u0026rsquo;s GitLab instance instead. Fly-Pie: A marking menu which can be used to launch applications, simulate hotkeys, open URLs and much more. AppIndicator and KStatusNotifierItem Support: Adds AppIndicator, KStatusNotifierItem and legacy Tray icons support to the Shell Time ++: A todo.txt manager, time tracker, timer, stopwatch, pomodoro, and alarm clock. 番茄钟 BackSlide: Automatic background-image (wallpaper) slideshow for Gnome Shell Remove Alt+Tab Delay v2: Another extension that removes the 0.15 second popup delay in switcher pop-ups. This extension is actively maintained. EasyScreenCast : This extension simplifies the use of the video recording function integrated in gnome shell, allows quickly to change the various settings of the desktop recording. Hide Top Bar: Hides the top bar, except in overview. However, there is an option to show the panel whenever the mouse pointer approaches the edge of the screen. And if \u0026ldquo;intellihide\u0026rdquo; is enabled, the panel only hides when a window takes the space. Battery Time: Show the remaining time until fully charged/discharged instead of the battery charge in percent in the panel. Caffeine: Disable the screensaver and auto suspend Todo.txt: A Gnome shell interface for todo.txt. Internet Radio: Listen to an Internet Radio Stream ibus font setting: use ibus font setting of ibus setup dialog to enhance the user experience  遗留名称 注意： 一些 GNOME 程序在文档和对话框中的名称已经更改，但执行文件名称却没有。下面表格列出了一些这样的应用程序。\n提示： 在搜索栏中搜索应用的遗留名称将成功找到对应的应用，例如搜索 nautilus 将返还 文件。\n   当前 遗留     文件 Nautilus   Web Epiphany   视频 Totem   主菜单 Alacarte   文档查看器 Evince   磁盘使用情况分析器 Baobab   图像查看器 EoG (Eye of GNOME)   密码和密钥 Seahorse    默认应用程序 mime类型文件\n存在于以下的两个路径：\n /usr/share/mime/ ~/.local/share/mime/  例如：/usr/share/mime/text/makrdown.xml\nGet the mime type of a file\n$ file --mime-type -b filename 应用程序 desktop文件\n存在于以下的两个路径：\n /usr/share/applications/ ~/.local/share/applications/  例如 typora.desktop 文件：\n[Desktop Entry] # 应用名称，即开始菜单中的名称 Type=ApplicationName=name # 应用执行文件位置 Exec=appPath # 应用图标位置 Icon=typora # 是否显示终端 Terminal=false # 所属分类 StartupNotify=trueCategories=Office # MIME 类型 MimeType=text/x-markdown 应用图标\n默认位置为 ~/.local/share/icons，一个直接放入，如 ~/.local/share/icons/typora.png，一个根据分辨率放入，如 ~/.local/share/icons/hicolor/256x256/typora.png\n应用程序默认关联文件\n存在于以下的两个路径：\n /usr/share/applications/mimeapps.list ~/.local/share/applications/mimeapps.list  例如\ntext/plain=org.gnome.gedit.desktop text/html=firefox.desktop 桌面卡死 总的来说，就是杀死相关进程，或者避免使用造成卡死相关软件。\n  选择其他 tty：\n$ pkill Xorg pkill 用于杀死一个进程，与 kill 不同的是它会杀死指定名字的所有进程。kill 命令杀死指定进程 PID，需要配合 ps 使用。\n  安全重启：同时按住 Ctrl 和 Alt 键，按住不要放，按一下 SysRq 键（有的键盘是PrtSc），按一下 R 键，按一下 E 键，依次按下 I , S , U , B 键。\n  解决 Ubuntu 经常卡死：ubuntu 的卡死可能与显卡驱动不兼容有关。用 nvidia 代替 nouveau显卡驱动。其中 nvidia-driver-470-server 是 server 版，最好用 nvidia-driver-470\n  NVIDIA NVIDIA Optimus NVIDIA Optimus 是一项允许英特尔（Intel）集成图形处理器（GPU）和英伟达（NVIDIA）独立图形处理器置入并通过一台笔记本电脑访问的技术。\nPRIME synchronization You can enable PRIME synchronization to prevent screen tearing. It requires:\n Linux kernel 4.5 or higher; X server 1.19 or higher; NVIDIA driver 370.23 or higher.  PRIME synchronization will be enabled automatically after you enable KMS for nvidia-drm module.\n  Add this line to the end of /etc/modprobe.d/nvidia.conf:\noptions nvidia-drm modeset=1   Regenerate your initramfs image by running:\n$ sudo update-initramfs -u   Reboot.\n  要检查重新启动后以前的更改是否有效，请运行命令：\n$ sudo cat /sys/module/nvidia_drm/parameters/modeset Y see more about nvidia on uat BinaryDriverHowto/Nvidia\nPermanently Set NVIDIA PowerMizer Settings $ nvidia-settings -q GpuPowerMizerMode Attribute \u0026#39;GPUPowerMizerMode\u0026#39; (rastating-PC:1[gpu:0]): 0. Valid values for \u0026#39;GPUPowerMizerMode\u0026#39; are: 0, 1 and 2. \u0026#39;GPUPowerMizerMode\u0026#39; can use the following target types: GPU. $ nvidia-settings -a \u0026#34;[gpu:0]/GpuPowerMizerMode=1\u0026#34; Attribute \u0026#39;GPUPowerMizerMode\u0026#39; (rastating-PC:1[gpu:0]) assigned value 1. $ nvidia-settings -q GpuPowerMizerMode Attribute \u0026#39;GPUPowerMizerMode\u0026#39; (rastating-PC:1[gpu:0]): 1. Valid values for \u0026#39;GPUPowerMizerMode\u0026#39; are: 0, 1 and 2. \u0026#39;GPUPowerMizerMode\u0026#39; can use the following target types: GPU. 添加到开机启动\n  Name：NVIDIA X Server Performance Settings\n  Command：/usr/bin/nvidia-settings -a \u0026quot;[gpu:0]/GpuPowerMizerMode=1\u0026quot;\n   密钥环 如果你用过 Ubuntu 或者其他的 Linux 发行版里的自动登录功能, 你可能遇到过这种弹出消息：\n 请输入密码以解锁你的登录密钥环\n登录密钥环在你登录系统时未解锁。\n 如果你一直点击取消，它会不断弹出几次才会消失。你可能想知道，为什么你会一直看到这个密钥环信息呢？\n让我来告诉你吧。它其实不是错误，而是一个安全特性。\n奇怪吗？下面就让我来解释下 Linux 里的密钥环概念。\n密钥环是什么，为什么需要它？ 在现实生活中你为什么要用钥匙环（也叫钥匙链）？你用它把一把或多把钥匙串到一起, 以便于携带和查找。\nLinux 里也是类似的。密钥环特性使你的系统可以将各种密码放在一起，并将其保存在一个地方。\n大多数 Linux 桌面环境，如 GNOME、KDE、Xfce 等采用 GNOME 密钥环来提供这个功能。\n该密钥环保存了 ssh 密钥、GPG 密钥以及使用此功能的应用程序（例如 Chromium 浏览器）的密钥。默认情况下，“密钥环”通过主密码来保护，该密码通常是帐户的登录密码。\n系统上的每个用户都有自己的密钥环，（通常）密码与用户帐户本身的密码相同。当你使用密码登录系统时，你的密匙环将使用你帐户的密码自动解锁。\n当你启用 Ubuntu 中的自动登录功能时时，就有问题了。这意味着你无需输入密码即可登录系统。在这种情况下，你的密钥环不会自动解锁。\n密钥环是一个安全特性\n记得我说过密钥环是一个安全特性吗？现在想象一下你在 Linux 电脑上开启了自动登录功能。有权访问你电脑的任何人无需密码就能进入你的系统。但是你可能不会在意，因为你只是用它来访问互联网。\n但是，如果你在 Ubuntu 中使用 Chromium 或 Google Chrome 之类的浏览器，并使用它来保存各种网站的登录密码，那么你将遇到麻烦。任何人都可以使用浏览器并利用你在浏览器中保存的密码登录网站。这不很危险吗？\n这就是为什么当你使用 Chrome 时，它将反复地提示你先解锁密钥环。这确保了只有知道密钥环密码（即账户密码）的人才能使用在浏览器中保存的密码来登录它们相关的网站。\n如果你反复取消解锁密钥环的提示，它最终将消失，并允许你使用浏览器。但是，保存的密码将不会被解锁，你在 Chromium/Chome 浏览器上将会看到“同步暂停”的提示。\n如果密钥环一直存在，为什么你从来没有见过它呢?\n如果你在你的 Linux 系统上从没见过它的话，这个问题就很有道理。\n如果你从没有用过自动登录功能（或者修改你的账户密码），你可能都没有意识到这个特性的存在。\n这是因为当你通过你的密码登录系统时，你的密钥环被你的账户密码自动解锁了。\nUbuntu（和其他发行版）在执行普通的管理任务如修改用户、安装新软件等需要输入密码，无论你是否是自动登录的。但是对于日常任务像使用浏览器，它不需要输入密码因为密钥环已经被解锁了。\n当你切换到自动登录时，你不再需要输入登录密码。这意味着密钥环没有被自动解锁，因此当你使用利用了密钥环特性的浏览器时，它将提示你来解锁密钥环。\n你可以轻松地管理密钥环和密码\n这个密钥环放在哪里？它的核心是一个守护任务（一个后台自动运行的程序）。\n别担心。你不必通过终端来操作守护任务。大多数桌面环境都自带一个可以和这个守护进程进行交互的图形化应用程序。KDE 上有 KDE 钱包，GNOME 和其他桌面上叫做“密码和密钥”（Password And Keys）。\n你可以用这个 GUI 程序来查看哪些应用程序在用密钥环来管理/保护密码。\n你可以看到，我的系统有自动创建的登录密钥环。也有一个存储 GPG 和 SSH 密钥的密钥环。那个证书用来保存证书机构颁发的证书（如 HTTPS 证书）。\n你也可以使用这个应用程序来手动保存网站的密码。\n这里有一个潜在的问题，如果你格式化你的系统，手动保存的密码必然会丢失。通常，你会备份你的个人文件，但并不是所有的用户特定数据，如密钥环文件。\n有一种办法能解决它。密钥环数据通常保存在 ~/.local/share/keyrings 目录。在这里你可以看到所有的密钥环，但是你不能直接看到它们的内容。如果你移除密钥环的密码（我会在这篇文章的后面描述操作步骤），你可以像一个普通的文本文件一样读取密钥环的内容。你可以将这个解锁后的密钥环文件完整地复制下来，并在其他的 Linux 机器上运行“密码和密钥”应用程序导入到其中。\n总结一下目前为止所学的内容：\n 大多数 Linux 系统缺省已经安装并激活了密钥环特性 系统上的每个用户都拥有他自己的密钥环 密钥环通常是用账户密码锁定的（保护） 当你通过密码登录时密钥环会被自动解锁 对于自动登录，密钥环不会自动解锁，因此当你试图使用依赖密钥环的应用程序时会被提示先解锁它 并不是所有的浏览器或应用程序利用了密钥环特性 （Linux 上）安装一个 GUI 程序可以和密钥环交互 你可以用密钥环来手动存储加密格式的密码 你可以自己修改密钥环密码 你可以通过导出（需要先解锁密钥环）并导入到其他计算机上的方式来获取手工保存的密码。  修改密钥环密码 假设你修改了你的账户密码。当你登录时，你的系统试图通过新的登录密码来自动解锁密钥环。但是密钥环还在使用老的登录密码。\n这种情况下，你可以修改密钥环密码为新的登录密码，这样密码环才能在你登录系统时自动解锁。\n 从菜单中打开“密码和密钥”应用程序 在“Login”密钥环上右击并点击“修改密码”：  如果你不记得老的登录密码怎么办？\nResetting everything (delete all passwords and start new keyring):\n$ rm ~/.local/share/keyrings/login.keyring Then, log out and log back in. Ubuntu will automatically create a new login.keyring for you.\n禁用密钥环密码 在你想用自动登录但又不想手动解锁密钥环时，你可以把禁用密钥环密码作为一个规避方法。记住你正在禁用一个安全特性，因此请三思。\n操作步骤和修改密钥环相似。打开“密码和密钥”应用程序，然后修改密钥环密码。\n技巧在于当它提示修改密码时，不要输入新密码，而是点击“继续”按钮。这将移除密钥环的密码。\n这种方法，密钥环没有密码保护，并将一直处于解锁状态。\nGnome Apps Books GNOME Books is a simple application to access and organize your ebooks. It is meant to be a simple and elegant replacement for using a file manager to deal with ebooks. The app supports comic books and ePub books.\n$ sudo apt install gnome-books e-book 需放在特定的目录，gnome-boos 自动扫描，在其他目录不扫描，而且也无法用 gnome-books file 方式打开，例如 ~/Public 目录。\nCalendar $ sudo apt install gnome-calendar $ gsettings set org.gnome.GWeather temperature-unit centigrade ","permalink":"https://sakamotokurome.github.io/posts/ubuntup0desktop/","summary":"友邦拓 乌班图 During the first ten years of this HOWTO\u0026rsquo;s life, I reported that from a new user\u0026rsquo;s point of view, all Linux distributions are almost equivalent. But in 2006-2007, an actual best choice emerged: Ubuntu. While other distros have their own areas of strength, Ubuntu is far and away the most accessible to Linux newbies. Beware, though, of the hideous and nigh-unusable \u0026ldquo;Unity\u0026rdquo; desktop interface","title":"Ubuntu Desktop"},{"content":"Hexo Hexo 是一个快速、简洁且高效的博客框架。\n安装   安装 Git：\n Windows: Download \u0026amp; install git. Mac: Install it with Homebrew, MacPorts or installer. Linux (Ubuntu, Debian): sudo apt-get install git-core Linux (Fedora, Red Hat, CentOS): sudo yum install git-core    安装 node.js：\n Windows: Install it with nvs (recommended) or nvm. Mac: Install it with Homebrew or MacPorts. Linux (DEB/RPM-based): Install it with NodeSource. Others: Install it through respective package manager. Refer to the guide provided by Node.js.    安装 Hexo：-g 表示全局安装，会将 Hexo 命令加入环境变量中。\n$ npm --registry https://registry.npm.taobao.org install -g hexo-cli # 持久使用镜像 $ npm config set registry https://registry.npm.taobao.org Where do global npm packages get installed\n$ npm root -g   建站 $ hexo init [folder] $ cd \u0026lt;folder\u0026gt; $ npm install 新建完成后，指定文件夹的目录如下：\n. ├── node_modules\t//依赖安装目录 ├── scaffolds\t//模板文件夹，Hexo的模板是指在新建的文章文件中默认填充的内容。 | ├── draft.md\t//草稿模板 | ├── page.md\t//页面模板 | └── post.md\t//文章模板 ├── source\t//资源文件夹 | └── _posts\t//文章目录 ├── themes\t//主题文件夹，Hexo 会根据主题来生成静态页面。 | └── landscape\t//默认主题 ├── .gitignore\t//指定不纳入git版本控制的文件 ├── _config.yml\t//站点配置文件 ├── db.json ├── package.json\t//应用程序的信息 └── package-lock.json source：资源文件夹是存放用户资源的地方。除 _posts 文件夹之外，开头命名为 _ (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。\n配置 您可以在 _config.yml 中修改大部分的配置。\n网站    参数 描述     title 网站标题   subtitle 网站副标题   description 网站描述   keywords 网站的关键词。支持多个关键词。   author 您的名字   language 网站使用的语言。对于简体中文用户来说，使用不同的主题可能需要设置成不同的值，请参考你的主题的文档自行设置，常见的有 zh-Hans和 zh-CN。   timezone 网站时区。Hexo 默认使用您电脑的时区。请参考 时区列表 进行设置，如 America/New_York, Japan, 和 UTC 。一般的，对于中国大陆地区可以使用 Asia/Shanghai。    其中，description主要用于SEO，告诉搜索引擎一个关于您站点的简单描述，通常建议在其中包含您网站的关键词。author参数用于主题显示文章的作者。\n网址    参数 描述 默认值     url 网址, 必须以 http:// 或 https:// 开头    root 网站根目录 url's pathname   permalink 文章的 永久链接 格式 :year/:month/:day/:title/   permalink_defaults 永久链接中各部分的默认值    pretty_urls 改写 permalink 的值来美化 URL    pretty_urls.trailing_index 是否在永久链接中保留尾部的 index.html，设置为 false 时去除 true   pretty_urls.trailing_html 是否在永久链接中保留尾部的 .html, 设置为 false 时去除 (对尾部的 index.html无效) true     网站存放在子目录\n如果您的网站存放在子目录中，例如 http://example.com/blog，则请将您的 url 设为 http://example.com/blog 并把 root 设为 /blog/。\n 例如：\n# 比如，一个页面的永久链接是 http://example.com/foo/bar/index.html pretty_urls: trailing_index: false # 此时页面的永久链接会变为 http://example.com/foo/bar/ 目录    参数 描述 默认值     source_dir 资源文件夹，这个文件夹用来存放内容。 source   public_dir 公共文件夹，这个文件夹用于存放生成的站点文件。 public   tag_dir 标签文件夹 tags   archive_dir 归档文件夹 archives   category_dir 分类文件夹 categories   code_dir Include code 文件夹，source_dir 下的子目录 downloads/code   i18n_dir 国际化（i18n）文件夹 :lang   skip_render 跳过指定文件的渲染。匹配到的文件将会被不做改动地复制到 public 目录中。您可使用 glob 表达式来匹配路径。     例如：\nskip_render: \u0026#34;mypage/**/*\u0026#34; # 将会直接将 `source/mypage/index.html` 和 `source/mypage/code.js` 不做改动地输出到 \u0026#39;public\u0026#39; 目录 # 你也可以用这种方法来跳过对指定文章文件的渲染 skip_render: \u0026#34;_posts/test-post.md\u0026#34; # 这将会忽略对 \u0026#39;test-post.md\u0026#39; 的渲染  提示\n如果您刚刚开始接触 Hexo，通常没有必要修改这一部分的值。\n 文章    参数 描述 默认值     new_post_name 新文章的文件名称 :title.md   default_layout 预设布局 post   auto_spacing 在中文和英文之间加入空格 false   titlecase 把标题转换为 title case false   external_link 在新标签中打开链接 true   external_link.enable 在新标签中打开链接 true   external_link.field 对整个网站（site）生效或仅对文章（post）生效 site   external_link.exclude 需要排除的域名。主域名和子域名如 www 需分别配置 []   filename_case 把文件名称转换为 (1) 小写或 (2) 大写 0   render_drafts 显示草稿 false   post_asset_folder 启动 Asset 文件夹 false   relative_link 把链接改为与根目录的相对位址 false   future 显示未来的文章 true   highlight 代码块的设置, 请参考 Highlight.js 进行设置    prismjs 代码块的设置, 请参考 PrismJS 进行设置      相对地址\n默认情况下，Hexo 生成的超链接都是绝对地址。例如，如果您的网站域名为 example.com,您有一篇文章名为 hello，那么绝对链接可能像这样：http://example.com/hello.html，它是绝对于域名的。相对链接像这样：/hello.html，也就是说，无论用什么域名访问该站点，都没有关系，这在进行反向代理时可能用到。通常情况下，建议使用绝对地址。\n 分类 \u0026amp; 标签    参数 描述 默认值     default_category 默认分类 uncategorized   category_map 分类别名    tag_map 标签别名     日期 / 时间格式 Hexo 使用 Moment.js 来解析和显示时间。\n   参数 描述 默认值     date_format 日期格式 YYYY-MM-DD   time_format 时间格式 HH:mm:ss   updated_option 当 Front Matter 中没有指定 updated 时 updated 的取值 mtime     updated_option\nupdated_option 控制了当 Front Matter 中没有指定 updated 时，updated 如何取值：\n mtime: 使用文件的最后修改时间。这是从 Hexo 3.0.0 开始的默认行为。 date: 使用 date 作为 updated 的值。可被用于 Git 工作流之中，因为使用 Git 管理站点时，文件的最后修改日期常常会发生改变 empty: 直接删除 updated。使用这一选项可能会导致大部分主题和插件无法正常工作。  use_date_for_updated 选项已经被废弃，将会在下个重大版本发布时去除。请改为使用 updated_option: 'date'。\n use_date_for_updated` | 启用以后，如果 Front Matter 中没有指定 `updated`， [`post.updated`](https://hexo.io/zh-cn/docs/configuration) 将会使用 `date` 的值而不是文件的创建时间。在 Git 工作流中这个选项会很有用 | `true 分页    参数 描述 默认值     per_page 每页显示的文章量 (0 = 关闭分页功能) 10   pagination_dir 分页目录 page    扩展    参数 描述     theme 当前主题名称。值为false时禁用主题   theme_config 主题的配置文件。在这里放置的配置会覆盖主题目录下的 _config.yml 中的配置   deploy 部署部分的设置   meta_generator Meta generator 标签。 值为 false 时 Hexo 不会在头部插入该标签    包括或不包括目录和文件\n在 Hexo 配置文件中，通过设置 include/exclude 可以让 Hexo 进行处理或忽略某些目录和文件夹。你可以使用 glob 表达式 对目录和文件进行匹配。\ninclude and exclude options only apply to the source/ folder, whereas ignore option applies to all folders.\n   参数 描述     include Hexo 默认会忽略隐藏文件和文件夹（包括名称以下划线和 . 开头的文件和文件夹，Hexo 的 _posts 和 _data 等目录除外）。通过设置此字段将使 Hexo 处理他们并将它们复制到 source 目录下。   exclude Hexo 会忽略这些文件和目录   ignore Ignore files/folders    举例：\n# Include/Exclude Files/Folders include: - \u0026#34;.nojekyll\u0026#34; # 包括 \u0026#39;source/css/_typing.css\u0026#39; - \u0026#34;css/_typing.css\u0026#34; # 包括 \u0026#39;source/_css/\u0026#39; 中的任何文件，但不包括子目录及其其中的文件。 - \u0026#34;_css/*\u0026#34; # 包含 \u0026#39;source/_css/\u0026#39; 中的任何文件和子目录下的任何文件 - \u0026#34;_css/**/*\u0026#34; exclude: # 不包括 \u0026#39;source/js/test.js\u0026#39; - \u0026#34;js/test.js\u0026#34; # 不包括 \u0026#39;source/js/\u0026#39; 中的文件、但包括子目录下的所有目录和文件 - \u0026#34;js/*\u0026#34; # 不包括 \u0026#39;source/js/\u0026#39; 中的文件和子目录下的任何文件 - \u0026#34;js/**/*\u0026#34; # 不包括 \u0026#39;source/js/\u0026#39; 目录下的所有文件名以 \u0026#39;test\u0026#39; 开头的文件，但包括其它文件和子目录下的单文件 - \u0026#34;js/test*\u0026#34; # 不包括 \u0026#39;source/js/\u0026#39; 及其子目录中任何以 \u0026#39;test\u0026#39; 开头的文件 - \u0026#34;js/**/test*\u0026#34; # 不要用 exclude 来忽略 \u0026#39;source/_posts/\u0026#39; 中的文件。你应该使用 \u0026#39;skip_render\u0026#39;，或者在要忽略的文件的文件名之前加一个下划线 \u0026#39;_\u0026#39; # 在这里配置一个 - \u0026#34;_posts/hello-world.md\u0026#34; 是没有用的。 ignore: # Ignore any folder named \u0026#39;foo\u0026#39;. - \u0026#34;**/foo\u0026#34; # Ignore \u0026#39;foo\u0026#39; folder in \u0026#39;themes/\u0026#39; only. - \u0026#34;**/themes/*/foo\u0026#34; # Same as above, but applies to every subfolders of \u0026#39;themes/\u0026#39;. - \u0026#34;**/themes/**/foo\u0026#34; 列表中的每一项都必须用单引号或双引号包裹起来。\ninclude 和 exclude 并不适用于 themes/ 目录下的文件。如果需要忽略 themes/ 目录下的部分文件或文件夹，可以使用 ignore 或在文件名之前添加下划线 _。\n使用代替配置文件\n可以在 hexo-cli 中使用 --config 参数来指定自定义配置文件的路径。你可以使用一个 YAML 或 JSON 文件的路径，也可以使用逗号分隔（无空格）的多个 YAML 或 JSON 文件的路径。例如：\n# use \u0026#39;custom.yml\u0026#39; in place of \u0026#39;_config.yml\u0026#39; $ hexo server --config custom.yml # use \u0026#39;custom.yml\u0026#39; \u0026amp; \u0026#39;custom2.json\u0026#39;, prioritizing \u0026#39;custom3.yml\u0026#39;, then \u0026#39;custom2.json\u0026#39; $ hexo generate --config custom.yml,custom2.json,custom3.yml 当你指定了多个配置文件以后，Hexo 会按顺序将这部分配置文件合并成一个 _multiconfig.yml。如果遇到重复的配置，排在后面的文件的配置会覆盖排在前面的文件的配置。这个原则适用于任意数量、任意深度的 YAML 和 JSON 文件。\n例如，使用 --options 指定了两个自定义配置文件：\n$ hexo generate --config custom.yml,custom2.json 如果 custom.yml 中指定了 foo: bar，在 custom2.json 中指定了 \u0026quot;foo\u0026quot;: \u0026quot;dinosaur\u0026quot;，那么在 _multiconfig.yml 中你会得到 foo: dinosaur。\n使用代替主题配置文件\n通常情况下，Hexo 主题是一个独立的项目，并拥有一个独立的 _config.yml 配置文件。\n除了自行维护独立的主题配置文件，你也可以在其它地方对主题进行配置。\n配置文件中的 theme_config\n 该特性自 Hexo 2.8.2 起提供\n # _config.yml theme: \u0026#34;my-theme\u0026#34; theme_config: bio: \u0026#34;My awesome bio\u0026#34; foo: bar: \u0026#39;a\u0026#39; # themes/my-theme/_config.yml bio: \u0026#34;Some generic bio\u0026#34; logo: \u0026#34;a-cool-image.png\u0026#34; foo: baz: \u0026#39;b\u0026#39; 最终主题配置的输出是：\n{ bio: \u0026#34;My awesome bio\u0026#34;, logo: \u0026#34;a-cool-image.png\u0026#34;, foo: { bar: \u0026#34;a\u0026#34;, baz: \u0026#34;b\u0026#34; } } 独立的 _config.[theme].yml 文件\n 该特性自 Hexo 5.0.0 起提供\n 独立的主题配置文件应放置于站点根目录下，支持 yml 或 json 格式。需要配置站点 _config.yml 文件中的 theme 以供 Hexo 寻找 _config.[theme].yml 文件。\n# _config.yml theme: \u0026#34;my-theme\u0026#34; # _config.my-theme.yml bio: \u0026#34;My awesome bio\u0026#34; foo: bar: \u0026#39;a\u0026#39; # themes/my-theme/_config.yml bio: \u0026#34;Some generic bio\u0026#34; logo: \u0026#34;a-cool-image.png\u0026#34; foo: baz: \u0026#39;b\u0026#39; 最终主题配置的输出是：\n{ bio: \u0026#34;My awesome bio\u0026#34;, logo: \u0026#34;a-cool-image.png\u0026#34;, foo: { bar: \u0026#34;a\u0026#34;, baz: \u0026#34;b\u0026#34; } }  我们强烈建议你将所有的主题配置集中在一处。如果你不得不在多处配置你的主题，那么这些信息对你将会非常有用：Hexo 在合并主题配置时，Hexo 配置文件中的 theme_config 的优先级最高，其次是 _config.[theme].yml 文件，最后是位于主题目录下的 _config.yml 文件。\n 指令   version 显示 Hexo 版本：\nhexo version   list 列出网站资料：\nhexo list   新建一篇文章：如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。\nhexo new [layout] \u0026lt;title\u0026gt; hexo n [layout] \u0026lt;title\u0026gt;   Hexo 有三种默认布局：\n   布局 路径     post source/_posts   page source   draft source/_drafts      预览草稿，publish 发表草稿：\nhexo server --draft hexo publish [layout] \u0026lt;filename\u0026gt;   clean 清除缓存文件 (db.json) 和已生成的静态文件 (public)：\nhexo clean   generate 生成静态文件：\nhexo generate hexo g   启动 hexo 的内置 Web 服务器：该命令将会调用 Markdown 引擎解析项目中的博客内容生成网页资源，资源将会存于内存中。\nhexo server hexo s --debug\t# 开启调试模式（--debug） hexo s --port 8000\t# 添加 -p / --port 参数来设置 Web 服务监听的端口号 hexo s --static\t# 加 -s / --static 参数，本地改动不触发 hexo 实时解析更新。   deploy 部署网站：\nhexo deploy hexo d   写作   Front-matter： 是文件最上方以 --- 分隔的区域，用于指定个别文件的变量\n--- layout: # 布局 title: # 标题 date: # 建立日期 updated: # 更新日期 comments: # 开启文章的评论功能 tags:\t# 标签 - 标签1 - 标签2 categories: [分类1, 分类2]\t# 分类, 不适用与分页 permalink: # 覆盖文章网址 --- 标签是一种列表结构，而分类是一种树结构。\n  文本居中标签：在引用单行文本时使用\n\u0026lt;blockquote class=\u0026quot;blockquote-center\u0026quot;\u0026gt;blah blah blah\u0026lt;/blockquote\u0026gt;\t# HTML方式 {% centerquote %}blah blah blah{% endcenterquote %}\t# 标签方式 {% cq %} blah blah blah {% endcq %}\t# 标签别名   引用块\n{% blockquote [author[, source]] [link] [source_link_title] %} content {% endblockquote %}   代码块\n``` [language] [title] [url] [link text] code snippet  - `langugae`：语言名称，引导渲染引擎正确解析并高亮显示关键字 - `title`：代码块标题，将会显示在左上角 - `url`：链接地址，如果没有指定 link text 则会在右上角显示 link - `link text`：链接名称，指定 url 后有效，将会显示在右上角 - 如果设置语言为 diff，可以在代码前添加 `+` 和 `-` 来使用如上所示的高亮增删行提示效果，在展示代码改动痕迹时比较实用。   note 标签：通过 note 标签可以为段落添加背景色\n{% note [class] %} 文本内容 (支持行内标签) {% endnote %}  支持的 class 种类包括 default、primary、success、info、warning、danger    label 标签：通过 label 标签可以为文字添加背景色\n{% label [class]@text %}  支持的 class 种类包括 default、primary、success、info、warning、danger    button 按钮：通过 button 标签可以快速添加带有主题样式的按钮\n{% button /path/to/url/, text, icon [class], title %} {% btn /path/to/url/, text, icon [class], title %}   tab 标签：tab 标签用于快速创建 tab 选项卡\n{% tabs [Unique name], [index] %} \u0026lt;!-- tab [Tab caption]@[icon] --\u0026gt; 标签页内容（支持行内标签） \u0026lt;!-- endtab --\u0026gt; {% endtabs %}  Unique name: 全局唯一的 Tab 名称，将作为各个标签页的 id 属性前缀 index: 当前激活的标签页索引，如果未定义则默认选中显示第一个标签页，如果设为 - 1 则默认隐藏所有标签页 Tab caption: 当前标签页的标题，如果不指定则会以 Unique name 加上索引作为标题 icon: 在标签页标题中添加 Font awesome 图标    引用站内链接\n{% post_path slug %} {% post_link slug [title] %}  slug 表示 _post 目录下的 Markdown 文件名。 post_path 标签将会渲染为文章的地址，即 permalink；而 post_link 标签将会渲染为链接，可以通过 title 指定链接标题。    插入 Swig 代码：通过 raw 标签来禁止 Markdown 引擎渲染标签内的内容。该标签通常用于在页面内引入三方脚本实现特殊功能。\n{% raw %} content {% endraw %}   插入 Gist\n{% gist gist_id [filename] %}  gist_id: Gist 仓库页面 url 中最后一段随机字符串 filename: Gist 中的文件名，如果 Gist 中只有一个文件，可以不用指定 filename，如果 Gist 中有多个文件，可以在标签内输入 filename 来指定只引入某个文件，如果没有指定 filename，将会引入 Gist 中的所有文件。    插入图片：\n  Markdown 并不会保存插入的图片资源本身，只是记录了获取资源的链接。\n  相对路径引用的标签插件\n{% asset_img slug [title] %}   slug 是资源文件夹下的图片名\n  Embedding an image using markdown：allows you to embed an image in markdown without using asset_img tag plugin.\npost_asset_folder: true marked: prependRoot: true postAsset: true ![](image.jpg) will be rendered as \u0026lt;img src=\u0026quot;/2020/01/02/foo/image.jpg\u0026quot;\u0026gt;.\n    用Typora编写Hexo博客时能实预览图片\n  思路是在before_post_render阶段将markdown文件中图片的路径转换为asset_img函数。\nnpm install hexo-image-link --save       文章加密\n  Install\nnpm install --save hexo-blog-encrypt   Quick start: Add the \u0026ldquo;password\u0026rdquo; value to your post\u0026rsquo;s front matter like\n--- password: mikemessi ---     Hexo 添加文章时自动打开编辑器\n  在 Hexo 目录下的 scripts 目录中创建一个 JavaScript 脚本文件。通过这个脚本，我们用其来监听 hexo new 这个动作，并在检测到 hexo new 之后，执行编辑器打开的命令。\n  将下列内容写入你的脚本\nvar spawn = require('child_process').exec; hexo.on('new', function(data){ spawn('start \u0026quot;markdown编辑器绝对路径.exe\u0026quot; ' + data.path); });     文章置顶\n--- sticky: true ---   资源文件夹 资源（Asset）代表 source 文件夹中除了文章以外的所有文件。\n文章资源文件夹\npost_asset_folder: true 当资源文件管理功能打开后，Hexo将会在你每一次通过 hexo new [layout] \u0026lt;title\u0026gt; 命令创建新文章时自动创建一个文件夹。这个资源文件夹将会有与这个文章文件一样的名字。将所有与你的文章有关的资源放在这个关联文件夹中之后，你可以通过相对路径来引用它们。\n部署 持续集成（Continuous Integration，简称 CI）\nSimply Push to Deploy：热部署，只需要将代码 push 到 Git 远程仓库即可自动构建及更新。\nNetlify\nGitHub Action：\n  Add your ssh key pair\n  Run the following terminal command, replacing the email with one connected to your GitHub account.\nssh-keygen -t rsa -C \u0026#34;username@example.com\u0026#34; Windows 下自定义 ssh key 文件需写成 GIT\\BlogSrc/.ssh/id_rsa\n  In Github Pages repo: Add the contents of the public key（id_rsa.pub） within your repositories deploy keys menu. You can find this option by going to Settings \u0026gt; Deploy Keys, you can name the public key whatever you want, but you do need to give it write access.\n  In hexo source code repo: Add the contents of the private key（id_rsa） to the Settings \u0026gt; Secrets menu as DEPLOY_KEY.\n    Configure github workflows：Create a workflow .yml file in your .github/workflows directory.\nname: Deploy on: [push] jobs: build: runs-on: ubuntu-latest name: A job to deploy blog. steps: - name: Checkout uses: actions/checkout@v1 with: submodules: true # Checkout private submodules(themes or something else). # Caching dependencies to speed up workflows. (GitHub will remove any cache entries that have not been accessed in over 7 days.) - name: Cache node modules uses: actions/cache@v1 id: cache with: path: node_modules key: ${{ runner.os }}-node-${{ hashFiles(\u0026#39;**/package-lock.json\u0026#39;) }} restore-keys: | ${{ runner.os }}-node- - name: Install Dependencies if: steps.cache.outputs.cache-hit != \u0026#39;true\u0026#39; run: npm ci # Deploy hexo blog website. - name: Deploy id: deploy uses: sma11black/hexo-action@v1.0.3 with: deploy_key: ${{ secrets.DEPLOY_KEY }} user_name: your github username  # (or delete this input setting to use bot account) user_email: your github useremail  # (or delete this input setting to use bot account) commit_msg: ${{ github.event.head_commit.message }}  # (or delete this input setting to use hexo default settings) # Use the output from the `deploy` step(use for test action) - name: Get the output run: | echo \u0026#34;${{ steps.deploy.outputs.notify }}\u0026#34;   一键部署\n  新建一个空的 repository（没有init任何内容）。你的 repository 必须直接命名为 \u0026lt;你的 GitHub 用户名.github.io\u0026gt;。从而能通过 \u0026lt;你的 GitHub 用户名.github.io\u0026gt; 域名直接访问你的blog。\n  安装 hexo-deployer-git。\nnpm install hexo-deployer-git --save   修改_config.yml配置。\ndeploy: type: git repo: git@github.com:yourname/yourname.github.io.git branch: master   生成站点文件并推送至远程库。执行 hexo clean \u0026amp; hexo deploy。\n  登入 Github，在库设置（Repository Settings）中将默认分支设置为_config.yml配置中的分支名称。稍等片刻（Blog 不会立马加载出来，需多刷新几下），您的站点就会显示在您的Github Pages中。\n  这是如何发生的：当执行 hexo deploy 时，Hexo 会将 public 目录中的文件和目录推送至 _config.yml 中指定的远端仓库和分支中，并且完全覆盖该分支下的已有内容。\n  部署分支与写作分支：hexo d 部署到 GitHub 的是 hexo 编译后的文件，不包含源文件。可以利用git的分支管理，将源文件上传到 GitHub。一个好的实践是放在两个不同的 Git 仓库中。\n  主题 创建 Hexo 主题非常容易，您只要在 themes 文件夹内，新增一个任意名称的文件夹，并修改 _config.yml 内的 theme 设定，即可切换主题。\n _config.yml：主题的配置文件。和 Hexo 配置文件不同，主题配置文件修改时会自动更新，无需重启 Hexo Server。 languages：语言文件夹。 layout：布局文件夹。 scripts：脚本文件夹。 source：资源文件夹。  在 GitHub 搜索 Hexo 即可找到流行的 Hexo 主题。各主题都有相应的使用文档。\n其他 列表之后不能立即接一个代码块，否则会解析出错。如\n- ```bash code... ``` 一行代码没有问题\n- `code` 首页展示最新博客 index_generator: path: \u0026#39;\u0026#39; per_page: 10 - order_by: -date + order_by: {updated: -1}  -updated_option: \u0026#39;mtime\u0026#39; +updated_option: \u0026#39;date\u0026#39; Are there more order options?\n  Api Document：https://hexojs.github.io/warehouse/Query.html#sort\n  sort(orderby, orderopt) → {Query}\n  Example:\nquery.sort('date', -1); query.sort({date: -1, title: 1}); query.sort('-date title');   If the order equals to -1, desc or descending, the data will be returned in reversed order.\n  Parameters:\n   Name Type Attributes     orderby String Object   order String Number        Sort is to sort the object properties (Page-Variables), refer to the above document for details。\n   Variable Description Type     page.title Article title string   page.date Article created date Moment.js object   page.updated Article last updated date Moment.js object      hexo-generator-index\nconst posts = locals.posts.sort(config.index_generator.order_by);   updated_option\nupdated_option 控制了当 Front Matter 中没有指定 updated 时，updated 如何取值：\n mtime: 使用文件的最后修改时间。这是从 Hexo 3.0.0 开始的默认行为。 date: 使用 date 作为 updated 的值。可被用于 Git 工作流之中，因为使用 Git 管理站点时，文件的最后修改日期常常会发生改变 empty: 直接删除 updated。使用这一选项可能会导致大部分主题和插件无法正常工作。    NexT Getting Started Installation\n  Installation\ncd hexo-site npm install hexo-theme-next   Usage, theme config file\ntheme: next   Update\ncd hexo-site npm update hexo-theme-next   Configuration\nInstalled through npm\ncp node_modules/hexo-theme-next/_config.yml _config.next.yml Theme Settings Choosing Scheme:\nBy using Scheme NexT gives you different views. And nearly all config can be used by those Schemes.\n# next/_config.yml scheme: Muse Configuring Favicon:\nBy default the Hexo site use NexT favicons in hexo-site/themes/next/source/images/ directory with different size for different device.\nYou can replace them with your own favicons.\nFor example, you can put your favicons in hexo-site/source/images/ directory. Then you need to rename them and change the settings in favicon section in theme config file.\nCreative Commons:\nNexT supports the display of Creative Commons 4.0 International License in sidebar and post.\n# next/_config.yml creative_commons: license: by-nc-sa sidebar: true post: false language: en 通行的版权协议是一种限制性的协议，就是说，只有它明文许可你可以做的事，你才能做，否则就是侵权行为。\n而\u0026quot;开放内容许可证\u0026quot;（open content licenses）只明文禁止使用者不能做的事，除此以外，可以随意使用这些作品。创作共用许可证（Creative Commons licenses，简称cc），就是这样一种许可证。\n使用创作共用许可证，作者可以选择保留四种权利：\n 署名（Attribution，简写为by）：必须提到原作者。 非商业用途（Noncommercial，简写为nc）：不得用于盈利性目的。 禁止演绎（No Derivative Works，简写为nd）：不得修改原作品。 相同方式共享（Share Alike，简写为sa）：如果允许修改原作品，那么必须使用相同的许可证发布。  Configuring Menu Items:\nMenu settings items have format Key: /link/ || icon which contains 3 values:\n Key → is the name of menu item (home, archives, etc.). /link/ → is the target link to relative url inside your site. icon → is the name of Font Awesome icon.  To customize menu items, edit the following content in theme config file\nmenu: home: / || fa fa-home about: /about/ || fa fa-user tags: /tags/ || fa fa-tags archives: /archives/ || fa fa-archive Google Calendar Page\nschedule: /schedule/ || fa fa-calendar sitemap：为了让博文被google或百度检索，需要使用hexo的sitemap功能。\nsitemap: /sitemap.xml || fa fa-sitemap   Install\nnpm install hexo-generator-sitemap --save   Hexo Config\nsitemap: path: sitemap.xml   Except home and archives, all custom pages under menu section need to be created manually!\nSidebar Setting\nConfiguring Avatar：\nPut your avatar under site directory source/uploads/ (create directory if it doesn\u0026rsquo;t exists).And then change option to url: /uploads/avatar.png.\navatar: url: /uploads/avatar.png rounded: true 点击头像回到首页：\n主要是将\u0026lt;img class=\u0026quot;site-author-image\u0026quot; ... /\u0026gt;加入到\u0026lt;a href=\u0026quot;/\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;。\nSidebar Social Links：\n  Edit the social section in theme config file as following:\nsocial: GitHub: https://github.com/yourname || fab fa-github E-Mail: mailto:yourname@example.com || fa fa-envelope   取消社交图标前的小圆点：\n# create hexo-site/source/_data/styles.styl .links-of-author a, .links-of-author .exturl { \u0026amp;:before { display: none; } }   Sidebar Blogrolls (友链):\nlinks: Title1: https://example.com/ Sidebar TOC:\ntoc: number: false expand_all: true max_depth: 5 Footer\nSite Footer Icon:\nBy default NexT shows red heart icon between year and copyright information in the footer.\nfooter: icon: animated: true Site Copyright Name:\nBy default NexT shows the name of author from site config file.\nfooter: copyright: YourName Site Platform Information:\nBy default NexT shows Hexo and Theme \u0026amp; scheme information.\nfooter: powered: false Site Beian Information:\nBeian information is for Chinese users.\nfooter: beian: enable: true icp: 京ICP备 1234567890号-1 gongan_id: 1234567890 gongan_num: 京公网安备 1234567890号 gongan_icon_url: /uploads/beian.png Post Settings\nPreamble Text:\nYou can use following ways to show summary of articles and a Read More button.\nUse \u0026lt;!-- more --\u0026gt; in your article to break your article manually, which is recommended by Hexo. (recommended)\nIf you have added description and set its value to your article summary in front-matter, NexT excerpts description as preamble text in homepage by default. Without description, the full contents would be the preamble text in homepage.\nPost Wordcount:\n  Installation\ncd hexo-site npm install hexo-word-counter hexo clean   Hexo Config\nsymbols_count_time: total_symbols: false\t# By default NexT shows the number of all posts words in footer section. total_time: false\t# By default NexT shows the estimated reading time of all posts in footer section.    Donate Settings:\n  Get your WeChat / Alipay receive money QRcode image(s) and put into source/images .\n  Set needed values in theme config file:\nreward_settings: enable: true animation: false comment: Buy me a coffee reward: wechatpay: /images/wechatpay.png alipay: /images/alipay.png   Follow Me:\nfollow_me: WeChat: /images/wechat_channel.jpg || fab fa-weixin RSS: /atom.xml || fa fa-rss  安装RSS插件  npm i hexo-generator-feed  配置站点配置文件(/_config.yml)的Extensions  plugin: - hexo-generator-feed # Feed Atom feed: type: atom path: atom.xml limit: 20  编辑主题配置文件(/theme/next/_config.yml)的social links，开启RSS的页面功能  rss: /atom.xml  关注RSS：把 https://vanehsiung.github.io/atom.xml 复制到RSS阅读器上，就能关注了。  Custom Pages\nCustom Page Support:\n  Adding New Page\ncd hexo-site hexo new page tags   Setting Front-matter Values\n--- title: Tags date: title: 2020-11-14 22:50:2 type: \u0026quot;tags\u0026quot; ---   Editting Menu\nmenu: tags: /tags/ || fa fa-tags   Custom 404 Page:\n  Create a new page called 404\ncd hexo-site hexo new page 404 --- title: 404 permalink: /404.html\t# 在 Github Docs 中 Github Pages 章有写 comments: false ---   Make sure relative_link is disabled in site config file\nrelative_link: false   Whether users can be redirected to the 404 page depends on the settings of the website hosting service or web server, not Hexo.\n  为 GitHub Pages 站点创建自定义 404 页面\n  Misc Theme Settings\nMobile Devices Adaptation:\nreduce padding/margin indents on devices with narrow width\nmobile_layout_economy: true Codeblock Style:\nNexT uses the Highlight.js and Prism package to support code highlight\n  Read Hexo\u0026rsquo;s documentation on Syntax Highlighting first, and set it up in site config file（在 _config.yml 中开启 Highlight 或 Prism）\nhighlight: enable: true   Preview all available Code Highlight themes here: NexT Highlight Theme Preview\n  Change the value of theme and prism to choose the highlight style you like\ntheme: light: xcode   NexT supports the copy-and-paste functionality of codeblock\ncodeblock: copy_button: enable: true style: mac\t# Mac Panel风格代码块 Back To Top:\nback2top: scrollpercent: true Fonts Customization：\nfont: enable: true host: https://fonts.loli.net global: family: Architects Daughter, Ma Shan Zheng codes: family: Share Tech Mono   host：查看字体与使用字体的网址是不一样的；可能不能查看字体，但可以使用字体\n  查看 Google Fonts，使用 Google Fonts https://fonts.googleapis.com，以下为镜像\n  https://fonts.loli.net\n  https://fonts.googleapis.cnpmjs.org\n  https://fonts.proxy.ustclug.org\n      查看谷歌字体中文版，使用 https://fonts.font.im\n  技巧：先放 latin 文字，再放 chinese 文字，就可以分别定制英文与中文（有些中文字体包含英文字母）。手机无法显示自定义的中文字体，但可以显示自定义的英文字体。\n  SEO\nSEO Setting:\nNext provides useful options for better Search Engine Optimization (SEO).\nBy default a canonical link tag is created in Hexo after you have set up your URL url: http://example.com in site config file.\n# theme config file disable_baidu_transformation: true index_with_subtitle: true exturl: true Webmaster Tools:\n  Google Webmaster Tools\n  Login to Google Webmaster Tools and go to verification methods and choose HTML Tag, you will get some code:\n\u0026lt;meta name=\u0026quot;google-site-verification\u0026quot; content=\u0026quot;XXXXXXXXXXXXXXXXXXXXXXX\u0026quot;\u0026gt;   Copy XXXXXXXXXXXXXXXXXXXXXXX value of content key.Edit theme config file and add or change google_site_verification section:\ngoogle_site_verification: XXXXXXXXXXXXXXXXXXXXXXX   submit sitemap\n  That the new console says \u0026lsquo;couldnt fetch\u0026rsquo; is a bug in the console. Pending is the real status!\n    Bing Webmaster Tools\n  Login to Bing Webmaster Tools and go to verification methods and choose HTML Tag, you will get some code:\n\u0026lt;meta name=\u0026quot;msvalidate.01\u0026quot; content=\u0026quot;XXXXXXXXXXXXXXXXXXXXXXX\u0026quot;\u0026gt;   Copy XXXXXXXXXXXXXXXXXXXXXXX value of content key. Edit theme config file and add or change bing_site_verification section:\nbing_site_verification: XXXXXXXXXXXXXXXXXXXXXXX   submit sitemap\n  Bing 收录最快，立马就可以看到\n    Baidu Webmaster Tools\n  Login to Baidu Webmaster Tools and go to verification methods and choose HTML Tag, you will get some code:\n\u0026lt;meta name=\u0026quot;baidu-site-verification\u0026quot; content=\u0026quot;XXXXXXXXXXXXXXXXXXXXXXX\u0026quot;\u0026gt;   Copy XXXXXXXXXXXXXXXXXXXXXXX value of content key.Edit theme config file and add or change baidu_site_verification section:\nbaidu_site_verification: XXXXXXXXXXXXXXXXXXXXXXX   Push the url to baidu automatically\nbaidu_push: true   submit sitemap\n    Third-party Services Comment Systems\nLiveRe (Korea):\n  Create an account or log into LiveRe, click on the installation button and select the free city version, then click on the install now button.\n  Copy the data-uid field in the installation code to get your LiveRe UID.\n  Add the obtained LiveRe UID to the livere_uid section in the theme config file as following:\nlivere_uid:   Valine (China)：\n  Create an account or log into LeanCloud, and then click on the bottom left corner to create the application in dashboard.\n  Go to the application you just created, select Settings → App Keys in the lower left corner, and you will see your APP ID and APP Key.\n  Edit configurations in valine section in the theme config file as following:\nvaline: enable: true appId: appKey:   评论数据管理：请自行登录Leancloud应用管理。具体步骤：登录\u0026gt;选择你创建的应用\u0026gt;存储\u0026gt;选择Class Comment\n  Statistics and Analytics\nAnalytics Tools:\n  Baidu Analytics (China)\n  Login to Baidu Analytics and locate to site code getting page.\n  Copy the script ID after hm.js?.\n  Edit theme config file and change section baidu_analytics to your script ID.\nbaidu_analytics:     Google Analytics\n  Create an account and log into Google Analytics.\n  Edit theme config file and fill tracking_id under section google_analytics with your Google track ID. Google track ID always starts with UA- (最新版 Google Analytics 是 G-).\ngoogle_analytics: tracking_id: G-XXXXXXXX only_pageview: false     Counting Tools:\nBusuanzi Counting (China), Edit busuanzi_count option in theme config file.\n不蒜子是基于域名来进行统计计算的。数据比百度统计多很多。网络不好的话，数据与图标不一定显示得出来。\nbusuanzi_count: enable: true Search Services\nLocal Search:\nThis search method is recommended for most users.\n  Installation\nnpm install hexo-generator-searchdb   Hexo Config\nsearch: path: search.xml field: post content: true format: html   NexT Config\nlocal_search: enable: true   External Libraries\nPJAX：\n  You can enable it by setting value pjax to true in theme config file.\npjax: true   It listens to every click on links you want (by default all of them).When an internal link is clicked, Pjax fetches the page\u0026rsquo;s HTML via AJAX.\n  Please use the absolute path of the image or Hexo asset_img tag in your posts, otherwise the images may fail to load during Pjax refresh.\n  例子：添加音乐播放器并保持跳转时不中断播放状态；fireworks 特效更流畅，不存在点击链接时的卡顿现象（点击链接时不会触发fireworks）。\n  Fancybox:\nA jQuery lightbox script for displaying images, videos and more.\nfancybox: true Lazyload:\nIt delays loading of images in long web pages. Images outside of viewport will not be loaded before user scrolls to them.\nlazyload: true Progress Bar:\nNProgress will automatically monitor your Ajax requests, event loop lag, document ready state and elements on your page to decide on the progress.\nnprogress: enable: true spinner: false Canvas Ribbon：\ncanvas_ribbon: enable: true size: 300\t# The width of the ribbon. alpha: 0.6\t# The transparency of the ribbon. zIndex: -1\t# The display level of the ribbon. 粒子漂浮聚合：\n该功能由 theme-next-canvas-nest 插件提供：\n  Create a file named footer.njk  in hexo/source/_data directory, Edit this file and add the following content\n\u0026lt;script color=\u0026quot;0,0,255\u0026quot; opacity=\u0026quot;0.5\u0026quot; zIndex=\u0026quot;-1\u0026quot; count=\u0026quot;99\u0026quot; src=\u0026quot;https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;   In the NexT _config.yml, uncomment footer under the custom_file_path section.\ncustom_file_path: footer: source/_data/footer.njk   Tag Plugins Mermaid\n  Settings\nmermaid: enable: true   Usage\n{% mermaid type %} {% endmermaid %}   Advanced Settings Custom Files\n  uncomment under the section in theme config file.stylecustom_file_path。\ncustom_file_path: head: source/_data/head.njk header: source/_data/header.njk ...   Edit in site root directory and add files:source/_data/...。\n  Then use it。\n  Stylus 是 CSS 的预处理框架，给 CSS 添加了可编程的特性。Stylus支持三种注释，单行注释（//)，多行注释(/* */)。\n  Nunjucks 是 jinja2 的 javascript 的实现，可以使用 {# and #} 来写注释，渲染时将会去除所有的注释。\n  不要直接修改 model 文件，而要使用 custom file，方便之后升级。\n  Front Matter\n--- photos: /uploads/png.png --- Misc Settings 想要什么功能可以搜一下，看是否有现成的 model 可以使用。\n网易云音乐\n 在网页版云音乐中找到歌曲，点击生成外链播放器 根据个人喜好选择播放器尺寸和播放模式 将获取到的 iframe 代码添加到页面中  Aplayer 音频播放器\n  借助 hexo-tag-aplayer 插件，可以通过标签的形式方便快捷的插入音频组件。\n  Installation\nnpm install --save hexo-tag-aplayer   Usage\n{% aplayer \u0026quot;title\u0026quot; \u0026quot;author\u0026quot; \u0026quot;url\u0026quot; [\u0026quot;picture_url\u0026quot;, \u0026quot;narrow\u0026quot;, \u0026quot;autoplay\u0026quot;, \u0026quot;width:xxx\u0026quot;, \u0026quot;lrc:xxx\u0026quot;] %}  title: 曲目标题 author: 曲目作者 url: 音乐文件 URL 地址 picture_url: (可选) 音乐对应的图片地址 narrow: （可选）播放器袖珍风格 autoplay: (可选) 自动播放，移动端浏览器暂时不支持此功能 width:xxx: (可选) 播放器宽度 (默认: 100%) lrc:xxx: （可选）歌词文件 URL 地址    当开启 Hexo 的 文章资源文件夹功能时，可直接引用\n{% aplayer \u0026quot;Caffeine\u0026quot; \u0026quot;Jeff Williams\u0026quot; \u0026quot;caffeine.mp3\u0026quot; \u0026quot;picture.jpg\u0026quot; \u0026quot;lrc:caffeine.txt\u0026quot; %}   Dpalyer 视频播放器\n  Installation\nnpm install hexo-tag-dplayer --save   Usage\n{% dplayer \u0026quot;url=video-url\u0026quot; \u0026quot;pic=image-url\u0026quot; ... [\u0026quot;key=value\u0026quot;] %}   部分重要 key\n 播放器  autoplay：是否开启视频自动播放，默认为 fasle loop：是否开启视频循环播放，默认为 false screenshot：是否开启截图，默认为 false mutex：是否禁止多个播放器同时播放，默认为 true dmunlimited：是否开启海量弹幕模式，默认为 false preload：预加载模式，可选 note metadata auto theme：主题色 lang：语言，可选 en zh-cn zh-tw logo：左上角的 Logo volume：默认音量，默认为 0.7 width：播放器宽度 height：播放器长度   视频  url：视频链接 pic：视频封面 thumbnails：视频缩略图，可以使用 DPlayer-thumbnails 生成 vidtype：视频类型，可选 auto hls flv dash 或其他自定义类型   字幕  suburl：字幕链接 subtype：字幕类型，可选 webvtt ass，目前只支持 webvtt subbottom：字幕距离播放器底部的距离，如 10px 10% subcolor：字幕颜色   弹幕  id：弹幕 id api：弹幕 api token：弹幕后端验证 token addition：额外外挂弹幕 dmuser：弹幕用户名 maximum：弹幕最大数量      看板娘\n该功能由 hexo-helper-live2d 插件支持\n  Installation\nnpm install --save hexo-helper-live2d   Config：在站点配置文件中设置，主题配置文件中设置没用\nlive2d: enable: true scriptFrom: local pluginRootPath: live2dw/ pluginJsPath: lib/ pluginModelPath: assets/ tagMode: false log: false model: use: live2d-widget-model-shizuku display: position: right width: 150 height: 300 mobile: show: true react: opacity: 0.7   Models：可以从 hexo live2d 模型预览 里找到你喜欢的角色，然后根据 live2d-widget-models 中提供的方法来下载模型数据.\nnpm install live2d-widget-model-shizuku   Fireworks\n一个鼠标点击动画特效\nnpm install next-theme/hexo-next-fireworks activate-power-mode\n一个为博客添加酷炫打字特效的插件\n  编辑 /hexo-site/source/_data/footer.njk\n\u0026lt;script src=\u0026quot;https://cdn.jsdelivr.net/gh/suyin-long/activate-power-mode@1.0/dist/activate-power-mode.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; POWERMODE.colorful = true; // make power mode colorful POWERMODE.shake = false; // turn off shake document.body.addEventListener('input', POWERMODE); \u0026lt;/script\u0026gt;   取消footer: source/_data/footer.njk的注释\n  搞怪网页标题\n  编辑 /hexo-site/source/_data/head.njk，添加\n{# 搞怪网页标题 #} {% if theme.title_trick.enable %} \u0026lt;script\u0026gt; var OriginTitile = document.title; var titleTime; document.addEventListener(\u0026quot;visibilitychange\u0026quot;, function() { if (document.hidden) { document.title = \u0026quot;{{ theme.title_trick.leave }}\u0026quot;; clearTimeout(titleTime); } else { document.title = \u0026quot;{{ theme.title_trick.enter }}\u0026quot;; titleTime = setTimeout(function() { document.title = OriginTitile; }, 2000); } }); \u0026lt;/script\u0026gt; {% endif %}   在主题配置文件中添加\n# a trick on website title title_trick: enable: true leave: \u0026#34;(つェ⊂)我藏好了哦~\u0026#34; enter: \u0026#34;(*´∇｀*) 被你发现啦~\u0026#34;   我先是放在 sorce/_data/head.njk 中，问题是改变一次标题后就只显示网址。我认为 script 可能在 \u0026lt;title\u0026gt; 之前加载，所以就放在 source/_data/header.njk，正常运行。\n  Hexo NexT Three\n  Install\nnpm install next-theme/hexo-next-three   Configure\n# JavaScript 3D library. # Dependencies: https://github.com/next-theme/hexo-next-three three: enable: true defer: true cdn: waves: enable: false cdn: lines: enable: false cdn: sphere: enable: false cdn:   hexo-cake-moon-menu\n  How to use\nnpm install hexo-cake-moon-menu   Config: In hexo _config.yml\nmoon_menu: back2top: enable: true icon: fas fa-chevron-up func: back2top order: -1 back2bottom: enable: true icon: fas fa-chevron-down func: back2bottom order: -2   permalink\n  默认的文章 url 地址为 http://yoursite.com/:year/:month/:day/:title/，这种 url 格式层级太多，并且如果文章标题是中文的话可能会发生转义而出现一堆乱码，不利于搜索引擎的爬取分析，因此建议在站点配置中修改 permalink 的格式来简化页面 url，并尽量采用英文命名 Markdown 文件。(这个根据个人选择，我认为有更有组织的文件结构更重要)\n  这个 front matter 必须是 html 文件，文件会生成到 public 根目录。\n --- permalink: /post-name.html ---   robots.txt\nrobots.txt（统一小写）是一种存放于网站根目录下的ASCII编码的文本文件，它通常告诉网络搜索引擎的漫游器（又称网络蜘蛛），此网站中的哪些内容是不应被搜索引擎的漫游器获取的，哪些是可以被漫游器获取的。\nrobots.txt在线生成器\nCDN CDN 的全称是(Content Delivery Network)，即内容分发网络。其目的是通过在现有的 Internet 中增加一层新的CACHE(缓存)层，将网站的内容发布到最接近用户的网络“边缘”的节点，使用户可以就近取得所需的内容，提高用户访问网站的响应速度。从技术上全面解决由于网络带宽小、用户访问量大、网点分布不均等原因，提高用户访问网站的响应速度。\nCDN 工作原理 传统访问过程：\n 用户输入访问的域名，操作系统向 LocalDns 查询域名的ip地址 LocalDns 向 ROOT DNS 查询域名的授权服务器（这里假设LocalDns缓存过期） ROOT DNS 将域名授权 dns 记录回应给 LocalDns LocalDns 得到域名的授权 dns 记录后，继续向域名授权 dns 查询域名的 ip 地址 域名授权 dns 查询域名记录后，回应给 LocalDns LocalDns 将得到的域名 ip 地址，回应给用户端 用户得到域名 ip 地址后，访问站点服务器 站点服务器应答请求，将内容返回给客户端  CDN 访问过程：\n 用户输入访问的域名，操作系统向 LocalDns 查询域名的 ip 地址 LocalDns 向 ROOT DNS 查询域名的授权服务器（这里假设LocalDns缓存过期） ROOT DNS 将域名授权 dns 记录回应给 LocalDns LocalDns 得到域名的授权 dns 记录后，继续向域名授权 dns 查询域名的 ip 地址 域名授权 dns 查询域名记录后（一般是CNAME），回应给 LocalDns LocalDns 得到域名记录后，向智能调度 DNS 查询域名的 ip 地址 智能调度 DNS 根据一定的算法和策略，将最适合的 CDN 节点 ip 地址回应给 LocalDns LocalDns 将得到的域名 ip 地址，回应给用户端 用户得到域名 ip 地址后，访问站点服务器 CDN 节点服务器应答请求，将内容返回给客户端  参考 CDN加速原理\nNPM npm makes it easy for JavaScript developers to share and reuse code, and it makes it easy to update the code that you\u0026rsquo;re sharing.\n基本：\n  package.json 和 package-lock.json\n package.json 执行 npm init 命令生成，描述项目模块信息 package-lock.json 执行 npm install 命令生成，描述模块来源及依赖信息，可删除    安装模块：\n  全局安装\nnpm install -g 模块名称   本地安装：读取 package.json 并下载模块到 node_modules 的目录，模块分为两类 dependencies 和devDependencies，分别对应生产环境需要的安装包和开发环境需要的安装包\nnpm install \u0026lt;package_name\u0026gt; # 在安装模块的时候，可以通过指定参数来修改 package.json 文件 npm install \u0026lt;package_name\u0026gt; --save npm install \u0026lt;package_name\u0026gt; --save-dev     更新模块\nnpm update   卸载模块\nnpm uninstall -g \u0026lt;package_name\u0026gt; npm uninstall \u0026lt;package_name\u0026gt; # 卸载模块的同时，也从 package.json 文件中移除 npm uninstall --save \u0026lt;package_name\u0026gt; npm uninstall --save-dev \u0026lt;package_name\u0026gt;   解决问题：\n  Ubuntu 安装最新 LTS 版本：官方教程，Windows 版本更好\nsudo mkdir -p /usr/local/lib/nodejs sudo tar -xJvf node-$VERSION-$DISTRO.tar.xz -C /usr/local/lib/nodejs vi ~/.profile # Nodejs VERSION=v10.15.0 DISTRO=linux-x64 export PATH=/usr/local/lib/nodejs/node-$VERSION-$DISTRO/bin:$PATH . ~/.profile\t# Refresh profile sudo ln -s /usr/local/lib/nodejs/node-$VERSION-$DISTRO/bin/node /usr/bin/node   查看 npm 配置\nnpm config list -l npm config ls   配置镜像：淘宝镜像不好用，特对对于 update\nnpm config set registry https://registry.npmjs.org --global   配置 NPM 不做严格的 SSL 校验\nnpm config set strict-ssl false   npm ERR! Unexpected end of JSON input while parsing near \u0026hellip;\nnpm cache clean --force   npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents：不管\n  npm ERR! code EINTEGRITY\ngrep -ir \u0026quot;sha1-WYr+VHVbKGilMw0q/51Ou1Mgm2U\u0026quot; ~/.npm\t# wanted sha1 npm cache clean --force grep -ir \u0026quot;sha1-WYr+VHVbKGilMw0q/51Ou1Mgm2U\u0026quot; ~/.npm npm install   getaddrinfo EAI_AGAIN registry.npmjs.org：网络问题，重新运行 npm install\n  升级为最新稳定版本的 node.js：超慢\nsudo npm cache clean -f sudo npm install -g n\t# n 是 Node版本管理控制器 sudo n stable   NPM 中文文档\nGreat Blogs yearito ，suyin ，yleao ，dlzhang\nVersion    Name Version     npm 7.0.8   hexo 5.2.0   hexo-theme-next 8.0.2    ","permalink":"https://sakamotokurome.github.io/posts/hexo/","summary":"Hexo Hexo 是一个快速、简洁且高效的博客框架。 安装 安装 Git： Windows: Download \u0026amp; install git. Mac: Install it with Homebrew, MacPorts or installer. Linux (Ubuntu, Debian): sudo apt-get install git-core Linux (Fedora, Red Hat, CentOS): sudo yum install git-core 安装 node.js： Windows: Install it with","title":"Hexo"},{"content":"Workspace：工作区，Index / Stage：暂存区，Repository：仓库区（或本地仓库），Remote：远程仓库\n远程仓库 安装，windows需要处理换行符 sudo yum install git 设置姓名和邮箱地址 git config --global user.name \u0026#34;Vane Hsiung\u0026#34; git config --global user.email \u0026#34;1664548605@qq.com\u0026#34; 提高输出可读性 git config --global color.ui auto 设置文件   显示当前的 Git 配置\ngit config --list cat ~/.giconfig   编辑Git配置文件\ngit config -e [--global]   设置SSH，添加认证密码 ssh-keygen -t rsa -C \u0026#34;1664548605@qq.com\u0026#34; 添加公开密钥 将下面的密钥添加到 GitHub 设置中的 SSH key 中\ncat ~/.ssh/id_rsa.pub 查看是否认证和通信成功 ssh -T git@github.com 获取远程仓库 clone 后默认在 master 分支下自动将 origin 设置为远程仓库标识符\ngit clone SSH 提速：\ngit clone SSH --depth=1 加上 \u0026ndash;depth 会只下载一个 commit，所以内容少了很多，速度也就上去了。\n而且下载下来的内容是可以继续提交新的 commit、创建新的分支的。不影响后续开发，只是不能切换到历史 commit 和历史分支。\n在一些场景下还是比较有用的：当需要切换到历史分支的时候也可以计算需要几个 commit，然后再指定 depth，这样也可以提高速度。\n获取远程非master分支 -b 后是新建分支名称\ngit checkout -b branchName origin/branchName 获取指定分支 使用git拉代码时可以使用 -b 指定分支，拉取 develop 分支代码：\ngit clone -b develop http://gitslab.yiqing.com/declare/about.git 查看当前项目拉的是哪个分支的代码详情：\ngit branch -v 查看分支上的递交情况:\ngit show-branch 获取最新的远程仓库分支 远程仓库拉取代码并合并到本地，可简写为 git pull 等同于 git fetch \u0026amp;\u0026amp; git merge\ngit pull \u0026lt;远程主机名\u0026gt; \u0026lt;远程分支名\u0026gt;:\u0026lt;本地分支名\u0026gt; # 取回远程仓库的变化，并与本地分支合并 git pull origin branchName # 使用rebase的模式进行合并 git pull --rebase \u0026lt;远程主机名\u0026gt; \u0026lt;远程分支名\u0026gt;:\u0026lt;本地分支名\u0026gt; # 获取远程仓库特定分支的更新 git fetch \u0026lt;远程主机名\u0026gt; \u0026lt;分支名\u0026gt; # 获取远程仓库所有分支的更新 git fetch --all 问题：For those who found this searching for an answer to fatal: 'origin/remote-branch-name' is not a commit and a branch 'local-branch-name' cannot be created from it, you may also want to try this first:\ngit fetch --all 与 git pull 不同的是 git fetch 操作仅仅只会拉取远程的更改，不会自动进行 merge 操作。对你当前的代码没有影响。\ngit rebase 让你的提交记录更加清晰可读\nrebase 翻译为变基，他的作用和 merge 很相似，用于把一个分支的修改合并到当前分支上。\n即逐个应用了 mater 分支的更改，然后以 master 分支最后的提交作为基点，再逐个应用 feature 的每个更改。\n大部分情况下，rebase 的过程中会产生冲突的，此时，就需要手动解决冲突，然后使用依次 git add  、git rebase --continue  的方式来处理冲突，完成 rebase 的过程，如果不想要某次 rebase 的结果，那么需要使用 git rebase --skip  来跳过这次 rebase 操作。\ngit merge 和 git rebase 的区别\n不同于 git rebase 的是，git merge 在不是 fast-forward（快速合并）的情况下，会产生一条额外的合并记录，类似 Merge branch 'xxx' into 'xxx' 的一条提交信息。\n另外，在解决冲突的时候，用 merge 只需要解决一次冲突即可，简单粗暴，而用 rebase 的时候 ，需要依次解决每次的冲突，才可以提交。\n同一台电脑配置多个 GItHub 账号 在日常使用 git 作为仓库使用的时候，有时可能会遇到这样的一些情况：\n 有两个 github 账号，一台电脑怎么同时连接这两个账号进行维护呢？ 自己用一个 github 账号，平时用来更新自己的一些资料；公司使用的 gitlab（也是 git 的衍生产品）  如下是解决方案：\n  创建默认 SSH Key\nssh-keygen -t rsa -C \u0026#34;one@example.com\u0026#34;   将公钥添加到 one@example.com 的 GitHub SSH key 中。\n  测试 ssh key 是否成功\nssh -T git@github.com   如果设置过全局，则清除 git 的全局设置\n# 查看当前配置 git config --list # 取消 global user.name user.email git config --global --unset user.name git config --global --unset user.email   生成另外一个账号新的SSH keys\nssh-keygen -t rsa -C \u0026#34;two@example.com\u0026#34; 私钥需重命名，如 id_rsa_two。然后将对应的公钥添加到two@example.com的 Github SSH key 中。\n  需添加新私钥到 SSH agent 中，因为默认只读取 id_rsa\n# Windows 在管理员下运行 Get-Service ssh-agent Set-Service ssh-agent -StartupType Manual Start-Service ssh-agent # Linux eval `ssh-agent -s` # 添加私钥 ssh-add ~/.ssh/id_rsa_new unable to start ssh-agent service\nCould not open a connection to your authentication agent\n  配置 ~/.ssh/config 文件，用于配置私钥对应的服务器\n# Default github user(one@example.com) Host git@github.com HostName github.com User \u0026#34;Your GitHub Account Name\u0026#34; IdentityFile ~/.ssh/id_rsa # another user(two@example.com) # 建一个别名，新建的帐号使用这个别名做克隆和更新 # \u0026#34;Host\u0026#34; 如果带了 \u0026#34;git@\u0026#34;，如 \u0026#34;git@two.github.com\u0026#34;，就会连接到 two.github.com # \u0026#34;Host\u0026#34; 没有带 \u0026#34;git@\u0026#34;，就会正确的连接到 github.com Host two.github.com HostName github.com User \u0026#34;Your GitHub Account Name\u0026#34; IdentityFile ~/.ssh/id_rsa_two 测试\n# default ssh -T git@github.com # another ssh -T git@two.github.com 可能需要重启系统\n$ sudo systemctl reboot   使用\n# default git remote add origin git@github.com:one/demo.git # another git remote add origin git@two.github.com:two/demo.git   设置每个项目的自己的 user.name 和 user.email\ngit config user.email \u0026#34;two@example.com\u0026#34; git config user.name \u0026#34;two\u0026#34;   Git 中 HTTPS 和 SSH 的 Clone 方式区别  HTTPS：不管是谁，拿到url随便clone，但是在push的时候需要验证用户名和密码； SSH：clone的项目你必须是拥有者或者管理员，而且需要在clone前添加SSH Key。SSH 在push的时候，是不需要输入用户名的，如果配置SSH key的时候设置了密码，则需要输入密码的。  本地仓库 初始化仓库 生成 .git 目录, 也就是当前目录的仓库，当前目录称为“附属于该仓库的工作树”\ngit init [project-name] 查看仓库的状态 git status # 显示有变更的文件 向暂存区添加文件   添加指定文件到暂存区\ngit add [file1] [file2] ...   添加指定目录到暂存区，包括子目录\ngit add [dir]   添加当前目录的所有文件到暂存区\ngit add .   删除工作区文件，并且将这次删除放入暂存区\ngit rm [file1] [file2] ...   改名文件，并且将这个改名放入暂存区\ngit mv [file-original] [file-renamed]   原理（git add 为如下两步简写）：\n  为 example.txt 创建一个副本。git hash-object 命令把 example.txt 的当前内容压缩成二进制文件，称为一个 Git 对象，保存在 .git/objects 目录。并计算当前内容的哈希值，前 2 个字符作为目录名，后 38 个字符作为该对象的文件名\ngit hash-object -w example.txt 二进制对象里面会保存一些元数据，如果想看该文件原始的文本内容，需用git cat-file命令\ngit cat-file -p e69de29bb2d1d6434b8b29ae775ad8c2e48c5391   所有变动的文件，Git 都记录在\u0026quot;暂存区\u0026quot;，git update-index 命令用于在暂存区记录一个发生变动的文件\ngit update-index --add --cacheinfo 100644 e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 example.txt git ls-files 命令显示暂存区当前内容\ngit ls-files --stage   查看更改前后的差别 习惯：git commit 前先 git diff HEAD\ngit diff 默认查看工作树和暂存区的差别\nHEAD查看工作树与最新提交的差别，HEAD 为指向当前分支中最新一次提交的指针，HEAD^ 指向 HEAD 的前一个提交，HEAD~6 则是 HEAD 之前的第6个提交。每一个分支都是一个文本文件，保存在 .git/refs/heads/ 目录中，文件的内容是最新提交的哈希值\ngit diff [HEAD] 将暂存区中文件保存到仓库历史记录中 -m 用于记录一行信息；不加 -m 记录详细信息，会新开编辑器进行编辑\n  相当与 git add 与 git commit\ngit commit -am \u0026#34;Message\u0026#34;   提交暂存区的指定文件到仓库区\ngit commit [file1] [file2] ... -m \u0026#34;Message\u0026#34;   提交工作区自上次commit之后的变化，直接到仓库区\ngit commit -a   提交时显示所有diff信息\ngit commit -v   原理（git commit -m \u0026quot;first commit\u0026quot; 为如下两步简写）：\n  git write-tree 命令保存当前的目录结构，生成一个 Git 对象\ngit write-tree   git commit-tree 命令用目录结构 Git 对象生成一个 Git 对象，需添加提交说明，-p 参数用来指定父提交\necho \u0026#34;first commit\u0026#34; | git e5a60f66d9966270c835343d4facc1c4bf44ed7a -p c9053865e9dff393fd2f7a92a18f9bd7f2caa7fa   修改提交信息 产生一个新的提交对象，替换掉上一次提交产生的提交对象\ngit commit --amend -m \u0026#34;Message\u0026#34; 重做上一次 commit，并包括指定文件的新变化\ngit commit --amend [file1] [file2] ... 压缩历史 用于拼错单词等简单的错误，选定当前分支中包含 HEAD（最新提交）在内的 number 个最新历史记录为对象并在编辑器中打开，pick 为合并对象，fixup 为被合并对象，最后 pick 提交信息会保留\ngit rebase -i HEAD~[number] 查看提交日志   --pretty=short 用于只显示第一行简述信息\n  FileName 为文件名或目录名，只显示指定文件的日志\n  -p 用于显示文件的改动\n  --stat 显示 commit 历史，以及每次 commit 发生变更的文件\ngit log [--pretty=short][FileName][-p][--stat] # 显示当前分支的版本历史   查看文件每次提交的diff\ngit log -p FileName   搜索提交历史，根据关键词\ngit log -S [keyword]   显示某个 commit 之后的所有变动，每个commit占据一行\ngit log [tag] HEAD --pretty=format:%s   显示某个 commit 之后的所有变动，其\u0026quot;提交说明\u0026quot;必须符合搜索条件\ngit log [tag] HEAD --grep feature   显示某个文件的版本历史，包括文件改名\ngit log --follow [file] git whatchanged [file]   git log 的运行过程\n 查找 HEAD 指针对应的分支 找到分支的最新提交 找到父节点（前一个提交） 依此类推，显示当前分支的所有提交  查看当前仓库操作日志 git reflog 怎么查看当前的git分支是基于哪个分支创建的\ngit reflog --date=local | grep \u0026lt;branchname\u0026gt;\n类似于如下\n6b3db1f HEAD@{Fri Jul 9 16:05:23 2021}: checkout: moving from development to feature/api_xiongwen_dump 可知 feature/api_xiongwen_dump 基于 development\n从暂存区撤销文件 停止追踪指定文件，但该文件会保留在工作区\ngit rm --cached [filename] 撤销提交 在当前提交后面，新增一次提交，抵消掉上一次提交导致的所有变化\ngit revert HEAD 想抵消多个提交，必须在命令行依次指定这些提交\ngit revert [倒数第一个提交] [倒数第二个提交] 回溯历史版本   重置暂存区的指定文件，与上一次 commit 保持一致，但工作区不变\ngit reset [file]   重置暂存区与工作区，与上一次 commit 保持一致\ngit reset --hard   让最新提交的指针回到以前某个时点，该时点之后的提交都从历史中消失\ngit reset 目标时间点哈希值 # 重置当前分支的指针为指定 commit，同时重置暂存区，但工作区不变   默认情况下，git reset不改变工作区的文件（但会改变暂存区），--hard参数可以让工作区里面的文件也回到以前的状态\ngit reset --hard 目标时间点哈希值 # 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致   重置当前 HEAD 为指定 commit，但保持暂存区和工作区不变\ngit reset --keep [commit]   添加远程仓库 origin 为远程仓库的标识符\ngit remote add origin SSH # 增加一个新的远程仓库，并命名 git remote -v # 显示所有远程仓库 git remote show [remote] # 显示某个远程仓库的信息 推送至远程仓库  推送的是当前分支 -u 在推送的同时将远程仓库的（origin仓库）的 branch 分支设为本地仓库当前分支的 upstream（上游） 运行 git pull 从远程仓库获取内容时，就可以省略参数  git push [-u origin branchName] # 上传本地指定分支到远程仓库 git push --set-upstream origin [branchName] # To push the current branch and set the remote as upstream 如果每次 git push 都需要输入账号和密码\n  首先在 git 工作目录下：\ngit config [--global] credential.helper store   然后执行一次 git pull，这次输入账号和密码之后就不用再输入了。\n  Git push existing repo to a new and different remote repo server? 需求：从公司的账户 clone repo 到本地，添加注释，pull 到自己账户的私有 repo 中。\n Create a new repo at github. git remote rename origin upstream git remote add origin URL_TO_GITHUB_REPO git push origin master  Now you can work with it just like any other github repo. To pull in patches from upstream, simply run git pull upstream master \u0026amp;\u0026amp; git push origin master.\n分支 创建并切换分支 # 切换分支，并更新工作区 git checkout branchName #切换至上一分支 git checkout - # 新建一个分支，并切换到该分支 git checkout -b branchName # 新建本地分支，但不切换 git branch \u0026lt;branch-name\u0026gt; # 新建一个分支，指向指定commit git branch [branch] [commit] # 新建一个分支，与指定的远程分支建立追踪关系 git branch --track [branch] [remote-branch] 以图表形式查看分支 git log --graph 显示分支 # 列出所有本地分支 git branch # 列出所有远程分支 git branch -r # 同时显示本地仓库和远程仓库的分支信息 git branch -a # 用于创建分支 git branch branchName # 本地分支对应哪个远程分支 git branch -vv 合并分支  --no-ff 用于记录本次分支合并 消除冲突：打开冲突的文件，在编辑器中改为想要的样子  git merge [--no-ff] branchName # 合并指定分支到当前分支 git cherry-pick [commit] # 选择一个 commit，合并进当前分支 删除分支   删除分支\n# 删除本地分支 git branch -d [branch-name]   删除远程分支\ngit push origin --delete [branch-name] git branch -dr [remote/branch]   撤销工作区的文件修改   先找暂存区，如果该文件有暂存的版本，则恢复该版本，否则恢复上一次提交的版本\ngit checkout -- [filename]   恢复某个 commit 的指定文件到暂存区和工作区\ngit checkout [commit] [file]   恢复暂存区的所有文件到工作区\ngit checkout .   分支重命名   重命名本地分支：\n  在当前分支时\ngit branch -m new_branch_name   当不在当前分支时\ngit branch -m old_branch_name new_branch_name     重命名远端分支：\n假设是在当前分支，并且远端分支与本地分支名是一致的重命名本地分支\ngit branch -m new_branch_name 删除远程分支\ngit push --delete origin old_branch_name 上传新命名的本地分支\ngit push origin new_branch_name 关联修改后的本地分支与远程分支\ngit branch --set-upstream-to origin/new_branch_name   标签   列出所有 tag\ngit tag   新建一个 tag 在当前commit\ngit tag [tag]   新建一个tag在指定commit\ngit tag [tag] [commit]   删除本地 tag\ngit tag -d [tag]   删除远程 tag\ngit push origin :refs/tags/[tagName]   查看 tag 信息\ngit show [tag]   提交指定 tag\ngit push [remote] [tag]   提交所有tag\ngit push [remote] --tags   新建一个分支，指向某个tag\ngit checkout -b [branch] [tag]   Git Ignore git 为我们提供了一个 .gitignore 文件，只要在这个文件中申明哪些文件你不希望添加到git中去，这样当你使用 git add . 的时候这些文件就会被自动忽略掉。\n经实验，可以为每一个平行非包含的目录设定一个 .gitignore。\nPull Request 当你想更正别人仓库里的错误时，要走一个流程：\n 先 fork 别人的仓库，相当于拷贝一份，相信我，不会有人直接让你改修原仓库的。 clone 到本地分支，做一些 bug fix。 发起 pull request 给原仓库，让他看到你修改的 bug。 原仓库 review 这个 bug，如果是正确的话，就会 merge 到他自己的项目中  至此，整个 pull request 的过程就结束了。\n拉取请求，就是请求对方拉取我本地仓库的 bug fix，合并到对方的 repo 中。以对方的视角来看，我的本地仓库就是一个远程仓库。因为我们是在请求对方做什么，所以要以对方视角来看，即 pull，因为对方可能同意，也可能不同意，所以是请求，即 pull request。\nGitHub Hosts GitHub520 本项目无需安装任何程序，通过修改本地 hosts 文件，试图解决：\n GitHub 访问速度慢的问题 GitHub 项目中的图片显示不出的问题  花 5 分钟时间，让你\u0026quot;爱\u0026quot;上 GitHub。\n# GitHub520 Host Start 140.82.112.26 alive.github.com 140.82.114.25 live.github.com 185.199.108.154 github.githubassets.com 140.82.113.22 central.github.com 185.199.108.133 desktop.githubusercontent.com 185.199.108.153 assets-cdn.github.com 185.199.108.133 camo.githubusercontent.com 185.199.108.133 github.map.fastly.net 199.232.69.194 github.global.ssl.fastly.net 140.82.113.4 gist.github.com 185.199.108.153 github.io 140.82.114.3 github.com 140.82.114.5 api.github.com 185.199.108.133 raw.githubusercontent.com 185.199.108.133 user-images.githubusercontent.com 185.199.108.133 favicons.githubusercontent.com 185.199.108.133 avatars5.githubusercontent.com 185.199.108.133 avatars4.githubusercontent.com 185.199.108.133 avatars3.githubusercontent.com 185.199.108.133 avatars2.githubusercontent.com 185.199.108.133 avatars1.githubusercontent.com 185.199.108.133 avatars0.githubusercontent.com 185.199.108.133 avatars.githubusercontent.com 140.82.112.10 codeload.github.com 52.216.170.203 github-cloud.s3.amazonaws.com 52.217.98.76 github-com.s3.amazonaws.com 52.216.164.3 github-production-release-asset-2e65be.s3.amazonaws.com 52.216.160.147 github-production-user-asset-6210df.s3.amazonaws.com 52.217.103.12 github-production-repository-file-5c1aeb.s3.amazonaws.com 185.199.108.153 githubstatus.com 64.71.168.201 github.community 185.199.108.133 media.githubusercontent.com # Update time: 2021-07-04T08:07:49+08:00 # Star me GitHub url: https://github.com/521xueweihan/GitHub520 # GitHub520 Host End GitHub Pages 使用 GitHub GitHub Pages 是一项静态站点托管服务，它直接从 GitHub 上的仓库获取 HTML、CSS 和 JavaScript 文件，（可选）通过构建过程运行文件，然后发布网站。\n有三种类型的 GitHub Pages 站点：项目、用户和组织。 项目站点连接到 GitHub 上托管的特定项目。 用户和组织站点连接到特定的 GitHub 帐户。\nTo publish a user site, you must create a repository owned by your user account that\u0026rsquo;s named \u0026lt;username.github.io\u0026gt;. Repositories using the legacy \u0026lt;username.github.com\u0026gt; naming scheme will still be published, but visitors will be redirected from http(s)://\u0026lt;username.github.com\u0026gt; to http(s)://\u0026lt;username.github.io. If both a \u0026lt;username.github.com\u0026gt; and \u0026lt;username.github.io\u0026gt; repository exist, only the \u0026lt;username.github.io\u0026gt; repository will be published.\nGitHub Pages sites are publicly available on the internet, even if the repository for the site is private or internal. 如果站点的仓库中有敏感数据，您可能想要在发布前删除它。\nGitHub Pages 站点的发布来源是存储站点源文件的分支和文件夹。用户和组织站点的默认发布源是仓库默认分支的根目录。 项目站点的默认发布来源是 gh-pages 分支的根目录。\n您可以创建自己的静态文件或使用静态站点生成器为您构建站点。默认情况下，GitHub Pages 将使用 Jekyll 来构建您的站点。\nGitHub Pages 站点受到以下使用限制的约束：\n GitHub Pages source repositories have a recommended limit of 1GB. 发布的 GitHub Pages 站点不得超过 1 GB。 GitHub Pages sites have a soft bandwidth limit of 100GB per month. GitHub Pages sites have a soft limit of 10 builds per hour.  可在 Repository 的 Settings 中配置 GitHub Pages 站点的发布源或取消发布 GitHub Pages 站点。\n使用 jekyll Github Docs 与 Jekyll 文档不一致，Windows 并未正式支持 Jekyll。\n使用 Hexo 我选择 Hexo，一个是安装简单；一个是文档好。\nGitHub Actions GitHub Actions 是什么 持续集成由很多操作组成，比如自动抓取代码、运行测试、登录远程服务器、发布到第三方服务等。GitHub 把这些操作就称为 actions。\n很多操作在不同项目里面是类似的，可以共享。GitHub 允许开发者把每个操作写成独立的脚本文件，存放到代码仓库，使得其他开发者可以引用。\n可在官方市场与 awesome actions 找 action。\nworkflow 文件 GitHub Actions 的配置文件叫做 workflow 文件，存放在代码仓库的 .github/workflows 目录。\nworkflow 文件采用 YAML 格式，一个库可以有多个 workflow 文件。GitHub 发现 .github/workflows 目录里有 .yml 文件，就会自动运行该文件。\n配置字段：\n  name：工作流程的名称。如果省略 name，GitHub 将其设置为相对于仓库根目录的工作流程文件路径\n  on：必要，触发工作流程的 GitHub 事件的名称\non: [push, pull_request]   on.\u0026lt;push|pull_request\u0026gt;.\u0026lt;branches|tags\u0026gt;：您可以将工作流配置为在特定分支或标记上运行\non: push: branches: - main - \u0026#39;mona/octocat\u0026#39; - \u0026#39;releases/**\u0026#39; tags: - v1 - v1.*    jobs：工作流程运行包括一项或多项作业。每项作业必须关联一个 ID\n  jobs.\u0026lt;job_id\u0026gt;.name：job_id 里面的 name 字段是任务的说明\njobs: my_first_job: name: My first job my_second_job: name: My second job   jobs.\u0026lt;job_id\u0026gt;.needs：作业默认是并行运行。needs字段指定当前任务的运行顺序\njobs: job1: job2: needs: job1 job3: needs: [job1, job2] 此例中作业执行顺序：job1、job2、job3\n  jobs.\u0026lt;job_id\u0026gt;.runs-on：必需，运行作业的机器类型\nruns-on: ubuntu-latest     jobs.\u0026lt;job_id\u0026gt;.steps：作业包含一系列任务，称为 steps\n  jobs.\u0026lt;job_id\u0026gt;.steps.name：步骤名称\n  jobs.\u0026lt;job_id\u0026gt;.steps.uses：引用的 Actions\nsteps: # Reference a specific commit - uses: actions/setup-node@74bc508 # Reference a minor version of a release - uses: actions/setup-node@v1.2 # Reference a branch - uses: actions/setup-node@main   jobs.\u0026lt;job_id\u0026gt;.steps.run：使用操作系统 shell 运行命令行程序\n- name: Clean install dependencies and build run: |npm ci npm run build     参考 GitHub Actions 入门教程\nGitHub Actions\n持续集成（Continuous integration，简称CI） 概念 持续集成指的是，频繁地（一天多次）将代码合并（集成）到主干源码仓库。在 CI 中可以通过自动化等手段高频率地去获取产品反馈并响应反馈的过程。\n流程  提交：开发者向代码仓库提交代码 测试（第一轮）：代码仓库对提交的代码跑自动化测试  单元测试：针对函数或模块的测试 集成测试：针对整体产品的某个功能的测试，又称功能测试 端对端测试：从用户界面直达数据库的全链路测试   构建：将源码转换为可以运行的实际代码，会安装依赖，配置各种资源等。常用的构建工具如下  Jenkins：开源 Travis Codeship Strider：开源   测试（第二轮）：第二轮是全面测试 部署：直接部署 回滚：当前版本发生问题，回滚到上一个版本的构建结果  Commit message 社区有多种 Commit Message Conventions。本文介绍 Angular 规范。\n格式化的 Commit message 好处   提供更多的历史信息，方便浏览\ngit log HEAD --pretty=format:%s   可以过滤某些 commit，便于查找信息\ngit log HEAD --grep feature   可以直接从 commit 生成 Change Log\n  Commit message 的格式 \u0026lt;type\u0026gt;(\u0026lt;scope\u0026gt;): \u0026lt;subject\u0026gt; // 空一行 \u0026lt;body\u0026gt; // 空一行 \u0026lt;footer\u0026gt;   Header 只有一行\n type 用于说明 commit 的类别  feat：新功能 fix：修补bug docs：文档 style： 格式 refactor：重构 test：增加测试 chore：构建过程或辅助工具的变动 Revert：当前 commit 用于撤销以前的 commit   scope 用于说明 commit 影响的范围 subject 是 commit 目的的简短描述  以动词开头，使用第一人称现在时 第一个字母小写 结尾不加句号      Body 部分是对本次 commit 的详细描述\n  Footer\n  不兼容变动：如果当前代码与上一个版本不兼容，则以 BREAKING CHANGE 开头，后面是对变动的描述、以及变动理由和迁移方法\n  关闭 Issue：如果当前 commit 针对某个issue，那么可以在 Footer 部分关闭这个 issue\nCloses #123, #245, #992     Commitizen Commitizen 是一个撰写 Commit message 的工具\n  Install the Commitizen cli tools\nnpm install commitizen -g   Initialize your project to use the cz-conventional-changelog adapter\ncommitizen init cz-conventional-changelog --save-dev --save-exact   以后，凡是用到 git commit 命令，一律改为使用 git cz。\n  参考 Commit message 和 Change log 编写指南\nYAML（YAML Ain\u0026rsquo;t a Markup Language） YAML 是专门用来写配置文件的语言\n简介 规则：\n 大小写敏感 使用缩进表示层级关系 缩进时不允许使用 Tab 键，只允许使用空格。 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可 # 表示注释，从这个字符一直到行尾，都会被解析器忽略 对象和数组可以结合使用，形成复合结构  对象 一组键值对\nanimal: pets 行内表示法\nhash: { name: Steve, foo: bar }  数组 一组连词线开头的行\n- Cat - Dog - Goldfish 数据结构的子成员是一个数组，则可以在该项下面缩进一个空格\n- - Cat - Dog - Goldfish 行内表示法\nanimal: [Cat, Dog] 纯量   字符串：字符串默认不使用引号表示\nstr: 这是一行字符串 包含空格或特殊字符，需要放在引号之中，单引号和双引号都可以使用，双引号不会对特殊字符转义\nstr: \u0026#39;内容： 字符串\u0026#39; 单引号之中如果还有单引号，必须连续使用两个单引号转义\nstr: \u0026#39;labor\u0026#39;\u0026#39;s day\u0026#39; 字符串可以写成多行，从第二行开始，必须有一个单空格缩进。换行符会被转为空格\nstr: 这是一段 多行 字符串 多行字符串可以使用|保留换行符，也可以使用\u0026gt;折叠换行\nthis: |Foo Bar that: \u0026gt;Foo Bar +表示保留文字块末尾的换行，-表示删除字符串末尾的换行\ns1: | Foo s2: |+ Foo s3: |- Foo\n  字符串之中可以插入 HTML 标记 ```yaml message: | \u0026lt;p style=\u0026quot;color: red\u0026quot;\u0026gt; 段落 \u0026lt;/p\u0026gt; 参考 YAML 语言教程\nThe Official YAML Web Site\n开源许可证 一般情况下，软件的源代码只由编写者拥有，而开源（即开放源代码，Open Source Code）是指一种更自由的软件发布模式。简单来说，开源软件的特点就是把软件程序和源代码文件一起打包提供给用户，让用户在不受限制地使用某个软件功能的基础上还可以对代码按需修改，让软件更贴合硬件环境，让功能更符合工作需求。用户还可以将其编制成衍生产品再发布出去。用户一般享有使用自由、复制自由、修改自由、创建衍生品自由，以及收费自由。是的，您没有看错，用户具备创建衍生品和收费的自由。这也就是说，可以对一个开源软件进行深度定制化加工。如果修改过的程序更加好用，或者颇具新的特色，只要符合原作者的许可要求，我们就完全可以合法地将软件进行商标注册，以商业版的形式再发布出去，只要有新用户使用您的软件并支付相应的费用，那就是您的收入。这也正好符合了黑客和极客对自由的追求，因此在合作与竞争中，国内外的开源社区慢慢生长出了强健的根基，人气也非常高。\n但是，如果开源软件只单纯追求“自由”而牺牲了程序员的利益，这肯定会影响程序员的创作热情。为了平衡两者的关系，截至目前，世界上已经有100多种被开源促进组织（OSI，Open Source Initiative）确认的开源许可证，用于保护开源工作者的权益。对于那些只知道一味抄袭、篡改、破解或者盗版他人作品的不法之徒，终归会在某一天收到法院的传票。\n考虑到大家没准儿以后会以开源工作者的身份编写出一款畅销软件，因此刘遄老师根据开源促进组织的推荐建议以及实际使用情况，为大家筛选出了程序员最喜欢的前6名的开源许可证，并教大家怎么从中进行选择。提前了解最热门的开源许可证，并在未来选择一个合适的可最大程度地保护自己软件权益的开源许可证，这对创业公司来讲能起到事半功倍的作用。\n开源许可证总览：https://opensource.org/licenses/alphabetical\nTips：上述提到的“开源许可证”与“开源许可协议”的含义完全相同，只不过是英文翻译后两种不同的叫法，这里不作区别。\nTips：自由软件基金会（Free Software Foundation，FSF）是一个非营利组织，其使命是在全球范围内促进计算机用户的自由，捍卫所有软件用户的权利。\n大家经常会在开源社区中看到Copyleft这个单词，这是一个由自由软件运动所发展出的概念，中文被翻译为“著佐权”或者“公共版权”。与Copyright截然相反，Copyleft不会限制使用者复制、修改或再发布软件。\n此外，大家应该经常会听到别人说开源软件是free的，没错，开源软件就是自由的。这里的free千万不要翻译成“免费”，这样就大错特错了，这与您去酒吧看到的“第一杯免费”的意思可相差甚远。\n下面我们来看一下程序员最喜欢的前6名的开源许可证，以及它们各自赋予用户的权利。\nGPL **GNU通用公共许可证（**General Public License，GPL）：目前广泛使用的开源软件许可协议之一，用户享有运行、学习、共享和修改软件的自由。GPL最初是自由软件基金会创始人Richard Stallman起草的，其版本目前已经发展到了第3版。GPL的目的是保证程序员在开源社区中所做的工作对整个世界是有益的，所开发的软件也是自由的，并极力避免开源软件被私有化以及被无良软件公司所剥削。\n现在，只要软件中包含了遵循GPL许可证的产品或代码，该软件就必须开源、免费，因此这个许可证并不适合商业收费软件。遵循该许可证的开源软件数量极其庞大，包括Linux内核在内的大多数的开源软件都是基于GPL许可证的。GPL赋予了用户著名的五大自由。\n **使用自由：**允许用户根据需要自由使用这个软件。\n**复制自由：**允许把软件复制到任何人的计算机中，并且不限制复制的数量。\n**修改自由：**允许开发人员增加或删除软件的功能，但软件修改后必须依然基于GPL许可证。\n**衍生自由：**允许用户深度定制化软件后，为软件注册自己的新商标，再发行衍生品的自由。\n**收费自由：**允许在各种媒介上出售该软件，但必须提前让买家知道这个软件是可以免费获得的。因此，一般来讲，开源软件都是通过为用户提供有偿服务的形式来营利的。\n LGPL 较宽松通用公共许可证（Lesser GPL, LGPL）：一个主要为保护类库权益而设计的GPL开源协议。与标准GPL许可证相比，LGPL允许商业软件以类库引用的方式使用开源代码，而不用将其产品整体开源，因此普遍被商业软件用来引用类库代码。简单来说，就是针对使用了基于LGPL许可证的开源代码，在涉及这部分代码，以及修改过或者衍生出来的代码时，都必须继续采用LGPL协议，除此以外的其他代码则不强制要求。\n如果您觉得LGPL许可证更多地是关注对类库文件的保护，而不是软件整体，那就对了。因为该许可证最早的名字是Library GPL，即GPL类库开源许可证，保护的对象有glibc、GTK widget toolkit等类库文件。\nBSD **伯克利软件发布版（**Berkeley Software Distribution, BSD）许可证：另一款被广泛使用的开源软件许可协议。相较于GPL许可证，BSD更加宽松，适合于商业用途。用户可以使用、修改和重新发布遵循该许可证的软件，并且可以将软件作为商业软件发布和销售，前提是需要满足下面3个条件。\n 如果再发布的软件中包含开源代码，则源代码必须继续遵循BSD许可证。\n如果再发布的软件中只有二进制程序，则需要在相关文档或版权文件中声明原始代码遵循了BSD许可证。\n不允许用原始软件的名字、作者名字或机构名称进行市场推广。\n Apache Apache许可证（Apache License）：顾名思义，是由Apache软件基金会负责发布和维护的开源许可协议。作为当今世界上最大的开源基金会，Apache不仅因此协议而出名，还因市场占有率第一的Web服务器软件而享誉行业。目前使用最广泛的Apache许可证是2004年发行的2.0版本，它在为开发人员提供版权及专利许可的同时，还允许用户拥有修改代码及再发布的自由。该许可证非常适合用于商业软件，现在热门的Hadoop、Apache HTTP Server、MongoDB等项目都是基于该许可证研发的。程序开发人员在开发遵循该许可证的软件时，要严格遵守下面4个条件。\n 该软件及其衍生品必须继续使用Apache许可证。\n如果修改了程序源代码，需要在文档中进行声明。\n若软件是基于他人的源代码编写而成的，则需要保留原始代码的许可证、商标、专利声明及原作者声明的其他内容信息。\n如果再发布的软件中有声明文件，则需在此文件中注明基于了Apache许可证及其他许可证。\n MIT MIT许可证（Massachusetts Institute of Technology License）：源于麻省理工学院，又称为X11协议。MIT许可证是目前限制最少的开源许可证之一，用户可以使用、复制、修改、再发布软件，而且只要在修改后的软件源代码中保留原作者的许可信息即可，因此普遍被商业软件（例如jQuery与Node.js）所使用。也就是说，MIT许可证宽松到一个新境界，即用户只要在代码中声明了MIT许可证和版权信息，就可以去做任何事情，而无须承担任何责任。\nMPL **Mozilla公共许可证（**Mozilla Public License，MPL）：于1998年初由Netscape公司的Mozilla小组设计，原因是它们认为GPL和BSD许可证不能很好地解决开发人员对源代码的需求和收益之间的平衡关系，因此便将这两个协议进行融合，形成了MPL。2012年年初，Mozilla基金会发布了MPL 2.0版本（目前为止也是最新的版本），后续被用在Firefox、Thunderbird等诸多产品上。最新版的MPL公共许可证有以下特点。\n 在使用基于MPL许可证的源代码时，后续只需要继续开源这部分特定代码即可，新研发的软件不用完全被该许可证控制。\n开发人员可以将基于MPL、GPL、BSD等多种许可证的代码一起混合使用。\n开发人员在发布新软件时，必须附带一个专门用于说明该程序的文件，内容要有原始代码的修改时间和修改方式。\n 总结 估计大家在看完上面琳琅满目的许可证后，会心生怨念：“这不都差不多吗？到底该选哪个呢？”写到这里时，刘遄老师也是一脸无助：“到底该怎么让大家进行选择呢？”搜肠刮肚之际突然眼前一亮，乌克兰程序员Paul Bagwell创作的一幅流程图正好对刚才讲过的这6款开源许可证进行了汇总归纳，具体如下图所示。\n开源许可证的选择流程图\n众所周知，绝大部分的开源软件在安装完毕之后即可使用，很难在软件界面中找到相关的收费信息。所以经常会有同学提问：“刘老师，开源社区的程序员总要吃饭的呀，他们是靠什么营利呢？”针对这个问题，网络上好像只有两种声音：\n **情怀——**开源社区的程序员觉悟好，本领强，写代码纯粹是为了兴趣以及造福社会；\n**服务——**先让用户把软件安装上，等用好、用习惯之后，再通过提供一些维护服务来营利。\n 这两种解释都各有道理，但是不够全面。读者也不要把开源软件和商业软件完全对立起来，因为好的项目也需要好的运营模式。就开源软件来讲，营利模式具体包括以下5种。\n 多条产品线：如MySQL数据库便有个人版和企业版两个版本，即个人版完全免费，起到了很好的推广作用；企业版则通过销售授权许可来营利。\n技术服务型：JBoss应用服务器便是典型代表，JBoss软件可自由免费使用，软件提供方通过技术文档、培训课程以及定制开发服务来盈利。\n软硬件结合：比如IBM公司在出售服务器时，一般会为用户捆绑销售AIX或Linux系统来确保硬件设施的营利。\n技术出版物：比如O\u0026rsquo;Reilly既是一家开源公司，也是一家出版商，诸多优秀图书都是由O\u0026rsquo;Reilly出版的。\n品牌和口碑：微软公司曾多次表示支持开源社区。大家对此可能会感到意外，但这是真的！Visual Studio Code、PowerShell、TypeScript等软件均已开源。大家是不是瞬间就对微软公司好感倍增了呢？买一份正版系统表示支持也就是人之常情了。\n SSH 原理与运用 数字签名与数字证书 鲍勃有两把钥匙，一把是公钥，另一把是私钥。\n鲍勃把公钥送给他的朋友们——帕蒂、道格、苏珊——每人一把。\n苏珊要给鲍勃写一封保密的信。她写完后用鲍勃的公钥加密，就可以达到保密的效果。\n鲍勃收信后，用私钥解密，就看到了信件内容。只要鲍勃的私钥不泄露，这封信就是安全的，即使落在别人手里，也无法解密。\n鲍勃给苏珊回信，决定采用\u0026quot;数字签名\u0026quot;。他写完后先用Hash函数，生成信件的摘要（digest）。\n然后，鲍勃使用私钥，对这个摘要加密，生成\u0026quot;数字签名\u0026quot;（signature）。\n鲍勃将这个签名，附在信件下面，一起发给苏珊。\n苏珊收信后，取下数字签名，用鲍勃的公钥解密，得到信件的摘要。由此证明，这封信确实是鲍勃发出的。\n苏珊再对信件本身使用Hash函数，将得到的结果，与上一步得到的摘要进行对比。如果两者一致，就证明这封信未被修改过。\n复杂的情况出现了。道格想欺骗苏珊，他偷偷使用了苏珊的电脑，用自己的公钥换走了鲍勃的公钥。此时，苏珊实际拥有的是道格的公钥，但是还以为这是鲍勃的公钥。因此，道格就可以冒充鲍勃，用自己的私钥做成\u0026quot;数字签名\u0026quot;，写信给苏珊，让苏珊用假的鲍勃公钥进行解密。\n后来，苏珊感觉不对劲，发现自己无法确定公钥是否真的属于鲍勃。她想到了一个办法，要求鲍勃去找\u0026quot;证书中心\u0026quot;（certificate authority，简称CA），为公钥做认证。证书中心用自己的私钥，对鲍勃的公钥和一些相关信息一起加密，生成\u0026quot;数字证书\u0026quot;（Digital Certificate）。\n鲍勃拿到数字证书以后，就可以放心了。以后再给苏珊写信，只要在签名的同时，再附上数字证书就行了。\n苏珊收信后，用CA的公钥解开数字证书，就可以拿到鲍勃真实的公钥了，然后就能证明\u0026quot;数字签名\u0026quot;是否真的是鲍勃签的。\n远程登录   1995年，芬兰学者 Tatu Ylonen 设计了 SSH 协议，用于计算机之间的加密登录。本文针对的实现是 OpenSSH。\n  基本用法：\n  假定你要以用户名 user，登录远程主机 host\nssh user@host   如果本地用户名与远程用户名一致，登录时可以省略用户名\nssh host   SSH 的默认端口是 22，使用 p 参数修这个端口\nssh -p 2222 user@host     中间人攻击（Man-in-the-middle attack）\n  SSH 加密登录过程\n 远程主机收到用户的登录请求，把自己的公钥发给用户。 用户使用这个公钥，将登录密码加密后，发送给远程主机。 远程主机用自己的私钥，解密登录密码，如果密码正确，就同意用户登录。      中间人攻击：攻击者插在用户与远程主机之间，用伪造的公钥，获取用户的登录密码，再用这个密码登录远程主机。\n  口令登录：第一次登录远程主机时，会询问是否接受远程主机公钥（是否继续连接），并显示公钥指纹——公钥长度较长（这里采用RSA算法，长达 1024 位），很难比对，所以对其进行MD5计算，将它变成一个 128 位的指纹。用户通过比对远程网站上贴出的公钥指纹，决定是否接受这个远程主机的公钥。当远程主机的公钥被接受以后，它就会被保存在文件 $HOME/.ssh/known_hosts 之中。\n  公钥登录：省去口令登录每次都必须输入密码的步骤。用户将自己的公钥储存在远程主机上，登录的时候，远程主机会向用户发送一段随机字符串，用户用自己的私钥加密后，再发回来，远程主机用事先储存的公钥进行解密，如果成功，就证明用户是可信的，直接允许登录shell，不再要求密码。\n  ssh-keygen\n在 $HOME/.ssh/ 目录下生成两个文件：公钥 id_rsa.pub 和私钥 id_rsa。\n    远程操作与端口转发   SSH 可以在用户和远程主机之间，建立命令和数据的传输通道\n  绑定本地端口：让那些不加密的网络连接，全部改走 SSH 连接\nssh -D 8080 user@host 建立一个 socket，去监听本地的 8080 端口。一旦有数据传向那个端口，就自动把它转移到 SSH 连接上面，发往远程主机。\n  本地端口转发：假定 host1 是本地主机，host2 是远程主机。由于种种原因，这两台主机之间无法连通。但是，另外还有一台 host3，可以同时连通前面两台主机。因此，很自然的想法就是，通过 host3，将 host1 连上 host2。\nssh -L 2121:host2:21 host3 L 参数接受三个值——\u0026ldquo;本地端口:目标主机:目标主机端口\u0026rdquo;。SSH 绑定本地端口 2121，指定 host3 将所有的数据转发到目标主机 host2 的 21 端口。本地端口转发使得 host1 和 host3 之间仿佛形成一个数据传输的秘密隧道，因此又被称为\u0026quot;SSH 隧道\u0026quot;。\n  远程端口转发：host1 与 host2 之间无法连通，必须借助 host3 转发，而 host3 是一台内网机器，它可以连接外网的 host1，但是反过来就不行。解决办法是从 host3 上建立与 host1 的 SSH 连接，然后在 host1 上使用这条连接。在 host3 执行下面的命令\nssh -R 2121:host2:21 host1 R 参数也是接受三个值——\u0026ldquo;远程主机端口:目标主机:目标主机端口\u0026rdquo;。它让 host1 监听它自己的 2121 端口，然后将所有数据经由 host3，转发到 host2 的 21 端口。\n  GitHub Packages Learn to safely publish and consume packages, store your packages alongside your code, and share your packages privately with your team or publicly with the open source community. You can also automate your packages with GitHub Actions.\nTip \u0026amp; Questions Repository size limits for GitHub.com Hard limits:\n Individual files in a repository are strictly limited to a 100 MB maximum size limit. Repositories have a hard size limit of 100GB.  解决SSH自动断线问题 在连接远程SSH服务的时候，经常会发生长时间后的断线，或者无响应（无法再键盘输入）。 总体来说有两个方法：\n一、客户端定时发送心跳\nputty、SecureCRT、XShell都有这个功能，设置请自行搜索\n此外在Linux下：\n  修改本机/etc/ssh/ssh_config\n# vim /etc/ssh/ssh_config   添加\nServerAliveInterval 30 ServerAliveCountMax 100 即每隔30秒，向服务器发出一次心跳。若超过100次请求，都没有发送成功，则会主动断开与服务器端的连接。\n  二、服务器端定时向客户端发送心跳（一劳永逸）\n  修改服务器端 ssh配置 /etc/ssh/sshd_config\n# vim /etc/ssh/sshd_config   添加\nClientAliveInterval 30 ClientAliveCountMax 6 ClientAliveInterval表示每隔多少秒，服务器端向客户端发送心跳，是的，你没看错。\n下面的ClientAliveInterval表示上述多少次心跳无响应之后，会认为Client已经断开。\n所以，总共允许无响应的时间是60*3=180秒。\n  new mode 100755 出现\n$ git diff filename old mode 100644 new mode 100755 但是文件内容并没有发生改变\n产生这个问题的原因就是：filemode的变化，文件chmod后其文件某些位是改变了的，如果严格的比较原文件和chmod后的文件，两者是有区别的，但是源代码通常只关心文本内容，因此chmod产生的变化应该忽略，所以设置一下：\n$ git config --add core.filemode false Check if pull needed in Git First use git remote update, to bring your remote refs up to date. Then you can do one of several things, such as:\n git status -uno will tell you whether the branch you are tracking is ahead, behind or has diverged. If it says nothing, the local and remote are the same. git show-branch *master will show you the commits in all of the branches whose names end in \u0026lsquo;master\u0026rsquo; (eg master and origin/master).  If you use -v with git remote update (git remote -v update) you can see which branches got updated, so you don\u0026rsquo;t really need any further commands.\nHowever, it looks like you want to do this in a script or program and end up with a true/false value. If so, there are ways to check the relationship between your current HEAD commit and the head of the branch you\u0026rsquo;re tracking, although since there are four possible outcomes you can\u0026rsquo;t reduce it to a yes/no answer. However, if you\u0026rsquo;re prepared to do a pull --rebase then you can treat \u0026ldquo;local is behind\u0026rdquo; and \u0026ldquo;local has diverged\u0026rdquo; as \u0026ldquo;need to pull\u0026rdquo;, and the other two (\u0026ldquo;local is ahead\u0026rdquo; and \u0026ldquo;same\u0026rdquo;) as \u0026ldquo;don\u0026rsquo;t need to pull\u0026rdquo;.\nYou can get the commit id of any ref using git rev-parse \u0026lt;ref\u0026gt;, so you can do this for master and origin/master and compare them. If they\u0026rsquo;re equal, the branches are the same. If they\u0026rsquo;re unequal, you want to know which is ahead of the other. Using git merge-base master origin/master will tell you the common ancestor of both branches, and if they haven\u0026rsquo;t diverged this will be the same as one or the other. If you get three different ids, the branches have diverged.\nTo do this properly, eg in a script, you need to be able to refer to the current branch, and the remote branch it\u0026rsquo;s tracking. The bash prompt-setting function in /etc/bash_completion.d has some useful code for getting branch names. However, you probably don\u0026rsquo;t actually need to get the names. Git has some neat shorthands for referring to branches and commits (as documented in git rev-parse --help). In particular, you can use @ for the current branch (assuming you\u0026rsquo;re not in a detached-head state) and @{u} for its upstream branch (eg origin/master). So git merge-base @ @{u} will return the (hash of the) commit at which the current branch and its upstream diverge and git rev-parse @ and git rev-parse @{u} will give you the hashes of the two tips. This can be summarized in the following script:\n#!/bin/sh  UPSTREAM=${1:-\u0026#39;@{u}\u0026#39;} LOCAL=$(git rev-parse @) REMOTE=$(git rev-parse \u0026#34;$UPSTREAM\u0026#34;) BASE=$(git merge-base @ \u0026#34;$UPSTREAM\u0026#34;) if [ $LOCAL = $REMOTE ]; then echo \u0026#34;Up-to-date\u0026#34; elif [ $LOCAL = $BASE ]; then echo \u0026#34;Need to pull\u0026#34; elif [ $REMOTE = $BASE ]; then echo \u0026#34;Need to push\u0026#34; else echo \u0026#34;Diverged\u0026#34; fi Note: older versions of git didn\u0026rsquo;t allow @ on its own, so you may have to use @{0} instead.\nThe line UPSTREAM=${1:-'@{u}'} allows you optionally to pass an upstream branch explicitly, in case you want to check against a different remote branch than the one configured for the current branch. This would typically be of the form remotename/branchname. If no parameter is given, the value defaults to @{u}.\nThe script assumes that you\u0026rsquo;ve done a git fetch or git remote update first, to bring the tracking branches up to date. I didn\u0026rsquo;t build this into the script because it\u0026rsquo;s more flexible to be able to do the fetching and the comparing as separate operations, for example if you want to compare without fetching because you already fetched recently.\nSetting the default editor for Git Pick one:\n  Set core.editor in your Git config:\ngit config --global core.editor \u0026#34;vim\u0026#34;   Set the GIT_EDITOR environment variable:\nexport GIT_EDITOR=vim   解决代码提交的冲突 更新时间：2022-07-01 GMT+08:00\n什么是代码提交冲突？ 在多人团队使用代码托管服务时，不可避免的会出现两个人同时修改了一个文件的情况，这时在推送（push）代码到代码托管仓库时就会出现代码提交冲突并推送失败，如下图就是因为本地仓库与远程仓库文件修改的冲突所产生的推送失败。\n说明：\n  不同版本的Git、不同编译工具的Git插件所返回提示的内容不完全一致，但所表达的意思基本一致。\n  只要在返回提示的内容中解读出，推送失败、另一个仓库成员，两个信息，一般即为产生了提交冲突。\n  Git在文件合并时是比较智能的，对于同一个文件不同位置的修改内容会自动合并，只有在同一个文件同一个位置被同时修改时（本地仓与远程仓的当前版本有差异），才会产生冲突。\n  在分支合并时，有时也会产生冲突，这时的判定方式与解决办法与提交远程仓库时的冲突基本一样，如下图是本地分支branch1向master分支合并时产生了冲突（file01文件的修改冲突了）。\n  如何解决代码提交冲突？ 当代码提交冲突产生时，我们可以将远程代码仓库拉取（pull）到本地仓库的工作区，这时Git会将可以合并的修改内容进行合并，并将不能合并的文件内容进行提示，开发者只需要对提示的冲突内容进行修改即可再次推送到远程仓库（add → commit → push）,这时冲突就解决完毕了。\n如下图所示，在做拉取（pull）操作时，Git提示您，一个文件合并时产生了冲突。\n当然在修改冲突文件时应该考虑清楚，必要时要与冲突方联系协商解决，避免覆盖他人代码。\n**说明：**git pull可以理解为 git fetch 的操作 + git merge的操作，其详细说明如下：\ngit fetch origin master #从远程主机的master分支拉取最新内容  git merge FETCH_HEAD #将拉取下来的最新内容合并到当前所在的分支中  在merge的时候，会将有冲突不能合并的内容做出提示。\n示例：冲突的产生与解决 下面我们来模拟一个情景来帮助理解冲突的产生和解决的过程，情景如下。\n某公司的一个项目使用代码托管服务和Git工具来管理，这个项目有一个功能（假设此功能涉及的修改文件是file01）由开发者1号（以下用01_dev表示）和开发者2号（以下用02_dev表示）共同开发，项目上线前一周，大家都在修改代码，产生了如下情况。\n  file01存储在远程仓库，此时文件内容如下。\n  01_dev在本地仓库修改了文件file01的第二行等内容，并已经成功推送到了远程仓库，此时01_dev的本地仓库和远程仓库的文件内容如下。\n  此时02_dev也在本地仓库修改了文件file01的第二行等内容，在推送远程仓库时\nGit提示file01文件上产生了冲突\n了，02_dev的本地仓库文件内容如下，此时与远程仓库的冲突很明显。\n  02_dev将远程仓库的代码拉取到本地，发现文件第二行开始的冲突并马上联系01_dev进行冲突的解决。\n  打开冲突的文件（如下图所示），他们发现，都对第2行进行了修改，也都在最后一行添加了内容，Git将第二行开始的内容识别为冲突。\n说明：\n Git很智能的将两个人的修改同时显示出来，并用“=======”分割开来  “\u0026laquo;\u0026laquo;\u0026laquo;\u0026lt;HEAD” 与 “=======” 中间的是冲突位置中对应的本地仓库的修改。 “=======” 与 “\u0026raquo;\u0026raquo;\u0026raquo;\u0026gt;” 中间的是冲突位置中对应的远程仓库的修改（也就是刚拉取下来的内容）。 “\u0026raquo;\u0026raquo;\u0026raquo;\u0026gt;” 后面是本次的提交ID。   “\u0026laquo;\u0026laquo;\u0026laquo;\u0026lt;HEAD”、“=======”、“\u0026raquo;\u0026raquo;\u0026raquo;\u0026gt;”、提交ID并非实际编写的代码，解决冲突时注意删除。    最后两人商量后认为最优的解决方案是将两个人的修改内容都保留，由02_dev负责修改，修改后02_dev的本地仓库文件内容如下图，同时保留了两个人的修改和新增内容。\n  这样02_dev就可以重新推送（add → commit → push）本次合并后的更新到远程仓库，推送成功后，远程仓库文件内容如下。此时冲突解决\n  **说明：**在上面的示例中，我们使用txt文本方式进行的演示，在实际开发中不同的文本编辑器、编程工具的Git插件中，对冲突的展示会略有不同。\n如何避免冲突的产生？ 代码提交、合并冲突经常发生，但只要在代码开发前，做好仓库预处理工作，就能有效的避免冲突的产生。\n在示例：冲突的产生与解决中，开发者02（02_dev）成功的解决了提交远程仓库时遇到的冲突问题，此时他的本地仓库与远程仓库的最新版本内容是一样的，但是开发者01（01_dev）本地仓库和远程仓库仍然是有版本差异的，此时如果直接推送本地仓库（push），仍然会产生冲突，那么如何避免呢？\n方式一（推荐新手使用）：\n如果开发者本地的仓库不常更新使用，在做本地修改时，可以重新clone一份远程仓库的内容到本地，修改后再次提交，这样简单直接的解决了版本差异问题，但缺点是如果仓库较大、更新记录较多，clone过程将耗费一定的时间。\n方式二（实际工作标准）：\n如果开发者每天都要对本地仓库进行修改，则建议在本地新建一条开发分支进行代码修改，在要提交远程仓库时，切换到master分支并将远程仓库的最新master分支内容拉取到本地，在本地进行分支合并，对产生的冲突进行修复，成功将内容合并到master分支后，再提交到远程仓库。\n如何在代码托管服务的控制台上解决分支合并冲突？ 代码托管服务支持云端的分支管理，当在进行分支合并时，有时也会产生冲突，下面我们来模拟一次产生了冲突的分支合并请求，并将其解决。\n  新建一个仓库。\n  在仓库中新建一个文件，在本案例中，我们在master分支上新建一个名为file03的文件，其内容初始编写如下。\n  基于master分支新建一个分支，在本案例中，我们将其命名为branch007。\n新建成功后，在master分支、branch007分支中的内容是一模一样的，下面我们需要让它们产生差异。\n  在master分支中，将file03的内容修改为如下图所示，将提交信息填写为“modify in master”。\n  切换到branch007分支，并将file03文件修改为如下图所示，将提交信息填写为“modify in branch007”。此时切换分支即可直观的看到两个分支上已经产生了差异，也就是冲突。\n  新建一个合并请求，选择将branch007分支合入到master分支，如下图单击**“确定”**按钮即可提交一条分支合并请求。\n此时将自动跳转到“合并请求详情”页面，当然您也可以在“合并请求列表”中单击请求的名称进入此页面，如下图所示，代码托管服务提示您当前的合并状态为**“冲突”，并建议您“在线解决冲突”或“本地解决冲突”**\n  下面我们根据提示，解决冲突：\n  在线解决冲突（\n推荐在代码量较小或涉及冲突的代码量较小的情况下使用）\n  单击提示内容“在线解决冲突”，弹出如下图页面非常直观的展示了代码冲突。\n在此页面中我们可以直接选择**“应用我的”或“应用他的”**来选择一方的修改作为最终修复后的内容。\n  当情况较复杂，简单的直接覆盖无法解决问题时，可单击\n进入“手动编辑”模式，如下图所示，可以看到跟示例：冲突的产生与解决\n中的冲突展现格式很像。\n  在上述页面中手动修改代码以解决冲突，并进行提交即可。\n**注意：**提交时注意需要填写提交信息。\n上图中“\u0026laquo;\u0026laquo;” 、“\u0026raquo;\u0026raquo;”、“====”等所在行是冲突展现与分割符，在修改代码解决冲突时，要注意将其删除。\n    本地解决冲突\n（推荐在大型项目中使用）\n单击提示内容**“本地解决冲突”**，即弹出指导内容如下图所示，按照步骤操作即可。\n  **说明：**代码托管服务会根据您的分支名自动生成适合您的Git命令，您只需要复制并在本地仓库执行即可。\n  使用上述两种方法之一，解决了冲突之后，分支合并状态变为**“开启”，此时可以单击“合入”**按钮，进行分支合并的操作了，系统会提示您合并成功。\n（可选）当然您也可以使用分支合并评审流程。\n此时master、branch007两个分支的内容是一样的了，您可以切换分支进行查看验证。\n  ","permalink":"https://sakamotokurome.github.io/posts/git/","summary":"Workspace：工作区，Index / Stage：暂存区，Repository：仓库区（或本地仓库），Remote：远程仓库 远程仓库 安装，","title":"Git"},{"content":" The goals of the FreeBSD Project are to provide software that may be used for any purpose and without strings attached. Many of us have a significant investment in the code (and project) and would certainly not mind a little financial compensation now and then, but we are definitely not prepared to insist on it. We believe that our first and foremost \u0026ldquo;mission\u0026rdquo; is to provide code to any and all comers, and for whatever purpose, so that the code gets the widest possible use and provides the widest possible benefit. This is, I believe, one of the most fundamental goals of Free Software and one that we enthusiastically support.\nThat code in our source tree which falls under the GNU General Public License (GPL) or Library General Public License (LGPL) comes with slightly more strings attached, though at least on the side of enforced access rather than the usual opposite. Due to the additional complexities that can evolve in the commercial use of GPL software we do, however, prefer software submitted under the more relaxed BSD license when it is a reasonable option to do so.\nJordan Hubbard - FreeBSD Handbook\n Install FreeBSD BIOS Disable unused and unwanted options.\nInstall   To put the image on the pendrive we will use the dd tool available on almost any Mac OS X (macOS) and Linux system. For Windows You will have to download it from here – dd for windows( bs=1M on Linux/Windows ).（可用 Rufus 替代）\nsudo dd if=FreeBSD-11.1-RELEASE-amd64-memstick.img of=/dev/da1 bs=1m   When we have a new machine there is always a problem with new name for it. The RFC 1178 Choosing a Name for Your Computer from 1990 year tries to address that issue\n  We will use ZFS because we want to use Boot Environments with sysutils/beadm port.\n Hit [ENTER] on the Pool Type/Disks to select target disk to install FreeBSD on. Now (in FreeBSD 12.x) it is possible to install FreeBSD on GELI encrypted root on ZFS pool without any additional partitions or filesystems. You need to select is Yes for the Encryption part . I advice using GPT (BIOS+UEFI) as it will support both system types so when you are running BIOS system now and will move the disk to other system that boots with UEFI it will also just work out of the box. We will set SWAP size to 0 (no SWAP) as it will not be needed. If we will need SWAP in the future, then we will create ZVOL on ZFS and use it as a SWAP device.     Select services as shown below.   Enable all security hardening features as shown below.  X11 Window System X 最初設計是以網路為中心，採用 “client-server” 架構。在此架構下 “X 伺服器” 在有鍵盤、螢幕、滑鼠的電腦上運作。該伺服器負責的工作包含管理顯示、處理來自鍵盤、滑鼠的輸入及來自其他設備)的輸入或輸出。\n每個 X 應用程式，如 XTerm、Firefox 都是 “客戶端”。\n視窗管理程式規定螢幕上的視窗該長什麼樣、要如何移動滑鼠指標、 要用什麼鍵來在視窗切換、每個視窗的標題列長相，及是否該有關閉按鈕，等等。視窗管理程式負責滑鼠指標的聚焦政策。 聚焦政策指的是如何決定使用中及接收鍵盤輸入的視窗。通常較為人熟悉的聚焦政策叫做 “click-to-focus”，這個模式中，滑鼠點選到的視窗便會處於作用中 (Active) 的狀態。\nKDE 與 GNOME 會被稱作桌面環境是因為包含了完整常用桌面作業的應用程式。\nBIOS or UEFI If you find a device that is not supported by any ‘accelerated’driver like intel or nvidia. You would use vesa driver (Video Electronics Standards Association) while booting in BIOS mode and You will use scfb driver (System Console Frame Buffer) while booting on UEFI mode. This can be checked by\nsudo sysctl machdep.bootmethod Packages sudo pkg install xorg Xorg Configuration   顯示卡、顯示器以及輸入裝置會自動偵測，無須任何手動設置。除非自動設置失敗，否則請勿建立 xorg.conf 或執行 -configure 步驟。\n  加入要執行 Xorg 的使用者到 video 或 wheel 群組，以便在可用時能開啟 3D 加速。要加入使用者 jru 到任一個可用的群組：\nsudo pw groupmod video -m jru || pw groupmod wheel -m jru   Login Class(可解决中文乱码，powershell 字符显示方形)\nAdd this login class to the /etc/login.conf file.\nvideo:\\  :charset=UTF-8:\\  :lang=en_US.UTF-8:\\  :tc=default: Rebuild the login class database.\nsudo cap_mkdb /etc/login.conf Lets set the login class to video for the vuk user.\nsudo pw usermod -L video -n vuk How the account looks after setting the login class.\nsudo grep vuk /etc/master.passwd vuk:{REMOVED}:1000:1000:video:0:0:vuk:/home/vuk:/bin/sh Now logout and login again to make that work. View the changes through the locale command.\n  显卡驱动：使用多檔，每一個檔案只設定一個指定項目會較傳統使用單一 /etc/X11/xorg.conf 設定來的簡單。完整路徑為 /usr/local/etc/X11/xorg.conf.d/。（安装 intel 显卡驱动与 nvidia 驱动难，scfb 与 vesa 驱动无法调整分辨率）\nsudo vi /usr/local/etc/X11/xorg.conf.d/driver-intel.conf Section \u0026#34;Device\u0026#34; Identifier \u0026#34;Card0\u0026#34; Driver \u0026#34;scfb\u0026#34; BusID \u0026#34;PCI:0:2:0\u0026#34; EndSection 若有多張顯示卡，可取消註解 BusID identifier 然後設定為想要的顯示卡，顯示卡的 Bus ID 清單可以使用 pciconf -lv | grep -B3 display 取得。\n  手動設定\n  設定檔可由 Xorg 根據偵測到的硬體產生，這個檔案對一開始自訂設定很有幫助。\nXorg -configure   設定檔會儲存至 /root/xorg.conf.new，做任何需要的更改，然後使用以下指令測試該檔案：\nXorg -config /root/xorg.conf.new 在新設定檔調整與測試過後，便可分開成較小的檔案放置到正常的位置 /usr/local/etc/X11/xorg.conf.d/。\n    Install Desktop Enviroment   FreeBSD 桌面发行版\n GhostBSD 是 FreeBSD 桌面发行版，注意使用 Official 版本，不能直接使用 FreeBSD 源升级。 nomadbsd 是个非常漂亮的 FreeBSD 桌面发行版 ，德国产。 可以在虚拟机里面安装 FreeBSD 桌面发行版，然后找到自己想用的桌面工具，再定制自己的 FreeBSD 桌面。    Install Desktop Environment\nsudo pkg install gnome3 sudo pkg install gnome3-lite sudo pkg install x11/kde5 sudo pkg install xfce sudo pkg install mate   Install/Enable Display Manager: You have to decide how You want to start your X11 Window Server, you may login in plan text console and then type xinit or startx to read your ~/.xinitrc configuration and daemons (The difference between xinit and startx is that startx command executes xinit command with arguments.) or You may want to use X11 Login manager such as xdm/sddm/slim with ~/.xsession configuration to load after successful login.\nsudo pkg install xdm sudo pkg install slim # xfce,mate，slim 有个 slim-themes 软件包 sudo pkg install x11/sddm # kde While xinit run commands based on the ~/.xinitrc file the XDM login manager looks for the ~/.xsession file. As You will be loading same stuff regardless of the startup method we will create a link of ~/.xsession pointing to the ~/.xinitrc file. This way either method You choose You will always end with started X11 session.\nln -s ~/.xinitrc ~/.xsession One more case about the ~/.xinitrc (or ~/.xsession) file. It is interpreted as a shell script (and yes you can do if/then/else/fi and case/esac or for/while POSIX shell scripting in it) but it does not need to be executable. The last command in this file MUST NOT to be put in the background (must be without the \u0026amp; char at the end) because the X11 session will end.\n  Setting\nsudo vi /etc/ttys # xdm ttyv8 \u0026#34;/usr/local/bin/xdm -nodaemon\u0026#34; xterm on secure sudo vi /etc/fstab # gnome, kde proc /proc procfs rw 0 0 sudo vi /etc/rc.conf moused_enalbe=\u0026#34;YES\u0026#34; dbus_enable=\u0026#34;YES\u0026#34; # gnome, kde, xfce hald_enable=\u0026#34;YES\u0026#34; # gnome, kde, mate gdm_enalbe=\u0026#34;YES\u0026#34; # gnome 启动 sddm_enable=\u0026#34;YES\u0026#34; # kde 启动 slim_enable=\u0026#34;YES\u0026#34; # xfce,mate gnome_enable=\u0026#34;YES\u0026#34; # gnome 服务   slim Usage(Failed to execute login command)\nsudo vi ~/.xinitrc exec mate-session # mate exec xfce4-session # xfce   Components   Window Manager: Openbox\u0026hellip;\n  Status Bar: Also known as information bar, the place on the screen that would provide You needed information such as current date and time, CPU, RAM and storage usage, current network information or battery status.\n  While Xmobar is nice solution it comes with about 2 GB of dependencies of Haskell and Haskell libraries.\n  While Polybar can look very nice on screenshots it is a lot more heavy on resources and is limited only to modules/features that were implemented in it.\n  I have used Conky for quite long time but after recent tests I made Dzen2 is a lot less on resources then Conky while doing the same thing.\n    Task Bar: A taskbar is an element of a graphical user interface which has various purposes. It typically shows which programs are currently running.\n  You can use classic taskbar like XFCE Panel used in the XFCE desktop environment.\n  You can also configure Tint2 that way. But it only shows applications that are active on the current desktop.\n  One of the greatest taskbars of all time was/is the Mac OS X Dock (now macOS Dock). It also has an indicator showing if application is launched. Currently the best and lightest solution for providing the dock-like functionality on open desktops seems to be Plank.\n    Application Launcher: While not being any crucial role of the desktop environment it have its uses and sometimes save time.\nLets start with resources, the Rofi implementation of application launcher uses almost 3 times more RAM then Dmenu solution.\n  Desktop with Dmenu launched and with alc characters inserted to ‘filter’ commands in the search of a calculator application.\n  The Rofi requires simple command.\nrofi -show run -theme solarized_alternate -font \u0026#34;Monaco 8\u0026#34;     Blue Light Spectrum Suppress: Automatically adjusts color temperature of the screen according to your current time in your location.\n  While F.lux (closed source) does not provide a native binary for FreeBSD it does offer such binary for Linux and as FreeBSD provides Linux Binary Compatibility its possible to use it on FreeBSD. To use F.lux just start it in the ~/.xinitrc or ~/.xsession file like that.\n~/path/to/bin/xflux -l 33.54321 -g 11.12345 \u0026amp; Of course 33.54321 is latitude and 11.12345 is longitude of your localization.\n  Redshift is the solution that I propose to use as open source blue light spectrum suppressor. Similarly like with the F.lux to start Redshift just put it in the ~/.xinitrc or ~/.xsession file like that.\nredshift -l 33.54321:11.12345 -g 0.9 \u0026amp;   Someone else suggested trying sctd which is sct but rewritten/modified to be a daemon that will automatically change the color temperature during the day (or night). The sctd uses smaller about of RAM memory, uses less libraries and size of these libraries is smaller then what redshfit needs.\n    Binary 套件 搜寻软件：FreeBSD Ports、FreshPorts\n因編譯選項不同，有些 Port 會有多個版本可使用。\n  USTC Mirrors：注意使用 Latest 源，有很多流行软件。创建 /usr/local/etc/pkg/repos/FreeBSD.conf 覆盖官方源 /etc/pkg/FreeBSD.conf 配置\nsudo vi /usr/local/etc/pkg/repos/FreeBSD.conf FreeBSD: { url: \u0026#34;pkg+http://mirrors.ustc.edu.cn/freebsd-pkg/${ABI}/latest\u0026#34;, } sudo pkg update -f # 更新索引   163 Mirrors\n url: \u0026quot;pkg+http://mirrors.163.com/freebsd-pkg/${ABI}/latest\u0026quot;,   要啟動 (Bootstrap) 系統，請執行\nsudo /usr/sbin/pkg   當升級原使用舊版 pkg_* 工具的既有系統時，必須將資料庫轉換成新的格式\nsudo pkg2ng   Update the available remote repositories as listed in pkg.conf\nsudo pkg update   Search for a package\nsudo pkg search perl   在指定要安裝的套件時，最好使用 Port 來源來指定該應用程式，Port 來源是指應用程式在 Port 樹中的路徑\nsudo pkg search -o perl   Install a package: Installing must specify a unique origin or version otherwise it will try installing all matches\nsudo pkg install perl-5.14   列出已經安裝的 Port 中有那些已過時\nsudo pkg version -l \u0026#34;\u0026lt;\u0026#34;   Upgrade from remote repository\nsudo pkg upgrade   Delete an installed package\nsudo pkg delete perl-5.14   Remove unneeded dependencies\nsudo pkg autoremove   List installed packages\nsudo pkg info   Display information about installed packages\nsudo pkg info perl-5.14   Show the pkg-message of a package\nsudo pkg info -D perl-5.14   要查詢已安在系統上的軟體是否有任何已知的漏洞\nsudo pkg audit -F   因為相依所安裝的套件稱作自動 (Automatic) 套件，而非自動套件即套件被安裝的原因不是因為其他套件所相依\nsudo pkg prime-list # deprecated   Clean the local cache of fetched remote packages\nsudo pkg clean   Packages\nsudo pkg install linux-sublime3 sudo pkg install mysql180-server mysql180-client   Port 套件 優點：\n 可更改編譯選項 部份軟體的授權條款中禁止以 Binary 格式發佈。 這種軟體必須以原始碼發佈並由終端使用者編譯。 原始碼可套用自訂的修補。  Port 中並不含實際的原始碼，在編譯 Port 解壓縮時會自動下載的原始碼到 /usr/ports/distfiles。\n  USTC Mirrors：在 /etc/make.conf 中添加以下内容\nMASTER_SITE_OVERRIDE?=http://mirrors.ustc.edu.cn/freebsd-ports/distfiles/${DIST_SUBDIR}/   163 Mirrors\nMASTER_SITE_OVERRIDE?=http://mirrors.163.com/freebsd-ports/distfiles/${DIST_SUBDIR}/   安裝 Port 套件集：下載壓縮後的 Port 套件集快照 (Snapshot) 到 /var/db/portsnap\nsudo portsnap fetch   第一次執行 Portsnap 時，要先解壓縮快照到 /usr/ports\nsudo portsnap extract   執行以下指令來更新 /usr/ports\nsudo portsnap fetch sudo portsnap update   要找到 Port 所在的分類\nsudo whereis lsof   使用 Port 套件集內建的搜尋機制來找軟體\nsudo cd /usr/ports sudo make search name=lsof sudo make quicksearch name=lsof # 不接受多資訊   若要進行更有深度的搜尋\nsudo make search key=string sudo make quicksearch key=string   一次設定所有Port 編譯選項\nsudo make config-recursive   重新進入 Port 的編譯選項清單\nsudo make config # or sudo make showconfig # or sudo make rmconfig   編譯並安裝 Port\nsudo cd /usr/ports/sysutils/lsof sudo make install   編譯在 /usr/ports Port 並安裝到 /usr/home/example/local\nsudo make WRKDIRPREFIX=../ports PREFIX=../local install   安裝過程中會建立工作用的子目錄用來儲存編譯時暫存的檔案。可移除此目錄來節省磁碟空間並漸少往後升級新版 Port 時造成問題\nsudo make clean   移除已安裝的 Port\nsudo cd /usr/ports/sysutils/lsof sudo make deinstall   Example\ncd /usr/ports/java/linux-oracle-jdk18 sudo make install   安裝後的注意事項：\n 大部份應用程式安裝會在 /usr/local/etc 安裝至少一個預設的設定檔。 應用程式提供的文件會安裝到 /usr/local/share/doc。 部份應用程式會以服務的方式執行，在啟動應用程式前前需要加入設定到 /etc/rc.conf。這些應用程式通常會安裝啟動 Script 到 /usr/local/etc/rc.d。  Linux® Binary 相容性 FreeBSD 提供 Linux® Binary 的相容性，允許使用者在 FreeBSD 系統上不需要修改就可以安裝和執行大部份的 Linux® Binary。\n最好不要直接安装 Linux 的软件，而使用 FreeBSD 源中的 Linux 软件，一般以 linux-package 命名。\n  載入 Linux® 核心模組\nsudo kldload linux   對 64-位元的相容性\nsudo kldload linux64   確認模組已載入\nsudo kldstat   安裝基本的 Linux® 程式庫和 Binary\nsudo pkg install emulators/linux_base-c7   Add the following line\nsudo vi /etc/fstab linprocfs /compat/linux/proc linprocfs rw 0 0 linsysfs /compat/linux/sys linsysfs rw 0 0 tmpfs /compat/linux/dev/shm tmpfs rw,mode=1777 0 0   開機時開啟 Linux® 相容性\nsudo vi /etc/rc.conf linux_enable=\u0026#34;YES\u0026#34;   安裝 Linux® ELF Binary\nsudo brandelf -t Linux my-linux-elf-binary   安裝以 Linux® RPM 為基礎的應用程式,需先安裝 archivers/rpm4 套件或 Port\nsudo pkg install rpm4 sudo cd /compat/linux sudo rpm2cpio \u0026lt; /path/to/linux.archive.rpm | cpio -id   手動安裝其他程式庫   在 Linux® 系統，可使用 ldd 來找出應用程式需要哪個共用程式庫\nldd linuxdoom libXt.so.3 (DLL Jump 3.1) =\u0026gt; /usr/X11/lib/libXt.so.3.1.0   複製 Linux® 系統輸出結果中最後一欄需要的的檔案到 FreeBSD 系統的 /compat/linux。 複製完後，建立符號連結 (Symbolic link) 至輸出結果第一欄的名稱\n/compat/linux/usr/X11/lib/libXt.so.3.1.0 /compat/linux/usr/X11/lib/libXt.so.3 -\u0026gt; libXt.so.3.1.0   自訂核心 為何要編譯自訂的核心? 自訂核心有許多項優點，如：\n 加速開機，因為自訂的核心只需要偵測您系統上存在的硬體，所以讓啟動所花的過程更流暢快速。 減少記憶體使用，自訂的核心通常會比 GENERIC 核心使用更少的記憶體，這很重要，因為核心必須一直存放在實體記憶體內。 支援額外的硬體，自訂的核心可以增加一些 GENERIC 核心沒有提供的硬體支援。  偵測系統硬體   dmesg or /var/run/dmesg.boot or /var/log/messages\n  pciconf -lv\n  在 man指令加上 -k 旗標可列出有包含指定裝置品牌或名稱的手冊頁面清單：man -k Intel\n  設定檔 /usr/src/sys 下子目錄代表著支援的硬體架構 (Architecture)，每個支援的硬體架構中會有 conf 子目錄，裡面含有供該架構使用的 GENERIC 核心設定檔。\n說明在GENERIC 同目錄的 NOTES 檔案中。所有架構通用選項，參考 /usr/src/sys/conf/NOTES。\n备份与恢复 dump \u0026amp; restore FreeBSD 系统的备份就是对系统文件的打包，然后放到一个安全的地方，使用的打包工具是 dump；FreeBSD 系统的恢复就是把你保存好的系统文件从安全的地方里面拿出来放到你的硬盘上去，使用的恢复工具是 restore；\n  需要备份的目录：\n / 这个目录存放很多基本工具，包括内核，需要备份； /home 用户数据，需要备份； /usr 很多工具以及系统的源代码都放在这里面，需要备份； /usr/local 所有安装的软件基本上都在这里，需要备份； /var 系统的日志，ports系统的数据库，需要备份；    备份方法：以 / 目录为例，把移动硬盘挂载在 /mnt/fender_01 目录，/ 目录对应硬盘上面的 /dev/ad12s1a 分区，备份整个目录的命令如下：\ndump -0Lauf /mnt/fender_01/dump/ad12sa1.dump /dev/ad12s1a  -0 备份所有的文件系统中的内容，也就是不使用增量备份； -f 指定备份结果存放的文件名； -a 告诉 dump 不考虑备份的介质的大小问题，早期备份使用磁带，dump 会预先计算一下需要的空间，使用这个选项告诉 dump 忽略这个问题； -u 告诉 dump 更新一下 /etc/dumpdates，这个文件记录了你在系统上搜有的备份活动； -L 备份已经挂载的文件系统时需要，这个选项会使用 UFS2 的 snapshot 功能来保证文件系统的一致性。    恢复方法\n  恢复 / 以外的目录：以恢复 /home 目录为例，重启系统进入单用户模式，挂载 /tmp 分区，挂载移动硬盘，这时备份生成的文件保存在 /mnt/01/dump/dev/ad12s1h.dump，格式化 /dev/ad12s1h：\nnewfs -U /dev/ad12s1h # -U 选型来打开 softupdate 挂载这个分区，例如 /mnt/02/，恢复目录：\ncd /mnt/02 restore -rf /mnt/01/dump/ad12s1h.dump   恢复 /：因为 restore 在 / 目录中，所以不能使用上面方法恢复 / 目录。解决办法是使用 freebsd_livefs_cd 启动系统。\n    备份 MBR\n  备份\ndd if=/dev/da0 of=/path/to/mbr.img bs=512 count=1   恢复\ndd if=/path/to/mbr.img of=/dev/da0 bs=512 count=1     参考：FreeBSD dump 备份\nrsync（remote sync） 可以在本地计算机与远程计算机之间，或者两个本地目录之间同步文件，且仅传输有变动的部分。\n  将源目录同步到目标目录\nrsync -r source1 source2 destination # -r 表示递归，即包含子目录 rsync -a source/ destination # -a 除了可以递归同步以外，还可以同步元信息（比如修改时间、权限等）   排除文件：同步时排除某些文件或目录，这时可以用 --exclude 参数指定排除模式，多个排除模式，可以用多个 --exclude 参数\nrsync -av --exclude dir source/ destination # 排除所有 TXT 文件   增量备份：除了源目录与目标目录直接比较，rsync 还支持使用基准目录，即将源目录与基准目录之间变动的部分，同步到目标目录。--link-dest 参数用来指定同步时的基准目录。\nrsync -a --delete --link-dest /compare/path /source/path /target/path   远程同步：rsync 默认使用 SSH 进行远程登录和数据传输\nrsync -av source/ username@remote_host:destination # 将本地内容同步到远程服务器 rsync -av username@remote_host:source/ destination # 将远程内容同步到本地   使用 rsync 来备份系统\nrsync -aH --delete --exclude dir --link-dest /compare/path source destination  -H 选项用来保持硬链接 默认情况下，rsync 只确保源目录的所有内容（明确排除的文件除外）都复制到目标目录。它不会使两个目录保持相同，并且不会删除文件。如果你想让那些在源目录里被删除的文件在目标目录里也被删除，那么你可以加上 --delete 选项来删除。--delete 参数会使得 destination 成为 source 的一个镜像。    参考：rsync 用法教程，使用 rsync 来备份 Linux 系统\nZ 檔案系統 (ZFS) ZFS 的設計目標主要有三個：\n 資料完整性：所有資料都會有一個資料的校驗碼 (checksum)，資料寫入時會計算校驗碼然後一併寫入，往後讀取資料時會再計算一次校驗碼，若校驗碼與當初寫入時不相符，便可偵測到資料錯誤，此時若有可用的資料備援 (Data redundancy)，ZFS 會嘗試自動修正錯誤。 儲存池：實體的儲存裝置都會先被加入到一個儲存池 (Pool)，這個共用的儲存池可用來配置儲存空間，儲存池的空間可被所有的檔案系統使用且透過加入新的儲存裝置來增加空間。 效能：提供多個快取機制來增加效能。先進、以記憶體為基礎的讀取快取可使用 ARC。第二層以磁碟為基礎的讀取快取可使用 L2ARC，以磁碟為基礎的同步寫入快取則可使用 ZIL。  Others Screen resolution on FreeBSD on VirtualBox 问题描述：在virtualbox虚拟机下，无法改变桌面分辨率为1366x768\nVBoxManage setextradata \u0026#34;FreeBSD\u0026#34; VBoxInternal2/EfiGraphicsResolution 1366x768 Disable the Forward/Back buttons on my mouse 问题描述：浏览网页时，鼠标滑轮滚动浏览器就会前进后退。\nSalved：\n  执行下面命令后，上下滑动鼠标滑轮，看看映射到那些button，一般是buttons 8 and 9\nsudo xev | grep -A2 ButtonPress   then disable button 8 and 9（前提是有上面的问题，否则就不要禁）\nsudo vi ~/.Xmodmap pointer = 1 2 3 4 5 6 7 0 0 0 0 0   test it with the command,command automatically when you log in; if yours doesn\u0026rsquo;t, arrange for it to run when X starts.\nsudo xmodmap ~/.Xmodmap   Install chinese font sudo pkg install zh-CJKUnifonts # CJK（中日韩统一表意文字） 设单使用模式为不安全 sudo vi /etc/ttys console none unknown off insecure No space left on device 问题描述：使用 pkg update 时提示这个问题。原因是 /tmp is too small。\nSalved:\nsudo vi /etc/fstab tmpfs /tmp tmpfs rw,size=256000000 0 0 # size 以Byte为单位 VirtualBox™ guest additions sudo cd /usr/ports/emulators/virtualbox-ose-additions \u0026amp;\u0026amp; make install clean sudo vi /etc/rc.conf vboxguest_enable=\u0026#34;YES\u0026#34; vboxservice_enable=\u0026#34;YES\u0026#34; vboxservice_flags=\u0026#34;--disable-timesync\u0026#34; # 若有使用 ntpd或 ntpdate，便可關閉主機時間同步功能 Fish Fish 是\u0026quot;the friendly interactive shell\u0026quot;的简称，最大特点就是方便易用。\nFish 会自动在光标后面给出建议，表示可能的选项，颜色为灰色。如果采纳建议，可以按下→或Control + F。如果只采纳一部分，可以按下Alt + →。\n输入命令时，Fish 会自动显示匹配的上一条历史记录。如果没有匹配的历史记录，Fish 会猜测可能的结果，自动补全各种输入。\nHow to start things at boot time   主流的桌面环境都自带应用程序自启动设置程序。\n  These directories are defined in /etc/defaults/rc.conf（主要是运行脚本）\n  Default startup directory is /usr/local/etc/rc.d/. if you need the files to be executed in a specific order, try numbering the files. For example:\n000This.Will.Run.First.sh 020This.Will.Run.Next.sh 030And.Then.This.sh   deprecated: /etc/rc.local\n    DSBAutostart is a Qt program that allows you to add commands to be executed at session start.\n（本质就是在 .xinitrc 调用程序指令，GUI 程序开机启动都需放入 .xinitrc，在 Xorg 启动后运行）\n  Installation\ncd /usr/ports/x11/dsbautostart \u0026amp;\u0026amp; make install distclean   Usage\n  Manual\n  Setup: Add the following command to your ~/.xinitrc, or to your window manager\u0026rsquo;s startup script (e.g. ~/.config/openbox/autostart.sh)\nsh ~/.config/DSB/autostart.sh\u0026amp;   ~/.config/DSB/autostart.sh\nPlank\u0026amp;     GUI: Setting -\u0026gt; DSBAutostart -\u0026gt; Add Command, example plank, then Save and Quit\n      FreeBSD Insall Oracle JDK  安装 Linux Compact 在 /usr/ports/java/linux-oracle-jdk18 运行 sudo make install 根据提示在 Oracle Java Archive 下载需要的 JDK 版本安装包，复制到 /usr/ports/distfiles 在 /usr/ports/java/linux-oracle-jdk18 运行 sudo make install，安装成功  FreeBSD Install Python and pip sudo pkg install python python --version Python 3.7.9 sudo pkg install py37-pip 简化启动 FreeBSD 默认启动过程相当详细，包含大量调试信息以及内核消息。\n Add the boot_mute=YES option to the /boot/loader.conf file. Add autoboot_delay=2 parameter to the /boot/loader.conf file. Add rc_startmsgs=\u0026quot;NO\u0026quot; to your /etc/rc.conf file.  连接网络 If You will have attached LAN cable and your interface is em0 (check ifconfig command output) then dhclient em0 command should grant You the working connection to the Internet – assuming that You have DHCP server on that network.\nifconfig em0 up dhclient em0 To test the network connectivity use the ping command.\nping -c 3 freebsd.org If You would like to connect to the World with wireless connection then here are the needed commands. First lets check what wireless card You have.\nsysctl net.wlan.devices We will now create wlan virtual device on top of our iwn0 device and bring it up.\nifconfig wlan0 create wlandev iwn0 ifconfig wlan0 up We can scan for existing nearby WiFi access points if needed.\nifconfig wlan0 scan Now we need to add the desired WiFi network to the /etc/wpa_supplicant.conf file as shown below.\nnetwork={ ssid=\u0026quot;WIFI-NETWORK-NAME\u0026quot; psk=\u0026quot;PASSWORD\u0026quot; } Then You may connect to it using the wpa_supplicant daemon. Hit the [CTRL]+[Z] key combination to put the process into suspended state. Then we type the bg command to put it back into running state, but in the background so we can continue to type next commands.\nwpa_supplicant -i wlan0 -c /etc/wpa_supplicant.conf Now we will request for the IP address from the access point DHCP server.\ndhclient wlan0 How To Add and Remove Users on FreeBSD   Add a User: adduser\n  Grant Sudo Privileges: On FreeBSD, users that are members of the wheel group are allowed to use sudo. This is due to the following line in the default sudoers file, /usr/local/etc/sudoers\n%wheel ALL=(ALL) NOPASSWD: ALL   Remove a User: rmuser\n  Lock a User Account: pw lock username\n  Unlock a User: pw unlock username\n  Is it possible to somehow install Flatpak for NetBSD though? No, snapd requires systemd and flatpak requires linux namespaces. Appimages might be possible in the future, see https://github.com/AppImage/AppImageKit/issues/98\npkgsrc pkgsrc 是一个在类 UNIX 系统上管理第三方软件的框架，目前包含超过 17,900 个软件包。\nRavenports Ravenports 是一个集成系统，旨在在所有类 UNIX 平台上构建复杂软件包。\nNix package manager This issue has been mentioned on NixOS Discourse. There might be relevant details there:\nhttps://discourse.nixos.org/t/what-is-sandboxing-and-what-does-it-entail/15533/1\n[Linuxulator] How to run Google Chrome (linux-binary) on FreeBSD 相关 NetBSD: huaweicloud、aliyun、tsinghua\nOpenBSD: huaweicloud、aliyun、tsinghua\n一篇好文：FreeBSD的现状和未来\nFreeBSD Desktop\nFreeBSD 使用手冊\nhelloSystem\nravynos\n","permalink":"https://sakamotokurome.github.io/posts/freebsd/","summary":"The goals of the FreeBSD Project are to provide software that may be used for any purpose and without strings attached. Many of us have a significant investment in the code (and project) and would certainly not mind a little financial compensation now and then, but we are definitely not prepared to insist on it. We believe that our first and foremost \u0026ldquo;mission\u0026rdquo; is to provide code to any and","title":"FreeBSD"},{"content":"   Just a little conversation\nAbout give me your picture\nOn the cover of a magazine\nOn the cover of a magazine\nJust a little conversation\nBut how long it might take one?\nTo get along with such thing?\nTo get along with such thing?\nBut everybody knows\nIt\u0026rsquo;s easier to fall apart\nJust a little conversation\nAbout give me your picture\nOn the cover of a magazine\nOn the cover of a magazine\n ","permalink":"https://sakamotokurome.github.io/posts/conversation/","summary":"Just a little conversation\nAbout give me your picture\nOn the cover of a magazine\nOn the cover of a magazine\nJust a little conversation\nBut how long it might take one?\nTo get along with such thing?\nTo get along with such thing?\nBut everybody knows\nIt\u0026rsquo;s easier to fall apart\nJust a little conversation\nAbout give me your picture\nOn the cover of a magazine","title":"Conversation"}]