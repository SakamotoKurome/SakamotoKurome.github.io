[{"content":"Portal 信息生产者主要是企业。\n OSCHINA：开源资讯 少数派：软硬件使用技巧 Linux 中国：Linux 相关 Distrowatch：Linxu 发行版排行 FreeBSDNews LWN.net: News and Information source for the free software community 36氪 虎嗅 利器 湾区日报：每天推送3到5篇优质英文文章 It\u0026rsquo;s FOSS: Focuses on Open Source in general and Linux in particular 开源工厂 \u0026lt;奇客\u0026gt; solidot：中文科技信息交流平台和开源新闻平台 LinuxToday: Linux News On Internet Time linuxinsider desktoplinux THE LINUX FOUNDATION ChinaUnix：Linux/Unix技术社区网站 Fedora Magazine Planet Gentoo 新运维 FreeBuf 51CTO  Forum\u0026amp;community 信息生产者主要是各个用户。\n 思否：技术文章 掘金：很多优质前端文章 v2ex：程序员之间的交流 博客园：blog，新闻 豆瓣：读书、电影 知乎：提问 StackOverflow：提问 牛客网：求职 The FreeBSD Forums openSUSE 中文论坛：很活跃的 Linux 论坛 Ubuntu 中文论坛 LUG@USTC：中国科学技术大学 Linux 用户协会 LinuxQuestions: Linux Community LINUX.ORG：Linux 主站 火狐社区 Ask Ubuntu freeCodeCamp 中文社区 Hacker News Daily 4chan ubuntu forums ASK FEDORA 灰狐和他的朋友们 Ubuntu 正体中文站 China FreeBSD Tuxmachines.org Linux Journal HowtoForge phoronix 先知社区 LUPA 开源社区 AOSC 社区：AOSC OS 是独立于 Debian 构建和维护的发行版。 北京 GNU/Linux 用户组 GamingOnLinux public0821: Linux sparkdev: Linux  Blog\u0026amp;log 信息生产者是个人。\n 月光博客：IT咨询 包昊军的博客 delphij\u0026rsquo;s Chaos：FreeBSD 学习日志：Web系统架构 Lamp Nginx Golang MySQL 𝚟𝚎𝚛𝚖𝚊𝚍𝚎𝚗: FreeBSD D0n9X1n\u0026rsquo;s Blog: Hexo, WorldPress Java技术驿站 芋道源码: Java 酷壳 – CoolShell.cn LinuxTOY：Linux 相关资讯 Zoom.Quiet：Python 与 开源 plaintxt.org：Minimalism in blog design, an experiment Sickly Life：日文 Blog，Ubuntu 相关 阿星Plus Js中文网周刊 当然我在扯淡 wlop：微博2020十大影响力画手 知名动漫博主 蘑菇天文馆：opensuser Jerry Qu：专注 WEB 端开发 Flavio Copes：I\u0026rsquo;m a computer engineer and I write free books to help you become a Web Developer 黑果小兵的部落阁 张鑫旭的个人主页 阮一峰的网络日志 廖雪峰的官方网站 囧克斯 W3cplus Houge\u0026rsquo;s Madness Blog marguerite：opensuser Slbtty\u0026rsquo;s Notepad：opensuser 鹤仙人：em\u0026hellip; 依云\u0026rsquo;s Blog：仙子 Eric S. Raymond\u0026rsquo;s Home Page Dark Side Make Linux 星黎殿 Mark Shuttleworth：Ubuntu创始人的blog V2方圆 omg! ubuntu! Yafa-Xena: Gentoo bitbili: Gentoo farseerfc 的小窝 YangMame ManateeLazyCat codeplayer 菜菜博士 阿虚同学的储物间 Vamei Felix\u0026rsquo;s Blog：肥猫、猫菊苣 iovxw 土木坛子 约伊兹的萌狼乡手札 喵\u0026rsquo;s StackHarbor 512 Pixels: 512 Pixels is a blog covering Apple, computer history, space, design and lots of other fine nerdery. CS Slayer：囧脸，Fcitx 作者 李皓奇 Phoenix\u0026rsquo;s island：凤凰酱 ICEHONEY：秋水学姐 Plum\u0026rsquo;s Blog: Ubuntu 初等記憶體 Beyond the void Henry\u0026rsquo;s Blog: FreeBSD! Planet Ubuntu：Ubuntu 开发者博客汇集 钛山：开源软件吉祥物 编程随想 FiveYellowMice 荒原之梦 Soymilk Gea-Suan Lin\u0026rsquo;s BLOG：偏技術方面的資訊 Nova Kwok\u0026rsquo;s Awesome Blog 凍仁的筆記：完全用 GNU/Linux 工作 国光：手把手教你配置 OpenCore Lan Tian：网络 Sukka：Hackintosh、DNS  Entertainment\u0026amp;games  Unsplash：图片 Pexels：图片 Pxhere：图片 Pixabay：图片 Canva：图片 Kisscc0：图片 10wallpaper.com：壁纸 wallpaperhub：电子产品的默认壁纸 wall.alphacoders.com：动漫风壁纸 极简壁纸 Rijksmuseum：the museum of the Netherlands wallhaven Lorem Picsum：The Lorem Ipsum for photos. RedMonk：编程语言排行榜 IPAddress：查 ip StatCounter：OS、浏览器使用数据 APKCombo：Google Play 镜像 Internet Speed Test - Measure Latency \u0026amp; Jitter | Cloudflare MSDN, 我告诉你 Alternativeto：寻找 Linux 下替代软件 Awesome Windows Windows绝赞应用 Softnic：软件下载，针对没有 Google Play 小众软件：windows 软件 酷安：安装 Microsoft 应用 W3Techs：World Wide Web Technology Surveys BuiltWith：Web Technology Usage Trends \u0026ldquo;LinuxQuestions.org Members Choice Results\u0026rdquo; EASYCOUNTER：couont wep pages hints using only html Steam Hardware \u0026amp; Software Survey YGOPRO：游戏王 萌卡社区：游戏王社区 YGOPRODECK：游戏王卡组 故宫博物院藏品总目 墨刀：原型设计工具 CanIUse：浏览器兼容性查询 ProcessOn：在线制作流程图 幕布：一键生成思维导图 Get Emoji ilovepdf：各种免费的 PDF 在线工具 找字网 有字库 Iconfont Color Hunt OSCI：Open Source Contributor Index Gitstar Ranking：GitHub 全球排名 Codrops：网页设计开发博客 Neumorphism：新拟态效果 uiGradients：渐变配色方案 kunstderfuge：该网站可以按照古典音乐家的人名查询，免费下载他们作品的 MIDI 文件 lofi.cafe：这个网站是一个制作精良的在线电台，播放工作学习时放松精神的背景音乐，可以根据音乐风格切换房间。 Slant：use Slant to find the best products and share their knowledge SHOUTcast：radio stations for Rhythmbox（how to） 中华人民共和国国家卫生健康委员会：可以查看医院等级信息 UNPKG：unpkg is a fast, global content delivery network for everything on npm. Skyline Webcams：该网站提供世界五大洲的直播摄像头，可以看到世界各个地点的实况。 figma：Figma是一个向量图形编辑器和原型设计工具，主要基于网页，透过macOS和Windows的桌面应用程序可启用额外的离线功能。 Manage your team’s work, projects, \u0026amp; tasks online • Asana JetBrains Mono Github Ranking freemdict The top 500 sites on the web DistroTest.net：Test a new operating system GAMUX：Linux Game Top500 Stack Overflow Developer Survey pixiv Server World 网址导航 Jamendo Music Magnatune: Music Magisk drivedroid: Boot a PC using ISO files stored on your Android phone TWRP pixelexperience Notion Avatar Maker 老生常谈 Distro Chooser 中华古籍资源库 My beautiful Linux development environment 中国哲学书电子化计划 Can You Run It：System Requirements Lab analyzes your computer in just seconds, and it\u0026rsquo;s FREE. Torlook: All popular torrent trackers indexed! TorrentFreak  YTS.mx: movies The Pirate Bay 1337X Nyaa: It is one of the largest public anime-dedicated torrent indexes. FitGirl Repacks: \u0026ldquo;repacking\u0026rdquo; games — compressing them significantly   IGGGAMES/PCGamesTorrents Immortal Proxy 游戏机模拟器  Cemu：Experimental software to emulate Wii U applications on PC PPSSPP：A PSP emulator. yuzu: Nintendo Switch Emulator PCSX2：The Playstation 2 emulator RPCS3：The Open-source PlayStation 3 Emulator，PS3中文游戏合集下载 Citra：Nintendo 3DS Emulator，3DS中文游戏全集   老男人游戏网 Gamebanana：Mod Emulation General Wiki 绅士天堂 吾爱破解 萌娘百科 Wikipedia PCGamingWiki Wikiwand Greasy Fork：用户脚本 Mox.moe：Kindle漫畫 Lutris：Play all your games on Linux 葡萄玩：是开源项目 Lutris 的中国定制版。 protondb：With Proton and Steam Play, many Windows games now work on Linux! Play On Linux：PlayOnLinux simplifies much of this and makes installing and using Windows programs in Ubuntu easier. Paint of Persia：这个工具让你可以在屏幕任何一个窗口，框选一部分内容，将其变成像素画。 NomnomNami YuriNovel ponpomuYuri 轻小说文库 宝书网 饭饭文学 La Memoria Vegetale 千秋书在 搬书匠 书栈网 BT之家 BD影视分享 在线之家 APKMODY: An Android App Store where you can download your favorite Premium / MOD / APK apps. Antivirus software：AV-Comparatives、AVTEST（杀毒软件评比） Yurifans Intel Product Specifications Google Public DNS：Configure your network settings to use the IP addresses 8.8.8.8 and 8.8.4.4 as your DNS servers. Norton DNS OpenDNS 114DNS LowEndBox: low end dedicated servers and cheap virtual private servers DOSBox: classic PC games emojimix: Combine two emojis into one and share them with your friends. Thousands of combinations are available. FODI: yuri lover Ubuntu certified hardware: Machines you can trust with Ubuntu Linux on Laptops: Reports on running Linux on notebook or laptop computers Library Genesis 凛凛酱：Custom ROM maintainers XDA: Custom ROM Forum virustotal 百合会 多多视频：原人人视频 动漫之家 拷贝漫画 MangaDex 灰机wiki：一个中文的游戏「维基农场」（维基自助托管平台）。 wikiHow：互联网上最值得信赖的指南网站 the visual novel database 游戏时光：游戏介绍、资料库 IGN: Imagine Games Network 飞瓜数据 B站版 flightlessmango: Games Benchmarks Steam520: Steam 250 is dedicated to making good Steam games discoverable.  Tutorial\u0026amp;materials  极客学院：在线教程 W3school：在线教程 菜鸟教程：在线教程 Arch Wiki FreeBSD Handbook Goodreads：找原文小说 图灵社区：电子书 Microsoft Docs 鸟哥 Linux 私房菜 中文马克思主义文库 Unix Toolbox Learn X in Y minutes openSUSE Wiki openSUSE Documentation Unofficial Guide to openSUSE Leap SUSE product documentation Ubuntu 中文 Wiki Ubuntu Manpage Ubuntu 正體中文 Wiki Full Circle：Ubuntu社区的独立杂志 Linux C编程一站式学习 亚嵌教育：Linux Books Linuxtopia：online resource for anyone learning or deploying enterprise level open source technology. Ultimate Guide: Getting Started With Ubuntu DB-Engines： Knowledge Base of Relational and NoSQL Database Management Systems Zoo Weekly MDN Web Docs YouZack：英语听力精听、背单词 现代 JavaScript 教程 CodinGame：编程学习平台，练习编程 FreeCodeCamp：编程学习平台，适合初学者 Codecademy：编程学习平台，适合初学者 JavaScript Weekly CodePen.io CSS Battle：一共有12个级别，需要你用 HTML和 CSS 100%还原它给出的页面，然后再尽量减少代码 Learn CSS Layout：学习 CSS 布局 CSS-Tricks：一些关于 CSS 的技巧优秀的教程和技巧 English++ Project 网道 Docs4dev 古登堡计划（Project Gutenberg）：专门提供公共领域的电子书下载 Project Bartleby：哥伦比亚大学的免费电子图书馆项目 The Labyrinth：中世纪研究 Spark Notes：学习笔记 Voice of the Shuttle：学术资源 Linux 101 掘金翻译计划 前端精读周刊 Linux就该这么学 金步国作品集：Linux KDE 25 年历史年表 KDE UserBase SEL 管理指南 鵝從未在裡面：ubuntu Official Ubuntu Documentation 开源世界旅行手册 书格 Eric S. Raymond 五部曲 开源软件指南 Fedora Project Wiki 如何成为黑客[English]-[Chinese] LibreOffice 中文社区 LibreOffice 简体中文用户文档 Linux Documentation Project Debian 参考手册 Linux工具快速教程 Complete Handbook: Gentoo Arch Linux 安装使用教程 Explanations Linux Wiki 极客手册：Fedora FreeBSD 从入门到跑路 KanCloud Free On-line Linux Technical Books and Tutorials working-on-gnu-linux  Open source project  Gitee：代码托管 Coding：代码托管 Apple Open Source USTC Open Source Software Mirror SourceForge：开源软件下载 OpenDesktop.org  pling xfce-look gnome-look KDE Store   FreshPorts: FreeBSD Ports FOSSHUB：Software Download Hub Welcome to Linux From Scratch!: Build your own custom Linux 超赞的 Linux 软件 GitHub：一个 GitHub 镜像，用于下载大文件 HelloGithub：分享 GitHub 上有趣、入门级的开源项目 GNU mozilla Gnome Debian Ubuntu The Linux Kernel Archives AppImage: Linux apps that run anywhere FLATHUB: the home of hundreds of apps which can be easily installed on any Linux distribution. snapcraft：The app store for Linux makedeb F-Droid：专门收录各类自由软件的 Android 应用商店。 Storybook：Storybook is an open source tool for building UI components and pages in isolation. gitmoji：An emoji guide for your commit messages Track Awesome List Compute Freely openSUSE Build Service：find rpm package for openSUSE and fedora \u0026hellip; StackEdit：科技爱好者周刊所用 \u0026gt;_ .bashrc PS1 generator musicForProgramming fedora SPINS: Alternative desktops for Fedora JSDELIVR：A free CDN for Open Source gentoo portage overlays KDE Applications Internet Archive Online UUID Generator Tool Launchpad：Launchpad is a software collaboration platform Pkgs.org：Packages for Linux and Unix Getdeb die.net  ","permalink":"https://sakamotokurome.github.io/posts/links/","summary":"Portal 信息生产者主要是企业。 OSCHINA：开源资讯 少数派：软硬件使用技巧 Linux 中国：Linux 相关 Distrowatch：Linxu 发行版排行 FreeBSDNews LWN.net:","title":"Links"},{"content":"友邦拓 乌班图\n During the first ten years of this HOWTO\u0026rsquo;s life, I reported that from a new user\u0026rsquo;s point of view, all Linux distributions are almost equivalent. But in 2006-2007, an actual best choice emerged: Ubuntu. While other distros have their own areas of strength, Ubuntu is far and away the most accessible to Linux newbies. Beware, though, of the hideous and nigh-unusable \u0026ldquo;Unity\u0026rdquo; desktop interface that Ubuntu introduced as a default a few years later; the Xubuntu or Kubuntu variants are better.\nEric Steven Raymond - How To Become A Hacker\n 学习 Linux 几点忠告 不要當“傳教士”\n(這點有一個重大弊端：開放軟體沒有商業軟件那樣的宣傳，如果使用者都如此低調，用戶群不會大幅擴展。)\n很多人在討論區不斷的引起的Linux對比Windows之類的討論，甚至爭的面紅耳赤，這是沒有必要的\n這種爭論是浪費時間而沒有任何用處的。對，你花了一下午，用許多事實“捍衛”了Linux比Windows好這個說法。但是Windows的支持者並不會喜歡上Linux的，他們只是稍微退縮一下，然後找一些新的證據來跟你辯論。\n世界上的人們都在利用Linux的研究最前沿的科學，我們還在這裡討論“要不要用Linux的這種無聊的問題，什麼時候才能趕上時代前進的步伐？\n什麼叫做Window支持者，什麼叫做Linux的支持者？我們為什麼要支持某一個而反對另外一個？你不需要為 Linux的護法，不需要成為 Linux的支持者“或者”GNU的傳教士“ GNU / Linux的已經用事實向世界證明了它們的威力，已經被大多數人接受。你只需要安安靜靜享受的GNU / Linux的給你的樂趣和自由。\n你需要關心的不是你的工具是什麼，而是你用它做了什麼。精通的Linux並不說明任何問題，因為它只是一個工具而已。如果你用的Windows能很好的完成你的任務，那你就沒有必要費時間去熟悉Linux操作系統。直到有一天你發現一項任務只有Linux操作系統才能完成的時候再換也不遲，因為你身邊的的Linux的愛好者一定會很樂意的幫助你。\n如果你在使用Linux操作系統的過程中對它產生了感情，那麼你應該明白那些習慣於使用Windows的人也會對Windows產生依賴。類似的爭論還有很多：微軟 Office Word和TeX，Emacs和Vim，Wolfram Mathematica和Maple，侏儒，fvwm的和KDE的時候，狗派\u0026hellip; \u0026hellip;和冷靜地對自己說：“我不站在它們任何一邊。”儘管這有些不容易辦到。\n各人的需要不同，生活的環境不同。對你來說好的東西，對別人來說不一定好，我們需要尊重別人的選擇。如果你當面說別人正在用的程序不好，沒有必要。\n不要強迫自己”\n喜歡電腦的人總是有某些心理強迫傾向。有的人說：“鍵盤比滑鼠快。我不要用滑鼠。這樣才有高效率。”所以他在編輯器裡無論什麼時候總是用20W的，大於 10J這樣的命令到達目的點。他甚至覺得圖形界面是多餘的，乾脆都不裝 Xwindow。\n全部用鍵盤看起來的確比讓手離開鍵盤去拿鼠標，再回來“快”多了，但是快的擊鍵頻率不等於工作的高效率，對你的健康更沒有什麼好處。這只能把你變成打鍵盤的機器。\n當你正在檢查你的文章或者程序，思維正在隨著字符的含義流動，突然為 20W，大於 10J這樣的東西出現在你的腦子裡，是不是會打斷思路？不？那說明你當時思考的問題比較簡單，這些干擾還不會起到副作用。\n其實很多人用電腦的時候，思想都受到某種教學的束縛，上面這個只是教多數種類中的一種。某些人創造了很多這種數學，用他的工作方式來要求別人，嘲笑方式跟他不一樣的人。比如有的人嘲笑其它人寫程序不按ç 8字符縮進，嘲笑別人在六裡用方向鍵，嘲笑別人不知道是什麼增值稅，嘲笑其它人用在Java，C＃這種由地方選區回收內存語言 \u0026hellip; \u0026hellip;\n你不用管各種各樣的教學，電腦只是你的工具，你想怎麼用就怎麼用。沒有人能夠約束你，沒有人可以嘲笑你的工作方式。電腦明天就不再是這個樣子，所以今天你不用完全了解它。你沒有必要知道別人創造的一切，因為你需要留點時間自己創造些東西。只要有樂趣！\n當你下次修改文章的時候，不妨試試悠閒的用滑鼠在你眼睛看到的地方輕輕點一下。\n 如果你發現自己有類似的強迫症，建議去諮詢一下心理醫生。\n 不要“玩”Linux\nLinux的很多人用的時候會感覺很迷茫，該用哪個發行版本呢？是不是我少裝了什麼？怎麼升級這麼快啊！怎麼這麼不穩定！每當遇到新的軟件他就想試用，每當新的版本出現，他就更新，然後用鼠標在新的菜單裡選擇從來沒見過的程序來用用。\n其實你是為了玩Linux而使用Linux操作系統的，而沒有找到正確的理由來利用Linux操作系統。你首先要明確用電腦的目的，你用它是為了解決你的實際問題，而不是為了學習安裝操作系統，不是為了測試哪個版本好用，不是為了“趕上潮流，更不是因為你硬盤太大了，你想多佔點空間。\n如果你啟動了電腦之後不知道應該幹什麼，那麼最好先不要用電腦，因為你可能有更重要的事情需要做。這沒什麼說的。\n不用挑剔發行版本\n很多人剛開始用linux的時候，總是在懷疑別的發行版本是否比自己正在用的這個好，總是懷疑自己以後什麼時候會失去支持，不得不換用別的發行。所以很多人今天是紅帽，明天又換成了Debian的，一會兒又是巴布亞\u0026hellip; \u0026hellip;甚至有的人在一台機器上裝了兩個版本的Linux操作系統，然後比較哪一個好。\n其實你完全沒有必要這樣做，任何發行，只要你熟悉了，你在上面的工作方式幾乎不會受到任何影響。我以前一直用的紅帽，當我有一天在我的一台新機器上安裝Debian時，我發現使用紅帽的經驗完全沒有浪費。我用了一個下午就配置好了Debian，使它服服貼貼的聽我的話，就跟沒有換發行版本一樣。\nDebian，拓林思，SuSE，紅帽，Gentoo\u0026hellip; \u0026hellip;任何一個版本都是不錯的。很多人認為自己攢一個 LFS的是高水平黑客的象徵，但是不是每個人都有精力去了解所有細節。\n不要盲目升級\n不知道這是心理作用還是什麼，有的人看到比較大的版本號，就會很想換成那個。很多人的Redhat的本來配置的很舒服了，可是一旦Redhat的發行新的版本，他們就會盡快下載過來，然後選擇升級安裝。結果很多時候把自己原來修改得很好的配置文件給沖掉了。新的軟件又帶來了新的問題，比如有一次我的rxvt的就升級到2.7.8跟miniChinput衝突了，升級到Redhat的8.0，xmms的發現居然缺省不能放了MP3播放，XFree86的是i810的模塊在啟動上有新的漏洞，Mozilla中，會導致突然退出。\n如果你已經配置好了一切，千萬別再整體升級了，這會浪費你很多很多時間的，不值得。有句話說得好：“如果沒有打破，不解決它。”如果你的程序能夠完成你需要做的事情，你何必升級呢？？？？\n 是的，不論是從論壇還是其他的地方反映出來的大部分都是這個問題，要么比较SUSE和Ubuntu的好，要么比Ubuntu或者Mandriva的好等等的言論。很多人還是把Linux操作系統看成了一個表面的東西。並沒有塌下心來學習 Linux系統。\n 不要配置你不需要的東西\n如果你只想做一個像我這樣的普通用戶，主要目的是用的Linux來完成自己的科研任務和日常工作，那就可以不用系統管理員或者網絡管理員的標準來要求自己，因為當一個系統和網絡管理員確實很辛苦。普通用戶學習那些不經常用到的複雜的維護系統的工具，其實是浪費時間，學了不用是會很快忘記的！\n我不是一個合格的網絡管理員，我的服務器都只設置了我自己需要的功能，設置好ssh連接的ftp已經足夠了，那樣可以省去我很多麻煩。我從來不過度考慮“安全，因為 Linux操作系統缺省已經很安全了。我沒有磁帶機，就不用管tar的那些稀奇古怪的參數了，czf，xzf，ztf已經可以滿足我所有的需要。桑達，awk的，\u0026hellip;我也只會幾種常用的命令行。\n不要習慣的使用根帳號。在需要的時候才用！\n這是很多剛接觸的UNIX類操作系統的人常見的現象，他們不喜歡在管理系統的時候才用，而是一直用根帳號幹所有事情，配置系統，安裝程序，瀏覽網頁，玩遊戲，編程 \u0026hellip; \u0026hellip;\n結果有一天，他不小心在某個系統目錄使用了del * \u0026hellip;後果不堪設想 \u0026hellip; \u0026hellip;\n不要用商業的眼光來看待Linux\nLinux不是商業軟件，所以不要用要求Solaris操作系統，視窗那樣的眼光來看 Linux操作系統。自由軟件的作者們從來不拉攏用戶，他們對用戶不負有任何責任。實際上在自由軟件的世界裡，開發者“和”用戶“並沒有明確的界限，大家是朋友。\n自由軟件很可能只是滿足作者和他的朋友的需要，甚至是為了好玩而創造的。自由軟件不是完美的，自由軟件承認自己有缺點，它不會自吹自擂，蒙蔽“用戶”的耳目。這種對作者責任的解脫激發了作者的創造力，他們不用過分考慮“向上兼容，他們往往比背上重重包袱的商業軟件結構更合理，技術更先進。\n所以當你用某個自由軟件遇到困難的時候，不應該埋怨軟件的作者，因為他們對你並沒有義務。你不應該把自己當成一個挑剔的顧客，而要把自己作為這個軟件的顧問和一個和藹的建議者，這樣你才能理解作者寫這個程序時的快樂，在遇到問題時向作者反映，幫助他完善這個軟件，成為一個快樂的參與者。就像你的哥哥送你一個他用舊了的自行車，你應該珍惜這份友情，而不要在車壞了，或者騎車摔了一跤的時候大罵你的哥哥。如果你真的不能使用這種合作的心態，那麼最好不要使用這個軟件。\n這是一種先進的文化，它包含了互相合作，科學創新的精神。理解這一點不是很容易，很多人往往是因為不能理解這種文化而離開自由軟件。這對於作者來說並沒有什麼損失。\n幹你的正事去\n很多人跟我說，你的網頁浪費我好多時間來配置這配置那，一會兒是fvwm的，一會兒是Mutt中\u0026hellip; \u0026hellip;\n嗯\u0026hellip; \u0026hellip;那些東西都是我有空的時候一點一點積累的，如果你想一次性搞定所有那些東西，恐怕得花你幾個星期甚至幾個月的時間！並不是一定要搞定所有這些東西你才能正常工作的。除非你真的非得利用某個程序，或者你閒著沒事，否則你可以不管這些東西。\n上面幾條僅供參考\n以上只是個人意見，不一定適合所有人。取捨由你了！\nSettings DNS GUI\n 打开设置窗口 如果你连接到了 WiFi 网络，点击“Wi-FI”标签栏。否则，如果你有一个有线连接，点击『Network』标签栏。 选择你要设置 DNS 的网络连接，并且点击齿轮状的按钮，打开网络管理器。 选择 IPv4 设置标签栏。 禁用自动开关，并且输入 DNS 的 IP 地址，用逗号隔开。我们使用 Google DNS 域名解析服务器。 点击“Apply”按钮，保存修改。  这个修改应该会立即有效，除非那些已经缓存了的 DNS 条目。如果你想切换回旧的设置，打开网络管理器，IPv4 设置，并且启用自动开关。\nCLI\n# 显示当前网络连接 $ nmcli connection show # 修改当前网络连接对应的DNS服务器，这里的网络连接可以用名称或者UUID来标识 $ nmcli con mod ens160 ipv4.dns \u0026#34;114.114.114.114 8.8.4.4\u0026#34; # 配置生效 $ nmcli con up ens160 或者\n# Config File $ vi /etc/netplan/01-network-manager-all.yaml network: version: 2 renderer: NetworkManager ethernets: ens3: dhcp4: no addresses: - 192.168.100.199/24 gateway4: 192.168.100.1 nameservers: address: [114.114.114.114, 8.8.4.4] wifis: ... # Apply the changes you made in the config file $ sudo netplan apply # To check if the system successfully applied the changes $ systemd-resolve --status | grep \u0026#39;DNS Servers\u0026#39; -A2 DNS Servers: 114.114.114.114 8.8.8.8 8.8.4.4 注意：您系统上的文件可能缺少整个以太网或 wifi 部分。 在这种情况下，添加缺少的行，确保遵守示例中提供的缩进。\nTesting the Domain Name Resolution Speed\n$ time dig @114.114.114.114 Others  Bluetooth: OFF Formats: United States Blank screen: 10 Night Light: On Touchpad: OFF Fractional Scaling  SoftWare\u0026amp;Updates software-properties-gtk or software-properties-kde\n  Ubuntu Software 栏 Download from 选择 USTC MIRRORS。\n  Other Software 栏下开启 Canonical Partner Repositories (The partner repositories offer access to proprietary and closed-source software)。\n  Ubuntu 自动下载并安装对你的系统至关重要的安全更新。而这个自动更新经常导致你“无法锁定管理目录”错误。在 Updates 栏下选择\n For other packages, subscribe to: All updates Automatically check for updates: Every two weeks When there are security updates: Download and Install automatically When there are other updates: Display immediately Notify me of a new Ubuntu version: For long-term support versions    更新系统:\n$ sudo apt update $ sudo apt upgrade $ sudo apt autoremove   Livepatch: 更新内核不需要 Reboot required 了\n$ sudo ua attach \u0026lt;subscription\u0026gt;   Ubuntu Software \u0026amp; Update 卡在 cache refresh\n通过 apt update 可以看见是 Connecting to security.ubuntu.com Failed，解决办法是更改 /etc/hosts 文件添加其 IP，可通过 EASYCOUNTER 查找：\n## security.ubuntu.com 91.189.88.142 security.ubuntu.com 91.189.88.152 security.ubuntu.com 91.189.91.38 security.ubuntu.com 91.189.91.39 security.ubuntu.com ## archive.canonical.com 91.189.92.150 archive.canonical.com 91.189.92.191 archive.canonical.com 91.189.91.15 archive.canonical.com ## downloads.sourceforge.net 216.105.38.13 downloads.sourceforge.net ubuntu下如何获取源码包和源码\n  在 Software \u0026amp; Updates 中选中 Source code，不要 Reload，因为很慢，在命令行中 update。或者在软件源配置文件 /etc/apt/sources.list 中添加 deb-src 项。\n  获取 xxx 源码包的详细信息\n$ sudo apt-cache showsrc xxx   获取源码包，并将源码包解压到同名目录\n$ sudo apt-get source xxx   Upgrade Ubuntu version\n 打开 Software Updater 更新软件 打开 Software \u0026amp; Updates 选择 Updates 栏，在 Notify me of a new Ubuntu Version 中选择 For any new version 。 打开 Software Updater 更新到新 Ubuntu 版本。 使用 lsb_release -a 确认 Ubuntu 版本。  Input Method Editor 首先在 Language Support 中下载语言包\nIBus ubuntu libpinyin 输入法支持云拼音，只需要开启就可以了。\n搜狗细胞词库\n到hslinuxextra下载sougou-phrases-full.7z。\n经过与ibus开发者协商，ibus-pinyin的词库查找规则做了一些更改，只要在词库目录（就是有一个.db文件的那个目录，一般是/usr/share/ibus-libpinyin/db/目录）把新词库复制过来并改名为local.db就可以使用了，如果感觉词库不好，直接删除掉local.db，就可以让ibus使用原来的词库。\n覆盖以后，你把ibus重启一下ibus-daemon -d -x -r，如果你能打出下面的这个词组，说明生效了：\n弗雷德霍姆行列式 这个词库，基于ibus原有的android词库文件，另外增加了搜狗的细胞词库。\nFcitx 4 在Ubuntu Wayland 桌面中使用fictx管理中文输入法\n$ sudo apt install fcitx -y 设置 fcitx：\n  在 Language Support 中选择 fcitx，全局应用，并恢复 ibus 自定义切换语言快捷键设置。\n  (可选）wayland桌面默认不读取/etc/profile中的环境变量，而是从/etc/environment文件中读取，这是导致fcitx不能正常工作的原因。\n$ sudo vim /etc/environment INPUT_METHOD=fcitx GTK_IM_MODULE=fcitx QT_IM_MODULE=fcitx XMODIFIERS=@im=fcitx   输入法框架：\n 搜狗输入法 for Linux 百度输入法Linux版 Google拼音  其他：\n 百度输入法不能安装用于更换皮肤的 fcitx-ui-qimpanel，否则乱码。需要手动安装 fcitx-libs，否则开机不自动启动。 在 fcitx 与 sogoupinyin 安装完之后，需要重启才能使用。  皮肤：\n fcitx 皮肤：/usr/share/fcitx/skin sogoupinyin 皮肤：/usr/share/sogou-qimpanel/skin。  旧：可以改名为 zip 解压 新：受版权保护    Fcitx 5 安装\n配置工具 KDE 下使用 kde-config-fcitx5， Gnome 下使用 fcitx5-config-qt。\n20.04 (20220122) 官方仓库里没有 Gnome 的配置工具 kcm-fcitx5（内含 fcitx5-config-qt），因此通过 ppa:zhsj/fcitx5 来安装\n$ sudo add-apt-repository ppa:zhsj/fcitx5 $ sudo apt-get update $ sudo apt install fcitx5 fcitx5-chinese-addons 或者也可以通过**通过 flatpak 安装**。\n安装后在 Ubuntu 在 Language Support 里修改输入法系统为 fcitx5，记得点击 Apply System-Wide。\n安装报如下错\nE: Failed to fetch http://103.95.217.6/ppa.launchpad.net/zhsj/fcitx5/ubuntu/pool/main/f/fcitx5-chinese-addons/fcitx5-module-cloudpinyin_5.0.4-1~ubuntu20.04.1~ppa1_amd64.deb 503 Service Unavailable [IP: 103.95.217.6 80] E: Aborting install. 可以在浏览器中打开链接直接下载。\n肥猫百万大词库\nDownload latest version of \u0026ldquo;zhwiki.dict\u0026rdquo; from https://github.com/felixonmars/fcitx5-pinyin-zhwiki/releases\nCopy into ~/.local/share/fcitx5/pinyin/dictionaries/ (create the folder if it does not exist)\n可以在设置中看到是否启用，或者输入 “jinjinjin” 会出现 “鑫”。\nAutomatically switch wallpapers Apps  Shotwell：在侧边栏 Photos 中 Ctrl + A，在菜单栏 File 中选择 Set as Desktop SlideShow\u0026hellip;；这会把图片复制到 .local/share/shotwell/wallpaper，并在该目录生成 wallpaper.xml，wallpaper.xml 定义自动切换壁纸动画。 替代软件： Variety、BingWall 等。 脚本分享：styli.sh、lswc 动态壁纸：komorebi、LiveWallpaper  unsplash   gsettings set org.gnome.desktop.background picture-uri file://$HOME/Wallpaper\n  添加脚本\n$ vi $HOME/.unsplash.sh #!/bin/bash SAVE_DIR=$HOME/DataOne/Unsplash FILE_NAME=daily$(date \u0026#39;+%Y%m%d\u0026#39;).jpeg wget -O $SAVE_DIR/$FILE_NAME https://source.unsplash.com/1920x1080/daily cp $SAVE_DIR/$FILE_NAME $HOME/Wallpaper 在 Unsplash Source 查看更多 API。\n  crontab -e\n0 12 * * * /home/vane/.unsplash.sh   除了使用 crontab 外，还可以使用 Startup Applications Preferences 添加一个启动项。\n  wallhaven   gsettings set org.gnome.desktop.background picture-uri $HOME/Wallpaper\n一般文件内容开头都会有一个文件类型的标记，根据文件名后缀只是一个快捷的方法，不用读取文件内容就判断文件类型，但不是唯一的方法。\n  vi $HOME/.wallhaven/wallhaven.sh\n#!/bin/bash  WORK_DIR=$HOME/.wallhaven SAVE_DIR=$HOME/Pictures/wallhaven IMG_URL=https://w.wallhaven.cc/full function GetListing() { echo \u0026#39;get listing\u0026#39; listing=$(curl https://wallhaven.cc/api/v1/search?apikey=\u0026lt;API KEY\u0026gt;\u0026amp;categories=010\u0026amp;purity=111\u0026amp;atleast=1920x1080\u0026amp;ratios=16x9\u0026amp;sorting=random\u0026amp;order=desc\u0026amp;page=1) echo \u0026#39;save listing\u0026#39; echo $listing | jq -r \u0026#39;.data[].path\u0026#39; | awk -F \u0026#39;/\u0026#39; \u0026#39;{print $NF}\u0026#39; \u0026gt; $WORK_DIR/listing echo \u0026#39;save res\u0026#39; cat $WORK_DIR/listing | wc -l \u0026gt; $WORK_DIR/res SetWallpaper } function SetWallpaper() { if [ -a $WORK_DIR/res ]; then echo \u0026#39;read res\u0026#39; read res \u0026lt; $WORK_DIR/res if [ $res -ne 0 ]; then echo \u0026#39;get img\u0026#39; img=$(cat $WORK_DIR/listing | tail -${res} | head -1) echo \u0026#34;down $imgfrom $IMG_URL/${img:10:2}/$img\u0026#34; curl -o $SAVE_DIR/$img $IMG_URL/${img:10:2}/$img if [ $? -eq 0 ]; then echo \u0026#39;set wallpaper\u0026#39; cp $SAVE_DIR/$img $HOME/Wallpaper echo \u0026#39;res-1\u0026#39; echo $(($res - 1)) \u0026gt; $WORK_DIR/res echo \u0026#39;exit\u0026#39; exit 0 else echo \u0026#39;download error\u0026#39; SetWallpaper fi else echo \u0026#39;res=0\u0026#39; GetListing fi else echo \u0026#39;no res\u0026#39; GetListing fi } SetWallpaper 使用 Shell 脚本来处理 JSON，jq Manual，wallhaven API v1 Documentation\n  crontab -e\n0 12 * * * /home/vane/.wallhaven/wallhaven.sh Gsettings 无法在 Cron 中使用：出现此问题是因为 cron 仅使用一组非常有限的环境变量。 唯一一个负责在将其设置为 cron 作业时以正确方式运行问题脚本的环境变量是 DBUS_SESSION_BUS_ADDRESS。\n  Astronomy #!/bin/bash API_KEY=zTL5rJmctXwHcsjfCSalfDRNFTeaVYa9FxgINVVU HTTP_REQUEST=https://api.nasa.gov/planetary/apod?api_key=$API_KEY HTTP_RESPONSE=$(curl $HTTP_REQUEST) IMG_HDURL=$(echo $HTTP_RESPONSE | jq -r \u0026#39;.hdurl\u0026#39;) IMG_FILENAME=$(echo ${IMG_HDURL##*/}) curl -o $HOME/DataOne/Images/Astronomy/$IMG_FILENAME $IMG_HDURL cp -av $HOME/DataOne/Images/Astronomy/$IMG_FILENAME $HOME/Wallpaper Social Telegram 先通过手机登录，再在电脑端登录。电脑先登录，手机老是收不到验证码。\n简介   Telegram —— 中文名又称\u0026quot;电报\u0026quot;，或简称\u0026quot;TG\u0026quot;。\n  Telegram 是跨平台的即时通信软件，其客户端是自由及开放源代码软件，但服务器是专有软件。\n  Telegram 在中国大陆境内无法直接连接，注册和使用都需要科学上网，请自备节点和工具。\n  下载：Telegram 有官方版和第三方版本，但出于安全和隐私的考虑，推荐大家使用 Telegram 官方版客户端\n  推荐设置  Privacy and Security  Phone Number  谁能看见我的手机号码：Nobody 谁能通过手机号码找到我：My Contacts   Forwarded Messages：Nobody Calls：Nobody Groups：My Contacts   Local Passcode：本地密码只是本设备打开 Telegram 的应用密码 Two-Step Verification：为了账号安全，强烈推荐您设置两步验证密码。 Delete my account：推荐您设置为一年  隐私保护注意事项  资料设置  昵称及用户名：避免使用与其他社交平台相同或相似的昵称及用户名 手机号码：在\u0026quot;设置——隐私——电话号码\u0026quot;中设置\u0026quot;不允许任何人查看我的手机号码\u0026quot;和\u0026quot;仅允许联系人通过手机号码找到我\u0026quot;。   群组聊天：Telegram 的群聊是\u0026quot;不安全\u0026quot;的。 公开群组的所有聊天内容都可被其他人查看，即使他人并未注册 Telegram； 对于群组内的机器人，它们可以收集群组内的绝大部分消息。 媒体文件：在分享照片时，请注意使用专业修图软件打码处理关键信息，并清除照片包含的地理位置信息 分享链接：从其他平台分享内容至 Telegram 时，请注意清除分享链接中的用户 UserID 识别信息，他人完全有可能从您的分享链接中获取您的用户信息。 第三方客户端：如无特殊需要，请使用官方 Telegram 客户端。第三方客户端有能力获取和控制您的账户，读取您全部的聊天记录，收集您设备的可识别信息，包括但不限于：手机号、设备型号、IMEI码、MAC码等。  常见问题及解答  无法给他人发送私聊：“Sorry, you can only send messages to mutual contacts at the momet.”  @SpamBot But I can\u0026rsquo;t message non-contacts！ No，I\u0026rsquo;ll never do any of this   群组和频道有什么类型？有什么特点？  群组(Group)或者频道(Channel)有两种类型。  一种是公开群组(Public Group/Channel) 一种是私有群组(Private Group/Channel)   公开群组(Public Group/Channel) 有自定义设置的ID，所有人可以通过搜索功能，输入id查询到相应的群组。公开群组的历史消息对所有人可见，即使没加入公开群组，也可以查看群组历史消息。 私有群组(Private Group/Channel) 没有自定义的ID，要加入只能通过点击邀请链接或者被邀请入群， 在私有群组，群主可以设定历史消息的可见性。而对于没有加入群组的人，则不可以查看群组的消息。   Telegram 用户名是什么？  其他用户可以通过用户名找到您，您将出现在“全局结果”下的联系人搜索中。这样人们就可以在不知道您的电话号码的情况下通过 Telegram 与您联系。 由于用户名的唯一性，可以防止他人盗用你的头像和昵称冒充你。   如何添加联系人？：添加和删除联系人都是单向操作，对方设备并不会同步。 添加非手机号码联系人后，对方能知道自己的手机号码吗？：如果想取消分享你的手机号，请到隐私设置(Privacy and Security)中找到手机号码(Phone Number)的设置，在里面移除对方即可。 不登陆 Telegram 如何查看频道消息？：Telegram 公开频道可以直接通过浏览器输入 https://t.me/s/频道id 访问，不需要拥有TG账号。  进阶知识 什么是 MTProxy 代理？\n MTProxy 是 Telegram 的官方项目，仅能用于代理 Telegram 软件 MTP 代理是在 Telegram 中内置的代理程序，可以直接在软件内配置，而不需要下载任何其他 App 来配置代理  主题与美化 美化主题频道\n 官方 Desktop 桌面版主题频道 @themes 官方 Android 安卓主题频道 @Androidthemes  在Telegram上使用EFB同时推送QQ与微信消息 众所周知,待机耗电两巨头皆出自TX,但其对于工作人群和大学生而言又是不可或缺的通讯手段.Telegram作为一款合格的IM支持Android众多特性(TX出来挨打),通知栏回复、消息再提醒、自定义震动以及最关键的FCM推送(FCM的特性和优势可以在Google上查询).使用插件利用Telegram来完成QQ微信的消息代收是目前Android系统较优秀的解决方案\n事前准备 物品准备\n 墙外VPS一枚 Telegram账号一枚 稳定的飞机 Xshell(注意不要下载成苏杰马克丁版)/PUTTY 可联网设备一枚,推荐电脑 基本的Linux和vim知识  本教程基于EFB v2.0.0, efb-qq-slave v2.0.0b2, efb-wechat-slave v2.0.0制作,方案为MASTER SLAVE处于同一系统且QQ微信各使用一个 Bot ,使用 Debian 10\n获取 Telegram ID\n向 @get_id_bot 发起会话,击 /start 即可获得你的 Telegram ID\n使用EFB转发微信消息 申请 Telegram Bot\n向 @BotFather 发起会话，发送命令 /newbot 以创建Bot（用户名须以Bot为结尾）\n设置好后还须对bot进行权限设置\n发送 /setprivacy 到 @BotFather，选择刚刚创建好的 Bot 用户名，然后选择 “Disable”.\n发送 /setjoingroups 到 @BotFather，选择刚刚创建好的 Bot 用户名，然后选择 “Enable”.\n发送 /setcommands 到 @BotFather，选择刚刚创建好的 Bot 用户名，然后发送如下内容：\nhelp - 显示命令列表. link - 将聊天链接到群组. unlink_all - 取消所有聊天与群组的链接. info - 显示当前Telegram聊天的信息. chat - 生成聊天对话框. update_info - 更新组名称和资料图片. 安装 EFB 及其从端\n安装相关依赖:\n$ apt install python3 python3-pip python3-pil python3-setuptools python3-numpy python3-yaml python3-requests ffmpeg libmagic-dev libwebp-dev vim -y 安装 EFB :\n$ pip3 install ehforwarderbot efb-telegram-master efb-wechat-slave 创建配置文件\n创建 EFB 配置文件:\n$ mkdir -p ~/.ehforwarderbot/profiles/wx/ $ vim ~/.ehforwarderbot/profiles/wx/config.yaml master_channel: blueset.telegram slave_channels: - blueset.wechat 创建 ETM 配置文件:\n$ mkdir -p ~/.ehforwarderbot/profiles/wx/blueset.telegram $ vim ~/.ehforwarderbot/profiles/wx/blueset.telegram/config.yaml token: \u0026#34;123456\u0026#34; #值为你在 @BotFather 处获得的 bot token admins: - 123456 #值为你在 @get_id_bot 处获得的 chat id 创建 EWS 配置文件:\n$ mkdir -p ~/.ehforwarderbot/profiles/wx/blueset.wechat $ vim ~/.ehforwarderbot/profiles/wx/blueset.wechat/config.yaml 其内容参见可选的配置文件，根据文档配置即可。\n输入ehforwarderbot --profile wx,扫码登录即可收发消息,使用screen命令保存后台\n使用EFB转发QQ消息 申请 Telegram Bot\n向 @BotFather 发起会话，发送命令 /newbot 以创建Bot（用户名须以Bot为结尾）\n设置好后还须对bot进行权限设置\n发送 /setprivacy 到 @BotFather，选择刚刚创建好的 Bot 用户名，然后选择 “Disable”.\n发送 /setjoingroups 到 @BotFather，选择刚刚创建好的 Bot 用户名，然后选择 “Enable”.\n发送 /setcommands 到 @BotFather，选择刚刚创建好的 Bot 用户名，然后发送如下内容：\nlink - 将会话绑定到 Telegram 群组. chat - 生成会话头. recog - 回复语音消息以进行识别. extra - 获取更多功能. 安装 EFB 及其从端\n$ apt-get install libopus0 ffmpeg libmagic1 python3-pip git nano docker.io libssl-dev python3-dev build-essential #安装相关依赖 $ pip3 install efb-telegram-master #安装 EFB $ pip3 install -U git+https://github.com/milkice233/efb-qq-slave $ pip3 install git+https://github.com/milkice233/efb-qq-plugin-iot 创建配置文件\n创建 EFB 配置文件:\n$ mkdir -p ~/.ehforwarderbot/profiles/qq/ $ vim ~/.ehforwarderbot/profiles/qq/config.yaml master_channel: blueset.telegram slave_channels: - milkice.qq 创建 ETM 配置文件:\n$ mkdir -p ~/.ehforwarderbot/profiles/qq/blueset.telegram $ vim ~/.ehforwarderbot/profiles/qq/blueset.telegram/config.yaml token: \u0026#34;123456\u0026#34; #值为你在 @BotFather 处获得的 bot token admins: - 123456 #值为你在 @get_id_bot 处获得的 chat id IOT 部分:\n$ wget https://github.com/opq-osc/OPQ/releases/download/v6.0.20/OPQBot_6.0.20_darwin_amd64.tar.gz #根据需要版本自行更改链 启动需要到Gitter获取token并填入CoreConf.conf文件\n如果需要更改API的端口请更改Port (例如更改成2333端口,就改成Port = “0.0.0.0:2333”)\n进入到文件目录 执行命令\nscreen -S iot ./OPQBot #输入完毕后 Ctrl+A+D  登录请 等待控制台输出Everything is ok!后 再用浏览器访问 http://IP:PORT/v1/Login/GetQRcode (IP为你机子的内网ip或者公网ip,PORT为你上一步更改的端口,默认8888\n然后用手机扫码登录,不支持帐号密码登陆\n创建 EQS 配置文件\n$ mkdir -p ~/.ehforwarderbot/profiles/qq/milkice.qq $ vim ~/.ehforwarderbot/profiles/qq/milkice.qq/config.yaml Client: iot iot: qq: 1234567890 # 此处填写登录的QQ号 host: \u0026#34;http://127.0.0.1\u0026#34; # 默认IP为本地 port: 8888 # 默认端口为 8888 receive_self_msg: False # 不接收自己发出的消息 输入ehforwarderbot --profile qq 即可,同样可以使用screen命令保存后台\n问题发现及解决方案   提示错误: efb-wechat-slave 2.0.0 has requirement requests\u0026gt;=2.22.0, but you'll have requests 2.21.0 which is incompatible.\n输入 pip3 install requests==2.22.0 解决\n  升级相关组件输入 pip3 install --upgrade efb-qq-slave efb-wechat-slave efb-telegram-master\n  参考链接 安装并使用 EFB：在 Telegram 收发 QQ 消息 - Milkice’s IceBox\n在 Telegram 上实现微信收发，EHForwarderBot 搭建记录 - Eliot’s Blog\nEFB WeChat Slave Channel：EFB 微信从端 (EWS) - bluesethttps://linux.cn/article-12826-1.html\nMutt Mutt 是一个基于文本的邮件客户端，因其强大的功能而闻名。 Mutt虽然已诞生二十多年了，但仍然是大量用户的首选邮件客户端。\nMutt主要侧重于作为邮件用户代理（MUA），最初是为了查看邮件而编写的。 与其他邮件应用程序相比，稍后实现的功能（检索，发送和过滤邮件）比较简单，因此用户可能希望使用外部应用程序来扩展Mutt的功能。\n模块搭配方案 就像穿衣搭配一样，收件发件过滤邮件转发邮件各种功能都有很多种程序可以用，mutt怎么搭配呢？\n常用选项有这些(User/Transport/Delivery)：\n MUA 收件：fetchmail或getmail或OfflineIMAP MTA 发件：sendmail或msmtp或postfix。其中msmtp兼容强，postfix对国内不友好 MDA 分类: procmail或maildrop 邮件编辑：VIM。  一般搭配是：\n 老式搭配：mutt + getmail + sendmail + procmail 新式搭配：mutt + fetchmail + msmtp + maildrop  这里我们用：mutt + fetchmail + msmtp + procmail\n安装：\n$ sudo apt install mutt fetchmail msmtp procmail -y Mutt或各个写协作程序在配置前都是不能使用的，学习曲线还是比较陡峭的，所以要做好准备去花好一段去了解和学习各个部件。\n大概的配置流程是：\n 配置收件：~/.fetchmailrc 配置过滤：~/.procmailrc 配置发件：~/.msmtprc 配置mutt框架本身：~/.muttrc  注意：初学过程中，不要一上来就配置mutt。最好是先从各个部件开始：收件-\u0026gt;过滤邮件-\u0026gt;阅读邮件-\u0026gt;发件-\u0026gt;mutt界面，按照这种顺序。\n收件：配置Fetchmail  Fetchmail是由著名的《大教堂与集市》作者 Eric Steven Raymond 编写的。\n Fetchmail是一个非常简单的收件程序，而且是前台运行、一次性运行的，意思是：你每次手动执行fetchmail命令，都是在前台一次收取完，程序就自动退出了，不是像一般邮件客户端一直在后台运行。\n注意：fetchmail只负责收件，而不负责存储！所以它是要调用另一个程序如procmail来进行存储的。\nfetchmail的配置文件为~/.fetchmailrc。然后文件权限最少要设置chmod 600 ~/.fetchmailrc\n比如我们要设置多个邮箱账户同时收取，那么配置如下：\npoll pop.AAA.com protocol POP3 user \u0026#34;me@AAA.com\u0026#34; password \u0026#34;123\u0026#34; poll pop.BBB.com protocol POP3 user \u0026#34;me\u0026#34; there with password \u0026#34;123\u0026#34; is falko here fetchall poll pop.CCC.com protocol POP3 user \u0026#34;me\u0026#34; there with password \u0026#34;123\u0026#34; is till here keep poll pop.DDD.com protocol POP3 user \u0026#34;me\u0026#34; password \u0026#34;123\u0026#34; ## QQ 邮箱 poll pop.qq.com port 995 protocol POP3 user \u0026#34;1664548605@qq.com\u0026#34; password [授权码] ssl keep # 全局选项 mimedecode # 不加 -d %T 就会报 ~/Mail/inbox is not a mailbox. 错误 mda \u0026#34;/usr/bin/procmail -d %T\u0026#34; 其中：\n 各种参数可以不按顺序，也可以不在一行。 空格隔开每个参数，poll隔开每个账户。 here, there, with, is等等，都不是关键词，随便写不影响参数。 以下是必填  poll后面是邮件服务器的地址，一般是pop.xxx.com protocol后面是收件协议，一般是pop或pop3 user后面是用户名，可以是username，也可以是邮箱地址 password后面是密码   sslproto：可能会报错 fetchmail: pop.qq.com: upgrade to TLS failed.，故可以禁掉SSL，同 man 手册查到  加上option --nosslcertck，虽然有报错，但至少可以收邮件了。 加--sslprotocl '', 注意要用空字符串   四选一：  nofetchall ：仅检索新消息（默认）。 fetchall ：获取所有消息，无论是否看到。 keep ：不要从服务器上删除看到的消息。 nokeep ：从服务器中删除看到的消息。   mimedecode用来自动解码MIME mda后面指定本机安装的邮件过滤分类程序。如果不填，则收取的邮件在本地不会保存。注意用which procmail查一下路径。 QQ 邮箱客户端设置 Outlook 设置：失败了  配置完成后，可以运行fetcmail -v来看看是否有错误信息，如果能够正常显示很多行的收取信息，那么就能正确登录邮箱收取了。\n一般收取的命令如下：\n# 只收取未读邮件 $ fetchmai # 收取所有邮件 $ fetchmail -a # （重要）收取新邮件，但不在服务器端删除已经收取的邮件 $ fetchmail -k 但是fetchmail只负责收取，不负责“下载”部分，你找不到邮件存在哪了。 所以还需要配置MDA分类器，如procmail，才能看到下载后的邮件。\n注意：Fetch其实不是在Mutt“里”使用的，而是脱离mutt之外的！也就是说，Mutt只负责读取本地存储邮件的文件夹更新，而不会自动帮你去执行fetchmail命令。\n你必须自己手动执行，或者用Crontab定期收取，或者设为Daemon守护进程，还可以在Mutt中设置快捷键执行Shell命令：\n  要使fetchmail作为守护进程运行，我们必须编辑/etc/default/fetchmail并将START_DAEMON设置为yes\n$ vi /etc/default/fetchmail START_DAEMON=yes 接下来，必须创建配置文件/etc/fetchmailrc并设置 set daemon 300 （这意味着fetchmail应该每300秒检索一次电子邮件）。\n  设置Mutt快捷键收取邮件的方法是在~/.muttrc中加入macro：\nmacro index,pager I \u0026#39;\u0026lt;shell-escape\u0026gt; fetchmail -vk\u0026lt;enter\u0026gt;\u0026#39; 这样的话，你就可以在index邮件列表中按I执行外部shell命令收取邮件了。\n  邮件过滤：配置Procmail Procmail是单纯负责邮件的存储、过滤和分类的，一般配合fetchmail收件使用。\n在Pipline中，fetchmail把收到的邮件全部传送到Procmail进行过滤筛选处理，然后Procmail就会把邮件存到本地形成文件，然后给邮件分类为工作、生活、重要、垃圾等。\n当然，分类规则是自己可以指定的。可以根据发信人、主题、长度以及关键字 等对邮件进行排序、分类、整理。\nProcmail 的配置文件是 ~/.procmailrc ，记得改权限：chmod 600 ~/.procmailrc。\n内容也非常简单，前面是邮件位置、日志等默认选项，后面则是一块一块的过滤规则。\n基本配置：\n# 邮件存储地址 MAILDIR=$HOME/Mail # 默认：收件箱 DEFAULT=$MAILDIR/inbox VERBOSE=off LOGFILE=/tmp/procmaillog # 某个垃圾邮件规则 :0 * ^From: webmaster@st\\.zju\\.edu\\.cn # 垃圾文件的存储位置 /dev/null # 其它所有都存到收件箱中 :0: inbox/ 其中，$HOME/Mail是设定的邮件存储位置。\n我们需要手动创建mkdir ~/Mail，否则程序会报错。\n配置好后，我们再测试一下就会看到：\n$ fetchmail -a 78 messages for 1664548605@qq.com at pop.qq.com (2843793 octets). reading message 1664548605@qq.com@pop.qq.com:1 of 78 (36692 octets) not flushed ... $ tree ~/Mail /home/vane/Mail └── inbox 0 directories, 1 file $ du -h Mail/inbox 2.1M\tMail/inbox 可以看到，所有邮件都保存在了inbox这个单一文件中。这个文件可以打开看到MIME格式(协议)的邮件源码。就像HTML一样，展示给我们的和背后的源码不一样。\n那么怎么把这个类似HTML的MIME格式邮件解析为我们人能读懂的内容呢？——这个我们就要靠mutt自己了，mutt自身具备基本的MIME邮件解析功能（不包括HTML格式邮件读取）。\n发件：配置msmtp msmtp是作为sendmail发邮件程序更好的替代品。\nmsmtp的配置文件为~/.msmtprc，记得改权限：chmod 600 ~/.msmtprc\n配置内容比收件还简单，因为发件永远比收件简单。\n基本配置：\naccount default auth login host smtp.XXX.com port 587 from ME@XXX.com user ME password passwd # 关于tls，如果是阿里云则不用写，如果是Outlook的话，必须写 tls on tls_starttls off tls_certcheck off # QQ 邮箱例子 account default # QQ邮箱这里必须是 on，否则会 535 Login Fail auth on host smtp.qq.com port 587 from 1664548605@qq.com # user 必须是 @ 之前的部分，不能自定义，否则会 535 Login Fail user 1664548605 password [授权码] tls on tls_starttls off tls_certcheck off logfile /tmp/msmtp.log QQ 邮箱例子：使用mutt+msmtp在Linux命令行界面下发邮件。\n总之，哪怕QQ 邮箱设置对了，也要多试几次才能发送成功。\n主界面：配置Mutt Mutt的配置文件为~/.muttrc，记得改权限：chmod 600 ~/.muttrc\n另外：mutt的配置文件还可以放在~/.mutt/muttrc。这种方法有一个好处，即~/.mutt/目录下可以放很多主题、插件等文件。\n基本配置：\n# 通用设定 set use_from=yes set envelope_from=yes #移动已读邮件 set move=yes #回复的时候调用原文 set include set charset=\u0026#34;utf-8\u0026#34; #自动显示HTML auto_view text/html # 发送者账号 set realname=\u0026#34;Vane Hsiung\u0026#34; set from=\u0026#34;1664548605@qq.com\u0026#34; # 分类邮箱 #Mail box type set mbox_type = Maildir set folder = \u0026#34;$HOME/Mail\u0026#34; #INBOX set spoolfile = \u0026#34;$HOME/Mail/inbox\u0026#34; #Seen box set mbox=\u0026#34;$HOME/Mail/seen\u0026#34; #Sent box set record=\u0026#34;$HOME/Mail/sent\u0026#34; #Draft box set postponed=\u0026#34;$HOME/Mail/draft\u0026#34; # 关联程序（需要自己用which命令确定一下） # 默认使用 nano set editor=\u0026#34;vim\u0026#34; set sendmail=\u0026#34;/usr/bin/msmtp\u0026#34; 以上如果有什么问题，可参考etchmail + proc + msmtp + mutt configuration samples。\n确认邮箱服务器 即使上面配置一切OK，也不一定能正常收发邮件。因为你用的Gmail、QQ、网易、阿里云等等，后台都有一系列的第三方收取设置。这是各不相同的。\n除了第三方客户端的允许，我们还要设置POP。最好放开全部邮件或者最近30天，然后禁止客户端删信。这是什么意思呢？POP默认客户端在收件后，服务器上的邮件就自动删除了！这个不太合适，所以必须要禁止。\n基本操作 邮件列表操作：\n 基本：q:Quit, d:删除当前邮件, s:将邮件移动至指定文件夹, m:创建新邮件, r:回复当前邮件, ?:帮助 移动：j/k 上下移动邮件, z/Z上下翻页, \u0026lt;Number\u0026gt; 跳至序号处（不进入邮件） \u0026lt;Enter\u0026gt; 打开选中的邮件 /在当前文件夹搜索 d 将选中邮件标记为删除, N 将选中邮件标记为未读, $ 让标记的东西生效，如删除、未读等。 f 转发选中邮件, e 编辑选中邮件 c切换文件夹(inbox/seen/draft等), 需要输入文件夹名称，或按?在列表里选择，j/k上下移动。  在邮件中的操作：\n j/k 上一封／下一封邮件, \u0026lt;Space\u0026gt;: 向下翻页, \u0026lt;Enter\u0026gt;: 向下滚动 e 编辑当前邮件, t编辑TO，c编辑CC，b编辑BCC，y发送邮件，a添加附件，Return查看附件，E编辑附件，D删除附件  使用命令操作：\nMutt如同Vim一样，不光可以把命令绑定为快捷键，还能直接输入:直接输入命令。 但是稍有不同的是，Mutt称之为Action，而且需要用:exec \u0026lt;命令\u0026gt;这样格式执行。\n比如sidebar侧边栏的移动，命令是：sidebar-next, sidebar-prev。 那么我们可以直接输入:exec sidebar-next，按下回车执行。\nIRC 简介 芬兰人雅尔可·欧伊卡利宁（Jarkko Oikarinen）于1988年8月创造了IRC来取代一个叫做MUT的程序。\n IRC（Internet Relay Chat的缩写，“因特网中继聊天”）是一个位于应用层的协议。 其主要用于群体聊天，但同样也可以用于个人对个人的聊天。 一个IRC服务器可以连接其他的IRC服务器以扩展为一个IRC网络。 IRC 不强制注册；但如果你注册了，就可以强制把占用自己唯一 ID 的人踢下线。 IRC 协议简单，开源实现多，其第三方机器人程序非常众多，几乎每种语言都有一个实现。 IRC 是开源社区会议标准；因此，许多开源世界的技术大牛混在那里。  irchelp：一个致力于帮助用户了解IRC的网站。\nIRC：Linux文档项目的IRC HOWTO\n服务器 首先要区分一些概念：\n Networks：是指的互相隔离的网络，如Freenode和DALnet这些是世界知名的网络，但互相隔离，频道不共享。 Servers：Network网络中的某一台电脑服务器，你加入世界上任何一个server都能加入这个Network。IRC是一个分布式的客户端/服务器结构。通过连接到一个IRC服务器，我们可以访问这个服务器以及它所连接的其他服务器上的频道（即这个 Network 中所有频道）。  频道存在于一个IRC服务器上。一个频道类似于一个聊天室，频道名称必须以#符号开始，例如#irchelp。\n要使用IRC，必须先登录到一个IRC服务器上，最常见的为irc.freenode.net——最大的IRC网络，为免费和开源软件社区，非营利组织和相关社区提供讨论设施。\nFreenode 用户模式。\nIRC使用的服务器端口有:\n 6667（明文传输，如irc://irc.freenode.net） 6697（SSL加密传输，如ircs://irc.freenode.net:6697）。  IRCD: 简称互联网中继聊天守护，是服务器软件实现了IRC 协议，使人们通过上网彼此交谈（交换文本即时消息）。\n客户端 IRC用户透过客户端软件和服务器相连。\nInternet Relay Chat客户端的比较：\n   Client Homepage Description     Irssi https://irssi.org/ 支持IPv6的模块化文本UI IRC客户端。轻量级流行客户端。   WeeChat https://weechat.org/ 便携式和多接口（文本，Web和GUI）IRC客户端。    Irssi 安装\n$ apt install irssi 命令行输入irssi即进入了聊天室。\n和一般Linux程序的一般命令、格式都不同，IRC客户端一般有自己的命令。窗口右下方[(status)]是输入命令的地方。\n一般命令(不区分大小写)：\n /quit，退出程序。一般的ctrl-c, ctrl-d, esc, q之类的都不管用 /help，帮助 /network list 查看已保存的服务器列表 /connect xxx.xxx.xxx 连接某服务器。连接 freenode，需要到 https://irc.com/login/sso 注册，然后按照 https://freenode.net/kb/answer/sasl 进行设置。 /join xxx 加入某channel /leave或/part 离开当前channel /normal或/n 查看当前channel的人数 /list -YES 查看当前服务器的所有chennels (慎用) /nick NewNickName 更改当前昵称 /msg NickName Content 给某人发送消息，一般都是给/msg nickserv管理人NPC发送消息  常用快捷键：\n Alt + 1/2/3/4...，切换window窗口，一般一个channel一个窗口 Alt + n/p，上下滚动屏幕  IRC 常用缩写词\n配置\n如果想长期保存、备份一个固定的程序配置，那么就需要修改配置文件。\nirssi默认的配置文件为~/.irssi/config。\n配置中，会在第一次运行时就自动设置了一些，包括根据当前电脑账户的用户名设置nickname等。整个配置，是一直“类似”JSON的格式。\nsettings ：记录自己的名字：nick, real_name, user_name\nservers ：这是指的Network而不是具体某台server，如Freenode、Dal、ESPer、EFnet等大型网络。服务器配置案例：\nservers = ( { address = \u0026#34;irc.dal.net\u0026#34;; chatnet = \u0026#34;DALnet\u0026#34;; port = \u0026#34;6667\u0026#34;; }, { address = \u0026#34;路径\u0026#34;; chatnet = \u0026#34;下面chatnet对应的名称\u0026#34;; port = \u0026#34;端口\u0026#34;; autoconnect = true; use_ssl = \u0026#34;yes\u0026#34;; password = \u0026#34;用户名:密码\u0026#34;; } ); chatnets：记录各个网络的登录信息，也可以作为“别名”，这样每次/connect不用输入全路径了。配置完每个服务器后，还要配置相应的chatnets，每一条的名称都要与servers中的对应。\nchatnets = { DALnet = { type = \u0026#34;IRC\u0026#34;; max_kicks = \u0026#34;4\u0026#34;; max_msgs = \u0026#34;20\u0026#34;;max_whois = \u0026#34;30\u0026#34;; }; Freenode = { type = \u0026#34;IRC\u0026#34;; max_kicks = \u0026#34;4\u0026#34;; max_msgs = \u0026#34;20\u0026#34;;max_whois = \u0026#34;30\u0026#34;; autosendcmd = \u0026#34;/msg nickserv identify MyName MyPassword\u0026#34;; }; }; channels ：记录自己收藏的频道名。RC的频道不是用URL之类很复杂的东西，全都是用#tag这种简单一个标签来区分的，非常好记。\nchannels = ( { name = \u0026#34;#lobby\u0026#34;; chatnet = \u0026#34;EsperNet\u0026#34;; autojoin = \u0026#34;No\u0026#34;; }, { name = \u0026#34;#freenode\u0026#34;; chatnet = \u0026#34;Freenode\u0026#34;; autojoin = \u0026#34;No\u0026#34;; }, ); statusbar：界面美化的设置。目前IRSSI的世界里，唯一知名的主题只有weed。\nMultimedia Pipewire 从 Pulseaudio 切换到 Pipewire 的理由是对于蓝牙的“LDAC”“APTX”之类编码格式的支持\nRhythmbox Music\n搜 \u0026ldquo;无损音乐\u0026rdquo; \u0026ldquo;车载音乐\u0026rdquo; 打包下载。\n电台\n很多电台是基于mms协议的，如果rhythmbox无法播放mms协议的电台，则需要安装支持mms协议的gstreamer插件——因为rhymbox使用gstreamer做后台解码。支持mms协议的插件为gstreamer bad插件，所以执行命令：\n$ sudo apt-get install gstreamer0.10-plugins-bad 同样的，如果需要播放mp3文件则安装ugly插件，需要播放wma文件则安装ffmpeg插件。\n电视台和电台MMS地址\n分享Rhythmbox电台列表\n最终还是没什么无法播放mms，因为 Rhythmbox 报错了。\nFeelUOwn FeelUOwn 是一个稳定、用户友好以及高度可定制的音乐播放器。\nSpotify 作为世界上最大的音乐流媒体服务商，Spotify 因优秀的设计和精准的音乐推荐算法让不少人为之倾心。\n在正式注册 Spotify 之前，我们先来看一看曲库的问题。由于不同地区的歌曲版权差异，Spotify 在不同地区提供服务时，其相应的曲库也有所不同。例如港区的曲库中，粤语歌就要比美区多，相反美区的英文歌就要比港区多。同理，若你喜欢听其他语种的歌，注册当地的 Spotify 则是最好的选择。\n注册后要是发现当前的地区选择并不是很理想，想要换区也是可行的。首先要挂上自己想要换到地区的代理，然后进入自己的「Profile/资料」界面，点击「Edit Profile/修改资料」，「Country/国家」这个选项就会出现你当前所挂代理地区，保存更改即可换区成功。\n登录的话，需要先在登录界面设置Proxy重启。登录后在设置里改回来，不再需要Proxy了。\nSpotifyd An open source Spotify client running as a UNIX daemon.\nNeteaseMusic Linux 下官方只发布了 deb 包，flatpak 直接安装\nYesPlayMusic 高颜值的第三方网易云播放器\nNetEase-MusicBox 网易云音乐命令行版\nlx-music-desktop 一个基于 electron 的音乐软件\nlisten1_desktop one for all free music in china\nQQMusic PulseAudio PulseAudio 是在GNOME 或 KDE等桌面环境中广泛使用的音频服务。它在内核音频组件（比如ALSA 和 OSS）和应用程序之间充当代理的角色。\n配置 Pulseaudio 支持通过多种模块扩展其功能。在这里可以找到PulseAudio可用的模块的详细信息： Pulseaudio Loadable Modules。增加 load-module \u0026lt;module-name-from-list\u0026gt; 到文件 /etc/pulse/default.pa就可以启用对应的模块。\n启动 警告： 如果你给每个用户拷贝了配置文件（例如client.conf, daemon.conf 或者 default.pa）到~/.config/pulse/ 或者 ~/.pulse/目录下，确定这些文件的修改与/etc/pulse/下的文件修改同步，否则PulseAudio可能由于配置文件错误而拒绝启动。\n注意： 大多数X11环境会在启动X11会话时自动启动PulseAudio。\n少数情况下PulseAudio在启动X11时没有自动启动，可运行下面的命令启动：\n$ pulseaudio --start 运行下面的命令可以终止PulseAudio：\n$ pulseaudio --kill 在不支持的桌面环境中自动启动 注意： 正如之前所说, 如果用户安装了桌面环境，PulseAudio很可能通过 /etc/X11/xinit/xinitrc.d/pulseaudio文件或者 /etc/xdg/autostart/目录下的文件自动启动\n查看PulseAudio是否正在运行：\n$ pgrep -af pulseaudio 369 /usr/bin/pulseaudio 如果PulseAudio未运行而且用户正在使用X11，运行下面的命令可以在启动PulseAudio的同时加载需要的X11插件：\n$ start-pulseaudio-x11 如果你没有运行GNOME, KDE或者Xfce，并且你的~/.xinitrc文件并未引用/etc/X11/xinit/xinitrc.d目录下的文件内容，为了让PulseAudio自动启动，你可以这样做：\n~/.xinitrc /usr/bin/start-pulseaudio-x11 后端设置 ALSA 配置ALSA与PulseAudio共同工作必须的文件/etc/asound.conf。\n为了防止应用程序使用ALSA的OSS模拟功能而忽略PulseAudio（从而导致其他应用程序无法播放声音），确定snd_pcm_oss模块没有在系统启动时自动加载。如果该模块已经被加载(lsmod | grep oss)，运行下面命令以卸载该模块：\n# rmmod snd_pcm_oss 均衡器 PulseAudio内置了10段均衡器系统，按下列步骤操作以启用均衡器：\n加载均衡器通道和dbus协议模块 $ pactl load-module module-equalizer-sink $ pactl load-module module-dbus-protocol 安装并运行图形前端 $ sudo apt install pulseaudio-equalizer $ qpaeq 每次启动时加载均衡器和dbus模块 编辑 /etc/pulse/default.pa 并加入下面几行：\n### Load the integrated PulseAudio equalizer and D-Bus module load-module module-equalizer-sink load-module module-dbus-protocol FFmpeg  powershell 执行与在 cmd 执行不一样，poweshell 某些 -c:v 会报错 ffmpeg 输出参数含义  frame: 编码的帧数量 fps：每秒编码的帧数 q：质量因子 size/ Lsize：视频和音频编码后的大小，即基本等于视频和音频 之和 time：输出帧的显示时间 bitrate：输出视频的比特率 dup：输入帧重复（duplicate）的数量 drop：输入帧丢弃（drop）的个数 speed：编码速度    视频文件本身其实是一个容器（container），里面包括了视频和音频，也可能有字幕等其他内容。\n视频和音频都需要经过编码，才能保存成文件。不同的编码格式（CODEC），有不同的压缩率，会导致文件大小和清晰度的差异。\n编码器（encoders）是实现某种编码格式的库文件。只有安装了某种格式的编码器，才能实现该格式视频/音频的编码和解码。\nFFmpeg 的命令行参数非常多，可以分成五个部分：\n$ ffmpeg [全局参数] [输入文件参数] -i 输入文件 [输出文件参数] [输出文件] 常用参数  -c：指定编码器 -c copy：直接复制，不经过重新编码（这样比较快） -c:v：指定视频编码器 -c:a：指定音频编码器 -i：指定输入文件 -an：去除音频流 -vn： 去除视频流 -preset：指定输出的视频质量，会影响文件的生成速度，有以下几个可用的值 ultrafast, superfast, veryfast, faster, fast, medium, slow, slower, veryslow。 -y：不经过确认，输出时直接覆盖同名文件。  查看视频文件的元信息 $ ffmpeg -i input.mp4 -hide_banner 转换编码格式 $ ffmpeg -i [input.file] -c:v libx264 output.mp4 转成 H.264 编码，一般使用编码器 libx264\n转换容器格式 $ ffmpeg -i input.mp4 -c copy output.mkv 改变分辨率 $ ffmpeg -i input.mp4 -vf scale=720:-1 output.mp4 提取视频 $ ffmpeg -i input.mp4 -an -c:v copy ouput.mp4 -vcodec codec 强制使用codec编解码方式。如果用copy表示原始编解码数据必须被拷贝。\n提取音频 $ ffmpeg -i input.mp4 -vn -c:a copy output.aac -c:a copy表示不改变音频编码，直接拷贝。\n添加音轨 $ ffmpeg -i input.aac -i input.mp4 output.mp4 音视频合成 $ ffmpeg -i video.mp4 -i audio.aac -c:v copy -c:a copy output.mp4 截图 从指定时间开始，连续对1秒钟的视频进行截图\n$ ffmpeg -y -i input.mp4 -ss 00:01:24 -t 00:00:01 output_%3d.jpg 指定只截取一帧\n$ ffmpeg -ss 01:23:45 -i input.mp4 -vframes 1 -q:v 2 output.jpg -vframes 1指定只截取一帧，-q:v 2表示输出的图片质量，一般是1到5之间（1 为质量最高）。\n裁剪 $ ffmpeg -ss [start] -i [input] -t [duration] -c copy [output] $ ffmpeg -ss [start] -i [input] -to [end] -c copy [output] 裁剪（cutting）指的是，截取原始视频里面的一个片段，输出为一个新视频。可以指定开始时间（start）和持续时间（duration），也可以指定结束时间（end）。\n添加字幕  外挂字幕：一个单独的外部字幕文件，格式类型一般有srt、vtt、ass等等。播放视频时，需要把外挂字幕和视频放在同一目录下，并在播放器中选择字幕文件才可以在视频中看到字幕。 软字幕：也叫内挂字幕、封装字幕、内封字幕，字幕流等，就是把前面的外挂字幕的字幕文件嵌入到视频中作为流的一部分，如果一个视频有多个字幕流那么播放视频是还得选择对应的字幕流 硬字幕：是嵌入到视频帧里面的字幕，它就像视频水印一样作为视频帧的一分部分了，不管再任何平台字幕看起来都是一样的，而且也不再要求播放器单独对字母进行渲染  常见的字幕格式有：\n SRT（标准外挂字幕格式）：只包含文字和时间码，没有样式，显示效果由播放器决定，不同的播放器显示出的效果可能差别很大。 ASS（高级外挂字幕格式）：支持样式、字体、字幕定位、淡入淡出、简单的特效。如果不缺字体，不同的播放器显示效果基本一致。  ffmpeg字幕处理流程(容器是否支持字幕流指的是输出容器)\n添加软字幕：\n$ ffmpeg -i video.mp4 -i subtitle.srt -c copy output.mkv 软字幕只有部分容器格式比如(mkv)才支持，MP4/MOV等不支持，而且也只有部分播放器支持软字幕或者外挂字幕(如VLC播放器)。\n添加多个字幕：\nffmpeg -i input.mp4 -i zh_CN.srt -i en_US.srt -map 0:v -map 0:a -map 1 -map 2 -c:v copy -c:a copy -metadata:s:s:0 language=chn -metadata:s:s:1 language=eng \u0026#34;output.mp4\u0026#34;  -map 是轨道参数，如果只有一个字幕，就不需要这个参数。-map 0:v 表示第一个文件输入视频轨道，-map 0:a 表示第二个轨道是第一个文件输入的音频轨道，-map 1 建立第三个轨道，-map 2 建立第四个轨道。如果没添加 map 参数，默认就只有一个字幕轨道，第二个英文字幕会覆盖第一个中文字幕轨道。 -metadata:s:s:0 language=chn 第一条字幕的语言设置为中文，-metadata:s:s:1 language=eng 第二条字幕的语言设置为英文。 language 不能自定义，只能设置成固定的缩写。  添加硬字幕：\n$ ffmpeg -i video.mkv -vf subtitles=subtitle.srt out.mp4 下载 m3u8 现在比较常见的视频流媒体，大部分都是 m3u8 格式的，而对于 m3u8 格式的视频而言，如果你下载过，你会发现它就是一个文本文件，大概也就只有几十 kb，从磁盘大小来看，应该也知道它并不是一个直接的视频文件。\n什么是 m3u8\n说到 m3u8 就要先说说 HLS（HTTP Live Streaming）。HLS 是 Apple 公司针对 iPhone、iPod、iTouch 等移动设备，而研发的基于 HTTP 协议的流媒体解决方案。在 HLS 技术中，Web 服务器可以向客户端提供接近实时的音视频流，但是它又是使用的标准的 HTTP 协议。所以基本上，比较大型的点播直播类服务，都是基于 HLS 的。\n而该技术的原理，就是将视频文件或者视频流，进行切片（ts文件），并建立索引文件（m3u8），它支持的视频流编码为 H.264，音频流编码为 AAC。\n简单来说，基于 HLS 的视频流，会将完整的视频，切割成一个个比较小的视频片段（ts 文件），然后根据协议组合成一个 m3u8 文件。这些比较小的 ts 文件，是可以单独播放的。而视频播放器，拿到 m3u8 文件之后，根据对其内 ts 片段的索引，连续播放不同的视频片段，来达到流畅的播放效果。\n下载的 m3u8 文件\n说这些概念都没用，我们来看两个真实的被下载的 m3u8 文件。\n这种 m3u8 文件就还是比较清晰的，能看到它一个个的片段。但是需要注意的是，这里的片段，全部是基于域名的相对地址，也就是说，这样一个 m3u8 文件，你丢到播放器里，是无法播放的，但是如果你记录了原始下载这个 m3u8 的链接，它在播放器里是可以正常播放的。\n当然，如果你修改这个 m3u8 文件，将它相对路径拼接上域名地址，也是可以达到播放的效果的。\n再来看看另外一种 m3u8 文件，它其内的 ts 片段，都是完整地址。\n像这种具有完整地址的 ts 片段，哪怕你将它保存成一个本地的文件，播放器依然是可以直接播放的，不过这里本质上依然是在在线播放。\n这两中 m3u8 文件，虽然有细微的差别，但是它们都是基于标准的协议。\n简单总结一下：\n m3u8 不是视频内容的文件，它占用的磁盘空间非常的小。 m3u8 文件，如果其内的 ts 片段，是完整地址，则可以保存后播放，否者只能在线播放。 播放器播放 m3u8 文件的时候，实际上，还是在线从线上获取的视频流进行播放，所以是存在失效的情况的。  暂时知道这三点就可以了，接下来我们再看如何将一个 m3u8 文件，下载成一个 mp4 视频文件。\n使用 fmpeg 下载 m3u8\nffmpeg 是一套可以用来记录、转换音视频，并将其转化为流的开源程序，采用 LGPL 或 GPL 协议许可证书，很多大型的音视频软件，内部都是基于 ffmpeg 的。\n$ ffmpeg -i \u0026#34;m3u8_file_uri\u0026#34; \u0026#34;save_video.mp4\u0026#34; 到此，如果 m3u8 的链接正确可播放，就会开始下载，等待下载完成就可以了，最终会在指定目录下，保存 save_video.mp4 文件，它就是最终我们下载的离线视频文件。\nMPV MPV 是一个基于 MPlayer 和 mplayer2 的开源极简全能播放器。支持各种视频格式、音频解码、支持特效字幕（电影动漫的ass特效字幕都没啥问题），不仅支持本地播放，同样支持网络播放（mpv 集成了 youtube-dl）。重点是 MPV 具有多系统平台支持、命令行、自定义、GPU 解码、脚本支持等特点……\nOSC 界面 由于默认情况下，MPV 播放器简约到连 GUI 界面都没有提供，因此需要通过命令行或配置文件设置。\n虽然 MPV 并没有提供官方的 GUI 界面，没有菜单，但它提供 OSC 操作界面和快捷键用于操作，只要关联好文件格式，使用 mpv 打开视频后，使用上其实也非常的简单方便。\n快捷键 操作主要通过键盘快捷键（区分大小写）调整。下面介绍一些常用的 mpv 快捷键（更多的快捷键请阅读官方参考手册）。\n鼠标操作\n   快捷键 作用说明     鼠标左键双击 进入/退出全屏   鼠标右键单击 暂停/继续播放   鼠标滚轮 快进/快退    播放控制\n   快捷键  作用说明     p Space 暂停、继续播放   / * 减少/增加音量   9 0 减少/增加音量（数字键盘区的9、0不可用）   m  静音   ← → 快退/快进5秒   ↑ ↓ 快进/快退1分钟   \u0026lt; \u0026gt; 上一个/下一个（播放列表中）   Enter  下一个（播放列表中）   l  设定/清除 A-B循环点   L  循环播放   s  截屏   q  停止播放并退出   Q  保存当前播放进度并退出，播放同样文件从上次保存进度继续播放。    视频控制\n   快捷键 作用说明     _(下划线) 循环切换可用视频轨   A 循环切换视频画面比例   Alt+0 0.5倍源视频画面大小   Alt+1 1倍源视频画面大小   Alt+2 2倍源视频画面大小    音频控制\n   快捷键  作用说明     #  循环切换可用音频轨   Ctrl + Ctrl - 音轨延迟+/- 0.1秒    字幕控制\n   快捷键  作用说明     V  关闭/开启字幕   j J 循环切换可用字幕轨   x z 字幕延迟 +/- 0.1秒   r t 上移/下移字幕位置    窗口控制\n   快捷键 作用说明     T 窗口始终置顶   f 进入/退出全屏   ESC 退出全屏    配置 因为mpv本身不具有图形化前端，绝大多数的设置选项都是靠在主设置文件 ~/.config/mpv/mpv.conf 中输入参数实现的。\n## 部分选项之间有关联作用，MPV读取参数时由上往下读，所以注意书写通用参数的顺序，可查看手册[02]的顺序逻辑部分的错误示范 ## 基础 ## # 视频硬件解码API选择 # 因系统环境、显卡、驱动等差异硬件解码API方式（阅读官方参考手册查询）各有不同，建议实际测试验证后再填入可用API。 # 默认值为 no（使用软件解码），auto 为自动。 hwdec=auto # 尽可能所有格式先尝试上面指定视频硬件解码API #hwdec-codecs=all  # 输出log， # ~~/ 意思是 mpv config dir(for example ~/.config/mpv/) log-file=\u0026#34;~~/mpv.log\u0026#34; ## 功能 ## # --fs 等效 --fullscreen。运行MPV自动进入全屏 #fs=yes  # 默认为系统原生窗口界面，启用此项使用无边框界面 #border=no # 窗口置顶 #ontop=yes  # 窗口模式下最大占屏幕的百分比 # 例如在FHD屏上打开4k视频初始窗口过大 #autofit-larger=80%x80%  # 窗口模式下最小占屏幕的百分比 # 例如在4k屏上打开720p视频初始窗口过小 #autofit-smaller=50%x50%  # 默认yes，默认情况下MPV的窗口比例锁定为视频比例。启用此项以实现窗口自由拉伸行为 # 当 keepaspect=yes 时四周填充黑边 # keepaspect-window=no  # 以暂停状态启动播放器 #pause=yes  # 始终循环播放当前文件\u0026lt;N|inf|no\u0026gt; #loop=inf  # 播放列表循环\u0026lt;N|inf|force|no\u0026gt; #loop-playlist=no  # 默认情况下播完列表所有文件MPV自动关闭，设置为 yes 所有播放完毕不退出，设置为 always 可以实现类似“每个文件播完都暂停”的效果\u0026lt;yes|默认no|always\u0026gt;  keep-open=yes # 退出时记住播放状态。缓存目录默认在设置文件夹中的 \u0026#34;watch_later\u0026#34; save-position-on-quit=yes # 播放网络视频时的向后缓存大小（KiB或MiB） demuxer-max-bytes=20MiB ## OSD ## ## OSD 即 On-Screen-Display ，通常为屏幕上弹出显示的信息。  ## OSC 即 on-screen-controller ，MPV中指的是简易操控界面 # \u0026lt;no,bar,msg,msg-bar\u0026gt; 在跳转时间轴时显示的信息类型 osd-on-seek=msg-bar # 更改OSD字体大小（全局，影响多个功能显示的文本）（默认值：55） #osd-font-size=40  # 以秒为单位显示OSD时间（毫秒精度），有助于查看视频帧的确切时间戳 osd-fractions=yes # 开始播放时短暂显示的信息：文件名 osd-playing-msg=\u0026#34;${filename}\u0026#34; # 设置OSD文本信息的持续时间（毫秒）（默认值：1000） osd-duration=2000 ## 音频 ## # 最大音量。默认值130（130的响度约为100的两倍）\u0026lt;100.0-1000.0\u0026gt; volume-max=120 # 播放器启动音量。0为静音，默认100 #volume=100  # 自动加载同名外挂音轨（fuzzy为模糊名，exact为精确名）\u0026lt;默认no|exact|fuzzy|all\u0026gt;  audio-file-auto=fuzzy ## 视频 ## # 如果做过专业校色应开启（系统目录存在对应的icm校色文档）。未做校色的广色域屏应手动指定 --target-prim=\u0026lt;value\u0026gt; #icc-profile-auto=yes  ## 脚本 滤镜 着色器 ## ## 内置脚本开关（如果没有必要的目的，那就不要屏蔽mpv内建的功能 # 控制台 #load-osd-console=no # 统计信息 #load-stats-overlay=no  ## 字幕 ## # 自动加载当前播放文件的同名外挂字幕 sub-auto=fuzzy # 在指定的额外目录中寻找匹配的字幕，支持相对和绝对路径。 # 示例即自动搜索当前文件路径下名为\u0026#34;sub\u0026#34;,\u0026#34;subtitles\u0026#34;,\u0026#34;字幕\u0026#34;和C盘的\u0026#34;字幕库\u0026#34;文件夹内 #sub-file-paths=sub;subtitles;字幕;C:/字幕库 # 字幕首选语言为中文，但MPV优先加载外挂轨道，此项参数可能实际用处不大 slang=chs,sc,zh,chi,zho # 在插值和颜色管理之前，将字幕混合到视频帧上\u0026lt;yes|video|默认no\u0026gt;。值video类似于yes，但是以视频的原始分辨率绘制字幕，并与视频一起缩放 # 启用此功能会将字幕限制在视频的可见部分（不能出现在视频下方的黑色空白处） # 还会让字幕受 --icc-profile --target-prim --target-trc --interpolation --gamma-factor --glsl-shaders 的影响 # 与 --interpolation 一起使用时，可提高字幕渲染性能  #blend-subtitles=video  # [当 --blend-subtitles=yes/video 时无效] 使ASS字幕尽可能输出在黑边上 sub-ass-force-margins=yes ## 截图 ## ## 以下预设参数只是为了截取最高质量的图片（高质量截图处理效率较低） # \u0026lt;默认 jpg|png|webp\u0026gt; screenshot-format=png # JPEG的最高质量，默认为90\u0026lt;0-100\u0026gt;  #screenshot-jpeg-quality=100  # 用与源视频相同的色度半采样写入JPEG，默认yes #screenshot-jpeg-source-chroma=yes  # PNG压缩等级，过高的等级影响性能，默认为7\u0026lt;0-9\u0026gt;  #screenshot-png-compression=5  # PNG的压缩过滤器。默认5即可实现最佳压缩率\u0026lt;0-5\u0026gt;  #screenshot-png-filter=5  # 使用适当的色彩空间标记屏幕截图（并非所有格式受支持）默认no #screenshot-tag-colorspace=yes  # 主要影响PNG，尽可能使用和视频输出时相同的位深，默认yes #screenshot-high-bit-depth=yes # 若直接在模板中设置路径，此时无需 --screenshot-directory screenshot-template=\u0026#34;MPV-%P-N%n\u0026#34; # 截屏文件保存路径 # ~/ 意思是 user home directory root (similar to shell, $HOME) screenshot-directory=\u0026#34;~/Pictures\u0026#34; Shotcut Shotcut is a free, open source, cross-platform video editor.\nDaVinci Resolve 专业的剪辑、调色、特效和音频后期制作！\nMKVToolNix MKVToolNix is a set of tools to create, alter and inspect Matroska(mkv) files under Linux, other Unices and Windows.\n轨道提取模式：\nmkvextract 输入文件名 tracks [选项] TID1:目标文件名1 [TID2:目标文件名2 ...] TID:输出文件名\t如果输入文件中存在 ID 为 TID 的轨道，则将其提取为文件 输出文件名。轨道 ID 与 mkvmerge --identify 文件 选项所输出的相同。\n$ mkvextract \u0026#34;Another Movie.mkv\u0026#34; tracks 0:video.h265 \u0026#34;1:main audio.aac\u0026#34; VLC VLC is a free and open source cross-platform multimedia player and framework that plays most multimedia files, and various streaming protocols.\nDownload Aria2 Aria2是一款开源下载工具，可帮助简化不同设备和服务器之间的下载过程。它支持磁力链接、BT种子、http等类型的文件下载，与迅雷相比，Aria2有着优秀的性能及较低的资源占用，架构本身非常轻巧，通常只需要4兆字节（HTTP下载）到9兆字节（用于BitTorrent交互）之间。最重要的一点是Aria2完全免费！\n$ sudo apt-get install aria2 下载安装完成之后，可以通过输入 aria2c -v 来验证是否安装成功。\nUsage 命令行使用\n使用Aria2下载文件，只需在命令后附加地址即可：\n$ aria2c URL 下载后以其他名称保存文件\n$ aria2c -o fileName URL 下载多个文件\n$ aria2c -Z URL URL 从列表下载文件：\n$ aria2c -i URLs.txt 限制下载速度：\n# 单个文件 aria2c –max-download-limit=500k URL # 全局 aria2c –max-overall-download-limit=500k URL 断点续传：\n$ aria2c -c URL 下载磁力链接文件：要下载磁力链接文件，如果下载没有速度，可以添加--bt-tracker=选项，tracker 中用 , 隔开：\n$ aria2c --bt-tracker=tracker,tracker torrent tracker 服务器：\n  trackerslist：trackers_best (20 trackers) =\u0026gt; link / mirror / mirror 2\n  TrackersListCollection：BEST Tracker list (78 trackers)=\u0026gt; link / mirror\n  中国可用的 BT Tracker 服务器列表\n  将多行文本转换成一行并用逗号隔开\n$ cat tracker | xargs | tr \u0026#39; \u0026#39; \u0026#39;,\u0026#39;   分段下载：可以加快文件的下载速度，对于下载大文件时特别有用，-s 后面的参数值介于1~5之间，你可以根据实际情况选择。下面命令将使用2连接来下载该文件：\n$ aria2c -s 2 URL 后台下载：\n$ aria2c -D url $ aria2c –deamon=true url 验证文件：\n$ aria2c –checksum=md5=提供的md5 设置dht端口：\n$ aria2c –dht-listen-port=1234 torrent 下载需要引用页的文件：\n$ aria2c –referer=referurl URL 下载需要Cookie验证的文件：\n$ aria2c –essay-header=’Cookie:key=value’ URL $ aria2c –load-cookies=cookie文件 URL 从密码保护的网站下载一个文件：\n$ aria2c --http-user=xxx --http-password=xxx URL $ aria2c --ftp-user=xxx --ftp-password=xxx URL 注意：当源地址存在诸如\u0026amp;,*等shell的特殊字符，请使用单引号或双引号把URI包含起来。\nRPC Server 模式\n该模式可以配合 Web UI 进行图形管理。默认启动是 6800 端口，怕别人盗用，可以设置用户名和密码(1.18.4以上版本支持密钥)。\n$ aria2c --enable-rpc --rpc-listen-all --rpc-allow-origin-all -c --dir ~/Download Configurat ion 默认情况下，aria2 检查旧路径 $HOME/.aria2/aria2.conf 是否存在，否则它会将 $XDG_CONFIG_HOME/aria2/aria2.conf 解析为它的配置文件。 您可以使用 --conf-path 选项指定配置文件的路径。 如果您不想使用配置文件，请使用 --no-conf 选项。\n配置详解：\n# Description: Awesome Aria2 configuration file # Version: 2021.09.15 ## \u0026#39;#\u0026#39;开头为注释内容, 选项都有相应的注释说明, 根据需要修改 ## ## 被注释的选项填写的是默认值, 如为空则无默认设置，请自行选取需要更改的添加到你的配置文件中 ## ## 文件保存设置 ## # 下载路径(可使用绝对路径或相对路径), 默认: 当前启动位置 #dir= dir=/home/kurome/Downloads # 磁盘缓存 # 启用磁盘缓存. 如果设置为 0, 将禁用磁盘缓存. 此功能将下载的数据缓存在内存中, 最多占用此选项设置的字节数. 缓存存储由 aria2 实例创建并对所有下载共享. 由于数据以较大的单位写入并按文件的偏移重新排序, 所以磁盘缓存的一个优点是减少磁盘的 I/O. 如果调用哈希检查时并且数据缓存在内存中时, 将不需要从磁盘中读取. 大小可以包含 K 或 M (1K = 1024, 1M = 1024K). disk-cache=64M # 文件预分配方式, 可选：none, prealloc, trunc, falloc, 默认:prealloc # 预分配对于机械硬盘可有效降低磁盘碎片、提升磁盘读写性能、延长磁盘寿命。 # 机械硬盘使用 ext4（具有扩展支持），btrfs，xfs 或 NTFS（仅 MinGW 编译版本）等文件系统建议设置为 falloc # 若无法下载，提示 fallocate failed.cause：Operation not supported 则说明不支持，请设置为 none # prealloc 分配速度慢, trunc 无实际作用，不推荐使用。 # 固态硬盘不需要预分配，只建议设置为 none ，否则可能会导致双倍文件大小的数据写入，从而影响寿命。 file-allocation=none # 文件分配限制 # 不对比此参数设置大小小的分配文件. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). no-file-allocation-limit=64M # 断点续传 # 继续下载部分完成的文件. 启用此选项可以继续下载从浏览器或其他程序按顺序下载的文件. 此选项目前只支持 HTTP(S)/FTP 下载的文件. continue=true # 始终断点续传 # 始终断点续传. 如果设置为\u0026#34;是\u0026#34;, aria2 始终尝试断点续传, 如果无法恢复, 则中止下载. 如果设置为\u0026#34;否\u0026#34;, 对于不支持断点续传的 URI 或 aria2 遇到 N 个不支持断点续传的 URI (N 为 --max-resume-failure-tries 选项设置的值), aria2 会从头下载文件. 参见 --max-resume-failure-tries 参数. always-resume=false # 最大断点续传尝试次数 # 当 --always-resume 选项设置为\u0026#34;否\u0026#34;时, 如果 aria2 检测到有 N 个 URI 不支持断点续传时, 将从头开始下载文件. 如果 N 设置为 0, 当所有 URI 都不支持断点续传时才会从头下载文件. 参见 --always-resume 选项. max-resume-failure-tries=0 # 获取服务器文件时间 # 从 HTTP/FTP 服务获取远程文件的时间戳, 如果可用将设置到本地文件 remote-time=true ## 进度保存设置 ## # 从会话文件中读取下载任务 input-file=/home/kurome/.aria2/aria2.session # 会话文件保存路径 # 当退出时保存错误及未完成的任务到指定的文件中. 必须用绝对路径 # 您可以在重启 aria2 时使用 --input-file 选项重新加载. 如果您希望输出的内容使用 GZip 压缩, 您可以在文件名后增加 .gz 扩展名. 请注意, 通过 aria2.addTorrent() 和 aria2.addMetalink() RPC 方法添加的下载, 其元数据没有保存到文件的将不会保存. 通过 aria2.remove() 和 aria2.forceRemove() 删除的下载将不会保存. #save-session= save-session=/home/kurome/.aria2/aria2.session # 任务状态改变后保存会话的间隔时间（秒）, 0 为仅在进程正常退出时保存, 默认:0 # 为了及时保存任务状态、防止任务丢失，此项值只建议设置为 1 save-session-interval=1 # 自动保存任务进度到控制文件(*.aria2)的间隔时间（秒），0 为仅在进程正常退出时保存，默认：60 # 不论设置的值为多少, aria2 会在任务结束时保存控制文件. 可以设置的值为 0 到 600. # 此项值也会间接影响从内存中把缓存的数据写入磁盘的频率 # 想降低磁盘 IOPS (每秒读写次数)则提高间隔时间 # 想在意外非正常退出时尽量保存更多的下载进度则降低间隔时间 # 非正常退出：进程崩溃、系统崩溃、SIGKILL 信号、设备断电等 auto-save-interval=20 # 强制保存，即使任务已完成也保存信息到会话文件, 默认:false # 即使任务完成或删除时使用 --save-session 选项时也保存该任务. 此选项在这种情况下还会保存控制文件. 此选项可以保存被认为已经完成但正在做种的 BT 任务. # 开启后会在任务完成后保留 .aria2 文件，文件被移除且任务存在的情况下重启后会重新下载。 # 关闭后已完成的任务列表会在重启后清空。 force-save=false ## 下载连接设置 ## # 文件未找到重试次数 # 如果 aria2 从远程 HTTP/FTP 服务器收到 \u0026#34;文件未找到\u0026#34; 的状态超过此选项设置的次数后下载将会失败. 设置为 0 将会禁用此选项. 此选项仅影响 HTTP/FTP 服务器. 重试时同时会记录重试次数, 所以也需要设置 --max-tries 这个选项. max-file-not-found=10 # 最大尝试次数 # 设置最大尝试次数. 0 表示不限制，默认:5 max-tries=0 # 重试等待时间, 默认:0 (禁用) # 设置重试间隔时间(秒). 当此选项的值大于 0 时, aria2 在 HTTP 服务器返回 503 响应时将会重试. retry-wait=10 # 连接超时时间 # 设置建立 HTTP/FTP/代理服务器 连接的超时时间(秒). 当连接建立后, 此选项不再生效, 请使用 --timeout 选项. connect-timeout=10 # 超时时间。默认：60 timeout=10 # 最大同时下载任务数, 运行时可修改, 默认:5 max-concurrent-downloads=5 # 单服务器最大连接线程数, 任务添加时可指定, 默认:1 # 最大值为 16 (增强版无限制), 且受限于单任务最大连接线程数(split)所设定的值。 max-connection-per-server=16 # 单任务最大连接线程数, 任务添加时可指定, 默认:5 # 下载时使用 N 个连接. 如果提供超过 N 个 URI 地址, 则使用前 N 个地址, 剩余的地址将作为备用. 如果提供的 URI 地址不足 N 个, 这些地址多次使用以保证同时建立 N 个连接. 同一服务器的连接数会被 --max-connection-per-server 选项限制. split=64 # 文件最小分段大小, 添加时可指定, 默认:20M # aria2 不会分割小于 2*SIZE 字节的文件. 例如, 文件大小为 20MB, 如果 SIZE 为 10M, aria2 会把文件分成 2 段 [0-10MB) 和 [10MB-20MB), 并且使用 2 个源进行下载 (如果 --split \u0026gt;= 2). 如果 SIZE 为 15M, 由于 2*15M \u0026gt; 20MB, 因此 aria2 不会分割文件并使用 1 个源进行下载. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). 可以设置的值为: 1M-1024M. # 理论上值越小使用下载分段就越多，所能获得的实际线程数就越大，下载速度就越快，但受限于所下载文件服务器的策略。 min-split-size=4M # 文件分片大小，最小值为 1M，默认：1M # 设置 HTTP/FTP 下载的分配大小. aria2 根据这个边界分割文件. 所有的分割都是这个长度的倍数. 此选项不适用于 BitTorrent 下载. 如果 Metalink 文件中包含分片哈希的结果此选项也不适用. piece-length=1M # 允许分片大小变化。默认：false # 如果设置为\u0026#34;否\u0026#34;, 当分片长度与控制文件中的不同时, aria2 将会中止下载. 如果设置为\u0026#34;是\u0026#34;, 您可以继续, 但部分下载进度将会丢失. allow-piece-length-change=true # 分片选择算法 # 指定 HTTP/FTP 下载使用的分片选择算法. 分片表示的是并行下载时固定长度的分隔段. 如果设置为\u0026#34;默认\u0026#34;, aria2 将会按减少建立连接数选择分片. 由于建立连接操作的成本较高, 因此这是合理的默认行为. 如果设置为\u0026#34;顺序\u0026#34;, aria2 将选择索引最小的分片. 索引为 0 时表示为文件的第一个分片. 这将有助于视频的边下边播. --enable-http-pipelining 选项有助于减少重连接的开销. 请注意, aria2 依赖于 --min-split-size 选项, 所以有必要对 --min-split-size 选项设置一个合理的值. 如果设置为\u0026#34;随机\u0026#34;, aria2 将随机选择一个分片. 就像\u0026#34;顺序\u0026#34;一样, 依赖于 --min-split-size 选项. 如果设置为\u0026#34;几何\u0026#34;, aria2 会先选择索引最小的分片, 然后会为之前选择的分片保留指数增长的空间. 这将减少建立连接的次数, 同时文件开始部分将会先行下载. 这也有助于视频的边下边播. #stream-piece-selector=default # 最小速度限制 # 当下载速度低于此选项设置的值(B/s) 时将会关闭连接. 0 表示不设置最小速度限制. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). 此选项不会影响 BT 下载. lowest-speed-limit=0 # 全局最大下载速度 # 设置全局最大下载速度 (字节/秒). 0 表示不限制. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). max-overall-download-limit=0 # 最大下载速度 # 设置每个任务的最大下载速度 (字节/秒). 0 表示不限制. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). max-download-limit=0 # 禁用 IPv6, 默认:false disable-ipv6=true # 支持 GZip # 如果远程服务器的响应头中包含 Content-Encoding: gzip 或 Content-Encoding: deflate , 将发送包含 Accept: deflate, gzip 的请求头并解压缩响应. http-accept-gzip=true # URI 复用 # 当所有给定的 URI 地址都已使用, 继续使用已经使用过的 URI 地址. reuse-uri=false # URI 选择算法 # 指定 URI 选择的算法. 可选的值包括 \u0026#34;按顺序\u0026#34;, \u0026#34;反馈\u0026#34; 和 \u0026#34;自适应\u0026#34;. 如果设置为\u0026#34;按顺序\u0026#34;, URI 将按列表中出现的顺序使用. 如果设置为\u0026#34;反馈\u0026#34;, aria2 将根据之前的下载速度选择 URI 列表中下载速度最快的服务器. 同时也将有效跳过无效镜像. 之前统计的下载速度将作为服务器状态文件的一部分, 参见 --server-stat-of 和 --server-stat-if 选项. 如果设置为\u0026#34;自适应\u0026#34;, 将从最好的镜像和保留的连接里选择一项. 补充说明, 其返回的镜像没有被测试过, 同时如果每个镜像都已经被测试过时, 返回的镜像还会被重新测试. 否则, 其将不会选择其他镜像. 例如\u0026#34;反馈\u0026#34;, 其使用服务器状态文件. #uri-selector=feedback # 禁用 netrc，默认:false no-netrc=true # .netrc 文件路径 #netrc-path=$(HOME)/.netrc # 允许覆盖 # 如果相应的控制文件不存在时从头重新下载文件. 参见 --auto-file-renaming 选项. allow-overwrite=false # 文件自动重命名。默认:true # 重新命名已经存在的文件. 此选项仅对 HTTP(S)/FTP 下载有效. 新的文件名后会在文件名后、扩展名 (如果有) 前追加句点和数字(1..9999). auto-file-renaming=true # 使用 UTF-8 处理 Content-Disposition，默认:false # 处理 \u0026#34;Content-Disposition\u0026#34; 头中的字符串时使用 UTF-8 字符集来代替 ISO-8859-1, 例如, 文件名参数, 但不是扩展版本的文件名. content-disposition-default-utf8=true # 最低 TLS 版本，可选：TLSv1.1、TLSv1.2、TLSv1.3 默认:TLSv1.2 #min-tls-version=TLSv1.2 ## BT/PT 下载设置 ## # BT 监听端口(TCP), 默认:6881-6999 # 设置 BT 下载的 TCP 端口. 多个端口可以使用逗号 \u0026#34;,\u0026#34; 分隔, 例如: 6881,6885. 您还可以使用短横线 \u0026#34;-\u0026#34; 表示范围: 6881-6999, 或可以一起使用: 6881-6889, 6999. # 直通外网的设备，比如 VPS ，务必配置防火墙和安全组策略允许此端口入站 # 内网环境的设备，比如 NAS ，除了防火墙设置，还需在路由器设置外网端口转发到此端口 listen-port=51413 # DHT 网络与 UDP tracker 监听端口(UDP), 默认:6881-6999 # 设置 DHT (IPv4, IPv6) 和 UDP 服务器使用的 UCP 端口. 多个端口可以使用逗号 \u0026#34;,\u0026#34; 分隔, 例如: 6881,6885. 您还可以使用短横线 \u0026#34;-\u0026#34; 表示范围: 6881-6999, 或可以一起使用: 6881-6889, 6999. # 因协议不同，可以与 BT 监听端口使用相同的端口，方便配置防火墙和端口转发策略。 dht-listen-port=51413 # 启用 DHT (IPv4), 默认:true # 启用 IPv4 DHT 功能. 此选项同时会启用 UDP 服务器支持. PT 下载(私有种子)会自动禁用 enable-dht=true # 启用 DHT (IPv6)，默认:false # 启用 IPv6 DHT 功能. 如果种子设置为私有, 即使此选项设置为\u0026#34;是\u0026#34;, aria2 也不会启用 DHT. 使用 --dht-listen-port 选项设置监听的端口. # 在没有 IPv6 支持的环境开启可能会导致 DHT 功能异常 enable-dht6=false # 外部 IP 地址 # 指定用在 BitTorrent 下载和 DHT 中的外部 IP 地址. 它可能被发送到 BitTorrent 服务器. 对于 DHT, 此选项将会报告本地节点正在下载特定的种子. 这对于在私有网络中使用 DHT 非常关键. 虽然这个方法叫外部, 但其可以接受各种类型的 IP 地址. # 使用场景：在家庭宽带没有公网 IP 的情况下可以把 BT 和 DHT 监听端口转发至具有公网 IP 的服务器，在此填写服务器的 IP ，可以提升 BT 下载速率。 #bt-external-ip= # DHT (IPv4) 文件，默认：$HOME/.aria2/dht.dat # 修改 IPv4 DHT 路由表文件路径. dht-file-path=/home/kurome/.aria2/dht.dat # DHT (IPv6) 文件，默认：$HOME/.aria2/dht6.dat # 修改 IPv6 DHT 路由表文件路径. dht-file-path6=/home/kurome/.aria2/dht6.dat # IPv4 DHT 网络引导节点 dht-entry-point=dht.transmissionbt.com:6881 # IPv6 DHT 网络引导节点 dht-entry-point6=dht.transmissionbt.com:6881 # 启用本地节点发现(LPD),PT 下载(私有种子)会自动禁用,默认:false bt-enable-lpd=true # 指定用于本地节点发现的接口，可能的值：接口，IP地址 # 如果未指定此选项，则选择默认接口。 #bt-lpd-interface= # 启用节点交换, 默认:true # 启用节点交换扩展. 如果种子设置为私有, 即使此选项设置为\u0026#34;是\u0026#34;, aria2 也不会启用此功能. enable-peer-exchange=true # BT 下载最大连接数（单任务），运行时可修改。0 为不限制，默认:55 # 理想情况下连接数越多下载越快，但在实际情况是只有少部分连接到的做种者上传速度快，其余的上传慢或者不上传。 # 如果不限制，当下载非常热门的种子或任务数非常多时可能会因连接数过多导致进程崩溃或网络阻塞。 # 进程崩溃：如果设备 CPU 性能一般，连接数过多导致 CPU 占用过高，因资源不足 Aria2 进程会强制被终结。 # 网络阻塞：在内网环境下，即使下载没有占满带宽也会导致其它设备无法正常上网。因远古低性能路由器的转发性能瓶颈导致。 bt-max-peers=128 # BT 下载期望速度值（单任务），运行时可修改。单位 K 或 M 。默认:50K # BT 下载速度低于此选项值时会临时提高连接数来获得更快的下载速度，不过前提是有更多的做种者可供连接。 # 实测临时提高连接数没有上限，但不会像不做限制一样无限增加，会根据算法进行合理的动态调节。 bt-request-peer-speed-limit=10M # 全局最大上传速度, 运行时可修改, 默认:0 (无限制) # 设置全局最大上传速度 (字节/秒). 0 表示不限制. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). # 设置过低可能影响 BT 下载速度 max-overall-upload-limit=2M # 单任务上传速度限制, 默认:0 (无限制) # 设置每个任务的最大上传速度 (字节/秒). 0 表示不限制. 您可以增加数值的单位 K 或 M (1K = 1024, 1M = 1024K). max-upload-limit=0 # 最小分享率, 0 为一直做种, 默认:1.0 # 指定分享率. 当分享率达到此选项设置的值时会完成做种. 强烈建议您将此选项设置为大于等于 1.0. 如果您想不限制分享比率, 可以设置为 0.0. 如果同时设置了 --seed-time 选项, 当任意一个条件满足时将停止做种. seed-ratio=1.0 # 最小做种时间（分钟） # 此选项设置为 0 时, 将在 BT 任务下载完成后不进行做种. seed-time=30 # 做种前检查文件哈希, 默认:true # 如果设置为\u0026#34;是\u0026#34;, 当使用 --check-integrity 选项完成哈希检查及文件完成后才继续做种. 如果您希望仅当文件损坏或未完成时检查文件, 请设置为\u0026#34;否\u0026#34;. 此选项仅对 BT 下载有效 bt-hash-check-seed=true # 继续之前的BT任务时, 无需再次校验, 默认:false # 不检查之前下载文件中每个分片的哈希值. bt-seed-unverified=false # BT tracker 服务器连接超时时间（秒）。默认：60 # 建立连接后，此选项无效，将使用 bt-tracker-timeout 选项的值 bt-tracker-connect-timeout=10 # BT tracker 服务器超时时间（秒）。默认：60 bt-tracker-timeout=10 # BT 服务器连接间隔时间。默认：0 (自动) # 设置请求 BT 服务器的间隔时间 (秒). 此选项将完全覆盖服务器返回的最小间隔时间和间隔时间, aria2 仅使用此选项的值.如果设置为 0, aria2 将根据服务器的响应情况和下载进程决定时间间隔. #bt-tracker-interval=0 # BT 下载优先下载文件开头或结尾 # 尝试先下载每个文件开头或结尾的分片. 此选项有助于预览文件. 参数可以包括两个关键词: head 和 tail. 如果包含两个关键词, 需要使用逗号分隔. 每个关键词可以包含一个参数, SIZE. 例如, 如果指定 head=SIZE, 每个文件的最前 SIZE 数据将会获得更高的优先级. tail=SIZE 表示每个文件的最后 SIZE 数据. SIZE 可以包含 K 或 M (1K = 1024, 1M = 1024K). bt-prioritize-piece=head=32M,tail=32M # 保存通过 WebUI(RPC) 上传的种子文件(.torrent)，默认:true # 在 dir 选项设置的目录中保存上传的种子文件或 Metalink 文件. 文件名包括 SHA-1 哈希后的元数据和扩展名两部分. 对于种子文件, 扩展名为 \u0026#39;.torrent\u0026#39;. 对于 Metalink 为 \u0026#39;.meta4\u0026#39;. 如果此选项设置为\u0026#34;否\u0026#34;, 通过 aria2.addTorrent() 或 aria2.addMetalink() 方法添加的下载将无法通过 --save-session 选项保存. # 所有涉及种子文件保存的选项都建议开启，不保存种子文件有任务丢失的风险。 # 通过 RPC 自定义临时下载目录可能不会保存种子文件。 rpc-save-upload-metadata=true # 下载种子文件(.torrent)自动开始下载, 默认:true，可选：false|mem # true：保存种子文件 # false：仅下载种子文件 # mem：将种子保存在内存中 # 如果设置为\u0026#34;是\u0026#34;或\u0026#34;仅内存\u0026#34;, 当后缀为 .torrent 或内容类型为 application/x-bittorrent 的文件下载完成时, aria2 将按种子文件读取并下载该文件中提到的文件. 如果设置为\u0026#34;仅内存\u0026#34;, 该种子文件将不会写入到磁盘中, 而仅会存储在内存中. 如果设置为\u0026#34;否\u0026#34;, 则 .torrent 文件会下载到磁盘中, 但不会按种子文件读取并且其中的文件不会进行下载. follow-torrent=true # 种子文件下载完后暂停任务，默认：false # 在开启 follow-torrent 选项后下载种子文件或磁力会自动开始下载任务进行下载，而同时开启当此选项后会建立相关任务并暂停。 pause-metadata=false # 保存磁力链接元数据为种子文件(.torrent), 默认:false # 保存种子文件为 \u0026#34;.torrent\u0026#34; 文件. 此选项仅对磁链生效. 文件名为十六进制编码后的哈希值及 \u0026#34;.torrent\u0026#34;后缀. 保存的目录与下载文件的目录相同. 如果相同的文件已存在, 种子文件将不会保存. bt-save-metadata=true # 加载已保存的元数据文件(.torrent)，默认:false # 当使用磁链下载时, 在从 DHT 获取种子元数据之前, 首先尝试加载使用 --bt-save-metadata 选项保存的文件. 如果文件加载成功, 则不会从 DHT 下载元数据. bt-load-saved-metadata=true # 删除 BT 下载任务中未选择文件，默认:false # 当 BT 任务完成后删除未选择的文件. 要选择需要下载的文件, 请使用 --select-file 选项. 如果没有选择, 则所有文件都默认为需要下载. 此选项会从磁盘上直接删除文件, 请谨慎使用此选项. bt-remove-unselected-file=true # BT强制加密, 默认: false # 启用后将拒绝旧的 BT 握手协议并仅使用混淆握手及加密。可以解决部分运营商对 BT 下载的封锁，且有一定的防版权投诉与迅雷吸血效果。 # 此选项相当于后面两个选项(bt-require-crypto=true, bt-min-crypto-level=arc4)的快捷开启方式，但不会修改这两个选项的值。 bt-force-encryption=true # BT加密需求，默认：false # 启用后拒绝与旧的 BitTorrent 握手协议(\\19BitTorrent protocol)建立连接，始终使用混淆处理握手。 #bt-require-crypto=true # BT最低加密等级，可选：plain（明文），arc4（加密），默认：plain # 设置加密方法的最小级别. 如果节点提供多种加密方法, aria2 将选择满足给定级别的最低级别. #bt-min-crypto-level=arc4 # 分离仅做种任务，默认：false # 从正在下载的任务中排除已经下载完成且正在做种的任务，并开始等待列表中的下一个任务。 # 统计当前活动下载任务(参见 -j 选项) 时排除仅做种的任务. 这意味着, 如果参数设置为 -j3, 此选项打开并且当前有 3 个正在活动的任务, 并且其中有 1 个进入做种模式, 那么其会从正在下载的数量中排除(即数量会变为 2), 在队列中等待的下一个任务将会开始执行. 但要知道, 在 RPC 方法中, 做种的任务仍然被认为是活动的下载任务. bt-detach-seed-only=true ## 客户端伪装 ## # 自定义 User Agent user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36 Edg/93.0.961.47 # BT 客户端伪装 # PT 下载需要保持 user-agent 和 peer-agent 两个参数一致 # 部分 PT 站对 Aria2 有特殊封禁机制，客户端伪装不一定有效，且有封禁账号的风险。 # 自定义 User Agent，默认：aria2/$VERSION #user-agent=Deluge 1.3.15 # Peer Agent # 指定 BT 扩展握手期间用于节点客户端版本的字符串. peer-agent=Deluge 1.3.15 # 节点 ID 前缀 # 指定节点 ID 的前缀. BT 中节点 ID 长度为 20 字节. 如果超过 20 字节, 将仅使用前 20 字节. 如果少于 20 字节, 将在其后不足随机的数据保证为 20 字节. peer-id-prefix=-DE13F0- ## 执行额外命令 ## # 下载停止后执行的命令 # 从 正在下载 到 删除、错误、完成 时触发。暂停被标记为未开始下载，故与此项无关。 #on-download-stop=/home/kurome/.aria2/delete.sh # 下载完成后执行的命令 # 此项未定义则执行 下载停止后执行的命令 (on-download-stop) #on-download-complete=/home/kurome/.aria2/clean.sh # 下载错误后执行的命令 # 此项未定义则执行 下载停止后执行的命令 (on-download-stop) #on-download-error= # 下载暂停后执行的命令 #on-download-pause= # 下载开始后执行的命令 #on-download-start= # BT 下载完成后执行的命令 #on-bt-download-complete= ## RPC 设置 ## # 启用 JSON-RPC/XML-RPC 服务器, 默认:false enable-rpc=true # 接受所有远程请求, 默认:false # 在 RPC 响应头增加 Access-Control-Allow-Origin 字段, 值为 * .web界面跨域权限需要 rpc-allow-origin-all=true # 允许外部访问, 默认:false rpc-listen-all=true # RPC 监听端口, 默认:6800 rpc-listen-port=6800 # RPC 密钥, v1.18.4新增功能, 取代 --rpc-user 和 --rpc-passwd 选项 rpc-secret=SetForYourself # RPC 最大请求大小 # 设置 JSON-RPC/XML-RPC 最大的请求大小. 如果 aria2 检测到请求超过设定的字节数, 会直接取消连接. rpc-max-request-size=10M # RPC 服务 SSL/TLS 加密, 默认：false # RPC 将通过 SSL/TLS 加密传输. RPC 客户端需要使用 https 协议连接服务器. 对于 WebSocket 客户端, 使用 wss 协议. 使用 --rpc-certificate 和 --rpc-private-key 选项设置服务器的证书和私钥. # 不推荐开启，建议使用 web server 反向代理，比如 Nginx、Caddy ，灵活性更强。 #rpc-secure= # 在 RPC 服务中启用 SSL/TLS 加密时的证书文件, # 使用 PEM 格式时，您必须通过 --rpc-private-key 指定私钥 #rpc-certificate=/path/to/certificate.pem # 在 RPC 服务中启用 SSL/TLS 加密时的私钥文件 #rpc-private-key=/path/to/certificate.key # 事件轮询方式, 可选：epoll, kqueue, port, poll, select, 不同系统默认值不同 # 设置事件轮训的方法. 对于 epoll, kqueue, port 和 poll, 只有系统支持时才可用. 最新的 Linux 支持 epoll. 各种 *BSD 系统包括 Mac OS X 支持 kqueue. Open Solaris 支持 port. 默认值根据您使用的操作系统不同而不同. #event-poll=select ## 高级选项 ## # 启用异步 DNS 功能。默认：true #async-dns=true # 指定异步 DNS 服务器列表，未指定则从 /etc/resolv.conf 中读取。 #async-dns-server=119.29.29.29,223.5.5.5,8.8.8.8,1.1.1.1 # 指定单个网络接口，可能的值：接口，IP地址，主机名 # 如果接口具有多个 IP 地址，则建议指定 IP 地址。 # 已知指定网络接口会影响依赖本地 RPC 的连接的功能场景，即通过 localhost 和 127.0.0.1 无法与 Aria2 服务端进行讯通。 #interface= # 指定多个网络接口，多个值之间使用逗号(,)分隔。 # 使用 interface 选项时会忽略此项。 #multiple-interface= ## 日志设置 ## # 日志文件保存路径，默认：不保存 # 如果设置为 \u0026#34;-\u0026#34;, 日志则写入到 stdout. 如果忽略或设置为空字符串(\u0026#34;\u0026#34;), 日志将不会记录到磁盘上. #log= # 日志级别，可选 debug, info, notice, warn, error 。默认：debug #log-level=warn # 控制台日志级别，可选 debug, info, notice, warn, error ，默认：notice console-log-level=notice # 安静模式，禁止在控制台输出日志，默认：false quiet=false # 下载进度摘要输出间隔时间（秒），0 为禁止输出。默认：60 summary-interval=0 ## BitTorrent trackers ## # BT 服务器地址 2022/02/26 # 逗号分隔的 BT 服务器地址. 如果服务器地址在 --bt-exclude-tracker 选项中, 其将不会生效. bt-tracker=udp://open.tracker.cl:1337/announce,udp://tracker.opentrackr.org:1337/announce,udp://9.rarbg.com:2810/announce,udp://www.torrent.eu.org:451/announce,udp://tracker2.dler.org:80/announce,udp://tracker.torrent.eu.org:451/announce,udp://tracker.moeking.me:6969/announce,udp://tracker.bitsearch.to:1337/announce,udp://tracker.0x.tf:6969/announce,udp://tracker-udp.gbitt.info:80/announce,udp://tr.cili001.com:8070/announce,udp://retracker.lanta-net.ru:2710/announce,udp://open.stealth.si:80/announce,udp://ipv4.tracker.harry.lu:80/announce,udp://explodie.org:6969/announce,udp://exodus.desync.com:6969/announce,udp://bt2.archive.org:6969/announce,udp://bt1.archive.org:6969/announce,https://tracker.nanoha.org:443/announce,https://tracker.lilithraws.org:443/announce 更多：Aria2 完美配置\nAria2 Web 控制台\nAira2 没有软件界面，程序员可以用代码执行任务，但普通用户怎样添加下载任务呢？——打开浏览器，输入网址aria2c.com（YAAW 的中文版）就可以打开 Aria2 Web 控制台。\nJSON-RPC Path 默认为: http://localhost:6800/jsonrpc，如果提示 “Aria2 RPC 服务器错误”，按照以下方法修改：\n 普通情况设置为: http://host:port/jsonrpc  host: 指运行 Aria2 所在机器的 IP 或者名字 port: 使用 --rpc-listen-port 选项设置的端口, 未设置则是 6800；可通过 lsof -i:6800 查看端口是否被占用   使用 --rpc-secret=xxxxxx 选项设置为: http://token:xxxxxx@host:port/jsonrpc 使用 --rpc-user=user --rpc-passwd=pwd 选项设置为: http://user:pwd@host:port/jsonrpc 以上JSON-RPC Path 中的 http 可以用 ws 替代, 代表使用 WebSocket 协议。换用 ws 也可能解决 “Aria2 RPC 服务器错误”。 当使用 https://aria2c.com 访问时, 可能需要使用 https 或 wss 协议。  在 Web UI 中对 Aria2 的设置会在 Aria2 重启后丢失,，必要的设置请写入配置文件。\n已经下载完成的任务会在 Aria2 重启后消失, 除非启用了 --force-save 选项。\nProtocol **HTTP / HTTPS / FTP / SFTP **\n超文本传输协议（HTTP / HTTPS）和 文件传输协议（FTP / SFTP）将文件放到服务器上，然后由服务器传送到不同的用户机器上，称为Client-Server Model简称C/S模式，或者叫一对多模式。\n缺点是：当非常多的用户同时访问和下载服务器上的文件时，由于服务器处理能力和带宽的限制，下载速度会急剧下降，有的用户可能访问不了服务器。\nBitTorrent 协议\nBitTorrent(简称BT)是一个文件分发协议，每个下载者在下载的同时不断向其他下载者上传已下载的数据。BT协议与FTP协议不同，特点是下载的人越多，下载速度越快，原因在于每个下载者将已下载的数据提供给其他下载者下载，充分利用了用户的上载带宽。通过一定的策略保证上传速度越快，下载速度也越快。在很短时间内，BitTorrent协议成为一种新的变革技术。\nBitTorrent 的发展依赖于对等网络 (Peer - to - Peer 简称 P2P)。P2P技术体现了互联网最根本的内涵——自由和免费，它的主要优点如下：\n 对等性高：非中心化，互联网回归本色——联系和传输； 扩展性强：用户扩展与资源、服务、系统同步扩展； 健壮性高：服务分散和自适应，耐攻击、高容错性； 性价比高：P2P成本低、存储和技术能力强； 负载均衡：分布存储和技术，整个网络负载得以均衡。  在P2P网络中，每个参与的节点既是服务器又是客户端，既是信息的提供者又是信息的消费者。P2P信息检索的目的就是网络中的任意节点都可以提交检索的请求，然后这些检索通过相关信息的节点将会回应请求，按照某种路由机制路由到本地相关的内容，以对等的形式直接传送到请求节点上。\n检索过程分为以下几个阶段：每个节点在加入网络的时候，会对存储在本节点上的内容进行索引，以满足本地内容检索的目的。然后按某种预定的规则选择一些节点作为自己的邻居，加入到P2P网络当中。发起者P提出检索请求q，并将q发送给自己的邻居，P的邻居收到q后，再按照某种策略转发给它在网络中的其它邻居节点。这样，q就在整个网络中传播开来。收到请求q的节点如果存储有相应内容信息 , 则将对应的内容返回。\n普通的HTTP/FTP下载使用TCP/IP协议，BitTorrent协议是架构于TCP/IP协议之上的一个P2P文件传输协议，处于TCP/IP结构的应用层。 BitTorrent协议本身也包含了很多具体的内容协议和扩展协议，并在不断扩充中。\n根据BitTorrent协议，文件发布者会根据要发布的文件生成提供一个.torrent文件，即种子文件，也简称为“种子”。\n种子还有如下相关概念：\n 发布BT种子的人，做种多少天指的就是持续多少天不撤种。这期间如果有别人下完了，就叫出种。下完的人可以继续做种。这时发布种子的人就可以不做种了，叫撤种。 一个资源只要有一个人在做种，那就其他人就可以继续下。如果没人做种了，叫断种，这是资源就死了，下不了了。某人长时间一直做种，叫保种。  .torrent文件本质上是文本文件，包含Tracker信息和文件信息两部分。Tracker信息主要是BT下载中需要用到的Tracker服务器的地址和针对Tracker服务器的设置，文件信息是根据对目标文件的计算生成的，计算结果根据BitTorrent协议内的B编码规则进行编码。它的主要原理是需要把提供下载的文件虚拟分成大小相等的块，块大小必须为2k的整数次方（由于是虚拟分块，硬盘上并不产生各个块文件），并把每个块的索引信息和Hash验证码写入种子文件（.torrent）中。所以，种子文件（.torrent）就是被下载文件的“索引”。\n下载者要下载文件内容，需要先得到相应的.torrent文件，然后使用BT客户端软件进行下载。\n下载时，BT客户端首先解析.torrent文件得到Tracker地址，然后连接Tracker服务器。Tracker服务器回应下载者的请求，提供下载者其他下载者（包括发布者）的IP。下载者再连接其他下载者，根据.torrent文件，两者分别对方告知自己已经有的块，然后交换对方没有的数据。此时不需要其他服务器参与，分散了单个线路上的数据流量，因此减轻了服务器负担。\n下载者每得到一个块，需要算出下载块的Hash验证码与.torrent文件中的对比，如果一样则说明块正确，不一样则需要重新下载这个块。这种规定是为了解决下载内容准确性的问题。\n从 BT 客户端角度考虑，下载原理分为以下几步：\n 根据 BitTorrent 协议，文件发布者会根据要发布的文件生成提供一个 .torrent 文件。客户端可从 Web 服务器上下载种子文件，并从中得到 Tracker 服务器 URL。 根据 Tracker URL 与 Tracker 服务器建立连接，并从服务器上得到 Peers 信息。 根据 Peers 信息与一个 Peer 建立连接，依据 Peer wire 协议完成握手，并从 Peer 端下载数据文件。同时监听 Peer 的连接，并给 Peer 上传数据文件。  迅雷，俗称吸血雷：\n 吸血就是指一些客户端在进行P2P下载时，从其它客户端下载的数据量非常多，但是分享给其它客户端的数据非常少，下载完成后立即关机走人的行为 而迅雷就是这样的一个下载器，迅雷的服务器疯狂索取资源，但自己又不上传资源给别人），当收集了大量资源后，进而下载限速，开启付费会员制度  BT下载讲究共享精神，这跟互联网的共享精神一脉相承，所以请不要在BT下载器设置里面限制上传速度。\n鉴于这类自私行为对其它合理使用P2P网络的用户的伤害，现在的很多P2P软件都加入反吸血功能。就是说检测到特定用户的吸血行为或者吸血软件时自动对这些用户降权处理，简单来说就是你的上传速度低的话，你的下载速度也不会特别快。\n这里又要多嘴一句\n 迅雷靠着自身在国内多年的发展，服务器里囤积了大量资源，所以很多其他BT下载器下载不动的资源，可能只有迅雷下载的动（因为它原来从别人那里下载了后存在了它的服务器上） 同理，很多文件可能只有115才能能离线下载，也是因为当年的115就存储了大量的资源在它服务器上 这里顺便可以说一下，所谓的百度云秒离线功能，不过是在你离线下载之前，已经有人把这个文件离线下载到百度云服务器中了  BT下载带来的好处\n 快。减少了网路传输节点。 减轻服务器压力。如果某公司有新版本软件推出（如LOL游戏更新时），服务器必定会人山人海，而使用BT能大大减轻服务器的负担，节约服务器的购置成本。 保护隐私。与有http那种中央服务器的网络系统不同，BT下载节点能遍布整个互联网（每个人都是分享者与下载者），给包括开发者在内的任何人、组织、或政府带来监控难题。  坏处当然也有，从上面第3点不难得出，BT下载很容易导致一个问题：盗版泛滥——海盗湾。\n上面说过了，想加入BT下载的无中心网络，首先需要找Tracker服务器问路，于是Tracker服务器成为了版权组织打击的重点，他们的想法很明确，只要除掉了Tracker，BT下载就完了。\n然而魔高一尺道高一丈，需求带动发展，这反而促使了BT技术的一次大升级，这带来了磁力链接。\nMagNet 协议\nMagNet协议，也就是磁力链接，简称磁链。 Magnet不需要Tracker服务器，也不需要.torrent文件，仅需要一串字符就可以进行文件下载。\n磁力链接基于的是DHT网络技术，因此可以在无固定Tracker服务器的情况下下载，实际过程是把所有下载者都变成一个小型Tracker服务。\nDHT技术：2002年，纽约大学的两个教授Petar Maymounkov和David Mazières发表了一篇论文，提出了一种真正去中心化的“点对点”下载模型，他们将其称为Kademlia方法。2005年，BT软件开始引入这种技术，在BT中被称为DHT协议（Distributed Hash Table，分布式哈希表）。\nDHT是一种分布式存储方法。DHT的作用是找到那些与本机正在下载（上传）相同文件的对端主机（Peer），当然，实现这一过程并不依赖Tracker服务器。在DHT网络中的每个客户端负责一个小范围的路由，并负责存储一小部分数据，从而实现整个DHT网络的寻址和存储。这种信息获取方式保证了整个网络没有单个的中心，即使一个节点下线，依然可以通过其他节点来获取文件，因此也就不需要Tracker服务器来告诉你，其他节点在什么地方。\nPEX：是Peer Exchange的简写，我们可以将其理解为“节点信息交换”。虽然DHT解决了去中心化的问题，但要在没有“中心协调员”（Tracker）的情况下实现高效寻址，就要借助PEX。PEX所提供的功能有点类似于以前的Tracker服务器，但工作方式却非常不同，我们可以打个比方来说明：\n 当你得到一个磁力链接并进行下载时，使用比如迅雷，迅雷就会实例化出一个DHT节点，加入DHT网络 把DHT网络比作一个朋友圈子，当你被A带进这个朋友圈，此刻你就只认识A而已 但是你的目的是想找唐纳德·特朗普（川普）总统，所以你就问A要川普的联系方式，但是A也没有川普的联系方式， 他介绍了一个美国朋友B给你认识 于是你去问B要川普的联系方式，B其实也没有川普的联系方式，但是B认识一个美国州长C 于是你又得到了C的联系方式，C把川普的联系方式告诉你之后，你就可以写信或者致电给川普了  这里相关的有个有趣的理论「六度分隔理论」（也叫六度空间理论）：简单来说，就是最多通过6个中间人你就能够认识世界上任何一个陌生人。\nMagnet links（磁力链接）示例：\nmagnet:?xt=urn:btih:36684b463ca2aa2f9347b18e9f6b1a9090bdb073\u0026amp;dn=Microsoft+iSCSI+Initiator  magnet：协议名。 xt：exact topic的缩写，表示资源定位点。BTIH（BitTorrent Info Hash）表示哈希方法名，这里还可以使用SHA1和MD5。这个值是文件的标识符，是不可缺少的。 dn：display name的缩写，表示向用户显示的文件名。这是一个可选项。 tr：tracker的缩写，表示tracker服务器的地址。这是一个可选项，本例中并未出现。  可能看出了DHT+PEX+Magnet Link模式中的一个问题——BT客户端的“第一步是如何迈出的”，套用在介绍PEX时使用的例子，那就是你怎怎么进入A的这个朋友圈的（即DHT节点如何进入DHT网络）？这确实是个问题。解决这个问题依然需要一台服务器（bootstrap node），不过这台服务器所起的作用与Tracker不同，它仅负责接纳DHT节点如何进入DHT网络，当DHT节点与其它DHT节点“搭上了话”，之后这台服务器就没有什么用处了。bootstrap node可以是不同BT客户端厂商独立运营的，也可以是几家联合共用，总之，它是分散的，只要在客户端软件中内置一张表单，那客户端就将有非常多的入口可供选择。\neD2k 协议\nBT / 磁力 / eD2k都是P2P技术 。eD2k链接对应的客户端，如eMule电骡是共享软件，而Magnet磁链对应的BT软件则是下载软件。这让它们在使用上，有着很多根本性的区别：\n BT使用的时候，只要你不下载东西你就不会上传 eMule电骡不同，比如，开启eMule电骡后，第一件事做的并不是什么下载，而是设置共享目录，该目录中的所有文件，都会实时共享到eD2k网络和KAD网络中。 目录中共享了的文件都会生成eD2k链接，所有人通过相应的eD2k链接，都能够拿到你共享的文件，一旦有人下载相应文件，那么你的eMule客户端就会上传数据，换言之，你想下载别人的文件，需要别人开着eMule客户端 我们平时使用eD2k链接下载，资源也是来自他人eMule所共享的文件的。当然，共享目录中也可以啥都不放，但很多eMule客户端都拥有队列优先级机制，上传得少，下载速度也会被限制。  电驴可以说是进化版的BT，用户不需要下载什么种子文件了，直接在“电驴”软件上输入eD2k开头的一长串代码一样的链接，就能下载。\n电驴以及后来的电骡、VERYCD电驴还有各种类似的软件，采用的eD2k网络仍是基于服务器的，你需要连接到服务器并从服务器索引 / 查找用户或者文件\n重要的是电驴提供的其中一种模式——KAD网络（类似磁力下载中的DHT网络），能够脱离中央服务器，直接实现网络来用户之间的点对点传输\n历史证明，这个脱离中央服务器的革新，真的十分十分的重要——这是电驴软件在面对盗版问题时，能够生存下来的主要原因，因为他们可以说，那是用户之间的自发传输行为，没有经过服务器\n但是，尽管电驴做了如此多的革新，但还是逃不过被时代淘汰的命运，客户端对于大部分人来说配置起来十分复杂，愿意一直开着服务器上传资源的人越来越少，更多人只想单纯的索取（类似上文提到的迅雷吸血行为），如今使用eD2k分享资源的人实在算少数，远不如磁力下载。\nOthers AriaNg\nAriaNg 是一个让 aria2 更容易使用的现代 Web 前端\n 使用很简单，将文件下载解压即可，可以本地打开 index.html 文件，也可上传到服务器。 如果您懒得部署 AriaNg ，可以直接访问现成的 http://a2.ssss.fun 。 打开后需要配置 AriaNg，打开 AriaNg 设置 - RPC，修改 Aria2 RPC 地址 和 Aria2 RPC 密钥 ，点击 重新加载 AriaNg 即可。  WebUI-Aria2\n这个项目的目标是创建世界上最好和最热门的界面来与 aria2 交互。\n使用非常简单，只需在任何网络浏览器中下载并打开 index.html。\nAria2 for \u0026hellip;.\n比如 YAAW for Chrome、Aria2 for Chrome 、Aria2 for Edge 之类的。\n在浏览器中直接内置一个 AriaNg，用于直接管理 Aria2。\nUsing Aria2 as a Daemon\n运行 gnome-session-properties打开应用程序首选项管理，添加：\n Name: Aria2 Daemon Command: /usr/bin/aria2c --conf-path=/home/kurome/.aria2/aria2.conf -D  会建立 .config/autostart/aria2c.desktop\n[Desktop Entry] Type=Application Exec=/usr/bin/aria2c --conf-path=/home/vane/.aria2/aria2.conf -D Hidden=false NoDisplay=false X-GNOME-Autostart-enabled=true Name[en_US]=Aria2 Daemon Name=Aria2 Daemon Comment[en_US]= Comment= BT 下载预热\n是这样滴，和很多BT客户端一样，Aria2有个dht.dat文件(开启ipv6还有个dht6.dat)，这玩意用于存储一种叫做DHT Routing Table的东西，DHT网络由无数节点组成，你接触到一个后能通过它接触到更多的节点，Aria2我记得是有内置的节点，但是！如果你在Aria2第一次运行的时候直接下载磁力链接或者冷门种子，你很可能遇到连MetaData都无法获取的情况，这就是因为第一次只是初始化dht.dat文件，你本地不存在DHT Routing Table的缓存，所以你无法从DHT网络中获取足够的数据。\n那么怎么办？我的建议是，找个热门种子(千万建议是种子，而不是磁力链接)，然后下一波，挂着做种，过几个小时后退出Aria2，或者等Aria2会话自动保存，你会发现dht.dat从空文件变成有数据了，这时候你下载就会正常很多。\n什么是PT，PT和BT有什么不同？\n答：PT（Private Tracker）下载其实也是Bt下载的一种，但有两个明显的改进：一是私密的小范围下载，二是进行流量统计，根据上载量决定你的权限。\nBT下载时，软件会分析.torrent种子文件得到Tracker地址，然后连接Tracker服务器，服务器返回其他下载者的IP，下载者再与这些IP联系进行下载，从而减轻了服务器的负担，BT下载的Tracker是公开的，而Private Tracker 下载(PT下载)的Tracker则是私有的，每个人的Tracker是不同的，即passkey不同，passkey对PT下载者很重要，所以不要轻易泄露出去。\n其实和通常BT相比，PT就是多了一个passkey验证，这样就能保证未注册的用户不能下载。所以passkey很重要，一旦发现有问题，就要到站点上去重置passkey。Tracker Server根据passkey把BT客户端上传量和下载量进行计算，从而算出分享率(上传量/下载量)。如果分享率太小，将会被删除帐号，从而不能下载。\n这样Private Tracker 下载(PT下载)是一种小范围的BT下载，通过禁用DHT有要求地选择并控制用户数量，这样，在有限的范围内，下载的用户基本上都可以达到自己的宽带上限，Private Tracker 下载(PT下载)下载还通过论坛等方式的约束机制将BT下载的理念现实化，真正让用户做到下载的过程中努力上传。因此，Private Tracker 下载(PT下载)的速度很快，能够让用户款待得到最大程度的使用。\nPT通过对做种时间和流量的要求在一定程度上避免了BT中存在的下完不做种的现象，因此在网络上，尤其是需要大文件（如高清）资源交换的时候广受欢迎，在PT站里，“水管”代表上传带宽的大小，大水管可以通过快速的上传获得积分，PT站点也会采取措施（比如做种时间，优惠等）使上传较慢的小水管能够参与贡献和共享资源。\nRPC\n首先了解什么叫RPC，为什么要RPC，RPC是指远程过程调用，也就是说两台服务器A，B，一个应用部署在A服务器上，想要调用B服务器上应用提供的函数/方法，由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义和传达调用的数据。\n比如说，一个方法可能是这样定义的：\nEmployee getEmployeeByName(String fullName) 那么：\n 首先，要解决通讯的问题，主要是通过在客户端和服务器之间建立TCP连接，远程过程调用的所有交换的数据都在这个连接里传输。连接可以是按需连接，调用结束后就断掉，也可以是长连接，多个远程过程调用共享同一个连接。 第二，要解决寻址的问题，也就是说，A服务器上的应用怎么告诉底层的RPC框架，如何连接到B服务器（如主机或IP地址）以及特定的端口，方法的名称名称是什么，这样才能完成调用。比如基于Web服务协议栈的RPC，就要提供一个endpoint URI，或者是从UDDI服务上查找。如果是RMI调用的话，还需要一个RMI Registry来注册服务的地址。 第三，当A服务器上的应用发起远程过程调用时，方法的参数需要通过底层的网络协议如TCP传递到B服务器，由于网络协议是基于二进制的，内存中的参数的值要序列化成二进制的形式，也就是序列化（Serialize）或编组（marshal），通过寻址和传输将序列化的二进制发送给B服务器。 第四，B服务器收到请求后，需要对参数进行反序列化（序列化的逆操作），恢复为内存中的表达方式，然后找到对应的方法（寻址的一部分）进行本地调用，然后得到返回值。 第五，返回值还要发送回服务器A上的应用，也要经过序列化的方式发送，服务器A接到后，再反序列化，恢复为内存中的表达方式，交给A服务器上的应用  为什么RPC呢？就是无法在一个进程内，甚至一个计算机内通过本地调用的方式完成的需求，比如比如不同的系统间的通讯，甚至不同的组织间的通讯。由于计算能力需要横向扩展，需要在多台机器组成的集群上部署应用，\nRPC的协议有很多，比如最早的CORBA，Java RMI，Web Service的RPC风格，Hessian，Thrift，甚至Rest API。\n其他下载工具\n qBittorrent Transmission rTorrent Deluge  有支持ed2k的计划吗？\n真是笑死我了，你们难道真的认为那所谓迅雷等国产BT下载软件会使用真正的eDonkey网络？\n非也！它们只不过通过ed2k链接所列出的哈希值 直接链接到它们服务器自身（如迅雷、百度）所存储的文件 或链接到BitTorrent协议的种子和磁力链接上。你们用的软件不是P2P（Peer to Peer），而是P2SP（Peer to Server and to Peer）！\n如果你们用过真正的ed2k下载器（如eMule、aMule）的话，你们会发现，真正的eDonkey网络早已消亡，截至目前全球用户也就50-60万的样子。\n最后，作为曾经的eMule老用户，我可以说明真正的eDonkey网络不仅有繁琐的排队机制，还有文件优先级网络优先级等复杂的设定，远比你们想像中难用的多。\nwarez groups\n  RELOADED\nRELOADED成立于2004年，前身是传奇破解组DEVIANCE，曾经在2次重大的政府扫荡中生存下来，由于竞争对手HOODLUM和VENGEANCE被端掉，RELOADED从此称霸PC游戏破解圈，在新游的首发破解上，RELOADED能占据80%。\nRELOADED也是国内最常见的PC游戏破解组，你在各个资源站看到标题写着某某游戏“R组”破解，就是他们的“杰作”。\n高光时刻：\n1、各大破解组都在追求游戏发售前破解游戏，而RELOADED最著名的应该就是2008年对《刺客信条》的破解了，R组在游戏发售1个月之前就放出破解版。\n2、修复了《彩虹六号：维加斯2》数字版的BUG，育碧当年对《彩虹六号：维加斯2》数字版无法运行的BUG毫无办法，最终只能给玩家发放RELOADED的游戏破解补丁\u0026hellip;这次事件让育碧颜面扫地，却成就了RELOADED。\n3、打破《分裂细胞：混沌理论》424天不被破解的记录。\n  SKIDROW\nSKIDROW 是来自美国的游戏破解组，成立时间大概是上个世纪90年代，主要作品有《猎杀潜艇5》、《刺客信条2》等，之后由于人员解散，直到2007年 SKIDROW 才重新开始活跃。\nSKIDROW 在同行中的口碑一般，被RELOADED等破解组爆出过盗用其他破解组代码的料。\n1、 Skidrow成名于DRM事件，DRM是育碧的反破解系统，Skidrow破解组成功破解了育碧两袋DRM系统，最著名的作品是对《刺客信条2》的破解。\n2、2017年，继CPY之后，成功破解了最新的Denuvo64加密技术。并批评CPY只会用Emulation(仿真器)而不是真正的破解。\n  Razor1911\nRazor1911 是来自挪威的破解组，成立于1985年，最初由3个年轻的计算机爱好者组成，主要是破解Commodore64和amiga机种的游戏软件，名称中的1911是因为1991在16进制里写作777，代表不朽。\n作为老牌破解组之一， Razor1911在2001年和2004年的FBI两次反盗版行动中幸存下来，不知道是不是因为名字带来的好运。在业内，如果说RELOADED是以高产著称，那么Razor1911就是以技术见长。\nRazor1911破解组最著名的作品应该是《星际争霸：母巢之战》的硬盘版，间接导致了星际争霸在全世界的流行。\n1、制作《星际争霸：母巢之战》硬盘版，在这一版的星际争霸中，所有文件的体积加起来只有100m多一点，而最为经典的地方就在于他们把光盘版中两个600m左右的install.exe文件压缩到了只有22m的大小。\n2、破解《GTA4》和该游戏价值20万美元的SecuRom反破解系统。\n3、破解EA origin平台的加密技术。\n4、破解《孤岛危机》和《上古卷轴5：天际》。\n  CPY\nCPY全名 CONSPiR4CY，是来自于意大利的破解组，成立于1999年，相比上面的三大破解组成立较晚。但是最近几年，CPY在破解了Denuvo加密技术（D加密）后名声大噪，俨然已超越了上面三大破解组。\n在国内有CPY掌握核心技术的说法，Steam、EA origin、Denuvo等加密技术先后被CPY破解。\n高光时刻：\n1、2015年，继Steam平台后，EA origin平台加密技术被破解，宣布了这套加密系统彻底完蛋。\n2、破解D加密技术，随后一系列热门游戏遭到破解，包括：《合金装备5 幻痛》《古墓丽影 崛起》《毁灭战士4》《看门狗2》等等。\n  CODEX\n会破解D加密，如今几乎已经垄断破解业。并在.nfo文件招聘栏中提到CODEX什么都不要，只要竞争!\n2022年2月，CODEX宣告退休。\n PLAZA EMPRESS    STEAMPUNKS\n  youtube-dl youtube-dl 是一个命令行程序，用于从 YouTube.com 和更多其他网站下载视频。 基于 Python 实现，不限于特定平台。\n# 安装 $ pip install -i https://pypi.tuna.tsinghua.edu.cn/simple youtube-dl # 使用 $ youtube-dl [OPTIONS] URL [URL...] 当前版本（2021.06.06）不能下载哔哩哔哩播放列表，可以用类似软件如 you-get， annie 代替。\nUsage 下载视频或整个视频播放列表\n 要从 Youtube 下载视频或整个视频播放列表，只需直接使用 URL 即可：youtube-dl [url]。程序自动选择一个最清晰的格式下载。 如果要指定视频下载之后的名称，可以使用如下方式：youtube-dl -o '名称' [url]。 还可以在下载视频时附加更多详细信息，可用的参数有标题、上传者名称（频道名称）和视频上传日期等：youtube-dl -o '%(title)s by %(uploader)s on %(upload_date)s in %(playlist)s.%(ext)s' [ul]。  查看视频的所有类型，只看不下载\n命令：youtube-dl -F [url]或者youtube-dl --list-formats [url]。 这是一个列清单参数，执行后并不会下载视频，但能知道这个目标视频都有哪些格式存在，以便有选择的下载。\n下载指定质量的视频和音频并自动合并\n下载最佳/最差质量的音/视频文件：\n默认情况下，youtube-dl将自主选择最佳质量的视频下载。 但是，也可以以特定的质量或格式来下载视频或播放列表\nYoutube-dl 支持以下品质：\n best选择最佳质量的音/视频文件 worst选择质量最差的格式（视频和音频） bestvideo选择最佳质量的仅视频格式（例如DASH视频），可能无法使用。 worstvideo选择质量最差的纯视频格式，可能无法使用。 bestaudio选择最优质的音频格式，可能无法使用。 worstaudio选择质量最差的音频格式，可能无法使用。  例如，如果要自动选择并下载最佳质量格式（音频和视频），只需使用以下命令：youtube-dl -f best [url]。\n您还可以组合使用以下不同的格式选项：youtube-dl -f bestvideo+bestaudio [ul]。该命令将分别下载最高质量的仅视频和最高质量的纯音频格式，再用ffmpeg或avconv合并成一个最佳质量的mkv文件；如果您不想合并，请将+（加号）替换为,（逗号）即可分别得到最高质量的音频和视频（两个文件）：youtube-dl -f 'bestvideo,bestaudio' [url]。\n 下载指定质量的音/视频文件：\n-F 获取的所有视频格式的清单，最左边一列就是编号对应着不同的格式。由于YouTube的1080p及以上的分辨率都是音视频分离的，所以我们需要分别下载视频和音频，可以使用137+140这样的组合。如果系统中安装了ffmpeg的话，youtube-dl 会自动合并下好的视频和音频，然后自动删除单独的音视频文件：youtube-dl -f [format code] [url]。\n从播放列表下载视频时，某些视频可能没有相同的格式。 在这种情况下，可以按首选顺序指定多个格式代码，例如：命令youtube-dl -f 22/17/18 \u0026lt;playlist_url\u0026gt;将以格式 22 下载视频（如果可用）；如果格式 22不可用，则它将下载格式 17（如果可用）；如果格式 22 和 17 都不可用，最后尝试下载格式 18。如果所有格式代码都不匹配，Youtube-dl 会报出提示。还需要注意的是，斜杠是左关联的，即最左侧的格式代码是首选。\n下载字幕\n youtube-dl --write-sub [url]这样会下载一个vtt格式的英文字幕和mkv格式的1080p视频下来 youtube-dl --write-sub --skip-download [url]下载单独的vtt字幕文件,而不会下载视频 youtube-dl --write-sub --all-subs [url]下载所有语言的字幕(如果有的话) youtube-dl --write-auto-sub [url]下载自动生成的字幕(YouTube only)  下载多个视频\n youtube-dl \u0026lt;url1\u0026gt; \u0026lt;url2\u0026gt;有时我们需要一次下载多个不同的视频，此时我们只需用空格将多个URL分隔开即可。 youtube-dl -a url.txt也可以将要下载视频的URL全部放在文本文件中，并将其作为参数传递给youtube-dl。此命令将下载url.txt文件中所有URL指向的视频。  只下载（视频中的）音频\n youtube-dl -x [url]仅从视频网站下载其音频。 youtube-dl -x --audio-format mp3 [ul]默认情况下，youtube-dl 将以Ogg （opus）格式保存音频。此命令将从给定的视频/播放列表下载音频，将其转换为 MP3 并将其保存在当前目录中。应注意：您应该安装 ffmpeg 或 avconv 将文件转换为 mp3 格式。  下载带有描述、元数据、注释、字幕和缩略图的视频\n要下载视频及其他详细信息，如：说明、元数据、注释、字幕和缩略图等，请使用以下命令： youtube-dl --write-description --write-info-json --write-annotations --write-sub --write-thumbnail [url]\n通过文件扩展名下载音/视频\n 以您的首选格式下载视频，例如 MP4，只需执行：youtube-dl --format mp4 [url]或者youtube-dl -f mp4 [url]。 某些视频可能无法以您的首选格式提供。 在这种情况下，youtube-dl 将下载其他最佳可用格式。例如： youtube-dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best' [ul] 此命令将下载最佳质量的MP4格式文件。如果 MP4 格式不可用，则它将下载其他最佳可用格式。  限制下载视频的大小\n从YouTube播放列表下载多个视频时，您可能只想下载特定大小的视频。例如：\n 此命令不会下载任何小于指定大小（例如100MB）的视频：youtube-dl --min-filesize 100M \u0026lt;playlist_url\u0026gt;。 如果您不想下载大于给定大小的视频，可以这样：youtube-dl --max-filesize 100M \u0026lt;playlist_url\u0026gt;。  我们还可以用组合格式，选择运算符来下载特定大小的视频。例如：\n 以下命令将下载最佳视频格式但不大于 100MB 的视频：youtube-dl -f 'best[filesize\u0026lt;100M]' [url]。  按日期下载视频\nYoutube-dl 允许我们按照上传日期来筛选和下载视频或播放列表，例如：\n 要下载 2019 年 8 月 1 日上传的视频，可以使用：youtube-dl --date 20190801 [URL]； 下载在特定日期或之前上传的视频：youtube-dl --datebefore 20190801 [URL]； 下载在特定日期或之后上传的视频：youtube-dl --dateafter 20190101 [URL]； 仅下载过去 6 个月内上传的视频：youtube-dl --dateafter now-6months [URL]； 下载特定时间段内（例如 2018 年 1 月 1 日至 2019 年 1 月 1 日）上传的视频：youtube-dl --dateafter 20180101 --datebefore 20190101 [URL]。  从播放列表下载特定的视频\n从播放列表下载特定的视频，是youtube-dl 的另一个非常有用的功能。例如：\n 要从播放列表下载第 10 个文件，可使用：youtube-dl --playlist-items 10 [playlist_url]； 要下载多个指定的文件，只需用逗号分隔：youtube-dl --playlist-items 2,3,7,10 [playlist_url]；  也可以按序号来指定要下载范围，例如：\n 从第 10 个开始，直接下载完整个列表：youtube-dl --playlist-start 10 [playlist_url]； 在播放列表中仅下载从第 2 到第 5 的文件：youtube-dl --playlist-start 2 --playlist-end 5 [playlist_url]。  Configuration 在 Linux 和 macOS 上，系统配置文件位于 /etc/youtube-dl.conf，用户配置文件位于 ~/.config/youtube-dl/config。\n# Continue on download errors, for example to skip unavailable videos in a playlist --ignore-errors # Time to wait before giving up, in seconds --socket-timeout 10 # Download only videos not listed in the archive file. Record the IDs of all downloaded videos in it. #--download-archive /path/archive.txt # Number of retries (default is 10), or \u0026#34;infinite\u0026#34;. --retries infinite # Give these arguments to the external downloader --external-downloader aria2c --external-downloader-args \u0026#34;--no-conf -c\u0026#34; # Output filename template, see the \u0026#34;OUTPUT TEMPLATE\u0026#34; for all the info -o \u0026#39;~/Videos/%(id)s.%(ext)s\u0026#39; # Write thumbnail image to disk #--write-thumbnail # download best 30hz mp4 file , h264+aac ,use http or https protocol,because we can use aria2c downloader to have a faster speed --format \u0026#39;(bestvideo[ext=mp4][fps\u0026lt;31]+bestaudio[ext=m4a]/best[ext=mp4]/bestvideo+bestaudio/best)[protocol^=http]\u0026#39; # Embed thumbnail in the audio as cover art #--embed-thumbnail # Write metadata to the video file --add-metadata curl 简介 curl 是常用的命令行工具，用来请求 Web 服务器。它的名字就是客户端（client）的 URL 工具的意思。\n它的功能非常强大，命令行参数多达几十种。如果熟练的话，完全可以取代 Postman 这一类的图形界面工具。\n本文介绍它的主要命令行参数，作为日常的参考，方便查阅。\n不带有任何参数时，curl 就是发出 GET 请求。\n$ curl https://www.example.com 上面命令向www.example.com发出 GET 请求，服务器返回的内容会在命令行输出。\n主要命令行参数 -A\n-A参数指定客户端的用户代理标头，即User-Agent。curl 的默认用户代理字符串是curl/[version]。\n$ curl -A \u0026#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36\u0026#39; https://google.com 上面命令将User-Agent改成 Chrome 浏览器。\n$ curl -A \u0026#39;\u0026#39; https://google.com 上面命令会移除User-Agent标头。\n也可以通过-H参数直接指定标头，更改User-Agent。\n$ curl -H \u0026#39;User-Agent: php/1.0\u0026#39; https://google.com -b\n-b参数用来向服务器发送 Cookie。\n$ curl -b \u0026#39;foo=bar\u0026#39; https://google.com 上面命令会生成一个标头Cookie: foo=bar，向服务器发送一个名为foo、值为bar的 Cookie。\n$ curl -b \u0026#39;foo1=bar;foo2=bar2\u0026#39; https://google.com 上面命令发送两个 Cookie。\n$ curl -b cookies.txt https://www.google.com 上面命令读取本地文件cookies.txt，里面是服务器设置的 Cookie（参见-c参数），将其发送到服务器。\n-c\n-c参数将服务器设置的 Cookie 写入一个文件。\n$ curl -c cookies.txt https://www.google.com 上面命令将服务器的 HTTP 回应所设置 Cookie 写入文本文件cookies.txt。\n-d\n-d参数用于发送 POST 请求的数据体。\n$ curl -d \u0026#39;login=emma＆password=123\u0026#39;-X POST https://google.com/login # 或者 $ curl -d \u0026#39;login=emma\u0026#39; -d \u0026#39;password=123\u0026#39; -X POST https://google.com/login 使用-d参数以后，HTTP 请求会自动加上标头Content-Type : application/x-www-form-urlencoded。并且会自动将请求转为 POST 方法，因此可以省略-X POST。\n-d参数可以读取本地文本文件的数据，向服务器发送。\n$ curl -d \u0026#39;@data.txt\u0026#39; https://google.com/login 上面命令读取data.txt文件的内容，作为数据体向服务器发送。\n\u0026ndash;data-urlencode\n--data-urlencode参数等同于-d，发送 POST 请求的数据体，区别在于会自动将发送的数据进行 URL 编码。\n$ curl --data-urlencode \u0026#39;comment=hello world\u0026#39; https://google.com/login 上面代码中，发送的数据hello world之间有一个空格，需要进行 URL 编码。\n-e\n-e参数用来设置 HTTP 的标头Referer，表示请求的来源。\ncurl -e \u0026#39;https://google.com?q=example\u0026#39; https://www.example.com 上面命令将Referer标头设为https://google.com?q=example。\n-H参数可以通过直接添加标头Referer，达到同样效果。\ncurl -H \u0026#39;Referer: https://google.com?q=example\u0026#39; https://www.example.com -F\n-F参数用来向服务器上传二进制文件。\n$ curl -F \u0026#39;file=@photo.png\u0026#39; https://google.com/profile 上面命令会给 HTTP 请求加上标头Content-Type: multipart/form-data，然后将文件photo.png作为file字段上传。\n-F参数可以指定 MIME 类型。\n$ curl -F \u0026#39;file=@photo.png;type=image/png\u0026#39; https://google.com/profile 上面命令指定 MIME 类型为image/png，否则 curl 会把 MIME 类型设为application/octet-stream。\n-F参数也可以指定文件名。\n$ curl -F \u0026#39;file=@photo.png;filename=me.png\u0026#39; https://google.com/profile 上面命令中，原始文件名为photo.png，但是服务器接收到的文件名为me.png。\n-G\n-G参数用来构造 URL 的查询字符串。\n$ curl -G -d \u0026#39;q=kitties\u0026#39; -d \u0026#39;count=20\u0026#39; https://google.com/search 上面命令会发出一个 GET 请求，实际请求的 URL 为https://google.com/search?q=kitties\u0026amp;count=20。如果省略--G，会发出一个 POST 请求。\n如果数据需要 URL 编码，可以结合--data--urlencode参数。\n$ curl -G --data-urlencode \u0026#39;comment=hello world\u0026#39; https://www.example.com -H\n-H参数添加 HTTP 请求的标头。\n$ curl -H \u0026#39;Accept-Language: en-US\u0026#39; https://google.com 上面命令添加 HTTP 标头Accept-Language: en-US。\n$ curl -H \u0026#39;Accept-Language: en-US\u0026#39; -H \u0026#39;Secret-Message: xyzzy\u0026#39; https://google.com 上面命令添加两个 HTTP 标头。\n$ curl -d \u0026#39;{\u0026#34;login\u0026#34;: \u0026#34;emma\u0026#34;, \u0026#34;pass\u0026#34;: \u0026#34;123\u0026#34;}\u0026#39; -H \u0026#39;Content-Type: application/json\u0026#39; https://google.com/login 上面命令添加 HTTP 请求的标头是Content-Type: application/json，然后用-d参数发送 JSON 数据。\n-i\n-i参数打印出服务器回应的 HTTP 标头。\n$ curl -i https://www.example.com 上面命令收到服务器回应后，先输出服务器回应的标头，然后空一行，再输出网页的源码。\n-I\n-I参数向服务器发出 HEAD 请求，然会将服务器返回的 HTTP 标头打印出来。\n$ curl -I https://www.example.com 上面命令输出服务器对 HEAD 请求的回应。\n--head参数等同于-I。\n$ curl --head https://www.example.com -k\n-k参数指定跳过 SSL 检测。\n$ curl -k https://www.example.com 上面命令不会检查服务器的 SSL 证书是否正确。\n-L\n-L参数会让 HTTP 请求跟随服务器的重定向。curl 默认不跟随重定向。\n$ curl -L -d \u0026#39;tweet=hi\u0026#39; https://api.twitter.com/tweet \u0026ndash;limit-rate4\n--limit-rate用来限制 HTTP 请求和回应的带宽，模拟慢网速的环境。\n$ curl --limit-rate 200k https://google.com 上面命令将带宽限制在每秒 200K 字节。\n-o\n-o参数将服务器的回应保存成文件，等同于wget命令。\n$ curl -o example.html https://www.example.com 上面命令将www.example.com保存成example.html。\n-O\n-O参数将服务器回应保存成文件，并将 URL 的最后部分当作文件名。\n$ curl -O https://www.example.com/foo/bar.html 上面命令将服务器回应保存成文件，文件名为bar.html。\n-s\n-s参数将不输出错误和进度信息。\n$ curl -s https://www.example.com 上面命令一旦发生错误，不会显示错误信息。不发生错误的话，会正常显示运行结果。\n如果想让 curl 不产生任何输出，可以使用下面的命令。\n$ curl -s -o /dev/null https://google.com -S\n-S参数指定只输出错误信息，通常与-s一起使用。\n$ curl -s -o /dev/null https://google.com 上面命令没有任何输出，除非发生错误。\n-u\n-u参数用来设置服务器认证的用户名和密码。\n$ curl -u \u0026#39;bob:12345\u0026#39; https://google.com/login 上面命令设置用户名为bob，密码为12345，然后将其转为 HTTP 标头Authorization: Basic Ym9iOjEyMzQ1。\ncurl 能够识别 URL 里面的用户名和密码。\n$ curl https://bob:12345@google.com/login 上面命令能够识别 URL 里面的用户名和密码，将其转为上个例子里面的 HTTP 标头。\n$ curl -u \u0026#39;bob\u0026#39; https://google.com/login 上面命令只设置了用户名，执行后，curl 会提示用户输入密码。\n-v\n-v参数输出通信的整个过程，用于调试。\n$ curl -v https://www.example.com --trace参数也可以用于调试，还会输出原始的二进制数据。\n$ curl --trace - https://www.example.com -x\n-x参数指定 HTTP 请求的代理。\n$ curl -x socks5://james:cats@myproxy.com:8080 https://www.example.com 上面命令指定 HTTP 请求通过myproxy.com:8080的 socks5 代理发出。\n如果没有指定代理协议，默认为 HTTP。\n$ curl -x james:cats@myproxy.com:8080 https://www.example.com 上面命令中，请求的代理使用 HTTP 协议。\n-X\n-X参数指定 HTTP 请求的方法。\n$ curl -X POST https://www.example.com 上面命令对https://www.example.com发出 POST 请求。\nHTTPie HTTPie（http）以一种更人性化的方式做同样的工作。你会看到彩色的、格式化的输出，这使得它更容易理解和调试。\naxel Lightweight CLI download accelerator\nUSENET 起源 简单地说，USENET是一个巨大无比的网上讨论组，一般也称为\u0026quot;新闻组\u0026quot;（newsgroups）。你可以将它想象成一个包罗万象、无所不有的网上论坛，但是它又不同于我们通常看到的普通论坛。这要从它的起源说起。\n上个世纪70年代末，当时还没有互联网和浏览器，它们都要在十多年后才会出现。那时所谓\u0026quot;上网\u0026quot;，就是用modem（调制解调器），拨一个电话号码，将自己的电脑连到另一台电脑（也称\u0026quot;主机\u0026quot;），收收邮件，看看上面系统管理员发的通告。如果想换一台主机看看，那就必须先挂断，再拨另外一个电话号码。\n这样的上网方式，很不利于开展多人的讨论。由于是拨号上网，只有地理位置相近的用户，才会登录同一台主机。很难想象，同一台机器的登录用户，既有东岸的纽约人，也有西岸的洛杉矶人。即使长途电话费不是问题，当时的主机也没有能力同时负担太多的远程终端。因此，迫切需要一种大规模的、分布式的、多中心的远程信息交换手段。\n1979年，Duke大学的两个研究生Tom Truscott和Jim Ellis，提出一种分布式的网上讨论组的构想。这种讨论组创建之初，主要是供UNIX爱好者协会（USENIX）的成员使用，因此就被定名为USENET。当然，后来全世界的用户都在使用它。\n运行机制 USENET的运行机制其实非常简单。对于用户来说，只有三步。\n1）网络服务提供商（ISP）在一个网络中，设定一台服务器作为USENET专用服务器，再将它的网址告诉用户。\n2）用户想要发言的时候，就向这个网址发送帖子（post），这与发送Email很相似，但是两者格式不一样，在USENET上发言必须使用专用的客户端。不过，现在大多数的Email客户端都带有新闻组功能，最常见的Outlook Express的设置可以参考网上的说明。\n3）查看其他人的发言时，就必须从服务器上下载其他人的帖子。下载完成后，如果想回复某人的帖子，就再重复第二步。\n可以看到，这个过程同邮件列表的运行几乎一模一样，不同之处在于，USENET服务器每天会同其他USENET服务器交换帖子。这就是说，全世界所有的USENET服务器最终都可以互相交换帖子，保持内容的同步。所以理论上，不管你的帖子是发到哪一台服务器上，最终全世界的人们都会看到，并且会从世界各地给你回复。\n因此，USENET就有一个其他交流机制所没有的优点，即这是一个真正的全世界参与的讨论组。\n内容结构 由于USENET中的讨论内容无所不包，所以必须根据主题分类。每一个主题就是一个\u0026quot;频道\u0026quot;，对这个主题感兴趣的用户就订阅这个频道。\nUSENET中的主题分类采用等级制（hierarchies），在形式上同域名很相似，即\u0026quot;一级主题.二级主题.三级主题\u0026hellip;.\u0026quot;，中间以小数点分隔。\n一级主题有9个。\n * comp.*: 与计算机相关的讨论。（computer-related discussions，比如comp.software, comp.sys.amiga）\n* misc.*: 各种不属于其他分类的主题。（Miscellaneous topics，比如misc.education, misc.forsale, misc.kids）\n* news.*: 对USENET本身的讨论（比如news.groups, news.admin）\n* rec.*: 休闲和娱乐（Recreation and entertainment，比如rec.music, rec.arts.movies）\n* sci.*: 与科学相关的讨论。（Science related discussions，比如sci.psychology, sci.research）\n* soc.*: 与社会相关的讨论。（Social discussions，比如soc.college.org, soc.culture.african）\n* talk.*: 各种争议性话题的讨论。（Talk about various controversial topics，比如talk.religion, talk.politics, talk.origins）\n* humanities.*: 艺术、文学、哲学方面的讨论。（Fine arts, literature, and philosophy，比如humanities.classics, humanities.design.misc）\n* alt.*: 自由讨论区。（alternative）\n 这9个一级主题中，除了alt.*以外，都不能自行设立讨论区。只有在alt主题区中，可以自己发起主题\u0026quot;频道\u0026quot;。\n二进制内容 USENET最初设计的时候，只打算用来传递文本信息，没有考虑传递二进制数据（也就是\u0026quot;文件\u0026quot;）。但是，随着互联网的发展，不传递二进制数据看上去是不可能的。\n于是，专门的编码方式被设计了出来，使得二进制文件可以转换成文本文件，在USENET上传递，用户下载以后再传换成原来的格式。这时，USENET就不仅是一个讨论组了，而成了传递文件的一种手段，图片、音频和视频都可以通过USENET传播。\n事实上，如今USENET上的流量，99%都已经是二进制文件了。它们大部分都在alt.binaries这个主题中传播。由于不受监管，所以各种各样的文件都有。\n收费服务 根据一项统计，2007年4月USENET上一天的流量为3.12TB，且还在快速增加中。这么大的流量，使得世界上提供USENET的服务商肯定不会很多。大家可以查看这个网页，上面有USENET提供商的不完全列表。\n这些服务商，又分为免费和收费两种。免费的USENET绝大多数都不提供二进制文件下载，查看alt.free.newsservers主题可以获得最新的免费USENET服务器的信息。\n在收费服务商中，名气比较大的是GIGANEWS，它提供多种收费账户供用户选择。其中白金用户每月费用为19.99美元，可以无限量下载，14天内不满意可以退款。如果你是一个狂热的下载爱好者，我强烈推荐去购买一个账户。\nGoogle Groups Google Groups也提供免费USENET服务。（当然，没有二进制文件下载。）我会另写文章专门介绍，这里就省略了。\nEditor VSCode 中国国内下载 VSCode 速度慢问题解决：使用 azure 中国 cdn 镜像地址加速下载 VSCode\n将默认下载地址\nhttps://az764295.vo.msecnd.net/stable/ 替换为 vscode.cdn.azure.cn\nhttps://vscode.cdn.azure.cn/stable/ 自动换行\n将word wrap的off改成on\n最适合程序员的笔记软件\nhttps://github.dev/[用户名]/[仓库名] 大小写转换快捷键\n File-\u0026gt;Preference-\u0026gt;Keybord Shortcuts 或直接按ctrl+k+ctrl+s 在上面的搜索栏中，输入 Transform 就可以看到有Transform to Uppercase和Trasnfrom to Lowercase的命令 设置快捷键  Google Keep Now I am using Google Keep.\nGoogle Keep键盘快捷键\n   hortcut Action     J/K Next/previous note   Shift + J/K Move note to next/previous position   N/P Next/previous list item   Shift + N/P Move list item to next/previous position   C New note   L New list   / Search   Ctrl + A Select all   E Archive   # Delete   F Pin/unpin   X Select   Ctrl + G Toggle list and grid view   Esc Close editor   Ctrl + Shift + 8 Toggle checkboxes   Ctrl + ] / [ Indent/dedent list item   ? Open shortcut list   @ Send feedback    Joplin+Typora+OneDrive Joplin $ wget -O - https://raw.githubusercontent.com/laurent22/joplin/dev/Joplin_install_and_update.sh | bash Typora 安装：\n# sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys BA300B7755AFCFAE $ wget -qO - https://typora.io/linux/public-key.asc | $ sudo apt-key add - # add Typora\u0026#39;s repository $ sudo add-apt-repository \u0026#39;deb https://typora.io/linux ./\u0026#39; $ sudo apt-get update # install typora $ sudo apt-get install typora 如果安装的时二进制包，则建立 typora.desktop\n$ gedit ~/.local/share/applications/typora.desktop [Desktop Entry] Name=Typora Comment=a minimal Markdown reading \u0026amp; writing app. Change Log: (https://typora.io/windows/dev_release.html) GenericName=Markdown Editor Exec=/home/kurome/.typora/Typora %U Icon=/home/kurome/.typora/resources/assets/icon/icon_256x256.png Type=Application StartupNotify=true Categories=Office;WordProcessor; MimeType=text/markdown;text/x-markdown; typora 有时会出现丢数据的现象，很困扰；特别是围栏代码块，失去了缩进，成了一行，完全不可阅读了。但是其他的 Markdown Editor 用的不习惯，例如 VSCode、Sublime、ghostwriter、marktext。因此最好通过 ppa 安装，获取 Typora 最新的版本。\n在Joplin下，菜单Tools-\u0026gt;Options-\u0026gt;General\u0026gt;Text editor command可以设置第三方编辑软件。\n配置 File \u0026gt; Preferences：\n General \u0026gt; Auto Save: on Editor \u0026gt; Spell Check: Disable Image \u0026gt; Use relative path if possible: on Markdown \u0026gt; Syntax Support \u0026gt; Inline Math: on  有时候标点符号没有与文字对齐，比如句号在右中，而不是右下，可以将语言设置为中文（it works for me）。\nCrack Typora 1.0.4\n  需要python、nodejs 环境，没有的话自行安装一下\n$ sudo apt install pip nodejs   克隆脚本文件 https://github.com/Mas0nShi/typoraCracker.git\n  安装依赖:\n$ pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r ~/Downloads/typoraCracker-master/requirements.tx Missing dependencies for SOCKS support：\n关闭代理，安装 pysocks\n# Unset socks proxy $ unset all_proxy $ unset ALL_PROXY # Install missing dependencies: $ pip install pysocks # Reset proxy $ source ~/.bashrc   执行解包命名：\n$ cd ~/Downloads/Typora-linux-x64/bin/Typora-linux-x64/resources/ $ python3 ~/Downloads/typoraCracker-master/typora.py app.asar workstation/outfile   替换掉License.js文件\n$ cp ~/Downloads/typoraCracker-master/example/patch/License.js workstation/outfile/dec_app/   打包app.asar文件\n$ python3 ~/Downloads/typoraCracker-master/typora.py -u workstation/outfile/dec_app workstation/outappasar   将打包回来的app.asar文件重新丢到Typora的resources目录下\n$ cp workstation/outappasar/app.asar .   授权码生成\n$ node ~/Downloads/typoraCracker-master/example/keygen.js CAJ8Q4-ETFCZ4-RH3X85-GMKD68   激活：授权码输入生成的码，邮箱输入crack@example.com，完事。\n  综上，破解 Typora 其实就是破解 app.asar 文件，破解一次 Typora 后，保留 app.asar，不论在哪个平台，用破解后的 app.asar 覆盖原本的 app.asar，就能实现破解 Typora。\nRecover Unsaved Drafts Preferences =\u0026gt; General =\u0026gt; Save \u0026amp; Recover =\u0026gt; Recover Unsaved Drafts =\u0026gt; 选择要恢复的文档，打开后另存为到之前保存的地址覆盖它即可\nCtrl 5 of typora does not work 不知道哪里覆盖了。重新定义一个快捷键。\nOpen Menu → Preference in Typora, then click “Open Advanced Settings”.\n\u0026#34;keyBinding\u0026#34;: { \u0026#34;Heading 5\u0026#34;: \u0026#34;Alt+5\u0026#34;, }, MarkText Foxit PDF Reader Industry’s most powerful PDF reader.\nPortable PDF Unlocker PDFCrack pdftk OCRmyPDF OCRmyPDF adds an OCR text layer to scanned PDF files, allowing them to be searched\nWPS WPS Office is a lightweight, feature-rich comprehensive office suite with high compatibility.\n最好用 snap 或者 flatpak 版本，因为很久没更新了，只有 WPS 2019，没有适配新的 KDE 5 和 Gnome 40。\nSublime Text Atom Vim vi 与 vim.tiny $ whereis vi vi: /usr/bin/vi /usr/share/man/man1/vi.1.gz $ ls -al /usr/bin/vi lrwxrwxrwx 1 root root 20 Oct 26 20:31 /usr/bin/vi -\u0026gt; /etc/alternatives/vi $ ls -al /etc/alternatives/vi lrwxrwxrwx 1 root root 17 Oct 26 20:31 /etc/alternatives/vi -\u0026gt; /usr/bin/vim.tiny 可见，在Ubuntu上，vi是vim.tiny的软连接，但是执行命令vi与vim.tiny后是不一样，比如vi是：在编辑模式下使用方向键的时候，并不会使光标移动，而是在命令行中出现[A [B [C [D之类的字母；并且编辑错误的话，退格键(Backspace键)是使用不了的。\nMethods to find out which (configuration) files are read by executable when started-\u0026gt;\u0026lsquo;strace vim/nano\u0026rsquo; (Ubuntu)：\n$ strace -o $HOME/tracefile vi $ cat tracefile | grep vimrc stat(\u0026#34;/usr/share/vim/vimrc.tiny\u0026#34;, {st_mode=S_IFREG|0644, st_size=662, ...}) = 0 openat(AT_FDCWD, \u0026#34;/usr/share/vim/vimrc.tiny\u0026#34;, O_RDONLY) = 3 stat(\u0026#34;/home/vane/.vimrc\u0026#34;, 0x7fff3e755550) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/.vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/_vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) stat(\u0026#34;/home/vane/.vim/vimrc\u0026#34;, 0x7fff3e755550) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/.vim/vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) 可以看到 vi，加载的是 /usr/share/vim/vimrc.tiny\n$ strace -o $HOME/tracefile vim.tiny $ cat tracefile | grep vimrc stat(\u0026#34;/usr/share/vim/vimrc\u0026#34;, {st_mode=S_IFREG|0644, st_size=2266, ...}) = 0 openat(AT_FDCWD, \u0026#34;/usr/share/vim/vimrc\u0026#34;, O_RDONLY) = 3 stat(\u0026#34;/home/vane/.vimrc\u0026#34;, 0x7fff7c99cc30) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/.vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/_vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) stat(\u0026#34;/home/vane/.vim/vimrc\u0026#34;, 0x7fff7c99cc30) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026#34;/home/vane/.vim/vimrc\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) 可以看到 vim.tiny，加载的是 /usr/share/vim/vimrc\n$ diff -u /etc/vim/vimrc /etc/vim/vimrc.tiny --- /etc/vim/vimrc\t2020-01-30 19:11:47.000000000 +0800 +++ /etc/vim/vimrc.tiny\t2020-04-15 14:40:31.000000000 +0800 @@ -1,55 +1,13 @@ ... +\u0026#34; Vim configuration file, in effect when invoked as \u0026#34;vi\u0026#34;. The aim of this +\u0026#34; configuration file is to provide a Vim environment as compatible with the +\u0026#34; original vi as possible. Note that ~/.vimrc configuration files as other +\u0026#34; configuration files in the runtimepath are still sourced. +\u0026#34; When Vim is invoked differently (\u0026#34;vim\u0026#34;, \u0026#34;view\u0026#34;, \u0026#34;evim\u0026#34;, ...) this file is +\u0026#34; _not_ sourced; /etc/vim/vimrc and/or /etc/vim/gvimrc are. ... 可以看到，上面什么说明白了。\nVim clear last search highlighting :noh VIMRC The ultimate Vim configuration (vimrc)\ncopilot.vim Neovim plugin for GitHub Copilot\nNeovim Neovim 提出了将 Vim 扩展为一个 IDE 的想法。\n它增加了现代终端的功能，如光标样式、焦点事件、括号内粘贴等，并内置了一个终端模拟器。最重要的是，你不需要忘却 Vim 的习惯就可以开始使用 Neovim。\n最适合程序员的笔记软件 程序员的笔记软件，应该满足下面几个条件。\n 跨平台，同时支持桌面电脑（Windows，Mac，Linux）和手机（Android，iOS）。 随时同步，打开任何一台机器，都能接着上一次的工作继续写。 实时存储，如果软件突然关闭，也不会丢失内容。 支持 Markdown 格式，便于后期直接发布。 支持推送到远程 Git 仓库，产生历史版本，同时作为远程备份。  Stackedit.io 和 HackMD.io，都不是很理想。\nGitHub 官方推出的 github.dev。只要访问 https://github.dev/[用户名]/[仓库名]，你就能在浏览器里面，使用 VS Code 编辑指定仓库。它实际上就是 VS Code 编辑器的 Web 版，并且与 Git 高度集成。GitHub 提供了一个快捷入口。 打开 GitHub 仓库主页，按一下小数点（.）这个键， 页面就会自动跳转到 VS Code 编辑环境。\n如果你更希望使用手机原生 App，我推荐 Obsidian。它有全平台的客户端，并且可以参考这篇文章设置 Git 集成。\n评论里还有很多推荐，选择一个合适的就行。\nShell Tmux Tmux 是一个终端复用器（terminal multiplexer），非常有用，属于常用的开发工具。\n简介 会话与进程\n命令行的典型使用方式是，打开一个终端窗口（terminal window，以下简称\u0026quot;窗口\u0026quot;），在里面输入命令。用户与计算机的这种临时的交互，称为一次\u0026quot;会话\u0026quot;（session） 。\n会话的一个重要特点是，窗口与其中启动的进程是连在一起的。打开窗口，会话开始；关闭窗口，会话结束，会话内部的进程也会随之终止，不管有没有运行完。\n一个典型的例子就是，SSH 登录远程计算机，打开一个远程窗口执行命令。这时，网络突然断线，再次登录的时候，是找不回上一次执行的命令的。因为上一次 SSH 会话已经终止了，里面的进程也随之消失了。\n为了解决这个问题，会话与窗口可以\u0026quot;解绑\u0026quot;：窗口关闭时，会话并不终止，而是继续运行，等到以后需要的时候，再让会话\u0026quot;绑定\u0026quot;其他窗口。\nTmux 的作用\nTmux 就是会话与窗口的\u0026quot;解绑\u0026quot;工具，将它们彻底分离。\n 它允许在单个窗口中，同时访问多个会话。这对于同时运行多个命令行程序很有用。 它可以让新窗口\u0026quot;接入\u0026quot;已经存在的会话。 它允许每个会话有多个连接窗口，因此可以多人实时共享会话。 它还支持窗口任意的垂直和水平拆分。  类似的终端复用器还有 GNU Screen。Tmux 与它功能相似，但是更易用，也更强大。\n基本用法 安装\nTmux 一般需要自己安装。\n$ sudo apt-get install tmux 启动与退出\n安装完成后，键入tmux命令，就进入了 Tmux 窗口。\n$ tmux Tmux 窗口，底部有一个状态栏。状态栏的左侧是窗口信息（编号和名称），右侧是系统信息。\n按下Ctrl+d或者显式输入exit命令，就可以退出 Tmux 窗口。\n$ exit 前缀键\nTmux 窗口有大量的快捷键。所有快捷键都要通过前缀键唤起。默认的前缀键是Ctrl+b，即先按下Ctrl+b，快捷键才会生效。\n举例来说，帮助命令的快捷键是Ctrl+b ?。它的用法是，在 Tmux 窗口中，先按下Ctrl+b，再按下?，就会显示帮助信息。\n然后，按下 ESC 键或q键，就可以退出帮助。\n会话管理 新建会话\n第一个启动的 Tmux 窗口，编号是0，第二个窗口的编号是1，以此类推。这些窗口对应的会话，就是 0 号会话、1 号会话。\n使用编号区分会话，不太直观，更好的方法是为会话起名。\n$ tmux new -s \u0026lt;session-name\u0026gt; 上面命令新建一个指定名称的会话。\n分离会话\n在 Tmux 窗口中，按下Ctrl+b d或者输入tmux detach命令，就会将当前会话与窗口分离。\n$ tmux detach 上面命令执行后，就会退出当前 Tmux 窗口，但是会话和里面的进程仍然在后台运行。\ntmux ls命令或Ctrl+b s可以查看当前所有的 Tmux 会话。\n$ tmux ls # or $ tmux list-session 接入会话\ntmux attach命令用于重新接入某个已存在的会话。\n# 使用会话编号 $ tmux attach -t 0 # 使用会话名称 $ tmux attach -t \u0026lt;session-name\u0026gt; 杀死会话\ntmux kill-session命令用于杀死某个会话。\n# 使用会话编号 $ tmux kill-session -t 0 # 使用会话名称 $ tmux kill-session -t \u0026lt;session-name\u0026gt; 切换会话\ntmux switch命令用于切换会话。\n# 使用会话编号 $ tmux switch -t 0 # 使用会话名称 $ tmux switch -t \u0026lt;session-name\u0026gt; 重命名会话\ntmux rename-session命令或Ctrl+b $用于重命名会话。\n$ tmux rename-session -t 0 \u0026lt;new-name\u0026gt; 上面命令将0号会话重命名。\n最简操作流程 综上所述，以下是 Tmux 的最简操作流程。\n 在服务器端新建会话tmux new -s my_session。 在 Tmux 窗口运行所需的程序。 按下快捷键Ctrl+b d将会话分离。 下次使用时，重新连接到会话tmux attach-session -t my_session。  窗格操作 Tmux 可以将窗口分成多个窗格（pane），每个窗格运行不同的命令。以下命令都是在 Tmux 窗口中执行。\n划分窗格\ntmux split-window命令用来划分窗格。\n# 划分上下两个窗格，或 Ctrl+b \u0026#34; $ tmux split-window # 划分左右两个窗格，或 Ctrl+b % $ tmux split-window -h 移动光标\ntmux select-pane命令或Ctrl+b \u0026lt;arrow key\u0026gt;用来移动光标位置。\n# 光标切换到上方窗格，或 Ctrl+b ; $ tmux select-pane -U # 光标切换到下方窗格，或 Ctrl+b o $ tmux select-pane -D # 光标切换到左边窗格 $ tmux select-pane -L # 光标切换到右边窗格 $ tmux select-pane -R  Ctrl+b x：关闭当前窗格。 Ctrl+b !：将当前窗格拆分为一个独立窗口。 Ctrl+b z：当前窗格全屏显示，再使用一次会变回原来大小。 Ctrl+b Ctrl+\u0026lt;arrow key\u0026gt;：按箭头方向调整窗格大小。 Ctrl+b q：显示窗格编号。  交换窗格位置\ntmux swap-pane命令用来交换窗格位置。\n# 当前窗格上移，或 Ctrl+b { $ tmux swap-pane -U # 当前窗格下移，或 Ctrl+b } $ tmux swap-pane -D  Ctrl+b Ctrl+o：所有窗格向前移动一个位置，第一个窗格变成最后一个窗格。 Ctrl+b Alt+o：所有窗格向后移动一个位置，最后一个窗格变成第一个窗格。  窗口管理 除了将一个窗口划分成多个窗格，Tmux 也允许新建多个窗口。\n新建窗口\ntmux new-window命令用来创建新窗口。\n$ tmux new-window # 新建一个指定名称的窗口 $ tmux new-window -n \u0026lt;window-name\u0026gt; Ctrl+b c：创建一个新窗口，状态栏会显示多个窗口的信息。\n切换窗口\ntmux select-window命令用来切换窗口。\n# 切换到指定编号的窗口 $ tmux select-window -t \u0026lt;window-number\u0026gt; # 切换到指定名称的窗口 $ tmux select-window -t \u0026lt;window-name\u0026gt;  Ctrl+b p：切换到上一个窗口（按照状态栏上的顺序）。 Ctrl+b n：切换到下一个窗口。 Ctrl+b \u0026lt;number\u0026gt;：切换到指定编号的窗口，其中的\u0026lt;number\u0026gt;是状态栏上的窗口编号。 Ctrl+b w：从列表中选择窗口。  重命名窗口\ntmux rename-window命令或Ctrl+b ,用于为当前窗口起名（或重命名）。\n$ tmux rename-window \u0026lt;new-name\u0026gt; 其他命令 下面是一些其他命令。\n# 列出所有快捷键，及其对应的 Tmux 命令 $ tmux list-keys # 列出所有 Tmux 命令及其参数 $ tmux list-commands # 列出当前所有 Tmux 会话的信息 $ tmux info # 重新加载当前的 Tmux 配置 $ tmux source-file ~/.tmux.conf Fish 命令行是程序员的必备技能。图形界面虽然好看，解决问题还是要靠命令行。\n命令行由 Shell 提供。各种命令通过 Shell，传递给操作系统的内核。学习命令行就是在学习 Shell。\nShell 有好几种，目前最常用是 Bash 和 zsh。但是，在我看来，它们都不如 Fish Shell 好用。\n五年前，我第一次尝试 Fish，感到很惊艳，一直用到现在。本文介绍 Fish 的主要特点，希望你也来尝试它。\n简介 Fish 是\u0026quot;the friendly interactive shell\u0026quot;的简称，最大特点就是方便易用。很多其他 Shell 需要配置才有的功能，Fish 默认提供，不需要任何配置。\n如果你想拥有一个方便好用的 Shell，又不想学习一大堆语法，或者花费很多时间配置，那么你一定要尝试一下 Fish。\n安装 Ubuntu 的安装方法。\n$ sudo apt install fish 其他系统的安装请参考官方网站。\n启动与帮助 安装完成后，就可以启动 Fish。\n$ fish 由于 Fish 的语法与 Bash 有很大差异，Bash 脚本一般不兼容。因此，我建议不要将 Fish 设为默认 Shell，而是每次手动启动它。\n使用过程中，如果需要帮助，可以输入help命令。浏览器就会自动打开，显示在线文档。\n$ help 彩色显示 进入 Fish 以后，你注意到的第一件事，可能就是它默认彩色显示。\n# 无效命令为红色 $ mkd # 有效命令为蓝色 $ mkdir 有效路径会有下划线。\n$ cat ~/somefi 上面代码表示，存在以~/somefi开头的路径。如果没有下划线，你就知道这个路径不存在。\n自动建议 Fish 会自动在光标后面给出建议，表示可能的选项，颜色为灰色。\n# 命令建议 $ /bin/hostname # 参数建议 $ grep --ignore-case # 路径建议 $ ls node_modules 如果采纳建议，可以按下→或Control + F。如果只采纳一部分，可以按下Alt + →。\n自动补全 输入命令时，Fish 会自动显示匹配的上一条历史记录。\n$ git commit -m \u0026#34;feat: first commit\u0026#34; 如果没有匹配的历史记录，Fish 会猜测可能的结果，自动补全各种输入。比如，输入pyt再按下Tab，就会自动补全为python命令。\n如果有多个可能的结果，Fish 会把它们都列出，还带有简要介绍。\n$ vi[按下 Tab 键] vi (Executable link, 2.7MB) view (Vi IMproved, 一个程序员的文本编辑器) viewer.py (Executable, 967B) viewres (Graphical class browser for Xt) ...and 12 more rows 这时，再按一次tab，就可以在这些命令之中选择。\n除了补全命令，Fish 还可以补全参数。比如，ls命令的-l参数后面按下Tab键，就会显示可以连用的其他参数。\n$ ls -l[按下 Tab 键] -l1 (List one file per line) -lA (Show hidden except . and ..) -la (Show hidden) -lB (Ignore files ending with ~) ...and 16 more rows``` Fish 还可以自动补全 Git 分支。\n$ git checkout master 易懂的语法 Fish 的语法非常自然，一眼就能看懂。\nif语句：\nif grep fish /etc/shells echo Found fish else if grep bash /etc/shells echo Found bash else echo Got nothing end switch语句：\nswitch (uname) case Linux echo Hi Tux! case Darwin echo Hi Hexley! case FreeBSD NetBSD DragonFly echo Hi Beastie! case \u0026#39;*\u0026#39; echo Hi, stranger! end while循环：\nwhile true echo \u0026#34;Loop forever\u0026#34; end for循环：\nfor file in *.txt cp $file $file.bak end 函数 Fish 的函数用来封装命令，或者为现有的命令起别名。\nfunction ll ls -lhG $argv end 上面代码定义了一个ll函数。命令行执行这个函数以后，就可以用ll命令替代ls -lhG。其中，变量$argv表示函数的参数。\n下面是另一个例子。\nfunction ls command ls -hG $argv end 上面的代码重新定义ls命令。注意，函数体内的ls之前，要加上command，否则会因为无限循环而报错。\n提示符 fish_prompt函数用于定义命令行提示符（prompt）。\nfunction fish_prompt set_color purple date \u0026#34;+%m/%d/%y\u0026#34; set_color FF0 echo (pwd) \u0026#39;\u0026gt;\u0026#39; set_color normal end 执行上面的函数以后，你的命令行提示符就会变成下面这样。\n02/06/13 /home/tutorial \u0026gt; 配置 Fish 的配置文件是~/.config/fish/config.fish，每次 Fish 启动，就会自动加载这个文件。\n我们可以在这个文件里面写入各种自定义函数，它们会被自动加载。比如，上面的fish_prompt函数就可以写在这个文件里面，这样每次启动 Fish，就会出现自定义的提示符。\nFish 还提供 Web 界面配置该文件。\n$ fish_config 输入上面的命令以后，浏览器就会自动打开本机的 8000 端口，用户可以在网页上对 Fish 进行配置，比如选择提示符和配色主题。\nZsh Oh My Zsh $ sh -c \u0026#34;$(wget https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)\u0026#34; oh-my-zsh应该对通配符作了限制，需要用跳脱字符\nsudo apt remove fcitx\\* Zsh theme：What\u0026rsquo;s the best theme for Oh My Zsh?\nProxy v2ray 节点准备 简单来讲节点是形如如下的神秘链接：\nss://xxxxxxxxxxxxxxxxxxxxxxxxxxxx vmess://xxxxxxxxxxxxxxxxxxxxxxxxxxxx 如果你没有这些连接：\n 自行部署，你则需要自行购买处于自由互联网的服务器并进行节点搭建，这不在本文讨论范围内。如果你需要购买服务器，推荐一个 VPS 提供商：justhost.ru。 购买机场的订阅服务，可以参考它们的订阅流程以获取节点。需要提醒的是，机场服务属于灰色产业，随时有停止服务的可能，购买建议以月付进行购买以避免过大损失。关于机场审计规则，我们的观点是\u0026quot;我可以不看，但是你不可以封禁\u0026quot;。对于机场审计程度，读者可根据自身实际情况自行评估。 如果你不想花任何费用，可安装赛风这类软件。它是自由软件。如果你使用赛风，可以非常方便的发送空邮件到get@psiphon3.com以获取赛风下载链接。赛风应用目前只支持 Windows\\Android\\IOS\\MacOS 平台。当你在这些平台上能够访问自由互联网时，可以去各个渠道搜索可用的节点和代理资源。注意，使用公共节点需要自行承担可能的风险。  安装 v2ray/Xray-core 是使用 Qv2ray（原项目已停止开发） 以及 V2rayA 的前提，需要先进行安装。\nQv2ray 和 V2rayA 是两款非常优秀的在 Linux 上可用的科学上网通用客户端：\n Qv2ray：安装后在 Plugins 中，选择 V2ray Core Plugin，并进行 V2ray 的设置。现在你已经可以使用，你需要按照官方文档导入已有的链接或订阅。 V2rayA：2rayA 是一个浏览器客户端，使用非常方便。更多使用方法请看官方文档  代理配置 在经过上述步骤后，你应该已经有了 SOCKS5 代理以及 HTTP 代理的地址和端口。接下来进行设置：\n  系统代理：在节点链接后，你可在系统设置 -\u0026gt; 网络设置 -\u0026gt; 代理中设置代理。注意，系统设置中的代理配置在 KDE 桌面环境中并不是所有应用都会遵守。没有遵循系统设置代理的应用还需要单独进行代理配置。\n  终端\n可以通过 export 命令设置当前终端的代理方式。比如使用 tldr 或 github raw 等资源需要设置 https 代理。\nexport https_proxy=http://127.0.0.1:8889 export http_proxy=http://127.0.0.1:8889 export all_proxy=http://127.0.0.1:8889 不同终端命令所识别的环境变量名不同，如 all_proxy 对 curl 生效，而对 wget 则不生效，具体可查看各个命令的 man page。\n  proxychains/proxychains-ng\n如果对于一个应用，KDE 的系统代理不生效，在终端 export 了 ALL_PROXY 变量再用终端启动此应用代理也不生效，并且这个应用自身也没有配置代理的选项（即应用不支持代理）。此时可以使用 proxychains，它可以为单行命令配置代理，它是一个预加载的 hook，允许通过一个或多个 SOCKS 或 HTTP 代理重定向现有动态链接程序的 TCP 流量（即强制应用走代理）。\n$ sudo apt install proxychains $ sudo vim /etc/proxychains.conf socks5 127.0.0.1 1089   透明代理 全局代理，也即透明代理。之所以叫做透明代理，是因为这代理对于操作系统中的各个应用相当于是透明的，应用们感知不到代理的存在。之所以叫做全局代理，很明显意为全局所有流量都走代理。\n  在 Qv2ray 的“首选项-入站设置”的下方启用任意门设置选项。\n 监听 ipv4 地址可填127.0.0.1 或 0.0.0.0，建议前者。若需双栈代理，则在监听 ipv6 地址填上::1（如果监听 ipv4 填了 0.0.0.0 则可不填）。 嗅探选择 Full，Destination Override 的三项均勾选。 模式选择“tproxy”。    安装cgproxy软件，编辑/etc/cgproxy/config.json：\n 在cgroup_proxy中括号里加上\u0026quot;/\u0026quot;，port改为 Qv2ray 首选项里的透明代理的端口。 cgproxy默认配置是代理所有 tcp 和 udp，ipv4 和 ipv6 的流量，如果不希望代理其中的某种（些）流量，则将对应的enable_xxx改为 false。注意这里的配置要和 Qv2ray 选项里的配置一致，如 Qv2ray 选项里没有勾选 udp，则这里务必把enable_udp改为 false。 如果希望当本机作为网关设备时为连接到本机的其他设备（如连接到本机开设的 wifi 热点的设备）也提供透明代理，则把enable_gateway改为 true    透明代理的基本原理是拦截系统发出的所有流量，并将这些流量转到代理工具里，从而实现让系统所有流量都走代理的目的。此时，为了避免流量出现死循环（即代理工具发出的流量又转回到代理工具里），需要将代理工具排除在透明代理环境外面。有两种方式可以实现这一点：\n  通过execsnoop监控代理工具的启动，并自动将其移至透明代理环境外面：\n cgproxy软件自带execsnoop支持，以上cgproxy测试过的发行版均可支持。 编辑/etc/cgproxy/config.json，在program_noproxy中括号里加上\u0026quot;v2ray\u0026quot;、\u0026quot;qv2ray\u0026quot;，以使qv2ray和v2ray发出的流量不经过透明代理。如果你的v2ray或qv2ray不在PATH里，则需要填写它们的绝对路径。    在每次连接代理节点时，让qv2ray自己把自己移到透明代理环境外面：\n安装 Qvplugin-Command 插件，在插件设置里的“pre-connection”栏里加上一句\nsh -c \u0026#34;cgnoproxy --pid $(pgrep -x qv2ray)\u0026#34;     如果启用了 udp 的透明代理（dns 也是 udp），则给 v2ray 二进制文件加上相应的特权：\nsudo setcap \u0026#34;cap_net_admin,cap_net_bind_service=ep\u0026#34; /usr/bin/v2ray 否则 udp 的透明代理可能会出问题。如果每次更新了 v2ray 二进制文件，都需要重新执行此命令。\n  启动透明代理服务：systemctl start cgproxy.service或systemctl enable --now cgproxy.service。\n  以上步骤完成后，透明代理应该能正常使用了。\ndns 如果勾选了“dns 拦截”，且启用了 dns 和 udp 的透明代理，则 v2ray 会拦截对系统 dns 的请求，并将其转发到 v2ray 的内置 dns 里，即让 v2ray 内置 dns 接管系统 dns。但 v2ray 内置 dns 是会遵循路由规则的。\n如果没勾选“dns 拦截”，则 v2ray 虽然不会让内置 dns 接管系统 dns，但如果启用了 dns 和 udp 的透明代理，则系统 dns 也会走透明代理进 v2ray，并遵循 v2ray 的路由规则。\n因此，在启用了 dns 和 udp 的透明代理时，若系统 dns 或 v2ray 的内置 dns 配置不当，可能导致 dns 请求发不出去，从而影响正常上网。\n由于 qv2ray 常见的路由规则是绕过国内 ip，国外 ip 均走代理。在这个情形中，以下两个配置是典型的有问题的 dns 配置方式：\n 配置了国外普通 dns 作为首选，但代理本身不支持 udp（此时 dns 查询的 udp 流量出不去，dns 无法查询） 配置了使用域名的 doh 作为首选。此时 doh 的域名无法被解析，从而 doh 也无法使用。  一般而言，如果并不在意将 dns 查询发给谁，那么，在绕过国内 ip 的情况下，只需要配置一个国内普通 dns 作为首选即可保证不会出问题。若代理本身不支持 udp，又希望使用国外 dns，则可以考虑使用使用 ip 的 doh（如https://1.1.1.1/dns-query等）。\n如果需要更复杂的 dns 配置，建议参考上游文档，并选择合适的不会影响正常上网的 dns 配置。\nClash 下载 clash\n$ gzip -d clash-v1.6.5.gz $ mkdir ~/.clash \u0026amp;\u0026amp; mv clash-v1.6.5 ~/.clash/clash 下载配置\n$ wget -O config.yaml [订阅链接] 运行 clash\n$ chmod 770 clash./clash -d . 使用 clash dashboard 选择节点\n设置系统代理：\n  GUI：打开系统设置，点击网络代理右边的 ⚙ 按钮，选择手动\n HTTP 和 HTTPS 代理为 127.0.0.1:7890 Socks 主机为 127.0.0.1:7891    CLI：change system proxy settings from the command line\n# To modify a DConf setting: $ gsettings set \u0026lt;schema\u0026gt; \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; # To read a DConf setting: $ gsettings get \u0026lt;schema\u0026gt; \u0026lt;key\u0026gt;   相关软件：\n glider Lantern Privoxy openvpn Shadowsocks Tor trojan：trojan教程  脚本一 $ vi ~/.clash/run-clash.sh #!/bin/bash CLASH_HOME=/home/vane/.clash subscription=\u0026#34;订阅连接\u0026#34; # 设置系统代理 function setting { gsettings set org.gnome.system.proxy.http host \u0026#39;127.0.0.1\u0026#39; gsettings set org.gnome.system.proxy.http port \u0026#39;7890\u0026#39; gsettings set org.gnome.system.proxy.https host \u0026#39;127.0.0.1\u0026#39; gsettings set org.gnome.system.proxy.https port \u0026#39;7890\u0026#39; gsettings set org.gnome.system.proxy.socks host \u0026#39;127.0.0.1\u0026#39; gsettings set org.gnome.system.proxy.socks port \u0026#39;7891\u0026#39; } # 更新订阅 function update { wget -O $CLASH_HOME/config.yaml $subscription } # 运行 clash function run { # 打开系统代理（之前已经设置了） gsettings set org.gnome.system.proxy mode \u0026#39;manual\u0026#39; $CLASH_HOME/clash -d $CLASH_HOME/ } # 停止运行 clash function stop { # 关闭系统代理  gsettings set org.gnome.system.proxy mode \u0026#39;none\u0026#39; } if [ \u0026#34;$1\u0026#34; = \u0026#34;-u\u0026#34; ]; then update elif [ \u0026#34;$1\u0026#34; = \u0026#34;-r\u0026#34; ]; then run elif [ \u0026#34;$1\u0026#34; = \u0026#34;-s\u0026#34; ]; then setting else if [ \u0026#34;$1\u0026#34; ]; then $CLASH_HOME/clash $1 else echo Plese run clash -r fi fi trap stop EXIT How to change system proxy settings from the command line on Ubuntu desktop\n$ chmod 700 run-clash.sh 脚本二 $ vi ~/.clash/rc.sh #!/bin/bash /usr/bin/wget -O home/kurome/.clash/config.yaml \u0026#34;订阅连接\u0026#34; /home/kurome/.clash/clash -d /home/kurome/.clash/ clash as a daemon：\n$ sudo vi /usr/lib/systemd/system/clash.service [Unit] Description=Clash daemon, A rule-based proxy in Go. After=network.target [Service] Type=simple Restart=always RestartSec=10 ExecStart=/bin/bash /home/kurome/.clash/rc.sh [Install] WantedBy=multi-user.target 运行\n$ systemctl enable clash.service $ systemctl start clash.service $ systemctl status clash.service 如果不想代理了，可以直接在 clash dashboard 的 Proxy （如果有的话）或者 Settting 里选择 DIRECT，而不是关闭 clash.service。根据设置的规则，有的流量会走代理，有的流量直接走。\nTUN 模式 “系统代理”一般只是桌面环境下的约定，需要 app 遵循约定才行。也就是说 HTTP_PROXY 这种环境变量只是约定俗成的，大家都从这里面读取代理地址，但是程序里必须要有读取这个变量的相关代码才行。\n因此某些软件\u0026amp;命令行软件不支持系统代理。\nClash for Windows tun 模式对全部 app 生效——对于不遵循系统代理的软件，TUN 模式可以接管其流量并交由 CFW 处理。启动 TUN 模式需要进行如下操作：\n  安装 nftables 和 iproute2 并重启\n$ sudo apt install nftables iproute2 $ sudo reboot   点击General中Service Mode右边Manage，在打开窗口中安装服务模式，安装完成应用会自动重启（某些系统需要手动重启 APP），Service Mode 右边地球图标变为绿色即安装成功\n  点击General中TUN Mode右边开关启动 TUN 模式\n  无法安装参考：\n$ curl https://gist.githubusercontent.com/Fndroid/2119fcb5ccb5a543a8f6a609418ae43f/raw/592eba4f480c7ccb4f29c9b8e80d24bfd5dda8cf/linux.sh \u0026gt; cfw-tun.sh \u0026amp;\u0026amp; chmod +x cfw-tun.sh \u0026amp;\u0026amp; sudo ./cfw-tun.sh install \u0026lt;cfw安装目录\u0026gt; 如要卸载则将 install 改为 uninstall，最后一部分位 CFW 安装目录\n  Setup System stack in Fake-IP mode Edit config\ndns: enable: true listen: 0.0.0.0:1053 fake-ip-range: 198.18.0.1/16 enhanced-mode: fake-ip nameserver: - 114.114.114.114 tun: enable: true stack: system dns-hijack: - tcp://8.8.8.8:53 interface-name: en0 Run Clash\nsudo ./clash Set Route\n# Based on https://github.com/Kr328/kr328-clash-setup-scripts/blob/master/setup-clash-tun.sh ipset create localnetwork hash:net ipset add localnetwork 127.0.0.0/8 ipset add localnetwork 10.0.0.0/8 ipset add localnetwork 169.254.0.0/16 ipset add localnetwork 192.168.0.0/16 ipset add localnetwork 224.0.0.0/4 ipset add localnetwork 240.0.0.0/4 ipset add localnetwork 172.16.0.0/12 ip tuntap add user root mode tun utun0 ip link set utun0 up ip route replace default dev utun0 table 0x162 ip rule add fwmark 0x162 lookup 0x162 iptables -t mangle -N CLASH iptables -t mangle -F CLASH iptables -t mangle -A CLASH -p tcp --dport 53 -j MARK --set-mark 0x162 iptables -t mangle -A CLASH -p udp --dport 53 -j MARK --set-mark 0x162 iptables -t mangle -A CLASH -m addrtype --dst-type BROADCAST -j RETURN iptables -t mangle -A CLASH -m set --match-set localnetwork dst -j RETURN iptables -t mangle -A CLASH -d 198.18.0.0/16 -j MARK --set-mark 0x162 iptables -t mangle -A CLASH -j MARK --set-mark 0x162 iptables -t mangle -I OUTPUT -j CLASH iptables -t mangle -I PREROUTING -m set ! --match-set localnetwork dst -j MARK --set-mark 0x162 sysctl -w net/ipv4/ip_forward=1 sysctl -w net.ipv4.conf.utun0.rp_filter=0 Set Gateway and DNS server in other devices\nSet the gateway and DNS server, then enjoy the clash\nTProxy Mode Transparent proxies act as intermediaries between a user and a web service. When a user connects to a service, the transparent proxy intercepts the request before passing it on to the provider. Transparent proxies are considered transparent because the user isn’t aware of them. On the other hand, the servers hosting the service recognize that the proxied traffic is coming from a proxy and not directly from the user.\nAnd Tproxy is first choice of realize transparent proxy with NAT on Linux. In the past, Clash TProxy mode only support TCP traffic. After version 0.19, Clash TProxy mode also support UDP traffic, it will solve a NAT problem.\nWhat\u0026rsquo;s different between TProxy mode and TUN mode?\nThere\u0026rsquo;s no big difference in user-side.\nIn developer side, Tproxy is a proxy, although it is not perceived by the application. And TUN is a gatway, application knows there is a gateway, and traffic must pass through it.\nCheck your config\nMake sure you config have no tun field.\ndns: enable: true listen: 0.0.0.0:1053 enhanced-mode: redir-host # or fake-ip nameserver: - 114.114.114.114 Add Rules in iptable\niptables -t nat -N clash iptables -t nat -A clash -d 0.0.0.0/8 -j RETURN iptables -t nat -A clash -d 10.0.0.0/8 -j RETURN iptables -t nat -A clash -d 127.0.0.0/8 -j RETURN iptables -t nat -A clash -d 169.254.0.0/16 -j RETURN iptables -t nat -A clash -d 172.16.0.0/12 -j RETURN iptables -t nat -A clash -d 192.168.0.0/16 -j RETURN iptables -t nat -A clash -d 224.0.0.0/4 -j RETURN iptables -t nat -A clash -d 240.0.0.0/4 -j RETURN iptables -t nat -A clash -d \u0026#34;$local_ipv4\u0026#34; -j RETURN iptables -t nat -A clash -p tcp -j REDIRECT --to-port \u0026#34;$proxy_port\u0026#34; iptables -t nat -I PREROUTING -p tcp -d 8.8.8.8 -j REDIRECT --to-port \u0026#34;$proxy_port\u0026#34; iptables -t nat -I PREROUTING -p tcp -d 8.8.4.4 -j REDIRECT --to-port \u0026#34;$proxy_port\u0026#34; iptables -t nat -A PREROUTING -p tcp -j clash iptables -t nat -A OUTPUT -p tcp -d 198.18.0.0/16 -j REDIRECT --to-port \u0026#34;$proxy_port\u0026#34; # use it just for fake-ip iptables -t nat -N CLASH_DNS iptables -t nat -F CLASH_DNS iptables -t nat -A CLASH_DNS -p udp -j REDIRECT --to-port 1053 iptables -t nat -I OUTPUT -p udp --dport 53 -j CLASH_DNS iptables -t nat -I PREROUTING -p udp --dport 53 -j REDIRECT --to 1053 配置文件 Clash 是基于 Go 语言写的科学上网工具，目前支持 windows, mac, android, openwrt, linux 平台，支持 ss, trojan, vmess, snell 协议，支持分流规则。\nclash 配置文件格式为 yaml 格式，格式如下：\nport: 7890 socks-port: 7891 allow-lan: true mode: Rule log-level: info external-controller: :9090 proxies: - {name: cfmem.com - 🇭🇰 gq - 香港Amazon数据中心 20-1} proxy-groups: - name: 🔰 节点选择 type: select proxies: - ♻️ 自动选择 - 🎯 全球直连 - cfmem.com - 🇭🇰 gq - 香港Amazon数据中心 20-1 rules: - DOMAIN-SUFFIX,local,🎯 全球直连 proxies proxies 代表节点数据，所有的分流规则都是按照这些节点数据来的，这里可以有很多个节点数据，可以是 trojan, ss, vmess 类型都可以，我们来看个例子：\n{name: cfmem.com - 🇭🇰 gq - 香港Amazon数据中心 20-1, server: xxxx, port: 59113, type: vmess, uuid: 1111111, alterId: 0, cipher: auto, tls: false} clash 用统一的格式来定义不同的节点类型，用 type 来进行区分，特有的属性只需要在这个结构体加上自己属性就可以， clash 客户端会根据 type 不同而来读数据\nproxy-groups 可以把 proxy-groups 理解为一道又道的过滤网，当你发出一个请求时，这个请求将会被在哪一层的过滤网给拦截下来，取决于你的 rules 与 请求匹配。我们来解析一下 proxy-groups 里面的参数。\nname\n代表组的名称，组的名称可以随意命名，但建议取有意义的名称，组的名称可以被其它的组引用，也可以放在规则里面\ntype\ntype 代表这个组的类型，有下面四种情况\n  select 手动选择，该组在节点列表上，手动选择列表或者 proxy-group\n  url-test 延迟最低节点，测试该组所有节点的延迟\n  fallback 回落，连接该组第一个节点，不可用时切换到下一个节点\n  load-balance 负载均衡，由该组2个以上的节点提供链接\n  proxies\n这里可以是组名称或者节点名称，依次从上到下进行选择，比如看下面这个\n- name: 🔰 节点选择 type: select proxies: - ♻️ 自动选择 - 🎯 全球直连 - cfmem.com - 🇭🇰 gq - 香港Amazon数据中心 20-1 - cfmem.com - 🇭🇰 gq - 香港Amazon数据中心 26-2 - cfmem.com - 🇭🇰 gq - 香港Amazon数据中心 28-3 - cfmem.com - 🇭🇰 香港-4 - cfmem.com - 🇭🇰 香港 2-5 - cfmem.com - 🇭🇰 香港 3-6 - cfmem.com - 🇭🇰 香港 4-7 - cfmem.com - 🇭🇰 香港 10-8 - cfmem.com - 🇭🇰 香港 11-9 - name: ♻️ 自动选择 type: url-test url: http://www.gstatic.com/generate_204 interval: 300 proxies: - cfmem.com - 🇭🇰 gq - 香港Amazon数据中心 20-1 - cfmem.com - 🇭🇰 gq - 香港Amazon数据中心 26-2 - cfmem.com - 🇭🇰 gq - 香港Amazon数据中心 28-3 - cfmem.com - 🇭🇰 香港-4 - cfmem.com - 🇭🇰 香港 2-5 - cfmem.com - 🇭🇰 香港 3-6 - cfmem.com - 🇭🇰 香港 4-7 - cfmem.com - 🇭🇰 香港 10-8 - cfmem.com - 🇭🇰 香港 11-9 - cfmem.com - 🇭🇰 香港 12-10 - name: 🌍 国外媒体 type: select proxies: - 🔰 节点选择 - ♻️ 自动选择 - 🎯 全球直连 - cfmem.com - 🇭🇰 gq - 香港Amazon数据中心 20-1 名称为自动选择的组会每间隔 300 毫秒去 ping 节点数据，测试的地址是：http://www.gstatic.com/generate_204\n而 国外媒体这一项是手动选择默认选择第一个 节点选择，节点选择的第一个是自动选择，所以默认是根据 ping 值来选择节点的\nrules rules 也就是具体的分发规则了，规则一般由 [规则前缀],[域名或地址],[组名] 组成。我们来看下，其中 no-resolve 表示不要解析这条规则，只处理直接 ip 访问请求\nrules: - DOMAIN-SUFFIX,local,🎯 全球直连 - IP-CIDR,192.168.0.0/16,🎯 全球直连,no-resolve - IP-CIDR,10.0.0.0/8,🎯 全球直连,no-resolve - IP-CIDR,172.16.0.0/12,🎯 全球直连,no-resolve - IP-CIDR,127.0.0.0/8,🎯 全球直连,no-resolve - IP-CIDR,100.64.0.0/10,🎯 全球直连,no-resolve - IP-CIDR6,::1/128,🎯 全球直连,no-resolve - IP-CIDR6,fc00::/7,🎯 全球直连,no-resolve - IP-CIDR6,fe80::/10,🎯 全球直连,no-resolve - IP-CIDR6,fd00::/8,🎯 全球直连,no-resolve - DOMAIN-KEYWORD,1drv,Ⓜ️ 微软服务 规则前缀有这些内容\n  DOMAIN-SUFFIX 表示包含什么后缀的域名\n  IP-CIDR IPV4匹配\n  IP-CIDR6 IPV6匹配\n  DOMAIN-KEYWORD,xxx 表示包含 xxx域名关键字的链接\n  DOMAIN abc.hello.com 表示包含完整的域名\n  PROCESS-NAME 表示进程名称\n  GEOIP 数据库（国家代码）匹配\n  MATCH 全匹配（一般放在最后）\n  DNS污染 DNS服务器即是将用户请求的域名(网站URL)转换为IP地址的服务器。当年中国长城防火墙开始部署时就是通过DNS污染来屏蔽网站的。这项名为DNS污染的技术，就是对用户请求的域名回应一个错误的IP地址，使用户无法访问某个网站。至此，国内几乎所有的公共DNS服务器都被污染，用户无法请求到被屏蔽网站的正确IP地址。但是目前，防火墙的屏蔽功能早已不止DNS污染那么简单了，可以针对IP/域名直接阻断连接，甚至屏蔽了国外未受污染的DNS服务器，因此仅靠国内的DNS是不够翻墙的。\n对抗DNS劫持 早期的DNS服务器（我们日常使用的基本也是）都是明文传输数据的，这就意味着防火墙可以探测出你访问的网站，并且直接篡改DNS服务器回应的IP地址。这不仅仅存在于长城防火墙，还存在于某些无良网络运营商，把用户的请求的网站劫持到某个假的网站上。\n于是目前出现了DoH与DoT，可使用https/tls 加密传输DNS请求，这使得DNS不再容易被劫持了。国内的许多公共DNS也都提供了这项服务。以下是我所推荐的国内DNS。\n https://223.5.5.5/dns-query https://223.6.6.6/dns-query https://doh.pub/dns-query  或许可以参考 如何选择适合的公共 DNS？\n何时使用 Clash只会在域名匹配为直连时使用配置文件的DNS，其余时刻均交给节点进行远程解析。当然，节点域名也会使用配置文件的DNS。\n举个例子，访问 google.com 时，匹配到代理规则，那么这个流量将直接被发送至节点服务器，交给节点处理（通常是节点服务器的DNS解析，这个不用管了）。访问 microsoft.com 时，匹配到直连规则，Clash将使用配置文件的DNS设定进行解析。\nDNS配置 首先，打开你的 Clash 配置文件（如果你使用 Clash for Windows 或 Clash for Android, 可以使用软件自带的“覆写/Mixin”功能），添加以下段落：\ndns: enable: true listen: 0.0.0.0:53Copy 这一段的意思是启用 Clash 的 DNS 服务并让其在 53 端口（这是绝大多数操作系统将 DNS 解析报文发送到的端口）监听来自任意网络界面的 DNS 请求。如果你的设备并不需要向其他设备提供解析服务，或你的设备常常需要接入不安全的网络（如手机，笔记本电脑），应当将第三行的 0.0.0.0:53 改为 127.0.0.1:53 让 Clash 仅监听本机的 DNS 解析报文。\n（Clash 默认会同时监听 IPv4 和 IPv6 界面，如果你不需要后者，可以添加一行 ipv6: false）\n由于连接到加密 DNS 服务时，需要解析服务器本身的域名，因此需要指定一些相对干净的国内 明文 DNS 服务器地址。继续添加以下部分（注意缩进）：\n#--omitted-- default-nameserver: - 119.29.29.29 - 223.5.5.5Copy 当收到 DNS 解析请求时，Clash 会使用以上 DNS 服务器解析加密 DNS 服务器地址并建立连接。\n接下来，指定解析国内域名时使用的加密 DNS 服务器地址：\n#--omitted-- nameserver: - https://doh.pub/dns-query - https://dns.alidns.com/dns-queryCopy Clash 支持 DoH（https://domain.tld/dns-query 形式） 和 DoT（tls://domain.tld 形式）两种加密 DNS 协议，不支持 DoQ.（当然也支持在此指定备用的明文 DNS）\n然后，指定解析国外域名时使用的加密 DNS 服务器地址，并设置分流规则：\n#--omitted-- fallback: - https://1.1.1.1/dns-query - https://dns.google/dns-query fallback-filter: geoip: true geoip-code: CN ipcidr: - 240.0.0.0/4Copy “fallback” 字段指定的 DNS 服务器将被用于解析非国外域名，而 “fallback-filter” 字段则实现我们想要的分流规则——当请求解析的域名在 GeoIP 数据库内的国家代码不是 CN 时，或是域名在前文设置的 DNS 服务器内的解析结果位于 240.0.0.0/4 这一 IP 段内时（被屏蔽的域名解析常常会被污染到这一段），使用 “fallback” 字段指定的 DNS 服务器解析域名。\n最后，修改系统 DNS 服务器为 127.0.0.1 即可。\n代理环境中的 DNS 解析行为 虽然 Fake IP 这个概念早在 2001 年就被提出来了，但是到 Clash 提供 fake-ip 增强模式以后，依然有很多人对 Fake IP 这个概念以及其作用知之甚少。本文就简单谈谈在代理环境中，TCP 连接建立之前发生的事。由于移动设备操作系统中网络栈相对复杂，本文的例子也并不一定适用于移动端环境。文章中也许会存在很多错误，也希望各路大佬的勘误和斧正。\n不使用代理 如果在不使用任何代理的情况下，打开一个没有命中 DNS 缓存的网站（比如 blog.skk.moe）的时候，浏览器和操作系统大概会执行这么一些操作：\n 浏览器自己都有 DNS 缓存机制，因此浏览器会先开始寻找自己的缓存，不过没有找到 blog.skk.moe 的解析结果 浏览器通过调用操作系统的 getaddrinfo 方法，向操作系统寻求解析结果 操作系统自己也有一层 DNS 缓存，但是现在操作系统从自己的缓存中依然找不到这一结果 在系统的网络设置之中有设置上游 DNS 地址，假设操作系统中设置的是 119.29.29.29，那么操作系统会向 119.29.29.29 发起解析请求（UDP 流量）拿到 blog.skk.moe 的 IP 当然如果 119.29.29.29 自己没有 blog.skk.moe 的解析结果会找它的上游去要。不过我们不关心这一点，反正最后 119.29.29.29 会把 blog.skk.moe 的解析结果返回给设备的操作系统 现在，浏览器已经可以开始向 blog.skk.moe 的 IP 发起 HTTPS 连接了  以上是打开一个网页常见的 DNS 解析流程，对于其它非 HTTP 的 TCP 连接（比如 SMTP）也都差不多是这个流程——由于 TCP/IP 的协议特性，在应用发起 TCP 连接时，会先发出一个 DNS question（发一个 IP Packet），获取要连接的服务器的 IP 地址，然后直接向这个 IP 地址发起连接。\n设置代理并使用直连 现在，我们在应用程序（比如我们的浏览器、或者其它应用）中设置了代理，但是这个代理不涉及到任何远端服务器（直连模式）。接下来以设置了 SOCKS5 代理的浏览器为例。\n 浏览器不再需要从自己的 DNS 缓存中寻找 blog.skk.moe，因为已经有了 SOCKS5 代理，浏览器可以直接将域名封装在 SOCKS5 流量之中发往代理客户端 代理客户端从 SOCKS5 流量中抽出 blog.skk.moe 这个域名并设法获得解析结果 代理客户端将你的 SOCKS5 流量还原成标准的 TCP 请求 代理客户端将这个 TCP 连接建立起来，在这个例子之中 TCP 连接承载的是 HTTPS  之前由于获取解析结果是浏览器在操作，而大部分浏览器都会选择调用系统的 getaddrinfo 方法，因此如果你想要在 DNS 上做一些黑魔法就只能在操作系统层面实现，比如在本机或者别处架设一个带黑魔法的 DNS 服务器，然后你系统中设置使用这个 DNS 服务器。现在 DNS 解析是由代理客户端执行，因此在代理客户端上就可以实现一些黑魔法。比如 Surge 自己实现了一个 DNS Server 可以并发向多个上游同时发起查询、比如 V2Ray 可以实现不同域名的查询分流，等等。当然代理客户端也可以使用操作系统的 getaddrinfo 方法。\n设置代理并将流量转发到远端服务器 现在在上一步的基础之上，我们为代理服务器设置了一个远端服务器，这个代理会使用 某种协议 和远端服务器通信，并且这种协议和 SOCKS5 一样支持将域名封装在传输中。浏览器和代理客户端之间依然使用 SOCKS5 通信。\n 因为已经有了 SOCKS5 代理，浏览器可以直接将域名 blog.skk.moe 和整个请求封装在 SOCKS5 流量之中发往代理客户端 代理客户端从 SOCKS5 流量中抽出 blog.skk.moe 这个域名以及其它数据 代理客户端使用 某种协议 将浏览器发出的 SOCKS5 的流量重组并发给远端服务器 远端服务器使用相同的 某种协议 从流量中获得其中的域名 blog.skk.moe 远端服务器的代理服务端发起了一次 DNS 解析请求试图解析 blog.skk.moe。绝大部分情况下，代理的服务端都会直接使用操作系统的 getaddrinfo 方法、也就是由远端服务器的操作系统负责 DNS  这一次，不论是代理客户端还是你的浏览器都没有进行 DNS 解析，DNS 解析是在远端服务器上进行的。因为 某种协议 支持封装域名，然后这一次和 blog.skk.moe 连接的是远端服务器，考虑到针对 CDN 优化，DNS 解析自然需要在远端服务器上执行。\n现在我已经介绍了通过代理直连和通过代理发送给远端服务器了。但是毫无疑问，我相信本文所有的读者自己使用的上网方式都不会是全面直连或者全面代理。这就是接下来要讲的：\n设置代理并使用 IP 规则和域名规则进行分流 分流是一个麻烦事。一般情况下，你可能会需要使用域名进行分流（不论是白名单还是黑名单）。不过更多情况下你会使用到基于 IP 的规则来进行分流。\n先来看第一个例子：使用域名规则进行分流。\n 浏览器将带有域名 blog.skk.moe 的 HTTPS 请求封装在 SOCKS5 流量之中发往代理客户端 代理客户端从 SOCKS5 流量中抽取出域名 blog.skk.moe 代理客户端开始将blog.skk.moe 和域名规则列表开始比较。这个列表可以是白名单或黑名单，域名可能也没有匹配上。反正最终比较得出的结果就是 blog.skk.moe 是否需要走代理。 如果不需要走代理，代理客户端剩下会做的事情和本文第二部分「设置代理并使用直连」就完全一样了；同理，需要走代理的话就需要进行本文第三部分的那个流程  使用域名规则分流很简单，除非 blog.skk.moe 最终是直连，否则代理客户端不需要进行 DNS 解析。\n现在来看第二个例子：使用 IP 规则分流。\n 浏览器将带有域名 blog.skk.moe 的 HTTPS 请求封装在 SOCKS5 流量之中发往代理客户端 代理客户端从 SOCKS5 流量中抽取出域名 blog.skk.moe 代理客户端得到 blog.skk.moe 的解析结果 代理客户端开始将blog.skk.moe 的解析结果和 IP 规则列表开始比较。这个列表可以是 cnlist 或者 MaxMind IP 数据库。反正最终得出的结果就是 blog.skk.moe 解析结果的 IP 是否需要走代理。 如果不需要走代理，代理客户端剩下会做的事情和本文第二部分「设置代理并使用直连」就完全一样了；同理，需要走代理的话就需要进行本文第三部分的那个流程。  使用 IP 规则分流，前提首先你得有一个 IP 拿来比较。所以代理客户端必须先进行一次 DNS 解析。使用什么方法进行 DNS 解析并不重要，之前已经说过代理客户端甚至可以使用自己的黑魔法，而我们只需要关心最终代理客户端拿到了一个 IP 并且可以用于规则判定。\n此时需要注意的是，虽然代理客户端获得了一个 IP，但是你只有在直连的时候，代理客户端可能（并且基本上都会）复用这个 IP；如果是将流量交给远程服务器，由于 某种协议 支持封装域名，因此远程服务器拿到的还是域名不是 IP、还需要进行一次解析。也就是说，远端服务器连接的 IP 与 代理客户端解析得到的 IP 毫无关系。\n使用 redir / tun2socks 实现全局流量经过代理 在开始之前，我们先复习一下 TCP/IP 协议怎么说的——「在应用发起 TCP 连接时，会先发出一个 DNS question（发一个 IP Packet），获取要连接的服务器的 IP 地址，然后直接向这个 IP 地址发起连接」\n全局流量代理可能会出现在路由器上或者 TUN/TAP 型的支持全局代理客户端上。用户不再主动为每个应用程序设置代理。此时应用程序是不会感知到代理客户端的存在，它们会正常的发起 TCP 连接，并且由于 TCP/IP 协议，在拿到 DNS 解析结果之前，连接是不能建立的。\n 浏览器自己都有 DNS 缓存机制，因此浏览器会先开始寻找自己的缓存，不过没有找到 blog.skk.moe 的解析结果 浏览器通过调用操作系统的 getaddrinfo 方法，向操作系统寻求解析结果 操作系统自己也有一层 DNS 缓存，但是现在操作系统从自己的缓存中依然找不到这一结果 在系统的网络设置之中有设置上游 DNS 地址。代理客户端可能会修改系统设置中的 DNS 到 127.0.0.1 或者别的 IP、也可能保留用户之前的设置，这无所谓，因为\u0026hellip; 操作系统发出的 DNS 解析请求会经过代理客户端并最终被截获 代理客户端可以将这个解析请求原样发出去、或者用自己的黑魔法，总之代理客户端都会拿到一个解析结果 代理客户端将这个解析结果返回回去，操作系统拿到了这个解析结果并返回给浏览器 浏览器对这个解析结果的 IP 建立一个 TCP 连接并发送出去 这个 TCP 连接被代理客户端截获。由于之前代理客户端进行的 DNS 解析请求这一动作，代理客户端可以找到这个只包含目标 IP 的 TCP 连接原来的目标域名 如果是支持 redir 的代理客户端，那么代理客户端就会直接将域名和 TCP 连接中的其它数据封装成 某种协议 发给远端服务器；或者封装成 SOCKS5 后交给支持 SOCKS5 的代理客户端  如果代理客户端需要按照域名进行分流，一般会在第 6 步代理客户端解析出一个 IP 或者第 9 步代理客户端拿到域名以后。FancySS、KoolSS、SSTap 的流程大抵都是如此。\n和应用程序直接将流量封装成 SOCKS5 大有不同，在类似于透明代理的环境下浏览器和其它应用程序是正常地发起 TCP 连接。因此除非得到一个 DNS 解析结果，否则 TCP 连接不会建立；代理客户端也会需要通过这个 DNS 查询动作，才能找到之后的 TCP 连接的域名。 你大概能够发现，浏览器、应用程序直接设置 SOCKS5 代理的话，可以不在代理客户端发起 DNS 解析请求就能将流量发送给远端服务器；而在透明代理模式下，不论是否需要 IP 规则分流都需要先进行一次 DNS 解析才能建立连接。\n有没有办法能像直接设置 SOCKS5 代理一样省掉一次 DNS 解析呢？有，就是代理客户端自己不先执行查询动作，丢一个 Fake IP 回去让浏览器、应用程序立刻建立 TCP 连接：\n在 redir / tun2socks 中使用 Fake IP Fake IP 的定义出自 RFC3089。这个 RFC 定义了一种新的将 TCP 连接封装成 SOCKS 协议的方法。\n 浏览器自己都有 DNS 缓存机制，因此浏览器会先开始寻找自己的缓存，不过并没有找到 blog.skk.moe 的解析结果 浏览器通过调用操作系统的 getaddrinfo 方法，向操作系统寻求解析结果 操作系统自己也有一层 DNS 缓存，但是现在操作系统从自己的缓存中依然找不到这一结果 在系统的网络设置之中设置了一个专门的上游 DNS 地址，可能是用户手动设置的也可能是代理客户端设置的。不论如何，这个设置最终会使操作系统向代理客户端发起 DNS 请求 操作系统发出的 DNS 解析请求会经过代理客户端并最终被截获 代理客户端从解析请求中获得域名，从 Fake IP 池中选取一个 IP 建立映射 代理客户端将这个 Fake IP 返回回去，操作系统拿到了这个 Fake IP 并返回给浏览器 浏览器对 Fake IP 建立一个 TCP 连接并发送出去 这个 TCP 连接被代理客户端截获。代理客户端抽取出 Fake IP 并反查出这个 TCP 连接中对应的域名 有了 TCP 连接和域名，代理客户端可以轻易地将其使用 SOSCKS5 或者 某种协议 进行封装  有了 Fake IP，代理客户端无需进行 DNS 解析。最后不论是浏览器、代理客户端还是远端服务器都不会去和 Fake IP 进行连接，因为在代理客户端这里就已经完成了截获、重新封装。\n即使按照域名规则分流，代理客户端都没有进行 DNS 解析的需要。只有在遇到了按照 IP 进行分流的规则时，代理客户端才需要进行一次解析拿到一个 IP 用于判断。即便如此，这个 IP 只用于分流规则的匹配，不会被用于实际的连接。\nFancySS 和 Surge / Clash 的区别 FancySS 是使用的 redir，Surge 的增强模式使用的是 Fake IP，Clash 的增强模式既有 redir-host 也有 Fake IP。首先把 FancySS 等路由器上常见的代理客户端和 Clash 的 redir-host 分为一类，Surge 的增强模式和 Clash 的 fake-ip 模式分为另一类。\n路由器上常见的代理客户端一般内置了 dns2socks、dnscryp-proxy、PCap_DNSProxy 等等 DNS 方案、也支持按照一定的规则进行分流，但是都是用于答复应用程序的 DNS question 使其建立 TCP 连接的，除非直连，否则通过这些 DNS 方案拿到的解析结果的 IP 并不会被用上。 大部分路由器上的代理客户端，DNS 解析请求都是通过路由器本机发出（或转发到单一远端服务器进行解析），因此解析结果只能说「至少能用」（不一定是有 CDN 优化的，甚至有可能会有 DNS 污染），如果流量不经过代理客户端直接发往这些 IP 地址，一般也不会影响浏览器、应用程序的正常使用。因此路由器上的代理客户端可以实现通过 iptables 控制让某些端口、某些设备的流量不经过代理客户端。 而在 Fake IP 模式下，浏览器、应用程序都是对 Fake IP 发起连接，如果没有代理客户端对连接进行重新封转，那么这部分流量就不能被发往真实的目的 IP，因此所有流量都必须经过代理客户端，而根据端口、设备的分流就需要由代理客户端自己实现。\n如果操作系统或者浏览器缓存了 DNS 解析结果 之前的透明代理的两个例子中，我们都假定浏览器和操作系统都没有缓存 DNS 解析结果。但是，如果操作系统或者应用程序缓存了 DNS 解析结果会发生什么？\n如果是不使用 Fake IP 的 redir / tun2socks 情况下，由于操作系统、浏览器或者应用程序中的任何一个缓存了 DNS 解析结果，因此 TCP 连接可以直接根据缓存的解析结果的 IP 建立，代理客户端并没有预先收到对应的 DNS question。在这种情况下，代理客户端有可能直接将这个连接视为和 IP 连接而不是和域名连接，根据域名规则的分流可能就会因此失效，不过根据 IP 分流的规则没有失效。 如果为了避免域名分流规则失效，你可以设法阻止操作系统或者浏览器缓存 DNS 解析结果，这样每次建立 TCP 连接之前都会发送 DNS question 使代理客户端探测到域名。但是这意味着每次 TCP 连接建立都需要代理客户端进行一次 DNS 解析请求（当然代理客户端可以对 DNS 解析进行缓存避免出现延时激增）。\n而对于 Fake IP 模式来说，由于代理客户端内存储有 Fake IP 和真实域名之间的映射表，因此即使操作系统或应用程序缓存了 Fake IP，在之后的 TCP 连接中，代理客户端收到流量后依然可以抽取出 Fake IP 反查出域名，因此不受 DNS 缓存的影响。\n我在这里留几个问题给大家思考一下：\n 如果使用了 Fake IP，代理客户端不论域名是否真实存在都会返回一个 Fake IP 给浏览器，那么浏览器在试图访问一个不存在的域名时，错误信息应该是什么样的？会不会出现 DNS 解析失败的错误信息？ 如果操作系统或者浏览器缓存了 Fake IP，但是代理客户端中 Fake IP 和域名的映射表丢失以后，会出现什么状况？可能会出现什么错误信息？  第二个问题很有趣。因为如果你找到了第二个问题的答案，你就会意识到 Clash 在 Fake IP 模式下偶发的无法上网的原因了。\n参考资料  HTTP 代理原理及实现（一） - 我的文章中举得都是 SOCKS5 的例子，如果想了解一下在 HTTP 代理中流量是如何被封装的，可以看看屈屈的这篇博客 Surge 原理与实现 - Surge 开发者写的 Surge 早期版本的工作原理，可以了解一下 Surge 是怎么处理各种协议的流量的 漫谈各种黑科技式 DNS 技术在代理环境中的应用 - Kitsunebi 开发者写的文章，详细地介绍了在不同的 V2Ray 配置下的 DNS 行为，同时还有对移动端网络栈的一些介绍  WireGuard 官方文档：https://github.com/pirate/wireguard-docs\nWireGuard 是由 Jason Donenfeld 等人用 C 语言编写的一个开源 VPN 协议，被视为下一代 VPN 协议，旨在解决许多困扰 IPSec/IKEv2、OpenVPN 或 L2TP 等其他 VPN 协议的问题。它与 Tinc 和 MeshBird 等现代 VPN 产品有一些相似之处，即加密技术先进、配置简单。从 2020 年 1 月开始，它已经并入了 Linux 内核的 5.6 版本，这意味着大多数 Linux 发行版的用户将拥有一个开箱即用的 WireGuard。\n术语 Peer/Node/Device\n连接到 VPN 并为自己注册一个 VPN 子网地址（如 192.0.2.3）的主机。还可以通过使用逗号分隔的 CIDR 指定子网范围，为其自身地址以外的 IP 地址选择路由。\n中继服务器（Bounce Server）\n一个公网可达的对等节点，可以将流量中继到 NAT 后面的其他对等节点。Bounce Server 并不是特殊的节点，它和其他对等节点一样，唯一的区别是它有公网 IP，并且开启了内核级别的 IP 转发，可以将 VPN 的流量转发到其他客户端。\n子网（Subnet）\n一组私有 IP，例如 192.0.2.1-255 或 192.168.1.1/24，一般在 NAT 后面，例如办公室局域网或家庭网络。\nCIDR 表示法\nCIDR中文全称是无分类域间路由选择，英文全称是Classless Inter-Domain Routing，在平常，大家多称之为无分类编址，它也是构成超网的一种技术实现。CIDR在一定程度上解决了路由表项目过多过大的问题。CIDR之所以称为无分类编址，就是因为CIDR完全放弃了之前的分类IP地址表示法，它真正消除了传统的A类、B类、C类地址以及划分子网的概念，它使用如下的IP地址表示法：\nIP地址 ::= {\u0026lt;网络前缀\u0026gt;， \u0026lt;主机号\u0026gt;} / 网络前缀所占位数 CIDR仅将IP地址划分为网络前缀和主机号两个部分，可以说又回到了二级IP地址的表示，不过大家要注意，最后面用“/”斜线分隔，在其后写上了网络前缀所占的位数，这样就不需要告知路由器地址掩码，仅需要通过网络前缀所占的位数就可以得到地址掩码，为了统一，CIDR中的地址掩码依然称为子网掩码。\nNAT\n子网的私有 IP 地址由路由器提供，通过公网无法直接访问私有子网设备，需要通过 NAT 做网络地址转换。路由器会跟踪发出的连接，并将响应转发到正确的内部 IP。\n公开端点（Public Endpoint）\n节点的公网 IP 地址:端口，例如 123.124.125.126:1234，或者直接使用域名 some.domain.tld:1234。如果对等节点不在同一子网中，那么节点的公开端点必须使用公网 IP 地址。\n私钥（Private key）\n单个节点的 WireGuard 私钥，生成方法是：wg genkey \u0026gt; example.key。\n公钥（Public key）\n单个节点的 WireGuard 公钥，生成方式为：wg pubkey \u0026lt; example.key \u0026gt; example.key.pub。\nDNS\n域名服务器，用于将域名解析为 VPN 客户端的 IP，不让 DNS请求泄漏到 VPN 之外。\n工作原理 中继服务器工作原理\n中继服务器（Bounce Server）和普通的对等节点一样，它能够在 NAT 后面的 VPN 客户端之间充当中继服务器，可以将收到的任何 VPN 子网流量转发到正确的对等节点。事实上 WireGuard 并不关心流量是如何转发的，这个由系统内核和 iptables 规则处理。\n如果所有的对等节点都是公网可达的，则不需要考虑中继服务器，只有当有对等节点位于 NAT 后面时才需要考虑。\n*在 WireGuard 里，客户端和服务端基本是平等的，差别只是谁主动连接谁而已。*双方都会监听一个 UDP 端口，谁主动连接，谁就是客户端。主动连接的客户端需要指定对端的公网地址和端口，被动连接的服务端不需要指定其他对等节点的地址和端口。如果客户端和服务端都位于 NAT 后面，需要加一个中继服务器，客户端和服务端都指定中继服务器作为对等节点，它们的通信流量会先进入中继服务器，然后再转发到对端。\nWireGuard 是支持漫游的，也就是说，双方不管谁的地址变动了，WireGuard 在看到对方从新地址说话的时候，就会记住它的新地址（跟 mosh 一样，不过是双向的）。所以双方要是一直保持在线，并且通信足够频繁的话（比如配置 persistent-keepalive），两边的 IP 都不固定也不影响的。\n流量路由\n利用 WireGuard 可以组建非常复杂的网络拓扑，这里主要介绍几个典型的拓扑：\n 端到端直接连接  这是最简单的拓扑，所有的节点要么在同一个局域网，要么直接通过公网访问，这样 WireGuard 可以直接连接到对端，不需要中继跳转。\n一端位于 NAT 后面，另一端直接通过公网暴露  这种情况下，最简单的方案是：通过公网暴露的一端作为服务端，另一端指定服务端的公网地址和端口，然后通过 persistent-keepalive 选项维持长连接，让 NAT 记得对应的映射关系。\n两端都位于 NAT 后面，通过中继服务器连接  大多数情况下，当通信双方都在 NAT 后面的时候，NAT 会做源端口随机化处理，直接连接可能比较困难。可以加一个中继服务器，通信双方都将中继服务器作为对端，然后维持长连接，流量就会通过中继服务器进行转发。\n两端都位于 NAT 后面，通过 UDP NAT 打洞  上面也提到了，当通信双方都在 NAT 后面的时候，直接连接不太现实，因为大多数 NAT 路由器对源端口的随机化相当严格，不可能提前为双方协调一个固定开放的端口。必须使用一个信令服务器（STUN），它会在中间沟通分配给对方哪些随机源端口。通信双方都会和公共信令服务器进行初始连接，然后它记录下随机的源端口，并将其返回给客户端。这其实就是现代 P2P 网络中 WebRTC 的工作原理。有时候，即使有了信令服务器和两端已知的源端口，也无法直接连接，因为 NAT 路由器严格规定只接受来自原始目的地址（信令服务器）的流量，会要求新开一个随机源端口来接受来自其他 IP 的流量（比如其他客户端试图使用原来的通信源端口）。运营商级别的 NAT 就是这么干的，比如蜂窝网络和一些企业网络，它们专门用这种方法来防止打洞连接。更多细节请参考下一部分的 NAT 到 NAT 连接实践的章节。\n如果某一端同时连接了多个对端，当它想访问某个 IP 时，如果有具体的路由可用，则优先使用具体的路由，否则就会将流量转发到中继服务器，然后中继服务器再根据系统路由表进行转发。你可以通过测量 ping 的时间来计算每一跳的长度，并通过检查对端的输出（wg show wg0）来找到 WireGuard 对一个给定地址的路由方式。\n报文格式\nWireGuard 使用加密的 UDP 报文来封装所有的数据，UDP 不保证数据包一定能送达，也不保证按顺序到达，但隧道内的 TCP 连接可以保证数据有效交付。WireGuard 的报文格式如下图所示：\n性能\nWireGuard 声称其性能比大多数 VPN 协议更好，但这个事情有很多争议，比如某些加密方式支持硬件层面的加速。\nWireGuard 直接在内核层面处理路由，直接使用系统内核的加密模块来加密数据，和 Linux 原本内置的密码子系统共存，原有的子系统能通过 API 使用 WireGuard 的 Zinc 密码库。WireGuard 使用 UDP 协议传输数据，在不使用的情况下默认不会传输任何 UDP 数据包，所以比常规 VPN 省电很多，可以像 55 一样一直挂着使用，速度相比其他 VPN 也是压倒性优势。\n安全模型\nWireGuard 使用以下加密技术来保障数据的安全：\n 使用 ChaCha20 进行对称加密，使用 Poly1305 进行数据验证。 利用 Curve25519 进行密钥交换。 使用 BLAKE2 作为哈希函数。 使用 HKDF 进行解密。  WireGuard 的加密技术本质上是 Trevor Perrin 的 Noise 框架的实例化，它简单高效，其他的 VPN 都是通过一系列协商、握手和复杂的状态机来保障安全性。WireGuard 就相当于 VPN 协议中的 qmail，代码量比其他 VPN 协议少了好几个数量级。\n密钥管理\nWireGuard 通过为每个对等节点提供简单的公钥和私钥来实现双向认证，每个对等节点在设置阶段生成密钥，且只在对等节点之间共享密钥。每个节点除了公钥和私钥，不再需要其他证书或预共享密钥。\n在更大规模的部署中，可以使用 Ansible 或 Kubernetes Secrets 等单独的服务来处理密钥的生成、分发和销毁。\n如果你不想在 wg0.conf 配置文件中直接硬编码，可以从文件或命令中读取密钥，这使得通过第三方服务管理密钥变得更加容易：\n[Interface] ... PostUp = wg set %i private-key /etc/wireguard/wg0.key \u0026lt;(cat /some/path/%i/privkey) 从技术上讲，多个服务端之间可以共享相同的私钥，只要客户端不使用相同的密钥同时连接到两个服务器。但有时客户端会需要同时连接多台服务器，例如，你可以使用 DNS 轮询来均衡两台服务器之间的连接，这两台服务器配置相同。大多数情况下，每个对等节点都应该使用独立的的公钥和私钥，这样每个对等节点都不能读取到对方的流量，保障了安全性。\n搭建使用与配置详解 快速开始 安装\n# Ubuntu ≥ 18.04 $ apt install wireguard 在中继服务器上开启 IP 地址转发：\n$ echo \u0026#34;net.ipv4.ip_forward = 1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf $ echo \u0026#34;net.ipv4.conf.all.proxy_arp = 1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf $ sysctl -p /etc/sysctl.conf 添加 iptables 规则，允许本机的 NAT 转换：\n$ iptables -A INPUT -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT $ iptables -A FORWARD -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT $ iptables -A FORWARD -i wg0 -o wg0 -m conntrack --ctstate NEW -j ACCEPT $ iptables -t nat -A POSTROUTING -s 192.0.2.0/24 -o eth0 -j MASQUERADE 需要把 eth0 改成你实际使用的网卡接口名称。\n配置文件\n配置文件可以放在任何路径下，但必须通过绝对路径引用。默认路径是 /etc/wireguard/wg0.conf。\n生成密钥\n#生成私钥 $ wg genkey \u0026gt; example.key # 生成公钥 $ wg pubkey \u0026lt; example.key \u0026gt; example.key.pub 启动与停止\n$ wg-quick up /full/path/to/wg0.conf $ wg-quick down /full/path/to/wg0.conf # 启动/停止 VPN 网络接口 $ ip link set wg0 up $ ip link set wg0 down # 注册/注销 VPN 网络接口 $ ip link add dev wg0 type wireguard $ ip link delete dev wg0 # 注册/注销 本地 VPN 地址 $ ip address add dev wg0 192.0.2.3/32 $ ip address delete dev wg0 192.0.2.3/32 # 添加/删除 VPN 路由 $ ip route add 192.0.2.3/32 dev wg0 $ ip route delete 192.0.2.3/32 dev wg0 查看信息\n# 查看系统 VPN 接口信息 $ ip link show wg0 # 查看 VPN 接口详细信息 $ wg show all $ wg show wg0 # 查看 VPN 接口地址 $ ip address show wg0 路由\n# 查看系统路由表 $ ip route show table main $ ip route show table local # 获取到特定 IP 的路由 $ ip route get 192.0.2.3 一键安装\n一键安装请参考这个项目：WireGuard installer\n配置详解 WireGuard 使用 INI 语法作为其配置文件格式。配置文件可以放在任何路径下，但必须通过绝对路径引用。默认路径是 /etc/wireguard/wg0.conf。\n配置文件的命名形式必须为 ${WireGuard 接口的名称}.conf。通常情况下 WireGuard 接口名称以 wg 为前缀，并从 0 开始编号，但你也可以使用其他名称，只要符合正则表达式 ^[a-zA-Z0-9_=+.-]{1,15}$ 就行。\n你可以选择使用 wg 命令来手动配置 VPN，但一般建议使用 wg-quick，它提供了更强大和用户友好的配置体验，可以通过配置文件来管理配置。\n下面是一个配置文件示例：\n[Interface] # Name = node1.example.tld Address = 192.0.2.3/32 ListenPort = 51820 PrivateKey = localPrivateKeyAbcAbcAbc= DNS = 1.1.1.1,8.8.8.8 Table = 12345 MTU = 1500 PreUp = /bin/example arg1 arg2 %i PostUp = /bin/example arg1 arg2 %i PreDown = /bin/example arg1 arg2 %i PostDown = /bin/example arg1 arg2 %i [Peer] # Name = node2-node.example.tld AllowedIPs = 192.0.2.1/24 Endpoint = node1.example.tld:51820 PublicKey = remotePublicKeyAbcAbcAbc= PersistentKeepalive = 25 [Interface]\n这一节定义本地 VPN 配置。例如：\n本地节点是客户端，只路由自身的流量，只暴露一个 IP。\n[Interface] # Name = phone.example-vpn.dev Address = 192.0.2.5/32 PrivateKey = \u0026lt;private key for phone.example-vpn.dev\u0026gt; 本地节点是中继服务器，它可以将流量转发到其他对等节点（peer），并公开整个 VPN 子网的路由。\n[Interface] # Name = public-server1.example-vpn.tld Address = 192.0.2.1/24 ListenPort = 51820 PrivateKey = \u0026lt;private key for public-server1.example-vpn.tld\u0026gt; DNS = 1.1.1.1  Name  这是 INI 语法中的标准注释，用于展示该配置部分属于哪个节点。这部分配置会被 WireGuard 完全忽略，对 VPN 的行为没有任何影响。\nAddress  定义本地节点应该对哪个地址范围进行路由。如果是常规的客户端，则将其设置为节点本身的单个 IP（使用 CIDR 指定，例如 192.0.2.3/32）；如果是中继服务器，则将其设置为可路由的子网范围。\n例如：\n 常规客户端，只路由自身的流量：Address = 192.0.2.3/32 中继服务器，可以将流量转发到其他对等节点（peer）：Address = 192.0.2.1/24 也可以指定多个子网或 IPv6 子网：Address = 192.0.2.1/24,2001:DB8::/64  ListenPort  当本地节点是中继服务器时，需要通过该参数指定端口来监听传入 VPN 连接，默认端口号是 51820。常规客户端不需要此选项。\nPrivateKey  本地节点的私钥，所有节点（包括中继服务器）都必须设置。不可与其他服务器共用。\n私钥可通过命令 wg genkey \u0026gt; example.key 来生成。\nDNS  通过 DHCP 向客户端宣告 DNS 服务器。客户端将会使用这里指定的 DNS 服务器来处理 VPN 子网中的 DNS 请求，但也可以在系统中覆盖此选项。例如：\n 如果不配置则使用系统默认 DNS 可以指定单个 DNS：DNS = 1.1.1.1 也可以指定多个 DNS：DNS = 1.1.1.1,8.8.8.8  Table  定义 VPN 子网使用的路由表，默认不需要设置。该参数有两个特殊的值需要注意：\n Table = off : 禁止创建路由 Table = auto（默认值） : 将路由添加到系统默认的 table 中，并启用对默认路由的特殊处理。  例如：Table = 1234\nMTU  定义连接到对等节点（peer）的 MTU（Maximum Transmission Unit，最大传输单元），默认不需要设置，一般由系统自动确定。\nPreUp  启动 VPN 接口之前运行的命令。这个选项可以指定多次，按顺序执行。\n例如添加路由：PreUp = ip rule add ipproto tcp dport 22 table 1234\nPostUp  启动 VPN 接口之后运行的命令。这个选项可以指定多次，按顺序执行。\n例如：\n  从文件或某个命令的输出中读取配置值：\nPostUp = wg set %i private-key /etc/wireguard/wg0.key \u0026lt;(some command here)   添加一行日志到文件中：\nPostUp = echo \u0026#34;$(date +%s) WireGuard Started\u0026#34; \u0026gt;\u0026gt; /var/log/wireguard.log   调用 WebHook：\nPostUp = curl https://events.example.dev/wireguard/started/?key=abcdefg   添加路由：\nPostUp = ip rule add ipproto tcp dport 22 table 1234   添加 iptables 规则，启用数据包转发：\nPostUp = iptables -A FORWARD -i %i -j ACCEPT; iptables -A FORWARD -o %i -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE   强制 WireGuard 重新解析对端域名的 IP 地址：\nPostUp = resolvectl domain %i \u0026#34;~.\u0026#34;; resolvectl dns %i 192.0.2.1; resolvectl dnssec %i yes   PreDown  停止 VPN 接口之前运行的命令。这个选项可以指定多次，按顺序执行。\n例如：\n  添加一行日志到文件中：\nPreDown = echo \u0026#34;$(date +%s) WireGuard Going Down\u0026#34; \u0026gt;\u0026gt; /var/log/wireguard.log   调用 WebHook：\nPreDown = curl https://events.example.dev/wireguard/stopping/?key=abcdefg   PostDown  停止 VPN 接口之后运行的命令。这个选项可以指定多次，按顺序执行。\n例如：\n  添加一行日志到文件中：\nPostDown = echo \u0026#34;$(date +%s) WireGuard Going Down\u0026#34; \u0026gt;\u0026gt; /var/log/wireguard.log   调用 WebHook：\nPostDown = curl https://events.example.dev/wireguard/stopping/?key=abcdefg   删除 iptables 规则，关闭数据包转发：\nPostDown = iptables -D FORWARD -i %i -j ACCEPT; iptables -D FORWARD -o %i -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE   [Peer]\n定义能够为一个或多个地址路由流量的对等节点（peer）的 VPN 设置。对等节点（peer）可以是将流量转发到其他对等节点（peer）的中继服务器，也可以是通过公网或内网直连的客户端。\n中继服务器必须将所有的客户端定义为对等节点（peer），除了中继服务器之外，其他客户端都不能将位于 NAT 后面的节点定义为对等节点（peer），因为路由不可达。对于那些只为自己路由流量的客户端，只需将中继服务器作为对等节点（peer），以及其他需要直接访问的节点。\n举个例子，在下面的配置中，public-server1 作为中继服务器，其他的客户端有的是直连，有的位于 NAT 后面：\n  public-server1（中继服务器）\n[peer] : public-server2, home-server, laptop, phone\n  public-server2（直连客户端）\n[peer] : public-server1\n  home-server（客户端位于 NAT 后面）\n[peer] : public-server1, public-server2\n  laptop（客户端位于 NAT 后面）\n[peer] : public-server1, public-server2\n  phone（客户端位于 NAT 后面）\n[peer] : public-server1, public-server2\n  配置示例：\n  对等节点（peer）是路由可达的客户端，只为自己路由流量\n[Peer] # Name = public-server2.example-vpn.dev Endpoint = public-server2.example-vpn.dev:51820 PublicKey = \u0026lt;public key for public-server2.example-vpn.dev\u0026gt; AllowedIPs = 192.0.2.2/32   对等节点（peer）是位于 NAT 后面的客户端，只为自己路由流量\n[Peer] # Name = home-server.example-vpn.dev Endpoint = home-server.example-vpn.dev:51820 PublicKey = \u0026lt;public key for home-server.example-vpn.dev\u0026gt; AllowedIPs = 192.0.2.3/32   对等节点（peer）是中继服务器，用来将流量转发到其他对等节点（peer）\n[Peer] # Name = public-server1.example-vpn.tld Endpoint = public-server1.example-vpn.tld:51820 PublicKey = \u0026lt;public key for public-server1.example-vpn.tld\u0026gt; # 路由整个 VPN 子网的流量 AllowedIPs = 192.0.2.1/24 PersistentKeepalive = 25    Endpoint  指定远端对等节点（peer）的公网地址。如果对等节点（peer）位于 NAT 后面或者没有稳定的公网访问地址，就忽略这个字段。通常只需要指定中继服务器的 Endpoint，当然有稳定公网 IP 的节点也可以指定。例如：\n  通过 IP 指定：\nEndpoint = 123.124.125.126:51820   通过域名指定：\nEndpoint = public-server1.example-vpn.tld:51820   AllowedIPs  允许该对等节点（peer）发送过来的 VPN 流量中的源地址范围。同时这个字段也会作为本机路由表中 wg0 绑定的 IP 地址范围。如果对等节点（peer）是常规的客户端，则将其设置为节点本身的单个 IP；如果对等节点（peer）是中继服务器，则将其设置为可路由的子网范围。可以使用 , 来指定多个 IP 或子网范围。该字段也可以指定多次。\n当决定如何对一个数据包进行路由时，系统首先会选择最具体的路由，如果不匹配再选择更宽泛的路由。例如，对于一个发往 192.0.2.3 的数据包，系统首先会寻找地址为 192.0.2.3/32 的对等节点（peer），如果没有再寻找地址为 192.0.2.1/24 的对等节点（peer），以此类推。\n例如：\n  对等节点（peer）是常规客户端，只路由自身的流量：\nAllowedIPs = 192.0.2.3/32   对等节点（peer）是中继服务器，可以将流量转发到其他对等节点（peer）：\nAllowedIPs = 192.0.2.1/24   对等节点（peer）是中继服务器，可以转发所有的流量，包括外网流量和 VPN 流量，可以用来干嘛你懂得：\nAllowedIPs = 0.0.0.0/0,::/0   对等节点（peer）是中继服务器，可以路由其自身和其他对等节点（peer）的流量：\nAllowedIPs = 192.0.2.3/32,192.0.2.4/32   对等节点（peer）是中继服务器，可以路由其自身的流量和它所在的内网的流量：\nAllowedIPs = 192.0.2.3/32,192.168.1.1/24   PublicKey  对等节点（peer）的公钥，所有节点（包括中继服务器）都必须设置。可与其他对等节点（peer）共用同一个公钥。\n公钥可通过命令 wg pubkey \u0026lt; example.key \u0026gt; example.key.pub 来生成，其中 example.key 是上面生成的私钥。\n例如：PublicKey = somePublicKeyAbcdAbcdAbcdAbcd=\nPersistentKeepalive  如果连接是从一个位于 NAT 后面的对等节点（peer）到一个公网可达的对等节点（peer），那么 NAT 后面的对等节点（peer）必须定期发送一个出站 ping 包来检查连通性，如果 IP 有变化，就会自动更新Endpoint。\n例如：\n 本地节点与对等节点（peer）可直连：该字段不需要指定，因为不需要连接检查。 对等节点（peer）位于 NAT 后面：该字段不需要指定，因为维持连接是客户端（连接的发起方）的责任。 本地节点位于 NAT 后面，对等节点（peer）公网可达：需要指定该字段 PersistentKeepalive = 25，表示每隔 25 秒发送一次 ping 来检查连接。  GUI Utilities Gnome GNOME 系统设置面板（gnome-control-center）和 GNOME 应用使用 dconf 配置系统存储设置。您可以使用 gsettings 或 dconf 命令行工具直接访问 dconf 数据库。这也可以让你修改用户界面不公开的设置。\nGNOME 桌面拥有强大的搜索功能，按 Super 键并搜索一些东西，可以进入“Settings-Search”中来设置可以搜索的内容和顺序。\nDo Not Disturb 使通知只在消息栏中，不会在桌面上弹出。\nGnome 3 自动切换的壁纸会有一个有时钟小图标。\n浏览 GNOME Shell cheat sheet 中解释了如何高效地使用 GNOME shell，它展示了 GNOME shell 的特色和快捷键，包括切换任务，使用键盘，窗口控制，面板，概览模式等等。以下是部分常用的快捷键：\n Super + m：显示消息托盘 Super + a：显示应用程序菜单 Alt- + Tab：切换当前使用的应用 Alt- + ` (美式键盘 Tab 上面的按键)：切换前台应用程序的窗口 Alt + F2，然后输入 r 或 restart：在图形界面出问题时重启界面（仅用于 X/传统 模式，不适用于 Wayland 模式）。也可通过此运行后台应用，如 cfw。  遗留名称 注意： 一些 GNOME 程序在文档和对话框中的名称已经更改，但执行文件名称却没有。下面表格列出了一些这样的应用程序。\n提示： 在搜索栏中搜索应用的遗留名称将成功找到对应的应用，例如搜索 nautilus 将返还 文件。\n   当前 遗留     文件 Nautilus   Web Epiphany   视频 Totem   主菜单 Alacarte   文档查看器 Evince   磁盘使用情况分析器 Baobab   图像查看器 EoG (Eye of GNOME)   密码和密钥 Seahorse    修改文件默认关联的应用程序  mime类型文件存在于以下的两个路径：  /usr/share/mime ~/.local/share/mime    /usr/share/mime/text/makrdown.xml  应用程序的desktop文件，存在于以下的两个路径：  /usr/share/applications ~/.local/share/applications    [Desktop Entry] # 应用名称，即开始菜单中的名称 Type=ApplicationName=name # 应用执行文件位置 Exec=appPath # 应用图标位置 Icon=default48.png # 是否显示终端 Terminal=false # 所属分类 StartupNotify=trueCategories=Office # MIME 类型 MimeType=text/x-markdown  应用程序默认关联文件，存在于以下的两个路径：  /usr/share/applications/mimeapps.list ~/.local/share/applications/mimeapps.list    Gedit 编码 直接打开gedit（非通过文件打开），点击左上角 Open，点击左下角 Automatically Detected，下拉选择 Add or Remove\u0026hellip;，将简体中文编码都选上。\n或者：\n$ gsettings list-keys org.gnome.gedit.preferences.encodings candidate-encodings $ gsettings set org.gnome.gedit.preferences.encodings candidate-encodings \u0026#34;[\u0026#39;UTF-8\u0026#39;, \u0026#39;ISO-8859-15\u0026#39;, \u0026#39;UTF-16\u0026#39;, \u0026#39;GBK\u0026#39;, \u0026#39;GB18030\u0026#39;, \u0026#39;GB2312\u0026#39;]\u0026#34; NVIDIA Optimus NVIDIA Optimus 是一项允许英特尔（Intel）集成图形处理器（GPU）和英伟达（NVIDIA）独立图形处理器置入并通过一台笔记本电脑访问的技术。\n桌面卡死 总的来说，就是杀死相关进程，或者避免使用造成卡死相关软件。\n  选择其他 tty：\n$ pkill Xorg pkill 用于杀死一个进程，与 kill 不同的是它会杀死指定名字的所有进程。kill 命令杀死指定进程 PID，需要配合 ps 使用。\n  安全重启：同时按住 Ctrl 和 Alt 键，按住不要放，按一下 SysRq 键（有的键盘是PrtSc），按一下 R 键，按一下 E 键，依次按下 I , S , U , B 键。\n  解决 Ubuntu 经常卡死：ubuntu 的卡死可能与显卡驱动不兼容有关。用 nvidia 代替 nouveau显卡驱动。其中 nvidia-driver-470-server 是 server 版，最好用 nvidia-driver-470\n  PRIME synchronization You can enable PRIME synchronization to prevent screen tearing. It requires:\n Linux kernel 4.5 or higher; X server 1.19 or higher; NVIDIA driver 370.23 or higher.  PRIME synchronization will be enabled automatically after you enable KMS for nvidia-drm module.\n  Add this line to the end of /etc/modprobe.d/nvidia.conf:\noptions nvidia-drm modeset=1   Regenerate your initramfs image by running:\n# update-initramfs -u   Reboot.\n  要检查重新启动后以前的更改是否有效，请运行命令：\n$ sudo cat /sys/module/nvidia_drm/parameters/modeset Y see more about nvidia on uat BinaryDriverHowto/Nvidia\nPermanently Set NVIDIA PowerMizer Settings $ nvidia-settings -q GpuPowerMizerMode Attribute \u0026#39;GPUPowerMizerMode\u0026#39; (rastating-PC:1[gpu:0]): 0. Valid values for \u0026#39;GPUPowerMizerMode\u0026#39; are: 0, 1 and 2. \u0026#39;GPUPowerMizerMode\u0026#39; can use the following target types: GPU. $ nvidia-settings -a \u0026#34;[gpu:0]/GpuPowerMizerMode=1\u0026#34; Attribute \u0026#39;GPUPowerMizerMode\u0026#39; (rastating-PC:1[gpu:0]) assigned value 1. $ nvidia-settings -q GpuPowerMizerMode Attribute \u0026#39;GPUPowerMizerMode\u0026#39; (rastating-PC:1[gpu:0]): 1. Valid values for \u0026#39;GPUPowerMizerMode\u0026#39; are: 0, 1 and 2. \u0026#39;GPUPowerMizerMode\u0026#39; can use the following target types: GPU. 添加到开机启动\n Name：NVIDIA X Server Performance Settings Command：/usr/bin/nvidia-settings -a \u0026quot;[gpu:0]/GpuPowerMizerMode=1\u0026quot;  密钥环 如果你用过 Ubuntu 或者其他的 Linux 发行版里的自动登录功能, 你可能遇到过这种弹出消息：\n 请输入密码以解锁你的登录密钥环\n登录密钥环在你登录系统时未解锁。\n 如果你一直点击取消，它会不断弹出几次才会消失。你可能想知道，为什么你会一直看到这个密钥环信息呢？\n让我来告诉你吧。它其实不是错误，而是一个安全特性。\n奇怪吗？下面就让我来解释下 Linux 里的密钥环概念。\n密钥环是什么，为什么需要它？ 在现实生活中你为什么要用钥匙环（也叫钥匙链）？你用它把一把或多把钥匙串到一起, 以便于携带和查找。\nLinux 里也是类似的。密钥环特性使你的系统可以将各种密码放在一起，并将其保存在一个地方。\n大多数 Linux 桌面环境，如 GNOME、KDE、Xfce 等采用 GNOME 密钥环来提供这个功能。\n该密钥环保存了 ssh 密钥、GPG 密钥以及使用此功能的应用程序（例如 Chromium 浏览器）的密钥。默认情况下，“密钥环”通过主密码来保护，该密码通常是帐户的登录密码。\n系统上的每个用户都有自己的密钥环，（通常）密码与用户帐户本身的密码相同。当你使用密码登录系统时，你的密匙环将使用你帐户的密码自动解锁。\n当你启用 Ubuntu 中的自动登录功能时时，就有问题了。这意味着你无需输入密码即可登录系统。在这种情况下，你的密钥环不会自动解锁。\n密钥环是一个安全特性\n记得我说过密钥环是一个安全特性吗？现在想象一下你在 Linux 电脑上开启了自动登录功能。有权访问你电脑的任何人无需密码就能进入你的系统。但是你可能不会在意，因为你只是用它来访问互联网。\n但是，如果你在 Ubuntu 中使用 Chromium 或 Google Chrome 之类的浏览器，并使用它来保存各种网站的登录密码，那么你将遇到麻烦。任何人都可以使用浏览器并利用你在浏览器中保存的密码登录网站。这不很危险吗？\n这就是为什么当你使用 Chrome 时，它将反复地提示你先解锁密钥环。这确保了只有知道密钥环密码（即账户密码）的人才能使用在浏览器中保存的密码来登录它们相关的网站。\n如果你反复取消解锁密钥环的提示，它最终将消失，并允许你使用浏览器。但是，保存的密码将不会被解锁，你在 Chromium/Chome 浏览器上将会看到“同步暂停”的提示。\n如果密钥环一直存在，为什么你从来没有见过它呢?\n如果你在你的 Linux 系统上从没见过它的话，这个问题就很有道理。\n如果你从没有用过自动登录功能（或者修改你的账户密码），你可能都没有意识到这个特性的存在。\n这是因为当你通过你的密码登录系统时，你的密钥环被你的账户密码自动解锁了。\nUbuntu（和其他发行版）在执行普通的管理任务如修改用户、安装新软件等需要输入密码，无论你是否是自动登录的。但是对于日常任务像使用浏览器，它不需要输入密码因为密钥环已经被解锁了。\n当你切换到自动登录时，你不再需要输入登录密码。这意味着密钥环没有被自动解锁，因此当你使用利用了密钥环特性的浏览器时，它将提示你来解锁密钥环。\n你可以轻松地管理密钥环和密码\n这个密钥环放在哪里？它的核心是一个守护任务（一个后台自动运行的程序）。\n别担心。你不必通过终端来操作守护任务。大多数桌面环境都自带一个可以和这个守护进程进行交互的图形化应用程序。KDE 上有 KDE 钱包，GNOME 和其他桌面上叫做“密码和密钥”（Password And Keys）。\n你可以用这个 GUI 程序来查看哪些应用程序在用密钥环来管理/保护密码。\n你可以看到，我的系统有自动创建的登录密钥环。也有一个存储 GPG 和 SSH 密钥的密钥环。那个证书用来保存证书机构颁发的证书（如 HTTPS 证书）。\n你也可以使用这个应用程序来手动保存网站的密码。\n这里有一个潜在的问题，如果你格式化你的系统，手动保存的密码必然会丢失。通常，你会备份你的个人文件，但并不是所有的用户特定数据，如密钥环文件。\n有一种办法能解决它。密钥环数据通常保存在 ~/.local/share/keyrings 目录。在这里你可以看到所有的密钥环，但是你不能直接看到它们的内容。如果你移除密钥环的密码（我会在这篇文章的后面描述操作步骤），你可以像一个普通的文本文件一样读取密钥环的内容。你可以将这个解锁后的密钥环文件完整地复制下来，并在其他的 Linux 机器上运行“密码和密钥”应用程序导入到其中。\n总结一下目前为止所学的内容：\n 大多数 Linux 系统缺省已经安装并激活了密钥环特性 系统上的每个用户都拥有他自己的密钥环 密钥环通常是用账户密码锁定的（保护） 当你通过密码登录时密钥环会被自动解锁 对于自动登录，密钥环不会自动解锁，因此当你试图使用依赖密钥环的应用程序时会被提示先解锁它 并不是所有的浏览器或应用程序利用了密钥环特性 （Linux 上）安装一个 GUI 程序可以和密钥环交互 你可以用密钥环来手动存储加密格式的密码 你可以自己修改密钥环密码 你可以通过导出（需要先解锁密钥环）并导入到其他计算机上的方式来获取手工保存的密码。  修改密钥环密码 假设你修改了你的账户密码。当你登录时，你的系统试图通过新的登录密码来自动解锁密钥环。但是密钥环还在使用老的登录密码。\n这种情况下，你可以修改密钥环密码为新的登录密码，这样密码环才能在你登录系统时自动解锁。\n 从菜单中打开“密码和密钥”应用程序 在“Login”密钥环上右击并点击“修改密码”：  如果你不记得老的登录密码怎么办？\n你可能知道在 Ubuntu 上重置忘记的密码很容易。但是密钥环在这种场景下还是有问题。你修改了账户密码，但是你不记得仍然被密钥环使用的老的账户密码。\n你不能修改它因为你不知道老的密码。怎么办？\n这种情况下，你将不得不移除整个密钥环。你可以通过“密码和密钥”应用程序来操作。\n另外，你也可以手动删除 ~/.local/share/keyrings 目录下的密钥环文件。\n老的密钥环文件被移除后，你再打开 Chrome/Chromium 时，它会提示你创建一个新的密钥环。\n你可以用新的登录密码，密钥环就会被自动解锁了。\n禁用密钥环密码 在你想用自动登录但又不想手动解锁密钥环时，你可以把禁用密钥环密码作为一个规避方法。记住你正在禁用一个安全特性，因此请三思。\n操作步骤和修改密钥环相似。打开“密码和密钥”应用程序，然后修改密钥环密码。\n技巧在于当它提示修改密码时，不要输入新密码，而是点击“继续”按钮。这将移除密钥环的密码。\n这种方法，密钥环没有密码保护，并将一直处于解锁状态。\nGnome Tweaks GNOME 桌面有称为“扩展”的小插件或附加组件，学会使用 GNOME 扩展来扩展系统的可用性。\n$ sudo apt install gnome-tweaks 同时会安装新的 GNOME Shell extensions，可以禁用桌面图标、Ubuntu Dock。可从浏览器安装 GNOME Shell extensions。\n如 OpenWeather，需设置 Location，Units 为公制单位，Layout为Right\ntheme design: Skeuomorphism vs Flat Design vs Material Design\n 主题目录： /usr/share/themes 或 ~/.themes 图标鼠标目录： /usr/share/icons 或 ~/.icons 壁纸： /usr/share/background , /usr/share/wallpapers  Ubuntu Dock Ubuntu Dock 就是 Dash to Dock。安装：\n$ sudo apt-get install gnome-shell-extension-dashtodock 重启，在 Extension 中设置 Dash to Dock，Dash to Dock 与 Ubuntu Dock 只能开启一个，否则有两个 Dock，但是就算关闭 Dash to Dock，Dash to Dock 设置依旧起作用到 Ubuntu Dock。\n重新登录。\nKDE Connect/GSConnect Files and links. Shared between devices.\nNetSpeed Displays Internet Speed\nClipboard Indicator Clipboard Manager extension for Gnome-Shell - Adds a clipboard indicator to the top panel, and caches clipboard history.\nCoverflow Alt-Tab Replacement of Alt-Tab, iterates through windows in a cover-flow manner.\nBluetooth Quick Connect Allow to connect to paired devices from gnome control panel.\nDesktop Icons NG (DING) with these advantages:\n Drag\u0026rsquo;n\u0026rsquo;Drop, both inside the desktop, between desktop and applications, and nautilus windows Allows to use \u0026ldquo;Open with\u0026hellip;\u0026rdquo; option with several files When hovering or clicking on an icon with a name too large to fit, it shows the full name Doesn\u0026rsquo;t hang the compositor when there is too much activity in the desktop folder  Frippery Move Clock Move clock to left of status menu button\nInput Method Panel Input Method Panel using KDE\u0026rsquo;s kimpanel protocol for Gnome-Shell\nLock Keys Numlock \u0026amp; Capslock status on the panel\nOpenWeather Weather extension to display weather information from https://openweathermap.org/ or https://darksky.net for almost all locations in the world.\nPanel Date Format Allows to customize the date format on the panel.\nRefresh Wifi Connections This extension adds a refresh button to the Wi-Fi connection selection dialog to manually request for a network scan.\nScreenshot Tool Conveniently create, copy, store and upload screenshots. Please log out and log in again after updating.\nSound Input \u0026amp; Output Device ChooserLivepatch Shows a list of sound output and input devices (similar to gnome sound settings) in the status menu below the volume slider.\nStatus Area Horizontal Spacing Reduce the horizontal spacing between icons in the top-right status area\nUnite Unite is a GNOME Shell extension which makes a few layout tweaks to the top panel and removes window decorations to make it look like Ubuntu Unity Shell.\nUser Themes Load shell themes from user directory.\nVitals A glimpse into your computer\u0026rsquo;s temperature, voltage, fan speed, memory usage, processor load, system resources, network speed and storage stats. This is a one stop shop to monitor all of your vital sensors. Uses asynchronous polling to provide a smooth user experience.\nPapirus Icon Theme $ sudo add-apt-repository ppa:papirus/papirus $ sudo apt-get update $ sudo apt-get install papirus-icon-theme Materia Theme $ sudo apt install materia-gtk-theme Chrome Import Passwords\n Launch Chrome on your computer. Type the following in the address bar and pressEnter: chrome://flags On the flags screen, put your cursor in the search box and type Password import. You should see the Password import flag in the search results. To enable this flag, click the dropdown menu next to the flag and select Enabled. Click Relaunch at the bottom to relaunch Chrome. This will restore all of your open tabs. When Chrome opens, click the three dots in the top-right corner, and select Settings \u0026gt; Passwords on the following screen. Click the three dots next to Saved Passwords and select Import. Navigate to your CSV passwords file and select it to import it into Chrome.  Tampermonkey 提供用户脚本\n FastGithub 镜像加速访问、克隆和下载 文本选中复制：解除网站不允许复制的限制，文本选中后点击复制按钮即可复制，主要用于 百度文库 道客巴巴 无忧考网 学习啦 蓬勃范文 思否社区 力扣 知乎 语雀 等 秒传链接提取：用于提取和生成百度网盘秒传链接 知乎增强：移除登录弹窗 网页复制限制解除  Download All Images 下载网页所有图片\nuBlock Origin 禁广告\n沙拉查词 聚合词典专业划词翻译\nInfinity New Tab Chrome Extension，解决 Chrome new tab 加载后会清空搜索栏问题\nQuestions The repository \u0026lsquo;http://dl.google.com/linux/chrome/deb stable Release\u0026rsquo; does not have a Release file\nThe \u0026ldquo;key\u0026rdquo; is \u0026ldquo;repository can\u0026rsquo;t be authenticated\u0026rdquo;\nIMHO\u0026hellip; you don\u0026rsquo;t have the key of the repo\nTo solve that just use this command:\n$ wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add - Chromium Chromium 是一款来自 \u0026ldquo;The Chromium Project\u0026rdquo; 的开源图形网络浏览器，基于 Blink 渲染引擎。它也是商业软件 Google Chrome 浏览器得以组成的基础。\n在这里你可以看到 Google Chrome 与 Chromium 浏览器的区别。此外，还有一点重要的不同：2021年3月2日发布的 Chromium 89 及其以后版本不再支持 Google 账户同步功能。\n注意： 目前，可以通过 使用 Chrome 的OAuth2 凭证或者 申请一个属于自己的凭证来恢复同步功能, 但是请注意，这不一定是一个长期的解决方案。长期来讲，最好考虑使用 xbrowsersync 来同步书签数据。\nFirefox 主要用于 Firefox，安装媒体解码器来播放 MP3、MPEG4 和其他格式媒体文件。由于各个国家的版权问题， Ubuntu 在默认情况下不会安装它。\n$ sudo apt-get install ubuntu-restricted-extras 这种方式会安装 .exe 程序，不如直接安装\n$ sudo apt-get install h264enc Flameshot Powerful, yet simple to use open-source screenshot software.\n   Keys Description     ←, ↓, ↑, → Move selection 1px   Shift + ←, ↓, ↑, → Resize selection 1px   Esc Quit capture   Ctrl + C Copy to clipboard   Ctrl + S Save selection as a file   Ctrl + Z Undo the last modification   Right Click Show color picker   Mouse Wheel Change the tool\u0026rsquo;s thickness    Add a new Shortcuts\n On \u0026lsquo;Name\u0026rsquo;, name it \u0026lsquo;Flameshot\u0026rsquo; Define the command as \u0026lsquo;flameshot gui\u0026rsquo;. Select \u0026lsquo;Define shortcut\u0026hellip;\u0026lsquo;and click your keyboard win + shift + Prt Sc key.  PPSSPP A PSP emulator.\n$ sudo add-apt-repository ppa:ppsspp/stable $ sudo apt-get update $ sudo apt install ppsspp Graphics:\n Rendering Mode  set the Backend from OpenGL to Vulkan.   Framework Control  Frameskipping is Off Auto-Frameskip is Off set the Alternative Speed to Unlimited   Postprocessing effects  Postprocessing shader should be off.   Performance  If your Device is Powerful, high rendering resolution will work. Its recommended to first try with 2x Rendering resolution as It brings impressive graphics and supports stable gameplay too Hardware transform, Software skinning, Vertex cache and Lazy texture caching should be checked. Retain changed textures should be unchecked while keeping Disable slower effects and Hardware Installation checked.   Overlay Information  Select FPS in Show FPS counter.    System:\n Make sure Fast memory is checked Set I/O timing method, to Simulate UMD delays or Fast  yuzu yuzu 是 Citra的制作者写的一个开源NS模拟器，用C++编写，特点包括Vulkan API的支持、灵活的模拟器配置以及游戏配置等等。\n玩了 super mario odyssey，过场动画很卡顿，可以软配置的很少，主要看硬件配置，我的配置玩 BOTW 是不可能了。\n安装   选择 File -\u0026gt; Open yuzu Folder\n  在打开的目录下，新建keys文件夹（如果没有），然后进入keys文件夹，放入key文件prod.keys，内容如下\naes_kek_generation_source = 4d870986c45d20722fba1053da92e8a9 aes_key_generation_source = 89615ee05c31b6805fe58f3da24f7aa8 bis_kek_source = 34c1a0c48258f8b4fa9e5e6adafc7e4f bis_key_00 = 374e0e2ab275141f811badcb0fefd881b71d6af540de58895901aa0c01663bc8 bis_key_01 = 0b08f19a42ac5ae590b3373ad9698344a571f35165663536dae0842b5221b31c bis_key_02 = 38f0936f33bacedc0c0a159ffbbeee0f40bb08386915bdd0c6730349b99081ec bis_key_03 = 38f0936f33bacedc0c0a159ffbbeee0f40bb08386915bdd0c6730349b99081ec bis_key_source_00 = f83f386e2cd2ca32a89ab9aa29bfc7487d92b03aa8bfdee1a74c3b6e35cb7106 bis_key_source_01 = 41003049ddccc065647a7eb41eed9c5f44424edab49dfcd98777249adc9f7ca4 bis_key_source_02 = 52c2e9eb09e3ee2932a10c1fb6a0926c4d12e14b2a474c1c09cb0359f015f4e4 device_key = bd16c45b2647d842c5ee3c869e3a9607 device_key_4x = 2078900c6bb36fff1fdad57a7dd1b66e eticket_rsa_kek = 19c8b441d318802bad63a5beda283a84 eticket_rsa_kek_source = dba451124ca0a9836814f5ed95e3125b eticket_rsa_kekek_source = 466e57b74a447f02f321cde58f2f5535 header_kek_source = 1f12913a4acbf00d4cde3af6d523882a header_key = aeaab1ca08adf9bef12991f369e3c567d6881e4e4a6a47a51f6e4877062d542d header_key_source = 5a3ed84fdec0d82631f7e25d197bf5d01c9b7bfaf628183d71f64d73f150b9d2 key_area_key_application_00 = ef979e289a132c23d39c4ec5a0bba969 key_area_key_application_01 = cdedbab97b69729073dfb2440bff2c13 key_area_key_application_02 = 75716ed3b524a01dfe21456ce26c7270 key_area_key_application_03 = f428306544cf5707c25eaa8bc0583fd1 key_area_key_application_04 = 798844ec099eb6a04b26c7c728a35a4d key_area_key_application_05 = a57c6eecc5410ada22712eb3ccbf45f1 key_area_key_application_06 = 2a60f6c4275df1770651d5891b8e73ec key_area_key_application_07 = 32221bd6ed19b938bec06b9d36ed9e51 key_area_key_application_08 = fb20aa9e3dbf67350e86479eb431a0b3 key_area_key_application_09 = ce8d5fa79e220d5f48470e9f21be018b key_area_key_application_0a = 38b865725adcf568a81d2db3ceaa5bcc key_area_key_application_0b = bbddfd40a59d0ff555c0954239972213 key_area_key_application_0c = 3fee7204e21c6b0ff1373226c0c3e055 key_area_key_application_source = 7f59971e629f36a13098066f2144c30d key_area_key_ocean_00 = b33813e4c9c4399c75fabc673ab4947b key_area_key_ocean_01 = c54166efa8c9c0f6511fa8b580191677 key_area_key_ocean_02 = 3061ce73461e0b0409d6a33da85843c8 key_area_key_ocean_03 = 06f170025a64921c849df168e74d37f2 key_area_key_ocean_04 = dc857fd6dc1c6213076ec7b902ec5bb6 key_area_key_ocean_05 = 131d76b70bd8a60036d8218c15cb610f key_area_key_ocean_06 = 17d565492ba819b0c19bed1b4297b659 key_area_key_ocean_07 = 37255186f7678324bf2b2d773ea2c412 key_area_key_ocean_08 = 4115c119b7bd8522ad63c831b6c816a6 key_area_key_ocean_09 = 792bfc652870cca7491d1685384be147 key_area_key_ocean_0a = dfcc9e87e61c9fba54a9b1c262d41e4d key_area_key_ocean_0b = 66fe3107f5a6a8d8eda2459d920b07a1 key_area_key_ocean_0c = b79b6bf3d6cdc5ec10277fc07a4fec93 key_area_key_ocean_source = 327d36085ad1758dab4e6fbaa555d882 key_area_key_system_00 = 6dd02aa15b440d6231236b6677de86bc key_area_key_system_01 = 4ab155e7f29a292037fd147592770b12 key_area_key_system_02 = b7a74adeaf89c2a198c327bdff322d7d key_area_key_system_03 = d5aab1acd23a8aec284a316df859d377 key_area_key_system_04 = 9b44b45b37de9d14754b1d22c2ca742c key_area_key_system_05 = 0012e957530d3dc7af34fbbe6fd44559 key_area_key_system_06 = 01744e3b0818445cd54ee9f89da43192 key_area_key_system_07 = d0d30e46f5695b875f11522c375c5a80 key_area_key_system_08 = bd06cb1b86bd5c433667470a09eb63de key_area_key_system_09 = e19f788f658eda8bbf34a1dd2a9503a9 key_area_key_system_0a = 7070e7ff5cfe448630143a9874903c38 key_area_key_system_0b = 3fa471d4483e58b8f7756fcb64f63890 key_area_key_system_0c = 7bfd381df3369407ab1c6bdd9fabf522 key_area_key_system_source = 8745f1bba6be79647d048ba67b5fda4a keyblob_00 = f759024f8199101dddc1ef91e6eecf37e24b95ac9272f7ae441d5d8060c843a48322d21cdd06d4fc958c68d3800eb4db939ffbec930177f77d136144ff615aa8835e811bb958deda218f8486b5a10f531b30cb9d269645ac9fc25c53fc80525e56bd3602988a9fcf06bbf99ca910ad6530791d512c9d57e17abf49220de6419bf4eca1685c1e4df77f19db7b44a985ca keyblob_01 = bd27264ae07e979756411d0c66e679e3c50851f3e902d9c2cd1a438b948159a517ec1566c10570326ea2697ee62da46f14bb5d581bfc06fd0c9387ea33d2d4dc63e7809ba90f03dd2c7112ffbfa548951b9b8c688b5e4f2951d24a73da29c668154a5d4838dba71ee068ace83fe720e8c2a495c596f73525dc3c05994b40ad27f8c60322f75cd548b821af9162e16f76 keyblob_02 = a3d4a8e153b8e6ae6e6aef3e8f219cb4b7790f47856accc76268f9afa99a1ff8b1a72f63d1f99f480a3c1532078bb59abdd25203cfb12a38b33e9ba6a09afb6f24283b3ba76a0161230a73669ddf5493c2b7919d094fd795b484794854f71e4f4c672245d7770e29397722444d111b4229cdbf35707b70634ea8f140766e884cc580cb1e2d9aa9866ffef920010fc409 keyblob_03 = 1558f525ae8c5be9243fb6d8a8b0a8ee0e886a59035668740a936619b7a5c83e821198b171d18e51445054df68688e45703b936818a827d8e540dd6bef2e11ec9ddc6cfe5fc736dd769b9f6e0a23a62e2e5f49e86143646a04ec3a23f828373a336a5c224a91f8a0c6c6a7b5844dd6415804209f83c943aeca9cfd856db6bd4ec32009c8cb268ed053052c9237dfd8bc keyblob_04 = 9fbeb1957fc1629e08b753a9086d6e01ffb4f11466b7417e3fa7f5f1efb754406704fd75afaf91a408a0b524c1fc80d36c2046fa4757412efe4c11e382f72e8a10d90ed580017d9deb87af2549b6b02661af48ff94f6072c0fef7fc2833b8bdae503898e2e927ac0663e8b6391dd4f1d685313935e2c48ece7d177c88bc9c883ede36c3677495784b838d7265c6ba7a1 keyblob_05 = 94a92da1d73c2b3e165c891ced5607fc6628ca2a0654f3fbc05711c063377c6e9c96a9d0192e530dd510e4fd41aa62ef4213c5f6e059e7e21db098a9b22d1e6c29bee148aaef15c52549d9165de96e85b0d029ecdc5843e2f32cb18be707eec61909cf3385d45bc2a4c8d76e9bfad5a40c4b92dcb982aa50d474897ac9ebb5351a7015dcc277a08f1214ad41384d7941 keyblob_key_00 = 839944c8a38df6791020b38147e906b0 keyblob_key_01 = b9e6fbde828b5f42c897ade8fd14c625 keyblob_key_02 = b6988a0795d294ef522908692d5db7ca keyblob_key_03 = 0e57d7777171d125d3fe3af5b397d009 keyblob_key_04 = b55a282d698fabeb4e03c67ff2026bc5 keyblob_key_05 = fdb542c1f1bdf134ec20b1fda02bc9e1 keyblob_key_source_00 = df206f594454efdc7074483b0ded9fd3 keyblob_key_source_01 = 0c25615d684ceb421c2379ea822512ac keyblob_key_source_02 = 337685ee884aae0ac28afd7d63c0433b keyblob_key_source_03 = 2d1f4880edeced3e3cf248b5657df7be keyblob_key_source_04 = bb5a01f988aff5fc6cff079e133c3980 keyblob_key_source_05 = d8cce1266a353fcc20f32d3b517de9c0 keyblob_mac_key_00 = 604422526723e541a849fa4c18660e0b keyblob_mac_key_01 = 279481456b1dc259d35599e6392e01e5 keyblob_mac_key_02 = dbbfb8096b676c2a54b5d9c61b423a94 keyblob_mac_key_03 = 48b7aef6d9b1edb132b8901a245a7750 keyblob_mac_key_04 = 544c082e9f8602c736dc0732d4319f88 keyblob_mac_key_05 = a540ec8ba84bd31eaaa9ce9f95226875 keyblob_mac_key_source = 59c7fb6fbe9bbe87656b15c0537336a5 mariko_master_kek_source_05 = 77605ad2ee6ef83c3f72e2599dac5e56 mariko_master_kek_source_06 = 1e80b8173ec060aa11be1a4aa66fe4ae mariko_master_kek_source_07 = 940867bd0a00388411d31adbdd8df18a mariko_master_kek_source_08 = 5c24e3b8b4f700c23cfd0ace13c3dc23 mariko_master_kek_source_09 = 8669f00987c805aeb57b4874de62a613 mariko_master_kek_source_0a = 0e440cedb436c03faa1daebf62b10982 mariko_master_kek_source_0b = e541acecd1a7d1abed0377f127caf8f1 mariko_master_kek_source_0c = 52719bdfa78b61d8d58511e48e4f74c6 master_kek_00 = f759024f8199101dddc1ef91e6eecf37 master_kek_01 = bd27264ae07e979756411d0c66e679e3 master_kek_02 = a3d4a8e153b8e6ae6e6aef3e8f219cb4 master_kek_03 = 1558f525ae8c5be9243fb6d8a8b0a8ee master_kek_04 = 9fbeb1957fc1629e08b753a9086d6e01 master_kek_05 = 94a92da1d73c2b3e165c891ced5607fc master_kek_08 = e42f1ec8002043d746575ae6dd9f283f master_kek_09 = cec2885fbeef5f6a989db84a4cc4b393 master_kek_0a = dd1a730232522b5cb4590cd43869ab6a master_kek_0b = fc6f0c891d42710180724ed9e112e72a master_kek_0c = 43f7fc20fcec22a5b2a744790371b094 master_kek_source_06 = 374b772959b4043081f6e58c6d36179a master_kek_source_07 = 9a3ea9abfd56461c9bf6487f5cfa095c master_kek_source_08 = dedce339308816f8ae97adec642d4141 master_kek_source_09 = 1aec11822b32387a2bedba01477e3b67 master_kek_source_0a = 303f027ed838ecd7932534b530ebca7a master_kek_source_0b = 8467b67f1311aee6589b19af136c807a master_kek_source_0c = 683bca54b86f9248c305768788707923 master_key_00 = c2caaff089b9aed55694876055271c7d master_key_01 = 54e1b8e999c2fd16cd07b66109acaaa6 master_key_02 = 4f6b10d33072af2f250562bff06b6da3 master_key_03 = 84e04ec20b9373818c540829cf147f3d master_key_04 = cfa2176790a53ff74974bff2af180921 master_key_05 = c1dbedcebf0dd6956079e506cfa1af6e master_key_06 = 0aa90e6330cdc12d819b3254d11a4e1e master_key_07 = 929f86fbfe4ef7732892bf3462511b0e master_key_08 = 23cfb792c3cb50cd715da0f84880c877 master_key_09 = 75c93b716255319b8e03e14c19dea64e master_key_0a = 73767484c73088f629b0eeb605f64aa6 master_key_0b = 8500b14bf4766b855a26ffc614097a8f master_key_0c = b3c503709135d4b35de31be4b0b9c0f7 master_key_source = d8a2410ac6c59001c61d6a267c513f3c package1_key_00 = f4eca1685c1e4df77f19db7b44a985ca package1_key_01 = f8c60322f75cd548b821af9162e16f76 package1_key_02 = c580cb1e2d9aa9866ffef920010fc409 package1_key_03 = c32009c8cb268ed053052c9237dfd8bc package1_key_04 = ede36c3677495784b838d7265c6ba7a1 package1_key_05 = 1a7015dcc277a08f1214ad41384d7941 package2_key_00 = a35a19cb14404b2f4460d343d178638d package2_key_01 = a0dd1eacd438610c85a191f02c1db8a8 package2_key_02 = 7e5ba2aafd57d47a85fd4a57f2076679 package2_key_03 = bf03e9889fa18f0d7a55e8e9f684323d package2_key_04 = 09df6e361e28eb9c96c9fa0bfc897179 package2_key_05 = 444b1a4f9035178b9b1fe262462acb8e package2_key_06 = 442cd9c21cfb8914587dc12e8e7ed608 package2_key_07 = 70c821e7d6716feb124acbac09f7b863 package2_key_08 = 8accebcc3d15a328a48365503f8369b6 package2_key_09 = f562a7c6c42e3d4d3d13ffd504d77346 package2_key_0a = 0803167ec7fc0bc753d8330e5592a289 package2_key_0b = 341db6796aa7bdb8092f7aae6554900a package2_key_0c = 4e97dc4225d00c6ae33d49bddd17637d package2_key_source = fb8b6a9c7900c849efd24d854d30a0c7 per_console_key_source = 4f025f0eb66d110edc327d4186c2f478 retail_specific_aes_key_source = e2d6b87a119cb880e822888a46fba195 rsa_oaep_kek_generation_source = a8ca938434127fda82cc1aa5e807b112 rsa_private_kek_generation_source = ef2cb61a56729b9157c38b9316784ddd save_mac_kek_source = d89c236ec9124e43c82b038743f9cf1b save_mac_key = 71a917f1bac8f4f04d732e734c90e2ec save_mac_key_source = e4cd3d4ad50f742845a487e5a063ea1f save_mac_sd_card_kek_source = 0489ef5d326e1a59c4b7ab8c367aab17 save_mac_sd_card_key_source = 6f645947c56146f9ffa045d595332918 sd_card_custom_storage_key_source = 370c345e12e4cefe21b58e64db52af354f2ca5a3fc999a47c03ee004485b2fd0 sd_card_kek_source = 88358d9c629ba1a00147dbe0621b5432 sd_card_nca_key_source = 5841a284935b56278b8e1fc518e99f2b67c793f0f24fded075495dca006d99c2 sd_card_save_key_source = 2449b722726703a81965e6e3ea582fdd9a951517b16e8f7f1f68263152ea296a sd_seed = fdb479221c43741a118fb5475374d2f7 secure_boot_key = 208de9b9de94ff698d00657a6a82a973 ssl_rsa_kek = b011100660d1dccbad1b1b733afa9f95 ssl_rsa_kek_source_x = 7f5bb0847b25aa67fac84be23d7b6903 ssl_rsa_kek_source_y = 9a383bf431d0bd8132534ba964397de3 titlekek_00 = 62a24d6e6d0d0e0abf3554d259be3dc9 titlekek_01 = 8821f642176969b1a18021d2665c0111 titlekek_02 = 5d15b9b95a5739a0ac9b20f600283962 titlekek_03 = 1b3f63bcb67d4b06da5badc7d89acce1 titlekek_04 = e45c1789a69c7afbbf1a1e61f2499459 titlekek_05 = ddc67f7189f4527a37b519cb051eee21 titlekek_06 = b1532b9d38ab036068f074c0d78706ac titlekek_07 = 81dc1b1783df268789a6a0edbf058343 titlekek_08 = 47dfe4bf0eeda88b17136b8005ab08ea titlekek_09 = adaa785d90e1a9c182ac07bc276bf600 titlekek_0a = 42daa957c128f75bb1fda56a8387e17b titlekek_0b = d08903363f2c8655d3de3ccf85d79406 titlekek_0c = be2682599db34caa9bc7ebb2cc7c654c titlekek_source = 1edc7b3b60e6b4d878b81715985e629b tsec_key = 53ec4ac7c6c32ff2abff3eeff4f84f36 tsec_root_key_02 = 4b4fbcf58e23cf4902d478b76c8048ec yuzu以及Ryujinx都需要prod.keys，里面包含了NS设备需要的key，需要通过 Hekate等一些列工具生成。yuzu不需要单独安装固件，只要把key文件放好就可以启动游戏了。\n  关闭模拟器，重新打开 yuzu ，若没有弹窗，则配置成功\n  设置 General\n确保勾选 Multicore CPU Emulation 和 Confirm exit while emulation is runing。\nLimit Speed percent：游戏运行速度，默认即可，可加快或限速\nPause emulation when inbackground：退到后台模拟器暂停运行\nHide mouse inactivity：运行时鼠标隐藏\nPrompt for user for game boot：游戏启动时选择哪个账户游玩\nWeb\nyuzu web service：填了用户名和令牌以后可以向官网报告游戏兼容性\nTelemetry：开了以后能让yuzu开发者查看你的使用情况，以便改善模拟器\nDiscord Presence：在discord中显示你的游戏状态\n系统\nSystem 页面，Language 选择 Simplified Chinese，Region 选择 China。这个设置的是系统语言，很多游戏会根据系统语言自动切换游戏内显示的语言。当然前提是游戏本身包含中文，如果游戏本身无中文只能通过打补丁的方式显示中文。\nCustom RTC：修改系统时间，可以触发某些游戏的特定彩蛋之类的功能。\nRNG seed：随机数种子，一般情况别改改。\nProfile Manager：这里可以改switch用户名称、头像。可以设置多个用户\nCPU\n图形\n API设置：支持OpenGL和Vulkan。 Use disk shader cache：磁盘着色器缓存，建议开启，这样就不用每次都重新编译，而是直接从磁盘加载到内存 Use asynchronous GPU emulation：GPU异步模拟，yuzu重写了GPU显存管理器，加速了缓存机制，使得帧数得到明显提示，同时性能提升40%-400%（来自BSoD Gaming的测试数据） Use NVDEC emulation：NVDEC是一项硬件转码技术，能减少转码期间计算密集型任务中CPU的负担，这是Nvidia的一个技术，有了它，过场动画的播放会畅顺很多  Advanced\n Accuracy Level：即模拟器左下角状态栏的 GPU NORMAL。是处理图形绘制精确度，开启High可能会修复一些图形错误，但是速度可能会变慢，一般选默认Normal即可 Use Vysnc (OpenGL Only)：开启垂直同步 Use Fast GPU time： 使用GPU加速渲染 Anisotropic Filtering：是各项异性过滤，是用来处理图形纹理错误的，可以选2x-16x  声音\n默认。\n控制\n连接手柄，选择该设备。\n管理 游戏格式分为两种，.xci 格式和 .nsp 格式。简单一点说，.xci 格式是卡带版，.nsp 格式是数字版。因此基本上所有的 DLC 基本都是 .nsp 格式，但也有 .xci 里集成了 DLC 的情况。\n添加游戏\n双击模拟器中间，添加游戏目录，游戏目录也不要有中文。添加完就可以看到游戏了。\n安装Update和DLC\n选择File -\u0026gt;Install Files to NAND\u0026hellip;，选中 Update和DLC文件，Update 安装最新就行，DLC 需要全部安装（可以不按顺序）。\n安装 Mod\nMod 用于修改游戏，如解决一些bug以及优化性能等。右键单击要为其添加模组的游戏。然后将整个mod文件夹粘贴到那里。你可以从 Switch Mods 获得一些基本的 yuzu 模组。\n注意：您可以通过右键单击游戏并单击属性来检查您拥有的游戏模组。\n放入着色器缓存\n放入着色器缓存（shader cache）可以明显提升游戏的流畅性，建议找找别人的着色器缓存。\n具体放入步骤：右键某个游戏，选择打开可转移着色器缓存，即可弹出缓存所在文件夹，然后放入你下载的别人的缓存就行了，比如 vulkan.bin 和 opengl.bin\nuTools uTools 是一个极简、插件化的现代桌面软件，通过自由选配丰富的插件，打造得心应手的工具集合。\nGoldendict通过快捷键（默认 alt + space ）就可以快速呼出这个搜索框。你可以往输入框内粘贴文本、图片、截图、文件、文件夹等等，能够处理此内容的插件也早已准备就绪，统一的设计风格和操作方式，助你高效的得到结果。\n一旦你熟悉它后，能够为你节约大量时间，即用即走、不中断、无干扰，让你可以更加专注地改变世界。\nLiferea Liferea is a web feed reader/news aggregator that brings together all of the content from your favorite subscriptions into a simple interface that makes it easy to organize and browse feeds. Its GUI is similar to a desktop mail/news client, with an embedded web browser.\nCalibre calibre is a powerful and easy to use e-book manager. Users say it’s outstanding and a must-have. It’ll allow you to do nearly everything and it takes things a step beyond normal e-book software. It’s also completely free and open source and great for both casual users and computer experts.\nVentoy 简单来说，Ventoy是一个制作可启动U盘的开源工具。\n有了Ventoy你就无需反复地格式化U盘，你只需要把 ISO/WIM/IMG/VHD(x)/EFI 等类型的文件直接拷贝到U盘里面就可以启动了，无需其他操作。\nbalenaEtcher Supported Operating Systems\n Linux (most distros) macOS 10.10 (Yosemite) and later Microsoft Windows 7 and later  UNetbootin UNetbootin installs Linux/BSD distributions to a partition or USB drive\nWoeUSB-ng WoeUSB-ng is a simple tool that enable you to create your own usb stick windows installer from an iso image or a real DVD. This is a rewrite of original WoeUSB.\nGoldenDict Timeshift System restore tool for Linux.\nTodoist Plank Plank is meant to be the simplest dock on the planet.\nMotrix A full-featured download manager.\nSteam YACReader work_crawler Download comics novels\ndingtalk 钉钉桌面版，基于electron和钉钉网页版开发\nhowdy Windows Hello™ style facial authentication for Linux\n向日葵 向日葵远程控制软件是一款免费的集远程控制电脑手机、远程桌面连接、远程开机、远程管理、支持内网穿透的一体化远程控制管理工具软件。\nKeePassXC CLI Utilities Ansible 安装Ansible之后,不需要启动或运行一个后台进程,或是添加一个数据库.只要在一台电脑(可以是一台笔记本)上安装好,就可以通过这台电脑管理一组远程的机器.在远程被管理的机器上,不需要安装运行任何软件,因此升级Ansible版本不会有太多问题.\nfdupes You can call it like fdupes -r /dir/ect/ory and it will print out a list of dupes. fdupes has also a simple Homepage and a Wikipedia article, which lists some more programs.\ndigiKam 可用于查找重复相片，然后根据需要删除重复内容。\nbypy bypy info 认证特别慢，而授权码又只有10分钟，导致后面授权码过期 Heroku server 认证失败失败。\n如此，可以通过手动认证。\n  通过 bypy -dv 查看详细输出，得到 Full URL，如 https://bypyoauth.herokuapp.com/auth?code=...\u0026amp;bypy_version=1.7.2\u0026amp;redirect_uri=oob，在浏览器中打开，获得token。\n  将其放在 ~/.bypy/bypy.json 中。\n  源码仓库也有示例。\n我下载一个大文件，总共12G左右，已用了两个晚上，中途没关（由于不是立马就要的东西，就用时间换金钱了），一次看进度时，Terminal 就卡退了，重新运行后，bypy会继续上次下载，而不是重新开始（这样话太可怕了）。\nFRP frp 是一个专注于内网穿透的高性能的反向代理应用，支持 TCP、UDP、HTTP、HTTPS 等多种协议。可以将内网服务以安全、便捷的方式通过具有公网 IP 节点的中转暴露到公网。\n其他内网穿透工具\n ngrok ZeroTier N2N Dog Tunnel Tinc  Git $ vi .gitignore_default $ vi .auto-git.sh #!/bin/bash TIME=\u0026#34;$(date \u0026#39;+%Y%m%d%H%M%S\u0026#39;)\u0026#34; echo \u0026#39;###SakamotoKuromeSource###\u0026#39; /bin/bash $HOME/Documents/SakamotoKuromeSource/deploy.sh echo \u0026#39;###vNotebook###\u0026#39; cd $HOME/Documents/vNotebook git pull echo \u0026#39;#Tree DataOne\u0026#39; echo \u0026#39;#Ignore files larger than 100MB\u0026#39; cat .gitignore_default \u0026gt; .gitignore find . -size +100M | sed \u0026#39;s|^./||g\u0026#39; | cat \u0026gt;\u0026gt; .gitignore git add . git commit -m \u0026#34;Update-${TIME}\u0026#34; git push -v $ crontab -e 0 12 * * * /home/vane/.auto-git.sh  A collection of useful .gitignore templates Ignore files \u0026gt;100MB in your Git repos About large files on GitHub  GitHub Desktop Focus on what matters instead of fighting with Git. Whether you\u0026rsquo;re new to Git or a seasoned user, GitHub Desktop simplifies your development workflow.\nlibguestfs libguestfs 支持几乎所有类型的磁盘镜像。\n在基于 Debian 的系统上：\n$ apt-get install libguestfs-tools 我们可以像下面这样挂载一个 qcow2 格式的磁盘镜像：\n$ guestmount -a /path/to/qcow2/image -m \u0026lt;device\u0026gt; /path/to/mount/point 要卸载它，则执行：\n$ guestunmount qcow2_mount_poin Oracle JDK   解压缩到目录\n$ tar -zxv -f jdk-7u60-linux-x64.gz -C dir   修改环境变量\n$ vi ~/.bashrc export JAVA_HOME=/usr/lib/jvm/jdk1.7.0_60 # 这里换成自己解压的jdk 目录 export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib export PATH=${JAVA_HOME}/bin:$PATH   使环境变量生效\n$ source ~/.bashrc   Snapper Snapper 是一个由 openSUSE 的 Arvin Schnell 开发的工具，用于管理 Btrfs 子卷和 LVM 精简配置(thin-provisioned)卷。它可以创建和比较快照，在快照间回滚，并支持自动按时间序列创建快照。\n列出子卷列表\n$ sudo btrfs subvolume list -p / ID 256 gen 7746 parent 5 top level 5 path @ ID 258 gen 7746 parmount -n -o remount,rw /ent 5 top level 5 path @home 安装 snapper\n$ sudo apt install snapper snapper-gui 创建配置文件，启用自动快照\n$ sudo snapper -c root create-config / $ sudo snapper -c home create-config /home Snapshots on boot\n$ sudo systemctl status snapper-boot.timer 管理 snapshot\n$ sudo snapper-gui Fail2Ban Fail2Ban 是一款入侵防御软件，可以保护服务器免受暴力攻击。 它是用 Python 编程语言编写的。 Fail2Ban 基于auth 日志文件工作，默认情况下它会扫描所有 auth 日志文件，如 /var/log/auth.log、/var/log/apache/access.log 等，并禁止带有恶意标志的IP，比如密码失败太多，寻找漏洞等等标志。\n通常，Fail2Ban 用于更新防火墙规则，用于在指定的时间内拒绝 IP 地址。 它也会发送邮件通知。 Fail2Ban 为各种服务提供了许多过滤器，如 ssh、apache、nginx、squid、named、mysql、nagios 等。\nFail2Ban 能够降低错误认证尝试的速度，但是它不能消除弱认证带来的风险。 这只是服务器防止暴力攻击的安全手段之一。\nSyncthing Syncthing是一款开源免费跨平台的文件同步工具，是基于P2P技术实现设备间的文件同步，所以它的同步是去中心化的，即你并不需要一个服务器，故不需要担心这个中心的服务器给你带来的种种限制，而且类似于torrent协议，参与同步的设备越多，同步的速度越快。针对隐私问题，Syncthing软件只会将数据存储于个人信任的设备上，不会存储到服务器上。设备之间的通信均通过TLS进行，Syncthing还使用了完全正向保密技术来进一步保障你的数据安全。对于处于不同局域网之中的设备之间的文件同步，Syncthing也提供了支持。\nmasscan Masscan号称是最快的互联网端口扫描器，最快可以在六分钟内扫遍互联网。\nImageMagick Use ImageMagick to create, edit, compose, or convert digital images. It can read and write images in a variety of formats (over 200) including PNG, JPEG, GIF, WebP, HEIC, SVG, PDF, DPX, EXR and TIFF. ImageMagick can resize, flip, mirror, rotate, distort, shear and transform images, adjust image colors, apply various special effects, or draw text, lines, polygons, ellipses and Bézier curves.\np7zip 7-Zip is a file archiver with a high compression ratio.\np7zip 是 7-Zip 的 POSIX 系统移植，支持 Linux。\n警告： 不要将7z格式用于备份目的，因为它不会保存文件的所有者/组。有关更多详细信息，请参见7z(1)。\n添加文件或目录至已有的存档（或创建一个新的存档）：\n$ 7z a \u0026lt;archive name\u0026gt; \u0026lt;file name\u0026gt; 也可以通过参数-p设置密码，并通过标志-mhe = on隐藏存档的结构：\n$ 7z a \u0026lt;archive name\u0026gt; \u0026lt;file name\u0026gt; -p -mhe=on 更新存档内已有的文件或添加新文件：\n$ 7z u \u0026lt;archive name\u0026gt; \u0026lt;file name\u0026gt; 列出存档内容：\n$ 7z l \u0026lt;archive name\u0026gt; 从存档中解压文件至当前文件夹，不使用存档内的目录结构：\n$ 7z e \u0026lt;archive name\u0026gt; 如果需要恢复存档内的目录结构，使用：\n$ 7z x \u0026lt;archive name\u0026gt; 解压至新的目录：\n$ 7z x -o\u0026lt;folder name\u0026gt; \u0026lt;archive name\u0026gt; 校验存档完整性：\n$ 7z t \u0026lt;archive name\u0026gt; Differences between 7z, 7za and 7zr binaries The package includes three binaries, /usr/bin/7z, /usr/bin/7za, and /usr/bin/7zr. Their manual pages explain the differences:\n 7z(1) uses plugins to handle archives. 7za(1) is a stand-alone executable that handles fewer archive formats than 7z. 7zr(1) is a stand-alone executable. It is a \u0026ldquo;light-version\u0026rdquo; of 7za that only handles 7z archives. In contrast to 7za, it cannot handle encrypted archives.  分卷压缩与解压缩 rar\n# rar a -vSIZE 压缩后的文件名 被压缩的文件或者文件夹 # 最大限制为 12M $ rar a -m5 -v12m myarchive myfiles #解压 $ rar e myarchive.part1.rar tar\n要将目录logs打包压缩并分割成多个1M的文件，可以用下面的命令：\n$ tar cjf - logs/ | split -b 1m - logs.tar.bz2. 完成后会产生下列文件：\nlogs.tar.bz2.aa, logs.tar.bz2.ab, logs.tar.bz2.ac 要解压的时候只要执行下面的命令就可以了：\n$ cat logs.tar.bz2.a* | tar xj 7z\n压缩：\n$ 7z a name.7z filename -v10m 这里a是添加文件到压缩卷，name.7z是压缩后文件,然后filename可以是文件夹或文件，-v10m是限制每个包大小不超过10m.\n解压到当前目录：\n$ 7z x film.7z.001 Wudao-dict 有道词典的命令行版本，支持英汉互查和在线查询。\nascii-image-converter ttyd Share your terminal over the web\nprogress Linux tool to show progress for cp, mv, dd, \u0026hellip; (formerly known as cv)\nvosk-api Offline speech recognition API for Android, iOS, Raspberry Pi and servers with Python, Java, C# and Node\nconvert MP3 to text The software you can use is Vosk-api, a modern speech recognition toolkit based on neural networks. It supports 7+ languages and works on variety of platforms including RPi and mobile.\nFirst you convert the file to the required format and then you recognize it:\n$ ffmpeg -i file.mp3 -ar 16000 -ac 1 file.wav Then install vosk-api with pip:\n$ pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple vosk Then use these steps:\n$ git clone https://github.com/alphacep/vosk-api $ cd vosk-api/python/example $ curl -O http://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip $ unzip vosk-model-small-en-us-0.15.zip $ mv vosk-model-small-en-us-0.15 model $ python3 ./test_simple.py test.wav \u0026gt; result.json The result will be stored in json format.\nThe same directory also contains an srt subtitle output example, which is easier to evaluate and can be directly useful to some users:\n$ python3 -m pip install srt $ python3 ./test_srt.py test.wav The example given in the repository says in perfect American English accent and perfect sound quality three sentences which I transcribe as:\none zero zero zero one nine oh two one oh zero one eight zero three The \u0026ldquo;nine oh two one oh\u0026rdquo; is said very fast, but still clear. The \u0026ldquo;z\u0026rdquo; of the before last \u0026ldquo;zero\u0026rdquo; sounds a bit like an \u0026ldquo;s\u0026rdquo;.\nThe SRT generated above reads:\n1 00:00:00,870 --\u0026gt; 00:00:02,610 what zero zero zero one 2 00:00:03,930 --\u0026gt; 00:00:04,950 no no to uno 3 00:00:06,240 --\u0026gt; 00:00:08,010 cyril one eight zero three so we can see that several mistakes were made, presumably in part because we have the understanding that all words are numbers to help us.\nNext I also tried with the vosk-model-en-us-0.22.zip which was a 1.8G download compared to 40M of vosk-model-small-en-us-0.15 and is listed at https://alphacephei.com/vosk/models:\n$ mv model vosk-model-small-en-us-0.15 $ curl -O http://alphacephei.com/vosk/models/vosk-model-en-us-0.22.zip $ unzip vosk-model-en-us-0.22.zip $ mv vosk-model-en-us-0.22 model and the result was:\n1 00:00:00,840 --\u0026gt; 00:00:02,610 one zero zero zero one 2 00:00:04,026 --\u0026gt; 00:00:04,980 i know what you window 3 00:00:06,270 --\u0026gt; 00:00:07,980 serial one eight zero three which got one more word correct.\ninxi inix 是一个用于获取 Linux 系统信息的终端命令。能够获取软件和硬件的详细信息，比如计算机型号、内核版本、发行版号以及桌面环境等信息，甚至可以读取主存模块占用主板的哪块 RAM 卡槽等详细信息。\ninxi 还可以用于监控系统中正在消耗 CPU 或者内存资源的进程。\n在 Ubuntu/Debian 发行版系统中，安装命令：\nsudo apt install inxi 用 -F 参数可以获取详细的系统信息。几乎囊括了所有层次的系统信息。\ninxi -F BusyBox BusyBox 是一个开源（GPL）项目，提供了近 400 个常用命令的简单实现，包括 ls、mv、ln、mkdir、more、ps、gzip、bzip2、tar 和 grep。它还包含了编程语言 awk、流编辑器 sed、文件系统检查工具 fsck、软件包管理器rpm 和 dpkg ，当然还有一个可以方便的访问所有这些命令的 shell（sh）。简而言之，它包含了所有 POSIX 系统需要的基本命令，以执行常见的系统维护任务以及许多用户和管理任务。\n事实上，它甚至包含一个 init 命令，可以作为 PID 1 启动，以作为所有其它系统服务的父进程。换句话说，BusyBox 可以作为 systemd、OpenRC、sinit、init 和其他初始化系统的替代品。\nBusyBox 非常小。作为一个可执行文件，它不到 1MB，所以它在嵌入式、边缘计算 和物联网领域很受欢迎，因为这些场景的存储空间是很宝贵的。在容器和云计算的世界里，它作为精简的 Linux 容器镜像的基础镜像也很受欢迎。\n极简主义 BusyBox 的部分魅力在于它的极简主义。它的所有命令都被编译到一个二进制文件里（busybox），它的手册只有 81 页（根据我对 man 送到 pr 管道的计算），但它涵盖了近 400 条命令。\n作为一个例子的比较，这是 “原版” 的 useradd —help 的输出：\n-b, --base-dir BASE_DIR base directory for home -c, --comment COMMENT GECOS field of the new account -d, --home-dir HOME_DIR home directory of the new account -D, --defaults print or change the default config -e, --expiredate EXPIRE_DATE expiration date of the new account -f, --inactive INACTIVE password inactivity -g, --gid GROUP name or ID of the primary group -G, --groups GROUPS list of supplementary groups -h, --help display this help message and exit -k, --skel SKEL_DIR alternative skeleton dir -K, --key KEY=VALUE override /etc/login.defs -l, --no-log-init do not add the user to the lastlog -m, --create-home create the user's home directory -M, --no-create-home do not create the user's home directory -N, --no-user-group do not create a group with the user's name -o, --non-unique allow users with non-unique UIDs -p, --password PASSWORD encrypted password of the new account -r, --system create a system account -R, --root CHROOT_DIR directory to chroot into -s, --shell SHELL login shell of the new account -u, --uid UID user ID of the new account -U, --user-group create a group with the same name as a user 而这是是同一命令的 BusyBox 版本：\n-h DIR Home directory -g GECOS GECOS field -s SHELL Login shell -G GRP Group -S Create a system user -D Don't assign a password -H Don't create home directory -u UID User id -k SKEL Skeleton directory (/etc/skel) 这种差异是一种特性还是一种限制，取决于你是喜欢你的命令拥有 20 个选项还是 10 个选项。对于一些用户和某些用例来说，BusyBox 的极简主义刚刚满足所需。对于其他人来说，它是一个很好的最小化环境，可以作为一个后备工具，或者作为安装更强大的工具的基础，比如 Bash、Zsh、GNU Awk 等等。\nLynis  使用这个全面的开源安全审计工具检查你的 Linux 机器的安全性。\n 你有没有想过你的 Linux 机器到底安全不安全？Linux 发行版众多，每个发行版都有自己的默认设置，你在上面运行着几十个版本各异的软件包，还有众多的服务在后台运行，而我们几乎不知道或不关心这些。\n要想确定安全态势（指你的 Linux 机器上运行的软件、网络和服务的整体安全状态），你可以运行几个命令，得到一些零碎的相关信息，但你需要解析的数据量是巨大的。\n如果能运行一个工具，生成一份关于机器安全状况的报告，那就好得多了。而幸运的是，有一个这样的软件：Lynis。它是一个非常流行的开源安全审计工具，可以帮助强化基于 Linux 和 Unix 的系统。根据该项目的介绍：\n “它运行在系统本身，可以进行深入的安全扫描。主要目标是测试安全防御措施，并提供进一步强化系统的提示。它还将扫描一般系统信息、易受攻击的软件包和可能的配置问题。Lynis 常被系统管理员和审计人员用来评估其系统的安全防御。”\n 安装 Lynis 你的 Linux 软件仓库中可能有 Lynis。如果有的话，你可以用以下方法安装它：\n$ sudo apt install lynis 然而，如果你的仓库中的版本不是最新的，你最好从 GitHub 上安装它。事实上，Lynis 主要是用 shell 脚本来实现的。\n运行 Lynis 通过给 Lynis 一个 -h 选项来查看帮助部分，以便有个大概了解：\n$ sudo lynis -h 你会看到一个简短的信息屏幕，然后是 Lynis 支持的所有子命令。\n接下来，尝试一些测试命令以大致熟悉一下。要查看你正在使用的 Lynis 版本，请运行：\n$ sudo lynis show version 3.0.0 要查看 Lynis 中所有可用的命令：\n$ sudo lynis show commands Commands: lynis audit lynis configure lynis generate lynis show lynis update lynis upload-only 审计 Linux 系统 要审计你的系统的安全态势，运行以下命令：\n$ sudo lynis audit system 这个命令运行得很快，并会返回一份详细的报告，输出结果可能一开始看起来很吓人，但我将在下面引导你来阅读它。这个命令的输出也会被保存到一个日志文件中，所以你可以随时回过头来检查任何可能感兴趣的东西。\nLynis 将日志保存在这里：\nFiles: - Test and debug information : /var/log/lynis.log - Report data : /var/log/lynis-report.dat 你可以验证是否创建了日志文件。它确实创建了：\n$ ls -l /var/log/lynis.log -rw-r-----. 1 root root 341489 Apr 30 05:52 /var/log/lynis.log $ ls -l /var/log/lynis-report.dat -rw-r-----. 1 root root 638 Apr 30 05:55 /var/log/lynis-report.dat 探索报告 Lynis 提供了相当全面的报告，所以我将介绍一些重要的部分。作为初始化的一部分，Lynis 做的第一件事就是找出机器上运行的操作系统的完整信息。之后是检查是否安装了什么系统工具和插件：\n[+] Initializing program ------------------------------------ - Detecting OS... [ DONE ] - Checking profiles... [ DONE ] --------------------------------------------------- Program version: 3.0.0 Operating system: Linux Operating system name: Red Hat Enterprise Linux Server 7.8 (Maipo) Operating system version: 7.8 Kernel version: 3.10.0 Hardware platform: x86_64 Hostname: example --------------------------------------------------- \u0026lt;\u0026lt;截断\u0026gt;\u0026gt; [+] System Tools ------------------------------------ - Scanning available tools... - Checking system binaries... [+] Plugins (phase 1) ------------------------------------ Note: plugins have more extensive tests and may take several minutes to complete - Plugin: pam [..] - Plugin: systemd [................] 接下来，该报告被分为不同的部分，每个部分都以 [+] 符号开头。下面可以看到部分章节。（哇，要审核的地方有这么多，Lynis 是最合适的工具！）\n[+] Boot and services [+] Kernel [+] Memory and Processes [+] Users, Groups and Authentication [+] Shells [+] File systems [+] USB Devices [+] Storage [+] NFS [+] Name services [+] Ports and packages [+] Networking [+] Printers and Spools [+] Software: e-mail and messaging [+] Software: firewalls [+] Software: webserver [+] SSH Support [+] SNMP Support [+] Databases [+] LDAP Services [+] PHP [+] Squid Support [+] Logging and files [+] Insecure services [+] Banners and identification [+] Scheduled tasks [+] Accounting [+] Time and Synchronization [+] Cryptography [+] Virtualization [+] Containers [+] Security frameworks [+] Software: file integrity [+] Software: System tooling [+] Software: Malware [+] File Permissions [+] Home directories [+] Kernel Hardening [+] Hardening [+] Custom tests Lynis 使用颜色编码使报告更容易解读。\n 绿色。一切正常 黄色。跳过、未找到，可能有个建议 红色。你可能需要仔细看看这个  在我的案例中，大部分的红色标记都是在 “Kernel Hardening” 部分找到的。内核有各种可调整的设置，它们定义了内核的功能，其中一些可调整的设置可能有其安全场景。发行版可能因为各种原因没有默认设置这些，但是你应该检查每一项，看看你是否需要根据你的安全态势来改变它的值：\n[+] Kernel Hardening ------------------------------------ - Comparing sysctl key pairs with scan profile - fs.protected_hardlinks (exp: 1) [ OK ] - fs.protected_symlinks (exp: 1) [ OK ] - fs.suid_dumpable (exp: 0) [ OK ] - kernel.core_uses_pid (exp: 1) [ OK ] - kernel.ctrl-alt-del (exp: 0) [ OK ] - kernel.dmesg_restrict (exp: 1) [ DIFFERENT ] - kernel.kptr_restrict (exp: 2) [ DIFFERENT ] - kernel.randomize_va_space (exp: 2) [ OK ] - kernel.sysrq (exp: 0) [ DIFFERENT ] - kernel.yama.ptrace_scope (exp: 1 2 3) [ DIFFERENT ] - net.ipv4.conf.all.accept_redirects (exp: 0) [ DIFFERENT ] - net.ipv4.conf.all.accept_source_route (exp: 0) [ OK ] - net.ipv4.conf.all.bootp_relay (exp: 0) [ OK ] - net.ipv4.conf.all.forwarding (exp: 0) [ OK ] - net.ipv4.conf.all.log_martians (exp: 1) [ DIFFERENT ] - net.ipv4.conf.all.mc_forwarding (exp: 0) [ OK ] - net.ipv4.conf.all.proxy_arp (exp: 0) [ OK ] - net.ipv4.conf.all.rp_filter (exp: 1) [ OK ] - net.ipv4.conf.all.send_redirects (exp: 0) [ DIFFERENT ] - net.ipv4.conf.default.accept_redirects (exp: 0) [ DIFFERENT ] - net.ipv4.conf.default.accept_source_route (exp: 0) [ OK ] - net.ipv4.conf.default.log_martians (exp: 1) [ DIFFERENT ] - net.ipv4.icmp_echo_ignore_broadcasts (exp: 1) [ OK ] - net.ipv4.icmp_ignore_bogus_error_responses (exp: 1) [ OK ] - net.ipv4.tcp_syncookies (exp: 1) [ OK ] - net.ipv4.tcp_timestamps (exp: 0 1) [ OK ] - net.ipv6.conf.all.accept_redirects (exp: 0) [ DIFFERENT ] - net.ipv6.conf.all.accept_source_route (exp: 0) [ OK ] - net.ipv6.conf.default.accept_redirects (exp: 0) [ DIFFERENT ] - net.ipv6.conf.default.accept_source_route (exp: 0) [ OK ] 看看 SSH 这个例子，因为它是一个需要保证安全的关键领域。这里没有什么红色的东西，但是 Lynis 对我的环境给出了很多强化 SSH 服务的建议：\n[+] SSH Support ------------------------------------ - Checking running SSH daemon [ FOUND ] - Searching SSH configuration [ FOUND ] - OpenSSH option: AllowTcpForwarding [ SUGGESTION ] - OpenSSH option: ClientAliveCountMax [ SUGGESTION ] - OpenSSH option: ClientAliveInterval [ OK ] - OpenSSH option: Compression [ SUGGESTION ] - OpenSSH option: FingerprintHash [ OK ] - OpenSSH option: GatewayPorts [ OK ] - OpenSSH option: IgnoreRhosts [ OK ] - OpenSSH option: LoginGraceTime [ OK ] - OpenSSH option: LogLevel [ SUGGESTION ] - OpenSSH option: MaxAuthTries [ SUGGESTION ] - OpenSSH option: MaxSessions [ SUGGESTION ] - OpenSSH option: PermitRootLogin [ SUGGESTION ] - OpenSSH option: PermitUserEnvironment [ OK ] - OpenSSH option: PermitTunnel [ OK ] - OpenSSH option: Port [ SUGGESTION ] - OpenSSH option: PrintLastLog [ OK ] - OpenSSH option: StrictModes [ OK ] - OpenSSH option: TCPKeepAlive [ SUGGESTION ] - OpenSSH option: UseDNS [ SUGGESTION ] - OpenSSH option: X11Forwarding [ SUGGESTION ] - OpenSSH option: AllowAgentForwarding [ SUGGESTION ] - OpenSSH option: UsePrivilegeSeparation [ OK ] - OpenSSH option: AllowUsers [ NOT FOUND ] - OpenSSH option: AllowGroups [ NOT FOUND ] 我的系统上没有运行虚拟机或容器，所以这些显示的结果是空的：\n[+] Virtualization ------------------------------------ [+] Containers ------------------------------------ Lynis 会检查一些从安全角度看很重要的文件的文件权限：\n[+] File Permissions ------------------------------------ - Starting file permissions check File: /boot/grub2/grub.cfg [ SUGGESTION ] File: /etc/cron.deny [ OK ] File: /etc/crontab [ SUGGESTION ] File: /etc/group [ OK ] File: /etc/group- [ OK ] File: /etc/hosts.allow [ OK ] File: /etc/hosts.deny [ OK ] File: /etc/issue [ OK ] File: /etc/issue.net [ OK ] File: /etc/motd [ OK ] File: /etc/passwd [ OK ] File: /etc/passwd- [ OK ] File: /etc/ssh/sshd_config [ OK ] Directory: /root/.ssh [ SUGGESTION ] Directory: /etc/cron.d [ SUGGESTION ] Directory: /etc/cron.daily [ SUGGESTION ] Directory: /etc/cron.hourly [ SUGGESTION ] Directory: /etc/cron.weekly [ SUGGESTION ] Directory: /etc/cron.monthly [ SUGGESTION ] 在报告的底部，Lynis 根据报告的发现提出了建议。每项建议后面都有一个 “TEST-ID”（为了下一部分方便，请将其保存起来）。\nSuggestions (47): ---------------------------- * If not required, consider explicit disabling of core dump in /etc/security/limits.conf file [KRNL-5820] https://cisofy.com/lynis/controls/KRNL-5820/ * Check PAM configuration, add rounds if applicable and expire passwords to encrypt with new values [AUTH-9229] https://cisofy.com/lynis/controls/AUTH-9229/ Lynis 提供了一个选项来查找关于每个建议的更多信息，你可以使用 show details 命令和 TEST-ID 号来访问：\n$ sudo lynis show details TEST-ID 这将显示该测试的其他信息。例如，我检查了 SSH-7408 的详细信息：\n$ sudo lynis show details SSH-7408 2020-04-30 05:52:23 Performing test ID SSH-7408 (Check SSH specific defined options) 2020-04-30 05:52:23 Test: Checking specific defined options in /tmp/lynis.k8JwazmKc6 2020-04-30 05:52:23 Result: added additional options for OpenSSH \u0026amp;lt; 7.5 2020-04-30 05:52:23 Test: Checking AllowTcpForwarding in /tmp/lynis.k8JwazmKc6 2020-04-30 05:52:23 Result: Option AllowTcpForwarding found 2020-04-30 05:52:23 Result: Option AllowTcpForwarding value is YES 2020-04-30 05:52:23 Result: OpenSSH option AllowTcpForwarding is in a weak configuration state and should be fixed 2020-04-30 05:52:23 Suggestion: Consider hardening SSH configuration [test:SSH-7408] [details:AllowTcpForwarding (set YES to NO)] [solution:-] 试试吧 如果你想更多地了解你的 Linux 机器的安全性，请试试 Lynis。如果你想了解 Lynis 是如何工作的，可以研究一下它的 shell 脚本，看看它是如何收集这些信息的。\nHow can I protect against single user mode Potential Attacks\nSingle User Mode\nThis is the easiest way to gain unauthorised access to a Linux system is to boot the server into Single User Mode because it does not, by default, require a root password to gain root level access. Single User Mood can be accessed by power cycling the machine and interrupting the boot process. To boot into single user mode where the GRUB bootloader is used perform the following; interrupt the boot process, press e to edit the boot configuration file, append to the line starting Linux one of either s, S, 1 or systemd. unit=[rescue.target, emergency.target, rescue] to change the argument being passed to the kernel during boot to boot into Single User Mode, then press ctrl+x.\nProtecting Against Single User Mode\nFor a traditional init based system\nAs root edit the file /etc/sysconfig/init then on the line SINGLE=/sbin/sushell change sushell TO sulogin.\nFor a systemd based system\nThe target configuration need to be altered for the root password to be prompted for. The targets are located in /lib/systemd/system the files which need alteration are emergency.service and rescue.service. Alter the line starting ExecStart=-/bin/sh –c “/usr/sbin/sushell; ……” and change the /usr/sbin/sushell to/usr/sbin/sulogin in both emergency.service and rescue.service.\nTo check this has taken affect\nThen save changes and reboot to confirm the alteration has taken affect, if the alteration was success when booting into single user mode it shall ask for the root password.\nRoot Password\nBy default, some Linux distributions do not have root password sets, this can be checked by running the command head -1 /etc/shadow and if the second column, using a colon as a delimiter, is an exclamation mark then no password has been set. If no root password is set, then regardless of if the system is set to prompt for a password for Single User Mode or not it will just load root access.\nSecuring Bootloader\nInsecure bootloaders can result in the bootloader being bypassed completely and a shell being used to gain direct root level access to the system. This is done by interrupting the GRUB boot process and appending init=/bin/bas to the line beginning linux16. This will tell the kernel to use bash instead of init.\nProtecting against bootloader side loading\nThe GRUB bootloader can be password protected by placing the configuration in /etc/grub.d/40_custom file because this file will remain un touched by updates and upgrades to the boot loader. In /etc/grub.d/40_custom add set superusers=”admin” then password admin after that save and exit the file and run the following command grub2-mkpasswd-… (allow tab completion to finish this command so that the system compatible script is run) the output of this command from grub2. Onwards need to be added to the end of the line password admin in /etc/grub.d/40_custom. After that the grub file need to be recompiled by running the command grub2-mkconfig –o /boot/grub2/grub.cfg for centos or update-grub¬ on debian.\nTo check this has taken affect\nThen save changes and reboot to confirm the alteration has taken affect, if the alteration was success when booting and wanting to change the grub setting you will need to supply the username admin and the encrypted password.\nProtecting Against Recovery Attack\nThese measures can aid in protection however, if a disk is used the recover Linux feature on the disk can be used to mount the file system and alter the GRUB setting from the disk. To protect against make any removable media have a lower boot priority than the boot drive and password protect the BIOS and boot option menu to stop someone who hasn’t got access altering the boot order and booting into a disk to make changes to the system.\nCheckInstall 如果你已经从它的源码运行“make install”安装了linux程序。想完整移除它将变得真的很麻烦，除非程序的开发者在Makefile里提供了uninstall的目标设置。否则你必须在安装前后比较你系统里文件的完整列表，然后手工移除所有在安装过程中加入的文件。\n这时候Checkinstall就可以派上使用。Checkinstall会跟踪install命令行所创建或修改的所有文件的路径(例如：“make install”、“make install_modules”等)并建立一个标准的二进制包，让你能用你发行版的标准包管理系统安装或卸载它，请参考其官方文档。\n安装Checkinstall：\n# apt install checkinstall  一旦checkinstall安装好，你就可以用下列格式创建一个特定的软件包\n# checkinstall \u0026lt;install-command\u0026gt;  如果没有参数，默认安装命令“make install”将被使用。\n在这个例子里，我们将创建一个htop包，这是一个linux交互式文本模式进程查看器（类似 top）。\n首先，让我们从项目的官方网站下载源代码，作为一个好的习惯，我们存储源码包到/usr/local/src下，并解压它。\n# cd /usr/local/src # wget http://hisham.hm/htop/releases/1.0.3/htop-1.0.3.tar.gz # tar xzf htop-1.0.3.tar.gz # cd htop-1.0.3  让我们看看htop的安装命令是什么，以便我们能用Checkinstall命令调用它，如下面所示，htop用“make install”命令安装。\n# ./configure # make install  因此，要创建一个htop安装包，我们可以不带任何参数的调用checkinstall，这将使用“make install”命令创建一个包。在这个过程中， checkinstall命令会问你几个问题。\n简而言之，如下命令会创建一个htop包：\n# ./configure # checkinstall  然后checkinstall将根据你的linux系统是什么，自动地创建一个.rpm或者.deb包。\ngksudo/kdesudo Taken from here:\n You should never use normal sudo to start graphical applications as root. You should use gksudo (kdesudo on Kubuntu) to run such programs. gksudo sets HOME=/root, and copies .Xauthority to a tmp directory. This prevents files in your home directory becoming owned by root.\n Please note that this is primarily about configuration files. If you run Nautilus as root, even with gksu/gksudo, and you create a file or folder anywhere with it (including in your home directory), that file or folder will be owned by root. But if you run Nautilus (or most other graphical applications) as root with sudo, they may save their configuration files in your home directory (rather than root\u0026rsquo;s home directory). Those configuration files may be owned by root and inaccessible when you\u0026rsquo;re not running as root, which can severely mess up your settings, and may even keep some applications from working altogether.\nThe solution, once you have made this mistake, is to find the configuration files and delete them or chown them back to belonging your non-root user. Many such files start with a . or are contained in a directory that starts with a .. Some are located inside the .config folder in your home directory. To see files and folders that start with a . in Nautilus, press Ctrl+H (this shows hidden files.) To see them with ls, use the -a (or -A) flag.\nTo find if there are files not owned by you in your home directory, you can use the following command in a terminal:\nfind $HOME -not -user $USER -exec ls -lad {} \\; which will list all files under the home directory not owned by the user.\nman 手册页（man pages），即参考手册页（reference manual pages）的简称，是你进入 Linux 的钥匙。你想知道的一切都在那里，包罗万象。这套文档永远不会赢得普利策奖，但这套文档是相当准确和完整的。手册页是主要信源，其权威性是众所周知的。\n虽然它们是源头，但阅读起来并不是最令人愉快的。有一次，在很久以前的哲学课上，有人告诉我，阅读 亚里士多德 是最无聊的阅读。我不同意：说到枯燥的阅读，亚里士多德远远地排在第二位，仅次于手册页。\n乍一看，这些页面可能看起来并不完整，但是，不管你信不信，手册页并不是为了隐藏信息 —— 只是因为信息量太大，这些页面必须要有结构，而且信息是以尽可能简短的形式给出的。这些解释相当简略，需要一些时间来适应，但一旦你掌握了使用它们的技巧，你就会发现它们实际上是多么有用。\n入门 这些页面是通过一个叫做 man 的工具查看的，使用它的命令相当简单。在最简单的情况下，要使用 man，你要在命令行上输入 man，后面加一个空格和你想查询的命令，比如 ls 或 cp，像这样：\nman ls man 会打开 ls 命令的手册页。\n你可以用方向键上下移动，按 q 退出查看手册页。通常情况下，手册页是用 less 打开的，所以 less 命令的键盘快捷键在 man 中也可以使用。\n例如，你可以用 /search_term 来搜索一个特定的文本，等等。\n有一个关于手册页的介绍，这是一篇值得阅读介绍。它非常详细地说明了手册页是如何布局和组织的。\n要看这个页面，请打开一个终端，然后输入：\nman man 节 在你开始更深入地研究手册页之前，知道手册页有一个固定的页面布局和一个归档方案会有帮助。这可能会让新手感到困惑，因为我可以说：“看手册页中关于 ls 的 NAME 节（section）”，我也可以说：“看第 5 节（section）中的 passwd 的手册页。”\n这个词，“节（section）” 被用于两种不同的方式，但并不总是向新人解释其中的区别。\n我不确定为什么会出现这种混淆，但我在培训新用户和初级系统管理员时看到过几次这种混淆。我认为这可能是隧道视野，专注于一件事会使一个人忘记另一件事。一叶障目，不见泰山。\n对于那些已经知道其中的区别的人，你可以跳过这一小节。这一部分是针对那些刚接触到手册页的人。\n这就是区别：\n对于手册页\n单独的手册页是用来显示信息块的。例如，每个手册页都有一个“NAME”节，显示命令的名称和简短的描述。还会有另一个信息块，称为“SYNOPSIS”，显示该命令是如何使用的，以此类推。\n每个手册页都会有这些，以及其他的标题。这些在各个手册页上的节，或者说标题，有助于保持事情的一致性和信息的分工。\n对于手册\n使用“节”，如 “查看第 5 节中的 passwd 的手册页”，是指整个手册的内容。当我们只看一页时，很容易忽略这一点，但是 passwd 手册页是同一本手册的一部分，该手册还有 ls、rm、date、cal 等的手册页。\n整个 Linux 手册是巨大的；它有成千上万的手册页。其中一些手册页有专门的信息。有些手册页有程序员需要的信息，有些手册页有网络方面的独特信息，还有一些是系统管理员会感兴趣的。\n这些手册页根据其独特的目的被分组。想想看，把整个手册分成几个章节 —— 每章有一个特定的主题。有 9 个左右的章节（非常大的章节）。碰巧的是，这些章节被称为“节”。\n总结一下：\n 手册中单页（我们称之为“手册页”）的节是由标题定义的信息块。 这个大的手册（所有页面的集合）中的章节，刚好被称为“节”。  现在你知道区别了，希望本文的其余部分会更容易理解。\n手册页的节 你将会看到不同的手册页，所以让我们先研究一下各个页面的布局。\n手册页被分成几个标题，它们可能因提供者不同而不同，但会有相似之处。一般的分类如下：\n NAME（名称） SYNOPSIS（概要） DESCRIPTION（描述） EXAMPLES（例子） DIAGNOSTICS（诊断） FILES（文件） LIMITS（限制） PORTABILITY（可移植性） SEE ALSO（另见） HISTORY（历史） WARNING（警告）或BUGS（错误） NOTES（注意事项）  NAME - 在这个标题下是命令的名称和命令的简要描述。\nSYNOPSIS - 显示该命令的使用方法。例如，这里是 cal 命令的概要：\ncal [Month] [Year] 概要以命令的名称开始，后面是选项列表。概要采用命令行的一般形式；它显示了你可以输入的内容和参数的顺序。方括号中的参数（[]）是可选的；你可以不输入这些参数，命令仍然可以正常工作。不在括号内的项目必须使用。\n请注意，方括号只是为了便于阅读。当你输入命令时，不应该输入它们。\nDESCRIPTION - 描述该命令或工具的作用以及如何使用它。这一节通常以对概要的解释开始，并说明如果你省略任何一个可选参数会发生什么。对于长的或复杂的命令，这一节可能会被细分。\nEXAMPLES - 一些手册页提供了如何使用命令或工具的例子。如果有这一节，手册页会尝试给出一些简单的使用例子，以及更复杂的例子来说明如何完成复杂的任务。\nDIAGNOSTICS - 本节列出了由命令或工具返回的状态或错误信息。通常不显示不言自明的错误和状态信息。通常会列出可能难以理解的信息。\nFILES - 本节包含了 UNIX 用来运行这个特定命令的补充文件的列表。这里，“补充文件”是指没有在命令行中指定的文件。例如，如果你在看 passwd 命令的手册，你可能会发现 /etc/passwd 列在这一节中，因为 UNIX 是在这里存储密码信息。\nLIMITS - 本节描述了一个工具的限制。操作系统和硬件的限制通常不会被列出，因为它们不在工具的控制范围内。\nPORTABILITY - 列出其他可以使用该工具的系统，以及该工具的其他版本可能有什么不同。\nSEE ALSO - 列出包含相关信息的相关手册页。\nHISTORY - 提供命令的简要历史，如它第一次出现的时间。\nWARNING - 如果有这个部分，它包含了对用户的重要建议。\nNOTES - 不像警告那样严重，但也是重要的信息。\n同样，并不是所有的手册都使用上面列出的确切标题，但它们足够接近，可以遵循。\n手册的节 整个 Linux 手册集合的手册页传统上被划分为有编号的节：\n第 1 节：Shell 命令和应用程序\n第 2 节：基本内核服务 - 系统调用和错误代码\n第 3 节：为程序员提供的库信息\n第 4 节：网络服务 - 如果安装了 TCP/IP 或 NFS 设备驱动和网络协议\n第 5 节：文件格式 - 例如：显示 tar 存档的样子\n第 6 节：游戏\n第 7 节：杂项文件和文档\n第 8 节：系统管理和维护命令\n第 9 节：不知名的内核规格和接口\n将手册页分成这些组，可以使搜索更有效率。在我工作的地方，我有时会做一些编程工作，所以我花了一点时间看第 3 节的手册页。我也做一些网络方面的工作，所以我也知道要涉足网络部分。作为几个实验性机器的系统管理员，我在第 8 节花了很多时间。\n将手册网归入特定的节（章节），使搜索信息更加容易 —— 无论是对需要搜索的人，还是对进行搜索的机器。\n你可以通过名称旁边的数字来判断哪个手册页属于哪个部分。例如，如果你正在看 ls 的手册页，而页面的最上面写着。 LS(1)，那么你正在浏览第 1 节中的 ls 页面，该节包含关于 shell 命令和应用程序的页面。\n下面是另一个例子。如果你在看 passwd 的手册页，页面的顶部显示: PASSWD(1)，说明你正在阅读第 1 节中描述 passwd 命令如何更改用户账户密码的手册页。如果你看到 PASSWD(5)，那么你正在阅读关于密码文件和它是如何组成的的手册页。\npasswd 恰好是两个不同的东西：一个是命令的名称，一个是文件的名称。同样，第 1 节描述了命令，而第 5 节涉及文件格式。\n括号中的数字是重要的线索 —— 这个数字告诉你正在阅读的页面来自哪一节。\n搜索一个特定的节 基本命令：\nman -a name 将在每一节中搜索由 name 标识的手册页，按数字顺序逐一显示。要把搜索限制在一个特定的部分，请在 man 命令中使用一个参数，像这样：\nman 1 name 这个命令将只在手册页的第 1 节中搜索 name。使用我们前面的 passwd 例子，这意味着我们可以保持搜索的针对性。如果我想阅读 passwd 命令的手册页，我可以在终端输入以下内容：\nman 1 passwd man 工具将只在第 1 节中搜索 passwd 并显示它。它不会在任何其他节中寻找 passwd。\n这个命令的另一种方法是输入: man passwd.1。\n搜索包含某个关键词的所有手册页 如果你想获得包含某个关键词的手册页的列表，man 命令中的 -k 选项（通常称为标志或开关）可以派上用场。例如，如果你想看一个关于 ftp 的手册列表，你可以通过输入以下内容得到这个列表：\nman -k ftp 在接下来的列表中，你可以选择一个特定的手册页来阅读。\n在某些系统上，在 man -k 工作之前，系统管理员需要运行一个叫做 catman 的工具。\n了解手册的各个节 有两个有趣的工具可以帮助你搜索信息：whatis和 whereis。\nwhatis\n有的时候，我们完全可以得到我们需要的信息。我们需要的信息有很大的机会是可以找到的 —— 找到它可能是一个小问题。\n例如，如果我想看关于 passwd 文件的手册页，我在终端上输入：\nman passwd 我就会看到关于 passwd 命令所有信息的手册页，但没有关于 passwd 文件的内容。我知道 passwd 是一个命令，也有一个 passwd 文件，但有时，我可能会忘记这一点。这时我才意识到，文件结构在手册页中的不同节，所以我输入了：\nman 4 passwd 我得到这样的答复：\nNo manual entry for passwd in section 4 See 'man 7 undocumented' for help when manual pages are not available. 又是一次健忘的失误。文件结构在 System V UNIX 页面的第 4 节中。几年前，当我建立文件时，我经常使用 man 4 ...；这仍然是我的一个习惯。那么它在 Linux 手册中的什么地方呢？\n现在是时候调用 whatis 来纠正我了。为了做到这一点，我在我的终端中输入以下内容：\nwhatis passwd 然后我看到以下内容：\npasswd (1) - change user password passwd (1ssl) - compute password hashes passwd (5) - the password file 啊！passwd 文件的页面在第 5 节。现在没问题了，可以访问我想要的信息了：\nman 5 passwd 然后我被带到了有我需要的信息的手册页。\nwhatis 是一个方便的工具，可以用简短的一句话告诉你一个命令的作用。想象一下，你想知道 cal 是做什么的，而不想查看手册页。只要在命令提示符下键入以下内容。\nwhatis cal 你会看到这样的回应：\ncal (1) - displays a calendar and the date of Easter 现在你知道了 whatis 命令，我可以告诉你一个秘密 —— 有一个 man 命令的等价物。为了得到这个，我们使用 -f 开关：man -f ...。\n试试吧。在终端提示下输入 whatis cal。执行后就输入：man -f cal。两个命令的输出将是相同的。\nwhereis\nwhereis 命令的名字就说明了这一点 —— 它告诉你一个程序在文件系统中的位置。它也会告诉你手册页的存放位置。再以 cal 为例，我在提示符下输入以下内容：\nwhereis cal 我将看到这个：\ncal: /usr/bin/cal /usr/share/man/man1/cal.1.gz 仔细看一下这个回答。答案只在一行里，但它告诉我两件事：\n /usr/bin/cal 是 cal 程序所在的地方，以及 /usr/share/man/man1/cal.1.gz 是手册页所在的地方（我也知道手册页是被压缩的，但不用担心 —— man 命令知道如何即时解压）。  whereis 依赖于 PATH 环境变量；它只能告诉你文件在哪里，如果它们在你的 PATH 环境变量中。\n你可能想知道是否有一个与 whereis 相当的 man 命令。没有一个命令可以告诉你可执行文件的位置，但有一个开关可以告诉你手册页的位置。在这个例子中使用 date 命令，如果我们输入：\nwhereis date 在终端提示符下，我们会看到：\ndate: /usr/bin/date /usr/share/man/man1/date.1.gz 我们看到 date 程序在 /usr/bin/ 目录下，其手册页的名称和位置是：/usr/share/man/man1/date.1.gz。\n我们可以让 man 像 whereis 一样行事，最接近的方法是使用 -w 开关。我们不会得到程序的位置，但我们至少可以得到手册页的位置，像这样：\nman -w date 我们将看到这样的返回：\n/usr/share/man/man1/date.1.gz 你知道了 whatis 和 whereis，以及让 man 命令做同样（或接近）事情的方法。我展示了这两种方法，有几个不同的原因。\n多年来，我使用 whatis 和 whereis，因为它们在我的培训手册中。直到最近我才了解到 man -f ... 和 man -w ...。我确信我看了几百次 man 的手册页，但我从未注意到 -f 和 -w 开关。我总是在看手册页的其他东西（例如：man -k ...）。我只专注于我需要找到的东西，而忽略了其他的东西。一旦我找到了我需要的信息，我就会离开这个页面，去完成工作，而不去注意这个命令所提供的其他一些宝贝。\n这没关系，因为这部分就是手册页的作用：帮助你完成工作。\n直到最近我向别人展示如何使用手册页时，我才花时间去阅读 —— “看看还有什么可能” —— 我们才真正注意到关于 man 命令的 -f 和 -w 标记可以做什么的信息。\n不管你使用 Linux 多久了，或者多么有经验，总有一些新东西需要学习。\n手册页会告诉你在完成某项任务时可能需要知道的东西 —— 但它们也有很多内容 —— 足以让你看起来像个魔术师，但前提是你要花时间去读。\n结论 如果你花一些时间和精力在手册页上，你将会取得胜利。你对手册页的熟练程度，将在你掌握 Linux 的过程中发挥巨大作用。\ntldr Collaborative cheatsheets for console commands\n“TLDR” 是流行的互联网行话，意思是“太长不读（to long didn\u0026rsquo;t read）”。这就是他们创建 tldr 的想法。如果你觉得手册页太长而不想阅读，tldr 通过提供命令的实际例子而将其简化了。\nls ls 命令可以列出一个 POSIX 系统上的文件。这是一个简单的命令，但它经常被低估，不是它能做什么（因为它确实只做了一件事），而是你该如何优化对它的使用。\nGNU 还是 BSD？ 在了解 ls 的隐藏能力之前，你必须确定你正在运行哪个 ls 命令。有两个最流行的版本：包含在 GNU coreutils 包中的 GNU 版本，以及 BSD 版本。如果你正在运行 Linux，那么你很可能已经安装了 GNU 版本的 ls。如果你正在运行 BSD 或 MacOS，那么你有的是 BSD 版本。本文会介绍它们的不同之处。\n你可以使用 --version 选项找出你计算机上的版本：\n$ ls --version 如果它返回有关 GNU coreutils 的信息，那么你拥有的是 GNU 版本。如果它返回一个错误，你可能正在运行的是 BSD 版本（运行 man ls | head 以确定）。\n你还应该调查你的发行版可能具有哪些预设选项。终端命令的自定义通常放在 $HOME/.bashrc 或 $HOME/.bash_aliases 或 $HOME/.profile 中，它们是通过将 ls 别名化为更复杂的 ls 命令来完成的。例如：\nalias ls=\u0026#39;ls --color\u0026#39; 发行版提供的预设非常有用，但它们确实很难分辨出哪些是 ls 本身的特性，哪些是它的附加选项提供的。你要是想要运行 ls 命令本身而不是它的别名，你可以用反斜杠“转义”命令：\n$ \\ls 分类 单独运行 ls 会以适合你终端的列数列出文件：\n$ ls ~/example bunko jdk-10.0.2 chapterize otf2ttf.ff despacer overtar.sh estimate.sh pandoc-2.7.1 fop-2.3 safe_yaml games tt 这是有用的信息，但所有这些文件看起来基本相同，没有方便的图标来快速表示出哪个是目录、文本文件或图像等等。\n使用 -F（或 GNU 上的长选项 --classify）以在每个条目之后显示标识文件类型的指示符：\n$ ls ~/example bunko jdk-10.0.2/ chapterize* otf2ttf.ff* despacer* overtar.sh* estimate.sh pandoc@ fop-2.3/ pandoc-2.7.1/ games/ tt* 使用此选项，终端中列出的项目使用简写符号来按文件类型分类：\n 斜杠（/）表示目录（或“文件夹”）。 星号（*）表示可执行文件。这包括二进制文件（编译代码）以及脚本（具有可执行权限的文本文件）。 符号（@）表示符号链接（或“别名”）。 等号（=）表示套接字。 在 BSD 上，百分号（%）表示涂改whiteout（某些文件系统上的文件删除方法）。 在 GNU 上，尖括号（\u0026gt;）表示门door（Illumos 和 Solaris上的进程间通信）。 竖线（|）表示 FIFO 管道。 这个选项的一个更简单的版本是 -p，它只区分文件和目录。  （LCTT 译注：在支持彩色的终端上，使用 --color 选项可以以不同的颜色来区分文件类型，但要注意如果将输出导入到管道中，则颜色消失。）\n长列表 从 ls 获取“长列表”的做法是如此常见，以至于许多发行版将 ll 别名为 ls -l。长列表提供了许多重要的文件属性，例如权限、拥有每个文件的用户、文件所属的组、文件大小（以字节为单位）以及文件上次更改的日期：\n$ ls -l -rwxrwx---. 1 seth users 455 Mar 2 2017 estimate.sh -rwxrwxr-x. 1 seth users 662 Apr 29 22:27 factorial -rwxrwx---. 1 seth users 20697793 Jun 29 2018 fop-2.3-bin.tar.gz -rwxrwxr-x. 1 seth users 6210 May 22 10:22 geteltorito -rwxrwx---. 1 seth users 177 Nov 12 2018 html4mutt.sh [...] 如果你不想以字节为单位，请添加 -h 标志（或 GNU 中的 --human）以将文件大小转换为更加人性化的表示方法：\n$ ls --human -rwxrwx---. 1 seth users 455 Mar 2 2017 estimate.sh -rwxrwxr-x. 1 seth seth 662 Apr 29 22:27 factorial -rwxrwx---. 1 seth users 20M Jun 29 2018 fop-2.3-bin.tar.gz -rwxrwxr-x. 1 seth seth 6.1K May 22 10:22 geteltorito -rwxrwx---. 1 seth users 177 Nov 12 2018 html4mutt.sh 要看到更少的信息，你可以带有 -o 选项只显示所有者的列，或带有 -g 选项只显示所属组的列：\n$ ls -o -rwxrwx---. 1 seth 455 Mar 2 2017 estimate.sh -rwxrwxr-x. 1 seth 662 Apr 29 22:27 factorial -rwxrwx---. 1 seth 20M Jun 29 2018 fop-2.3-bin.tar.gz -rwxrwxr-x. 1 seth 6.1K May 22 10:22 geteltorito -rwxrwx---. 1 seth 177 Nov 12 2018 html4mutt.sh 也可以将两个选项组合使用以显示两者。\n时间和日期格式 ls 的长列表格式通常如下所示：\n-rwxrwx---. 1 seth users 455 Mar 2 2017 estimate.sh -rwxrwxr-x. 1 seth users 662 Apr 29 22:27 factorial -rwxrwx---. 1 seth users 20697793 Jun 29 2018 fop-2.3-bin.tar.gz -rwxrwxr-x. 1 seth users 6210 May 22 10:22 geteltorito -rwxrwx---. 1 seth users 177 Nov 12 2018 html4mutt.sh 月份的名字不便于排序，无论是通过计算还是识别（取决于你的大脑是否倾向于喜欢字符串或整数）。你可以使用 --time-style 选项和格式名称更改时间戳的格式。可用格式为：\n full-iso：ISO 完整格式（1970-01-01 21:12:00） long-iso：ISO 长格式（1970-01-01 21:12） iso：iso 格式（01-01 21:12） locale：本地化格式（使用你的区域设置） posix-STYLE：POSIX 风格（用区域设置定义替换 STYLE）  你还可以使用 date 命令的正式表示法创建自定义样式。\n按时间排序 通常，ls 命令按字母顺序排序。你可以使用 -t 选项根据文件的最近更改的时间（最新的文件最先列出）进行排序。\n例如：\n$ touch foo bar baz $ ls bar baz foo $ touch foo $ ls -t foo bar baz 列出方式 ls 的标准输出平衡了可读性和空间效率，但有时你需要按照特定方式排列的文件列表。\n要以逗号分隔文件列表，请使用 -m：\nls -m ~/example bar, baz, foo 要强制每行一个文件，请使用 -1 选项（这是数字 1，而不是小写的 L）：\n$ ls -1 ~/bin/ bar baz foo 要按文件扩展名而不是文件名对条目进行排序，请使用 -X（这是大写 X）：\n$ ls bar.xfc baz.txt foo.asc $ ls -X foo.asc baz.txt bar.xfc 隐藏杂项 在某些 ls 列表中有一些你可能不关心的条目。例如，元字符 . 和 .. 分别代表“本目录”和“父目录”。如果你熟悉在终端中如何切换目录，你可能已经知道每个目录都将自己称为 .，并将其父目录称为 ..，因此当你使用 -a 选项显示隐藏文件时并不需要它经常提醒你。\n要显示几乎所有隐藏文件（. 和 .. 除外），请使用 -A 选项：\n$ ls -a . .. .android .atom .bash_aliases [...] $ ls -A .android .atom .bash_aliases [...] 有许多优秀的 Unix 工具有保存备份文件的传统，它们会在保存文件的名称后附加一些特殊字符作为备份文件。例如，在 Vim 中，备份会以在文件名后附加 ~ 字符的文件名保存。\n这些类型的备份文件已经多次使我免于愚蠢的错误，但是经过多年享受它们提供的安全感后，我觉得不需要用视觉证据来证明它们存在。我相信 Linux 应用程序可以生成备份文件（如果它们声称这样做的话），我很乐意相信它们存在 —— 而不用必须看到它们。\n要隐藏备份文件，请使用 -B 或 --ignore-backups 隐藏常用备份格式（此选项在 BSD 的 ls 中不可用）：\n$ ls bar.xfc baz.txt foo.asc~ foo.asc $ ls -B bar.xfc baz.txt foo.asc 当然，备份文件仍然存在；它只是过滤掉了，你不必看到它。\n除非另有配置，GNU Emacs 在文件名的开头和结尾添加哈希字符（＃）来保存备份文件（#file＃）。其他应用程序可能使用不同的样式。使用什么模式并不重要，因为你可以使用 --hide 选项创建自己的排除项：\n$ ls bar.xfc baz.txt #foo.asc# foo.asc $ ls --hide=\u0026#34;#*#\u0026#34; bar.xfc baz.txt foo.asc 递归地列出目录 除非你在指定目录上运行 ls，否则子目录的内容不会与 ls 命令一起列出：\n$ ls -F example/ quux* xyz.txt $ ls -R quux xyz.txt ./example: bar.xfc baz.txt #foo.asc# foo.asc 使用别名使其永久化 ls 命令可能是 shell 会话期间最常使用的命令。这是你的眼睛和耳朵，为你提供上下文信息和确认命令的结果。虽然有很多选项很有用，但 ls 之美的一部分就是简洁：两个字符和回车键，你就知道你到底在哪里以及附近有什么。如果你不得不停下思考（更不用说输入）几个不同的选项，它会变得不那么方便，所以通常情况下，即使最有用的选项也不会用了。\n解决方案是为你的 ls 命令添加别名，以便在使用它时，你可以获得最关心的信息。\n要在 Bash shell 中为命令创建别名，请在主目录中创建名为 .bash_aliases 的文件（必须在开头包含 .）。 在此文件中，列出要创建的别名，然后是要为其创建别名的命令。例如：\nalias ls=\u0026#39;ls -A -F -B --human --color\u0026#39; 这一行导致你的 Bash shell 将 ls 命令解释为 ls -A -F -B --human --color。\n你不必仅限于重新定义现有命令，还可以创建自己的别名：\nalias ll=\u0026#39;ls -l\u0026#39; alias la=\u0026#39;ls -A\u0026#39; alias lh=\u0026#39;ls -h\u0026#39; 要使别名起作用，shell 必须知道 .bash_aliases 配置文件存在。在编辑器中打开 .bashrc 文件（如果它不存在则创建它），并包含以下代码块：\nif [ -e $HOME/.bash_aliases ]; then source $HOME/.bash_aliases fi 每次加载 .bashrc（这是一个新的 Bash shell 启动的时候），Bash 会将 .bash_aliases 加载到你的环境中。你可以关闭并重新启动 Bash 会话，或者直接强制它执行此操作：\n$ source ~/.bashrc 如果你忘了你是否有别名命令，which 命令可以告诉你：\n$ which ls alias ls=\u0026#39;ls -A -F -B --human --color\u0026#39; /usr/bin/ls 如果你将 ls 命令别名为带有选项的 ls 命令，则可以通过将反斜杠前缀到 ls 前来覆盖你的别名。例如，在示例别名中，使用 -B 选项隐藏备份文件，这意味着无法使用 ls 命令显示备份文件。 可以覆盖该别名以查看备份文件：\n$ ls bar baz foo $ \\ls bar baz baz~ foo 做一件事，把它做好 ls 命令有很多选项，其中许多是特定用途的或高度依赖于你所使用的终端。在 GNU 系统上查看 info ls，或在 GNU 或 BSD 系统上查看 man ls 以了解更多选项。\n你可能会觉得奇怪的是，一个以每个工具“做一件事，把它做好”的前提而闻名的系统会让其最常见的命令背负 50 个选项。但是 ls 只做一件事：它列出文件，而这 50 个选项允许你控制接收列表的方式，ls 的这项工作做得非常、非常好。\nexa A modern replacement for ‘ls’.\ndu (Disk Usage) 在 Linux 中使用 ls 命令 列出的目录内容中，目录的大小仅显示 4KB。这是一个默认的大小，是用来存储磁盘上存储目录的元数据的大小。\ndu 命令 表示 磁盘使用率。这是一个标准的 Unix 程序，用于估计当前工作目录中的文件空间使用情况。\n它使用递归方式总结磁盘使用情况，以获取目录及其子目录的大小。\n$ du -hs --max-depth=0 /path/dir  du – 这是一个命令 -h – 以易读的格式显示大小 (例如 1K 234M 2G) -s – 仅显示每个参数的总数 --max-depth=N – 目录的打印深度  NCurses Disk Usage Ncdu is a disk usage analyzer with an ncurses interface.\nncdu 命令旨在提供一份关于你在硬盘上使用的空间的交互式报告。\ngdu Fast disk usage analyzer with console interface written in Go\nDiff diff是Unix系统的一个很重要的工具程序。\n它用来比较两个文本文件的差异，是代码版本管理的基石之一。你在命令行下，输入：\n$ diff \u0026lt;变动前的文件\u0026gt; \u0026lt;变动后的文件\u0026gt; diff就会告诉你，这两个文件有何差异。它的显示结果不太好懂，下面我就来说明，如何读懂diff。\n三种格式 由于历史原因，diff有三种格式：\n 正常格式（normal diff） 上下文格式（context diff） 合并格式（unified diff）  我们依次来看。\n示例文件 为了便于讲解，先新建两个示例文件。\n第一个文件叫做f1，内容是每行一个a，一共7行。\na a a a a a a 第二个文件叫做f2，修改f1而成，第4行变成b，其他不变。\na a a b a a a 正常格式 现在对f1和f2进行比较：\n$ diff f1 f2 这时，diff就会显示正常格式的结果：\n4c4 \u0026lt; a --- \u0026gt; b 第一行是一个提示，用来说明变动位置。\n4c4 它分成三个部分：前面的\u0026quot;4\u0026quot;，表示f1的第4行有变化；中间的\u0026quot;c\u0026quot;表示变动的模式是内容改变（change），其他模式还有\u0026quot;增加\u0026quot;（a，代表addition）和\u0026quot;删除\u0026quot;（d，代表deletion）；后面的\u0026quot;4\u0026quot;，表示变动后变成f2的第4行。\n第二行分成两个部分。\n\u0026lt; a 前面的小于号，表示要从f1当中去除该行（也就是第4行），后面的\u0026quot;a\u0026quot;表示该行的内容。\n第三行用来分割f1和f2。\n--- 第四行，类似于第二行。\n\u0026gt; b 前面的大于号表示f2增加了该行，后面的\u0026quot;b\u0026quot;表示该行的内容。\n最早的Unix（即AT\u0026amp;T版本的Unix），使用的就是这种格式的diff。\n上下文格式 上个世纪80年代初，加州大学伯克利分校推出BSD版本的Unix时，觉得diff的显示结果太简单，最好加入上下文，便于了解发生的变动。因此，推出了上下文格式的diff。\n它的使用方法是加入c参数（代表context）。\n$ diff -c f1 f2 显示结果如下：\n*** f1 2012-08-29 16:45:41.000000000 +0800 --- f2 2012-08-29 16:45:51.000000000 +0800 *************** *** 1,7 **** a a a !a a a a --- 1,7 ---- a a a !b a a a 这个结果分成四个部分。\n第一部分的两行，显示两个文件的基本情况：文件名和时间信息。\n*** f1 2012-08-29 16:45:41.000000000 +0800 --- f2 2012-08-29 16:45:51.000000000 +0800 ***表示变动前的文件，---表示变动后的文件。\n第二部分是15个星号，将文件的基本情况与变动内容分割开。\n*************** 第三部分显示变动前的文件，即f1。\n*** 1,7 **** a a a !a a a a 这时不仅显示发生变化的第4行，还显示第4行的前面三行和后面三行，因此一共显示7行。所以，前面的*** 1,7 ****就表示，从第1行开始连续7行。\n另外，文件内容的每一行最前面，还有一个标记位。如果为空，表示该行无变化；如果是感叹号（!），表示该行有改动；如果是减号（-），表示该行被删除；如果是加号（+），表示该行为新增。\n第四部分显示变动后的文件，即f2。\n--- 1,7 ---- a a a !b a a a 除了变动行（第4行）以外，也是上下文各显示三行，总共显示7行。\n合并格式 如果两个文件相似度很高，那么上下文格式的diff，将显示大量重复的内容，很浪费空间。1990年，GNU diff率先推出了\u0026quot;合并格式\u0026quot;的diff，将f1和f2的上下文合并在一起显示。\n它的使用方法是加入u参数（代表unified）。\n$ diff -u f1 f2 显示结果如下：\n--- f1 2012-08-29 16:45:41.000000000 +0800 +++ f2 2012-08-29 16:45:51.000000000 +0800 @@ -1,7 +1,7 @@ a a a -a +b a a a 它的第一部分，也是文件的基本信息。\n--- f1 2012-08-29 16:45:41.000000000 +0800 +++ f2 2012-08-29 16:45:51.000000000 +0800 ---表示变动前的文件，+++表示变动后的文件。\n第二部分，变动的位置用两个@作为起首和结束。\n@@ -1,7 +1,7 @@ 前面的\u0026quot;-1,7\u0026quot;分成三个部分：减号表示第一个文件（即f1），\u0026ldquo;1\u0026quot;表示第1行，\u0026ldquo;7\u0026quot;表示连续7行。合在一起，就表示下面是第一个文件从第1行开始的连续7行。同样的，\u0026quot;+1,7\u0026quot;表示变动后，成为第二个文件从第1行开始的连续7行。\n第三部分是变动的具体内容。\na a a -a +b a a a 除了有变动的那些行以外，也是上下文各显示3行。它将两个文件的上下文，合并显示在一起，所以叫做\u0026quot;合并格式\u0026rdquo;。每一行最前面的标志位，空表示无变动，减号表示第一个文件删除的行，加号表示第二个文件新增的行。\ngit格式 版本管理系统git，使用的是合并格式diff的变体。\n$ git diff 显示结果如下：\ndiff --git a/f1 b/f1 index 6f8a38c..449b072 100644 --- a/f1 +++ b/f1 @@ -1,7 +1,7 @@ a a a -a +b a a a 第一行表示结果为git格式的diff。\ndiff --git a/f1 b/f1 进行比较的是，a版本的f1（即变动前）和b版本的f1（即变动后）。\n第二行表示两个版本的git哈希值（index区域的6f8a38c对象，与工作目录区域的449b072对象进行比较），最后的六位数字是对象的模式（普通文件，644权限）。　index 6f8a38c..449b072 100644 第三行表示进行比较的两个文件。\n--- a/f1 +++ b/f1 ---表示变动前的版本，+++表示变动后的版本。\n后面的行都与官方的合并格式diff相同。\n@@ -1,7 +1,7 @@ a a a -a +b a a a Crontab 使用 crontab 命令来执行定时任务。所谓定时任务，就是未来的某个或多个时点，预定要执行的任务，比如每五分钟收一次邮件、每天半夜两点分析一下日志等等。\nInstalling $ sudo apt install cronie Running $ systemctl enable crond.service $ systemctl start crond.service 命令详解 crontab 命令通过 /etc/cron.allow 和 /etc/cron.deny 文件来限制某些用户是否可以使用 crontab 命令：\n 当系统中有 /etc/cron.allow 文件时，只有写入此文件的用户可以使用 crontab 命令，没有写入的用户不能使用 crontab 命令。 当系统中只有 /etc/cron.deny 文件时，写入此文件的用户不能使用 crontab 命令，没有写入文件的用户可以使用 crontab 命令。 /etc/cron.allow 文件比 /etc/cron.deny 文件的优先级高，Linux 系统中默认只有 /etc/cron.deny 文件。  crontab 命令的基本格式如下：\ncrontab [选项] [file] 注意，这里的 file 指的是命令文件的名字，表示将 file 作为 crontab 的任务列表文件并载入 crontab，若在命令行中未指定文件名，则此命令将接受标准输入（键盘）上键入的命令，并将它们键入 crontab。\n常用选项    选项 功能     -u user 用来设定某个用户的 crontab 服务，例如 \u0026ldquo;-u demo\u0026rdquo; 表示设备 demo 用户的 crontab 服务，此选项一般有 root 用户来运行。   -e 编辑某个用户的 crontab 文件内容。如果不指定用户，则表示编辑当前用户的 crontab 文件。   -l 显示某用户的 crontab 文件内容，如果不指定用户，则表示显示当前用户的 crontab 文件内容。   -r 从 /var/spool/cron 删除某用户的 crontab 文件，如果不指定用户，则默认删除当前用户的 crontab 文件。   -i 在删除用户的 crontab 文件时，给确认提示。    crontab 文件格式 * * * * * 执行的任务 执行的任务字段既可以定时执行系统命令，也可以定时执行某个 Shell 脚本。\n执行时间\n   项目 含义 范围     第一个\u0026rdquo;*\u0026quot; 一小时当中的第几分钟（minute） 0~59   第二个\u0026quot;*\u0026quot; 一天当中的第几小时（hour） 0~23   第三个\u0026quot;*\u0026quot; 一个月当中的第几天（day） 1~31   第四个\u0026quot;*\u0026quot; 一年当中的第几个月（month） 1~12   第五个\u0026quot;*\u0026quot; 一周当中的星期几（week） 0~7（0和7都代表星期日）    时间特殊符号\n   特殊符号 含义     *（星号） 代表任何时间。比如第一个\u0026quot;*\u0026ldquo;就代表一小时种每分钟都执行一次的意思。   ,（逗号） 代表不连续的时间。比如\u0026quot;0 8，12，16***命令\u0026quot;就代表在每天的 8 点 0 分、12 点 0 分、16 点 0 分都执行一次命令。   -（中杠） 代表连续的时间范围。比如\u0026quot;0 5 ** 1-6命令\u0026rdquo;，代表在周一到周六的凌晨 5 点 0 分执行命令。   /（正斜线） 代表每隔多久执行一次。比如\u0026quot;*/10****命令\u0026quot;，代表每隔 10 分钟就执行一次命令。    当“crontab -e”编辑完成之后，一旦保存退出，那么这个定时任务实际就会写入 /var/spool/cron/ 目录中，每个用户的定时任务用自己的用户名进行区分。而且 crontab 命令只要保存就会生效，只要 crond 服务是启动的。\ncrontab举例\n   时间 含义     45 22 ***命令 在每天 22 点 45 分执行命令   0 17 ** 1命令 在每周一的 17 点 0 分执行命令   0 5 1，15**命令 在每月 1 日和 15 日的凌晨 5 点 0 分执行命令   40 4 ** 1-5命令 在每周一到周五的凌晨 4 点 40 分执行命令   */10 4 ***命令 在每天的凌晨 4 点，每隔 10 分钟执行一次命令   0 0 1，15 * 1命令 在每月 1 日和 15 日，每周一 0 点 0 分都会执行命令    注意事项\n 6 个选项都不能为空，必须填写。如果不确定，则使用“*”代表任意时间。 crontab 定时任务的最小有效时间是分钟，最大有效时间是月。像 2018 年某时执行、3 点 30 分 30 秒这样的时间都不能被识别。 在定义时间时，日期和星期最好不要在一条定时任务中出现，因为它们都以天为单位，非常容易让管理员混淆。 在定时任务中，不管是直接写命令，还是在脚本中写命令，最好都使用绝对路径。有时使用相对路径的命令会报错。  run a script on startup Put the script in the appropriate user\u0026rsquo;s cron table (i. e. the crontab) with a schedule of @reboot.\nA user can edit its cron table with crontab -e.\nAn example which will run /path/to/script.sh at startup:\n@reboot /path/to/script.sh If you need to run it as root, don\u0026rsquo;t use @reboot sudo /path/to/script.sh; use sudo crontab -eu root to edit root\u0026rsquo;s crontab.\nps 简介 要对进程进行监测和控制，首先必须要了解当前进程的情况，也就是需要查看当前进程，而 ps 命令（Process Status）就是最基本同时也是非常强大的进程查看命令。使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等等。总之大部分信息都是可以通过执行该命令得到的。ps命令列出的是当前那些进程的快照，就是执行ps命令的那个时刻的那些进程，如果想要动态的显示进程信息，就可以使用top命令。\nlinux上进程有5种状态：\n  就绪状态和运行状态\n就绪状态的状态标志state的值为TASK_RUNNING。此时，程序已被挂入运行队列，处于准备运行状态。一旦获得处理器使用权，即可进入运行状态。\n当进程获得处理器而运行时 ，state的值仍然为TASK_RUNNING，并不发生改变；但Linux会把一个专门用来指向当前运行任务的指针current指向它，以表示它是一个正在运行的进程。\n  可中断等待状态\n状态标志state的值为TASK_INTERRUPTIBL。此时，由于进程未获得它所申请的资源而处在等待状态。一旦资源有效或者有唤醒信号，进程会立即结束等待而进入就绪状态。\n  不可中断等待状态\n状态标志state的值为TASK_UNINTERRUPTIBL。此时，进程也处于等待资源状态。一旦资源有效，进程会立即进入就绪状态。这个等待状态与可中断等待状态的区别在于：处于TASK_UNINTERRUPTIBL状态的进程不能被信号量或者中断所唤醒，只有当它申请的资源有效时才能被唤醒。\n这个状态被应用在内核中某些场景中，比如当进程需要对磁盘进行读写，而此刻正在DMA中进行着数据到内存的拷贝，如果这时进程休眠被打断（比如强制退出信号）那么很可能会出现问题，所以这时进程就会处于不可被打断的状态下。\n  停止状态\n状态标志state的值为TASK_STOPPED。当进程收到一个SIGSTOP信号后，就由运行状态进入停止状态，当受到一个SIGCONT信号时，又会恢复运行状态。这种状态主要用于程序的调试，又被叫做“暂停状态”、“挂起状态”。\n  中止状态\n状态标志state的值为TASK_DEAD。进程因某种原因而中止运行，进程占有的所有资源将被回收，除了task_struct结构（以及少数资源）以外，并且系统对它不再予以理睬，所以这种状态也叫做“僵死状态”，进程成为僵尸进程。\n  ps 标识进程状态对应的 5 种状态码：\n R：就绪状态和运行状态 runnable (on run queue) S：可中断等待状态 sleeping D：不可中断等待状态 uninterruptible sleep (usually IO) T：停止状态 traced or stopped Z：中止状态 a defunct (”zombie”) process  ps 标识进程的其他状态码：\n X：死掉的进程 Dead （应该不会出现） W：内存交互状态Paging （从 2.6 内核开始无效） N：高优先级 \u0026lt;：低优先级 s：包含子进程 L：被锁入内存 l：多线程状态 +：前台进程  命令参数 在不同的 Linux 发行版上，ps 命令的语法各不相同，为此，Linux 采取了一个折中的方法，即融合各种不同的风格，兼顾那些已经习惯了其它系统上使用 ps 命令的用户。ps命令支持三种使用的语法格式：\n UNIX 风格，选项可以组合在一起，并且选项前必须有“-”连字符； BSD 风格，选项可以组合在一起，但是选项前不能有“-”连字符； GNU 风格的选项，选项前有两个“-”连字符；  ps 命令常用的参数：\nps -a 显示所有终端下执行的进程，包含其他用户的进程 ps -A 显示所有进程 ps -e 和-A功能一样 ps -H 显示树状结构，表示程序间的相互关系 ps -f 全格式显示进程 ps a 显示当前终端下执行的进程 ps c 显示进程的真实名称 ps e 列出程序所使用的环境变量 ps f 用ASCII字符显示树状结构，表达程序间的相互关系 ps x 显示所有进程，无论是否运行在终端上 ps u 显示用户相关的进程或者与用户相关的属性 ps r 只显示正在运行的进程 使用实例 大家如果执行 man ps 命令，则会发现 ps 命令的帮助为了适应不同的类 UNIX 系统，可用格式非常多，不方便记忆。所以，我建议大家记忆几个固定选项即可。\nps aux 查看系统中所有的进程\n# ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.2 2872 1416 ? Ss Jun04 0:02 /sbin/init root 2 0.0 0.0 0 0 ? S Jun04 0:00 [kthreadd] root 3 0.0 0.0 0 0 ? S Jun04 0:00 [migration/0] root 4 0.0 0.0 0 0 ? S Jun04 0:00 [ksoftirqd/0] …省略部分输出… 输出信息中各列的具体含义：\n   表头 含义     USER 该进程是由哪个用户产生的。   PID 进程的 ID。   %CPU 该进程占用 CPU 资源的百分比，占用的百分比越高，进程越耗费资源。   %MEM 该进程占用物理内存的百分比，占用的百分比越高，进程越耗费资源。   VSZ 该进程占用虚拟内存的大小，单位为 KB。   RSS 该进程占用实际物理内存的大小，单位为 KB。   TTY 该进程是在哪个终端运行的。其中，tty1 ~ tty7 代表本地控制台终端（可以通过 Alt+F1 ~ F7 快捷键切换不同的终端），tty1~tty6 是本地的字符界面终端，tty7 是图形终端。pts/0 ~ 255 代表虚拟终端，一般是远程连接的终端，第一个远程连接占用 pts/0，第二个远程连接占用 pts/1，依次増长。   STAT 进程状态。   START 该进程的启动时间。   TIME 该进程占用 CPU 的运算时间，注意不是系统时间。   COMMAND 产生此进程的命令名。    ps -le 查看系统中所有的进程\nps aux 命令可以看到系统中所有的进程，ps -le 命令也能看到系统中所有的进程。由于 -l 选项的作用，所以 ps -le 命令能够看到更加详细的信息，比如父进程的 PID、优先级等。但是这两个命令的基本作用是一致的，掌握其中一个就足够了。\n# ps -le F S UID PID PPID C PRI Nl ADDR SZ WCHAN TTY TIME CMD 4 S 0 1 0 0 80 0 - 718 - ? 00:00:02 init 1 S 0 2 0 0 80 0 - 0 - ? 00:00:00 kthreadd 1 S 0 3 2 0 -40 - - 0 - ? 00:00:00 migration/0 1 S 0 4 2 0 80 0 - 0 - ? 00:00:00 ksoflirqd/0 1 S 0 5 2 0 -40 - - 0 - ? 00:00:00 migration/0 …省略部分输出… 输出信息中各列的含义：\n   表头 含义     F 进程标志，说明进程的权限，常见的标志有两个: 1：进程可以被复制，但是不能被执行；4：进程使用超级用户权限；   S 进程状态。具体的状态和\u0026quot;psaux\u0026quot;命令中的 STAT 状态一致；   UID 运行此进程的用户的 ID；   PID 进程的 ID；   PPID 父进程的 ID；   C 该进程的 CPU 使用率，单位是百分比；   PRI 进程的优先级，数值越小，该进程的优先级越高，越早被 CPU 执行；   NI 进程的优先级，数值越小，该进程越早被执行；   ADDR 该进程在内存的哪个位置；   SZ 该进程占用多大内存；   WCHAN 该进程是否运行。\u0026quot;-\u0026ldquo;代表正在运行；   TTY 该进程由哪个终端产生；   TIME 该进程占用 CPU 的运算时间，注意不是系统时间；   CMD 产生此进程的命令名；    ps -l 查看当前 Shell 产生的进程\n# ps -l F S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD 4 S 0 18618 18614 0 80 0 - 1681 - pts/1 00:00:00 bash 4 R 0 18683 18618 4 80 0 - 1619 - pts/1 00:00:00 ps top 简介 top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。\ntop显示系统当前的进程和其他状况，是一个动态显示过程，即可以通过用户按键来不断刷新当前状态。如果在前台执行该命令，它将独占前台，直到用户终止该程序为止。\n比较准确的说，top命令提供了实时的对系统处理器的状态监视。它将显示系统中CPU最“敏感”的任务列表。该命令可以按CPU使用、内存使用和执行时间对任务进行排序；而且该命令的很多特性都可以通过交互式命令或者在个人定制文件中进行设定。\n命令参数 top 命令的基本格式如下：\n#top [选项] 选项：\n -d 秒数：指定 top 命令每隔几秒更新。默认是 3 秒； -b：使用批处理模式输出。一般和\u0026rdquo;-n\u0026quot;选项合用，用于把 top 命令重定向到文件中； -n 次数：指定 top 命令执行的次数。一般和\u0026quot;-b\u0026quot;选项合用； -p 进程PID：仅查看指定 ID 的进程； -s：使 top 命令在安全模式中运行，避免在交互模式中出现错误； -u 用户名：只监听某个用户的进程；  交互操作指令 在 top 命令的显示窗口中，还可以使用如下按键，进行一下交互操作：\n ? 或 h：显示交互模式的帮助 P：按照 CPU 的使用率排序，默认就是此选项 M：按照内存的使用率排序 N：按照 PID 排序 T：按照 CPU 的累积运算时间排序，也就是按照 TIME+ 项排序 k：按照 PID 给予某个进程一个信号。一般用于中止某个进程，信号 9 是强制中止的信号 r：按照 PID 给某个进程重设优先级（Nice）值 \u0026lt;Space\u0026gt;：立即刷新 s：设置刷新时间间隔 c：显示命令完全模式 t:：显示或隐藏进程和CPU状态信息 m：显示或隐藏内存状态信息 l：显示或隐藏uptime信息 f：增加或减少进程显示标志 S：累计模式，会把已完成或退出的子进程占用的CPU时间累计到父进程的TIME+ u：指定显示用户进程 i：只显示正在运行的进程 W：保存对top的设置到文件 ~/.toprc，下次启动将自动调用toprc文件的设置。 q：退出  使用实例 # top top - 12:26:46 up 1 day, 13:32, 2 users, load average: 0.00, 0.00, 0.00 Tasks: 95 total, 1 running, 94 sleeping, 0 stopped, 0 zombie Cpu(s): 0.1%us, 0.1%sy, 0.0%ni, 99.7%id, 0.1%wa, 0.0%hi, 0.1%si, 0.0%st Mem: 625344k total, 571504k used, 53840k free, 65800k buffers Swap: 524280k total, 0k used, 524280k free, 409280k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 19002 root 20 0 2656 1068 856 R 0.3 0.2 0:01.87 top 1 root 20 0 2872 1416 1200 S 0.0 0.2 0:02.55 init 2 root 20 0 0 0 0 S 0.0 0.0 0:00.03 kthreadd 第一行为任务队列信息\n   内 容 说 明     12:26:46 系统当前时间   up 1 day, 13:32 系统的运行时间.本机己经运行 1 天 13 小时 32 分钟   2 users 当前登录了两个用户   load average: 0.00,0.00，0.00 系统在之前 1 分钟、5 分钟、15 分钟的平均负载。如果 CPU 是单核的，则这个数值超过 1 就是高负载：如果 CPU 是四核的，则这个数值超过 4 就是高负载 （这个平均负载完全是依据个人经验来进行判断的，一般认为不应该超过服务器 CPU 的核数）    第二行为进程信息\n   内 容 说 明     Tasks: 95 total 系统中的进程总数   1 running 正在运行的进程数   94 sleeping 睡眠的进程数   0 stopped 正在停止的进程数   0 zombie 僵尸进程数。如果不是 0，则需要手工检查僵尸进程    第三行为 CPU 信息\n   内 容 说 明     Cpu(s): 0.1 %us 用户模式占用的 CPU 百分比   0.1%sy 系统模式占用的 CPU 百分比   0.0%ni 改变过优先级的用户进程占用的 CPU 百分比   99.7%id 空闲 CPU 占用的 CPU 百分比   0.1%wa 等待输入/输出的进程占用的 CPU 百分比   0.0%hi 硬中断请求服务占用的 CPU 百分比   0.1%si 软中断请求服务占用的 CPU 百分比   0.0%st st（steal time）意为虚拟时间百分比，就是当有虚拟机时，虚拟 CPU 等待实际 CPU 的时间百分比    第四行为物理内存信息\n   内 容 说 明     Mem: 625344k total 物理内存的总量，单位为KB   571504k used 己经使用的物理内存数量   53840k free 空闲的物理内存数量。我们使用的是虚拟机，共分配了 628MB内存，所以只有53MB的空闲内存   65800k buffers/cache 作为缓冲的内存数量    缓冲（buffer）和缓存（cache）的区别：\n 缓存（cache）是在读取硬盘中的数据时，把最常用的数据保存在内存的缓存区中，再次读取该数据时，就不去硬盘中读取了，而在缓存中读取。 缓冲（buffer）是在向硬盘写入数据时，先把数据放入缓冲区,然后再一起向硬盘写入，把分散的写操作集中进行，减少磁盘碎片和硬盘的反复寻道，从而提高系统性能。  简单来说，缓存（cache）是用来加速数据从硬盘中\u0026quot;读取\u0026quot;的，而缓冲（buffer）是用来加速数据\u0026quot;写入\u0026quot;硬盘的。\n第五行为交换分区（swap）信息\n   内 容 说 明     Swap: 524280k total 交换分区（虚拟内存）的总大小   Ok used 已经使用的交换分区的大小   524280k free 空闲交换分区的大小   409280k cached 作为缓存的交换分区的大小    第六行为系统进程信息\n再来看 top 命令的第二部分输出，主要是系统进程信息，各个字段的含义如下：\n PID：进程的 ID。 USER：该进程所属的用户。 PR：优先级，数值越小优先级越高。 NI：优先级，数值越小、优先级越高。 VIRT：该进程使用的虚拟内存的大小，单位为 KB。 RES：该进程使用的物理内存的大小，单位为 KB。 SHR：共享内存大小，单位为 KB。 S：进程状态。 %CPU：该进程占用 CPU 的百分比。 %MEM：该进程占用内存的百分比。 TIME+：该进程共占用的 CPU 时间。 COMMAND：进程的命令名。  htop htop 是一个 Linux 下的交互式的进程浏览器，可以用来替换Linux下的top命令。\n与Linux传统的top相比，htop更加人性化。它可让用户交互式操作，支持颜色主题，可横向或纵向滚动浏览进程列表，并支持鼠标操作。\nbpytop Linux/OSX/FreeBSD resource monitor\nlsof 简介 lsof 命令，“list opened files”的缩写，直译过来，就是列举系统中已经被打开的文件。通过 lsof 命令，我们就可以根据文件找到对应的进程信息，也可以根据进程信息找到进程打开的文件。\n在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。\n在终端下输入lsof即可显示系统打开的文件，因为 lsof 需要访问核心内存和各种文件，所以必须以 root 用户的身份运行它才能够充分地发挥其功能。\n$ sudo lsof | less COMMAND PID TID TASKCMD USER FD TYPE DEVICE SIZE/OFF NODE NAME systemd 1 root cwd DIR 8,2 4096 2 / systemd 1 root rtd DIR 8,2 4096 2 / systemd 1 root txt REG 8,2 1620224 2491035 /usr/lib/systemd/systemd systemd 1 root mem REG 8,2 1369352 2498532 /usr/lib/x86_64-linux-gnu/libm-2.31.so systemd 1 root mem REG 8,2 178528 2490726 /usr/lib/x86_64-linux-gnu/libudev.so.1.6.17 输出各列信息的意义如下：\n  COMMAND：进程的名称\n  PID：进程标识符\n  PPID：父进程标识符（需要指定-R参数）\n  USER：进程所有者\n  PGID：进程所属组\n  FD：文件描述符（filedescriptor，简称 fd），应用程序通过文件描述符识别该文件类型。\n例如 cwd 表示current work dirctory，即应用程序的当前工作目录，这是该应用程序启动的目录，除非它本身对这个目录进行更改。txt 表示该类型的文件是程序代码，如应用程序二进制文件本身或共享库，如上列表中显示的 /usr/lib/systemd/systemd 程序。\n  TYPE：文件类型，如DIR、REG等，常见的文件类型:\n DIR：目录 REG：普通文件 CHR：字符 BLK：块设备类型 UNIX： UNIX 域套接字 FIFO：先进先出 (FIFO) 队列 IPv4：网际协议 (IP) 套接字    DEVICE：指定磁盘的名称\n  SIZE：文件的大小\n  NODE：索引节点（文件在磁盘上的标识）\n  NAME：打开文件的确切名称\n  命令参数    参数 含义     -a 列出打开文件存在的进程   -c \u0026lt;进程名\u0026gt; 列出指定进程名所打开的文件   -g 列出GID号进程详情   -d \u0026lt;文件号\u0026gt; 列出占用该文件号的进程   +d \u0026lt;目录\u0026gt; 列出目录下被打开的文件   +D \u0026lt;目录\u0026gt; 递归列出目录下被打开的文件   -n \u0026lt;目录\u0026gt; 列出使用NFS的文件   -i \u0026lt;条件\u0026gt; 列出符合条件的进程   -p \u0026lt;进程号\u0026gt; 列出指定进程号所打开的文件   -u 列出UID号进程详情   -h 显示帮助信息   -v 显示版本信息    使用实例 查询某个文件被哪个进程调用\n$ lsof /bin/bash 查询某个目录下所有的文件是被哪些进程调用的\n$ lsof +d /usr/lib 查看以httpd开头的进程调用了哪些文件\n$ lsof -c httpd 查询PID是1的进程调用的文件\n$ lsof -p 1 按照用户名查询某个用户的进程调用的文件\n$ lsof -u username 列出某个用户以及某个进程所打开的文件信息\n$ lsof -u test -c mysql 列出所有的网络连接\n$ lsof -i 列出所有tcp 网络连接信息\n$ lsof -i tcp 列出谁在使用某个端口\n$ lsof -i :3306 列出某个用户的所有活跃的网络端口\n$ lsof -a -u test -i 根据文件描述列出对应的文件信息\n$ lsof -d txt 列出被进程号为1234的进程所打开的所有 IPV4 network files\n$ lsof -i 4 -a -p 1234 列出目前连接主机nf5260i5-td上端口为：20，21，80相关的所有文件信息，且每隔3秒重复执行\n$ lsof -i @nf5260i5-td:20,21,80 -r 3 write 在服务器上，有时会有多个用户同时登录，一些必要的沟通就显得尤为重要。比如,我必须关闭某个服务，或者需要重启服务器，当然需要通知同时登录服务器的用户，这时就可以使用 write 命令。\nwrite 命令的信息如下：\n 命令名称：write。 英文原意：send a message to another user。 所在路径：/usr/bin/write。 执行权限：所有用户。 功能描述：向其他用户发送信息。  write 命令的基本格式如下:\n$ write 用户名 [终端号] write 命令没有多余的选项，我们要向在某个终端登录的用户发送信息，就可以这样来执行命令：\n# 向在pts/1 (远程终端1)登录的user1用户发送信息，使用\u0026#34;Ctrl+D\u0026#34;快捷键保存发送的数据 $ write user1 pts/1 hello I will be in 5 minutes to restart, please save your data 这时，user1 用户就可以收到你要在 5 分钟之后重启系统的信息了。\nxargs 标准输入与管道命令 Unix 命令都带有参数，有些命令可以接受\u0026quot;标准输入\u0026quot;（stdin）作为参数。\n$ cat /etc/passwd | grep root 上面的代码使用了管道命令（|）。管道命令的作用，是将左侧命令（cat /etc/passwd）的标准输出转换为标准输入，提供给右侧命令（grep root）作为参数。\n因为grep命令可以接受标准输入作为参数，所以上面的代码等同于下面的代码。\n$ grep root /etc/passwd 但是，大多数命令都不接受标准输入作为参数，只能直接在命令行输入参数，这导致无法用管道命令传递参数。举例来说，echo命令就不接受管道传参。\n$ echo \u0026#34;hello world\u0026#34; | echo 上面的代码不会有输出。因为管道右侧的echo不接受管道传来的标准输入作为参数。\nxargs 命令的作用 xargs命令的作用，是将标准输入转为命令行参数。\n$ echo \u0026#34;hello world\u0026#34; | xargs echo hello world 上面的代码将管道左侧的标准输入，转为命令行参数hello world，传给第二个echo命令。\nxargs命令的格式如下。\n$ xargs [-options] [command] 真正执行的命令，紧跟在xargs后面，接受xargs传来的参数。\nxargs的作用在于，大多数命令（比如rm、mkdir、ls）与管道一起使用时，都需要xargs将标准输入转为命令行参数。\n$ echo \u0026#34;one two three\u0026#34; | xargs mkdir 上面的代码等同于mkdir one two three。如果不加xargs就会报错，提示mkdir缺少操作参数。\nxargs 的单独使用 xargs后面的命令默认是echo。\n$ xargs # 等同于 $ xargs echo 大多数时候，xargs命令都是跟管道一起使用的。但是，它也可以单独使用。\n输入xargs按下回车以后，命令行就会等待用户输入，作为标准输入。你可以输入任意内容，然后按下Ctrl d，表示输入结束，这时echo命令就会把前面的输入打印出来。\n$ xargs hello (Ctrl + d) hello 再看一个例子。\n$ xargs find -name \u0026#34;*.txt\u0026#34; ./foo.txt ./hello.txt 上面的例子输入xargs find -name以后，命令行会等待用户输入所要搜索的文件。用户输入\u0026quot;*.txt\u0026quot;，表示搜索当前目录下的所有 TXT 文件，然后按下Ctrl d，表示输入结束。这时就相当执行find -name *.txt。\n-d 参数与分隔符 默认情况下，xargs将换行符和空格作为分隔符，把标准输入分解成一个个命令行参数。\n$ echo \u0026#34;one two three\u0026#34; | xargs mkdir 上面代码中，mkdir会新建三个子目录，因为xargs将one two three分解成三个命令行参数，执行mkdir one two three。\n-d参数可以更改分隔符。\n$ echo -e \u0026#34;a\\tb\\tc\u0026#34; | xargs -d \u0026#34;\\t\u0026#34; echo a b c 上面的命令指定制表符\\t作为分隔符，所以a\\tb\\tc就转换成了三个命令行参数。echo命令的-e参数表示解释转义字符。\n-p 参数，-t 参数 使用xargs命令以后，由于存在转换参数过程，有时需要确认一下到底执行的是什么命令。\n-p参数打印出要执行的命令，询问用户是否要执行。\n$ echo \u0026#39;one two three\u0026#39; | xargs -p touch touch one two three ?... 上面的命令执行以后，会打印出最终要执行的命令，让用户确认。用户输入y以后（大小写皆可），才会真正执行。\n-t参数则是打印出最终要执行的命令，然后直接执行，不需要用户确认。\n$ echo \u0026#39;one two three\u0026#39; | xargs -t rm rm one two three -0 参数与 find 命令 由于xargs默认将空格作为分隔符，所以不太适合处理文件名，因为文件名可能包含空格。\nfind命令有一个特别的参数-print0，指定输出的文件列表以null分隔。然后，xargs命令的-0参数表示用null当作分隔符。\n$ find /path -type f -print0 | xargs -0 rm 上面命令删除/path路径下的所有文件。由于分隔符是null，所以处理包含空格的文件名，也不会报错。\n还有一个原因，使得xargs特别适合find命令。有些命令（比如rm）一旦参数过多会报错\u0026quot;参数列表过长\u0026quot;，而无法执行，改用xargs就没有这个问题，因为它对每个参数执行一次命令。\n$ find . -name \u0026#34;*.txt\u0026#34; | xargs grep \u0026#34;abc\u0026#34; 上面命令找出所有 TXT 文件以后，对每个文件搜索一次是否包含字符串abc。\n-L 参数 如果标准输入包含多行，-L参数指定多少行作为一个命令行参数。\n$ xargs find -name \u0026#34;*.txt\u0026#34; \u0026#34;*.md\u0026#34; find: paths must precede expression: `*.md\u0026#39; 上面命令同时将\u0026quot;*.txt\u0026quot;和*.md两行作为命令行参数，传给find命令导致报错。\n使用-L参数，指定每行作为一个命令行参数，就不会报错。\n$ xargs -L 1 find -name \u0026#34;*.txt\u0026#34; ./foo.txt ./hello.txt \u0026#34;*.md\u0026#34; ./README.md 上面命令指定了每一行（-L 1）作为命令行参数，分别运行一次命令（find -name）。\n下面是另一个例子。\n$ echo -e \u0026#34;a\\nb\\nc\u0026#34; | xargs -L 1 echo a b c 上面代码指定每行运行一次echo命令，所以echo命令执行了三次，输出了三行。\n-n 参数 -L参数虽然解决了多行的问题，但是有时用户会在同一行输入多项。\n$ xargs find -name \u0026#34;*.txt\u0026#34; \u0026#34;*.md\u0026#34; find: paths must precede expression: `*.md\u0026#39; 上面的命令将同一行的两项作为命令行参数，导致报错。\n-n参数指定每次将多少项，作为命令行参数。\n$ xargs -n 1 find -name 上面命令指定将每一项（-n 1）标准输入作为命令行参数，分别执行一次命令（find -name）。\n下面是另一个例子。\n$ echo {0..9} | xargs -n 2 echo 0 12 34 56 78 9 上面命令指定，每两个参数运行一次echo命令。所以，10个阿拉伯数字运行了五次echo命令，输出了五行。\n-I 参数 如果xargs要将命令行参数传给多个命令，可以使用-I参数。\n-I指定每一项命令行参数的替代字符串。\n$ cat foo.txt one two three $ cat foo.txt | xargs -I file sh -c \u0026#39;echo file; mkdir file\u0026#39; one two three $ ls one two three 上面代码中，foo.txt是一个三行的文本文件。我们希望对每一项命令行参数，执行两个命令（echo和mkdir），使用-I file表示file是命令行参数的替代字符串。执行命令时，具体的参数会替代掉echo file; mkdir file里面的两个file。\n\u0026ndash;max-procs 参数 xargs默认只用一个进程执行命令。如果命令要执行多次，必须等上一次执行完，才能执行下一次。\n--max-procs参数指定同时用多少个进程并行执行命令。--max-procs 2表示同时最多使用两个进程，--max-procs 0表示不限制进程数。\n$ docker ps -q | xargs -n 1 --max-procs 0 docker kill 上面命令表示，同时关闭尽可能多的 Docker 容器，这样运行速度会快很多。\nawk awk是处理文本文件的一个应用程序，几乎所有 Linux 系统都自带这个程序。\n它依次处理文件的每一行，并读取里面的每一个字段。对于日志、CSV 那样的每行格式相同的文本文件，awk可能是最方便的工具。\nawk其实不仅仅是工具软件，还是一种编程语言。不过，本文只介绍它的命令行用法，对于大多数场合，应该足够用了。\n基本用法 awk的基本用法就是下面的形式。\n# 格式 $ awk 动作 文件名 # 示例 $ awk \u0026#39;{print $0}\u0026#39; demo.txt 上面示例中，demo.txt是awk所要处理的文本文件。前面单引号内部有一个大括号，里面就是每一行的处理动作print $0。其中，print是打印命令，$0代表当前行，因此上面命令的执行结果，就是把每一行原样打印出来。\n下面，我们先用标准输入（stdin）演示上面这个例子。\n$ echo \u0026#39;this is a test\u0026#39; | awk \u0026#39;{print $0}\u0026#39; this is a test 上面代码中，print $0就是把标准输入this is a test，重新打印了一遍。\nawk会根据空格和制表符，将每一行分成若干字段，依次用$1、$2、$3代表第一个字段、第二个字段、第三个字段等等。\n$ echo \u0026#39;this is a test\u0026#39; | awk \u0026#39;{print $3}\u0026#39; a 上面代码中，$3代表this is a test的第三个字段a。\n下面，为了便于举例，我们把/etc/passwd文件保存成demo.txt。\nroot❌0:0:root:/root:/usr/bin/zsh daemon❌1:1:daemon:/usr/sbin:/usr/sbin/nologin bin❌2:2:bin:/bin:/usr/sbin/nologin sys❌3:3:sys:/dev:/usr/sbin/nologin sync❌4:65534:sync:/bin:/bin/sync 这个文件的字段分隔符是冒号（:），所以要用-F参数指定分隔符为冒号。然后，才能提取到它的第一个字段。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{ print $1 }\u0026#39; demo.txt root daemon bin sys sync 变量 除了$ + 数字表示某个字段，awk还提供其他一些变量。\n变量NF表示当前行有多少个字段，因此$NF就代表最后一个字段。\n$ echo \u0026#39;this is a test\u0026#39; | awk \u0026#39;{print $NF}\u0026#39; test $(NF-1)代表倒数第二个字段。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{print $1, $(NF-1)}\u0026#39; demo.txt root /root daemon /usr/sbin bin /bin sys /dev sync /bin 上面代码中，print命令里面的逗号，表示输出的时候，两个部分之间使用空格分隔。\n变量NR表示当前处理的是第几行。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{print NR \u0026#34;) \u0026#34; $1}\u0026#39; demo.txt 1) root 2) daemon 3) bin 4) sys 5) sync 上面代码中，print命令里面，如果原样输出字符，要放在双引号里面。\nawk的其他内置变量如下。\n FILENAME：当前文件名 FS：字段分隔符，默认是空格和制表符。 RS：行分隔符，用于分割每一行，默认是换行符。 OFS：输出字段的分隔符，用于打印时分隔字段，默认为空格。 ORS：输出记录的分隔符，用于打印时分隔记录，默认为换行符。 OFMT：数字输出的格式，默认为％.6g。  函数 awk还提供了一些内置函数，方便对原始数据的处理。\n函数toupper()用于将字符转为大写。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{ print toupper($1) }\u0026#39; demo.txt ROOT DAEMON BIN SYS SYNC 上面代码中，第一个字段输出时都变成了大写。\n其他常用函数如下。\n tolower()：字符转为小写。 length()：返回字符串长度。 substr()：返回子字符串。 sin()：正弦。 cos()：余弦。 sqrt()：平方根。 rand()：随机数。  awk内置函数的完整列表，可以查看手册。\n条件 awk允许指定输出条件，只输出符合条件的行。\n输出条件要写在动作的前面。\n$ awk \u0026#39;条件 动作\u0026#39; 文件名 请看下面的例子。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;/usr/ {print $1}\u0026#39; demo.txt root daemon bin sys 上面代码中，print命令前面是一个正则表达式，只输出包含usr的行。\n下面的例子只输出奇数行，以及输出第三行以后的行。\n# 输出奇数行 $ awk -F \u0026#39;:\u0026#39; \u0026#39;NR % 2 == 1 {print $1}\u0026#39; demo.txt root bin sync # 输出第三行以后的行 $ awk -F \u0026#39;:\u0026#39; \u0026#39;NR \u0026gt;3 {print $1}\u0026#39; demo.txt sys sync 下面的例子输出第一个字段等于指定值的行。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;$1 == \u0026#34;root\u0026#34; {print $1}\u0026#39; demo.txt root $ awk -F \u0026#39;:\u0026#39; \u0026#39;$1 == \u0026#34;root\u0026#34; || $1 == \u0026#34;bin\u0026#34; {print $1}\u0026#39; demo.txt root bin if 语句 awk提供了if结构，用于编写复杂的条件。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{if ($1 \u0026gt; \u0026#34;m\u0026#34;) print $1}\u0026#39; demo.txt root sys sync 上面代码输出第一个字段的第一个字符大于m的行。\nif结构还可以指定else部分。\n$ awk -F \u0026#39;:\u0026#39; \u0026#39;{if ($1 \u0026gt; \u0026#34;m\u0026#34;) print $1; else print \u0026#34;---\u0026#34;}\u0026#39; demo.txt root --- --- sys sync find find 命令由 POSIX 规范 定义，它创建了一个用于衡量 POSIX 系统的开放标准，这包括 Linux、BSD 和 macOS。简而言之，只要你运行的是 Linux、BSD 或 macOS，那么 find 已经安装了。\n但是，并非所有的 find 命令都完全相同。例如，GNU 的 find 命令有一些 BSD、Busybox 或 Solaris 上 find 命令可能没有或有但实现方式不同的功能。本文使用 findutils 包中的 GNU find，因为它很容易获得且非常流行。本文演示的大多数命令都适用于 find 的其他实现，但是如果你在 Linux 以外的平台上尝试命令并得到非预期结果，尝试下载并安装 GNU 版本。\nman文档中给出的find命令的一般形式为：\nfind [-H] [-L] [-P] [-D debugopts] [-Olevel] [path...] [expression] 其实[-H] [-L] [-P] [-D debugopts] [-Olevel]这几个选项并不常用（至少在我的日常工作中，没有用到过），上面的find命令的常用形式可以简化为：\nfind [path...] [expression]   path：find命令所查找的目录路径。例如用.来表示当前目录，用/来表示系统根目录\n  expression：expression可以分为——“-options [-print -exec -ok \u0026hellip;]”\n   -options，指定find命令的常用选项 -print，find命令将匹配的文件输出到标准输出 -exec，find命令对匹配的文件执行该参数所给出的shell命令。相应命令的形式为'command' { } \\;，注意{ }和\\；之间的空格 find ./ -size 0 -exec rm {} \\; 删除文件大小为零的文件 （还可以以这样做：rm -i find ./ -size 0 或 find ./ -size 0 | xargs rm -f \u0026amp;）  为了用ls -l命令列出所匹配到的文件，可以把ls -l命令放在find命令的-exec选项中：find . -type f -exec ls -l { } \\; 在/logs目录中查找更改时间在5日以前的文件并删除它们：find /logs -type f -mtime +5 -exec rm { } \\; -ok，和-exec的作用相同，只不过以一种更为安全的模式来执行该参数所给出的shell命令，在执行每一个命令之前，都会给出提示，让用户来确定是否执行。 find . -name \u0026quot;*.conf\u0026quot; -mtime +5 -ok rm { } \\; 在当前目录中查找所有文件名以.LOG结尾、更改时间在5日以上的文件，并删除它们，只不过在删除之前先给出提示    也有人这样总结find命令的结构：\nfind start_directory options criteria_to_match action_to_perform_on_results 常用选项  -name  按照文件名查找文件。 find /dir -name filename  在/dir目录及其子目录下面查找名字为filename的文件 find . -name \u0026quot;*.c\u0026quot; 在当前目录及其子目录（用“.”表示）中查找任何扩展名为“c”的文件 -perm 按照文件权限来查找文件。 find . -perm 755 –print 在当前目录下查找文件权限位为755的文件，即文件属主可以读、写、执行，其它用户可以读、执行的文件 -prune  使用这一选项可以使find命令不在当前指定的目录中查找，如果同时使用-depth选项，那么-prune将被find命令忽略。 find /apps -path \u0026quot;/apps/bin\u0026quot; -prune -o –print 在/apps目录下查找文件，但不希望在/apps/bin目录下查找 find /usr/sam -path \u0026quot;/usr/sam/dir1\u0026quot; -prune -o –print 在/usr/sam目录下查找不在dir1子目录之内的所有文件 -user  按照文件属主来查找文件。 find ~ -user sam –print 在$HOME目录中查找文件属主为sam的文件 -group  按照文件所属的组来查找文件。 find /apps -group gem –print 在/apps目录下查找属于gem用户组的文件 -mtime -n +n  按照文件的更改时间来查找文件， - n表示文件更改时间距现在n天以内，+ n表示文件更改时间距现在n天以前。 find / -mtime -5 –print 在系统根目录下查找更改时间在5日以内的文件 find /var/adm -mtime +3 –print 在/var/adm目录下查找更改时间在3日以前的文件 -nogroup  查找无有效所属组的文件，即该文件所属的组在/etc/groups中不存在。 find / –nogroup -print -nouser  查找无有效属主的文件，即该文件的属主在/etc/passwd中不存在。 find /home -nouser –print -newer file1 ! file2  查找更改时间比文件file1新但比文件file2旧的文件。 -type  查找某一类型的文件，诸如： b - 块设备文件。 d - 目录。 c - 字符设备文件。 p - 管道文件。 l - 符号链接文件。 f - 普通文件。 find /etc -type d –print 在/etc目录下查找所有的目录 find . ! -type d –print 在当前目录下查找除目录以外的所有类型的文件 find /etc -type l –print 在/etc目录下查找所有的符号链接文件 -size n：[c] 查找文件长度为n块的文件，带有c时表示文件长度以字节计。 find . -size +1000000c –print 在当前目录下查找文件长度大于1 M字节的文件 find /home/apache -size 100c –print 在/home/apache目录下查找文件长度恰好为100字节的文件 find . -size +10 –print 在当前目录下查找长度超过10块的文件（一块等于512字节） -depth：在查找文件时，首先查找当前目录中的文件，然后再在其子目录中查找。 find / -name \u0026quot;CON.FILE\u0026quot; -depth –print 它将首先匹配所有的文件然后再进入子目录中查找 -mount：在查找文件时不跨越文件系统mount点。 find . -name \u0026quot;*.XC\u0026quot; -mount –print 从当前目录开始查找位于本文件系统中文件名以XC结尾的文件（不进入其它文件系统） -follow：如果find命令遇到符号链接文件，就跟踪至链接所指向的文件。  按名称查找文件 你可以借助正则表达式使用完整或部分的文件名来定位文件。find 命令需要你给出想搜索的目录；指定搜索属性选项，例如，-name 用于指定区分大小写的文件名；然后是搜索字符串。默认情况下，搜索字符串按字面意思处理：除非你使用正则表达式语法，否则 find 命令搜索的文件名正是你在引号之间输入的字符串。\n假设你的 Documents 目录包含四个文件：Foo、foo、foobar.txt 和 foo.xml。以下是对 foo 的字面搜索：\n$ find ~ -name \u0026#34;foo\u0026#34; /home/tux/Documents/examples/foo 你可以使用 -iname 选项使其不区分大小写来扩大搜索范围：\n$ find ~ -iname \u0026#34;foo\u0026#34; /home/tux/Documents/examples/foo /home/tux/Documents/examples/Foo 通配符 你可以使用基本的 shell 通配符来扩展搜索。例如，* 表示任意数量的字符：\n$ find ~ -iname \u0026#34;foo*\u0026#34; /home/tux/Documents/examples/foo /home/tux/Documents/examples/Foo /home/tux/Documents/examples/foo.xml /home/tux/Documents/examples/foobar.txt ? 表示单个字符：\n$ find ~ -iname \u0026#34;foo*.???\u0026#34; /home/tux/Documents/examples/foo.xml /home/tux/Documents/examples/foobar.txt 这不是正则表达式语法，因此 . 在示例中只表示字母“点”。\n正则表达式 你还可以使用正则表达式。与 -iname 和 -name 一样，也有区分大小写和不区分大小写的选项。但不一样的是，-regex 和 -iregex 搜索应用于整个路径，而不仅仅是文件名。这意味着，如果你搜索 foo，你不会得到任何结果，因为 foo 与 /home/tux/Documents/foo 不匹配。相反，你必须要么搜索整个路径，要么在字符串的开头使用通配符：\n$ find ~ -iregex \u0026#34;.*foo\u0026#34; /home/tux/Documents/examples/foo /home/tux/Documents/examples/Foo 查找近一周修改过的文件 要查找近一周修改的文件，使用 -mtime 选项以及过去的天数（负数）：\n$ find ~ -mtime -7 /home/tux/Documents/examples/foo /home/tux/Documents/examples/Foo /home/tux/Documents/examples/foo.xml /home/tux/Documents/examples/foobar.txt 查找近几天修改的文件 你可以结合使用 -mtime 选项来查找近几天范围内修改的文件。对于第一个 -mtime 参数，表示上一次修改文件的最近天数。第二个参数表示最大天数。例如，搜索修改时间超过 1 天但不超过 7 天的文件：\n$ find ~ -mtime +1 -mtime -7 按文件类型限制搜索 指定查找文件的类型来优化 find 的结果是很常见的。如果你不确定要查找的内容，则不应该使用此选项。但如果你知道要查找的是文件而不是目录，或者是目录而不是文件，那么这可能是一个很好的过滤器。选项是 -type，它的参数是代表不同类型数据的字母代码。最常见的是：\n d - 目录 f - 文件 l - 链接文件 s - 套接字 p - 命名管道（用于 FIFO） b - 块设备（通常是硬盘）  下面是一些例子：\n$ find ~ -type d -name \u0026#34;Doc*\u0026#34; /home/tux/Documents $ find ~ -type f -name \u0026#34;Doc*\u0026#34; /home/tux/Downloads/10th-Doctor.gif $ find /dev -type b -name \u0026#34;sda*\u0026#34; /dev/sda/dev/sda1 调整范围 find 命令默认是递归的，这意味着它会在指定的目录中层层搜索结果。这在大型文件系统中可能会变得不堪重负，但你可以使用 -maxdepth 选项来控制搜索深度：\n$ find /usr -iname \u0026#34;*xml\u0026#34; | wc -l 15588 $ find /usr -maxdepth 2 -iname \u0026#34;*xml\u0026#34; | wc -l 15 也可以使用 -mindepth 设置最小递归深度：\n$ find /usr -mindepth 8 -iname \u0026#34;*xml\u0026#34; | wc -l 9255 与 xargs 在使用find命令的-exec选项处理匹配到的文件时， find命令将所有匹配到的文件一起传递给exec执行。但有些系统对能够传递给exec的命令长度有限制，这样在find命令运行几分钟之后，就会出现溢出错误。错误信息通常是“参数列太长”或“参数列溢出”。这就是xargs命令的用处所在，特别是与find命令一起使用。\nfind命令把匹配到的文件传递给xargs命令，而xargs命令每次只获取一部分文件而不是全部，不像-exec选项那样。这样它可以先处理最先获取的一部分文件，然后是下一批，并如此继续下去。\n在有些系统中，使用-exec选项会为处理每一个匹配到的文件而发起一个相应的进程，并非将匹配到的文件全部作为参数一次执行；这样在有些情况下就会出现进程过多，系统性能下降的问题，因而效率不高；\n而使用xargs命令则只有一个进程。另外，在使用xargs命令时，究竟是一次获取所有的参数，还是分批取得参数，以及每一次获取参数的数目都会根据该命令的选项及系统内核中相应的可调参数来确定。\n来看看xargs命令是如何同find命令一起使用的，并给出一些例子。\nfind . -type f -print | xargs file 查找系统中的每一个普通文件，然后使用xargs命令来测试它们分别属于哪类文件\nfind / -name \u0026quot;core\u0026quot; -print | xargs echo \u0026quot;\u0026quot; \u0026gt;/tmp/core.log 在整个系统中查找内存信息转储文件(core dump) ，然后把结果保存到/tmp/core.log 文件中：\nfind . -type f -print | xargs grep \u0026quot;hostname\u0026quot; 用grep命令在所有的普通文件中搜索hostname这个词\nfind ./ -mtime +3 -print|xargs rm -f –r 删除3天以前的所有东西 （find . -ctime +3 -exec rm -rf {} \\;）\nfind ./ -size 0 | xargs rm -f \u0026amp; 删除文件大小为零的文件\nfind命令配合使用exec和xargs可以使用户对所匹配到的文件执行几乎所有的命令。\nfd fd 命令是一个流行的、用户友好的 find 命令的替代品。\ngrep grep (global search regular expression(RE) and print out the line，全面搜索正则表达式并把行打印出来)是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。\ngrep 这个名字，来源于一个 Unix/Linux 中的古老的行编辑器 ed 中执行相似操作的命令：\ng/re/p 语法如下所示:\ngrep [OPTIONS] PATTERN [FILE...] grep [OPTIONS] [-e PATTERN | -f FILE] [FILE...] grep命令用于搜索由Pattern参数指定的模式，并将每个匹配的行写入标准输出中。这些模式是具有限定的正则表达式，它们使用ed或egrep命令样式。\n如果在File参数中指定了多个名称，grep命令将显示包含匹配行的文件的名称。\n对 shell 有特殊含义的字符 ($, *, [, |, ^, (, ), \\ ) 出现在 Pattern参数中时必须带双引号。如果 Pattern参数不是简单字符串，通常必须用单引号将整个模式括起来。在诸如 [a-z], 之类的表达式中，-（减号）cml 可根据当前正在整理的序列来指定一个范围。整理序列可以定义等价的类以供在字符范围中使用。\n如果未指定任何文件，grep会假定为标准输入。\n基本集 grep正则表达式元字符集：\n ^ 锚定行的开始 如：'^grep'匹配所有以grep开头的行。 $ 锚定行的结束 如：'grep$'匹配所有以grep结尾的行。 . 匹配一个非换行符的字符 如：'gr.p'匹配gr后接一个任意字符，然后是p。 * 匹配零个或多个先前字符 如：' *grep'匹配所有一个或多个空格后紧跟grep的行。 .*一起用代表任意字符。 [] 匹配一个指定范围内的字符，如'[Gg]rep'匹配Grep和grep。 [^]  匹配一个不在指定范围内的字符，如：'[^A-FH-Z]rep'匹配不包含A-F和H-Z的一个字母开头，紧跟rep的行。 \\(..\\) 标记匹配字符，如：'\\(love\\)'，love被标记为1。 \\\u0026lt; 锚定单词的开始，如：'\\ \\\u0026gt; 锚定单词的结束，如grep\\\u0026gt;'匹配包含以grep结尾的单词的行。 x\\{m\\} 连续重复字符x，m次，如：'o\\{5\\}'匹配包含连续5个o的行。 x\\{m,\\} 连续重复字符x,至少m次，如：'o\\{5,\\}'匹配至少连续有5个o的行。 x\\{m,n\\} 连续重复字符x，至少m次，不多于n次，如：'o\\{5,10\\}'匹配连续5\u0026ndash;10个o的行。 \\w 匹配一个文字和数字字符，也就是[A-Za-z0-9]，如：'G\\w*p'匹配以G后跟零个或多个文字或数字字符，然后是p。 \\W  w的反置形式，匹配一个非单词字符，如点号句号等。\\W*则可匹配多个。 \\b 单词锁定符，如: '\\bgrep\\b'只匹配grep，即只能是grep这个单词，两边均为空格。  常用选项 -? 同时显示匹配行上下的？行，如：grep -2 pattern filename同时显示匹配行的上下2行。\n-b，--byte-offset 打印匹配行前面打印该行所在的块号码。\n-c,--count 只打印匹配的行数，不显示匹配的内容。\n-f File，--file=File 从文件中提取模板。空文件中包含0个模板，所以什么都不匹配。\n-h，--no-filename 当搜索多个文件时，不显示匹配文件名前缀。\n-i，--ignore-case 忽略大小写差别。\n-q，--quiet 取消显示，只返回退出状态。0则表示找到了匹配的行。\n-l，--files-with-matches 打印匹配模板的文件清单。\n-L，--files-without-match 打印不匹配模板的文件清单。\n-n，--line-number 在匹配的行前面打印行号。\n-s，--silent 不显示关于不存在或者无法读取文件的错误信息。\n-v，--revert-match 反检索，只显示不匹配的行。\n-w，--word-regexp 如果被\\引用，就把表达式做为一个单词搜索。\n-V，--version 显示软件版本信息。\n怎么样使用 grep 来搜索一个文件 搜索 /etc/passwd 文件下的 boo 用户,输入:\n$ grep boo /etc/passwd 输出内容:\nfoo❌1000:1000:foo,,,:/home/foo:/bin/ksh 可以使用 grep 去强制忽略大小写。例如，使用 -i 选项可以匹配 boo, Boo, BOO 和其他组合：\n$ grep -i \u0026quot;boo\u0026quot; /etc/passwd 递归使用 grep 你可以递归地使用 grep 进行搜索。例如，在文件目录下面搜索所有包含字符串“192.168.1.5”的文件\n$ grep -r \u0026quot;192.168.1.5\u0026quot; /etc/ 或者是：\n$ grep -R \u0026quot;192.168.1.5\u0026quot; /etc/ 示例输出:\n/etc/ppp/options:# ms-wins 192.168.1.50/etc/ppp/options:# ms-wins 192.168.1.51/etc/NetworkManager/system-connections/Wired connection 1:addresses1=192.168.1.5;24;192.168.1.2; 你会看到搜索到 192.168.1.5 的结果每一行都前缀以找到匹配的文件名（例如：/etc/ppp/options）。输出之中包含的文件名可以加 -h 选项来禁止输出：\n$ grep -h -R \u0026quot;192.168.1.5\u0026quot; /etc/ 或者\n$ grep -hR \u0026quot;192.168.1.5\u0026quot; /etc/ 示例输出:\n# ms-wins 192.168.1.50# ms-wins 192.168.1.51addresses1=192.168.1.5;24;192.168.1.2; 使用 grep 去搜索文本 当你搜索 boo 时，grep 命令将会匹配 fooboo，boo123, barfoo35 和其他所有包含 boo 的字符串，你可以使用 -w 选项去强制只输出那些仅仅包含那个整个单词的行（LCTT译注：即该字符串两侧是英文单词分隔符，如空格，标点符号，和末端等，因此对中文这种没有断字符号的语言并不适用。）。\n$ grep -w \u0026quot;boo\u0026quot; file 使用 grep 命令去搜索两个不同的单词 使用 egrep 命令如下:\n$ egrep -w 'word1|word2' /path/to/file （LCTT 译注：这里使用到了正则表达式，因此使用的是 egrep 命令，即扩展的 grep 命令。）\n统计文本匹配到的行数 grep 命令可以通过加 -c 参数显示每个文件中匹配到的次数：\n$ grep -c 'word' /path/to/file 传递 -n 选项可以输出的行前加入匹配到的行的行号：\n$ grep -n 'root' /etc/passwd 示例输出:\n1:root:x:0:0:root:/root:/bin/bash1042:rootdoor:x:0:0:rootdoor:/home/rootdoor:/bin/csh3319:initrootapp:x:0:0:initrootapp:/home/initroot:/bin/ksh 反转匹配（不匹配） 可以使用 -v 选项来输出不包含匹配项的内容，输出内容仅仅包含那些不含给定单词的行，例如输出所有不包含 bar 单词的行：\n$ grep -v bar /path/to/file UNIX/Linux 管道与 grep 命令 grep 常常与管道一起使用，在这个例子中，显示硬盘设备的名字：\n# dmesg | egrep '(s|h)d[a-z]' 显示 CPU 型号：\n# cat /proc/cpuinfo | grep -i 'Model' 然而，以上命令也可以按照以下方法使用，不使用管道:\n# grep -i 'Model' /proc/cpuinfo 示例输出:\nmodel : 30model name : Intel(R) Core(TM) i7 CPU Q 820 @ 1.73GHzmodel : 30model name : Intel(R) Core(TM) i7 CPU Q 820 @ 1.73GHz 如何仅仅显示匹配到内容的文件名字? 使用 -l 选项去显示那些文件内容中包含 main() 的文件名：\n$ grep -l 'main' *.c 最后，你可以强制 grep 以彩色输出：\n$ grep --color vivek /etc/passwd 查找文件内容 从根目录开始查找所有扩展名为 .log 的文本文件，并找出包含 \u0026ldquo;ERROR\u0026rdquo; 的行：\n$ find / -type f -name \u0026#34;*.log\u0026#34; | xargs grep \u0026#34;ERROR\u0026#34; 例子：从当前目录开始查找所有扩展名为 .in 的文本文件，并找出包含 \u0026ldquo;thermcontact\u0026rdquo; 的行：\n$ find . -name \u0026#34;*.in\u0026#34; | xargs grep \u0026#34;thermcontact\u0026#34; cat bat A cat(1) clone with wings.\n添加了语法高亮和 Git 集成等功能，并且还提供了分页选项。\nip linux的ip命令和ifconfig类似，但前者功能更强大，并旨在取代后者。使用ip命令，只需一个命令，你就能很轻松地执行一些网络管理任务。ifconfig是net-tools中已被废弃使用的一个命令，许多年前就已经没有维护了。iproute2套件里提供了许多增强功能的命令，ip命令即是其中之一。\n设置和删除Ip地址 要给你的机器设置一个IP地址，可以使用下列ip命令：\n$ sudo ip addr add 192.168.0.193/24 dev wlan0 请注意IP地址要有一个后缀，比如/24。这种用法用于在无类域内路由选择（CIDR）中来显示所用的子网掩码。在这个例子中，子网掩码是255.255.255.0。\n在你按照上述方式设置好IP地址后，需要查看是否已经生效。\n$ ip addr show wlan0 你也可以使用相同的方式来删除IP地址，只需用del代替add。\n$ sudo ip addr del 192.168.0.193/24 dev wlan0 列出路由表条目 ip命令的路由对象的参数还可以帮助你查看网络中的路由数据，并设置你的路由表。第一个条目是默认的路由条目，你可以随意改动它。\n在这个例子中，有几个路由条目。这个结果显示有几个设备通过不同的网络接口连接起来。它们包括WIFI、以太网和一个点对点连接。\n$ ip route show 假设现在你有一个IP地址，你需要知道路由包从哪里来。可以使用下面的路由选项（译注：列出了路由所使用的接口等）：\n$ ip route get 10.42.0.47 更改默认路由 要更改默认路由，使用下面ip命令：\n$ sudo ip route add default via 192.168.0.196 显示网络统计数据 使用ip命令还可以显示不同网络接口的统计数据。\n当你需要获取一个特定网络接口的信息时，在网络接口名字后面添加选项ls即可。使用多个选项**-s**会给你这个特定接口更详细的信息。特别是在排除网络连接故障时，这会非常有用。\n$ ip -s -s link ls p2p1 ARP条目 地址解析协议（ARP）用于将一个IP地址转换成它对应的物理地址，也就是通常所说的MAC地址。使用ip命令的neigh或者neighbour选项，你可以查看接入你所在的局域网的设备的MAC地址。\n$ ip neighbour 监控netlink消息 也可以使用ip命令查看netlink消息。monitor选项允许你查看网络设备的状态。比如，所在局域网的一台电脑根据它的状态可以被分类成REACHABLE或者STALE。使用下面的命令：\n$ ip monitor all 激活和停止网络接口 你可以使用ip命令的up和down选项来激某个特定的接口，就像ifconfig的用法一样。\n在这个例子中，当ppp0接口被激活和在它被停止和再次激活之后，你可以看到相应的路由表条目。这个接口可能是wlan0或者eth0。将ppp0更改为你可用的任意接口即可。\n$ sudo ip link set ppp0 down $ sudo ip link set ppp0 up 获取帮助 当你陷入困境，不知道某一个特定的选项怎么用的时候，你可以使用help选项。man页面并不会提供许多关于如何使用ip选项的信息，因此这里就是获取帮助的地方。\n比如，想知道关于route选项更多的信息：\n$ ip route help 小结 对于网络管理员们和所有的Linux使用者们，ip命令是必备工具。是时候抛弃ifconfig命令了，特别是当你写脚本时。\ndig 使用 dig 来进行 DNS 查询。\n参数类型：查询和格式化 有两种主要的参数可以传递给 dig：\n 告诉 dig 要进行什么 DNS 查询的参数。 告诉 dig 如何 格式化响应的参数。  首先，让我们看一下查询选项。\n主要的查询选项 你通常想控制 DNS 查询的 3 件事是：\n 名称（如 jvns.ca）。默认情况下，查询的是空名称（.）。 DNS 查询类型（如 A 或 CNAME）。默认是 A。 发送查询的 服务器（如 8.8.8.8）。默认是 /etc/resolv.conf 中的内容。  其格式是：\ndig @server name type 这里有几个例子：\n dig @8.8.8.8 jvns.ca 向谷歌的公共 DNS 服务器（8.8.8.8）查询 jvns.ca。 dig ns jvns.ca 对 jvns.ca 进行类型为 NS 的查询。  -x：进行反向 DNS 查询\n我偶尔使用的另一个查询选项是 -x，用于进行反向 DNS 查询。下面是输出结果的样子。\n$ dig -x 172.217.13.174 174.13.217.172.in-addr.arpa. 72888 IN PTR yul03s04-in-f14.1e100.net。 -x 不是魔术。dig -x 172.217.13.174 只是对 174.13.217.172.in-addr.arpa. 做了一个 PTR 查询。下面是如何在不使用 `-x’ 的情况下进行完全相同的反向 DNS 查询。\n$ dig ptr 174.13.217.172.in-addr.arpa. 174.13.217.172.in-addr.arpa. 72888 IN PTR yul03s04-in-f14.1e100.net。 我总是使用 -x，因为它可以减少输入。\nDNS反向查询大概的一个定义就是：\n从 IP 地址获取 PTR 记录。也就是说，通过使用一些网络工具可以将 IP 地址转换为主机名。 实际上，PRT 代表 POINTER，在 DNS 系统有唯一性，将 IP 地址与规范化的主机名联系起来。PTR 记录其实是 NDS 系统的一部分，但是由专门的区域文件组成的，使用的是传统的 in-addr.arpa 格式。\n格式化响应的选项 现在，让我们讨论一下你可以用来格式化响应的参数。\n我发现 dig 默认格式化 DNS 响应的方式对初学者来说是很难接受的。下面是输出结果的样子：\n; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.16.20 \u0026lt;\u0026lt;\u0026gt;\u0026gt; -r jvns.ca ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 28629 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096 ; COOKIE: d87fc3022c0604d60100000061ab74857110b908b274494d (good) ;; QUESTION SECTION: ;jvns.ca. IN A ;; ANSWER SECTION: jvns.ca. 276 IN A 172.64.80.1 ;; Query time: 9 msec ;; SERVER: 192.168.1.1#53(192.168.1.1) ;; WHEN: Sat Dec 04 09:00:37 EST 2021 ;; MSG SIZE rcvd: 80 如果你不习惯看这个，你可能需要花点时间来筛选，找到你要找的 IP 地址。而且大多数时候，你只对这个响应中的一行感兴趣（jvns.ca. 180 IN A 172.64.80.1）。\n下面是我最喜欢的两种方法，可以使 dig 的输出更容易管理：\n方式 1 : +noall +answer\n这告诉 dig 只打印 DNS 响应中的“答案”部分的内容。下面是一个查询 google.com 的 NS 记录的例子：\n$ dig +noall +answer ns google.com google.com. 158564 IN NS ns4.google.com. google.com. 158564 IN NS ns1.google.com. google.com. 158564 IN NS ns2.google.com. google.com. 158564 IN NS ns3.google.com. 这里的格式是：\nNAME TTL TYPE CONTENT google.com 158564 IN NS ns3.google.com. 顺便说一下：如果你曾经想知道 IN 是什么意思，它是指“查询类”，代表“互联网internet”。它基本上只是上世纪 80、90 年代的遗物，当时还有其他网络与互联网竞争，如“混沌网络chaosnet”。\n方式 2：+short\n这就像 dig +noall +answer，但更短：它只显示每条记录的内容。比如说：\n$ dig +short ns google.com ns2.google.com. ns1.google.com. ns4.google.com. ns3.google.com. digrc 如果你不喜欢 dig 的默认格式（我就不喜欢！），你可以在你的主目录下创建一个 .digrc 文件，告诉它默认使用不同的格式。\n我非常喜欢 +noall +answer 格式，所以我把 +noall +answer 放在我的 ~/.digrc 中。下面是我使用该配置文件运行 dig jvns.ca 时的情况。\n$ dig jvns.ca jvns.ca. 255在172.64.80.1中 这样读起来就容易多了！\n如果我想回到所有输出的长格式（我有时会这样做，通常是因为我想看响应的权威部分的记录），我可以通过运行再次得到一个长答案。\n$ dig +all jvns.ca dig +trace 我使用的最后一个 dig 选项是 +trace。dig +trace 模仿 DNS 解析器在查找域名时的做法 —— 它从根域名服务器开始，然后查询下一级域名服务器（如 .com），以此类推，直到到达该域名的权威域名服务器。因此，它将进行大约 30 次 DNS 查询。（我用 tcpdump 检查了一下，对于每个根域名服务器的 A / AAAA 记录它似乎要进行 2 次查询，所以这已经是 26 次查询了。我不太清楚它为什么这样做，因为它应该已经有了这些 IP 的硬编码，但它确实如此。）\n我发现这对了解 DNS 的工作原理很有用，但我不认为我用它解决过问题。\n为什么要用 dig 尽管有一些更简单的工具来进行 DNS 查询（如 dog 和 host），我发现自己还是坚持使用 dig。\n我喜欢 dig 的地方实际上也是我 不喜欢 dig 的地方 —— 它显示了大量的细节！\n我知道，如果我运行 dig +all，它将显示 DNS 响应的所有部分。例如，让我们查询 jvns.ca 的一个根名称服务器。响应有 3 个部分，我可能会关心：回答部分、权威部分和附加部分。\n$ dig @h.root-servers.net. jvns.ca +all ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 18229 ;; flags: qr rd; QUERY: 1, ANSWER: 0, AUTHORITY: 4, ADDITIONAL: 9 ;; WARNING: recursion requested but not available ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 1232 ;; QUESTION SECTION: ;jvns.ca. IN A ;; AUTHORITY SECTION: ca. 172800 IN NS c.ca-servers.ca. ca. 172800 IN NS j.ca-servers.ca. ca. 172800 IN NS x.ca-servers.ca. ca. 172800 IN NS any.ca-servers.ca. ;; ADDITIONAL SECTION: c.ca-servers.ca. 172800 IN A 185.159.196.2 j.ca-servers.ca. 172800 IN A 198.182.167.1 x.ca-servers.ca. 172800 IN A 199.253.250.68 any.ca-servers.ca. 172800 IN A 199.4.144.2 c.ca-servers.ca. 172800 IN AAAA 2620:10a:8053::2 j.ca-servers.ca. 172800 IN AAAA 2001:500:83::1 x.ca-servers.ca. 172800 IN AAAA 2620:10a:80ba::68 any.ca-servers.ca. 172800 IN AAAA 2001:500:a7::2 ;; Query time: 103 msec ;; SERVER: 198.97.190.53#53(198.97.190.53) ;; WHEN: Sat Dec 04 11:23:32 EST 2021 ;; MSG SIZE rcvd: 289 dog 也显示了 “附加” 部分的记录，但它没有明确指出哪个是哪个（我猜 + 意味着它在附加部分？） ，但它似乎没有显示“权威”部分的记录。\n$ dog @h.root-servers.net. jvns.ca NS ca. 2d0h00m00s A \u0026#34;c.ca-servers.ca.\u0026#34; NS ca. 2d0h00m00s A \u0026#34;j.ca-servers.ca.\u0026#34; NS ca. 2d0h00m00s A \u0026#34;x.ca-servers.ca.\u0026#34; NS ca. 2d0h00m00s A \u0026#34;any.ca-servers.ca.\u0026#34; A c.ca-servers.ca. 2d0h00m00s + 185.159.196.2 A j.ca-servers.ca. 2d0h00m00s + 198.182.167.1 A x.ca-servers.ca. 2d0h00m00s + 199.253.250.68 A any.ca-servers.ca. 2d0h00m00s + 199.4.144.2 AAAA c.ca-servers.ca. 2d0h00m00s + 2620:10a:8053::2 AAAA j.ca-servers.ca. 2d0h00m00s + 2001:500:83::1 AAAA x.ca-servers.ca. 2d0h00m00s + 2620:10a:80ba::68 AAAA any.ca-servers.ca. 2d0h00m00s + 2001:500:a7::2 而 host 似乎只显示“答案”部分的记录（在这种情况下没有得到记录）：\n$ host jvns.ca h.root-servers.net Using domain server: Name: h.root-servers.net Address: 198.97.190.53#53 Aliases: 总之，我认为这些更简单的 DNS 工具很好（我甚至自己做了一个 简单的网络 DNS 工具），如果你觉得它们更容易，你绝对应该使用它们，但这就是为什么我坚持使用 dig 的原因。drill 的输出格式似乎与 dig 的非常相似，也许 drill 更好！但我还没有真正试过它。\nSamba Samba 是 SMB/CIFS 网络协议的重新实现, 可以在 Linux 和 Windows 系统间进行文件、打印机共享，和 NFS 的功能类似。\n安装 $ sudo apt install samba $ sudo systemctl enable --now smbd.service Samba 服务的配置文件是 /etc/samba/smb.conf，smb.conf(5)提供了详细的文档。\n如果使用了 防火墙，请记得打开需要的端口(通常是 137-139 + 445)。完整列表请查看 Samba 端口使用。\n创建共享 创建的目录即之后能够在Windows主机上直接访问的目录。例如：在用户samba_user的主目录下新建share文件夹为共享目录，由于Windows下的文件夹需可读可写可执行，需更改权限为777\n$ mkdir /home/samba_user/smbshare $ sudo chmod 777 /home/samba_user/smbshare 修改 /etc/samba/smb.conf，在smb.conf文件最后加上以下内容\n$ sudo vim /etc/samba/smb.conf [share] path = /home/samba_user/smbshare public = yes writable = yes valid users = samba_user create mask = 0644 force create mode = 0644 directory mask = 0755 force directory mode = 0755 available = yes  [share]表示共享文件夹的别名，之后将直接使用这个别名 force create mode 与 force directory mode的设置是因为Windows下与Linux下文件和文件夹的默认权限不同造成的，Windows下新建的文件是可执行的，必须强制设定其文件权限。 valid users 设置为你当前的Linux用户名，例如我的是samba_user，因为第一次打开共享文件夹时，需要验证权限。  用户管理 Samba 需要 Linux 账户才能使用 - 可以使用已有账户或创建新用户。\n虽然用户名可以和 Linux 系统共享，Samba 使用单独的密码管理，将下面的 samba_user 替换为上面设置的 valid users:\n$ sudo smbpasswd -a samba_user 根据服务器角色的差异，可能需要修改已有的文件权限和属性。\nWhich is faster-Samba or scp? Depends on the machines. Machines with really fast CPU may do SCP or SFTP faster.\nOtherwise, Samba will probably be faster because it doesn\u0026rsquo;t have to encrypt.\nsudo 简单的说，sudo 是一种权限管理机制，管理员可以授权于一些普通用户去执行一些 root 执行的操作，而不需要知道 root 的密码。\n严谨些说，sudo 允许一个已授权用户以超级用户或者其它用户的角色运行一个命令。当然，能做什么不能做什么都是通过安全策略来指定的。sudo 支持插件架构的安全策略，并能把输入输出写入日志。第三方可以开发并发布自己的安全策略和输入输出日志插件，并让它们无缝的和 sudo 一起工作。默认的安全策略记录在 /etc/sudoers 文件中。而安全策略可能需要用户通过密码来验证他们自己。也就是在用户执行 sudo 命令时要求用户输入自己账号的密码。如果验证失败，sudo 命令将会退出。\n命令语法 $ sudo [-bhHpV][-s ][-u \u0026lt;用户\u0026gt;][指令] $ sudo [-klv] 参数：\n -b 在后台执行指令。 -h 显示帮助。 -H 将HOME环境变量设为新身份的HOME环境变量。 -k 结束密码的有效期限，也就是下次再执行sudo时便需要输入密码。 -l 列出目前用户可执行与无法执行的指令。 -p 改变询问密码的提示符号。 -s 执行指定的shell。 -u \u0026lt;用户\u0026gt; 以指定的用户作为新的身份。若不加上此参数，则预设以root作为新的身份。 -v 延长密码有效期限5分钟。 -V 显示版本信息。 -S 从标准输入流替代终端来获取密码  基本配置 系统默认创建了一个名为 sudo 的组。只要把用户加入这个组，用户就具有了 sudo 的权限。\n至于如何把用户加入 sudo 组，您可以直接编辑 /etc/group 文件，当然您得使用一个有 sudo 权限的用户来干这件，在 sudo 组中加入新的用户，要使用逗号分隔多个用户。\n或者您可以使用 usermod 命令把用户添加到一个组中：\n$ sudo usermod -a -G sudo jack 上面的设置中我们把用户 jack 添加到了 sudo 组中，所以当用户 jack 登录后就可以通过 sudo 命令以 root 权限执行命令了！\n详细配置 在前面的配置中我们只是把用户 jack 加入了 sudo 组，他就具有了通过 root 权限执行命令的能力。\n现在我们想问一下，这是怎么发生的？是时候介绍如何配置 sudo 命令了！\nsudo 命令的配置文件为 /etc/sudoers。\n编辑这个文件是有单独的命令的 visudo，这个文件我们最好不要使用 vim 命令来打开，是因为一旦你的语法写错会造成严重的后果，这个工具会替你检查你写的语法，这个文件的语法遵循以下格式：\nwho where whom command 说白了就是哪个用户在哪个主机以谁的身份执行那些命令，那么这个 where, 是指允许在那台主机 ssh 连接进来才能执行后面的命令，文件里面默认给 root 用户定义了一条规则：\nroot ALL=(ALL:ALL) ALL  root 表示 root 用户。 ALL 表示从任何的主机上都可以执行，也可以这样 192.168.100.0/24。 (ALL:ALL) 是以谁的身份来执行，ALL:ALL 就代表 root 可以任何人的身份来执行命令。 ALL 表示任何命令。  那么整条规则就是 root 用户可以在任何主机以任何人的身份来执行所有的命令。\n现在我们可以回答 jack 为什么具有通过 root 权限执行命令的能力了。打开 /etc/sudoers 文件：\n%sudo ALL=(ALL:ALL) ALL sudo 组中的所有用户都具有通过 root 权限执行命令的能力！\n再看个例子：\nnick 192.168.10.0/24=(root) /usr/sbin/useradd 上面的配置只允许 nick 在 192.168.10.0/24 网段上连接主机并且以 root 权限执行 useradd 命令。\n设置 sudo 时不需要输入密码\n只需要在配置行中添加 NOPASSWD: 就可以了：\n%sudo ALL=(ALL:ALL) NOPASSWD:ALL 日志 在 ubuntu 中，sudo 的日志默认被记录在 /var/log/auth.log 文件中。当我们执行 sudo 命令时，相关日志都是会被记录下来的。\n与输出重定向 如果当前用户没有某个文件的写权限，又要通过输出重定向往该文件中写入内容。结果只能是 \u0026ldquo;Permission denied\u0026rdquo;。\n比如当前用户为 nick，下面的命令试图查询 /root 目录下的文件并把结果写入到 /root/test.txt 文件中，注意用户 nick 没有对 /root/test.txt 文件的写权限：\n$ sudo ls -al /root/test.txt -rw-r--r-- 1 root root 0 Jan 10 05:19 /root/test.txt $ sudo ls -al /root \u0026gt; /root/test.txt -bash: /root/test.txt: Premission denied 不工作的原因是：虽然 ls 命令是以 sudo 方式执行的，但是输出重定向操作是由当前 shell 执行的，它(当前 shell)没有 /root/test.txt 文件的权限，所以最终失败。\n搞清楚了原因，就可以通过不同的方式来解决这个问题了，下面介绍四种方式。\n以 sudo 方式运行 shell\n既然是 shell 进程没有权限，那就用 sudo 的方式执行 shell：\n$ sudo bash -c \u0026#39;ls -al /root \u0026gt; /root/test.txt\u0026#39; 把命令写入脚本，以 sudo 方式执行脚本\n把下面的代码保存到脚本文件 test.sh 中：\n#!/bin/bash ls -al /root \u0026gt; /root/test.txt 然后通过下面的方式执行：\n$ chmod +x test.sh $ sudo ./test.sh 如果觉着创建脚本麻烦的话还可以使用变通的方式：\n$ sudo bash \u0026lt;\u0026lt;EOF \u0026gt; ls -al /root \u0026gt; /root/test.txt \u0026gt; EOF 或者是下面的写法：\n$ echo \u0026#39;ls -al /root \u0026gt; /root/test.txt\u0026#39; | sudo bash 先通过 sudo -s 启动 shell，然后执行命令\n先通过 sudo -s 命令切换到 root 用户再执行命令，最后 ctrl + d 退出。\n通过 sudo tee 命令实现\nTee 命令用于将数据重定向到文件，另一方面还可以提供一份重定向数据的副本作为后续命令的 stdin。简单的说就是把数据重定向到给定文件和屏幕上：\n面的命令中通过 sudo tee 把 ls 命令的输出写入文件：\n$ sudo ls -al /root | sudo tee /root/test.txt \u0026gt; /dev/null 其中的 \u0026gt; /dev/null 阻止 tee 把内容输出到终端。\nfdisk Linux 系统中所有的硬件设备都是通过文件的方式来表现和使用的，我们将这些文件称为设备文件，硬盘对应的设备文件一般被称为块设备文件。\n磁盘分类 比较常见的磁盘类型有消费类市场中的 SATA 硬盘和服务器中使用的 SCSI 硬盘、SAS 硬盘，当然还有当下大热的各种固态硬盘。\nSATA 硬盘\nSATA(Serial ATA)口的硬盘又叫串口硬盘，Serial ATA 采用串行连接方式，串行 ATA 总线使用嵌入式时钟信号，具备了更强的纠错能力，与以往相比其最大的区别在于能对传输指令(不仅仅是数据)进行检查，如果发现错误会自动矫正，这在很大程度上提高了数据传输的可靠性。串行接口还具有结构简单、支持热插拔的优点。SATA 硬盘主要用于消费类市场和一些低端服务器：\nSCSI 硬盘\nSCSI 硬盘即采用 SCSI 接口的硬盘。它由于性能好、稳定性高，因此在服务器上得到广泛应用。同时其价格也不菲，正因它的价格昂贵，所以在普通PC上很少见到它的踪迹。SCSI 硬盘使用 50 针接口，外观和普通硬盘接口有些相似(下图来自互联网)：\nSAS 硬盘\nSAS 是 Serial Attached SCSI 的缩写，即串行连接的 SCSI，其目标是定义一个新的串行点对点的企业级存储设备接口。串行接口减少了线缆的尺寸，允许更快的传输速度。SAS 硬盘与相同转速的 SCSI 硬盘相比有相同或者更好的性能。SAS 硬盘一般用于比较高端的服务器。\n固态硬盘\n固态硬盘(Solid State Disk)，一般称之为 SSD 硬盘，固态硬盘是用固态电子存储芯片阵列而制成的硬盘，由控制单元和存储单元(FLASH芯片、DRAM芯片)组成。其主要特点是没有传统硬盘的机械结构，读写速度非常快(下图来自互联网)：\n表示方法 在 Linux 系统中磁盘设备文件的命名规则为：\n主设备号 + 次设备号 + 磁盘分区号 对于目前常见的磁盘，一般表示为：\nsd[a-z]x  主设备号代表设备的类型，相同的主设备号表示同类型的设备。当前常见磁盘的主设备号为 sd。 次设备号代表同类设备中的序号，用 \u0026ldquo;a-z\u0026rdquo; 表示。比如 /dev/sda 表示第一块磁盘，/dev/sdb 表示第二块磁盘。 x 表示磁盘分区编号。在每块磁盘上可能会划分多个分区，针对每个分区，Linux 用 /dev/sdbx 表示，这里的 x 表示第二块磁盘的第 x 个分区。  磁盘分区 创建磁盘分区大概有下面几个目的：\n 提升数据的安全性(一个分区的数据损坏不会影响其他分区的数据) 支持安装多个操作系统 多个小分区对比一个大分区会有性能提升 更好的组织数据  本文以常见的 MBR 分区为例介绍磁盘分区中的一些常见概念。MBR 磁盘的分区由主分区、扩展分区和逻辑分区组成。在一块磁盘上，主分区的最大个数是 4，其中扩展分区也是一个主分区，并且最多只能有一个扩展分区，但可以在扩展分区上创建多个逻辑分区。因此主分区(包括扩展分区)的范围是 1-4，逻辑分区从 5 开始。对于逻辑分区，Linux 规定它们必须建立在扩展分区上，而不是建立在主分区上。\n主分区的作用是用来启动操作系统的，主要存放操作系统的启动或引导程序。\n扩展分区只不过是逻辑分区的 \u0026ldquo;容器\u0026rdquo;。实际上只有主分区和逻辑分区是用来进行数据存储的，因而可以将数据集中存放在磁盘的逻辑分区中。\n我们可以通过 fdisk 命令来查看磁盘分区的信息：\n$ sudo fdisk -l /dev/sda 分区信息：\n Device 显示了磁盘分区对应的设备文件名。 Boot 显示是否为引导分区，是引导分区就有一个 \u0026lsquo;*\u0026rsquo; 号。 Start 表示磁盘分区的起始位置。 End 表示磁盘分区的结束位置。 Sectors 表示分区占用的扇区数目。 Size 显示分区的大小。 Id/Type 显示的内容相同，分别是数值 ID 及其文字描述。 Id 列显示了磁盘分区对应的 ID，根据分区的不同，分区对应的 ID 号也不相同。Linux 下用 83 表示主分区和逻辑分区，5 表示扩展分区，8e 表示 LVM 分区，82 表示交换分区，7 表示 NTFS 分区。  划分磁盘分区 fdisk 是 Linux 系统中一款功能强大的磁盘分区管理工具，可以观察硬盘的使用情况，也可以用来管理磁盘分区。\n假设我们的 Linux 系统中增加了一块新的磁盘，系统对应的设备名为 /dev/sdd，下面我们通过 fdisk 命令对这个磁盘进行分区：\n$ (echo n; echo p; echo 1; echo ; echo ; echo w) | sudo fdisk /dev/sdd  命令 n 来创建新分区 p 来创建主分区 主分区的编号为 1- 4，这里我们输入了 1。 分区的大小是通过设置分区开始处的扇区和结束处的扇区设置的。这里如果回车两次会把整个磁盘划分为一个分区，也就是整个磁盘的容器都分给了一个分区。 注意此时的分区信息还没有写入到磁盘中，在这里还可以反悔，如果确认执行上面的分区，执行 w 命令就行了。  这时分区操作已经完成了，我们可以通过下面的命令查看分区的结果：\n$ sudo fdisk -l /dev/sdd 分区是使用磁盘的基础，在分区完成后还需要对分区进行格式化，并把格式化后的文件系统挂载到 Linux 系统之后才能存储文件。\n更改分区的类型\n创建的分区类型默认为 83(Linux)，如果想要一个 8e(Linux LVM)类型的分区，在 fdisk 输入 t 命令来修改分区的类型。\nOthers Ubuntu Packages Search List of applications—Arch 常用软件—openSUSE 应用程序—Ubuntu 生态适配清单—UOS QEMU KVM QEMU 的图形前端 与其他的虚拟化程序如 VirtualBox 和 VMware 不同, QEMU不提供管理虚拟机的GUI（运行虚拟机时出现的窗口除外），也不提供创建具有已保存设置的持久虚拟机的方法。除非您已创建自定义脚本以启动虚拟机，否则必须在每次启动时在命令行上指定运行虚拟机的所有参数。\nLibvirt提供了一种管理 QEMU 虚拟机的便捷方式。有关可用的前端，请参阅 libvirt 客户端列表。\n创建新虚拟系统 创建硬盘镜像 除非直接从 CD-ROM 或网络引导（并且不安装系统到本地），运行 QEMU 时都需要硬盘镜像。硬盘镜像是一个文件，存储虚拟机硬盘上的内容。\n一个硬盘镜像可能是 raw镜像, 和客户机器上看到的内容一模一样，并且将始终使用主机上的来宾硬盘驱动器的全部容量。此方法提供的I / O开销最小，但可能会浪费大量空间，因为guest虚拟机上未使用的空间无法在主机上使用。\n另外一种方式是qcow2 格式，仅当客户系统实际写入内容的时候，才会分配镜像空间。对客户机器来说，硬盘大小表现为完整大小，即使它可能仅占用主机系统上的非常小的空间。此映像格式还支持QEMU快照功能。但是，使用此格式而不是 raw 可能会影响性能。\nQEMU 提供 qemu-img命令创建硬盘镜像.例如创建一个 4 GB raw 格式的镜像:\n$ qemu-img create -f raw image_file 4G 您也可以用 -f qcow2 创建一个 qcow2 镜像。\n用 dd 或 fallocate 也可以创建一个 raw 镜像。\n警告： 如果硬盘镜像存储在 Btrfs 系统上，则应在创建任何映像之前考虑禁用该目录的 写时复制。\n调整镜像大小\n警告： 调整包含NTFS引导文件系统的镜像将无法启动已安装的操作系统，推荐在操作之前进行备份\n执行 qemu-img 带 resize 选项调整硬盘驱动镜像的大小.它适用于 raw 和 qcow2. 例如, 增加镜像 10 GB 大小, 运行:\n$ qemu-img resize disk_image +10G 在磁盘映像扩容后，必须使用虚拟机内部系统的分区工具对该镜像进行分区并格式化后才能真正开始使用新空间。 在收缩磁盘映像时，必须首先使用虚拟机内部系统的分区工具减少分该分区的大小，然后相应地收缩磁盘映像，否则收缩磁盘映像将导致数据丢失！\n安装操作系统 这是你第一次需要去启动模拟器的步骤，为了在磁盘镜像上安装操作系统，你必须同时将磁盘镜像与安装介质装载到虚拟机上，从安装介质中启动操作系统。\n以i386的客户机为例，为了从CD-ROM内的把可用于启动的ISO文件安装到磁盘镜像上，你需要：\n$ qemu-system-x86_64 -cdrom iso_image -boot order=d -drive file=disk_image,format=raw 在安装完操作系统后，就可以直接从QEMU镜像内启动了。\n注意： 默认情况下仅分配给虚拟机128MB的内存， 分配的内存大小可以通过 -m 调整， 比如 -m 512M 或 -m 2G。\n提示：\n 相较于指定 -boot order=x ，一部分用户感觉使用 -boot menu=on 启用boot菜单的体验更舒服些，至少在配置和实验时是这样的。 当使用无界面（headless）模式时， 将会默认在本地5900端口启动一个VNC服务器， 可以用 TigerVNC 连接到客户机的系统上: vncviewer :5900 若你在安装过程中需要替换软盘或CD，可以使用QEMU机器监视器（在虚拟机窗口中按Ctrl + Alt + 2）来删除存储设备并将其连接到虚拟机。使用info block查看块设备，然后使用change命令换出设备。按下Ctrl + Alt + 1返回虚拟机。  运行虚拟化的系统 qemu-system-* 程序 (例如 qemu-system-i386 或 qemu-system-x86_64, 取决于客户机架构)用来运行虚拟化的客户机. 用法是:\n$ qemu-system-i386 options disk_image 所有 qemu-system-*的选项是相同的。\n默认 QEMU会在窗口中显示虚拟机的视频输出.有一点要记住:当您单击QEMU窗口,鼠标指针被捕获。要放开，按 Ctrl+Alt+g.\n警告： QEMU 不应以 root 身份运行. 如果必须以root身份在某个脚本中运行QEMU，那么你需要使用 -runas 选项让QEMU放弃root权限\n启用 KVM KVM 必须要您处理器和内核支持, 和必要的 kernel modules加载。更多信息参见 KVM。\n要在KVM模式中启动QEMU, 追加 -enable-kvm到启动选项. 要检查是否为正在运行的 VM 启用了 KVM，请使用 Ctrl+Alt+Shift+2 进入 QEMU Monitor，然后键入 info kvm。\n注意：\n -machine 选项中的 accel=kvm 参数与-enable-kvm 或 -accel kvm 选项是等价的。 CPU模型 host 需要 KVM。 如果你使用GUI工具去启动QEMU，但是性能体验极差，那么最好检查一下是否真的开启了KVM支持，因为QEMU可能选择了备用的模拟模式，即软件级模拟。 需要启用KVM才能正常启动windows7和windows8，否则会出现“蓝屏”.  启用 IOMMU (Intel VT-d/AMD-Vi) 的支持 首先启用IOMMU。\n确保您的 CPU 支持 AMD-Vi/Intel Vt-d 并且已经在 BIOS 中打开。通常这个选项会在类似“其他 CPU 特性”的菜单里，也有可能隐藏在超频选项之中。选项可能就叫做 “VT-d” 或者 “AMD-Vi” ，也有可能是更通用的名称，比如“虚拟化技术”之类。有可能您主板的手册并不会解释这些。\n设置内核参数以启用 IOMMU，注意不同品牌的 CPU 所需的内核参数并不同。\n 对于 Intel CPU(VT-d)，使用 intel_iommu=on。 对于 AMD CPU(AMD-Vi)，使用 amd_iommu=on。  您同时需要设置iommu=pt，这将防止Linux试图接触(touching)无法直通的设备。\n在重启之后，检查 dmesg 以确认 IOMMU 已经被正确启用：\n$ dmesg | grep -e DMAR -e IOMMU ... [ 0.000000] Intel-IOMMU: enabled ... 添加 -device intel-iommu 选项创建IOMMU设备:\n$ qemu-system-x86_64 -enable-kvm -machine q35 -device intel-iommu -cpu host .. 注意： 在基于Intel CPU的系统上用 -device intel-iommu 创建QEMU内的IOMMU设备将会禁用PCI直通， 如果需要PCI直通，则不应设置-device intel-iommu。\n宿主机和虚拟机数据交互 网络 我们可以利用任何支持文件传输的网络协议实现客户机和宿主机之间的数据交互, 例如 NFS, SMB, NBD, HTTP, FTP, 或 SSH, 当然这么做的前提是你已经配置好二者之间的网络，且在系统上启动了相应的服务程序。\n在默认情况下，用户模式的客户机能够通过10.0.2.2这个IP访问到宿主机。任何运行于宿主机上的服务端程序都可以通过这个地址被访问到，比如说我们可以通过这个IP访问到宿主机上的SSH服务器或SMB服务器。因此在这种情况下，客户机能够挂载宿主机通过SMB or NFS暴露出来的目录，也可以访问宿主机上的HTTP服务器等。 通常情况下宿主机无法访问客户机上的服务，不过你也可以通过一些特殊的网络配置达到这个目的 (参阅#Tap 网络)\nQEMU 端口转发 QEMU能够将宿主机的端口转发到客户机上以实现一些功能，例如从宿主机上访问客户机的SSH端口。\n举个例子，将宿主机上的10022端口与客户机上的22 (SSH) 端口进行绑定， 对应的QEMU命令如下：\n$ qemu-system-x86_64 disk_image -nic user,hostfwd=tcp::10022-:22 确认你客户机上的sshd程序正在运行，然后可以通过如下命令连接到客户机的SSH端口\n$ ssh guest-user@localhost -p 10022 你可以用 SSHFS 把客户机的整个文件系统都挂到宿主机上，这样就可以在宿主机上对客户机的文件系统进行读写了。\n想进行多端口转发的话, 只需要在-nic参数中指定多个hostfwd, 以VNC端口为例:\n$ qemu-system-x86_64 disk_image -nic user,hostfwd=tcp::10022-:22,hostfwd=tcp::5900-:5900 QEMU 的内置SMB服务器 QEMU的文档中指出它有一个内置的SMB服务器，但实际上，它只是在宿主机上加载一个自动生成的smb.conf配置文件 (位于/tmp/qemu-smb.random_string)，然后启动宿主机上的Samba，使得客户机能够通过一个IP地址进行访问 (默认的IP地址是10.0.2.4)。这个方法只适用于用户网络，在你不想在宿主机开启通常的Samba服务 (客户机同样能访问这类Samba服务) 时这个方法还挺好用的。\n宿主机上必须安装 Samba。通过如下QEMU命令启用这项特性:\n$ sudo apt install samba $ qemu-system-x86_64 disk_image -net nic -net user,smb=shared_dir_path shared_dir_path 就是你想要在宿主机和客户机之间共享的目录。\n接着，在客户机内，你应该能够通过10.0.2.4访问到名为qemu的共享文件夹。例如在Windows Explorer中前往 \\\\10.0.2.4\\qemu 这个地址。\n注意：\n 如果你像这样多次指定共享选项 -net user,smb=shared_dir_path1 -net user,smb=shared_dir_path2 or -net user,smb=shared_dir_path1,smb=shared_dir_path2 qemu只会共享参数中最后的一个目录。 如果你不能访问共享文件夹且客户机系统为 Windows, 请检查 NetBIOS 协议是否被启用 并确认防火墙没有屏蔽NetBIOS协议的 端口 如果你不能访问共享文件夹且客户机系统为 Windows 10 Enterprise 或 Education 或 Windows Server 2016, 请启用游客访问.  共享多个文件夹并在运行时增删文件夹的一个方法是：共享一个空目录，然后在其中创建指向其余共享目录的符号链接。可以用下面的脚本修改SMB服务器的配置，这个脚本还能使宿主机上不允许执行的文件在客户机内拥有执行权限。\n#!/bin/bash eval $(ps h -C smbd -o pid,args | grep /tmp/qemu-smb | gawk \u0026#39;{print \u0026#34;pid=\u0026#34;$1\u0026#34;;conf=\u0026#34;$6}\u0026#39;) echo \u0026#34;[global] allow insecure wide links = yes [qemu] follow symlinks = yes wide links = yes acl allow execute always = yes\u0026#34; \u0026gt;\u0026gt; $conf # in case the change is not detected automatically: smbcontrol --configfile=$conf $pid reload-config 仅当客户机第一次访问到网络驱动后，才能将该脚本启用，并作用于qemu启动的SMB服务器。共享多文件的另一个方法是在配置文件里加入额外的共享路径，就像下面这样\n$ echo \u0026#34;[myshare] path=another_path read only=no guest ok=yes force user=username\u0026#34; \u0026gt;\u0026gt; $conf 这个共享文件夹可以在客户机内通过\\\\10.0.2.4\\*myshare*访问。\n网络 采用TAP设备（tun 与 tap 设备，都是虚拟网络设备，tun 设备用来实现三层隧道（三层 ip 数据报），tap 设备用来实现二层隧道（二层以太网数据帧）。）和网桥（使用网桥可以将多个接口连接到同一网段内，这一功能等同于交换式集线器。）的虚拟网络的性能应该会比使用用户模式网络或VDE要好，原因在于TAP设备和网桥是在内核中实现的。\n此外，虚拟网络的性能可以通过将网络设备直接注册到虚拟机中改善，这比默认情况下模拟e1000 NIC的性能表现要更好，参阅 [安装 virtio 驱动](#安装 virtio 驱动) 获得更多相关信息。\n关于链路层地址的限制 若在QEMU启动中指定了 -net nic 参数，QEMU将会为虚拟机注册一块虚拟网卡，其链路层地址为 52:54:00:12:34:56 。然而，当在多台虚拟机之间搭建桥接网络时，每台虚拟机在tap设备的虚拟机端都需要拥有一个独一无二的链路层地址 (MAC)，否则网桥会因为收到多个不同源却拥有相同MAC地址的数据包而无法正常工作。即使你为多个tap设备配置了不同的MAC地址也依旧会出现这个问题，因为当数据包通过tap设备时，tap设备并不会改写包内的链路层地址。\n因此请确保每个虚拟机拥有自己独一无二的网卡地址, 并且它们都以 52:54: 开头。 可以通过如下命令手动设置虚拟机的MAC地址, 下面的\u0026rsquo;X\u0026rsquo;可以替换成任何16进制字符:\n$ qemu-system-x86_64 -net nic,macaddr=52:54:XX:XX:XX:XX -net vde disk_image 用户模式 默认情况下，没有任何-netdev参数，QEMU将使用带有内置DHCP服务器的用户模式网络。当您的虚拟机运行其DHCP客户端时，将为其分配IP地址，它们将能够通过QEMU伪装的IP来访问物理主机的网络。\n警告： 仅适用于TCP和UDP协议，因此ICMP协议（包括ping）将不起作用。 请勿使用ping测试网络连接。\n如果主机已连接Internet，则此默认配置可以使您的虚拟机轻松访问Internet。但是如果您同时启动多个虚拟机，则虚拟机将无法在外部网络上直接看到，虚拟机也将无法相互通信。\nQEMU的用户模式网络可以提供更多功能，例如内置TFTP或SMB服务器，将主机端口重定向到虚拟机（例如，允许SSH连接到虚拟机）或将虚拟机连接到VLAN（vlan 全程 virtual lan，能够用来虚拟分配以太网。归属于不同的 VLAN ID 的设备之间需要一个路由才能够通信，这意味这不同的 VLAN ID 将以太网划分成了不同的分组。），以便它们可以彼此通信。 有关更多详细信息，请参见-net user标志上的QEMU文档。\n但是，用户模式网络在效用和性能上都有局限性。更高级的网络配置需要使用TAP设备或其他方法。\nTap 网络 Tap devices是一个Linux内核特性，允许您创建作为真实网络接口的虚拟网络接口。发送到tap接口的包将被传递到一个用户空间程序(如QEMU)，该程序将自己绑定到该接口。\nQEMU可以为虚拟机使用tap网络，因此发送到tap接口的包将被发送到虚拟机，并显示为来自虚拟机中的网络接口(通常是以太网接口)。相反，虚拟机通过其网络接口发送的所有内容都将出现在tap接口上。\nLinux桥接驱动程 序支持Tap设备，因此可以将Tap设备彼此桥接在一起，也可以连接其他主机接口，如eth0。如果您希望您的虚拟机能够相互通信，或者希望LAN上的其他机器能够与虚拟机通信，那么这是非常理想的方案。\n警告： 如果您将tap设备和一些主机接口桥接在一起，例如eth0，您的虚拟机将直接出现在外部网络上，这将使它们遭受攻击的可能。根据您的虚拟机可以访问的资源，您可能需要采取所有precautions来保护您的虚拟机。如果风险太大,虚拟机没有资源或您设置多个虚拟机,一个更好的解决方案可能是使用host-only networking建立NAT。在这种情况下，您只需要在主机上安装一个防火墙，而不是为每个虚拟机安装多个防火墙。\n正如在用户模式网络部分中指出的，tap设备提供比用户模式具有更高的网络性能。如果虚拟机中的操作系统支持virtio网络驱动程序，那么网络性能也会显著提高。假设使用tap0设备，virtio驱动程序在客户端上使用，并且没有使用脚本来帮助启动/停止网络，使用下面的qemu命令：\n-net nic,model=virtio -net tap,ifname=tap0,script=no,downscript=no 但是，如果已经使用带有virtio网络驱动程序的Tap设备，则甚至可以通过启用vhost来提高网络性能，例如：\n-net nic,model=virtio -net tap,ifname=tap0,script=no,downscript=no,vhost=on 仅主机网络\n如果为网桥提供了IP地址，并且使能发往该网桥的流量允许，但没有实际接口（例如eth0）连接到网桥，则虚拟机与虚拟机间，虚拟机与主机间能够相互通信。但是，如果您没有在物理主机上设置IP掩蔽，则他们将无法与外部网络进行通信。 此配置被其他虚拟化软件（例如VirtualBox）称为“仅主机网络模式”。\n提示：\n  如果你想设置IP掩蔽，例如虚拟机的NAT，请查看Internet sharing#Enable NAT页面。\n  您也许想在网桥接口上运行一个DHCP服务器来服务虚拟网络。例如，使用172.20.0.1/16子网，dnsmasq作为DHCP服务器:\n# ip addr add 172.20.0.1/16 dev br0 # ip link set br0 up # dnsmasq --interface=br0 --bind-interfaces --dhcp-range=172.20.0.2,172.20.255.254   内部网络\n如果您不为网桥提供IP地址并在iptables添加INPUT规则链，将所有流向网桥中的数据丢弃，则虚拟机将能够彼此通信，但无法与物理主机或外部网络通信。此配置被其他虚拟化软件（例如VirtualBox）称为“内部网络”。您将需要为虚拟机分配静态IP地址，或在其中一个虚拟机上运行DHCP服务器。\n在默认情况下，iptables将丢弃桥接网络中的数据包。您可能需要使用这样的iptables规则来允许桥接网络中的数据包:\n# iptables -I FORWARD -m physdev --physdev-is-bridged -j ACCEPT 使用 qemu-bridge-helper 桥接网络\n这种方法不需要启动脚本，并且很容易适应多个tap和多个桥。它使用/usr/lib/qemu/qemu-bridge-helper，允许在现有桥上创建tap设备。\n提示： 参见 Network bridge 获取创建网桥的信息.\n首先，创建一个配置文件，包含QEMU使用的所有网桥的名称:\n/etc/qemu/bridge.conf allow bridge0 allow bridge1 ... 现在启动虚拟机：\n$ qemu-system-i386 -net nic -net bridge,br=bridge0 [...] 在多个TAP设备的情况下，最基本的用法是要为所有NIC指定VLAN：\n$ qemu-system-i386 -net nic -net bridge,br=bridge0 -net nic,vlan=1 -net bridge,vlan=1,br=bridge1 [...] 手工创建网桥\n将虚拟机连接到主机接口，如eth0，这可能是最常见的配置。这种配置使虚拟机看起来直接位于外部网络，与物理主机位于同一以太网段。\n物理设备和Tap设备之间通过iptables进行网络共享\n桥接网络能在有线接口(例如eth0)之间工作，并且很容易设置。但是，如果主机通过无线设备连接到网络，则无法进行桥接。\n解决这个问题的一种方法是，给tap设备设置一个静态IP，使linux自动处理它的路由，然后通过iptables规则转发tap接口和连接到网络的设备之间的通信。\n通过 VDE2 配置网络 VDE全称为Virtual Distributed Ethernet，作为uml_switch的一个扩展，是一个用于管理虚拟网络的工具包\n其基本的思想是创建一个虚拟的开关，就如插座那样，允许虚拟机和物理机通过\u0026quot;插入\u0026quot;连接彼此。下面的配置非常简单，然而，VDE的功能远比展示的更强大，其能够接入虚拟开关，在不同的主机上运行它们并监听开关上的通信。\n本方法的优点在于无需sudo特权，普通用户一般没有运行modprobe的权限。\nVDE2 网桥 任何连接到vde上的虚拟机都会暴露给外部。举个例子，每台虚拟机都能直接从ADSL路由器那收到DHCP的配置信息。\n简化配置参数 如果你经常需要以不同的网络配置选项运行QEMU，就会发现时常得输入大量的-netdev和-device选项组合，这些是大量重复性的劳动。可以用-nic选项将二者结合，就如下面这样，底下这些参数：\n-netdev tap,id=network0,ifname=tap0,script=no,downscript=no,vhost=on -device virtio-net-pci,netdev=network0 可简化为:\n-nic tap,script=no,downscript=no,vhost=on,model=virtio-net-pci 要注意的是缺失了网络ID，因此将会以model=创建这些设备。{ic|-nic}}命令的前半部分参数正是-netdev的参数，而后半部分参数（model=之后的部分）则与设备有关，原本设备所提供的参数同样可以在此使用（例如，可以指定smb=）。若要完全禁用网络，可以用-nic none。\n图形 QEMU 可以使用一下几个图形输出：std, cirrus, vmware, qxl, xenfs 和 vnc。\n使用 vnc 选项，你可以单独运行客户机，并且通过 VNC 连接。\nstd 使用 -vga std 你可以得到最高 2560 x 1600 像素的分辨率。从 QEMU 2.2 开始是默认选项。\nqxl QXL是一个支持2D的并行虚拟化图形驱动。需要在客户机中安装驱动并在启动QEMU时设置-vga qxl选项。你可能也会想使用#SPICE优化QXL的图形表现。\n在Linux客户机中，需要加载qxl和bochs_drm这两个内核模块，以获得一个比较好的效果。\nQXL设备的默认VGA内存大小为16M，这样的内存大小最高支持QHD (2560x1440)的分辨率，如果想要一个更高的分辨率，请增加vga_memmb。\nvmware 尽管Bug有点多，但相比于std和cirrus它的表现会更好。对于Arch Linux客户机来说可以安装xf86-video-vmware和xf86-input-vmmouse获取VMware驱动。\nvirtio virtio-vga / virtio-gpu 是一个基于virgl的3D并行虚拟化图形驱动。目前依旧处于开发中，仅支持最近的（\u0026gt;= 4.4）的Linux客户机，且需要以gallium-drivers=virgl选项编译mesa (\u0026gt;=11.2)。\n若要在客户机上启用3D加速，那么需要用-vga virtio选项选择此vga，并用-display sdl,gl=on或-display gtk,gl=on在显示设备上启用opengl上下文，这两个选项分别适用于sdl输出和gtk输出。如果配置成功了，那么在客户机的kernel log里可以看到：\n# dmesg | grep drm [drm] pci: virtio-vga detected [drm] virgl 3d acceleration enabled cirrus cirrus是2.2之前默认的图形选项，不应当在现代操作系统中使用它。\nnone 这就像一台完全没有VGA卡的PC，无法通过-vnc访问它。另外，这种情况与使用-nographic选项不同，-nographic会让QEMU模拟VGA卡，只是关闭了SDL输出。\nSPICE SPICE project旨在为用户提供一种完全开源的方式，无缝地对虚拟机进行远程访问。\nVNC 可以用-vnc :*X*选项将QEMU的VGA输出重定向至VNC会话中。将*X*替换为输出目标的编号（0代表之后监听在5900，1代表监听在5901\u0026hellip;）。\n$ qemu-system-x86_64 -vnc :0 警告： 默认的VNC服务器没有使用任何验证手段，用户可以从任何主机上连接到VNC。\n基本的口令验证\n可以通过使用password选项很容易地设置访问口令。必须在QEMU Monitor中指定口令，仅当用户提供口令时才有可能连接到VNC。\n$ qemu-system-x86_64 -vnc :0,password -monitor stdio 在QEMU Monitor中设置口令需使用change vnc password命令，然后指定一个口令。\n底下的命令将在启动VNC时直接为其设置口令：\n$ printf \u0026quot;change vnc password\\n%s\\n\u0026quot; MYPASSWORD | qemu-system-x86_64 -vnc :0,password -monitor stdio 注意： 口令被限制在8个字符内，可以用暴力破解的方式猜到口令。因此在公网上推荐使用更细致的保护措施。\n音频 -audiodev标识用于设定后端音频驱动及其相关选项。最简单的情况下，你需要选择一个驱动并设置一个id。\n-audiodev pa,id=snd0 使用音频设备 Intel HD Audio\n模拟Intel HD Audio需要添加控制器和编解码器设备。可以用如下命令列出可用的Intel HDA Audio设备：\n$ qemu-system-x86_64 -device help | grep hda 添加音频控制器：\n-device ich9-intel-hda 添加音频编解码器并将其映射到宿主机的音频后端id上。\n-device hda-output,audiodev=snd0 Intel 82801AA AC97\n模拟AC97需要添加声卡设备并将其映射到宿主机的一个音频后端id上。\n-device AC97,audiodev=snd0 无音频设备 通过如下命令获取支持模拟的音频驱动列表：\n$ qemu-system-x86_64 -soundhw help 比如，要在客户机上模拟hda驱动，需要使用-device intel-hda -device hda-duplex选项启动QEMU。\n注意： 客户机的显卡模拟驱动可能也会导致客户机中的音频质量出现问题，需要一个个进行排查。使用qemu-system-x86_64 -h | grep vga列出可用的选项\n安装 virtio 驱动 QEMU为用户提供并行虚拟化块设备和网络设备的能力，其是借助virtio驱动实现的，拥有更好的性能表现以及更低的开销。\nvirtio块设备需要使用-drive指定一个disk image的参数，且需要带上if=virtio参数：\n$ qemu-system-x86_64 -boot order=c -drive file=disk_image,if=virtio 网络配置也是类似的：\n$ qemu-system-x86_64 -nic user,model=virtio-net-pci 注意： 仅有当客户机有virtio设备对应的驱动时该方法才能起效，Linux是有这方面支持的，不过无法保证这些驱动能够兼容其他操作系统。\n以下以windows为例。\n块设备驱动 Windows没有自带virtio驱动，因此需要在安装时加载该驱动。镜像文件可以从Fedora 仓库下载。\n通过ISO加载只对Windows Vista和Windows Server 2008及其之后的版本有效。这个方法的具体操作是在主磁盘设备和Windows安装盘外挂载一个额外的cdrom设备，将系统镜像与virtio驱动一同加载：\n$ qemu-system-x86_64 ... \\ -drive file=windows_disk_image,index=0,media=disk,if=virtio \\ -drive file=windows.iso,index=2,media=cdrom \\ -drive file=virtio.iso,index=3,media=cdrom \\ ... 在安装过程中，Windows Installer会询问你“Where do you want to install Windows?”，其会返回一个警告表示没有找到任何磁盘设备。接下来跟着如下示例中的步骤进行操作（基于Windows Server 2012 R2 with Update）：\n Select the option Load Drivers. Uncheck the box for Hide drivers that are not compatible with this computer\u0026rsquo;s hardware. Click the browse button and open the CDROM for the virtio iso, usually named \u0026ldquo;virtio-win-XX\u0026rdquo;. Now browse to E:\\viostor\\[your-os]\\amd64, select it, and confirm.  现在应该能看到virtio磁盘出现在列表中了，等待着被选中、格式化并安装。\n网络驱动 安装virtio网络驱动程序要容易一些，只需如上所述添加-net参数即可。\n$ qemu-system-i386 -m 4G -vga std -drive file=windows_disk_image,if=virtio -net nic,model=virtio-net-pci -cdrom virtio-win-0.1-185.iso Windows将检测网络适配器并尝试为其找到驱动程序。如果失败，请转到“设备管理器”，找到带有感叹号图标的网络适配器（双击打开），切换到驱动程序并单击“更新驱动程序”，然后选择虚拟CD-ROM。别忘了选中显示要递归搜索目录的复选框。\nBalloon 驱动 如果想要追踪客户机内存状态（比如通过virsh的dommemstat命令）或者在运行时改变客户机内存大小（尽管依然无法改变实际的内存大小，不过可以通过inflating balloon驱动限制内存的使用），那么请在客户机上安装balloon驱动吧。\nQEMU 监视器 QEMU运行时会提供一个监视器console界面以方便用户同虚拟机进行交互。QEMU监视器提供了许多有趣的功能，例如获取当前虚拟机的信息，热插拔设备，创建快照等。在QEMU监视器console中运行help或?命令获得完整的命令列表。\n访问QEMU监视器Console 图形化界面\n当使用默认的std图形选项时，可以通过按下Ctrl+Alt+2组合键或从QEMU窗口上的View \u0026gt; compatmonitor0访问到QEMU监视器。若要返回到虚拟机的图形界面，那么按下Ctrl+Alt+1或者View \u0026gt; VGA就行。\n然而，这种标准的访问方式不够方便，而且并不是在QEMU的所有图形化输出方式中都适用。\nTelnet\n启动QEMU时带上-monitor telnet:127.0.0.1:*port*,server,nowait参数可以启用telnet。虚拟机启动后可以通过telnet访问到监视器：\n$ telnet 127.0.0.1 port 注意： 如果指定 127.0.0.1 作为监听地址，那么只能在运行QEMU的宿主机上连接到该监视器。如果想要远程访问，QEMU需要在0.0.0.0上进行监听：-monitor telnet:0.0.0.0:*port*,server,nowait。还要记住的是，最好对firewall进行配置，该连接是完全不进行认证和加密的，因此需要通过防火墙确保本地网络环境是可信的。\nUNIX socket\n通过-monitor unix:*socketfile*,server,nowait参数运行QEMU，之后就可以通过socat或openbsd-netcat连接到监视器上。\n例如，如果QEMU是通过如下命令启动：\n$ qemu-system-x86_64 [...] -monitor unix:/tmp/monitor.sock,server,nowait [...] 就可以像这样连接到监视器上：\n$ socat - UNIX-CONNECT:/tmp/monitor.sock 或者通过这种方式:\n$ nc -U /tmp/monitor.sock TCP\n可以使用-monitor tcp:127.0.0.1:*port*,server,nowait参数将监视器暴露于TCP端口上，然后用netcat（openbsd-netcat或gnu-netcat都可）进行连接：\n$ nc 127.0.0.1 port 注意： 为了能够从其它设备上通过TCP socket访问到监视器，而不仅仅从运行QEMU的主机上连接，需要像前面Telnet中描述的那样，在0.0.0.0地址上进行监听。\n标准 I/O\n如果以-monitor stdio参数运行QEMU，那么其实是可以在运行QEMU的终端下访问到监视器的。\n在Monitor conosle下向虚拟机发送按键行为 由于在某些配置下，宿主机可能会拦截一些按键组合另作他用，这导致要在虚拟机中触发一些特定按键组合变得有些困难（一个显然的例子就是Ctrl+Alt+F*组合，该组合用于改变当前的tty）。我们采用在monitor console下发送按键组合的方式解决该问题。只需切换到monitor console下，然后使用sendkey命令，即可将按键转发至虚拟机中，例如：\n(qemu) sendkey ctrl-alt-f2 通过 monitor console 创建快照和管理快照 注意： 该特性\u0026quot;只\u0026quot;支持qcow2格式的虚拟机磁盘镜像，对于raw是无效的。\n有时候我们很需要将虚拟机的当前状态进行保存，或是将虚拟机重置到之前的快照状态，而且最好是随时能进行这些操作。QEMU monitor console为用户提供了必要的功能，进行快照创建，快照管理，以及快照恢复。\n Use savevm name 用于创建一个名为name的快照。 Use loadvm name 用于将虚拟机状态恢复至快照name。 Use delvm name 用于删除快照name。 Use info snapshots 用于查看保存的快照列表，这些快照由一个自增长的ID和标签名（用户创建快照时赋予）进行标识。  以冻结模式运行虚拟机 QEMU支持以冻结态运行虚拟机（需使用-snapshot参数），换句话说，虚拟机关闭时，对于虚拟机的一切修改都会丢弃。当用户对磁盘镜像写入时，这些变动最终写入的位置是/tmp目录下的一个临时文件，QEMU关机时将会把他们丢弃。\n不过，即使虚拟机运行于冻结状态下，依旧可以通过monitor console将这些变化写入磁盘镜像（如果你想的话）。使用下面的命令：\n(qemu) commit all 另外如果在冻结状态下创建快照，这些快照在QEMU退出时都会被丢弃，除非你显式地commit了他们。\nmonitor console中的开机和暂停命令 在QEMU monitor console下也可以模拟对物理机的一些操作：\n system_powerdown 会向虚拟机发送ACPI关机信号，效果就类似物理机上按下电源按钮。 system_reset 会重置虚拟机，类似物理机上的重置按钮。该操作可能导致数据丢失或文件系统的损坏，这是因为虚拟机并不是\u0026quot;干净地\u0026quot;重启的。 stop 会暂停虚拟机。 cont 使暂停的虚拟机恢复运行。  虚拟机截屏 可以在monitor console下运行该命令，获取PPM格式的截屏图片：\n(qemu) screendump file.ppm QEMU 机器协议 QEMU机器协议（QMP）是一个基于JSON格式的协议，使得其他应用程序可以通过该协议控制QEMU实例。类似#QEMU 监视器，其提供了与运行中的虚拟机进行交互的能力，且能够编程进行控制。关于QMP各命令的描述可以在这个qmp-commands链接中找到。\n技巧 改善虚拟机的性能表现 底下是一些可以改善虚拟机性能表现的技术，例如：\n  启用#启用 KVM：QEMU的启动命令加上-enable-kvm选项。\n  通过-cpu host选项让QEMU模拟宿主机上的特定CPU，如果没有该选项QEMU尝试模拟的是一个更为通用的CPU。\n  特别的，如果客户机是Windows，启用Hyper-V enlightenments可以改善性能：-cpu host,hv_relaxed,hv_spinlocks=0x1fff,hv_vapic,hv_time.\n  如果宿主机有多个核心，可以用-smp选项为客户机分配更多核心。\n  检查是否为虚拟机分配的足够的内存。默认情况下，QEMU仅仅为每台虚拟机分配128MiB的内存，可以使用-m选项分配更多的内存。例如，-m 1024代表启动一台内存为1024MiB的虚拟机。\n  如果客户机操作系统支持相关的驱动，可以使用virtio创建网络设备或块设备。\n  使用TAP设备代替user-mode网络，参阅#Tap 网络。\n  如果客户机需要进行大量的磁盘写工作，在宿主机文件系统上设置合适的挂载选项可以优化该工作。例如，可以用barrier=0选项挂载一个ext4 file system。在使用这些性能强化选项之前最好阅读相关文档，因为性能上的提升通常伴随着数据完整性下降的代价。\n  如果有一块原始磁盘镜像，你可能会想要禁用cache：\n$ qemu-system-x86_64 -drive file=disk_image,if=virtio,cache=none   使用原生的Linux AIO：\n$ qemu-system-x86_64 -drive file=disk_image,if=virtio,aio=native,cache.direct=on   如果正同时运行多台虚拟机，而它们拥有同样的操作系统，可以通过启用内核页归并节省内存。参阅#开启KSM。\n  在一些情况下，可以在运行时从安装了balloon驱动的客户机上回收内存，这需要QEMU启动该客户机时使用-device virtio-balloon选项。\n  允许使用一个ICH-9 AHCI控制器的仿真层，尽管它并不稳定。AHCI的仿真模拟支持NCQ，因此可以同时处理多个读写请求：\n$ qemu-system-x86_64 -drive id=disk,file=disk_image,if=none -device ich9-ahci,id=ahci -device ide-drive,drive=disk,bus=ahci.0   参阅 https://www.linux-kvm.org/page/Tuning_KVM 获取更多信息\n开机时启动QEMU虚拟机 通过libvirt实现\n如果虚拟机是通过libvirt设置的，可以用virsh autostart将其配置为开机自启，或者通过virt-managerGUI中虚拟机的Boot Options，选择\u0026quot;Start virtual machine on host boot up\u0026quot;实现开机自启。\n通过systemd service实现\n可以用如下的systemd unit和config配置开机时启动QEMU VM。\n/etc/systemd/system/qemu@.service [Unit] Description=QEMU virtual machine [Service] Environment=\u0026quot;haltcmd=kill -INT $MAINPID\u0026quot; EnvironmentFile=/etc/conf.d/qemu.d/%i ExecStart=/usr/bin/qemu-system-x86_64 -name %i -enable-kvm -m 512 -nographic $args ExecStop=/bin/bash -c ${haltcmd} ExecStop=/bin/bash -c 'while nc localhost 7100; do sleep 1; done' [Install] WantedBy=multi-user.target 注意： 为了方便地结束任务，该service会等待至console端口被释放（这意味着VM已被关闭）。\n接着创建per-VM配置文件，命名为/etc/conf.d/qemu.d/*vm_name*，在其中设置好args和haltcmd变量，配置示例：\n/etc/conf.d/qemu.d/one args=\u0026quot;-hda /dev/vg0/vm1 -serial telnet:localhost:7000,server,nowait,nodelay \\ -monitor telnet:localhost:7100,server,nowait,nodelay -vnc :0\u0026quot; haltcmd=\u0026quot;echo 'system_powerdown' | nc localhost 7100\u0026quot; # or netcat/ncat /etc/conf.d/qemu.d/two args=\u0026quot;-hda /srv/kvm/vm2 -serial telnet:localhost:7001,server,nowait,nodelay -vnc :1\u0026quot; haltcmd=\u0026quot;ssh powermanager@vm2 sudo poweroff\u0026quot; 对该变量的描述如下：\n args - 使用的QEMU命令行参数。 haltcmd - 安全关闭虚拟机的命令，在第一个例子中，QEMU monitor是通过-monitor telnet:..选项暴露至telnet，因而关闭虚拟机是通过nc命令在monitor console中发送system_powerdown，完成ACPI关机的工作。在另一个例子里，使用的则是SSH。  若要设置启动时运行哪个虚拟机，enable qemu@*vm_name*.service这个systemd单元\n鼠标整合 添加-usb -device usb-tablet选项以避免点击客户机系统的窗口时鼠标被捕获。该选项代表QEMU能够在不捕获鼠标的情况下，向系统报告鼠标的位置，该选项启用时还会覆盖PS/2鼠标模拟功能。 命令示例：\n$ qemu-system-x86_64 -hda disk_image -m 512 -usb -device usb-tablet 宿主机的USB设备传递至虚拟机 从客户机访问连接到宿主机USB口的设备是可能的，首先需要识别设备连接的位置，可以用lsusb命令找到设备连接位置，例如：\n$ lsusb ... Bus 003 Device 007: ID 0781:5406 SanDisk Corp. Cruzer Micro U3 上面以显示的数字分别用于标识\n 003 host_bus 007 host_addr 0781 vendor_id 5406 product_id  基本的思想是在QEMU中-device usb-ehci,id=ehci或-device qemu-xhci,id=xhci分别对EHCI (USB 2)或XHCI (USB 3)（在win7无法自动安装 USB3 驱动，因此应用 USB2）控制器进行模拟，然后将物理设备通过-device usb-host,..选项进行添加。\n识别出该设备，并将其连接至任一总线以及宿主机上的地址，通用的语法如下：\n-device usb-host,bus=controller_id.0,vendorid=0xvendor_id,productid=0xproduct_id 应用于上面例子中使用的设备，它变成：\n-device usb-ehci,id=ehci -device usb-host,bus=ehci.0,vendorid=0x0781,productid=0x5406 运行QEMU时会遇到 libusb couldn't open USB device Permission denied 权限错误，可以通过 udev 为设备设定合适的权限。\n$ vi /etc/udev/rules.d/50-usbtinyisp.rules SUBSYSTEMS==\u0026#34;usb\u0026#34;, ATTRS{idVendor}==\u0026#34;0781\u0026#34;, ATTRS{idProduct}==\u0026#34;5406\u0026#34;, GROUP=\u0026#34;vane\u0026#34;, MODE=\u0026#34;0660\u0026#34; $ ls -al /dve/bus/usb/003/007 crw-rw---- 1 root vane 189, 11 Nov 7 12:37 /dev/bus/usb/003/007 使用SPICE进行USB重定向 使用#SPICE时可以将USB设备从客户端重定向至虚拟机中，无需使用QEMU命令。还支持为配置USB重定向插槽数（插槽数将决定可同时重定向的最大设备数）。相比于前面那种使用-usbdevice进行重定向的方法，SPICE方法的优势在于可以在虚拟机启动后USB设备热插拔，移除或添加USB设备时无需停机。这个方法还允许通过网络将客户端的USB设备重定向至服务端。总之，其是在QEMU虚拟机中使用USB设备最灵活的方法。\n开启KSM Kernel Samepage Merging (KSM) 是Linux内核的一个特性，允许应用程序向内核申请同其他申请页归并的进程进行页归并，KSM机制允许客户虚拟机之间进行页共享。当许多客户机运行相似的操作系统时，这个机制可以节省客观的内存。\n多屏支持 Linux的QXL驱动支持默认支持四头（虚拟屏幕），可以通过qxl.heads=N这一内核参数进行变更。\n复制和粘贴 在宿主机和客户机之间共享剪贴板的方法之一是使用SPICE远程桌面协议，通过SPICE客户端访问客户机，你需要遵照#SPICE节中描述的步骤，通过该方式运行的客户机将支持与宿主机进行复制粘贴的操作。\nQEMU-KVM Win7 环境准备   安装QEMU：sudo apt install qemu-kvm\n  下载 Windows virtio driver iso：https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/archive-virtio/virtio-win-0.1.102/，因为要将磁盘挂接为 virtio 磁盘。\n需使用 virtio-win-0.1.102，我使用最新的 virtio-win-0.1.208.iso，Windows安装程序会提示驱动没有包含签名错误No signed device drivers were found. Make sure that the installation media contains the correct drivers, and then click OK\n  创建系统盘 qemu-img create -f qcow2 Windows7-VM.img 30G，这将作为Win7的操作系统盘。\n  创建启动脚本\n$ vi start_Windows7_VM.sh #!/bin/bash DISKIMG=$HOME/.vm/Windows7-VM.img exec qemu-system-x86_64 --enable-kvm \\ \t-cpu host,hv_relaxed,hv_spinlocks=0x1fff,hv_vapic,hv_time \\ \t-drive file=${DISKIMG},if=virtio \\ \t-net nic,model=virtio-net-pci -net user,smb=$HOME/Downloads \\ \t-m 4096 \\ \t-smp cores=2,threads=4 \\ \t-monitor stdio \\ \t-vga std \\ \t-audiodev pa,id=snd0 -device ich9-intel-hda -device hda-output,audiodev=snd0 \\ \t-usb -device usb-tablet \\ \t-rtc base=localtime,clock=host \\ \t-name \u0026#39;Windows7 VM\u0026#39; \\ \t$@ $ chmod u+x start_Windows7_VM.sh   ./start_Windows7_VM.sh -boot d -cdrom $HOME/Downloads/cn_windows_7_ultimate_x64_dvd_x15-66043.iso -drive file=$HOME/Downloads/virtio-win-0.1.102.iso,index=3,media=cdrom\n  安装 Win 7  选择 Custom（advanced）  选择 CD Drive (E:) virtio-win  选择 viostor  安装 Win7 Virtio SCSI Driver  安装好以后，就可以看到安装的目标磁盘了  进入常规的 Win7 安装流程  安装 Virtio 网络驱动 但是安装失败：\n尝试 device manager 安装：\n[QEMU 的内置SMB服务器](#QEMU 的内置SMB服务器) 宿主机的USB设备传递至虚拟机 QEMU-KVM WinXP SP3 windows_xp.sh #!/bin/bash DISKIMG=$HOME/.vm/WindowsXP-VM.img exec qemu-system-x86_64 --enable-kvm \\ \t-cpu host,hv_relaxed,hv_spinlocks=0x1fff,hv_vapic,hv_time \\ \t-drive file=${DISKIMG} \\ \t-net nic,model=rtl8139 -net user,smb=$HOME/Downloads \\ \t-m 4096 \\ \t-cpu Nehalem \\ \t-rtc base=localtime,clock=host \\ \t-usb -device usb-tablet \\ \t-monitor stdio \\ \t-vga std \\ \t$@ Windows XP cannot connect to samba share You have \u0026lsquo;client min protocol = NT1\u0026rsquo; set, there is another similar setting \u0026lsquo;server min protocol\u0026rsquo; which from Samba 4.11.0 is set to SMBv2. Your XP is probably only using SMBv1, so it will not be able to see or connect to your Samba server.\nSo you have to edit the [global] section in the /etc/samba/smb.conf and add the server min protocol = NT1 option here. Then restart the Samba service.\n例如：\n$ ps h -C smbd -o pid,args 1707 /usr/sbin/smbd --foreground --no-process-group $ vim /tmp/qemu-smb.SL95F1/smb.conf [global] server min protocol = NT1 $ sudo smbcontrol 1707 reload-config 或者编写如下脚本\n#!/bin/bash echo \u0026#34;[global] server min protocol = NT1\u0026#34; \u0026gt;\u0026gt; /tmp/**/smb.conf sudo smbcontrol $(ps h -C smbd -o pid) reload-config Windows XP 上网提示：您的时钟快了/慢了 此时，无论你怎么调整日期和时间，都不能解决上网问题。即使把日期从2020年调整到2015年，此时虽然不在提示 “您的时钟快了”，也有证书期限等异常。\n出现这种问题的原因，是因为 Windows XP 确实太老了，Google Chrome、Mozilla Firefox 及其内核的浏览器已经不支持了。\nVirtual Machine Manager 键盘不能输入的问题 在 Display 中，设定 keymap，比如 en-us\n无网络 在 NIC 中，将 Device model 设置为 rtl8139\nQEMU-KVM Gentoo Configuration Host To create a disk image for the virtual machine, run:\n$ qemu-img create -f qcow2 Gentoo-VM.img 30G Download a minimal Gentoo LiveCD from here.\nSince QEMU requires a lot of options, it would be a good idea to put them into a shell script, e.g.:\n$ vim start_Gentoo_VM.sh #!/bin/bash DISKIMG=$HOME/VirtualMachine/Gentoo-VM.img exec qemu-system-x86_64 -enable-kvm \\  -bios /usr/share/edk2-ovmf/OVMF_CODE.fd \\  -cpu host \\  -drive file=${DISKIMG},if=virtio \\  -netdev user,id=vmnic,hostname=Gentoo-VM,hostfwd=tcp::10022-:22 \\  -device virtio-net,netdev=vmnic \\  -device virtio-rng-pci \\  -m 4G \\  -smp 2 \\  -monitor stdio \\  -vga std \\  -audiodev pa,id=snd0 -device ich9-intel-hda -device hda-output,audiodev=snd0 \\  -name \u0026#34;Gentoo VM\u0026#34; \\  $@ $ chmod u+x start_Gentoo_VM.sh Change the path to your disk image Gentoo-VM.img in the script. You can add more options when calling the script. To boot the disk image, run:\n$ ./start_Gentoo_VM.sh -boot d -cdrom $HOME/Downloads/install-amd64-minimal-20211107T170547Z.iso Install the guest per the Gentoo Handbook. See the guest section for optimum support. After the installation start the script without the additional options.\nUsing UEFI with QEMU UEFI for x86 QEMU/KVM VMs is called OVMF (Open Virtual Machine Firmware). It comes from EDK2 (EFI Development Kit), which is the UEFI reference implementation.\n$ sudo apt-get install ovmf 检查是否安装，命令为：\n$ dpkg -L ovmf | grep OVMF.fd /usr/share/ovmf/ OVMF.fd /usr/share/qemu/ OVMF.fd 要在虚拟机中运行操作系统的映像文件，添加 -bios /usr/share/ovmf/OVMF.fd。该代码调用名为 OVMF.fd 的文件，该文件是 Qemu 的 UEFI 固件。\n$ qemu-system-x86_64 -bios /usr/share/ovmf/OVMF.fd -cdrom ubuntu-21.04-desktop-amd64.iso 这个名为ovmf的包其实就是名为TianoCore的程序。该名称本身代表开放虚拟机固件)。\n\u0026ldquo;BdsDxe: failed to load Boot0001\u0026rdquo; solution: Try hitting F2 to enter the OVMF settings during guest boot and manually pick a new boot drive option.\nTips 通过 Qemu 安装 Windows 到硬盘 双系统新思路。今天装windows, 在linux上先用虚拟机，把硬盘直通进去，在raw盘上装好，然后更新grub, 再重启就可以直接接进去了。\n这样可以避免装机还要做启动盘，装机过程中的重启也可以避免了。\nwin的安装过程中驱动都是按照虚拟机的配置安装的，但是win10是自动装驱动的，重启进去后过了一会显卡驱动自动都装好了。\nLooking Glass Looking Glass 讓 Linux 可完美玩 Windows 遊戲 超低延遲不掉格\n當用戶安裝了虛擬電腦（VM）實行 Windows，並執行遊戲時，它採用的 KVM frame relay 技術可將 Windows 顯示記憶體，透過 PCI pass-through 直接由 Windows VM 被配置的顯示卡，複製到 Linux 被配置的顯示卡，這樣 Linux 便可在極為低延遲的情況下，接近完美顯示 Windows 遊戲的內容。\n簡單來說，就是一部 Linux 電腦裡面裝有虛擬電腦運行的 Windows，Windows 遊戲實行時，在被配置的顯示卡記憶體資料，在主機板 PCI 通道直接複製到 Linux 被配置的顯示卡。即是說 Windows 遊戲原本畫面，可高速反映到 Liunx 的虛擬電腦軟件上。這樣 Linux 用戶就算不 Dual boot 或使用兩個熒幕，在 Linux 上都可得到接近相同的打機體驗。\nxrdp xrdp 使用 RDP（Microsoft 远程桌面协议）为远程计算机提供图形登录。xrdp 接受来自各种 RDP 客户端的连接：FreeRDP、rdesktop、NeutrinoRDP 和 Microsoft 远程桌面客户端（适用于 Windows、macOS、iOS 和 Android）。\n正如 Windows 到 Windows 远程桌面一样，xrdp 不仅支持图形远程处理，还支持\n 双向剪贴板传输（文本、位图、文件） 音频重定向 驱动器重定向（在远程机器上安装本地客户端驱动器）  RDP 传输默认使用 TLS 加密。\nQEMU/KVM VS Virtualbox Linux 系统上的虚拟化解决方案 – KVM 和 VirtualBox\nKVM 提供了一些 VirtualBox 没有的功能，反之亦然。IT 世界中没有通用工具，因此使用适合您需求的工具非常重要。基本思想是：如果你想安装二进制 Linux 发行版作为来宾，使用 KVM。它速度更快，并且它的驱动程序包含在官方内核树中。如果您的客户涉及大量编译并且需要一些更高级的功能，并且/或者不是 Linux 系统，那么最好使用 VirtualBox。\n技术原因很简单：KVM 更好地与 Linux 集成，它更小更快，虽然你可以在 Linux 以外的其他客户机上使用它，但我们发现体验相当麻烦：BSD 的 I/O 和 Solaris 往往很慢（确切地说，是 OpenIndiana）在引导安装 ISO 后会立即出现恐慌。由于我们使用当前版本的 BSD（并且经常从源代码编译/更新系统）并且还需要 Solaris，我们发现 VirtualBox 是一个更好的选择。Oracle VirtualBox 的另一个优点是它支持挂起，即您可以将机器状态保存在主机的硬盘上并关闭 VirtualBox，当（重新)启动时，系统将从它离开的地方恢复。这就是为什么我们提到源代码编译：如果你有一台嘈杂的机器，你不想一夜之间离开，但你的 Gentoo 虚拟机只是编译一个新的 gcc 版本，暂停机器状态，关闭主机，明天继续。\n桌面虚拟化、KVM 还是 Virtualbox？\n这两者中的哪一个更适合在 Linux 台式机/笔记本电脑上运行 Windows 10 虚拟机？\n  带有virt-manager 的QEMU/KVM应该可以与 Virtualbox 媲美。\nVirtualbox 没问题，特别是如果跨主机操作系统使用相同的虚拟化很重要，但 QEMU/KVM 是更好的投资。QEMU/HAXM 也应该可以在 Mac 和 Windows 上运行，尽管它目前还不够成熟。\n  KVM, obviously. You\u0026rsquo;re probably going to need to learn how to manage it, but it is a much better system and allows abstraction on completely unexposed CPU hardware so you can easily take your image and put it onto another KVM. Windows doesn\u0026rsquo;t like to have it\u0026rsquo;s CPUs exchange on it very often.\n  KVM 与 VirtualBox\n  表现\n这是要考虑的最重要的领域之一，即管理程序的性能将如何影响您的基础架构。KVM 是 1 类管理程序（这些虚拟机管理程序直接运行在宿主机的硬件上来控制硬件和管理客操作系统），而 VirtualBox 是 2 类管理程序（这些虚拟机管理程序运行在传统的操作系统上，就像其他计算机程序那样运行），这意味着 KVM 应该优于 VirtualBox。\n根据SPECvirt_sc2013 基准测试，VirtualBox 通常比 KVM 需要更多时间来创建和启动服务器，而 KVM 以接近本机的速度运行应用程序，比其他行业管理程序更快。尽管对于典型负载，差异可能微不足道。\n  管理程序管理\n这两个给定的应用程序都可以通过 GUI 进行管理。Virtualbox 相对来说有更好的 GUI，但 KVM 的当前 GUI 使其管理比以往任何时候都更容易。”\n如果您更喜欢命令行，那么 KVM 中有各种命令行选项。Virtualbox 也提供了一个命令行界面，但它不如 KVM virsh 全面。您不能直接从 bash 启动 Virtualbox VM。\n  可扩展性\nKVM 继承了 Linux 的性能，如果来宾机器和请求的数量增加，可以扩展以匹配需求负载。KVM 允许对要求最苛刻的应用程序工作负载进行虚拟化，并且是许多企业虚拟化设置的基础，例如数据中心和私有云。\nVirtualBox 可以为每个 VM 提供多达 32 个虚拟 CPU，而不管主机上物理存在多少 CPU 内核。还可以为具有多达 1024 个 CPU 的主机提供支持。\n  安全\nKVM 提供增强的安全性，因为它结合使用 SELinux 和安全虚拟化 (sVirt)。VirtualBox 可以执行虚拟机的安全实时迁移和磁盘映像加密。它还包括远程桌面协议 (RDP) 身份验证和用于创建进一步身份验证要求以帮助提高安全性的 SDK。您可以在此页面上看到 Virtualbox 的安全功能列表。\n  成本和定价\nKVM 是一个开源的免费平台，由 Red Hat 等供应商提供有偿支持。虽然 Virtualbox 在限制范围内是免费的。一旦您超过一定的使用水平，您必须获得产品许可。\n  支持\n对于 KVM，您需要依赖开源社区和您自己的 IT 组织或受支持的供应商（如红帽）的支持。Oracle 正在积极开发 Virtualbox，您可以从他们那里获得任何支持。\n  libvirt Libvirt 是一组软件的汇集，提供了管理虚拟机和其它虚拟化功能（如：存储和网络接口等）的便利途径。这些软件包括：一个长期稳定的 C 语言 API、一个守护进程（libvirtd）和一个命令行工具（virsh）。Libvirt 的主要目标是提供一个单一途径以管理多种不同虚拟化方案以及虚拟化主机，包括：KVM/QEMU，Xen，LXC，OpenVZ 或 VirtualBox hypervisors。\nLibvirt 的一些主要功能如下：\n VM management（虚拟机管理）：各种虚拟机生命周期的操作，如：启动、停止、暂停、保存、恢复和迁移等；多种不同类型设备的热插拔操作，包括磁盘、网络接口、内存、CPU等。 Remote machine support（支持远程连接）：Libvirt 的所有功能都可以在运行着 libvirt 守护进程的机器上执行，包括远程机器。通过最简便且无需额外配置的 SSH 协议，远程连接可支持多种网络连接方式。 Storage management（存储管理）：任何运行 libvirt 守护进程的主机都可以用于管理多种类型的存储：创建多种类型的文件镜像（qcow2，vmdk，raw，\u0026hellip;），挂载 NFS 共享，枚举现有 LVM 卷组，创建新的 LVM 卷组和逻辑卷，对裸磁盘设备分区，挂载 iSCSI 共享，以及更多\u0026hellip;\u0026hellip; Network interface management（网络接口管理）：任何运行 libvirt 守护进程的主机都可以用于管理物理的和逻辑的网络接口，枚举现有接口，配置（和创建）接口、桥接、VLAN、端口绑定。 Virtual NAT and Route based networking（虚拟 NAT 和基于路由的网络）：任何运行 libvirt 守护进程的主机都可以管理和创建虚拟网络。Libvirt 虚拟网络使用防火墙规则实现一个路由器，为虚拟机提供到主机网络的透明访问。  安装 基于守护进程/客户端的架构的 libvirt 只需要安装在需要要实现虚拟化的机器上。注意，服务器和客户端可以是相同的物理机器。\n服务端\n安装 libvirt 以及至少一个虚拟运行环境（hypervisor）：libvirt 的 KVM/QEMU 驱动 是 libvirt 的首选驱动，如果 KVM 功能已启用，则支持全虚拟化和硬件加速的客户机。\n$ sudo apt update $ sudo apt install qemu-kvm libvirt-daemon-system 安装 libvirt-daemon-system 后，需要将用于管理虚拟机的用户添加到libvirt组中。这对于 sudo 组的成员是自动完成的，但对于应该访问系统范围的 libvirt 资源的其他任何人，都需要另外完成。这样做将授予用户访问高级网络选项的权限。\n在终端中输入：\n$ sudo adduser $USER libvirt 如果选择的用户是当前用户，您需要注销并重新登录才能使新的组成员身份生效。\n客户端\n客户端是用于管理和访问虚拟机的用户界面。\n virsh — virsh 是用于管理和配置域（虚拟机）的命令行程序。 Virtual Machine Manager — 使用libvirt对KVM，Xen，LXC进行管理的图形化工具。  配置 对于系统 级别的管理任务（如：全局配置和镜像卷 位置），libvirt 要求至少要设置授权和启动守护进程。\n注意： 对于用户会话 级别的管理任务，守护进程的安装和设置不是 必须的。授权总是仅限本地，前台程序将启动一个 libvirtd 守护进程的本地实例。\n设置授权 自 libvirt：连接授权：Libvirt 守护进程允许管理员分别为客户端连接的每个网络 socket 选择不同授权机制。这主要是通过 libvirt 守护进程的主配置文件 /etc/libvirt/libvirtd.conf 来实现的。每个 libvirt socket 可以有独立的授权机制配置。目前的可选项有 none、polkit 和 sasl。\n由于 libvirt 在安装时将把 polkit 作为依赖一并安装，所以 polkit 通常是 unix_sock_auth 参数的默认值。但基于文件的权限仍然可用。\n使用 polkit\n注意： 为使 polkit 认证工作正常，应该重启一次系统。\nlibvirt 守护进程在 polkit 策略配置文件（/usr/share/polkit-1/actions/org.libvirt.unix.policy）中提供了两种策略：\n org.libvirt.unix.manage 面向完全的管理访问（读写模式后台 socket），以及 org.libvirt.unix.monitor 面向仅监视察看访问（只读 socket）。  默认的面向读写模式后台 socket 的策略将请求认证为管理员。这点类似于 sudo 认证，但它并不要求客户应用最终以 root 身份运行。默认策略下也仍然允许任何应用连接到只读 socket。\n基于文件的权限授权\n为了给 libvirt 组用户定义基于文件的权限以管理虚拟机，取消下列行的注释：\n$ vim /etc/libvirt/libvirtd.conf #unix_sock_group = \u0026#34;libvirt\u0026#34; #unix_sock_ro_perms = \u0026#34;0777\u0026#34; # set to 0770 to deny non-group libvirt users #unix_sock_rw_perms = \u0026#34;0770\u0026#34; #auth_unix_ro = \u0026#34;none\u0026#34; #auth_unix_rw = \u0026#34;none\u0026#34; 有些资料提到可以通过改变某些特定 libvirt 目录的权限以简化管理。需要记住的是：包更新时，这些变更会丢失。如要修改这些系统目录的权限，需要 root 用户权限。\n守护进程 libvirtd.service 和 virtlogd.service这两个服务单元都要启动。可以把 libvirtd.service 设置为启用，这时系统将同时启用 virtlogd.service 和 virtlockd.socket 两个服务单元，因此后二者不必再设置为启用。\n测试 测试 libvirt 在系统级工作是否正常：\n$ virsh -c qemu:///system 测试 libvirt 在用户会话级工作是否正常：\n$ virsh -c qemu:///session 管理 绝大部分的 libvirt 管理可以通过三个工具实现：virt-manager（图形界面）、virsh 和 guestfish（它是 libguestfs 的一部分）。\nvirsh Visrsh 用于管理客户域（虚拟机），在脚本式虚拟化管理环境中工作良好。由于需要通过通讯管道与虚拟运行环境通讯，绝大部分 virsh 命令需要管理员权限。尽管如此，一些典型的管理操作如域的创建、运行等也可以像VirtualBox 那样以普通用户身份执行。\nVirsh 允许带命令行选项执行。如果不带则进入其内置的交互式终端：virsh。交互式终端支持 tab 键命令补全。\n从命令行执行：\n$ virsh [可选项] \u0026lt;命令\u0026gt; [参数]... 在交互式终端里运行：\nvirsh # \u0026lt;命令\u0026gt; [参数]... 帮助也是可用的：\n$ virsh help [option*] or [group-keyword*] 存储池 存储池是指保存卷的位置。Libvirt 中卷的定义相当于其他系统中虚拟磁盘或虚拟机镜像的概念。存储池应该是一个目录、一个网络文件系统或一个分区（此处包括 LVM）。存储池可以在活动与不活动之间切换，可以为其分配存储空间。\n以下示例为添加存储池、目录和 LVM 卷的方法：\n$ virsh pool-define-as name type [source-host] [source-path] [source-dev] [source-name] [\u0026lt;target\u0026gt;] [--source-format format] $ virsh pool-define-as poolname dir - - - - /home/username/.local/libvirt/images $ virsh pool-define-as poolname fs - - /dev/vg0/images - mntpoint 上述示例仅仅定义了存储池的信息，下面创建它：\n$ virsh pool-build poolname $ virsh pool-start poolname $ virsh pool-autostart poolname 删除它的命令：\n$ virsh pool-undefine poolname 提示： 对于 LVM 存储池而言：\n 最佳实践是仅把一个卷组分配给一个存储池。 请为存储池选择一个与 LVM 卷组不同的名字。否则当存储池被删除时，该卷组也将被删除。  用 virt-manager 新建存储池\n首先，连接到虚拟运行环境（例如QEMU/KVM的系统/用户会话）。然后，右键点击一个连接（例如QEMU/KVM）选择详情，切换到存储选项卡，点击左下角的**+**，按照向导操作。\n存储卷 存储池被创建之后，就可以在存储池中创建存储卷。如果你想新建一个域（虚拟机），那么这一步可以跳过，因为这一步可以在创建域的过程中完成。\n用 virsh 新建卷\n新建卷，列出卷，变更卷大小，删除卷：\n$ virsh vol-create-as poolname volumename 10GiB --format aw|bochs|raw|qcow|qcow2|vmdk $ virsh vol-upload --pool poolname volumename volumepath $ virsh vol-list poolname $ virsh vol-resize --pool poolname volumename 12GiB $ virsh vol-delete --pool poolname volumename $ virsh vol-dumpxml --pool poolname volumename # for details. 域 虚拟机被称作**“域”**。如果你想在命令行下操作，使用virsh列出，创建，暂停，关闭……域。virt-viewer可以用来查看使用virsh启动的域。域的创建通常以图形化的virt-manager或者命令行下的virt-install完成。 创建新域通常需要安装媒介，例如存储池中的iso文件或是直接从光驱安装。\n列出活动的和不活动的域：\n# virsh list --all 用 virt-install 新建域\n对于很详细的域（虚拟机）配置，可以用 virt-manager 新建域更简单地完成。但是，基础配置同样可以用virt-install完成并且同样运行顺利。至少要配置--name, --memory, 存储(--disk, --filesystem,或--nodisks),和安装方法（通常来说是.iso文件或CD）。查看virt-install(1)得到未列出的选项和更多的详情。\nWindows:\n$ virt-install \\  --name=windows7 \\  --memory 2048 \\  --cdrom /dev/sr0 \\  --os-variant=win7 \\  --disk /mnt/storage/domains/windows7.qcow2,size=20GiB \\  --network network=vm-net \\  --graphics spice 导入现有的卷：\n$ virt-install \\  --name demo \\  --memory 512 \\  --disk /home/user/VMs/mydisk.img \\  --import 用 virt-manager 新建域\n首先，连接到虚拟运行环境（例如 QEMU/KVM system 或用户 session，在连接上右击并选择 新建，然后跟随向导完成。\n 在第四步中取消选中立即分配全部虚拟磁盘空间会加快创建过程并节省实际虚拟磁盘空间占用；然而，这将导致将来花费额外的磁盘整理时间。 在第五步中打开高级选项并确认虚拟化类型设为 kvm（这通常是首选模式）。如果要求附加的硬件配置，选中安装前定制选项。  管理域\n启动域：\n$ virsh start domain $ virt-viewer --connect qemu:///session domain 正常关闭域；强制关闭域:\n$ virsh shutdown domain $ virsh destroy domain 在libvirtd启动时自动启动域:\n$ virsh autostart domain $ virsh autostart domain --disable 在宿主机关闭时自动关闭域:\n使用libvirt-guests.serviceSystemd服务，运行中的域可以在宿主机关闭时自动挂起/关闭。同时这个服务还可以让挂起/休眠的域在宿主机启动的时候自动恢复。查看/etc/conf.d/libvirt-guests并设置相关选项。\n编辑一个域的XML配置：\n$ virsh edit domain 注意： 直接被QEMU启动的虚拟机不被libvirt管理。\n网络 这里是有关 libvirt 网络的一个正宗的概述。\n默认情况下，当 libvirtd 服务启动后，即创建了一个名为 default 的 NAT 网桥与外部网络联通（仅 IPv4）。对于其他的网络连接需求，可创建下列四种类型的网络以连接到虚拟机：\n bridge — 这是一个虚拟设备，它通过一个物理接口直接共享数据。使用场景为：宿主机有 静态 网络、不需与其它域连接、要占用全部进出流量，并且域运行于 系统 层级。有关如何在现有默认网桥时增加另一个网桥的方法，请参阅 网桥。网桥创建后，需要将它指定到相应客户机的 .xml 配置文件中。 network — 这是一个虚拟网络，它可以与其它虚拟机共用。使用场景为：宿主机有 动态 网络（例如：NetworkManager）或使用无线网络。 macvtap — 直接连接到宿主机的一个物理网络接口。 user — 本地网络，仅用于用户 会话。  绝大多数用户都可以通过 virsh 的各种可选项创建具有各种功能的网络，一般来说比通过 GUI 程序（像 virt-manager 之类）更容易做到。也可以按用 virt-install 新建域 所述实现。\n注意： libvirt 通过 dnsmasq 处理 DHCP 和 DNS 请求，以启动每个虚拟网络的不同实例。也会为特定的路由添加 iptables 规则并启用 ip_forward 内核参数。这也意味着宿主机上已运行的dnsmasq并不是libvirt所必须的（并可能干扰到libvirt的dnsmasq实例）。\nUEFI 支持 Libvirt 可以通过 qemu 和 OVMF 来支持 UEFI 虚拟机。 安装 ovmf 。 添加下面的内容到 /etc/libvirt/qemu.conf 。\n$ vim /etc/libvirt/qemu.conf nvram = [ \u0026#34;/usr/share/ovmf/x64/OVMF_CODE.fd:/usr/share/ovmf/x64/OVMF_VARS.fd\u0026#34; ] 重启 libvirtd\n现在你可以创建一个 UEFI 虚拟机了。 你可以通过 virt-manager 来创建。当你进行到向导的最后一步时：\n 勾选在安装前自定义配置，之后点击完成。 在概况屏幕, 将固件改为\u0026rsquo;UEFI x86_64\u0026rsquo;。 点击开始安装 在启动屏幕，你需要使用linuxefi命令来启动安装程序，并且你需要在系统中运行efibootmgr验证确实运行在UEFI模式下。  VM 相关 VirtualBox 执行 .vbs 文件\n$ cscript test.vbs 删除备份\n删除虚拟机备份，当前状态前一个备份删除得快，两个备份之间的备份删除得慢。\n共享文件夹\n固定分配的共享文件夹对于定义共享文件夹的虚拟机是永久存在的；\n临时分配的共享文件夹在虚拟机运行时添加/删除，虚拟机关闭后消失。\n把img系统镜像转为VDI或VMDK格式文件\n$ VBoxManage convertdd *.img *.vdi 在 virtualbox 新建虚拟机时指定 vdi 硬盘文件，就可以安装系统\n增加现有虚拟机的磁盘大小 下面是你迟早会遇到的情况。\n你在 VirtualBox 中安装了一个或多个操作系统。在创建这些虚拟操作系统的同时，你还在 VirtualBox 中为它们创建了虚拟硬盘。\n你指定了虚拟磁盘的最大大小，比如说 15 或 20GB，但现在使用了一段时间后，你发现你的虚拟机已经没有空间了。\n虽然在 Ubuntu 和其他操作系统上有释放磁盘空间的方法，但更稳健的处理方式是增加 VirtualBox 中创建的虚拟机的磁盘大小。\n是的，你可以在 VirtualBox 中扩大虚拟硬盘，即使在创建之后也可以。虽然这是一个安全且经过测试的过程，但我们强烈建议你在执行这样的操作之前，先创建一个虚拟机的备份。\n我将向你展示如何在 VirtualBox 中以图形和命令行（对于 Linux 极客）方式调整磁盘大小。这两种方法都很简单直接。\n方法 1：在 VirtualBox 中使用虚拟媒体管理器\nVirtualBox 6 增加了一个调整虚拟磁盘大小的图形化选项。你可以在 VirtualBox 主页的文件选项卡中找到它。\n进入 “File -\u0026gt; Virtual Media Manager”：\n在列表中选择一个虚拟机，然后使用 “Size” 滑块或输入你需要的大小值。完成后点击 “Apply”。\n请记住，虽然你增加了虚拟磁盘的大小，但如果你的空间是动态分配的，那么实际的分区大小仍然不变。\n方法 2：使用 Linux 命令行增加 VirtualBox 磁盘空间\n如果你使用 Linux 操作系统作为宿主机，在宿主机中打开终端并输入以下命令来调整 VDI 的大小：\nVBoxManage modifymedium \u0026quot;/path_to_vdi_file\u0026quot; --resize \u0026lt;megabytes\u0026gt; 在你按下回车执行命令后，调整大小的过程应该马上结束。\n 注意事项\nVirtualBox 早期版本命令中的 *modifyvdi 和 modifyhd 命令也支持，并在内部映射到 modifymedium 命令。\n 如果你不确定虚拟机的保存位置，可以在 VirtualBox 主页面点击 “Files -\u0026gt; Preferences” 或使用键盘快捷键 Ctrl+G 找到默认位置。\nSeamless Mode 虚拟机通常在一个窗口中运行来宾操作系统及其程序。但是，VirtualBox和VMware都有一些功能，允许您在主机桌面上运行虚拟化程序，从而将它们从监狱中释放出来。\u0026hellip;\n这意味着您可以在不使用虚拟机窗口和来宾操作系统桌面的情况下使用程序。如果使用多个监视器，甚至可以将虚拟机中的不同窗口放置在不同的监视器上。\n工作原理\n所有这些特性都同样工作。启动虚拟机，启动您想要使用的程序，然后启用“无缝模式”或“统一模式”。来宾操作系统的桌面和虚拟机窗口将消失，将来宾操作系统的窗口留在桌面上。它们看起来正在运行，好像它们在您的主机操作系统上运行，但虚拟机仍在后台运行。程序仍然是沙盒，因此它们无法访问主机操作系统的文件——它们似乎正在主机操作系统上运行。\n无论您使用的是Windows、Linux还是Mac，这些技巧都有效。您可以在Linux桌面上无缝运行Windows程序，也可以在Windows桌面上运行Linux软件。\n使用virtualbox的无缝模式\n请注意，VirtualBox只允许您在Windows、Linux和Solaris客户机上使用此功能。如果你设法让MacOSX在VirtualBox虚拟机上运行，或者你正在使用像俳句这样的小众操作系统，你将无法使用这个功能。\n在使用此功能之前，必须在要使用的来宾虚拟机内安装VirtualBox来宾添加软件包。如果您还没有这样做，请启动虚拟机，单击“设备”菜单，然后选择“安装来宾添加”。系统将提示您安装软件。\n要使用此功能，请同时按“主机键”（通常是右Ctrl键，但它显示在虚拟机窗口的右下角）和“L”。也可以单击“视图”菜单，然后选择“切换到无缝模式”。\nVirtualBox将隐藏来宾操作系统的桌面背景，使其看起来好像来宾操作系统的程序正在主机操作系统的桌面上运行。但是，正在运行的应用程序不会出现在操作系统的标准任务栏上。\n要退出无缝模式，只需按主机键，然后再次按L。您还可以在任务栏上方找到VirtualBox菜单，您可以将鼠标悬停在上面查看。单击查看并再次选择切换到无缝模式以禁用无缝模式。\n使用vmware的unity模式\nVMware有一个类似的功能，名为Unity mode。它可以在免费的VMware Player、VMware Workstation和VMware的其他付费应用程序上使用。与VirtualBox一样，VMware的Unity模式适用于Windows和Linux客户机。\nVBox+WinXP SP3 Windows XP; Guest Additions installation stuck; Virtualbox 6.1.18\nDisconnect network. It helps me.\nvs VMWare 工具是用来解决问题的，没必要看到开源就意识形态附体\npiix4_smbus Host SMBus controller not enabled\n从内核的说明文档来看，这个 piix4 实际上是 Intel 82371AB 南桥芯片，多功能总线控制器，而在 VMware 里面并没有这个真实的芯片组，但在启动时最会尝试载入这个驱动模块，所以会报错，但对系统没有任何影响。\n虚拟机网络模式 桥接\n桥接网络是指本地物理网卡和虚拟网卡通过VMnet0虚拟交换机进行桥接，物理网卡和虚拟网卡在拓扑图上处于同等地位，那么物理网卡和虚拟网卡就相当于处于同一个网段，虚拟交换机就相当于一台现实网络中的交换机,所以两个网卡的IP地址也要设置为同一网段。\n所以当我们要在局域网使用虚拟机，对局域网其他pc提供服务时，例如提供ftp，提供ssh，提供http服务，那么就要选择桥接模式。\n例如大学宿舍里有一个路由器，宿舍里四个人连接这个路由器，路由器的wanip就不理会了，这个ip是动态获取的，而lanip默认是192.168.1.1,子网掩码是255.255.255.0。而其他四个人是自动获取ip，假设四个人的ip是:\nA:192.168.1.100/255.255.255.0,\nB:192.168.1.101/255.255.255.0\nC:192.168.1.102/255.255.255.0\nD:192.168.1.103/255.255.255.0\n那么虚拟机的ip可以设置的ip地址是192.168.1.2-192.168.1.99,192.168.1.104-192.168.1.254 (即网络地址全0和全1的除外，再除去ABCD四个人的ip地址)\n那么虚拟机的ip地址可以设置为192.168.1.98/255.255.255.0，设置了这个ip地址，ABCD这四个人就可以通过192.168.1.98访问虚拟机了，如果虚拟机需要上外网，那么还需要配置虚拟机的路由地址，就是192.168.1.1了，这样，虚拟机就可以上外网了，但是，上网我们一般是通过域名去访问外网的，所以我们还需要为虚拟机配置一个dns服务器，我们可以简单点，把dns服务器地址配置为google的dns服务器:8.8.8.8,到此，虚拟机就可以上网了。\nNAT\nNAT模式中，就是让虚拟机借助NAT(网络地址转换)功能，通过宿主机器所在的网络来访问公网。\nNAT模式中，虚拟机的网卡和物理网卡的网络，不在同一个网络，虚拟机的网卡，是在vmware提供的一个虚拟网络。\nNAT和桥接的比较:\n NAT模式和桥接模式虚拟机都可以上外网。 由于NAT的网络在vmware提供的一个虚拟网络里，所以局域网其他主机是无法访问虚拟机的，而宿主机可以访问虚拟机，虚拟机可以访问局域网的所有主机，因为真实的局域网相对于NAT的虚拟网络，就是NAT的虚拟网络的外网。 桥接模式下，多个虚拟机之间可以互相访问；NAT模式下，多个虚拟机之间也可以相互访问。  如果你建一个虚拟机，只是给自己用，不需要给局域网其他人用，那么可以选择NAT，毕竟NAT模式下的虚拟系统的TCP/IP配置信息是由VMnet8(NAT)虚拟网络的DHCP服务器提供的，只要虚拟机的网路配置是DHCP，那么你不需要进行任何其他的配置，只需要宿主机器能访问互联网即可，就可以让虚拟机联网了。\n例如你想建多个虚拟机集群，作为测试使用，而宿主机可能是一个笔记本，ip不固定。这种应用场景，我们需要采用nat模式了，但是我们要考虑一个问题，虚拟机之间是需要互访的，默认采用dhcp，虚拟机的ip每次重启，ip都是不固定的，所以我们需要手工设置虚拟机的ip地址。\nHost-Only\n在Host-Only模式下，虚拟网络是一个全封闭的网络，它唯一能够访问的就是主机。其实Host-Only网络和NAT网络很相似，不同的地方就是Host-Only网络没有NAT服务，所以虚拟网络不能连接到Internet。主机和虚拟机之间的通信是通过VMware Network Adepter VMnet1虚拟网卡来实现的。\nHost-Only的宗旨就是建立一个与外界隔绝的内部网络，来提高内网的安全性。这个功能或许对普通用户来说没有多大意义，但大型服务商会常常利用这个功能。\npodman Podman: A tool for managing OCI containers and pods.\nAndroid-x86 android x86 是一个自由而开源的项目，将谷歌制作的安卓系统从 ARM 架构移植到了 x86 架构，可以让用户在他们的桌面电脑上运行安卓系统来享受所有的安卓功能和应用程序及游戏。\n首次启动运行该安卓系统，运行：\n$ qemu-img create -f qcow2 Android8-VM.img 30G $ gedit start_Android8_VM.sh #!/bin/bash DISKIMG=/media/kurome/Ventoy/QemuKVM/Android8-VM.img exec qemu-system-x86_64 --enable-kvm \\  -hda ${DISKIMG} \\  -net nic -net user \\  -m 4096 \\  -smp cores=2,threads=4 \\  -monitor stdio \\  -vga std \\  -soundhw es1370 \\  -usb -device usb-tablet \\  -name \u0026#39;Andriod8 VM\u0026#39; \\  $@ $ chmod u+x start_Android8_VM.sh $ ./start_Android8_VM.sh -boot d -cdrom ~/Downloads/android-x86_64-9.0-r2.iso 在，安卓系统已经完全安装在你的 android.img 文件中，你应该使用下面的 QEMU 命令来启动它，而不是前面的命令：\n$ ./start_Android8_VM.sh Anbox Anbox 简介 Anbox 是 “Android in a box” 的缩写。Anbox 是一个基于容器的方法，可以在普通的 GNU/Linux 系统上启动完整的 Android 系统。\nAnbox 可以让你在 Linux 系统上运行 Android，而没有虚拟化的迟钝，因为核心的 Android 操作系统已经使用 Linux 命名空间（LXE）放置到容器中了。\nAndroid 容器不能直接访问到任何硬件，所有硬件的访问都是通过在主机上的守护进程进行的。\n每个应用程序将在一个单独窗口打开，就像其它本地系统应用程序一样，并且它可以显示在启动器中。\n安装使用 Anbox 也可作为 snap 软件包安装，请确保你已经在你的系统上启用了 snap 支持。\n为使 Anbox 工作，确保需要的内核模块已经安装在你的系统中。对于基于 Ubuntu 的用户，使用下面的 PPA 来安装它。\n$ sudo add-apt-repository ppa:morphis/anbox-support $ sudo apt update $ sudo apt install linux-headers-generic anbox-modules-dkms 在你安装 anbox-modules-dkms 软件包后，你必须手动重新加载内核模块，或需要系统重新启动。\n$ sudo modprobe ashmem_linux $ sudo modprobe binder_linux 安装 anbox。\n$ sudo apt install anbox 如果你已经在你的系统上安装 snap，其它的步骤可以忽略。\n$ sudo snap install --devmode --beta anbox 默认情况下，Anbox 并没有带有 Google Play Store。因此，我们需要手动下载每个应用程序（APK），并使用 Android 调试桥（ADB）安装它。\n$ sudo apt install android-tools-adb 既然我们不能使用 Play Store ，你就得从信得过的网站来下载 APK 软件包，像 APKMirror ，然后手动安装它。\n首先，你需要启动 ADB 服务。为做到这样，运行下面的命令。\n$ adb devices 安装语法格式：\n$ adb install Name-Of-Your-Application.apk Waydroid Waydroid是一个基于lxc容器技术，用以启动完整安卓系统的方案。\nGenymotion Android Virtual Devices for all your development \u0026amp; testing needs\nLooking Glass An extremely low latency KVMFR (KVM FrameRelay) implementation for guests with VGA PCI Passthrough.\nLibVF.IO Commodity GPU Multiplexing Driven By VFIO \u0026amp; YAML.\nWine 简介 Wine 是在x86、x86-64容许类Unix操作系统在X Window System运行Microsoft Windows程序的软件。另外，Wine也提供程序运行库（Winelib）来帮助计算机程序设计师将Windows程序移植到类Unix系统；也有不少软件经过Wine测试后发布，比如Picasa、uTorrent、MediaCoder。\nWine通过提供一个兼容层来将Windows的系统调用转换成与POSIX标准的系统调用。它还提供了Windows系统运行库的替代品和一些系统组件的替代品。为了避免著作权问题，Wine主要使用黑箱测试逆向工程来编写。\nWine最早是“Windows Emulator”，即Windows模拟器的缩写，但Wine现在为“Wine Is Not an Emulator”的递归缩写，即Wine不是模拟器。Wine的正确名称是“Wine”，而不是全大写或全小写。\nWine计划在1993年由Bob Amstadt及Eric Youngdale发起，最初目的是为了让16位Windows 3.1程序可以在Linux上执行，但随着电脑和时代的演进，Wine也一路支持到更新的Windows和64位的计算机体系结构。\n由于Windows的DLL为封闭源代码，所以程序员只能由最底层的设计开始，耗费大量的时间来编写和测试，最后达至兼容，这过程是困难且缓慢的。\n在1999年期间，当Corel加入这个计划后，Wine很快便能兼容WordPerfect Office，但Corel不久便停止支持这项计划，所以Wine的发展又逐渐趋缓，一直到2006年Google积极参与这个计划后，Wine的发展才又恢复起色，最后终于在2008年发布首个稳定版，其后便以每两周发布一个新版的速度发展着，除此之外，Google每年所举办的夏日代码大赛活动也对Wine有着不少贡献。\nWine虽然是从Linux开始发展，但现在已经支持多种平台，有BSD、Mac OS X与Solaris-x86，在2013年的自由及开源软件开发者欧洲会议上，Wine的项目领导人Alexandre Julliard（英语：Alexandre Julliard）表示目前将积极支持Android平台。\n在2008年，Wine已经能够完美运行很多知名程序，例如Lotus Notes及Microsoft Office 2007，Photoshop CS2，但其可靠性及稳定性仍有待改善。如果该程序包含本地的微软Windows系统的库，那样Wine便可很顺利运行该程序。\n有些Wine DLLs亦已能完美地取代Windows原来的DLLs，使得有些程序可完美运行。\n最晚到2006年，Wine上面已经可以完全基于Wine DLL完美地运行暴雪发行的多款3D游戏了，如魔兽世界、魔兽争霸等。\n注：以下如果使用zsh，~ 应替换为 $HOME才能正常使用\n安装 使用 Ubuntu 仓库版本\n$ sudo apt install wine 使用 wine 仓库安装最新版本\n如果您之前安装过来自其他仓库的 Wine 安装包，请在尝试安装 WineHQ 安装包之前删除它及依赖它的所有安装包（如：wine-mono、wine-gecko、winetricks），否则可能导致依赖冲突。\n如果您使用的是 64 位系统，请开启 32 bit 架构支持（如果您之前没有开启的话）：\n# Verifying you have 64-bit kernel architecture. $ dpkg --print-architecture # Verifying you have multi-arch support enabled.  $ dpkg --print-foreign-architectures # Enabling multi-arch support. $ sudo dpkg --add-architecture i386 $ sudo apt update 下载添加仓库密钥：\n$ wget -nc https://dl.winehq.org/wine-builds/winehq.key $ sudo apt-key add winehq.key 并添加 Ubuntu 20.04 仓库：\n$ sudo add-apt-repository \u0026#39;deb https://dl.winehq.org/wine-builds/ubuntu/ focal main\u0026#39; 安装：\n$ sudo apt update $ sudo apt install --install-recommends winehq-stable 配置 配置Wine的方式通常有：\n winecfg是Wine的图形界面配置程序。控制台下调用$ winecfg（或指定系统目录：$ WINEPREFIX=~/.系统目录 winecfg）即可启动 control.exe是Windows控制面板的Wine实现，通过$ wine control命令启动 regedit是Wine的注册表编辑器，比较前两者，该工具能配置更多东西。部分常用键值参见：WineHQ\u0026rsquo;s article on Useful Registry Keys  初始设置 通过全局菜单，应用程序 - \u0026gt;附件 - \u0026gt;终端 ，输入命令： winecfg 这将在你的家目录中创建一个隐藏文件夹（.wine），其中包含类似于在Windows中的虚拟C：驱动器以及注册表文件。一旦该目录中创建完，wine配置窗口将出现。该窗口将允许您定制wine的各种设置，其中包括Windows版本，DLL替换，显示设置，驱动器映射，以及应用程序的特定设置。单击OK按钮关闭该窗口。\nWINEPREFIX Wine默认将配置文件和安装的Windows程序保存在~/.wine。这样的目录称为一个\u0026quot;Wine prefix\u0026quot;或\u0026quot;Wine bottle\u0026quot;（下文称“系统目录”）。每次运行Windows程序（包括内置程序，如winecfg）时，系统目录会自动创建（如果缺失）或更新。系统目录中存放有文件夹 ~/.wine/drive_c 相当于Windows下C:\\C盘（更确切的说应是系统盘）。\n通过设置WINEPREFIX环境变量，可以更改Wine系统目录的位置。如果希望让不同的Windows程序使用不同的系统环境或配置，这一变量会非常有用。建议把你安装的不同的Windows程序分给不同的WINEPREFIX，便于打包和隔离。当你要启动这个Windows程序前也记得要设置WINEPREFIX。\n例如，如果您使用 $ env WINEPREFIX=~/.win-a wine-A程序.exe参数来运行一个程序。另一个使用 $ env WINEPREFIX=~/.win-b wine-B程序.exe参数，这两个程序将使用独立的C盘和注册表配置。\n以下命令会建立一个默认的系统目录，且不启动任何Windows程序：\n$ env WINEPREFIX=~/.customprefix wineboot -u WINEARCH 这个WINEARCH 决定了你模拟的Windows是32位或是64位的x86。对应的值为win32及win64，如果你的Unix系统是64位的它就默认是win64。\n发行版所提供的wine一般都有32位及64位两个包，直接对应所模拟的Windows位数，包里面的Unix二进制及运行库也都是对应位数。\n对于64位用户，默认创建的系统目录是64位环境的。若想使用纯32位环境，修改WINEARCH 变量win32为即可： $ WINEARCH=win32 winecfg这样就会生成32位Wine环境。若不设置WINEARCH得到的就是64位环境。\n通过WINEPREFIX变量，在不同的系统目录分别创建32位和64位环境：\n$ WINEARCH=win32 WINEPREFIX=~/win32 winecfg $ WINEPREFIX=~/win64 winecfg 注意： 系统目录创建过程中，64位版本的wine将视全部目录如同64位系统目录，也将不会在已存在的目录中创建任何32位的。创建32位系统目录，您必须让Wine创建指定的WINEPREFIX目录。\nwinetricks也接受WINEPREFIX变量，以安装Steam为例：\n$ WINEARCH=win32 WINEPREFIX=~/.local/share/wineprefixes/steam winetricks steam 编辑 ~/.bashrc，使得 WINEPREFIX 和 WINEARCH 永久生效\nexport WINEPREFIX=$HOME/.config/wine/ export WINEARCH=win32 图形驱动 你需要安装32位的显卡驱动。缺少或未能正确配置驱动的一个标志是 Wine 在终端窗口里报告如下内容：\nDirect rendering is disabled, most likely your OpenGL drivers have not been installed correctly 注意： 在安装对应的库以后，你可能需要重启 X\n声音 Wine程序有可能遇到某些声音问题。首先，确保winecfg中只启用了一种声卡驱动。目前，Wine对Alsa的支持最好。\nMIDI 支持\nMIDI 是九十年代非常流行的游戏声音系统。如果你尝试运行老一点的游戏，音乐无法开箱即用的情况并不罕见。 Wine 拥有非常优秀的 MIDI 支持。但是首先你需要确保 Wine 会使用正确的 MIDI 输出。详细设置参考 Wine Wiki\n字体 中文乱码\n将中文字体copy到对应wine的目录（本地安装的wine是~/.wine，playonlinux是.PlayOnLinux/wineprefix/对应目录）下的drive_c/windows/Fonts/。\n在wine目录下任意位置添加modify_font.reg文件：\nREGEDIT4 [HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows NT\\CurrentVersion\\FontLink\\SystemLink] \u0026#34;Lucida Sans Unicode\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;Microsoft Sans Serif\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;MS Sans Serif\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;Tahoma\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;Tahoma Bold\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;msyh\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;Arial\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; \u0026#34;Arial Black\u0026#34;=\u0026#34;SourceHanSans.ttc\u0026#34; 将SourceHanSans.ttc改成自己想改的中文字体。\n在wine命令提示符运行：\n$ regedit modify_font.reg 语言区域\n如果安装的系统LANG不为zh-CN，那么wine运行程序的默认语种也不会是中文，这可能导致一部分乱码。解决这个问题，用\n$ env LANG=zh_CN.UTF-8 wine example.exe 运行程序\n启动器和菜单 Wine不会为内置程序（如winecfg、winebrowser）创建桌面启动器和菜单项。但手动安装的Windows程序通常会自动创建启动器和菜单项。在Windows下，安装程序（如setup.exe）通常会在桌面和开始菜单建立快捷方式，而Wine下会创建遵循freedesktop.org规范的.desktop文件（即启动器，相当于快捷方式）。\n提示： 如果启动器没有自动创建，或者这些文件丢失了，可以尝试使用winemenubuilder修复。\nGnome3 中清理 Wine 菜单启动项\n系统全局的菜单启动器安装在 /usr/share/applications/，清除相应程序的“.desktop”文件即可从整个系统删除该启动器。\n如果这样还是无法解决问题，那么很可能 Wine 的启动器存放在用户级别的 ~/.local/share/applications/wine/Programs/ 目录中。删除相应的“.desktop”文件即可清理对应启动项。删除整个 Programs 文件夹将清理所有 Wine 程序的启动项。\n安装/运行/卸载 Windows 程序 警告： 千万不要以root身份运行Wine！详情参见本文。\n使用wine安装应用程序，可以按照以下步骤：\n 从某个地址下载Windows应用程序.exe（可执行文件）. 把它放在一个方便的目录（例如，桌面或个人文件夹） 打开终端，并且切换到.exe文件所在的目录。 输入命令 wine application-name.exe 。  这将使用Wine启动.EXE。如果它是一个安装程序，它应该像在windows一样的运行。如果应用程序要求目录来安装应用程序，选择把它放在 C:\\Program Files 。\n运行Windows程序格式为 WINEPREFIX=\u0026quot;wine配置文件存放地\u0026quot; wine [路径]程序.exe 参数 ，如：\n$ wine notepad.exe c:/abc.txt $ wine notepad.exe ~/.wine/drive_c/abc.txt 路径可以是Unix路径，也可以是（在有WINEPREFIX情况下的）Windows路径，wine会自动判断。\n对wine来说，你Unix系统里的其他文件（即模拟的C盘之外的文件）的Windows路径都以Z盘开头：\n$ wine notepad.exe z:/home/username/.wine/drive_c/abc.txt 内置的msiexec程序可以运行MSI安装包：\n$ [wine] msiexec /i path_to_msi 还可以通过在终端运行 winefile 使用 Wine 文件浏览器。\n在某些情况下，应用程序需要被从一个特定位置上运行。在这种情况下创建命令启动\n$ sh -c \u0026#34;cd /home/USER/.wine/drive_c/Program Files/APPDIR; wine game.exe\u0026#34; wine uninstaller 这将打开一个类似于Windows的程序“添加/删除程序”控制面板，让您卸载wine安装的应用程序。通过 wine 直接运行卸载程序也应该正常工作。或者，您也可以简单地删除应用程序的文件夹。\n技巧 提示： 此外您可能会感兴趣以下文章的开始所提供的链接\n Wine程序数据库 (Wine Application Database, AppDB) —— 特定Windows程序的Wine兼容情况（运行时的已知问题、用户评分、指南等等），Rating一列由运行结果好到坏为Platinum、Gold、Silver、Bronze、Garbage，无近期结果或近期仍然Silver以下的就放弃吧。 WineHQ论坛 —— 要是看完上述网页还有问题，可以到这里咨询  OpenGL 模式 很多游戏（比如魔兽争霸啦）都支持OpenGL模式，在Wine下可能比默认DirectX模式性能更好。一般添加-opengl启动程序即可，但不同程序可能有所不同：\n$ wine /path/to/3d_game.exe -opengl 请参考AppDB，了解特定程序的相关信息。\nWine 控制台 有些时候，可能需要运行.exe给游戏打补丁，比如给古董游戏添加宽屏支持。这时直接通过Wine运行可能没有用。那么，打开终端，运行一下命令：\n$ wineconsole cmd 将进入一个和Windows下cmd一样的命令行环境。在该环境下试试也许就可以了。\nwinetricks 使用Winetricks快速脚本，能够方便地安装许多Windows组件，包括DirectX、msxml（被Office 2007、IE浏览器依赖）visual运行库还有其他更多的。\n使用 Ubuntu 仓库版本\n$ sudo apt install winetricks 使用 Github 安装最新版本\n$ cd \u0026#34;${HOME}/.local/bin\u0026#34; $ wget https://raw.githubusercontent.com/Winetricks/winetricks/master/src/winetricks $ chmod u+x winetricks 可以用winetricks list-all来看看它支持什么。\nUsing winetricks\n获得 winetricks 后，您只需在控制台输入sh winetricks即可运行它。如果你先chmod +x winetricks ，你也可以使用./winetricks。如果不带参数运行，winetricks 会显示一个带有可用包列表的 GUI。如果您知道要安装的软件包的名称，可以将它们附加到 winetricks 命令，它将立即开始安装过程。例如，\n$ sh winetricks corefonts vcrun6 将安装 corefonts 和 vcrun6 软件包。\n所有 Wine 命令一样，winetricks 知道 WINEPREFIX 环境变量。\n$ env WINEPREFIX=~/.winetest sh winetricks mfc40 拥有多个 Wine 版本的用户可以指定 winetricks 应该使用哪个版本\n$ env WINE=~/wine-git/wine sh winetricks mfc40 使用 ~/wine-git 目录中的 Wine 安装 mfc40 包。\nMono \u0026amp; Gecko Mono 是 .NET Framework 的开源和跨平台实现。Wine 可以使用 Windows 构建的 Mono 来运行 .NET 应用程序。\nWine 实现了自己的 Internet Explorer 版本。该实现基于Mozilla 的 Gecko Layout Engine的自定义版本。\n在 USTC MIRROR 分别下载对应的版本，放入~/.cache/wine就可以了。\nCrossOver CrossOver是Wine的付费、商业化版本，提供更全面的终端用户支持。它包括脚本、补丁、GUI和可能永远不会被Wine项目接受的第三方软件。这种组合使得那些不太懂技术的人运行Windows程序变得相当容易。\n首先在 CrossOver 下载 .bin 安装包，然后要把 .bin 文件设置成可执行的：chmod u+x crossover.bin，接下来运行该文件：./crossover.bin。\n无限试用\ncrossover 有15天的试用期，crossover的时间验证信息写在每一个winebottle容器中，相互是完全隔离（不是写在全局配置中）。即使一个容器过期了，依然可以创建新的容器，并重新计算试用期，所以不需要重装软件本身。\n即使重装程序，已经过期的容器依旧不能用，不过可以删除该容器，或者删除容器下的.eval文件。\n$ rm ~/.cxoffice/**/.eval Tutorials 相对于 wine 而言，CrossOver 更加简洁方便，全程使用 GUI。\n在 Select Application 的时候，即使列表中没有列出你需要安装的 Windows 软件，依旧可以尝试使用默认的 Unlisted application，如一些 roguelike、galgame 游戏是可以直接运行的。\n如果无法运行：\n 如果报错缺少dll，这时就在网上查找一下，比如 sskin.dll，如果教程使用的 winetricks，则可以在 winetricks/files/verbs/all.txt 找到具体的依赖名称，如 Visual C++ 6 SP4 libraries，然后可以在 Select Application 输入依赖名来安装，如果下载慢，也可以通过软件显示的下载链接直接下载。 如果什么错也没报，那么就需要参考 Unsupported Troubleshooting 安装依赖或配置 winecfg，确保在安装游戏的时候没有选择升级依赖（比如 DirectX ）并且之后安装了必要的依赖项。推荐游戏自带的 CommonRedist 或在 WineHQ - Browse Applications、PlayOnLinux、PCGamingWiki 上找依赖，可以但不推荐在虚拟机中运行一下看报错。 如果先是正常运行，之后 wine 报错 page fault 退出，那么可以参考 Gathering debug logs in Crossover Linux 创建 crash log。  凡是依赖解决了，游戏一般是能够运行了，但是运行的好不好，有没有bug就不敢保证了，比如 Skul - The Hero Slayer 是可以直接运行的，但是无法正常显示血量，即使重新安装依赖也是如此。\n以下测试的是运行游戏所必须的依赖：\n  Sekiro Shadows Die Twice\n Microsoft Visual C++ 6.0 (4.2 \u0026amp; 6.0) Redistributable    The Elder Scrolls V Skyrim Special Edition\n DirectX for Modern Games 使用 SkyrimSELauncher.exe 配置，使用 SkyrimSE.exe 启动    Life is Strange - Before the Storm\n 先安装下面两个依赖，如果 FitGirl 报 Getting unarc.dll returned an error code -6，就 try using the set memory limit to 2 gb option；如果是 Miss files，那么就重装。 Microsoft Visual C++ 6.0 (4.2 \u0026amp; 6.0) Redistributable DirectX for Modern Games 游戏需要加载一会儿，这个时候屏幕没反应。    NieR - Automata\n DirectX for Modern Games 如果 unable to input name for profile creation，可以尝试将 CrossOver 升级到最新版本。    Dead Cells\n 参考 [playonlinux/dead cells](playonlinux/dead cells) 的 SourceCode 安装依赖后能够运行 DirectX for Modern Games OpenAL，安装后要在 Wine Configuration \u0026gt; Libraries 中添加 openal32（不加，点击无反应、闪退）（Libraries 中是运行时自动加载进来的库，而需要的 openal32 没有自动加载进来，因此手动添加） Microsoft Visual C++ 6.0 (4.2 \u0026amp; 6.0) Redistributable    The Binding of Isaac Rebirth Repentance\n 要在 Wine Configuration \u0026gt; Libraries 中添加 openal32（不加，点击无反应、闪退） 《以撒的結合：重生》給新玩家的基本攻略    Valiant Hearts The Great War\n Copy over the cracked content from the /Crack directory on the image to your game install directory manually.    DARK SOULS REMASTERED\n 更改语言：In the game installation folder find the \u0026ldquo;steam_emu.ini\u0026rdquo;, open it and find the line with language, change it to schinese.（在 font 目录可以找到所有语言）    Braid\n DirectX for Modern Games    Dying Light Platinum Edition\n Microsoft Visual C++ 6.0 (4.2 \u0026amp; 6.0) Redistributable    DXVK 游戏使用 Vulkan 将获取更好的性能，为使用 Vulkan，需启用 DXVK。DXVK provides a Vulkan-based translation layer for DXGI, D3D10 and D3D11, which can be used on Linux with Wine.\n打开 System Information，如果在属性下找到了 \u0026ldquo;vulkan.present\u0026rdquo;=\u0026ldquo;yes\u0026rdquo;，则表示支持 vulkan 并可以安装 DXVK。\n首先安装驱动程序\n$ sudo apt install mesa-vulkan-drivers mesa-vulkan-drivers:i386 libvulkan1 libvulkan1:i386 vulkan-utils 然后像安装普通软件那样，在 Select an Application to install 搜索并选择 DXVK (Upstream) 安装——DXVK (Builtin) 可能会导致游戏无法运行。安装后就自动启用了，也可以通过右键一个 Bottle\u0026gt;Settings\u0026gt;DXVK Vulkan backand for D3D11(Custom) 启用。\nEsync 注：Some Windows applications will not work correctly which ESync enabled. 例如 My Friend Pedro 开了后闪退，应该先保证正确运行，再考虑提升性能。\nWhat is \u0026ldquo;wine esync\u0026rdquo; and how should I set it up?\nthe thing with Far Cry 4, 3 and Primal also Dirt Rally in wine is that it massively loads wineserver and synchronizing all the time, so it is stuck at around 20 fps on ryzen, all those games mentioned. with esync, wineserver is skipped for synchronizing and eventfd is being used, thus increasing performance that much. Games that are CPU bound with wineserver having huge load (wineserver is singlethreaded) benefit the most of this\nWhat is the function of esync? Why most games need it disabled?\nThe function of esync is to provide lightweight thread synchronization facilities (events/semaphores/mutexes) so that game code that uses them heavily will run faster.\nIt does this using a linux-specific facility called eventfd, which is built around file descriptors. These are a limited resource normally not needed in large quantities, and therefore traditionally made available to a process only in moderate quantities. This helps prevent runaway processes and malicious code from consuming so many descriptors that none are left for other processes (a denial of service).\nTherefore, when a game that uses tens of thousands of thread synchronization objects is run with esync, it will fail unless the system\u0026rsquo;s per-process file descriptor limit is much higher than the traditional default. Some linux distributions have already adopted a high default, while others still default to a thousand or so. That\u0026rsquo;s why these games run fine with esync on some distributions but fail on others unless the system\u0026rsquo;s DefaultLimitNOFILE setting is increased.\nEdit: If you\u0026rsquo;re interested in esync technical issues that are not distribution-specific, check out this comment.\nHowToEsync What is Esync?\nEsync removes wineserver overhead for synchronization objects. This increases performance for a lot of games, especially ones that rely heavily on multithreading.\nA more detailed explanation can be found here.\nHow to check Esync compatibility\nSystems using Systemd 240 and newer are already compatible with Esync.\nIf you\u0026rsquo;re unsure that your system is compatible, run the ulimit -Hn command. If the value printed is equal to or greater than 524288, then your system is Esync-compatible.\nHow to make your system Esync compatible\nIf your system is not Esync-compatible (ulimit -Hn, which prints the limit for number of opened files for a process, prints a value lower than 524288, like 4096), you have 2 different methods of solving this problem. Which method is preferable depends on the distribution currently in use. Applying both methods should have no negative side effect.\n Modifying Systemd configuration  This method applies to Ubuntu and other systems using systemd. You (with root privileges or sudo) need to edit both /etc/systemd/system.conf and /etc/systemd/user.conf by adding DefaultLimitNOFILE=524288. If DefaultLimitNOFILE= already exists in both system.conf and user.conf, add 524288 after = and make sure to uncomment the line (remove the # in the beginning of the line) to make it functional.\nOnce the files are edited, restart your computer for the changes to take effect. To verify if the limits were applied, run ulimit -Hn to see 524288 being reported.\nIf the value printed still says something like 4096, try the ulimits method below.\nModifying ulimits.conf  On Linux distributions not using Systemd or distributions using pam-limits.conf (Arch Linux, Fedora, Solus,\u0026hellip; ), you (with root privileges or sudo) need to edit /etc/security/limits.conf.\nChange username to your actual username. Once the file is edited, reboot for the changes to take effect, and verify by running ulimit -Hn to see the new limit (524288).\nusername hard nofile 524288 中文乱码 注：某些游戏会因为语言设置而无法运行。\n修改步骤：打开容器 C:Drive，返回到顶层文件夹（即容器名称），即可找到cxbottle.conf，在文件最后面添加如下内容：\n[EnvironmentVariables] \u0026#34;LANG\u0026#34; = \u0026#34;zh_CN.UTF-8\u0026#34; 实例 Cemu 用 Crossover 试了一下，不能用 vulkan，很卡，鼠标延迟很高。\nOffice 2013 Pro 注：在安装前先在 AppDB 中查找要安装的应用，在 Test Results 部分有相关教程，如 Microsoft Office 2013 Test Results\n注：要提高安装成功率，第一，不同 wine 版本安装结果是不同的，AppDB 有相应的信息；第二，winetricks 如果提供安装镜像的话，一定要用该镜像，winetrics 是一个很大的脚本，打开脚本搜索 office2013pro 即可找到官方镜像下载链接；第三，如果第一次安装失败，可以再尝试安装一次。\nI installed office 2013 and I used to get a black window after starting it up. I fixed the black screen by following the solution posted in the [WineHQ-Forum](https://forum.winehq.org/viewtopic.php?f=8\u0026amp;t=28446\u0026amp;p=109296\u0026amp;hilit=office 2013#p109284).\nHere\u0026rsquo;s what I did:\nInstall Components\n$ sudo apt install winbind cabextract Create Clean 32bit Prefix for Win7\nCrete a clean 32 bit prefix and start up winecfg:\n$ env WINEPREFIX=~/.wine-office2013pro WINEARCH=win32 winecfg In the winecfg applications tab select \u0026ldquo;Windows version: Windows 7\u0026rdquo; Close wine config and install winetricks\nInstall Libraries\nThen start winetricks for your prefix\n$ env WINEPREFIX=~/.wine-office2013pro WINEARCH=win32 winetricks accept \u0026ldquo;select the default wineprefix\u0026rdquo; with OK. Now, select \u0026ldquo;Install Windows DLL components\u0026rdquo; and go and install msxml6（这个时候会下载 msxml6，可以手动下载后移动到~/.cache/winetricks中）\nTo fix the problem in PowerPoint (not enough memory), I added two overrides with winecfg in Library section: \u0026ldquo;riched20\u0026rdquo; and \u0026ldquo;usp10\u0026rdquo;.\n如果是中文软件需安装中文字体。\n在这里我直接使用 winetrics 成功安装 office2013pro（wine 6）：\n$ env WINEPREFIX=~/.wine-office2013pro WINEARCH=win32 winetricks office2013pro 这样下面步骤不需要了。\nFix Black Window\nIn order to fix the black window that impedes Office 13 to be used, add the HKCU\\Software\\Wine\\Direct3D\\MaxVersionGL new DWORD value 30002 (hexa) to the registry.\nHere\u0026rsquo;s how to do this: In Winetricks select Run regedit and wait for the Registry Editor window to open. In the folder tree expand HKEY_CURRENT_USER - Software - Wine and create a new key in the Wine folder. To do so, right click, select new\u0026ndash;\u0026gt;key and name it Direct3D. Now create new\u0026ndash;\u0026gt;DWORD Value, rename the file to MaxVersionGL and set the value data to 30002 (hexadecimal). Close the Registry Editor window.\nClose the winetricks window and run installer:\nInstall Office 2013\n$ env LANG=zh_CN.UTF-8 WINEPREFIX=~/.wine-office2013pro WINEARCH=win32 wine ~/PathTo/Office2013Setup.x86.exe From here, the install runs and completes 100%.\n安装后可以在 ~/.local/share/applications/wine 下找到 微信、QQ 的 .desktop 文件，右键编辑，将 Exec=env 行改为 Exec=env LANG=zh_CN.utf8\nWeChat Linux 安装微信的可选方案总结\n 腾讯官方 Web 版微信 Franz + 微信（基于 Web 版） Electronic-Wechat（基于 Web 版） 虚拟机 + 微信原生 PC 客户端 CrossOver + 微信原生 PC 客户端 Winetricks（基于 Wine） + 微信原生 PC 客户端 Winetricks-ZH（基于 Wine） + 微信原生 PC 客户端 AppImage + AppImage 打包构建的（Wine + 微信原生 PC 客户端） Flatpak + Flatpak 打包构建的（Deepin-Wine + 微信原生 PC 客户端） Wine + PlayonLinux + 微信原生 PC 客户端  Genshin Impact  Lutris An Anime Game Launcher 葡萄玩：跑腾讯云游戏，再用云游戏玩国服原神。  fstab /etc/fstab是用来存放文件系统的静态信息的文件。当系统启动的时候，系统会自动地从这个文件读取信息，并且会自动将此文件中指定的文件系统挂载到指定的目录。\n查看/etc/fstab\n# cat /etc/fstab \u0026lt;file system\u0026gt; \u0026lt;dir\u0026gt; \u0026lt;type\u0026gt; \u0026lt;options\u0026gt; \u0026lt;dump\u0026gt; \u0026lt;pass\u0026gt; tmpfs /tmp tmpfs nodev,nosuid 0 0 /dev/sda1 / ext4 defaults,noatime 0 1 /dev/sda2 none swap defaults,nodelalloc 0 0 /dev/sda3 /home ext4 defaults,noatime 0 2 分别解释一下各字段的用处：\n \u0026lt;file system\u0026gt; 要挂载的分区或存储设备 \u0026lt;dir\u0026gt; 挂载的目录位置 \u0026lt;type\u0026gt; 挂载分区的文件系统类型，比如：ext3、ext4、xfs、swap \u0026lt;options\u0026gt; 挂载使用的参数有哪些。举例如下：  auto - 在启动时或键入了 mount -a 命令时自动挂载。 noauto - 只在你的命令下被挂载。 exec - 允许执行此分区的二进制文件。 noexec - 不允许执行此文件系统上的二进制文件。 ro - 以只读模式挂载文件系统。 rw - 以读写模式挂载文件系统。 user - 允许任意用户挂载此文件系统，若无显示定义，隐含启用 noexec, nosuid, nodev 参数。 users - 允许所有 users 组中的用户挂载文件系统. nouser - 只能被 root 挂载。 owner - 允许设备所有者挂载。 sync - I/O 同步进行。 async - I/O 异步进行。 dev - 解析文件系统上的块特殊设备。 nodev - 不解析文件系统上的块特殊设备。 suid - 允许 suid 操作和设定 sgid 位。这一参数通常用于一些特殊任务，使一般用户运行程序时临时提升权限。 nosuid - 禁止 suid 操作和设定 sgid 位。 noatime - 不更新文件系统上 inode 访问记录，可以提升性能。 nodiratime - 不更新文件系统上的目录 inode 访问记录，可以提升性能(参见 atime 参数)。 relatime - 实时更新 inode access 记录。只有在记录中的访问时间早于当前访问才会被更新。（与 noatime 相似，但不会打断如 mutt 或其它程序探测文件在上次访问后是否被修改的进程。），可以提升性能。 flush - vfat 的选项，更频繁的刷新数据，复制对话框或进度条在全部数据都写入后才消失。 defaults - 使用文件系统的默认挂载参数，例如 ext4 的默认参数为:rw, suid, dev, exec, auto, nouser, async.   \u0026lt;dump\u0026gt; dump 工具通过它决定何时作备份。dump 会检查其内容，并用数字来决定是否对这个文件系统进行备份。 允许的数字是 0 和 1 。0 表示忽略， 1 则进行备份。大部分的用户是没有安装 dump 的 ，对他们而言 \u0026lt;dump\u0026gt; 应设为 0。 \u0026lt;pass\u0026gt; fsck 读取 \u0026lt;pass\u0026gt; 的数值来决定需要检查的文件系统的检查顺序。允许的数字是0, 1, 和2。 根目录应当获得最高的优先权 1, 其它所有需要被检查的设备设置为 2。 0 表示设备不会被 fsck 所检查。  示例：\n/dev/sda1 /mnt/LinuxOSBuckup ext4 defaults 0 2 UUID of Storage Devices Finding UUID with blkid\n$ sudo blkid Finding UUID with ls\n$ ls -l /dev/disk/by-uuid Finding UUID with lsblk\n$ sudo lsblk -f Package Management dpkg 管理软件包 dpkg 意即 Debian 包管理器（Debian PacKaGe manager）。dpkg 是一个可以安装、构建、删除及管理 Debian 软件包的命令行工具。\n其它的一些工具如 dpkg-deb 和 dpkg-query 等使用 dpkg 作为执行某些操作的前端。\n现在大多数系统管理员使用 Apt、Apt-Get 及 Aptitude 等工具，不用费心就可以轻松地管理软件。\n尽管如此，必要的时候还是需要用 dpkg 来安装某些软件。\n常见命令及文件位置 dpkg 命令的语法:\n$ dpkg [\u0026lt;option\u0026gt; ...] \u0026lt;command\u0026gt; dpkg 相关文件的位置在 /var/lib/dpkg\n/var/lib/dpkg/status 包含了被 dpkg 命令（install、remove 等）所修改的包的信息\n/var/lib/dpkg/status 包含了可用包的列表\n安装/升级软件 在基于 Debian 的系统里，用以下命令来安装 .deb 软件包。要是已经安装了软件包，就会升级它。\n$ sudo dpkg -i package.deb 从文件夹里安装软件 在基于 Debian 的系统里，用下列命令从目录中逐个安装软件。这会安装 /opt/software 目录下的所有以 .deb 为后缀的软件。\n$ sudo dpkg -iR /opt/software 显示已安装软件列表 以下命令可以列出 Debian 系的系统中所有已安装的软件，同时会显示软件版本和描述信息。\n$ dpkg -l 查看指定的已安装软件 用以下命令列出指定的一个已安装软件，同时会显示软件版本和描述信息。\n$ dpkg -l package 查看软件安装目录 以下命令可以在基于 Debian 的系统上查看软件的安装路径。\n$ dpkg -L package 查看 deb 包内容 下列命令可以查看 deb 包内容。它会显示 .deb 包中的一系列文件。\n$ dpkg -c package.deb 显示软件的详细信息 以下命令可以显示软件的详细信息，如软件名、软件类别、版本、维护者、软件架构、依赖的软件、软件描述等等。\n$ dpkg -s package 查看文件属于哪个软件 用以下命令来查看文件属于哪个软件。\n$ dpkg -S /path/file 移除/删除软件 以下命令可以用来移除/删除一个已经安装的软件，但不删除配置文件。\n$ sudo dpkg -r package 清除软件 以下命令可以用来移除/删除包括配置文件在内的所有文件。\n$ sudo dpkg -P package Debian 打包入门 deb包本身有三部分组成：\n注：原文写的不是很好，具体学习还是看官方的 Debian 新维护者手册\nCardbook 是用于管理基于 CardDav 和 vCard 标准的联系人的Thunderbird扩展。\n使用 dh_make 在当前目录下创建一个 debian 目录。\n$ dh_make\\ \t--native \\ \t--single \\ \t--packagename cardbook_1.0.0 \\ \t--email minkush@example.com 一些重要的文件，比如 control、rules、changelog、copyright 等文件被初始化其中。所创建的文件的完整列表如下：\n$ find debian debian debian/manpage.sgml.ex debian/cardbook.doc-base.EX debian/changelog debian/control debian/postrm.ex debian/postinst.ex debian/source debian/source/format debian/README.Debian debian/manpage.1.ex debian/salsa-ci.yml.ex debian/rules debian/cardbook.cron.d.ex debian/README.source debian/preinst.ex debian/prerm.ex debian/copyright debian/cardbook-docs.docs debian/README debian/manpage.xml.ex 在当前目录执行 dpkg-buildpackage -us -uc -ui 将会在上层目录创建一个空的包文件以及四个名为 .changes、.deb、 .dsc、 .tar.gz 的文件。\n .dsc 文件包含了所发生的修改和签名 .deb 文件是用于安装的主要包文件。 .tar.gz （tarball）包含了源代码。  这个过程也在 debian/cardbook/usr/share/doc/cardbook 目录下创建了 README 和 changelog 文件。它们包含了关于这个包的基本信息比如描述、作者、版本。\n检查这个包安装的内容：\n$ dpkg -c cardbook_1.0.0_amd64.deb /usr /usr/share /usr/share/doc /usr/share/doc/cardbook /usr/share/doc/cardbook/README.Debian /usr/share/doc/cardbook/changelog.gz /usr/share/doc/cardbook/copyright build-essential 在 Ubuntu 中安装构建基础包（build-essential），只需要在终端中简单输入这个命令：\n$ sudo apt update \u0026amp;\u0026amp; sudo apt install build-essential 构建基础包（build-essential）实际上是属于 Debian 的。在它里面其实并不是一个软件。它包含了创建一个 Debian 包（.deb）所需的软件包列表。这些软件包包括 libc、gcc、g++、make、dpkg-dev 等。构建基础包包含这些所需的软件包作为依赖，所以当你安装它时，你只需一个命令就能安装所有这些软件包。\n请不要认为构建基础包是一个可以在一个命令中神奇地安装从 Ruby 到 Go 的所有开发工具的超级软件包。它包含一些开发工具，但不是全部。\nPackage converter  alien：Alien is really designed to be used to convert from alien file formats to the packaging format used by the distribution you run it on. gentoo-zh：gentoo 本质是通过 bash 安装软件，因此，可以参考此仓库尝试手动安装软件。  Is linux binary universal to all kinds of distributions?\nThis is two questions:\nIs a Linux binary universal to all distributions?\nIt depends:\n If the program is using nothing outside the Linux kernel, it will be universal except for the 32- or 64-bit question. A Linux \u0026ldquo;hello world\u0026rdquo; (a minimalistic program that just prints \u0026ldquo;hello world\u0026rdquo; to a terminal window) could probably be independent of the distribution. If the program is using any non-kernel library or service (which is most of Linux, the kernel is fairly small), there are differences in which libraries are included, which versions these libraries are and where they are located. So in this (most common) case distributions are not equal.  Why do many commercial programs say that they only work on one or a few distributions?\nBecause there is a very large number of Linux distributions, and nobody wants to test their program on all of them.\nA commercial vendor will normally say that they support only the distributions they have tested their software on. It may or may not work on other distributions, from the vendor\u0026rsquo;s perspective the point is just that you can\u0026rsquo;t complain if it does not work on a distribution they don\u0026rsquo;t support.\nWhich distributions are selected for testing depends on what the vendor expects their customers to be using. Commercial/professional programs commonly pick enterprise distributions, possibly through a reasoning similar to \u0026ldquo;people who paid for their OS are more likely to pay for our software\u0026rdquo;, possibly simply by counting the distributions used by their existing customers.\nSee also Mark Shuttleworth (the guy that is the reason we have an Ubuntu in the first place) on [binary compatibility between Ubuntu and Debian](https://wiki.ubuntu.com/MarkShuttleworth#What about binary compatibility) - Debian is the closest distribution relative of Ubuntu.\nAPT Debian 使用一套名为 Advanced Packaging Tool（APT）的工具来管理包系统。在基于 Debian 的 Linux 发行版中，有各种工具可以与 APT 进行交互，以方便用户安装、删除和管理的软件包。apt-get 便是其中一款广受欢迎的命令行工具，但是最常用的命令都被分散在了 apt-get、apt-cache 和 apt-config 这三条命令当中，apt 命令的引入就是为了解决命令过于分散的问题。（简单来说就是：apt = apt-get、apt-cache 和 apt-config 中最常用命令选项的集合）\n   apt 命令 取代的命令 命令的功能     apt install apt-get install 安装软件包   apt remove apt-get remove 移除软件包   apt purge apt-get purge 移除软件包及配置文件   apt update apt-get update 刷新存储库索引   apt upgrade apt-get upgrade 升级所有可升级的软件包   apt autoremove apt-get autoremove 自动删除不需要的包   apt full-upgrade apt-get dist-upgrade 在升级软件包时自动处理依赖关系   apt search apt-cache search 搜索应用程序   apt show apt-cache show 显示装细节   apt list  列出包含条件的包（已安装，可升级等）   apt edit-sources  编辑源列表    列出所有手动安装软件 $ apt-mark showmanual 查看软件包依赖 当你在 Linux 中安装一个软件包，有时这个软件包还需要其他的软件包来使它工作正常。这些额外的软件包就叫作这个包的依赖。假如这些软件包之前没有在系统中被安装，那么这些依赖在安装这个软件包的同时会被自动安装上。\n使用 apt show 来查看依赖\n你可以使用 apt show 命令 来展示一个包的详细信息。其中依赖信息就是其中一部分，你可以在以 “Depends” 打头的那些行中看到它们。\n例如，下面展示的是使用 apt show 展示 ubuntu-restricted-extras 这个包的详细信息：\n$ apt show ubuntu-restricted-extras Package: ubuntu-restricted-extras Version: 67 ... Depends: ubuntu-restricted-addons Recommends: libavcodec-extra, ttf-mscorefonts-installer, unrar ... 如你所见，ubuntu-restricted-extras 包依赖于 ubuntu-restricted-addons 这个软件包。\n但你得小心的是依赖包还可能依赖于其他包，这样一直循环往复直到尽头。但幸好 APT 包管理器可以为你处理这些复杂的依赖关系，自动地安装所有的依赖（大多数情况下）。\n什么是推荐包？\n你注意到了上面结果输出中以 “Recommends” 开头的那些行了吗？\n推荐包不是软件包的直接依赖，但它们可以开启软件包的一些额外功能。\n正如你上面看到的那样， ubuntu-restricted-extras 包有 ttf-mscorefonts-installer 这个推荐包，用来在 Ubuntu 上安装 Microsoft 的字体。\n这些推荐包也会默认被一同安装上，假如你想显式地禁止这些推荐包的安装，你可以像下面这样使用 –-no-install-recommends 选项。\n$ sudo apt install --no-install-recommends package_name 使用 apt-cache 来直接获取依赖信息\n上面通过 apt show 的方式会获取到大量信息，假如你想在脚本中获取到依赖信息，那么 apt-cache 命令将会给你一个更好且更简洁的输出结果。\n$ apt-cache depends package_name 使用 dpkg 来查看一个 DEB 文件的依赖\napt 和 apt-cache 都作用于软件仓库中的软件包，但假如你下载了一个 DEB 文件，那么这两个命令就不起作用了。\n在这种情形下，你可以使用 dpkg 命令的 -I 或 --info 选项。\n$ dpkg -I path_to_deb_file 依赖信息就可以在以 “Depends” 开头的那些行中找到。\n使用 apt-rdepends 来查看依赖及依赖的依赖\n假如你想查看更多关于依赖的信息，那么你可以使用 apt-rdepends 工具。这个工具可以创建完整的依赖树。这样你就可以得到一个软件包的依赖以及这些依赖的依赖。\n它不是一个常规的 apt 命令，所以你需要从 universe 软件仓库中安装上它：\n$ sudo apt install apt-rdepends 这个命令的输出通常很多，取决于依赖树的大小。\neading package lists... Done Building dependency tree Reading state information... Done shutter Depends: procps Depends: xdg-utils imagemagick Depends: imagemagick-6.q16 (\u0026gt;= 8:6.9.2.10+dfsg-2~) imagemagick-6.q16 Depends: hicolor-icon-theme Depends: libc6 (\u0026gt;= 2.4) Depends: libmagickcore-6.q16-6 (\u0026gt;= 8:6.9.10.2) Depends: libmagickwand-6.q16-6 (\u0026gt;= 8:6.9.10.2) hicolor-icon-theme libc6 Depends: libcrypt1 (\u0026gt;= 1:4.4.10-10ubuntu4) Depends: libgcc-s1 libcrypt1 Depends: libc6 (\u0026gt;= 2.25) apt-rdepends 工具的功能非常多样，它还可以用来计算反向依赖。这意味着你可以查看某个特定的包被哪些软件包依赖。\n$ apt-rdepends -r package_name 输出可能会非常多，因为它将打印出反向依赖树。\n$ apt-rdepends -r ffmpeg Reading package lists... Done Building dependency tree Reading state information... Done ffmpeg Reverse Depends: ardour-video-timeline (\u0026gt;= 1:5.12.0-3ubuntu4) Reverse Depends: deepin-screen-recorder (5.0.0-1build2) Reverse Depends: devede (4.15.0-2) Reverse Depends: dvd-slideshow (0.8.6.1-1) Reverse Depends: green-recorder (\u0026gt;= 3.2.3) Repository Mirror Select the fastest mirror\nYou can use deb mirror to have the best mirror picked for you automatically.\napt-get now supports a \u0026lsquo;mirror\u0026rsquo; method that will automatically select a good mirror based on your location. Putting:\ndeb mirror://mirrors.ubuntu.com/mirrors.txt precise main restricted universe multiverse deb mirror://mirrors.ubuntu.com/mirrors.txt precise-updates main restricted universe multiverse deb mirror://mirrors.ubuntu.com/mirrors.txt precise-backports main restricted universe multiverse deb mirror://mirrors.ubuntu.com/mirrors.txt precise-security main restricted universe multiverse on the top in your /etc/apt/sources.list file should be all that is needed to make it automatically pick a mirror for you based on your geographical location.\nThe command line way\nThere are many command line tools available to find the best APT mirrors based on download speed. I have tested the following tools and they are working just fine in my Ubuntu 20.04 LTS desktop.\n Apt-select Apt-smart  apt-fast apt-fast: A shellscript wrapper for apt that speeds up downloading of packages.\n$ sudo apt-get install aria2 $ sudo add-apt-repository ppa:apt-fast/stable $ sudo apt-get update $ sudo apt-get -y install apt-fast $ sudo nano /etc/apt-fast.conf MIRRORS=(\u0026#39;https://mirrors.bfsu.edu.cn/ubuntu/,https://mirrors.tuna.tsinghua.edu.cn/ubuntu/\u0026#39;) apt-aria2 #!/bin/bash  ## apt-aria2: To help download packages faster via aria2, instead of wget. ## Author: Anjishnu Sarkar ## Version: 0.5 ## Acknowledgement: This script is a rewrite of the apt-fast script by ## Matt Parnell (admin@mattparnell.com) (http://www.mattparnell.com) ## Usage: Same as apt-get. Using the option \u0026#34;-y\u0026#34; always. ## BUG: ## *) If this script is interuppted, then next time aria2 starts downloading ## the same from the begining. Can be solved - something to do with .st file. ## TODO: ## *) Start installing via apt-get as soon as first package is downloaded ## and also keep downloading at the same time. This however might lead ## to dependencies not being satisfied. ## Initialization(s): Download=\u0026#34;False\u0026#34; Install=\u0026#34;True\u0026#34; Confirm=\u0026#34;True\u0026#34; UniqueName=\u0026#34;$RANDOM\u0026#34; Options=\u0026#34;$@\u0026#34; ## Checking for commands which requires download while test -n \u0026#34;${1}\u0026#34; do case \u0026#34;${1}\u0026#34; in install|upgrade|dist-upgrade|source|build-dep) ## Download Download=\u0026#34;True\u0026#34; ;; update|remove|autoremove|purge|dselect-upgrade|clean|autoclean|check) ## Anything other than download Download=\u0026#34;False\u0026#34; ;; -d) ## Download only (don\u0026#39;t install) Install=\u0026#34;False\u0026#34; ;; -y) ## No need to ask for confirmation Confirm=\u0026#34;False\u0026#34; ;; *) ## Nothing to be done. If any wrong options/commands are given then ## let apt-get handle it. ;; esac shift done ## In case download is true if [ \u0026#34;$Download\u0026#34; == \u0026#34;True\u0026#34; ];then ## Installing pre-requisite(s): aria2 if ! which aria2c \u0026gt; /dev/null; then echo \u0026#34;Aria2 not installed. Installing aria2 first via apt-get\u0026#34; apt-get -y --force-yes install aria2 fi ArchiveDir=/var/cache/apt/archives/ cd ${ArchiveDir}/partial PrintUris=$(apt-get --yes --print-uris ${Options}) if [ $? -ne 0 ];then echo \u0026#34;Aborting.\u0026#34; exit 1 fi PackageInfo=$(echo \u0026#34;$PrintUris\u0026#34; | awk \u0026#39;/Reading package/,/After this operation/\u0026#39;) # echo \u0026#34;$PrintUris\u0026#34; | grep ^\\\u0026#39; | cut -d\\\u0026#39; -f2 \u0026gt; \u0026#34;$UniqueName\u0026#34;-uris.txt echo \u0026#34;$PrintUris\u0026#34; | grep \u0026#34;http:\u0026#34; | cut -d\\\u0026#39; -f2 \u0026gt; \u0026#34;$UniqueName\u0026#34;-uris.txt NumberOfPackages=$(wc -l \u0026#34;$UniqueName\u0026#34;-uris.txt | awk \u0026#39;{print $1}\u0026#39;) ## Print info echo \u0026#34;$PackageInfo\u0026#34; echo \u0026#34;Number of packages to be downloaded: $NumberOfPackages\u0026#34; ## Check whether package has already been installed or not InstallUpgradeMsg=$(echo \u0026#34;$PackageInfo\u0026#34; | grep \\  -e \u0026#34;The following NEW packages will be installed:\u0026#34; \\  -e \u0026#34;The following packages will be upgraded:\u0026#34;) if [ -z \u0026#34;$InstallUpgradeMsg\u0026#34; ];then rm -f \u0026#34;$UniqueName\u0026#34;-uris.txt exit 0 fi ## In $InstallUpgradeMsg is not null, then proceed... ## If confirm is true if [ \u0026#34;$Confirm\u0026#34; == \u0026#34;True\u0026#34; ];then echo -n \u0026#34;Do you want to continue [y|n]? \u0026#34; read Ans case \u0026#34;$Ans\u0026#34; in y|yes|\u0026#34;\u0026#34;) ;; n|no|*) echo \u0026#34;Abort.\u0026#34; rm -f \u0026#34;$UniqueName\u0026#34;-uris.txt exit 1 ;; esac fi if [ $NumberOfPackages -ne 0 ];then ## Downloading the packages echo \u0026#34;Proceeding with downloading ...\u0026#34; while read DebUrl do DebName=$(basename \u0026#34;$DebUrl\u0026#34;) echo \u0026#34;$DebName\u0026#34; AptConf=\u0026#34;/etc/apt/apt.conf\u0026#34; if [ -f \u0026#34;$AptConf\u0026#34; ];then http_proxy=$(grep -i \u0026#34;http::proxy\u0026#34; \u0026#34;$AptConf\u0026#34; | cut -d \\\u0026#34; -f2) fi if [ -n \u0026#34;$http_proxy\u0026#34; ];then echo \u0026#34;Using proxy...\u0026#34; aria2c -c -s 10 -j 10 --http-proxy=$http_proxy \u0026#34;$DebUrl\u0026#34; else echo \u0026#34;Not using proxy...\u0026#34; aria2c -c -s 10 -j 10 \u0026#34;$DebUrl\u0026#34; fi if [ $? -eq 0 ];then mv $DebName ${ArchiveDir} fi done \u0026lt; \u0026#34;$UniqueName\u0026#34;-uris.txt fi rm -f \u0026#34;$UniqueName\u0026#34;-uris.txt # echo \u0026#34;Installing...\u0026#34; if [ \u0026#34;$Install\u0026#34; == \u0026#34;True\u0026#34; ];then apt-get -y --force-yes ${Options} fi else ## Cases when download is false apt-get ${Options} fi PPA 软件仓库是一组文件，其中包含各种软件及其版本的信息，以及校验和等其他一些详细信息。每个版本的 Ubuntu 都有自己的四个官方软件仓库：\n Main - Canonical 支持的自由开源软件。 Universe - 社区维护的自由开源软件。 Restricted - 设备的专有驱动程序。 Multiverse - 受版权或法律问题限制的软件。  你可以在 这里 看到所有版本的 Ubuntu 的软件仓库。你可以浏览并转到各个仓库。\n这些信息存储在系统的 /etc/apt/sources.list 文件中。如果查看此文件的内容，你就会看到里面有软件仓库的网址。# 开头的行将被忽略。\nUbuntu 不会在官方仓库中立即提供新版本的软件。他们需要一个步骤来检查此新版本的软件是否与系统兼容，从而可以确保系统的稳定性。这意味着它需要经过几周才能在 Ubuntu 上可用，在某些情况下，这可能需要几个月的时间。\n为获取最新版本的软件，需要使用 PPA，PPA (Personal Package Archives) 允许开发者上传要构建的 Ubuntu 源包，并通过 Launchpad 作为 apt 的软件仓库发布。\n通过如下命令添加 PPA 软件仓库并获取最新版本软件：\n$ sudo add-apt-repository \u0026lt;PPA_info\u0026gt; $ sudo apt-get update $ sudo apt-get install \u0026lt;package_in_PPA\u0026gt; 当你使用 PPA 时，它不会更改原始的 sources.list 文件。相反，它在 /etc/apt/sources.d 目录中创建了两个文件，一个 .list 文件和一个带有 .save 后缀的备份文件。这是一种安全措施，可以确保添加的 PPA 不会和原始的 sources.list 文件弄混，它还有助于移除 PPA。\n开发人员为他们的软件创建的 PPA 称为官方 PPA。但有时，个人会创建由其他开发人员所创建的项目的 PPA。为什么会有人这样做？ 因为许多开发人员只提供软件的源代码。\n如果 PPA 不适用于你的系统版本，你可以点击应用程序 PPA 页面的 View package details，在这里，你可以单击软件包以显示更多详细信息，还可以在此处找到包的源代码和 DEB 文件。建议 使用 Gdebi 安装这些 DEB 文件 而不是通过软件中心，因为 Gdebi 在处理依赖项方面要好得多。\n就安全性而言，很少见到因为使用 PPA 之后你的 Linux 系统被黑客攻击或注入恶意软件。到目前为止，我不记得发生过这样的事件。官方 PPA 可以不加考虑的使用，使用非官方 PPA 完全是你自己的决定。根据经验，如果程序需要 sudo 权限，则应避免通过第三方 PPA 进行安装。\nSnap \u0026amp; Flatpak A fundamental difference between Snap and Flatpak\nFlatpak is designed to install and update “apps”; user-facing software such as video editors, chat programs and more.\nsnaps can install anything which contains a kernel, printer drivers, audio subsystems and more.\nSnap and Flatpak are the software behind two universal Linux app stores: the Snap Store and Flathub.\n讨论 openSUSE 群\nFlatpak使用bubblewrap来隔离应用程序，bwrap是非常轻量化的沙箱程序，因此攻击面极小。但bwrap需要用户对Linux程序工作方式有准确的了解（使用哪些syscall），Flatpak相当于充当了一个bwrap的前端帮助控制bwrap权限。\n目前Flatpak的问题在于seccomp权限太过广泛，但目前Flatpak维护者已经意识到了这个问题（注释：在他们踩了一次坑之后），已经计划打算解决了。\n另一个问题是程序请求的权限过于广泛，但这更多是一个决策问题而不是技术问题，而且你可以用Flatseal手动调整权限。\nFlatpak你不能用常规程序方式来理解，每个程序都是一个完全独立的空间，只有给予了权限才有对应访问权，也可以用Portals调用文件选择器来获得单独一个文件的完全访问权，Flatpak版的Steam是把所有程序配置文件放在~/.var/app里面了，类似安卓下面的分区存储做法。\nAppImage就只是个自挂载程序，自带的文件透明挂载到它自己的根文件系统下面，所以依然依赖主机的一部分库。所以是的，跟打包者用的系统有关系。\nFlatpak不是这种机制，每个Flatpak空间是完全空白的，需要打包者自己选择加入哪些东西，所以Flatpak跨发行版的兼容性也更好。\n良好打包的AppImage可以有很好的跨发行版兼容性，但是代价就是需要手工测试每个发行版下面的效果。在跨发行版兼容性这点上我更看好Flatpak。\n最后，不要跟我提Snap，我不想碰那个东西，也对它没有研究的兴趣。\nFlatpak确实有很多可取之处，或者不能说是Flatpak可取，而是Linux桌面软件生态现状决定了，只有更激进的手段才能改变现状。\nAppImage那种策略还是过于不痛不痒了，结果就是程序仅仅是被打包成一个个单文件，但背后的库依赖地狱、权限隔离问题一个都没解决。\n但AppImage作者的想法本来也不是靠AppImage颠覆，他是希望Linux能够重新恢复LSB，确保发行版之间的兼容性本身可靠而不是依赖Flatpak这些技术，就类似于Windows上的软件不需要什么沙箱模拟器，你几乎可以保证旧版本的软件能在新版本运行。\n其实也可以说明，微软那种在桌面上采取的策略，很可能难以在Linux社区里推广开来，微软那种做法，确保绝对的向下兼容性，不是谁都有精力来做的。\n比如说如果让微软来做Wayland，那微软根本就不会把Wayland做出来，而是把X11一直迭代、削减臃肿功能直到性能和现代化图形技术栈的性能相匹敌，同时确保向下兼容性。而最新一代的X11很可能和最早的X11已经彻底不一样了，甚至会有“检测程序版本然后自动匹配对应的X11功能”这些奇怪的兼容性策略出来。或许有一天微软会把新项目叫做Wayland，但这个改名也仅仅是营销目的而不是技术目的。\n毕竟LSB已经没了，Ubuntu甚至砍掉32位兼容性，也可以说明其实Linux这边并没有太多人在乎这问题。\n毕竟“反正源代码都在那，重新编译一遍不就好了吗”\nFedora 群\n空のあお, [2/28/22 8:25 PM] 软件有不同版本的依赖 这些依赖很难共存 有些旧版依赖还有更旧的依赖 不说二进制兼容，有些连源码兼容都搞不定 就算搞定了，一段时间过后依赖升级了，还是得坏 flatpak的做法是维护abi稳定的qt和gtk两大ui库和必要桌面库的runtime，用来公用 通过容器隔离app，让每个app自己构建所需的特定依赖到容器里\n竹林里有冰, [2/28/22 8:33 PM] sandbox他是用bubblewrap实现的吧，你可以直接使用bubblewrap，应该一样可以做到他的沙盒化，更小巧一点 bubblewrap的缺点就是需要针对每个程序写上配置，除了有点麻烦其他倒还不错\nNeomonk Zen, [2/28/22 8:36 PM] 也不知flatpak的软件仓库，有没什么审核机制来防止恶意软件，如果没有的话，那还蛮可怕的，想想Chrome和Android的软件市场，都有很多恶意软件\nRobin Lee, [2/28/22 8:39 PM] 没有深入的审核，跟各大发行版的官方包差不多，但flatpak可以限制应用权限\n在 Ubuntu 上使用 Flatpak The official Flatpak PPA is the recommended way to install Flatpak. To install it, run the following in a terminal:\n$ sudo add-apt-repository ppa:flatpak/stable $ sudo apt update $ sudo apt install flatpak Flathub is the best place to get Flatpak apps. To enable it, run:\n$ flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo To complete setup, restart your system. Now all you have to do is install some apps!\nQuestions snap \u0026ldquo;canonical-livepatch\u0026rdquo; has \u0026ldquo;install-snap\u0026rdquo; change in progress\nSnap 包是 Ubuntu 16.04 LTS 发布时引入的新应用格式包。目前已流行在很多 Linux 发行版上。并且可以很方便地安装常用软件，如 VLC、Sublime Text、VSCode、Node、WPS等\n当你在安装完 Snap 后，你会发现在在根目录下会出现如 /dev/loop0 的挂载点，这些挂载点正是 Snap 软件包的目录。\n  原因是软件之前安装了一次，只是安装失败。\n$ snap changessnap abort 5\t## 5 为安装失败软件的 ID   现在重新安装\n  一些软件最好在官网下载或在 Snap 中下载，官方 Repository 可能并不新，比如 VLC。\ntasksel: Install Group Software 安装\n$ sudo apt install tasksel list tasks\n$ tasksel --list-tasks displays description\n$ tasksel --task-desc dns-server install\n$ sudo apt install dns-server pacstall An AUR-inspired package manager for Ubuntu\nAppImage Linux apps that run anywhere\n包管理器的进化 今天，每个可计算设备都会使用某种软件来完成预定的任务。在软件开发的上古时期，为了找出软件中的 bug 和其它缺陷，软件会被严格的测试。在近十年间，软件被通过互联网来频繁分发，以试图通过持续不断的安装新版本的软件来解决软件的缺陷问题。在很多情况下，每个独立的应用软件都有其自带的更新器。而其它一些软件则让用户自己去搞明白如何获取和升级软件。\nLinux 较早采用了维护一个中心化的软件仓库来发布软件更新这种做法，用户可以在这个软件仓库里查找并安装软件。在这篇文章里， 笔者将回顾在 Linux 上的如何进行软件安装的历史，以及现代操作系统如何保持更新以应对软件安全漏洞（CVE）不断的曝光。\n手动安装软件 曾几何时，软件都是通过 FTP 或邮件列表（LCTT 译注：即通过邮件列表发布源代码的补丁包）来分发的（最终这些发布方式在互联网的迅猛发展下都演化成为一个个现今常见的软件发布网站）。（一般在一个 tar 文件中）只有一个非常小的文件包含了创建二进制的说明。你需要做的是先解压这个包，然后仔细阅读当中的 README 文件， 如果你的系统上恰好有 GCC（LCTT 译注：GNU C Compiler）或者其它厂商的 C 编译器的话，你得首先运行 ./configure 脚本，并在脚本后添加相应的参数，如库函数的路径、创建可执行文件的路径等等。除此之外，这个配置过程也会检查你操作系统上的软件依赖是否满足安装要求。如果缺失了任何主要的依赖，该配置脚本会退出不再继续安装，直到你满足了该依赖。如果该配置脚本正常执行完毕，将会创建一个 Makefile 文件。\n当有了一个 Makefile 文件时， 你就可以接下去执行 make 命令（该命令由你所使用的编译器提供）。make 命令也有很多参数，被称为 make 标识flag，这些标识能为你的系统优化最终生成出来的二进制可执行文件。在计算机世界的早期，这些优化是非常重要的，因为彼时的计算机硬件正在为了跟上软件迅速的发展而疲于奔命。今日今时，编译标识变得更加通用而不是为了优化哪些具体的硬件型号，这得益于现代硬件和现代软件相比已经变得成本低廉，唾手可得。\n最后，在 make 完成之后， 你需要运行 make install （或 sudo make install）（LCTT 译注：依赖于你的用户权限） 来“真正”将这个软件安装到你的系统上。可以想象，为你系统上的每一个软件都执行上述的流程将是多么无聊费时，更不用说如果更新一个已经安装的软件将会多复杂，多么需要精力投入。（LCTT 译注：上述流程也称 CMMI 安装， 即Configure、Make、Make Install）\n软件包 package（LCTT 译注：下文简称“包”）这个概念是用来解决在软件安装、升级过程中的复杂性的。包将软件安装升级中需要的多个数据文件合并成一个单独的文件，这将便于传输和（通过压缩文件来）减小存储空间（LCTT 译注：减少存储空间这一点在现在已经不再重要），包中的二进制可执行文件已根据开发者所选择的编译标识预编译。包本身包括了所有需要的元数据，如软件的名字、软件的说明、版本号，以及要运行这个软件所需要的依赖包等等。\n不同流派的 Linux 发行版都创造了它们自己的包格式，其中最常用的包格式有：\n .deb：这种包格式由 Debian、Ubuntu、Linux Mint 以及其它的变种使用。这是最早被发明的包类型。 .rpm：这种包格式最初被称作红帽包管理器Red Hat Package Manager（LCTT 译注： 取自英文的首字母）。使用这种包的 Linux 发行版有 Red Hat、Fedora、SUSE 以及其它一些较小的发行版。 .tar.xz：这种包格式只是一个软件压缩包而已，这是 Arch Linux 所使用的格式。  尽管上述的包格式自身并不能直接管理软件的依赖问题，但是它们的出现将 Linux 软件包管理向前推进了一大步。\n软件仓库 多年以前（当智能电话还没有像现在这样流行时），非 Linux 世界的用户是很难理解软件仓库的概念的。甚至今时今日，大多数完全工作在 Windows 下的用户还是习惯于打开浏览器，搜索要安装的软件（或升级包），下载然后安装。但是，智能电话传播了软件“商店”（LCTT 译注： 对应 Linux 里的软件仓库）这样一个概念。智能电话用户获取软件的方式和包管理器的工作方式已经非常相近了。些许不同的是，尽管大多数软件商店还在费力美化它的图形界面来吸引用户，大多数 Linux 用户还是愿意使用命令行来安装软件。总而言之，软件仓库是一个中心化的可安装软件列表，上面列举了在当前系统中预先配置好的软件仓库里所有可以安装的软件。\n包管理器 包管理器用来和相应的软件仓库交互，获取软件的相应信息。下面对流行做一个简短介绍。\n基于 PRM 包格式的包管理器 更新基于 RPM 的系统，特别是那些基于 Red Hat 技术的系统，有着非常有趣而又详实的历史。实际上，现在的 YUM 版本（用于 企业级发行版）和 DNF（用于社区版）就融合了好几个开源项目来提供它们现在的功能。\nRed Hat 最初使用的包管理器，被称为 RPM（红帽包管理器Red Hat Package Manager），时至今日还在使用着。不过，它的主要作用是安装本地的 RPM 包，而不是去在软件仓库搜索软件。后来开发了一个叫 up2date 的包管理器，它被用来通知用户包的最新更新，还能让用户在远程仓库里搜索软件并便捷的安装软件的依赖。尽管这个包管理器尽职尽责，但一些社区成员还是感觉 up2date 有着明显的不足。\n现在的 YUM 来自于好几个不同社区的努力。1999-2001 年一群在 Terra Soft Solution 的伙计们开发了Yellowdog Updater（YUP），将其作为 Yellow Dog Linux 图形安装器的后端。杜克大学Duke University喜欢这个主意就决定去增强它的功能，它们开发了Yellowdog Updater, Modified（YUM），这最终被用来帮助管理杜克大学的 Red Hat 系统。Yum 壮大的很快，到 2005 年，它已经被超过一半的 Linux 市场所采用。今日，几乎所有的使用 RPM 的的 Linux 都会使用 YUM 来进行包管理（当然也有一些例外）。\nDandified Yum（DNF）是 YUM 的下一代接班人。从 Fedora 18 开始被作为包管理器引入系统，不过它并没有被企业版所采用，所以它只在 Fedora（以及变种）上占据了主导地位。DNF 的用法和 YUM 几乎一模一样，它主要是用来解决性能问题、晦涩无说明的API、缓慢/不可靠的依赖解析，以及偶尔的高内存占用。DNF 是作为 YUM 的直接替代品来开发的，因此这里笔者就不重复它的用法了，你只用简单的将 yum 替换为 dnf 就行了。\nZypper 是用来管理 RPM 包的另外一个包管理器。这个包管理器主要用于 SUSE（和 openSUSE），在MeeGo、Sailfish OS、Tizen 上也有使用。它最初开发于 2006 年，已经经过了多次迭代。除了作为系统管理工具 YaST 的后端和有些用户认为它比 YUM 要快之外也没有什么好多说的。\n基于 Debian 的包管理器 作为一个现今仍在被积极维护的最古老的 Linux 发行版之一，Debian 的包管理系统和基于 RPM 的系统的包管理系统非常类似。它使用扩展名为 “.deb” 的包，这种文件能被一个叫做 dpkg 的工具所管理。dpgk 同 rpm 非常相似，它被设计成用来管理在存在于本地（硬盘）的包。它不会去做包依赖关系解析（它会做依赖关系检查，不过仅此而已），而且在同远程软件仓库交互上也并无可靠的途径。为了提高用户体验并便于使用，Debian 项目开始了一个软件项目：Deity，最终这个代号被丢弃并改成了现在的 Advanced Pack Tool（APT）。\n在 1998 年，APT 测试版本发布（甚至早于 1999 年的 Debian 2.1 发布），许多用户认为 APT 是基于 Debian 系统标配功能之一。APT 使用了和 RPM 一样的风格来管理仓库，不过和 YUM 使用单独的 .repo 文件不同，APT 曾经使用 /etc/apt/sources.list 文件来管理软件仓库，后来的变成也可以使用 /etc/apt/sources.d 目录来管理。如同基于 RPM 的系统一样，你也有很多很多选项配置来完成同样的事情。你可以编辑和创建前述的文件，或者使用图形界面来完成上述工作（如 Ubuntu 的“Software \u0026amp; Updates”）。\n现今大多数的 Ubuntu 教程里都径直使用了 apt。 单独一个 apt 设计用来实现那些最常用的 APT 命令的。apt 命令看上去是用来整合那些被分散在 apt-get、apt-cache 以及其它一些命令的的功能的。它还加上了一些额外的改进，如色彩、进度条以及其它一些小功能。\n基于 Arch 的包管理器 Arch Linux 使用称为 packman 的包管理器。和 .deb 以及 .rpm 不同，它使用更为传统的 LZMA2 压缩包形式 .tar.xz 。这可以使 Arch Linux 包能够比其它形式的压缩包（如 gzip）有更小的尺寸。自从 2002 年首次发布以来， pacman 一直在稳定发布和改善。使用它最大的好处之一是它支持 Arch Build System，这是一个从源代码级别构建包的构建系统。该构建系统借助一个叫 PKGBUILD 的文件，这个文件包含了如版本号、发布号、依赖等等的元数据，以及一个为编译遵守 Arch Linux 需求的包所需要的带有必要的编译选项的脚本。而编译的结果就是前文所提的被 pacman 所使用的 .tar.xz 的文件。\n上述的这套系统技术上导致了 Arch User Respository（AUR）的产生，这是一个社区驱动的软件仓库，仓库里包括有 PKGBUILD 文件以及支持补丁或脚本。这给 Arch Linux 带了无穷无尽的软件资源。最为明显的好处是如果一个用户（或开发者）希望他开发的软件能被广大公众所使用，他不必通过官方途径去在主流软件仓库获得许可。而不利之处则是它必须将依赖社区的流程，类似于 Docker Hub、 Canonical 的 Snap Packages（LCTT 译注： Canonical 是 Ubuntu 的发行公司），或者其它类似的机制。\n有很多特定于 AUR 的包管理器能被用来从 AUR 里的 PGKBUILD 文件下载、编译、安装。其中 yaourt 和 pacaur 颇为流行。不过，这两个项目已经被 Arch Wiki 列为“不继续开发以及有已知的问题未解决”。因为这个原因，这里直接讨论 aurman，除了会搜索 AUR 以及包含几个有帮助的（其实很危险）的选项之外，它的工作机制和 pacman 极其类似。\nconda 简介 Conda 是一个开源的软件包管理系统和环境管理系统，用于安装多个版本的软件包及其依赖关系，并在它们之间轻松切换。 Conda 是为 Python 程序创建的，适用于 Linux，OS X 和 Windows，也可以打包和分发其他软件。\n安装 conda分为anaconda和miniconda。anaconda是包含一些常用包的版本（这里的常用不代表你常用），miniconda则是精简版，需要啥装啥，所以推荐使用miniconda。\nminiconda官网：https://conda.io/miniconda.html\n选择适合自己的版本下载：\n$ wget -c https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh 这里选择的是latest-Linux版本，所以下载的程序会随着python的版本更新而更新。\n安装：\n$ chmod 777 Miniconda3-latest-Linux-x86_64.sh $ bash Miniconda3-latest-Linux-x86_64.sh 加不加入环境变量都可以。所谓的会污染环境等等问题可能都是将大量的软件直接安装在conda的base环境中引起的，只要养成好的使用习惯，灵活使用conda create 命令将不同的软件安装到自己单独的虚拟环境中就可以了。把conda这条蟒蛇关进一个一个的笼子里，才能更好的为我们的科研服务~\n添加频道 这个道理跟家里的电视机是一样一样的，安装conda就相当于买了一台电视机，但是有电视了不意味着你就能看节目了，你要手动添加频道才能看你想看的电视节目。\n添加清华的镜像channels：\n$ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ $ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ $ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ $ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ 为了分担清华源镜像的压力，北京外国语大学也开启了镜像站点，同样是由清华TUNA团队维护的，如果有小伙伴遇到清华源速度很慢的情况的话，可以考虑换成北外的镜像。\n$ conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/cloud/bioconda/ $ conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/cloud/conda-forge/ $ conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/free/ $ conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/main/ 显示安装的频道\n$ conda config --set show_channel_urls yes 查看已经添加的channels\n$ conda config --get channels 已添加的channel在哪里查看\n$ vim ~/.condarc 软件包管理 $ conda install gatk 搜索安装包 $ conda search gatk 安装完成后，可以用“which 软件名”来查看该软件安装的位置：\n$ which gatk 安装特定版本 $ conda install 软件名=版本号 $ conda install gatk=3.7 这时conda会先卸载已安装版本，然后重新安装指定版本。\n查看已安装软件 $ conda list 更新指定软件 $ conda update gatk 卸载指定软件 $ conda remove gatk 环境管理 退出conda环境 退出也很简单，之前我们是. ./activate 或者 (. ~/miniconda3/bin/activate)现在退出只要:\n$ . ./deactivate # 或者用  $ conda deactivate 就退出当前的环境了\n创建conda环境 之前创建的时候显示的是（base）这是conda的基本环境，有些软件依赖的是python2的版本，当你还是使用你的base的时候你的base里的python会被自动降级，有可能会引发别的软件的报错，所以，可以给一些特别的软件一些特别的关照，比如创建一个单独的环境。\n在conda环境下，输入conda env list（或者输入conda info --envs也是一样滴）查看当前存在的环境：\n$ conda env list 创建一个新的环境\n$ conda create -n python2 python=2  -n: 设置新的环境的名字 python=2 指定新环境的python的版本，非必须参数 这里也可以用一个-y参数，可以直接跳过安装的确认过程。  conda会创建一个新的python2的环境，并且会很温馨的提示你只要输入conda activate python2就可以启动这个环境了。\n删除环境 $ conda remove -n myenv --all 重命名环境 实际上conda并没有提供这样的功能，但是可以曲线救国，原理是先克隆一个原来的环境，命名成想要的名字，再把原来的环境删掉即可\n接下来演示把一个原来叫做py2的环境重新命名成python2：\n$ conda create -n python2 --clone py2 $ conda remove -n py2 --all 自动更新 Ubuntu 默认的配置会每天自动安装安全更新而忽略其它包的更新。\n更新机制 Ubuntu 默认定义了 4 个 systemd unit 执行更新任务，它们分别是：\n/lib/systemd/system/apt-daily-upgrade.service /lib/systemd/system/apt-daily-upgrade.timer /lib/systemd/system/apt-daily.service /lib/systemd/system/apt-daily.timer 中的 apt-daily.timer 和 apt-daily-upgrade.timer 是两个触发器，分别在每天指定的时间触发 apt-daily.service 和 apt-daily-upgrade.service。这两个 service 的类型都是 oneshot，意思是当任务完成后 service 进程退出。这两个 service 其实调用的是同一个脚本： /usr/lib/apt/apt.systemd.daily。apt-daily.service 为脚本传入参数 \u0026ldquo;update\u0026rdquo;，其功能为检查系统的更新并下载对应的更新包。apt-daily-upgrade.service 为脚本传入参数 \u0026ldquo;install\u0026rdquo;，其功能为安装更新并删除缓存在本地的更新包。\napt-daily.timer 默认每天触发两次，分别为 6 点和 18 点，主要是为了缓解服务器端的下载压力。我们可以根据自身业务的特点设置合适的触发时间。\napt-daily-upgrade.service 默认每天在 6 点触发一次，我们也可以设置为其它时间，比如午夜。\napt.systemd.daily /usr/lib/apt/apt.systemd.daily 脚本负责完成与更新相关的一系列工作，这些工作主要分为两大块：\n 检查更新并下载更新包 安装更新并清理更新包  apt.systemd.daily 脚本中调用 apt-config 命令从 /etc/apt/apt.conf.d/10periodic 文件和 /etc/apt/apt.conf.d/20auto-upgrades 读中取配变量，并根据这些变量的值来控制系统的更新策略。下面我们介绍几个比较重要的配置项。\n隔多少天执行一次 apt-get update，默认是 1 天，0 表示不执行该操作：\nAPT::Periodic::Update-Package-Lists \u0026#34;1\u0026#34;; 隔多少天执行一次 apt-get upgrade \u0026ndash;download-only 下载更新包，0 表示不执行该操作：\nAPT::Periodic::Download-Upgradeable-Packages \u0026#34;0\u0026#34;; 下载的更新版被缓存在目录 /var/cache/apt/archives/ 中，执行升级操作时直接从缓存目录中读取包文件而不是从网络上下载。\n隔多少天执行一次 apt-get autoclean 清除无用的更新包，0 表示不执行该操作：\nAPT::Periodic::AutocleanInterval \u0026#34;0\u0026#34;; 隔多少天执行一次 Unattended-Upgrade 执行系统安全更新(或者所有包的更新)，0 表示不执行该操作：\nAPT::Periodic::Unattended-Upgrade \u0026#34;1\u0026#34;; 通过这些配置，我们可以控制自动更新的频率和行为。注意，到目前为止的配置还只能安装系统的安全更新，如果要想安装所有包的更新还需要其它的配置。\n在继续介绍后面的内容前，让我们先来了解一下 apt.systemd.daily 脚本中用到的 apt-config 命令和 apt.systemd.daily 脚本依赖的配置文件。\napt-config 命令\napt-config 是一个被 APT 套件使用的内部命令，使用它可以在脚本中提取 /etc/apt/apt.conf 目录下配置文件中的信息。\n比如，如果要在脚本中获取 APT::Periodic::Update-Package-Lists 的设置，可以使用下面的代码：\n#!/bin/bash ABC=0 eval $(apt-config shell ABC APT::Periodic::Update-Package-Lists) echo ${ABC} 此时脚本变量 ABC 中保存的就是 APT::Periodic::Update-Package-Lists 的值。\n10periodic 和 20auto-upgrades\n/etc/apt/apt.conf.d/10periodic 是 update-notifier-common 的配置文件：\n$ dpkg-query -S /etc/apt/apt.conf.d/10periodic update-notifier-common: /etc/apt/apt.conf.d/10periodic 在 ubuntu 16.04 和 18.04 中，这两个文件的默认内容是一样的。apt.systemd.daily 脚本在注释中说我们可以通过 /etc/apt/apt.conf.d/10periodic 文件自定义相关的变量值，它通过 get-config 命令来获得这些变量的值。但是测试的结果是 /etc/apt/apt.conf.d/20auto-upgrades 文件中的变量会覆盖 /etc/apt/apt.conf.d/10periodic 文件中的变量。看来是 get-config 命令根据文件名称的顺序，排在后面的文件中的变量会覆盖前面文件中的变量。\n在 desktop 版本中，通过 GUI 程序修改相关的变量，这两个文件都会被修改并保持一致，所以在 server 版中我们最好也同时修改这两个文件并保持其内容一致。\nunattended-upgrades Ubuntu 实际上是通过 unattended-upgrades 命令来自动安装更新的。Ubuntu 16.04/18.04 默认安装了这个包，如果碰到没有安装的情况你还可以通过下面的命令自行安装：\n$ sudo apt install unattended-upgrades unattended-upgrades 的配置文件为 /etc/apt/apt.conf.d/50unattended-upgrades。\n注意，unattended-upgrades 不仅能够安装系统的安全更新，还可以安装所有包的更新。但是默认的配置只安装安全更新，我们可以通过配置项让 unattended-upgrades 安装所有的包更新或者只安装安全更新。\nunattended-upgrades 命令被设计为通过 cron 定时执行系统更新，但在 Ubuntu 16.04/18.04 中是通过 systemd 的 timer unit 定时触发 service unit 执行的。\nunattended-upgrades 命令的日志文件存放在 /var/log/unattended-upgrades 目录下。\nunattended-upgrade 命令常见的用法之一是检查系统是否有更新：\n$ sudo unattended-upgrade --dry-run 另一种用法是安装更新：\n$ sudo unattended-upgrade 在 apt.systemd.daily 脚本中执行 unattended-upgrade 命令时，由于更新包已经提前下载到缓存目录了(/var/cache/apt/archives)，所以直接它直接使用缓存中的更新包。\n配置文件 50unattended-upgrades\n50unattended-upgrades 文件中的默认配置只是安装安全更新：\nUnattended-Upgrade::Allowed-Origins { \u0026#34;${distro_id}:${distro_codename}\u0026#34;; \u0026#34;${distro_id}:${distro_codename}-security\u0026#34;; \u0026#34;${distro_id}ESM:${distro_codename}\u0026#34;; // \u0026#34;${distro_id}:${distro_codename}-updates\u0026#34;; // \u0026#34;${distro_id}:${distro_codename}-proposed\u0026#34;; // \u0026#34;${distro_id}:${distro_codename}-backports\u0026#34;; }; 如果要自动安装所有包的更新，只要取消下面行的注释就行了：\n\u0026#34;${distro_id}:${distro_codename}-updates\u0026#34;; 我们还可以通过黑名单的方式指定不更新哪些包：\nUnattended-Upgrade::Package-Blacklist { \u0026#34;vim\u0026#34;; \u0026#34;libc6\u0026#34;; \u0026#34;libc6-dev\u0026#34;; \u0026#34;libc6-i686\u0026#34;; }; 下面的配置项指定在更新后移除无用的包：\nUnattended-Upgrade::Remove-Unused-Kernel-Packages \u0026#34;true\u0026#34;; Unattended-Upgrade::Remove-Unused-Dependencies \u0026#34;true\u0026#34;; 有些更新需要重启系统，而默认的配置是不重启系统的。下面的配置允许重启系统(更新完成后，如果需要重启，立即重启系统)：\nUnattended-Upgrade::Automatic-Reboot \u0026#34;true\u0026#34;; 但是多数情况下我们更期望指定一个时间让系统重启(如果需要重启，在下面配置中指定的时间重启系统)：\nUnattended-Upgrade::Automatic-Reboot-Time \u0026#34;02:38\u0026#34;; 在系统更新的过程中发生了错误怎么办？当然是通知管理员啦！下面的配置在发生错误时给管理员发送邮件：\nUnattended-Upgrade::Mail \u0026#34;user@example.com\u0026#34;; Unattended-Upgrade::MailOnlyOnError \u0026#34;true\u0026#34;; 注意：如果要向外网发送邮件，需要安装 mailx 等工具。\n关闭自动更新 如果你的主机运行在封闭的环境中，并且无法连接到有效的更新源，此时可以选择关闭自动更新功能。首选的方法是停止相关的服务：\n$ sudo systemctl stop apt-daily.service $ sudo systemctl stop apt-daily.timer $ sudo systemctl stop apt-daily-upgrade.service $ sudo systemctl stop apt-daily-upgrade.timer $ sudo systemctl disable apt-daily.service $ sudo systemctl disable apt-daily.timer $ sudo systemctl disable apt-daily-upgrade.service $ sudo systemctl disable apt-daily-upgrade.timer 或者修改自动更新程序的配置文件也可以，同时更新 /etc/apt/apt.conf.d/10periodic 和 /etc/apt/apt.conf.d/20auto-upgrades：\nAPT::Periodic::Update-Package-Lists \u0026#34;1\u0026#34;; APT::Periodic::Unattended-Upgrade \u0026#34;1\u0026#34;; 改为\nAPT::Periodic::Update-Package-Lists \u0026#34;0\u0026#34;; APT::Periodic::Unattended-Upgrade \u0026#34;0\u0026#34;; LVM 在对磁盘分区的大小进行规划时，往往不能确定这个分区要使用的空间的大小。而使用 fdisk、gdisk 等工具对磁盘分区后，每个分区的大小就固定了。如果分区设置的过大，就白白浪费了磁盘空间；如果分区设置的过小，就会导致空间不够用的情况出现。对于分区过小的问题，可以从新划分磁盘的分区，或者通过软连接的方式将此分区的目录链接到另外一个分区。这样虽然能够临时解决问题，但是给管理带来了麻烦。类似的问题可以通过 LVM 来解决。\nLVM 是什么 LVM 是 Logical Volume Manager 的缩写，中文一般翻译为 \u0026ldquo;逻辑卷管理\u0026rdquo;，它是 Linux 下对磁盘分区进行管理的一种机制。LVM 是建立在磁盘分区和文件系统之间的一个逻辑层，系统管理员可以利用 LVM 在不重新对磁盘分区的情况下动态的调整分区的大小。如果系统新增了一块硬盘，通过 LVM 就可以将新增的硬盘空间直接扩展到原来的磁盘分区上。\nLVM 的优点如下：\n 文件系统可以跨多个磁盘，因此大小不再受物理磁盘的限制。 可以在系统运行状态下动态地扩展文件系统大小。 可以以镜像的方式冗余重要数据到多个物理磁盘上。 可以很方便地导出整个卷组，并导入到另外一台机器上。  LVM 也有一些缺点：\n 在从卷组中移除一个磁盘的时候必须使用 reducevg 命令(这个命令要求root权限，并且不允许在快照卷组中使用)。 当卷组中的一个磁盘损坏时，整个卷组都会受影响。 因为增加了一个逻辑层，存储的性能会受影响。  LVM 的优点对服务器的管理非常有用，但对于桌面系统的帮助则没有那么显著，所以需要我们根据使用的场景来决定是否应用 LVM。\nLVM 中的基本概念 通过 LVM 技术，可以屏蔽掉磁盘分区的底层差异，在逻辑上给文件系统提供了一个卷的概念，然后在这些卷上建立相应的文件系统。下面是 LVM 中主要涉及的一些概念。\n **物理存储设备(Physical Media)：**指系统的存储设备文件，比如 /dev/sda、/dev/sdb 等。 **PV(物理卷 Physical Volume)：**指硬盘分区或者从逻辑上看起来和硬盘分区类似的设备(比如 RAID 设备)。 **VG(卷组 Volume Group)：**类似于非 LVM 系统中的物理硬盘，一个 LVM 卷组由一个或者多个 PV(物理卷)组成。 **LV(逻辑卷 Logical Volume)：**类似于非 LVM 系统上的磁盘分区，LV 建立在 VG 上，可以在 LV 上建立文件系统。 **PE(Physical Extent)：**PV(物理卷)中可以分配的最小存储单元称为 PE，PE 的大小是可以指定的。 **LE(Logical Extent)：**LV(逻辑卷)中可以分配的最小存储单元称为 LE，在同一个卷组中，LE 的大小和 PE 的大小是一样的，并且一一对应。  可以这么理解，LVM 是把硬盘的分区分成了更小的单位(PE)，再用这些单元拼成更大的看上去像分区的东西(PV)，进而用 PV 拼成看上去像硬盘的东西(VG)，最后在这个新的硬盘上创建分区(LV)。文件系统则建立在 LV 之上，这样就在物理硬盘和文件系统中间添加了一层抽象(LVM)。下图大致描述了这些概念之间的关系：\n对上图中的结构做个简单的介绍：\n两块物理硬盘 A 和 B 组成了 LVM 的底层结构，这两块硬盘的大小、型号可以不同。PV 可以看做是硬盘上的分区，因此可以说物理硬盘 A 划分了两个分区，物理硬盘 B 划分了三个分区。然后将前三个 PV 组成一个卷组 VG1，后两个 PV 组成一个卷组 VG2。接着在卷组 VG1 上划分了两个逻辑卷 LV1 和 LV2，在卷组 VG2 上划分了一个逻辑卷 LV3。最后，在逻辑卷 LV1、LV2 和 LV3 上创建文件系统，分别挂载在 /usr、/home 和 /var 目录。\nLVM 工具 在安装 Linux 时，如果选择使用 LVM 创建分区，就会安装 LVM 相关的工具。当前这个软件包的名称为 lvm2，其中包含了大量 LVM 工具。比如单是查看 LVM 相关实体状态的命令就有如下一些：\n$ sudo pvscan $ sudo pvs $ sudo pvdisplay $ sudo vgscan $ sudo vgs $ sudo vgdisplay $ sudo lvscan $ sudo lvs $ sudo lvdisplay 如果安装系统时没有默认安装 LVM 工具包，可以通过下面的命令安装它们：\n$ sudo apt update $ sudo apt install lvm2 接下来我们通过例子来演示如何使用 LVM 来一步步的创建出逻辑卷(LV)，然后在 LV 上创建文件系统并挂载到 Linux 系统中。\n使用 gdisk 对物理磁盘进行分区 目前常见的磁盘分区格式有两种，MBR 分区和 GPT 分区。\nMBR 分区，MBR 的意思是 \u0026ldquo;主引导记录\u0026rdquo;。MBR 最大支持 2TB 容量，在容量方面存在着极大的瓶颈。\nGPT 分区，GPT 意为 GUID 分区表，它支持的磁盘容量比 MBR 大得多。这是一个正逐渐取代 MBR 的新标准，它是由 UEFI 辅住而形成的，将来 UEFI 用于取代老旧的 BIOS，而 GPT 则取代老旧的 MBR。\n使用 fdisk 工具创建 MBR 磁盘分区，而 gdisk 是 Linux 系统中 GPT 格式的磁盘分区管理工具。\n假设我们的 Linux 系统中增加了一块新的磁盘，系统对应的设备名为 /dev/sdb，下面我们通过 gdisk 命令对这个磁盘进行分区。\n在用 gdisk 命令对磁盘分区前，我们先用 parted 命令查看 /dev/sdb 当前的分区情况：\n$ sudo parted /dev/sdb print 下面通过 gdisk 命令创建分区：\n$ sudo gdisk /dev/sdb 通过 p 命令可以查看磁盘当前的状态：输出中的前几行是磁盘的基本信息，比如总大小，一共有多少个扇区(sector)，每个扇区的大小，当前剩余的空间等等。\n然后是已经存在的分区信息：\n 第一列 Number 显示了分区的编号，比如 1 号指 /dev/sdb1。 第二列 Start 表示磁盘分区的起始位置。 第三列 End 表示磁盘分区的结束位置。 第四列 Size 显示分区的容量。 第五列 Code 和第六列 Name 显示分区类型的 ID和名称，比如 Linux filesystem 为 8300，Linux swap 为 8200，Linux LVM 为 8e00。  通过 n 命令来创建新分区：\n分区编号和开始/结束的扇区都直接通过回车选择默认值，这样所有的磁盘空间都划分到了一个分区中，然后输入 8e00 说明我们要创建的分区类型为 Linux LVM。最后输入 w 命令并确认执行分区操作。分区成功后可通过 p 命令查看我们创建的分区的信息。\n创建物理卷 PV # pvcreate DEVICE 现在我们可以基于磁盘分区 /dev/sdb1 来创建 LVM 物理卷(LV)，可以通过 pvcreate 命令来完成：\n$ sudo pvcreate /dev/sdb1 此时 /dev/sdb1 已经完成了从磁盘分区到 PV 的华丽转身！注意上面的命令，磁盘分区被直接转换成了 PV，连名称都没有变化！我们可以通过 pvs 命令查看 /dev/sdb1，目前它还没有被加入到 VG 中。\n创建卷组 VG # vgcreate \u0026lt;volume_group\u0026gt; \u0026lt;physical_volume1\u0026gt; \u0026lt;physical_volume2\u0026gt; ... 基于一个或多个 PV，可以创建 VG。我们使用刚才创建的 PV /dev/sdb1 来创建一个名称为 nickvg 的 VG：\n$ sudo vgcreate -s 32G nickvg /dev/sdb1 注意 vgcreate 命令中的 -s 选项，它指定了 PE(Physical Extent) 的大小。可以通 vgs 命令观察 VG 的信息：\n$ sudo vgs nickvg 如果目标 VG 已经存在，则使用 vgextend 把 PV 加入到 VG 中即可。\n# vgextend \u0026lt;卷组名\u0026gt; \u0026lt;物理卷\u0026gt; 创建逻辑卷 LV # lvcreate -L \u0026lt;卷大小\u0026gt; \u0026lt;卷组名\u0026gt; -n \u0026lt;卷名\u0026gt; 有了 VG 就可以创建逻辑卷 LV 了，lvcreate 命令用来创建 LV，让我们在前面创建的 nickvg 上创建名称为 nicklv00 的 LV：\n$ sudo lvcreate -L 15G -n nicklv00 nickvg 选项 -L 指定新建 LV 的容量，这里是 15G；选项 -n 则指定新建 LV 的名称，这里为 nicklv00。可以通过 lvs 命令观察 LV 的信息，注意需要同时指出 LV 所在的 VG：\n$ sudo lvs nickvg/nicklv00 如果你想让要创建的逻辑卷拥有卷组（VG）的所有未使用空间，请使用以下命令：\n# lvcreate -l +100%FREE \u0026lt;volume_group\u0026gt; -n \u0026lt;logical_volume\u0026gt; 格式化逻辑卷(创建文件系统) # mkfs.\u0026lt;类型\u0026gt; /dev/mapper/\u0026lt;卷组名\u0026gt;-\u0026lt;卷名\u0026gt; # mount /dev/mapper/\u0026lt;卷组名\u0026gt;-\u0026lt;卷名\u0026gt; \u0026lt;挂载点\u0026gt; 当我们创建 LV nickvg/nicklv00 时，其实是创建了名称为 /dev/nickvg/nicklv00 的设备文件。\n现在你的逻辑卷应该已经在/dev/mapper/和/dev/YourVolumeGroupName中了。\n现在我们来格式化这个逻辑卷(在该 LV 上创建文件系统)，目标为比较常见的 ext4 格式：\n$ sudo mkfs.ext4 /dev/nickvg/nicklv00 然后创建个目录，比如 /home/doc，并把新建的文件系统挂载到这个目录上：\n$ sudo mkdir /home/doc $ sudo mount /dev/nickvg/nicklv00 /home/doc 最后可以通过 df 命令查看这个文件系统的使用情况。\n开机自动挂载 编辑 /etc/fstab 文件：\n$ sudo vim /etc/fstab 把下面的行添加的文件末尾并保存文件：\n/dev/mapper/nickvg-nicklv00 /home/doc ext4 defaults 0 2 调整逻辑卷 同时缩小逻辑卷和其文件系统\n 注意： 只有ext2，ext3，ext4，ReiserFS和 XFS 文件系统支持以下操作。\n 将MyVolGroup组中的逻辑卷mediavol扩大10GiB，并同时扩大其文件系统：\n# lvresize -L +10G --resizefs MyVolGroup/mediavol 将MyVolGroup组中的逻辑卷mediavol大小调整为15GiB，并同时调整其文件系统：\n# lvresize -L 15G --resizefs MyVolGroup/mediavol 将卷组中的所有剩余空间分配给mediavol：\n# lvresize -l +100%FREE --resizefs MyVolGroup/mediavol 重命名卷 重命名卷组\n要重命名一个卷组，请使用vgrename(8)命令。\n可使用下面的任意一条命令将卷组vg02重命名为my_volume_group\n# vgrename /dev/vg02 /dev/my_volume_group # vgrename vg02 my_volume_group 重命名逻辑卷\n要重命名一个逻辑卷，请使用lvrename(8)命令。\n可使用下面的任意一条命令将vg02组中的逻辑卷lvold重命名为lvnew.\n# lvrename /dev/vg02/lvold /dev/vg02/lvnew # lvrename vg02 lvold lvnew 移除逻辑卷 警告： 在移除逻辑卷之前，请先备份好数据以免丢失！\n首先，找到你所要移除的逻辑卷的名称。你可以使用以下命令来查看系统的所有逻辑卷：\n# lvs 接下来，找到你所要移除的逻辑卷的挂载点\n$ lsblk 并卸载它：\n# umount /\u0026lt;mountpoint\u0026gt; 最后，使用以下命令来移除逻辑卷：\n# lvremove \u0026lt;volume_group\u0026gt;/\u0026lt;logical_volume\u0026gt; 例如：\n# lvremove VolGroup00/lvolhome 请输入y来确定你要执行移除逻辑卷操作。\n此外，请不要忘了更新/etc/fstab。\n你可以再次使用lvs命令来确认你的逻辑卷已被移除。\nLVM 快照 LVM 机制还提供了对 LV 做快照的功能，也就是说可以给文件系统做一个备份，这也是设计 LVM 快照的主要目的。LVM 的快照功能采用写时复制技术(Copy-On-Write，COW)，这比传统的备份技术的效率要高很多。创建快照时不用停止服务，就可以对数据进行备份。说明：LVM 还支持 thin 类型的快照，但是本文中的快照都是指 COW 类型的快照。\nLVM 采用的写时复制，是指当 LVM 快照创建的时候，仅创建到实际数据的 inode 的硬链接(hark-link)而已。只要实际的数据没有改变，快照就只包含指向数据的 inode 的指针，而非数据本身。快照会跟踪原始卷中块的改变，一旦你更改了快照对应的文件或目录，这个时候原始卷上将要改变的数据会在改变之前拷贝到快照预留的空间。\nLVM 快照的原理\n创建快照实际上也是创建了一个逻辑卷，只不过该卷的属性与普通逻辑卷的属性有些不一样。我们可以通过下图来理解快照数据卷(图中的实线框表示快照区域，虚线框表示文件系统)：\n左图为最初创建的快照数据卷状况，LVM 会预留一个区域 (比如左图的左侧三个 PE 区块) 作为数据存放处。 此时快照数据卷内并没有任何数据，而快照数据卷与源数据卷共享所有的 PE 数据， 因此你会看到快照数据卷的内容与源数据卷中的内容是一模一样的。 等到系统运行一阵子后，假设 A 区域的数据被更新了(上面右图所示)，则更新前系统会将该区域的数据移动到快照数据卷中， 所以在右图的快照数据卷中被占用了一块 PE 成为 A，而其他 B 到 I 的区块则还是与源数据卷共享！\n由於快照区与原本的 LV 共享很多 PE 区块，因此快照区与被快照的 LV 必须要在同一个 VG 上头，下面两点非常重要：\n VG中需要预留存放快照本身的空间，不能全部被占满。 快照所在的 VG 必须与被备份的 LV 的 VG 相同，否则创建快照会失败。  创建 LVM 快照\n其实快照就是一个特殊类型的数据卷，所以创建快照的命令和创建数据卷的命令相同，也是 lvcreate：\n# lvcreate --size 100M --snapshot --name snap01 /dev/vg0/lv 此时如果把 LV snap01 挂载到系统中，里面的内容和 LV /dev/vg0/lv 中的内容是一样的。\n创建的快照的大小可以比源数据卷小，但是当源数据卷中的数据更新过多时会导致快照容量不足而引起的错误并丢失数据。如上你可以修改少于100M的数据，直到该快照逻辑卷空间不足为止。\n创建快照后，如果源数据卷中的文件被更新了，快照系统中则保存着其创建快照时的版本。\n还原部分数据\n如果我们明确的知道需要还原某个文件，可以挂载快照数据卷，直接拷贝其中旧版本的文件即可。\n合并快照(merge snapshot)\n要将逻辑卷卷\u0026rsquo;lv\u0026rsquo; 恢复到创建快照\u0026rsquo;snap01\u0026rsquo;时的状态，即还原整个数据卷上的数据，请使用：\n# lvconvert --merge /dev/vg0/snap01 如果逻辑卷处于活动状态，则在下次重新启动时将进行合并（merging）(合并（merging）甚至可在LiveCD中进行)。\n注意： 合并后快照将被删除。\n可以拍摄多个快照，每个快照都可以任意与对应的逻辑卷合并。\n快照可以被挂载，并可用dd或者tar备份。使用dd备份的快照的大小为拍摄快照后对应逻辑卷中变更过文件的大小。 要使用备份，只需创建并挂载一个快照，并将备份写入或解压到其中。再将快照合并到对应逻辑卷即可。\n快照主要用于提供一个文件系统的拷贝，以用来备份; 比起直接备份分区，使用快照备份可以提供一个更符合原文件系统的镜像。\nZFS 历史 ZFS 是由 Matthew Ahrens 和 Jeff Bonwick 在 2001 年开发的。ZFS 是作为 Sun MicroSystem 公司的 OpenSolaris 的下一代文件系统而设计的。在 2008 年，ZFS 被移植到了 FreeBSD 。同一年，一个移植 ZFS on Linux 的项目也启动了。然而，由于 ZFS 是CDDL 许可的，它和 GPL 不兼容，因此不能将它迁移到 Linux 内核中。为了解决这个问题，绝大多数 Linux 发行版提供了一些方法来安装 ZFS　。\n在甲骨文公司收购太阳微系统公司之后不久，OpenSolaris 就闭源了，这使得 ZFS 的之后的开发也变成闭源的了。许多 ZFS 开发者对这件事情非常不满。三分之二的 ZFS 核心开发者，包括 Ahrens 和 Bonwick，因为这个决定而离开了甲骨文公司。他们加入了其它公司，并于 2013 年 9 月创立了 OpenZFS 这一项目。该项目引领着 ZFS 的开源开发。\n让我们回到上面提到的许可证问题上。既然 OpenZFS 项目已经和 Oracle 公司分离开了，有人可能好奇他们为什么不使用和 GPL 兼容的许可证，这样就可以把它加入到 Linux 内核中了。根据 OpenZFS 官网 的介绍，更改许可证需要联系所有为当前 OpenZFS 实现贡献过代码的人（包括初始的公共 ZFS 代码以及 OpenSolaris 代码），并得到他们的许可才行。这几乎是不可能的（因为一些贡献者可能已经去世了或者很难找到），因此他们决定保留原来的许可证。\n特性 正如前面所说过的，ZFS 是一个先进的文件系统。因此，它有一些有趣的特性。\n存储池 与大多数文件系统不同，ZFS 结合了文件系统和卷管理器的特性。这意味着，它与其他文件系统不同，ZFS 可以创建跨越一系列硬盘或池的文件系统。不仅如此，你还可以通过添加硬盘来增大池的存储容量。ZFS 可以进行分区和格式化。\n写时拷贝 Copy-on-write 是另一个有趣并且很酷的特性。在大多数文件系统上，当数据被重写时，它将永久丢失。而在 ZFS 中，新数据会写到不同的块。写完成之后，更新文件系统元数据信息，使之指向新的数据块（LCTT 译注：更新之后，原数据块成为磁盘上的垃圾，需要有对应的垃圾回收机制）。这确保了如果在写新数据的时候系统崩溃（或者发生其它事，比如突然断电），那么原数据将会保存下来。这也意味着，在系统发生崩溃之后，不需要运行 fsck 来检查和修复文件系统。\n快照 写时拷贝使得 ZFS 有了另一个特性：snapshots。ZFS 使用快照来跟踪文件系统中的更改。快照包含文件系统的原始版本（文件系统的一个只读版本），实时文件系统则包含了自从快照创建之后的任何更改。没有使用额外的空间。因为新数据将会写到实时文件系统新分配的块上。如果一个文件被删除了，那么它在快照中的索引也会被删除。所以，快照主要是用来跟踪文件的更改，而不是文件的增加和创建。\n快照可以挂载成只读的，以用来恢复一个文件的过去版本。实时文件系统也可以回滚到之前的快照。回滚之后，自从快照创建之后的所有更改将会丢失。\n数据完整性验证和自动修复 当向 ZFS 写入新数据时，会创建该数据的校验和。在读取数据的时候，使用校验和进行验证。如果前后校验和不匹配，那么就说明检测到了错误，然后，ZFS 会尝试自动修正错误。\nRAID-Z ZFS 不需要任何额外软件或硬件就可以处理 RAID（磁盘阵列）。毫不奇怪，因为 ZFS 有自己的 RAID 实现：RAID-Z 。RAID-Z 是 RAID-5 的一个变种，不过它克服了 RAID-5 的写漏洞：意外重启之后，数据和校验信息会变得不同步（LCTT 译注：RAID-5 的条带在正写入数据时，如果这时候电源中断，那么奇偶校验数据将跟该部分数据不同步，因此前边的写无效；RAID-Z 用了 “可变宽的 RAID 条带” 技术，因此所有的写都是全条带写入）。为了使用基本级别的 RAID-Z（RAID-Z1），你需要至少三块磁盘，其中两块用来存储数据，另外一块用来存储奇偶校验信息。而 RAID-Z2 需要至少两块磁盘存储数据以及两块磁盘存储校验信息。RAID-Z3 需要至少两块磁盘存储数据以及三块磁盘存储校验信息。另外，只能向 RAID-Z 池中加入偶数倍的磁盘，而不能是奇数倍的。\n巨大的存储潜力 创建 ZFS 的时候，它是作为最后一个文件系统而设计的 。那时候，大多数文件系统都是 64 位的，ZFS 的创建者决定直接跳到 128 位，等到将来再来证明这是对的。这意味着 ZFS 的容量大小是 32 位或 64 位文件系统的 1600 亿亿倍。事实上，Jeff Bonwick（其中一个创建者）说：“完全填满一个 128 位的存储池所需要的能量，从字面上讲，比煮沸海洋需要的还多。”\n如何安装 ZFS？ 如果你想立刻使用 ZFS（开箱即用），那么你需要安装 FreeBSD 或一个使用 illumos 内核的操作系统。illumos 是 OpenSolaris 内核的一个克隆版本。\n事实上，支持 ZFS 是一些有经验的 Linux 用户选择 BSD 的主要原因。\n如果你想在 Linux 上尝试 ZFS，那么只能在存储文件系统上使用。据我所知，没有任何 Linux 发行版可以在根目录上安装 ZFS，实现开箱即用。如果你对在 Linux 上尝试 ZFS 感兴趣，那么 ZFS on Linux 项目 上有大量的教程可以指导你怎么做。\n在 Ubuntu 上使用 ZFS 如果您正在考虑将 ZFS 用于您的超高速 NVMe SSD，这可能不是一个最佳选择。 它比别的文件系统要慢，不过，这完全没有问题， 它旨在存储大量的数据并保持安全。\n$ sudo apt-get install zfsutils-linux 创建池 在 ZFS 中，池大致相当于 RAID 。 它们很灵活且易于操作。\nRAID0 RAID0 只是把你的硬盘集中到一个池子里面，就像一个巨大的驱动器一样。 它可以提高你的驱动器速度，（LCTT 译注：数据条带化后，并行访问，可以提高文件读取速度）但是如果你的驱动器有损坏，你可能会失丢失数据。\n在计算机数据存储中，数据条带化是一种对逻辑顺序数据（例如文件）进行分段的技术，以便将连续的段存储在不同的物理存储设备上。\n要使用 ZFS 实现 RAID0，只需创建一个普通的池。\n$ sudo zpool create your-pool /dev/sdc /dev/sdd RAID1（镜像） 您可以在 ZFS 中使用 mirror 关键字来实现 RAID1 功能。 RAID1 会创建一个一对一的驱动器副本。 这意味着您的数据一直在备份。 它也提高了性能。 当然，你将一半的存储空间用于了复制。\n$ sudo zpool create your-pool mirror /dev/sdc /dev/sdd RAID5/RAIDZ1 ZFS 将 RAID5 功能实现为 RAIDZ1。 RAID5 要求驱动器至少是 3 个。并允许您通过将备份奇偶校验数据写入驱动器空间的 1/n（n 是驱动器数），留下的是可用的存储空间。 如果一个驱动器发生故障，阵列仍将保持联机状态，但应尽快更换发生故障的驱动器（LCTT 译注：与原文翻译略有不同，原文是驱动器的数目是三的倍数，根据 wiki， RAID5 至少需要 3 块驱动器，也可以从下面的命令中猜测)。\n$ sudo zpool create your-pool raidz1 /dev/sdc /dev/sdd /dev/sde RAID6/RAIDZ2 RAID6 与 RAID5 几乎完全相同，但它至少需要四个驱动器。 它将奇偶校验数据加倍，最多允许两个驱动器损坏，而不会导致阵列关闭（LCTT 译注：这里也与原文略有出入，原文是驱动器的数目是四的倍数，根据 wiki ，RAID6 至少需要四个驱动器)。\n$ sudo zpool create your-pool raidz2 /dev/sdc /dev/sdd /dev/sde /dev/sdf RAID10（条带化镜像） RAID10 旨在通过数据条带化提高存取速度和数据冗余来成为一个两全其美的解决方案。 你至少需要四个驱动器，但只能使用一半的空间。 您可以通过在同一个池中创建两个镜像来创建 RAID10 中的池（LCTT 译注：这里也与原文略有出入，原文是驱动器的数目是四的倍数，根据 wiki， RAID10 至少需要四个驱动器）。\n$ sudo zpool create your-pool mirror /dev/sdc /dev/sdd mirror /dev/sde /dev/sdf 池的操作 还有一些管理工具，一旦你创建了你的池，你就必须使用它们来操作。 首先，检查你的池的状态。\n$ sudo zpool status 更新 当你更新 ZFS 时，你也需要更新你的池。 当您检查它们的状态时，您的池会通知您任何更新。 要更新池，请运行以下命令。\n$ sudo zpool upgrade your-pool 你也可以更新全部池。\n$ sudo zpool upgrade -a 添加驱动器 您也可以随时将驱动器添加到池中。 告诉 zpool 池的名称和驱动器的位置，它会处理好一切。\n$ sudo zpool add your-pool /dev/sdx 实例 使用两块硬盘上的等容量分区建立 raid 1。\n$ ls -l /dev/disk/by-id usb-JMicron_Generic_DISK00_0123456789ABCDEF-0:0-part1 -\u0026gt; ../../sdb1 usb-JMicron_Generic_DISK01_0123456789ABCDEF-0:1-part2 -\u0026gt; ../../sdc2 $ sudo zpool create -f -o ashift=12 -o cachefile=/etc/zfs/zpool.cache -O compression=lz4 -O xattr=sa -O relatime=on -O acltype=posixacl -O dedup=off -m none dpool mirror usb-JMicron_Generic_DISK00_0123456789ABCDEF-0:0-part1 usb-JMicron_Generic_DISK01_0123456789ABCDEF-0:1-part2 $ sudo zfs create -o mountpoint=none -o canmount=off dpool/DATA $ sudo zfs create -o mountpoint=/home/kurome/DataPool dpool/DATA/important $ sudo zpool export dpool $ sudo zpool import dpool Systemd LINUX PID 1 和 SYSTEMD 要说清 Systemd，得先从Linux操作系统的启动说起。Linux 操作系统的启动首先从 BIOS 开始，然后由 Boot Loader 载入内核，并初始化内核。内核初始化的最后一步就是启动 init 进程。这个进程是系统的第一个进程，PID 为 1，又叫超级进程，也叫根进程。它负责产生其他所有用户进程。所有的进程都会被挂在这个进程下，如果这个进程退出了，那么所有的进程都被 kill 。如果一个子进程的父进程退了，那么这个子进程会被挂到 PID 1 下面。（注：PID 0 是内核的一部分，主要用于内进换页，参看：Process identifier）\nSysV Init PID 1 这个进程非常特殊，其主要就任务是把整个操作系统带入可操作的状态。比如：启动 UI – Shell 以便进行人机交互，或者进入 X 图形窗口。传统上，PID 1 和传统的 Unix System V 相兼容的，所以也叫 sysvinit，这是使用得最悠久的 init 实现。Unix System V 于1983年 release。\n在 sysvint 下，有好几个运行模式，又叫 runlevel。比如：常见的 3 级别指定启动到多用户的字符命令行界面，5 级别指定启起到图形界面，0 表示关机，6 表示重启。其配置在 /etc/inittab 文件中。\n与此配套的还有 /etc/init.d/ 和 /etc/rc[X].d，前者存放各种进程的启停脚本（需要按照规范支持 start，stop子命令），后者的 X 表示不同的 runlevel 下相应的后台进程服务，如：/etc/rc3.d 是 runlevel=3 的。 里面的文件主要是 link 到 /etc/init.d/ 里的启停脚本。其中也有一定的命名规范：S 或 K 打头的，后面跟一个数字，然后再跟一个自定义的名字，如：S01rsyslog，S02ssh。S 表示启动，K表示停止，数字表示执行的顺序。\nUpStart Unix 和 Linux 在 sysvint 运作多年后，大约到了2006年的时候，Linux内核进入2.6时代，Linux有了很多更新。并且，Linux开始进入桌面系统，而桌面系统和服务器系统不一样的是，桌面系统面临频繁重启，而且，用户会非常频繁的使用硬件的热插拔技术。于是，这些新的场景，让 sysvint 受到了很多挑战。\n比如，打印机需要CUPS等服务进程，但是如果用户没有打机印，启动这个服务完全是一种浪费，而如果不启动，如果要用打印机了，就无法使用，因为sysvint 没有自动检测的机制，它只能一次性启动所有的服务。另外，还有网络盘挂载的问题。在 /etc/fstab 中，负责硬盘挂载，有时候还有网络硬盘（NFS 或 iSCSI）在其中，但是在桌面机上，有很可能开机的时候是没有网络的， 于是网络硬盘都不可以访问，也无法挂载，这会极大的影响启动速度。sysvinit 采用 netdev 的方式来解决这个问题，也就是说，需要用户自己在 /etc/fstab 中给相应的硬盘配置上 netdev 属性，于是 sysvint 启动时不会挂载它，只有在网络可用后，由专门的 netfs 服务进程来挂载。这种管理方式比较难以管理，也很容易让人掉坑。\n所以，Ubuntu 开发人员在评估了当时几个可选的 init 系统后，决定重新设计这个系统，于是，这就是我们后面看到的 upstart 。 upstart 基于事件驱动的机制，把之前的完全串行的同步启动服务的方式改成了由事件驱动的异步的方式。比如：如果有U盘插入，udev 得到通知，upstart 感知到这个事件后触发相应的服务程序，比如挂载文件系统等等。因为使用一个事件驱动的玩法，所以，启动操作系统时，很多不必要的服务可以不用启动，而是等待通知，lazy 启动。而且事件驱动的好处是，可以并行启动服务，他们之间的依赖关系，由相应的事件通知完成。\nupstart 有着很不错的设计，其中最重要的两个概念是 Job 和 Event。\nJob 有一般的Job，也有service的Job，并且，upstart 管理了整个 Job 的生命周期，比如：Waiting, Starting, pre-Start, Spawned, post-Start, Running, pre-Stop, Stopping, Killed, post-Stop等等，并维护着这个生命周期的状态机。\nEvent 分成三类，signal, method 和 hooks。signal 就是异步消息，method 是同步阻塞的。hooks 也是同步的，但介于前面两者之间，发出hook事件的进程必须等到事件完成，但不检查是否成功。\n但是，upstart 的事件非常复杂，也非常纷乱，各种各样的事件（事件没有归好类）导致有点凌乱。不过因为整个事件驱动的设计比之前的 sysvinit 来说好太多，所以，也深得欢迎。\nSystemd 直到2010的有一天，一个在 RedHat工作的工程师 Lennart Poettering 和 Kay Sievers ，开始引入了一个新的 init 系统—— systemd。这是一个非常非常有野心的项目，这个项目几乎改变了所有的东西，systemd 不但想取代已有的 init 系统，而且还想干更多的东西。\nLennart 同意 upstart 干的不错，代码质量很好，基于事件的设计也很好。但是他觉得 upstart 也有问题，其中最大的问题还是不够快，虽然 upstart 用事件可以达到一定的启动并行度，但是，本质上来说，这些事件还是会让启动过程串行在一起。 如：NetworkManager 在等 D-Bus 的启动事件，而 D-Bus 在等 syslog 的启动事件。\nLennart 认为，实现上来说，upstart 其实是在管理一个逻辑上的服务依赖树，但是这个服务依赖树在表现形式上比较简单，你只需要配置——“启动 B好了就启动A”或是“停止了A后就停止B”这样的规则。但是，Lennart 说，这种简单其实是有害的（this simplification is actually detrimental）。他认为，\n  从一个系统管理的角度出来，他一开始会设定好整个系统启动的服务依赖树，但是这个系统管理员要人肉的把这个本来就非常干净的服务依整树给翻译成计算机看的懂的 Event/Action 形式，而且 Event/Action 这种配置方式是运行时的，所以，你需要运行起来才知道是什么样的。\n  Event逻辑从头到脚到处都是，这个事件扩大了运维的复杂度，还不如之前的 sysvint。 也就是说，当用户配置了 “启动 D-Bus 后请启动 NetworkManager”， 这个 upstart 可以干，但是反过来，如果，用户启动 NetworkManager，我们应该先去启动他的前置依赖 D-Bus，然而你还要配置相应的反向 Event。本来，我只需要配置一条依赖的，结果现在我要配置很多很多情况下的Event。\n  最后，upstart 里的 Event 的并不标准，很混乱，没有良好的定义。比如：既有，进程启动，运行，停止的事件，也有USB设备插入、可用、拔出的事件，还有文件系统设备being mounted、 mounted 和 umounted 的事件，还有AC电源线连接和断开的事件。你会发现，这进程启停的、USB的、文件系统的、电源线的事件，看上去长得很像， 但是没有被标准化抽像出来掉，因为绝大多数的事件都是三元组：start, condition, stop 。这种概念设计模型并没有在 upstart 中出现。因为 upstart 被设计为单一的事件，而忽略了逻辑依赖。\n  当然，如果 systemd 只是解决 upstart 的问题，他就改造 upstart 就好了，但是 Lennart 的野心不只是想干个这样的事，他想干的更多。\n首先，systemd 清醒的认识到了 init 进程的首要目标是要让用户快速的进入可以操作OS的环境，所以，这个速度一定要快，越快越好，所以，systemd 的设计理念就是两条：\n To start less. And to start more in parallel.  也就是说，按需启动，能不启动就不启动，如果要启动，能并行启动就并行启动，包括你们之间有依赖，我也并行启动。按需启动还好理解，那么，有依赖关系的并行启动，它是怎么做到的？这里，systemd 借鉴了 MacOS 的 Launchd 的玩法（在Youtube上有一个分享——Launchd: One Program to Rule them All，在苹果的开源网站上也有相关的设计文档——About Daemons and Services）\n要解决这些依赖性，systemd 需要解决好三种底层依赖—— Socket， D-Bus ，文件系统。\n  Socket依赖。如果服务C依赖于服务S的socket，那么就要先启动S，然后再启动C，因为如果C启动时找不到S的Socket，那么C就会失败。systemd 可以帮你在S还没有启动好的时候，建立一个socket，用来接收所有的C的请求和数据，并缓存之，一旦S全部启动完成，把systemd替换好的这个缓存的数据和Socket描述符替换过去。\n  D-Bus依赖。D-Bus 全称 Desktop Bus，是一个用来在进程间通信的服务。除了用于用户态进程和内核态进程通信，也用于用户态的进程之前。现在，很多的现在的服务进程都用 D-Bus 而不是Socket来通信。比如：NetworkManager 就是通过 D-Bus 和其它服务进程通讯的，也就是说，如果一个进程需要知道网络的状态，那么就必需要通过 D-Bus 通信。D-Bus 支持 “Bus Activation”的特性。也就是说，A要通过 D-Bus 服务和B通讯，但是B没有启动，那么 D-Bus 可以把B起来，在B启动的过程中，D-Bus 帮你缓存数据。systemd 可以帮你利用好这个特性来并行启动 A 和 B。\n  文件系统依赖。系统启动过程中，文件系统相关的活动是最耗时的，比如挂载文件系统，对文件系统进行磁盘检查（fsck），磁盘配额检查等都是非常耗时的操作。在等待这些工作完成的同时，系统处于空闲状态。那些想使用文件系统的服务似乎必须等待文件系统初始化完成才可以启动。systemd 参考了 autofs 的设计思路，使得依赖文件系统的服务和文件系统本身初始化两者可以并发工作。autofs 可以监测到某个文件系统挂载点真正被访问到的时候才触发挂载操作，这是通过内核 automounter 模块的支持而实现的。比如一个 open() 系统调用作用在某个文件系统上的时候，而这个文件系统尚未执行挂载，此时 open() 调用被内核挂起等待，等到挂载完成后，控制权返回给 open() 系统调用，并正常打开文件。这个过程和 autofs 是相似的。\n  下图来自 Lennart 的演讲里的一页PPT，展示了不同 init 系统的启动。\n除此之外，systemd 还在启动时管理好了一些下面的事。\n用C语言取代传统的脚本式的启动。前面说过，sysvint 用 /etc/rcX.d 下的各种脚本启动。然而这些脚本中需要使用 awk, sed, grep, find, xargs 等等这些操作系统的命令，这些命令需要生成进程，生成进程的开销很大，关键是生成完这些进程后，这个进程就干了点屁大的事就退了。换句话说就是，我操作系统干了那么多事为你拉个进程起来，结果你就把个字串转成小写就退了，把我操作系统当什么了？\n在正常的一个 sysvinit 的脚本里，可能会有成百上千个这样的命令。所以，慢死。因此，systemd 全面用 C 语言全部取代了。一般来说，sysvinit 下，操作系统启动完成后，用 echo $$ 可以看到，pid 被分配到了上千的样子，而 systemd 的系统只是上百。\n另外，systemd 是真正一个可以管住服务进程的——可以跟踪上服务进程所fork/exec出来的所有进程。\n  我们知道， 传统 Unix/Linux 的 Daemon 服务进程的最佳实践基本上是这个样子的（具体过程可参看这篇文章“[SysV Daemon](http://0pointer.de/public/systemd-man/daemon.html#SysV Daemons)”）\n 进程启动时，关闭所有的打开的文件描述符（除了标准描述符0,1,2），然后重置所有的信号处理。 调用 fork() 创建子进程，在子进程中 setsid()，然后父进程退出（为了后台执行） 在子进程中，再调用一次 fork()，创建孙子进程，确定没有交互终端。然后子进程退出。 在孙子进程中，把标准输入标准输出标准错误都连到 /dev/null 上，还要创建 pid 文件，日志文件，处理相关信号 …… 最后才是真正开始提供服务。    在上面的这个过程中，服务进程除了两次 fork 外还会 fork 出很多很多的子进程（比如说一些Web服务进程，会根据用户的请求链接来 fork 子进程），这个进程树是相当难以管理的，因为，一旦父进程退出来了，子进程就会被挂到 PID 1下，所以，基本上来说，你无法通过服务进程自已给定的一个pid文件来找到所有的相关进程（这个对开发者的要求太高了），所以，在传统的方式下用脚本启停服务是相当相当的 Buggy 的，因为无法做对所有的服务生出来的子子孙孙做到监控。\n  为了解决这个问题，upstart 通过变态的 strace 来跟踪进程中的 fork() 和 exec() 或 exit() 等相关的系统调用。这种方法相当笨拙。 systemd 使用了一个非常有意思的玩法来 tracking 服务进程生出来的所有进程，那就是用 cgroup （我在 Docker 的基础技术“cgroup篇”中讲过这个东西）。cgroup主要是用来管理进程组资源配额的事，所以，无论服务如何启动新的子进程，所有的这些相关进程都会同属于一个 cgroup，所以，systemd 只需要简单的去遍历一下相应的 cgroup 的那个虚文件系统目录下的文件，就可以正确的找到所有的相关进程，并将他们一一停止。\n  另外，systemd 简化了整个 daemon 开发的过程：\n 不需要两次 fork()，只需要实现服务本身的主逻辑就可以了。 不需要 setsid()，systemd 会帮你干 不需要维护 pid文件，systemd 会帮处理。 不需要管理日志文件或是使用syslog，或是处理HUP的日志reload信号。把日志打到 stderr 上，systemd 帮你管理。 处理 SIGTERM 信号，这个信号就是正确退出当前服务，不要做其他的事。 ……  除此之外，systemd 还能——\n 自动检测启动的服务间有没有环形依赖。 内建 autofs 自动挂载管理功能。 日志服务。systemd 改造了传统的 syslog 的问题，采用二进制格式保存日志，日志索引更快。 快照和恢复。对当前的系统运行的服务集合做快照，并可以恢复。 ……  还有好多好多，他接管很多很多东西，于是就让很多人不爽了，因为他在干了很多本不属于 PID 1 的事。\nSystemd 争论和八卦 于是 systemd 这个东西成了可能是有史以来口水战最多的一个开源软件了。systemd 饱受各种争议，最大的争议就是他破坏了 Unix 的设计哲学（相关的哲学可以读一下《Unix编程艺术》），干了一个大而全而且相当复杂的东西。当然，Lennart 并不同意这样的说法，他后来又写一篇blog “The Biggest Myths”来解释 systemd 并不是这样的，大家可以前往一读。\n这个争议大到什么样子呢？2014 年，Debian Linux 因为想准备使用 systemd 来作为标准的 init 守护进程来替换 sysvinit 。而围绕这个事的争论达到了空前的热度，争论中充满着仇恨，systemd 的支持者和反对者都在互相辱骂，导致当时 Debian 阵营开始分裂。还有人给 Lennart 发了死亡威胁的邮件，用比特币雇凶买杀手，扬言要取他的性命，在Youbute上传了侮辱他的歌曲，在IRC和各种社交渠道上给他发下流和侮辱性的消息。这已经不是争议了，而是一种不折不扣的仇恨！\n于是，Lennart 在 Google Plus 上发了贴子，批评整个 Linux 开源社区和 Linus 本人。他大意说，\n 这个社区太病态了，全是 ass holes，你们不停用各种手段在各种地方用不同的语言和方式来侮辱和漫骂我。我还是一个年轻人，我从来没有经历过这样的场面，但是今天我已经对这种场面很熟悉了。我有时候说话可能不准确，但是我不会像他样那样说出那样的话，我也没有被这些事影响，因为我脸皮够厚，所以，为什么我可以在如何大的反对声面前让 systemd 成功，但是，你们 Linux 社区太可怕了。你们里面的有精神病的人太多了。另外，对于Linus Torvalds，你是这个社区的 Role Model，但可惜你是一个 Bad Role Model，你在社区里的刻薄和侮辱性的言行，基本从一定程度上鼓励了其它人跟你一样，当然，并不只是你一个人的问题，而是在你周围聚集了一群和你一样的这样干的人。送你一句话—— A fish rots from the head down ！一条鱼是从头往下腐烂的……\n 这篇契文很长，喜欢八卦的同学可以前往一读。感受一下 Lennart 当时的心态（我觉得能算上是非常平稳了）。\nLinus也在被一媒体问起 systemd 这个事来（参看“Torvalds says he has no strong opinions on systemd”），Linus在采访里说，\n 我对 systemd 和 Lennart 的贴子没有什么强烈的想法。虽然，传统的 Unix 设计哲学—— “Do one thing and Do it well”，很不错，而且我们大多数人也实践了这么多年，但是这并不代表所有的真实世界。在历史上，也不只有systemd 这么干过。但是，我个人还是 old-fashioned 的人，至少我喜欢文本式的日志，而不是二进制的日志。但是 systemd 没有必要一定要有这样的品味。哦，我说细节了……\n 今天，systemd 占据了几乎所有的主流的 Linux 发行版的默认配置，包括：Arch Linux、CentOS、CoreOS、Debian、Fedora、Megeia、OpenSUSE、RHEL、SUSE企业版和 Ubuntu。而且，对于 CentOS, CoreOS, Fedora, RHEL, SUSE这些发行版来说，不能没有 systemd。（Ubuntu 还有一个不错的wiki – Systemd for Upstart Users 阐述了如何在两者间切换）\n其它 还记得在《缓存更新的套路》一文中，我说过，如果你要做好架构，首先你得把计算机体系结构以及很多老古董的基础技术吃透了。因为里面会有很多可以借鉴和相通的东西。那么，你是否从这篇文章里看到了一些有分布式架构相似的东西？\n比如：从 sysvinit 到 upstart 再到 systemd，像不像是服务治理？Linux系统下的这些服务进程，是不是很像分布式架构中的微服务？还有那个D-Bus，是不是很像SOA里的ESB？而 init 系统是不是很像一个控制系统？甚至像一个服务编排（Service Orchestration）系统？\n分布式系统中的服务之间也有很多依赖，所以，在启动一个架构的时候，如果我们可以做到像 systemd 那样并行启动的话，那么是不是就像是一个微服务的玩法了？\n嗯，你会发现，技术上的很多东西是相通的，也是互相有对方的影子，所以，其实技术并不多。关键是我们学在了表面还是看到了本质。\n命令 Systemd 是 Linux 系统工具，用来启动守护进程，已成为大多数发行版的标准配置。\n系统管理 Systemd 并不是一个命令，而是一组命令，涉及到系统管理的方方面面。\nsystemctl\nsystemctl是 Systemd 的主命令，用于管理系统。\n# 重启系统 $ sudo systemctl reboot # 关闭系统，切断电源 $ sudo systemctl poweroff # CPU停止工作 $ sudo systemctl halt # 暂停系统 $ sudo systemctl suspend # 让系统进入冬眠状态 $ sudo systemctl hibernate # 让系统进入交互式休眠状态 $ sudo systemctl hybrid-sleep # 启动进入救援状态（单用户状态） $ sudo systemctl rescue systemd-analyze\nsystemd-analyze命令用于查看启动耗时。\n# 查看启动耗时 $ systemd-analyze # 查看每个服务的启动耗时 $ systemd-analyze blame # 显示瀑布状的启动过程流$ $ systemd-analyze critical-chain # 显示指定服务的启动流 $ systemd-analyze critical-chain atd.service hostnamectl\nhostnamectl命令用于查看当前主机的信息。\n# 显示当前主机的信息 $ hostnamectl # 设置主机名。 $ sudo hostnamectl set-hostname rhel7 localectl\nlocalectl命令用于查看本地化设置。\n# 查看本地化设置 $ localectl # 设置本地化参数。 $ sudo localectl set-locale LANG=en_GB.utf8 $ sudo localectl set-keymap en_GB timedatectl\ntimedatectl命令用于查看当前时区设置。\n# 查看当前时区设置 $ timedatectl # 显示所有可用的时区 $ timedatectl list-timezones # 设置当前时区 $ sudo timedatectl set-timezone America/New_York $ sudo timedatectl set-time YYYY-MM-DD $ sudo timedatectl set-time HH:MM:SS loginctl\nloginctl命令用于查看当前登录的用户。\n# 列出当前session $ loginctl list-sessions # 列出当前登录用户 $ loginctl list-users # 列出显示指定用户的信息 $ loginctl show-user ruanyf Unit 含义\nSystemd 可以管理所有系统资源。不同的资源统称为 Unit（单元）。简单说，单元就是 Systemd 的最小功能单位，是单个进程的描述。一个个小的单元互相调用和依赖，组成一个庞大的任务管理系统，这就是 Systemd 的基本思想。\n由于 Systemd 要做的事情太多，导致单元有很多不同的种类，大概一共有12种。\n Service unit：系统服务 Target unit：多个 Unit 构成的一个组 Device Unit：硬件设备 Mount Unit：文件系统的挂载点 Automount Unit：自动挂载点 Path Unit：文件或路径 Scope Unit：不是由 Systemd 启动的外部进程 Slice Unit：进程组，资源分配 Snapshot Unit：Systemd 快照，可以切回某个快照 Socket Unit：进程间通信的 socket Swap Unit：swap 文件 Timer Unit：定时器  systemctl list-units命令可以查看当前系统的所有 Unit 。\n# 列出正在运行的 Unit $ systemctl list-units # 列出所有Unit，包括没有找到配置文件的或者启动失败的 $ systemctl list-units --all # 列出所有没有运行的 Unit $ systemctl list-units --all --state=inactive # 列出所有加载失败的 Unit $ systemctl list-units --failed # 列出所有正在运行的、类型为 service 的 Unit $ systemctl list-units --type=service Unit 的状态\nsystemctl status命令用于查看系统状态和单个 Unit 的状态。\n# 显示系统状态 $ systemctl status # 显示单个 Unit 的状态 $ sysystemctl status bluetooth.service # 显示远程主机的某个 Unit 的状态 $ systemctl -H root@rhel7.example.com status httpd.service 例如查看 httpd 状态\n$ sudo systemctl status httpd httpd.service - The Apache HTTP Server Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled) Active: active (running) since 金 2014-12-05 12:18:22 JST; 7min ago Main PID: 4349 (httpd) Status: \u0026#34;Total requests: 1; Current requests/sec: 0; Current traffic: 0 B/sec\u0026#34; CGroup: /system.slice/httpd.service ├─4349 /usr/sbin/httpd -DFOREGROUND ├─4350 /usr/sbin/httpd -DFOREGROUND ├─4351 /usr/sbin/httpd -DFOREGROUND ├─4352 /usr/sbin/httpd -DFOREGROUND ├─4353 /usr/sbin/httpd -DFOREGROUND └─4354 /usr/sbin/httpd -DFOREGROUND 12月 05 12:18:22 localhost.localdomain systemd[1]: Starting The Apache HTTP Server... 12月 05 12:18:22 localhost.localdomain systemd[1]: Started The Apache HTTP Server. 12月 05 12:22:40 localhost.localdomain systemd[1]: Started The Apache HTTP Server. 上面的输出结果含义如下。\n Loaded行：配置文件的位置，是否设为开机启动 Active行：表示正在运行 Main PID行：主进程ID Status行：由应用本身（这里是 httpd ）提供的软件当前状态 CGroup块：应用的所有子进程 日志块：应用的日志  除了status命令，systemctl还提供了三个查询状态的简单方法，主要供脚本内部的判断语句使用。\n# 显示某个 Unit 是否正在运行 $ systemctl is-active application.service # 显示某个 Unit 是否处于启动失败状态 $ systemctl is-failed application.service # 显示某个 Unit 服务是否建立了启动链接 $ systemctl is-enabled application.service Unit 管理\n对于用户来说，最常用的是下面这些命令，用于启动和停止 Unit（主要是 service）。\n# 立即启动一个服务 $ sudo systemctl start apache.service # 立即停止一个服务 $ sudo systemctl stop apache.service # 重启一个服务 $ sudo systemctl restart apache.service # 杀死一个服务的所有子进程 $ sudo systemctl kill apache.service # 重新加载一个服务的配置文件 $ sudo systemctl reload apache.service # 重载所有修改过的配置文件 $ sudo systemctl daemon-reload # 显示某个 Unit 的所有底层参数 $ systemctl show httpd.service # 显示某个 Unit 的指定属性的值 $ systemctl show -p CPUShares httpd.service # 设置某个 Unit 的指定属性 $ sudo systemctl set-property httpd.service CPUShares=500 有时候，该命令可能没有响应，执行systemctl stop服务停不下来。这时候就不得不\u0026quot;杀进程\u0026quot;了，向正在运行的进程发出kill信号，执行systemctl kill。\n依赖关系\nUnit 之间存在依赖关系：A 依赖于 B，就意味着 Systemd 在启动 A 的时候，同时会去启动 B。\nsystemctl list-dependencies命令列出一个 Unit 的所有依赖。\n$ systemctl list-dependencies nginx.service 上面命令的输出结果之中，有些依赖是 Target 类型（详见下文），默认不会展开显示。如果要展开 Target，就需要使用--all参数。\n$ systemctl list-dependencies --all nginx.service Unit 的配置文件 概述\n每一个 Unit 都有一个配置文件，告诉 Systemd 怎么启动这个 Unit 。\n除了系统默认的单元文件/lib/systemd/system，Systemd 默认从目录/etc/systemd/system/读取配置文件。但是，里面存放的大部分文件都是符号链接，指向目录/usr/lib/systemd/system/。那些支持 Systemd 的软件，安装的时候，也会自动在/usr/lib/systemd/system目录添加一个配置文件。\nsystemctl enable命令用于在/etc/systemd/system/和/usr/lib/systemd/system之间，建立符号链接关系。\n$ sudo systemctl enable clamd@scan.service # 等同于 $ sudo ln -s \u0026#39;/usr/lib/systemd/system/clamd@scan.service\u0026#39; \u0026#39;/etc/systemd/system/multi-user.target.wants/clamd@scan.service\u0026#39; 如果配置文件里面设置了开机启动，systemctl enable命令相当于激活开机启动。\n与之对应的，systemctl disable命令用于在两个目录之间，撤销符号链接关系，相当于撤销开机启动。\n$ sudo systemctl disable clamd@scan.service 配置文件的后缀名，就是该 Unit 的种类，比如sshd.socket。如果省略，Systemd 默认后缀名为.service，所以sshd会被理解成sshd.service。\n设置开机启动以后，软件并不会立即启动，必须等到下一次开机。如果想现在就运行该软件，那么要执行systemctl start命令。\n配置文件的状态\nsystemctl list-unit-files命令用于列出所有配置文件。\n# 列出所有配置文件 $ systemctl list-unit-files # 列出指定类型的配置文件 $ systemctl list-unit-files --type=service 这个命令会输出一个列表。\n$ systemctl list-unit-filesUNIT FILE STATEchronyd.service enabledclamd@.service staticclamd@scan.service disabled 这个列表显示每个配置文件的状态，一共有四种。\n enabled：已建立启动链接 disabled：没建立启动链接 static：该配置文件没有[Install]部分（无法执行），只能作为其他配置文件的依赖 masked：该配置文件被禁止建立启动链接  注意，从配置文件的状态无法看出，该 Unit 是否正在运行。这必须执行前面提到的systemctl status命令。\n$ systemctl status bluetooth.service 一旦修改配置文件，就要让 Systemd 重新加载配置文件，然后重新启动，否则修改不会生效。\n$ sudo systemctl daemon-reload $ sudo systemctl restart httpd.service 配置文件的格式\n配置文件就是普通的文本文件，可以用文本编辑器打开。\nsystemctl cat命令可以查看配置文件的内容。\n$ systemctl cat sshd.service [Unit] Description=OpenSSH server daemon Documentation=man:sshd(8) man:sshd_config(5) After=network.target sshd-keygen.service Wants=sshd-keygen.service [Service] EnvironmentFile=/etc/sysconfig/sshd ExecStart=/usr/sbin/sshd -D $OPTIONS ExecReload=/bin/kill -HUP $MAINPID Type=simpleKill Mode=process Restart=on-failure RestartSec=42s [Install] WantedBy=multi-user.target 从上面的输出可以看到，配置文件分成几个区块。每个区块的第一行，是用方括号表示的区别名，比如[Unit]。注意，配置文件的区块名和字段名，都是大小写敏感的。\n每个区块内部是一些等号连接的键值对。\n[Section] Directive1=value Directive2=value . . . 注意，键值对的等号两侧不能有空格。\n配置文件的区块\n[Unit]区块通常是配置文件的第一个区块，用来定义 Unit 的元数据，以及配置与其他 Unit 的关系。它的主要字段如下。\n  Description：当前服务的简单描述\n  Documentation：文档地址\n  启动顺序\n Before：如果该字段指定的 Unit 也要启动，那么必须在当前 Unit 之后启动 After：如果该字段指定的 Unit 也要启动，那么必须在当前 Unit 之前启动。如network.target或sshd-keygen.service需要启动，那么sshd.service应该在它们之后启动。    依赖关系：\n举例来说，某 Web 应用需要 postgresql 数据库储存数据。在配置文件中，Before、After 只定义要在 postgresql 之后启动，而没有定义依赖 postgresql 。上线后，由于某种原因，postgresql 需要重新启动，在停止服务期间，该 Web 应用就会无法建立数据库连接。\n注意，Wants字段与Requires字段只涉及依赖关系，与启动顺序无关，默认情况下是同时启动的。\n Wants：与当前 Unit 配合的其他 Unit，如果它们没有运行，当前 Unit 不会启动失败。如sshd.service与sshd-keygen.service之间存在\u0026quot;弱依赖\u0026quot;关系，即如果\u0026quot;sshd-keygen.service\u0026quot;启动失败或停止运行，不影响sshd.service继续执行。 Requires：当前 Unit 依赖的其他 Unit，如果它们没有运行，当前 Unit 会启动失败。Requires字段则表示\u0026quot;强依赖\u0026quot;关系，即如果该服务启动失败或异常退出，那么sshd.service也必须退出。    BindsTo：与Requires类似，它指定的 Unit 如果退出，会导致当前 Unit 停止运行\n  Conflicts：这里指定的 Unit 不能与当前 Unit 同时运行\n  Condition...：当前 Unit 运行必须满足的条件，否则不会运行\n  Assert...：当前 Unit 运行必须满足的条件，否则会报启动失败\n  StartLimitIntervalSec=interval, StartLimitBurst=burst：设置单元的启动频率限制。 也就是该单元在 interval 时间内最多允许启动 burst 次。\n   [Service]区块用来定义如何启动当前服务，只有 Service 类型的 Unit 才有这个区块。它的主要字段如下。\n EnvironmentFile字段：指定当前服务的环境参数文件。该文件内部的key=value键值对，可以用$key的形式，在当前配置文件中获取。sshd 的环境参数文件是/etc/sysconfig/sshd。 ExecStart字段：定义启动进程时执行的命令。是配置文件里面最重要的字段。上面的例子中，启动sshd，执行的命令是/usr/sbin/sshd -D $OPTIONS，其中的变量$OPTIONS就来自EnvironmentFile字段指定的环境参数文件。与之作用相似的，还有如下这些字段。  ExecReload字段：重启服务时执行的命令 ExecStop字段：停止服务时执行的命令 ExecStartPre字段：启动服务之前执行的命令 ExecStartPost字段：启动服务之后执行的命令 ExecStopPost字段：停止服务之后执行的命令   Type：字段定义启动类型。它可以设置的值如下。  simple（默认值）：ExecStart字段启动的进程为主进程 forking：ExecStart字段将以fork()方式启动，此时父进程将会退出，子进程将成为主进程 oneshot：类似于simple，但只执行一次，Systemd 会等它执行完，才启动其他服务 dbus：类似于simple，但会等待 D-Bus 信号后启动 notify：类似于simple，启动结束后会发出通知信号，然后 Systemd 再启动其他服务 idle：类似于simple，但是要等到其他任务都执行完，才会启动该服务。一种使用场合是为让该服务的输出，不与其他服务的输出相混合   KillMode字段：定义 Systemd 如何停止服务。  control-group（默认值）：当前控制组里面的所有子进程，都会被杀掉 process：只杀主进程。比如sshd的KillMode设为process，子进程打开的 SSH session 仍然保持连接。 mixed：主进程将收到 SIGTERM 信号，子进程收到 SIGKILL 信号 none：没有进程会被杀掉，只是执行服务的 stop 命令。   Restart：Restart字段：定义了服务退出后，Systemd 重启该服务的方式。  no（默认值）：退出后不会重启 on-success：只有正常退出时（退出状态码为0），才会重启 on-failure：非正常退出时（退出状态码非0），包括被信号终止和超时，才会重启。比如sshd任何意外的失败，都将重启sshd；如果 sshd 正常停止（比如执行systemctl stop命令），它就不会重启。对于守护进程，推荐设为on-failure。 on-abnormal：只有被信号终止和超时，才会重启。对于那些允许发生错误退出的服务，可以设为on-abnormal。 on-abort：只有在收到没有捕捉到的信号终止时，才会重启 on-watchdog：超时退出，才会重启 always：不管是什么退出原因，总是重启   RestartSec字段：表示 Systemd 重启服务之前，需要等待的秒数。 TimeoutSec：定义 Systemd 停止当前服务之前等待的秒数  所有的启动设置之前，都可以加上一个连词号（-），表示\u0026quot;抑制错误\u0026quot;，即发生错误的时候，不影响其他命令的执行。比如，EnvironmentFile=-/etc/sysconfig/sshd（注意等号后面的那个连词号），就表示即使/etc/sysconfig/sshd文件不存在，也不会抛出错误。\n [Install]通常是配置文件的最后一个区块，定义如何安装这个配置文件，即怎样做到开机启动。它的主要字段如下。\n WantedBy字段：表示该服务所在的 Target，它的值是一个或多个 Target。Target的含义是服务组，表示一组服务。WantedBy=multi-user.target指的是，sshd 所在的 Target 是multi-user.target。当前 Unit 激活时（enable）符号链接会放入/etc/systemd/system目录下面 [Target 名].wants子目录中，如multi-user.target.wants子目录。 RequiredBy：它的值是一个或多个 Target，当前 Unit 激活时，符号链接会放入/etc/systemd/system目录下面以 Target 名 + .required后缀构成的子目录中 Alias：当前 Unit 可用于启动的别名 Also：当前 Unit 激活（enable）时，会被同时激活的其他 Unit  Unit 配置文件的完整字段清单，请参考官方文档。\nTarget 启动计算机的时候，需要启动大量的 Unit。如果每一次启动，都要一一写明本次启动需要哪些 Unit，显然非常不方便。Systemd 的解决方案就是 Target。\n简单说，Target 就是一个 Unit 组，包含许多相关的 Unit 。启动某个 Target 的时候，Systemd 就会启动里面所有的 Unit。从这个意义上说，Target 这个概念类似于\u0026quot;状态点\u0026quot;，启动某个 Target 就好比启动到某种状态。\n传统的init启动模式里面，有 RunLevel 的概念，跟 Target 的作用很类似。不同的是，RunLevel 是互斥的，不可能多个 RunLevel 同时启动，但是多个 Target 可以同时启动。\n# 查看当前系统的所有 Target $ systemctl list-unit-files --type=target # 查看一个 Target 包含的所有 Unit $ systemctl list-dependencies multi-user.target # 查看启动时的默认 Target，在这个组里的所有服务，都将开机启动。 $ systemctl get-default # 设置启动时的默认 Target $ sudo systemctl set-default multi-user.target # 切换 Target 时，默认不关闭前一个 Target 启动的进程， # systemctl isolate 命令改变这种行为， # 关闭前一个 Target 里面所有不属于后一个 Target 的进程 $ sudo systemctl isolate multi-user.target Target 与 传统 RunLevel 的对应关系如下。\nTraditional runlevel New target name Symbolically linked to... Runlevel 0 | runlevel0.target -\u0026gt; poweroff.target Runlevel 1 | runlevel1.target -\u0026gt; rescue.target Runlevel 2 | runlevel2.target -\u0026gt; multi-user.target Runlevel 3 | runlevel3.target -\u0026gt; multi-user.target Runlevel 4 | runlevel4.target -\u0026gt; multi-user.target Runlevel 5 | runlevel5.target -\u0026gt; graphical.target Runlevel 6 | runlevel6.target -\u0026gt; reboot.target 它与init进程的主要差别如下。\n（1）默认的 RunLevel（在/etc/inittab文件设置）现在被默认的 Target 取代，位置是/etc/systemd/system/default.target，通常符号链接到graphical.target（图形界面）或者multi-user.target（多用户命令行）。\n（2）启动脚本的位置，以前是/etc/init.d目录，符号链接到不同的 RunLevel 目录 （比如/etc/rc3.d、/etc/rc5.d等），现在则存放在/lib/systemd/system和/etc/systemd/system目录。\n（3）配置文件的位置，以前init进程的配置文件是/etc/inittab，各种服务的配置文件存放在/etc/sysconfig目录。现在的配置文件主要存放在/lib/systemd目录，在/etc/systemd目录里面的修改可以覆盖原始设置。\n日志管理 Systemd 统一管理所有 Unit 的启动日志。带来的好处就是，可以只用journalctl一个命令，查看所有日志（内核日志和应用日志）。日志的配置文件是/etc/systemd/journald.conf。\njournalctl功能强大，用法非常多。\n# 查看所有日志（默认情况下 ，只保存本次启动的日志） $ sudo journalctl # 查看内核日志（不显示应用日志） $ sudo journalctl -k # 查看系统本次启动的日志 $ sudo journalctl -b $ sudo journalctl -b -0 # 查看上一次启动的日志（需更改设置） $ sudo journalctl -b -1 # 查看指定时间的日志 $ sudo journalctl --since=\u0026#34;2012-10-30 18:17:16\u0026#34; $ sudo journalctl --since \u0026#34;20 min ago\u0026#34; $ sudo journalctl --since yesterday $ sudo journalctl --since \u0026#34;2015-01-10\u0026#34; --until \u0026#34;2015-01-11 03:00\u0026#34; $ sudo journalctl --since 09:00 --until \u0026#34;1 hour ago\u0026#34; # 显示尾部的最新10行日志 $ sudo journalctl -n # 显示尾部指定行数的日志 $ sudo journalctl -n 20 # 实时滚动显示最新日志 $ sudo journalctl -f # 查看指定服务的日志 $ sudo journalctl /usr/lib/systemd/systemd # 查看指定进程的日志 $ sudo journalctl _PID=1 # 查看某个路径的脚本的日志 $ sudo journalctl /bin/bash # 查看指定用户的日志 $ sudo journalctl _UID=33 --since today # 查看某个 Unit 的日志 $ sudo journalctl -u nginx.service $ sudo journalctl -u nginx.service --since today # 实时滚动显示某个 Unit 的最新日志 $ sudo journalctl -u nginx.service -f # 合并显示多个 Unit 的日志 $ journalctl -u nginx.service -u php-fpm.service --since today # 查看指定优先级（及其以上级别）的日志，共有8级 # 0: emerg # 1: alert # 2: crit # 3: err # 4: warning # 5: notice # 6: info # 7: debug $ sudo journalctl -p err -b # 日志默认分页输出，--no-pager 改为正常的标准输出 $ sudo journalctl --no-pager # 以 JSON 格式（单行）输出 $ sudo journalctl -b -u nginx.service -o json # 以 JSON 格式（多行）输出，可读性更好 $ sudo journalctl -b -u nginx.serviceqq -o json-pretty # 显示日志占据的硬盘空间 $ sudo journalctl --disk-usage # 指定日志文件占据的最大空间 $ sudo journalctl --vacuum-size=1G # 指定日志文件保存多久 $ sudo journalctl --vacuum-time=1years 定时器示例 邮件脚本 先写一个发邮件的脚本mail.sh。\n#!/usr/bin/env bash echo \u0026#34;This is the body\u0026#34; | /usr/bin/mail -s \u0026#34;Subject\u0026#34; someone@example.com 上面代码的someone@example.com，请替换成你的邮箱地址。\n然后，执行这个脚本。\n$ bash mail.sh 执行后，你应该就会收到一封邮件，标题为Subject。\n如果你的 Linux 系统不能发邮件，建议安装 ssmtp 或者 msmtp。另外，mail命令的用法，可以参考这里。\nService 单元 Service 单元就是所要执行的任务，比如发送邮件就是一种 Service。\n新建 Service 非常简单，就是在/usr/lib/systemd/system目录里面新建一个文件，比如mytimer.service文件，你可以写入下面的内容。\n[Unit] Description=MyTimer [Service] ExecStart=/bin/bash /path/to/mail.sh 注意，定义的时候，所有路径都要写成绝对路径，比如bash要写成/bin/bash，否则 Systemd 会找不到。\n现在，启动这个 Service。\n$ sudo systemctl start mytimer.service 如果一切正常，你应该就会收到一封邮件。\nTimer 单元 Service 单元只是定义了如何执行任务，要定时执行这个 Service，还必须定义 Timer 单元。\n/usr/lib/systemd/system目录里面，新建一个mytimer.timer文件，写入下面的内容。\n[Unit] Description=Runs mytimer every hour [Timer] OnUnitActiveSec=1h Unit=mytimer.service [Install] WantedBy=multi-user.target 这个 Timer 单元文件分成几个部分。\n[Timer]部分定制定时器。Systemd 提供以下一些字段。\n OnActiveSec：定时器生效后，多少时间开始执行任务 OnBootSec：系统启动后，多少时间开始执行任务 OnStartupSec：Systemd 进程启动后，多少时间开始执行任务 OnUnitActiveSec：该单元上次执行后，等多少时间再次执行 OnUnitInactiveSec： 定时器上次关闭后多少时间，再次执行 OnCalendar：基于绝对时间，而不是相对时间执行 AccuracySec：如果因为各种原因，任务必须推迟执行，推迟的最大秒数，默认是60秒 Unit：真正要执行的任务，默认是同名的带有.service后缀的单元 Persistent：如果设置了该字段，即使定时器到时没有启动，也会自动执行相应的单元 WakeSystem：如果系统休眠，是否自动唤醒系统  上面的脚本里面，OnUnitActiveSec=1h表示一小时执行一次任务。其他的写法还有OnCalendar=*-*-* 02:00:00表示每天凌晨两点执行，OnCalendar=Mon *-*-* 02:00:00表示每周一凌晨两点执行，具体请参考中文手册。\nSystem time 一个操作系统通过如下内容确定时间：时间数值、时间标准、时区和夏令时调节(中国已经废止)。本文分别介绍各个部分的定义及如何设置他们。要维护准确的系统时间，请参考 网络时间协议 一文。\n硬件时钟和系统时钟 系统用两个时钟保存时间：硬件时钟和系统时钟。\n硬件时钟(即实时时钟 RTC 或 CMOS 时钟)仅能保存：年、月、日、时、分、秒这些时间数值，无法保存时间标准(UTC 或 localtime)和是否使用夏令时调节。\n系统时钟(即软件时间) 与硬件时间分别维护，保存了：时间、时区和夏令时设置。Linux 内核保存为自 UTC 时间 1970 年1月1日经过的秒数。初始系统时钟是从硬件时间计算得来，计算时会考虑/etc/adjtime的设置。系统启动之后，系统时钟与硬件时钟独立运行，Linux 通过时钟中断计数维护系统时钟。\n如果系统时间是按 32 位整数保存的，最大只能记到 2038 年，所以 32 位 Linux 系统将在 2038 年停止工作。\n大部分操作系统的时间管理包括如下方面：\n 启动时根据硬件时钟设置系统时间 运行时通过时间同步联网校正时间 关机时根据系统时间设置硬件时间  读取时间 下面命令可以获得硬件时间和系统时间(硬件时钟按 localtime 显示):\n$ timedatectl Local time: Thu 2022-01-27 10:35:26 CST Universal time: Thu 2022-01-27 02:35:26 UTC RTC time: Thu 2022-01-27 02:35:26 Time zone: Asia/Shanghai (CST, +0800) System clock synchronized: yes NTP service: active RTC in local TZ: no 名词解释：\n CST：(China Standard Time,UTC+8:00) 中国沿海时间(北京时间) UTC：(Universal Time Coordinated,UTC) 世界协调时间 GMT：(Greenwich Mean Time ,GMT）格林威治时间 LT：(locale time）本地时间  设置时间 设置系统时间的本地时间：\n# timedatectl set-time \u0026#34;yyyy-MM-dd hh:mm:ss\u0026#34; 例如:\n# timedatectl set-time \u0026#34;2014-05-26 11:13:54\u0026#34; 设置时间为2014年，5月26日，11时13分54秒。\n时间标准 时间表示有两个标准：localtime 和 UTC(Coordinated Universal Time) 。UTC 是与时区无关的全球时间标准。尽管概念上有差别，UTC 和 GMT (格林威治时间) 是一样的。localtime 标准则依赖于当前时区。\n时间标准由操作系统设定，Windows 默认使用 localtime，Mac OS 默认使用 UTC，而 UNIX 系列的操作系统两者都有。使用 Linux 时，最好将硬件时钟设置为 UTC 标准，并在所有操作系统中使用。这样 Linux 系统就可以自动调整夏令时设置，而如果使用 localtime 标准那么系统时间不会根据夏令时自动调整。\n通过如下命令可以检查当前设置，systemd 默认硬件时钟为协调世界时（UTC）。\n$ timedatectl status | grep local RTC in local TZ: no 硬件时间可以用 hwclock 命令设置，将硬件时间设置为 localtime：\n# timedatectl set-local-rtc 1 硬件时间设置成 UTC：\n# timedatectl set-local-rtc 0 上述命令会自动生成/etc/adjtime，无需单独设置。\n注意： 如果不存在 /etc/adjtime，systemd 会假定硬件时间按 UTC 设置。\n系统启动装入 rtc 驱动时可能会根据系统时钟设置硬件时钟。是否设置依赖于平台、内核版本和内核编译选项。如果进行了设置，此时会假定硬件时钟为 UTC 标准，/sys/class/rtc/rtcN/hctosys(N=0,1,2,..) 会设置成 1。后面 systemd 会根据/etc/adjtime重新设置。\n如果设置成本地时间，处理夏令时有些麻烦。如果夏令时调整发生在关机时，下次启动时时间会出现问题（更多信息）。最新的内核直接从实时时钟芯片（RTC）读取时间，不使用 hwclock，内核把从 RTC 读取的时间当作 UTC 处理。所以如果硬件时间是地方时，系统启动一开始识别的时间是错误的，之后很快会进行矫正。这可能导致一些问题（尤其是时间倒退时）。\nWindows 系统使用 UTC 如果同时安装了 Windows 操作系统（默认使用地方时），那么一般 RTC 会被设置为地方时。Windows 其实也能处理 UTC，需要修改注册表。建议让 Windows 使用 UTC，而非让 Linux 使用地方时。Windows 使用 UTC 后，请记得禁用 Windows 的时间同步功能，以防 Windows 错误设置硬件时间。如上文所说，Linux 可以使用NTP服务来在线同步硬件时钟。\n使用 regedit,新建如下 DWORD 值，并将其值设为十六进制的 1。\nHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation\\RealTimeIsUniversal 也可以用管理员权限启动命令行来完成：\nreg add \u0026#34;HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\TimeZoneInformation\u0026#34; /v RealTimeIsUniversal /d 1 /t REG_DWORD /f 如果以上操作不起作用，并且你使用的是 Windows 64位系统，将 DWORD 修改为 QWORD。\n如果 Windows 要求根据夏令时更新时钟，可以允许。时钟仍然是 UTC，仅是显示时间会改变。\n设置时间标准后需要重新设置硬件时间和系统时间。\n如果你有时间偏移问题，再次设置你的时区:\n# timedatectl set-timezone Asia/Shanghai UTC 在Ubuntu的设置 Ubuntu及其衍生发行版会在安装时检测计算机上是否存在Windows，若存在则会默认使用localtime。这是为了让Windows用户能够在不修改注册表的情况下，在Ubuntu内看到正确的时间。\n要改变这种行为，请参见上面的内容。\n时区 检查当前时区：\n$ timedatectl status 显示可用时区：\n$ timedatectl list-timezones 修改时区：\n# timedatectl set-timezone \u0026lt;Zone\u0026gt;/\u0026lt;SubZone\u0026gt; 例如：\n# timedatectl set-timezone Asia/Shanghai 此命令会创建一个/etc/localtime软链接，指向/usr/share/zoneinfo/中的时区文件，如果手动创建此链接请确保是相对链接而不是绝对链接。\n注意： 如果pre-systemd配置的/etc/timezone仍然存在于你的系统，你可以放心地将其删除，因为它不再使用。\n时钟偏移 最能代表“真实时间”的是国际原子时钟)，所有的时钟都是有误差的。电子时钟的时间是不准的，但是一般有固定的偏移。这种于基值的差称为“time skew”或“时间偏移”。用 hwclock 设置硬件时间时，会计算每天偏移的秒数。偏移值是原硬件时间与新设置硬件时间的差，并且考虑上次硬件时间设置时的偏移。新的偏移值会在设置时钟时写到文件 /etc/adjtime 。\n注意： 如果硬件时间值与原值的差小于 24 小时，偏移量不会重新计算，因为时间过短，无法精确设置偏移。\n如果硬件时钟总是过快或过慢，可能是计算了错误的偏移值。硬件时钟设置错误或者时间标准与其他操作系统不一致导致。删除文件 /etc/adjtime 可以删除偏移值，然后设置正确的硬件时钟和系统时钟，并检查时间标准是不是设置正确。\n注意： 使用 Systemd 时，要使用 /etc/adjtime中的 drift 值(即无法或不想使用 NTP 时); 需要每次调用 hwclock --adjust命令，可以通过 cron 任务实现。\n提高系统时间精度的方法有：\nNTP 可以通过网络时间协议同步 Linux 系统的时间。NTP 也会修正中断频率和每秒滴答数以减少时间偏移。并且每隔 11 分钟同步一次硬件时钟。\n时钟同步 网络时间协议 (NTP) 是一个通过包交换和可变延迟网络来同步计算机系统时间的协议。下列为这个协议的实现：\n NTP 守护进程是这个协议的参考实现，推荐用于时间服务器。它也可以调节中断频率和每秒滴答次数以减少系统时钟误差，使得硬件时钟每隔11秒重新同步一次。 sntp 是一个 SNTP 客户端。它取代了 ntpdate ，并被推荐用于非服务器环境。 systemd-timesyncd 是一个简单的 SNTP 守护进程。它只实现了客户端，专用于从远程服务器查询时间，更适用于绝大部分安装的情形。 OpenNTPD 是 OpenBSD 项目的一部分，同时实现了客户端和服务器。 Chrony 是一个客户端和服务器，更适合漫游，是为不能始终保持在线的系统而特别设计。 ntpclient 是简单的命令行 NTP 客户端  防火墙 保障数据的安全性是继保障数据的可用性之后最为重要的一项工作。防火墙作为公网与内网之间的保护屏障，在保障数据的安全性方面起着至关重要的作用。\n防火墙管理工具 众所周知，相较于企业内网，外部的公网环境更加恶劣，罪恶丛生。在公网与企业内网之间充当保护屏障的防火墙虽然有软件或硬件之分，但主要功能都是依据策略对穿越防火墙自身的流量进行过滤。就像家里安装的防盗门一样，目的是保护亲人和财产安全。防火墙策略可以基于流量的源目地址、端口号、协议、应用等信息来定制，然后防火墙使用预先定制的策略规则监控出入的流量，若流量与某一条策略规则相匹配，则执行相应的处理，反之则丢弃。这样一来，就能够保证仅有合法的流量在企业内网和外部公网之间流动了。\n从RHEL 7系统开始，firewalld防火墙正式取代了iptables防火墙。对于接触Linux系统比较早或学习过RHEL 5/6系统的读者来说，当他们发现曾经掌握的知识在RHEL 7/8中不再适用，需要全新学习firewalld时，难免会有抵触心理。其实，iptables与firewalld都不是真正的防火墙，它们都只是用来定义防火墙策略的防火墙管理工具而已；或者说，它们只是一种服务。iptables服务会把配置好的防火墙策略交由内核层面的netfilter网络过滤器来处理，而firewalld服务则是把配置好的防火墙策略交由内核层面的nftables包过滤框架来处理。换句话说，当前在Linux系统中其实存在多个防火墙管理工具，旨在方便运维人员管理Linux系统中的防火墙策略，我们只需要配置妥当其中的一个就足够了。\n虽然这些工具各有优劣，但它们在防火墙策略的配置思路上是保持一致的。大家甚至可以不用完全掌握本章介绍的内容，只要在这多个防火墙管理工具中任选一款并将其学透，就足以满足日常的工作需求了。\nIptables 在早期的Linux系统中，默认使用的是iptables防火墙管理服务来配置防火墙。尽管新型的firewalld防火墙管理服务已经被投入使用多年，但是大量的企业在生产环境中依然出于各种原因而继续使用iptables。\n策略与规则链 防火墙会按照从上到下的顺序来读取配置的策略规则，在找到匹配项后就立即结束匹配工作并去执行匹配项中定义的行为（即放行或阻止）。如果在读取完所有的策略规则之后没有匹配项，就去执行默认的策略。一般而言，防火墙策略规则的设置有两种：“通”（即放行）和“堵”（即阻止）。当防火墙的默认策略为拒绝时（堵），就要设置允许规则（通），否则谁都进不来；如果防火墙的默认策略为允许，就要设置拒绝规则，否则谁都能进来，防火墙也就失去了防范的作用。\niptables服务把用于处理或过滤流量的策略条目称之为规则，多条规则可以组成一个规则链，而规则链则依据数据包处理位置的不同进行分类，具体如下：\n 在进行路由选择前处理数据包（PREROUTING）； 处理流入的数据包（INPUT）； 处理流出的数据包（OUTPUT）； 处理转发的数据包（FORWARD）； 在进行路由选择后处理数据包（POSTROUTING）。  一般来说，从内网向外网发送的流量一般都是可控且良性的，因此使用最多的就是INPUT规则链，该规则链可以增大黑客人员从外网入侵内网的难度。\n比如在您居住的社区内，物业管理公司有两条规定：禁止小商小贩进入社区；各种车辆在进入社区时都要登记。显而易见，这两条规定应该是用于社区的正门的（流量必须经过的地方），而不是每家每户的防盗门上。根据前面提到的防火墙策略的匹配顺序，可能会存在多种情况。比如，来访人员是小商小贩，则直接会被物业公司的保安拒之门外，也就无须再对车辆进行登记。如果来访人员乘坐一辆汽车进入社区正门，则“禁止小商小贩进入社区”的第一条规则就没有被匹配到，因此按照顺序匹配第二条策略，即需要对车辆进行登记。如果是社区居民要进入正门，则这两条规定都不会匹配到，因此会执行默认的放行策略。\n但是，仅有策略规则还不能保证社区的安全，保安还应该知道采用什么样的动作来处理这些匹配的流量，比如“允许”“拒绝”“登记”“不理它”。这些动作对应到iptables服务的术语中分别是ACCEPT（允许流量通过）、REJECT（拒绝流量通过）、LOG（记录日志信息）、DROP（拒绝流量通过）。“允许流量通过”和“记录日志信息”都比较好理解，这里需要着重讲解的是REJECT和DROP的不同点。就DROP来说，它是直接将流量丢弃而且不响应；REJECT则会在拒绝流量后再回复一条“信息已经收到，但是被扔掉了”信息，从而让流量发送方清晰地看到数据被拒绝的响应信息。\n下面举一个例子，让各位读者更直观地理解这两个拒绝动作的不同之处。比如有一天您正在家里看电视，突然听到有人敲门，您透过防盗门的猫眼一看是推销商品的，便会在不需要的情况下开门并拒绝他们（REJECT）。但如果看到的是债主带了十几个小弟来讨债，此时不仅要拒绝开门，还要默不作声，伪装成自己不在家的样子（DROP）。\n当把Linux系统中的防火墙策略设置为REJECT动作后，流量发送方会看到端口不可达的响应：\n[root@linuxprobe ~]# ping -c 4 192.168.10.10 PING 192.168.10.10 (192.168.10.10) 56(84) bytes of data. From 192.168.10.10 icmp_seq=1 Destination Port Unreachable From 192.168.10.10 icmp_seq=2 Destination Port Unreachable From 192.168.10.10 icmp_seq=3 Destination Port Unreachable From 192.168.10.10 icmp_seq=4 Destination Port Unreachable --- 192.168.10.10 ping statistics --- 4 packets transmitted, 0 received, +4 errors, 100 packet loss, time 3002ms 而把Linux系统中的防火墙策略修改成DROP动作后，流量发送方会看到响应超时的提醒。但是流量发送方无法判断流量是被拒绝，还是接收方主机当前不在线：\n[root@linuxprobe ~]# ping -c 4 192.168.10.10 PING 192.168.10.10 (192.168.10.10) 56(84) bytes of data. --- 192.168.10.10 ping statistics --- 4 packets transmitted, 0 received, 100 packet loss, time 3000ms 基本的命令参数 iptables是一款基于命令行的防火墙策略管理工具，具有大量的参数，学习难度较大。好在对于日常的防火墙策略配置来讲，大家无须深入了解诸如“四表五链”的理论概念，只需要掌握常用的参数并做到灵活搭配即可，这就足以应对日常工作了。\n根据OSI七层模型的定义，iptables属于数据链路层的服务，所以可以根据流量的源地址、目的地址、传输协议、服务类型等信息进行匹配；一旦匹配成功，iptables就会根据策略规则所预设的动作来处理这些流量。另外，再次提醒一下，防火墙策略规则的匹配顺序是从上到下的，因此要把较为严格、优先级较高的策略规则放到前面，以免发生错误。表8-1总结归纳了常用的iptables命令参数。再次强调，无须死记硬背这些参数，只需借助下面的实验来理解掌握即可。\n命令格式 iptables [-t table] COMMAND chain CRETIRIA -j ACTION  -t table ：filter/nat/mangle COMMAND：定义如何对规则进行管理 chain：指定你接下来的规则到底是在哪个链上操作的，当定义策略的时候，是可以省略的 CRETIRIA:指定匹配标准 -j ACTION :指定如何进行处理  参数说明    参数 说明 示例     -F 清空规则链 iptables -F   -L 查看规则链 iptables -L   -A 追加规则 iptables -A INPUT   -D 删除规则 iptables -D INPUT 1   -R 修改规则 iptable -R INPUT 1 -s 192.168.120.0 -j DROP   -I 在头部插入规则 iptables -I INPUT 1 \u0026ndash;dport 80 -j ACCEPT   -L 查看规则 iptables -L INPUT   -N 新的规则 iptables -N allowed   -V 查看iptables版本 iptables -V   -p 协议（tcp/udp/icmp） iptables -A INPUT -p tcp   -s 匹配原地址，加\u0026quot; ! \u0026ldquo;表示除这个IP外 iptables -A INPUT -s 192.168.1.1   -d 匹配目的地址 iptables -A INPUT -d 192.168.12.1   \u0026ndash;sport 匹配源端口流入的数据 iptables -A INPUT -p tcp \u0026ndash;sport 22   \u0026ndash;dport 匹配目的端口流出的数据 iptables -A INPUT -p tcp \u0026ndash;dport 22   -i 匹配入口网卡流入的数据 iptables -A INPUT -i eth0   -o 匹配出口网卡流出的数据 iptables -A FORWARD -o eth0   -j 要进行的处理动作:DROP(丢弃)，REJECT(拒绝)，ACCEPT(接受)，SANT(基于原地址的转换) iptable -A INPUT 1 -s 192.168.120.0 -j DROP   \u0026ndash;to-source 指定SANT转换后的地址 iptables -t nat -A POSTROUTING -s 192.168.10.0/24 -j SANT \u0026ndash;to-source 172.16.100.1   -t 表名(raw、mangle、nat、filter) iptables -t nat   -m 使用扩展模块来进行数据包的匹配(multiport/tcp/state/addrtype) iptables -m multiport    动作说明 处理动作除了 ACCEPT、REJECT、DROP、REDIRECT 和 MASQUERADE 以外，还多出 LOG、ULOG、DNAT、SNAT、MIRROR、QUEUE、RETURN、TOS、TTL、MARK 等，其中某些处理动作不会中断过滤程序，某些处理动作则会中断同一规则链的过滤，并依照前述流程继续进行下一个规则链的过滤，一直到堆栈中的规则检查完毕为止。透过这种机制所带来的好处是，我们可以进行复杂、多重的封包过滤，简单的说，iptables 可以进行纵横交错式的过滤（tables）而非链状过滤（chains）。\n   动作 说明 示例     ACCEPT 将封包放行，进行完此处理动作后，将不再比对其它规则，直接跳往下一个规则链（nat:postrouting）    REJECT 拦阻该封包，并传送封包通知对方，可以传送的封包有几个选择：ICMP port-unreachable、ICMP echo-reply 或是 tcp-reset（这个封包会要求对方关闭联机），进行完此处理动作后，将不再比对其它规则，直接 中断过滤程序。 iptables -A FORWARD -p TCP \u0026ndash;dport 22 -j REJECT \u0026ndash;reject-with tcp-reset   DROP 丢弃封包不予处理，进行完此处理动作后，将不再比对其它规则，直接中断过滤程序。    REDIRECT 将封包重新导向到另一个端口（PNAT），进行完此处理动作后，将 会继续比对其它规则。 这个功能可以用来实作通透式 porxy 或用来保护 web 服务器。 iptables -t nat -A PREROUTING -p tcp \u0026ndash;dport 80 -j REDIRECT \u0026ndash;to-ports 8080   MASQUERADE 改写封包来源 IP 为防火墙 NIC IP，可以指定 port 对应的范围，进行完此处理动作后，直接跳往下一个规则链（mangle:postrouting）。这个功能与 SNAT 略有不同，当进行 IP 伪装时，不需指定要伪装成哪个 IP，IP 会从网卡直接读取，当使用拨接连线时，IP 通常是由 ISP 公司的 DHCP 服务器指派的，这个时候 MASQUERADE 特别有用。 iptables -t nat -A POSTROUTING -p TCP -j MASQUERADE \u0026ndash;to-ports 1024-31000   LOG 将封包相关讯息纪录在 /var/log 中，详细位置请查阅 /etc/syslog.conf 组态档，进行完此处理动作后，将会继续比对其它规则。 iptables -A INPUT -p tcp -j LOG \u0026ndash;log-prefix \u0026ldquo;INPUT packets\u0026rdquo;   SNAT 改写封包来源 IP 为某特定 IP 或 IP 范围，可以指定 port 对应的范围，进行完此处理动作后，将直接跳往下一个规则链（mangle:postrouting）。 iptables -t nat -A POSTROUTING -p tcp-o eth0 -j SNAT \u0026ndash;to-source 194.236.50.155-194.236.50.160:1024-32000   DNAT 改写封包目的地 IP 为某特定 IP 或 IP 范围，可以指定 port 对应的范围，进行完此处理动作后，将会直接跳往下一个规则链（filter:input 或 filter:forward）。 iptables -t nat -A PREROUTING -p tcp -d 15.45.23.67 \u0026ndash;dport 80 -j DNAT \u0026ndash;to-destination 192.168.1.1-192.168.1.10:80-100   MIRROR 镜射封包，也就是将来源 IP 与目的地 IP 对调后，将封包送回，进行完此处理动作后，将会中断过滤程序。    QUEUE 中断过滤程序，将封包放入队列，交给其它程序处理。透过自行开发的处理程序，可以进行其它应用，例如：计算联机费用……等。    RETURN 结束在目前规则链中的过滤程序，返回主规则链继续过滤，如果把自订规则链看成是一个子程序，那么这个动作，就相当于提早结束子程序并返回到主程序中。    MARK 将封包标上某个代号，以便提供作为后续过滤的条件判断依据，进行完此处理动作后，将会继续比对其它规则。 iptables -t mangle -A PREROUTING -p tcp \u0026ndash;dport 22 -j MARK \u0026ndash;set-mark 2    例子 1．在iptables命令后添加-L参数查看已有的防火墙规则链。\n[root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination ACCEPT udp -- anywhere anywhere udp dpt:domain ACCEPT tcp -- anywhere anywhere tcp dpt:domain ACCEPT udp -- anywhere anywhere udp dpt:bootps ACCEPT tcp -- anywhere anywhere tcp dpt:bootps Chain FORWARD (policy ACCEPT) target prot opt source destination ACCEPT all -- anywhere 192.168.122.0/24 ctstate RELATED,ESTABLISHED ACCEPT all -- 192.168.122.0/24 anywhere ACCEPT all -- anywhere anywhere REJECT all -- anywhere anywhere reject-with icmp-port-unreachable REJECT all -- anywhere anywhere reject-with icmp-port-unreachable Chain OUTPUT (policy ACCEPT) target prot opt source destination ACCEPT udp -- anywhere anywhere udp dpt:bootpc 2．在iptables命令后添加-F参数清空已有的防火墙规则链。\n[root@linuxprobe ~]# iptables -F [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination 3．把INPUT规则链的默认策略设置为拒绝。\n[root@linuxprobe ~]# iptables -P INPUT DROP [root@linuxprobe ~]# iptables -L Chain INPUT (policy DROP) target prot opt source destination Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination 前文提到，防火墙策略规则的设置无非有两种方式：“通”和“堵”。当把INPUT链设置为默认拒绝后，就要往里面写入允许策略了，否则所有流入的数据包都会被默认拒绝掉。同学们需要留意的是，规则链的默认策略拒绝动作只能是DROP，而不能是REJECT。\n4．向INPUT链中添加允许ICMP流量进入的策略规则。\n在日常运维工作中，经常会使用ping命令来检查对方主机是否在线，而向防火墙的INPUT规则链中添加一条允许ICMP流量进入的策略规则就默认允许了这种ping命令检测行为。\n[root@linuxprobe ~]# iptables -I INPUT -p icmp -j ACCEPT [root@linuxprobe ~]# ping -c 4 192.168.10.10 PING 192.168.10.10 (192.168.10.10) 56(84) bytes of data. 64 bytes from 192.168.10.10: icmp_seq=1 ttl=64 time=0.154 ms 64 bytes from 192.168.10.10: icmp_seq=2 ttl=64 time=0.041 ms 64 bytes from 192.168.10.10: icmp_seq=3 ttl=64 time=0.038 ms 64 bytes from 192.168.10.10: icmp_seq=4 ttl=64 time=0.046 ms --- 192.168.10.10 ping statistics --- 4 packets transmitted, 4 received, 0 packet loss, time 104ms rtt min/avg/max/mdev = 0.038/0.069/0.154/0.049 ms 5．删除INPUT规则链中刚刚加入的那条策略（允许ICMP流量），并把默认策略设置为允许。\n使用-F参数会清空已有的所有防火墙策略；使用-D参数可以删除某一条指定的策略，因此更加安全和准确。\n[root@linuxprobe ~]# iptables -D INPUT 1 [root@linuxprobe ~]# iptables -P INPUT ACCEPT [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination 6．将INPUT规则链设置为只允许指定网段的主机访问本机的22端口，拒绝来自其他所有主机的流量。\n要对某台主机进行匹配，可直接写出它的IP地址；如需对网段进行匹配，则需要写为子网掩码的形式（比如192.168.10.0/24）。\n[root@linuxprobe ~]# iptables -I INPUT -s 192.168.10.0/24 -p tcp --dport 22 -j ACCEPT [root@linuxprobe ~]# iptables -A INPUT -p tcp --dport 22 -j REJECT [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination ACCEPT tcp -- 192.168.10.0/24 anywhere tcp dpt:ssh REJECT tcp -- anywhere anywhere tcp dpt:ssh reject-with icmp-port-unreachable ………………省略部分输出信息……………… 再次重申，防火墙策略规则是按照从上到下的顺序匹配的，因此一定要把允许动作放到拒绝动作前面，否则所有的流量就将被拒绝掉，从而导致任何主机都无法访问我们的服务。另外，这里提到的22号端口是ssh服务使用的。\n在设置完上述INPUT规则链之后，使用IP地址在192.168.10.0/24网段内的主机访问服务器（即前面提到的设置了INPUT规则链的主机）的22端口，效果如下：\n[root@Client A ~]# ssh 192.168.10.10 The authenticity of host \u0026#39;192.168.10.10 (192.168.10.10)\u0026#39; can\u0026#39;t be established. ECDSA key fingerprint is SHA256:5d52kZi1la/FJK4v4jibLBZhLqzGqbJAskZiME6ZXpQ. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added \u0026#39;192.168.10.10\u0026#39; (ECDSA) to the list of known hosts. root@192.168.10.10\u0026#39;s password: 此处输入服务器密码 Activate the web console with: systemctl enable --now cockpit.socket Last login: Wed Jan 20 16:30:28 2021 from 192.168.10.1 然后，再使用IP地址在192.168.20.0/24网段内的主机访问服务器的22端口（虽网段不同，但已确认可以相互通信），效果如下：\n[root@Client B ~]# ssh 192.168.10.10 Connecting to 192.168.10.10:22... Could not connect to \u0026#39;192.168.10.10\u0026#39; (port 22): Connection failed. 由上可以看到，提示连接请求被拒绝了（Connection failed）。\n7．向INPUT规则链中添加拒绝所有人访问本机12345端口的策略规则。\n[root@linuxprobe ~]# iptables -I INPUT -p tcp --dport 12345 -j REJECT [root@linuxprobe ~]# iptables -I INPUT -p udp --dport 12345 -j REJECT [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination REJECT udp -- anywhere anywhere udp dpt:italk reject-with icmp-port-unreachable REJECT tcp -- anywhere anywhere tcp dpt:italk reject-with icmp-port-unreachable ACCEPT tcp -- 192.168.10.0/24 anywhere tcp dpt:ssh REJECT tcp -- anywhere anywhere tcp dpt:ssh reject-with icmp-port-unreachable ………………省略部分输出信息……………… 8．向INPUT规则链中添加拒绝192.168.10.5主机访问本机80端口（Web服务）的策略规则。\n[root@linuxprobe ~]# iptables -I INPUT -p tcp -s 192.168.10.5 --dport 80 -j REJECT [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination REJECT tcp -- 192.168.10.5 anywhere tcp dpt:http reject-with icmp-port-unreachable REJECT udp -- anywhere anywhere udp dpt:italk reject-with icmp-port-unreachable REJECT tcp -- anywhere anywhere tcp dpt:italk reject-with icmp-port-unreachable ACCEPT tcp -- 192.168.10.0/24 anywhere tcp dpt:ssh REJECT tcp -- anywhere anywhere tcp dpt:ssh reject-with icmp-port-unreachable ………………省略部分输出信息……………… 9．向INPUT规则链中添加拒绝所有主机访问本机1000～1024端口的策略规则。\n前面在添加防火墙策略时，使用的是-I参数，它默认会把规则添加到最上面的位置，因此优先级是最高的。如果工作中需要添加一条最后“兜底”的规则，那就用-A参数吧。这两个参数的效果差别还是很大的：\n[root@linuxprobe ~]# iptables -A INPUT -p tcp --dport 1000:1024 -j REJECT [root@linuxprobe ~]# iptables -A INPUT -p udp --dport 1000:1024 -j REJECT [root@linuxprobe ~]# iptables -L Chain INPUT (policy ACCEPT) target prot opt source destination REJECT tcp -- 192.168.10.5 anywhere tcp dpt:http reject-with icmp-port-unreachable REJECT udp -- anywhere anywhere udp dpt:italk reject-with icmp-port-unreachable REJECT tcp -- anywhere anywhere tcp dpt:italk reject-with icmp-port-unreachable ACCEPT tcp -- 192.168.10.0/24 anywhere tcp dpt:ssh REJECT tcp -- anywhere anywhere tcp dpt:ssh reject-with icmp-port-unreachable REJECT tcp -- anywhere anywhere tcp dpts:cadlock2:1024 reject-with icmp-port-unreachable REJECT udp -- anywhere anywhere udp dpts:cadlock2:1024 reject-with icmp-port-unreachable ………………省略部分输出信息……………… 有关iptables命令的知识讲解到此就结束了，大家是不是意犹未尽？考虑到Linux防火墙的发展趋势，大家只要能把上面的实例吸收消化，就可以完全搞定日常的iptables配置工作了。但是请特别注意，使用iptables命令配置的防火墙规则默认会在系统下一次重启时失效，如果想让配置的防火墙策略永久生效，还要执行保存命令：\n[root@linuxprobe ~]# iptables-save  # Generated by xtables-save v1.8.2 on Wed Jan 20 16:56:27 2021 ………………省略部分输出信息……………… 对了，如果公司服务器是5/6/7版本的话，对应的保存命令应该是：\n[root@linuxprobe ~]# service iptables save iptables: Saving firewall rules to /etc/sysconfig/iptables: [ OK ] 基本概念 iptables 是一个配置 Linux 内核 防火墙 的命令行工具，是 Netfilter 项目的一部分。术语 iptables 也经常代指该内核级防火墙。iptables 可以直接配置，也可以通过许多 控制台 和 图形化 前端配置。iptables 用于 ipv4，ip6tables 用于 IPv6。iptables和ip6tables 拥有相同的语法，但是有些特别的选项，对 IPv4 和 IPv6 有些不同的。\niptables 可以检测、修改、转发、重定向和丢弃 IPv4 数据包。过滤 IPv4 数据包的代码已经内置于内核中，并且按照不同的目的被组织成 表 的集合。表 由一组预先定义的 链 组成，链 包含遍历顺序规则。每一条规则包含一个谓词的潜在匹配和相应的动作（称为 目标），如果谓词为真，该动作会被执行。也就是说条件匹配。iptables 是用户工具，允许用户使用 链 和 规则。很多新手面对复杂的 linux IP 路由时总是感到气馁，但是，实际上最常用的一些应用案例（NAT 或者基本的网络防火墙）并不是很复杂。\n理解 iptables 如何工作的关键是上面这张图。图中在上面的小写字母代表 表，在下面的大写字母代表 链。从任何网络端口 进来的每一个 IP 数据包都要从上到下的穿过这张图。一种常见的错误认知是认为 iptables 对从内部端口进入的数据包和从面向互联网端口进入的数据包采取不同的处理方式，相反，iptabales 对从任何端口进入的数据包都会采取相同的处理方式。可以定义规则使 iptables 采取不同的方式对待从不同端口进入的数据包。当然一些数据包是用于本地进程的，因此在图中表现为从顶端进入，到 \u0026lt;Local Process\u0026gt; 停止，而另一些数据包是由本地进程生成的，因此在图中表现为从 \u0026lt;Local Process\u0026gt; 发出，一直向下穿过该流程图。一份关于该流程图如何工作的详细解释请参考这里。\n在大多数使用情况下都不会用到 raw，mangle 和 security 表。\n表(Tables) ptables 包含 5 张表（tables）:\n raw 用于配置数据包，raw 中的数据包不会被系统跟踪。 filter 是用于存放所有与防火墙相关操作的默认表。 nat 用于 网络地址转换（例如：端口转发）。 mangle 用于对特定数据包的修改（参考 损坏数据包）。 security 用于 强制访问控制 网络规则（例如： SELinux \u0026ndash; 详细信息参考 该文章）。  大部分情况仅需要使用 filter 和 nat。其他表用于更复杂的情况——包括多路由和路由判定——已经超出了本文介绍的范围。\n链(Chains) 表由链组成，链是一些按顺序排列的规则的列表。默认的 filter 表包含 INPUT， OUTPUT 和 FORWARD 3条内建的链，这3条链作用于数据包过滤过程中的不同时间点，如该上面流程图所示。nat 表包含PREROUTING， POSTROUTING 和 OUTPUT 链。\n使用 iptables(8) 查看其他表中内建链的描述。\n默认情况下，任何链中都没有规则。可以向链中添加自己想用的规则。链的默认规则通常设置为 ACCEPT，如果想确保任何包都不能通过规则集，那么可以重置为 DROP。默认的规则总是在一条链的最后生效，所以在默认规则生效前数据包需要通过所有存在的规则。\n用户可以加入自己定义的链，从而使规则集更有效并且易于修改。如何使用自定义链请参考 Simple stateful firewall。\n规则 (Rules) 数据包的过滤基于 规则。规则由一个目标（数据包包匹配所有条件后的动作）和很多匹配（导致该规则可以应用的数据包所满足的条件）指定。一个规则的典型匹配事项是数据包进入的端口（例如：eth0 或者 eth1）、数据包的类型（ICMP, TCP, 或者 UDP）和数据包的目的端口。\n目标使用 -j 或者 --jump 选项指定。目标可以是用户定义的链（例如，如果条件匹配，跳转到之后的用户定义的链，继续处理）、一个内置的特定目标或者是一个目标扩展。内置目标是 ACCEPT， DROP， QUEUE 和 RETURN，目标扩展是 REJECT 和 LOG。如果目标是内置目标，数据包的命运会立刻被决定并且在当前表的数据包的处理过程会停止。如果目标是用户定义的链，并且数据包成功穿过第二条链，目标将移动到原始链中的下一个规则。目标扩展可以被终止（像内置目标一样）或者不终止（像用户定义链一样）。详细信息参阅 iptables-extensions(8)。\n遍历链(Traversing Chains) 该流程图描述链了在任何接口上收到的网络数据包是按照怎样的顺序穿过表的交通管制链。第一个路由策略包括决定数据包的目的地是本地主机（这种情况下，数据包穿过 INPUT 链），还是其他主机（数据包穿过 FORWARD 链）；中间的路由策略包括决定给传出的数据包使用那个源地址、分配哪个接口；最后一个路由策略存在是因为先前的 mangle 与 nat 链可能会改变数据包的路由信息。数据包通过路径上的每一条链时，链中的每一条规则按顺序匹配；无论何时匹配了一条规则，相应的 target/jump 动作将会执行。最常用的3个 target 是 ACCEPT, DROP ,或者 jump 到用户自定义的链。内置的链有默认的策略，但是用户自定义的链没有默认的策略。在 jump 到的链中，若每一条规则都不能提供完全匹配，那么数据包像下面这张图片描述的一样返回到调用链。在任何时候，若 DROP target 的规则实现完全匹配，那么被匹配的数据包会被丢弃，不会进行进一步处理。如果一个数据包在链中被 ACCEPT，那么它也会被所有的父链 ACCEPT，并且不再遍历其他父链。然而，要注意的是，数据包还会以正常的方式继续遍历其他表中的其他链。\n模块(Modules) 有许多模块可以用来扩展 iptables，例如 connlimit, conntrack, limit 和 recent。这些模块增添了功能，可以进行更复杂的过滤。\nFirewalld RHEL 8系统中集成了多款防火墙管理工具，其中firewalld（Dynamic Firewall Manager of Linux systems，Linux系统的动态防火墙管理器）服务是默认的防火墙配置管理工具，它拥有基于CLI（命令行界面）和基于GUI（图形用户界面）的两种管理方式。\nRHEL 8系统中集成了多款防火墙管理工具，其中firewalld（Dynamic Firewall Manager of Linux systems，Linux系统的动态防火墙管理器）服务是默认的防火墙配置管理工具，它拥有基于CLI（命令行界面）和基于GUI（图形用户界面）的两种管理方式。\n相较于传统的防火墙管理配置工具，firewalld支持动态更新技术并加入了区域（zone）的概念。简单来说，区域就是firewalld预先准备了几套防火墙策略集合（策略模板），用户可以根据生产场景的不同而选择合适的策略集合，从而实现防火墙策略之间的快速切换。例如，我们有一台笔记本电脑，每天都要在办公室、咖啡厅和家里使用。按常理来讲，这三者的安全性按照由高到低的顺序来排列，应该是家庭、公司办公室、咖啡厅。当前，我们希望为这台笔记本电脑制定如下防火墙策略规则：在家中允许访问所有服务；在办公室内仅允许访问文件共享服务；在咖啡厅仅允许上网浏览。在以往，我们需要频繁地手动设置防火墙策略规则，而现在只需要预设好区域集合，然后轻点鼠标就可以自动切换了，从而极大地提升了防火墙策略的应用效率。firewalld中常见的区域名称（默认为public）以及相应的策略规则如表所示。\n   区域 默认规则策略     trusted 允许所有的数据包   home 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh、mdns、ipp-client、amba-client与dhcpv6-client服务相关，则允许流量   internal 等同于home区域   work 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh、ipp-client与dhcpv6-client服务相关，则允许流量   public 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh、dhcpv6-client服务相关，则允许流量   external 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh服务相关，则允许流量   dmz 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh服务相关，则允许流量   block 拒绝流入的流量，除非与流出的流量相关   drop 拒绝流入的流量，除非与流出的流量相关    终端管理工具 命令行终端是一种极富效率的工作方式，firewall-cmd是firewalld防火墙配置管理工具的CLI（命令行界面）版本。它的参数一般都是以“长格式”来提供的。大家不要一听到长格式就头大，因为RHEL 8系统支持部分命令的参数补齐，其中就包含这条命令（很酷吧）。也就是说，现在除了能用Tab键自动补齐命令或文件名等内容之外，还可以用Tab键来补齐表所示的长格式参数。这太棒了！\n   参数 作用     \u0026ndash;get-default-zone 查询默认的区域名称   \u0026ndash;set-default-zone=\u0026lt;区域名称\u0026gt; 设置默认的区域，使其永久生效   \u0026ndash;get-zones 显示可用的区域   \u0026ndash;get-services 显示预先定义的服务   \u0026ndash;get-active-zones 显示当前正在使用的区域与网卡名称   \u0026ndash;add-source= 将源自此IP或子网的流量导向指定的区域   \u0026ndash;remove-source= 不再将源自此IP或子网的流量导向某个指定区域   \u0026ndash;add-interface=\u0026lt;网卡名称\u0026gt; 将源自该网卡的所有流量都导向某个指定区域   \u0026ndash;change-interface=\u0026lt;网卡名称\u0026gt; 将某个网卡与区域进行关联   \u0026ndash;list-all 显示当前区域的网卡配置参数、资源、端口以及服务等信息   \u0026ndash;list-all-zones 显示所有区域的网卡配置参数、资源、端口以及服务等信息   \u0026ndash;add-service=\u0026lt;服务名\u0026gt; 设置默认区域允许该服务的流量   \u0026ndash;add-port=\u0026lt;端口号/协议\u0026gt; 设置默认区域允许该端口的流量   \u0026ndash;remove-service=\u0026lt;服务名\u0026gt; 设置默认区域不再允许该服务的流量   \u0026ndash;remove-port=\u0026lt;端口号/协议\u0026gt; 设置默认区域不再允许该端口的流量   \u0026ndash;reload 让“永久生效”的配置规则立即生效，并覆盖当前的配置规则   \u0026ndash;panic-on 开启应急状况模式   \u0026ndash;panic-off 关闭应急状况模式    与Linux系统中其他的防火墙策略配置工具一样，使用firewalld配置的防火墙策略默认为运行时（Runtime）模式，又称为当前生效模式，而且会随着系统的重启而失效。如果想让配置策略一直存在，就需要使用永久（Permanent）模式了，方法就是在用firewall-cmd命令正常设置防火墙策略时添加\u0026ndash;permanent参数，这样配置的防火墙策略就可以永久生效了。但是，永久生效模式有一个“不近人情”的特点，就是使用它设置的策略只有在系统重启之后才能自动生效。如果想让配置的策略立即生效，需要手动执行firewall-cmd \u0026ndash;reload命令。\n接下来的实验都很简单，但是提醒大家一定要仔细查看使用的是Runtime模式还是Permanent模式。如果不关注这个细节，就算正确配置了防火墙策略，也可能无法达到预期的效果。\n1．查看firewalld服务当前所使用的区域。\n这是一步非常重要的操作。在配置防火墙策略前，必须查看当前生效的是哪个区域，否则配置的防火墙策略将不会立即生效。\n[root@linuxprobe ~]# firewall-cmd --get-default-zone public 2．查询指定网卡在firewalld服务中绑定的区域。\n在生产环境中，服务器大多不止有一块网卡。一般来说，充当网关的服务器有两块网卡，一块对公网，另外一块对内网，那么这两块网卡在审查流量时所用的策略肯定也是不一致的。因此，可以根据网卡针对的流量来源，为网卡绑定不同的区域，实现对防火墙策略的灵活管控。\n[root@linuxprobe ~]# firewall-cmd --get-zone-of-interface=ens160 public 3．把网卡默认区域修改为external，并在系统重启后生效。\n[root@linuxprobe ~]# firewall-cmd --permanent --zone=external --change-interface=ens160 The interface is under control of NetworkManager, setting zone to \u0026#39;external\u0026#39;. success [root@linuxprobe ~]# firewall-cmd --permanent --get-zone-of-interface=ens160 external 4．把firewalld服务的默认区域设置为public。\n默认区域也叫全局配置，指的是对所有网卡都生效的配置，优先级较低。在下面的代码中可以看到，当前默认区域为public，而ens160网卡的区域为external。此时便是以网卡的区域名称为准。\n通俗来说，默认区域就是一种通用的政策。例如，食堂为所有人准备了一次性餐具，而环保主义者则会自己携带碗筷。如果您自带了碗筷，就可以用自己的；反之就用食堂统一提供的。\n[root@linuxprobe ~]# firewall-cmd --set-default-zone=public Warning: ZONE_ALREADY_SET: public success [root@linuxprobe ~]# firewall-cmd --get-default-zone  public [root@linuxprobe ~]# firewall-cmd --get-zone-of-interface=ens160 external 5．启动和关闭firewalld防火墙服务的应急状况模式。\n如果想在1s的时间内阻断一切网络连接，有什么好办法呢？大家下意识地会说：“拔掉网线！”这是一个物理级别的高招。但是，如果人在北京，服务器在异地呢？panic紧急模式在这个时候就派上用场了。使用\u0026ndash;panic-on参数会立即切断一切网络连接，而使用\u0026ndash;panic-off则会恢复网络连接。切记，紧急模式会切断一切网络连接，因此在远程管理服务器时，在按下回车键前一定要三思。\n[root@linuxprobe ~]# firewall-cmd --panic-on success [root@linuxprobe ~]# firewall-cmd --panic-off success 6．查询SSH和HTTPS协议的流量是否允许放行。\n在工作中可以不使用\u0026ndash;zone参数指定区域名称，firewall-cmd命令会自动依据默认区域进行查询，从而减少用户输入量。但是，如果默认区域与网卡所绑定的不一致时，就会发生冲突，因此规范写法的zone参数是一定要加的。\n[root@linuxprobe ~]# firewall-cmd --zone=public --query-service=ssh yes [root@linuxprobe ~]# firewall-cmd --zone=public --query-service=https no 7．把HTTPS协议的流量设置为永久允许放行，并立即生效。\n默认情况下进行的修改都属于Runtime模式，即当前生效而重启后失效，因此在工作和考试中尽量避免使用。而在使用\u0026ndash;permanent参数时，则是当前不会立即看到效果，而在重启或重新加载后方可生效。于是，在添加了允许放行HTTPS流量的策略后，查询当前模式策略，发现依然是不允许放行HTTPS协议的流量：\n[root@linuxprobe ~]# firewall-cmd --permanent --zone=public --add-service=https success [root@linuxprobe ~]# firewall-cmd --zone=public --query-service=https no 不想重启服务器的话，就用\u0026ndash;reload参数吧：\n[root@linuxprobe ~]# firewall-cmd --reload success [root@linuxprobe ~]# firewall-cmd --zone=public --query-service=https yes 8．把HTTP协议的流量设置为永久拒绝，并立即生效。\n由于在默认情况下HTTP协议的流量就没有被允许，所以会有“Warning: NOT_ENABLED: http”这样的提示信息，因此对实际操作没有影响。\n[root@linuxprobe ~]# firewall-cmd --permanent --zone=public --remove-service=http Warning: NOT_ENABLED: http success [root@linuxprobe ~]# firewall-cmd --reload  success 9．把访问8080和8081端口的流量策略设置为允许，但仅限当前生效。\n[root@linuxprobe ~]# firewall-cmd --zone=public --add-port=8080-8081/tcp success [root@linuxprobe ~]# firewall-cmd --zone=public --list-ports 8080-8081/tcp 10．把原本访问本机888端口的流量转发到22端口，要且求当前和长期均有效。\nSSH远程控制协议是基于TCP/22端口传输控制指令的，如果想让用户通过其他端口号也能访问ssh服务，就可以试试端口转发技术了。通过这项技术，新的端口号在收到用户请求后会自动转发到原本服务的端口上，使得用户能够通过新的端口访问到原本的服务。\n来举个例子帮助大家理解。假设小强是电子厂的工人，他喜欢上了三号流水线上的工人小花，但不好意思表白，于是写了一封情书并交给门卫张大爷，希望由张大爷转交给小花。这样一来，情书（信息）的传输由从小强到小花，变成了小强到张大爷再到小花，情书（信息）依然能顺利送达。\n使用firewall-cmd命令实现端口转发的格式有点长，这里为大家总结好了：\nfirewall-cmd --permanent --zone=\u0026lt;区域\u0026gt; --add-forward-port=port=\u0026lt;源端口号\u0026gt;:proto=\u0026lt;协议\u0026gt;:toport=\u0026lt;目标端口号\u0026gt;:toaddr=\u0026lt;目标IP地址\u0026gt; 上述命令中的目标IP地址一般是服务器本机的IP地址：\n[root@linuxprobe ~]# firewall-cmd --permanent --zone=public --add-forward-port=port=888:proto=tcp:toport=22:toaddr=192.168.10.10 success [root@linuxprobe ~]# firewall-cmd --reload success 在客户端使用ssh命令尝试访问192.168.10.10主机的888端口，访问成功：\n[root@client A ~]# ssh -p 888 192.168.10.10 The authenticity of host \u0026#39;[192.168.10.10]:888 ([192.168.10.10]:888)\u0026#39; can\u0026#39;t be established. ECDSA key fingerprint is b8:25:88:89:5c:05:b6:dd:ef:76:63:ff:1a:54:02:1a. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added \u0026#39;[192.168.10.10]:888\u0026#39; (ECDSA) to the list of known hosts. root@192.168.10.10\u0026#39;s password:此处输入远程root管理员的密码 Last login: Sun Jul 19 21:43:48 2021 from 192.168.10.10 11．富规则的设置。\n富规则也叫复规则，表示更细致、更详细的防火墙策略配置，它可以针对系统服务、端口号、源地址和目标地址等诸多信息进行更有针对性的策略配置。它的优先级在所有的防火墙策略中也是最高的。比如，我们可以在firewalld服务中配置一条富规则，使其拒绝192.168.10.0/24网段的所有用户访问本机的ssh服务（22端口）：\n[root@linuxprobe ~]# firewall-cmd --permanent --zone=public --add-rich-rule=\u0026#34;rule family=\u0026#34;ipv4\u0026#34; source address=\u0026#34;192.168.10.0/24\u0026#34; service name=\u0026#34;ssh\u0026#34; reject\u0026#34; success [root@linuxprobe ~]# firewall-cmd --reload success 在客户端使用ssh命令尝试访问192.168.10.10主机的ssh服务（22端口）：\n[root@client A ~]# ssh 192.168.10.10 Connecting to 192.168.10.10:22... Could not connect to \u0026#39;192.168.10.10\u0026#39; (port 22): Connection failed. 图形管理工具 在各种版本的Linux系统中，几乎没有能让刘遄老师欣慰并推荐的图形化工具，但是firewall-config做到了。它是firewalld防火墙配置管理工具的GUI（图形用户界面）版本，几乎可以实现所有以命令行来执行的操作。毫不夸张地说，即使读者没有扎实的Linux命令基础，也完全可以通过它来妥善配置RHEL 8中的防火墙策略。\n成功 firewall-config 安装后，其工具的界面如图所示：\n其功能具体如下。\n1：选择运行时（Runtime）或永久（Permanent）模式的配置。\n2：可选的策略集合区域列表。\n3：常用的系统服务列表。\n4：主机地址的黑白名单。\n5：当前正在使用的区域。\n6：管理当前被选中区域中的服务。\n7：管理当前被选中区域中的端口。\n8：设置允许被访问的协议。\n9：设置允许被访问的端口。\n10：开启或关闭SNAT（源网络地址转换）技术。\n11：设置端口转发策略。\n12：控制请求icmp服务的流量。\n13：管理防火墙的富规则。\n14：被选中区域的服务，若勾选了相应服务前面的复选框，则表示允许与之相关的流量。\n15：firewall-config工具的运行状态。\n除了图中列出的功能，还有用于将网卡与区域绑定的Interfaces选项，以及用于将IP地址与区域绑定的Sources选项。另外再啰唆一句。在使用firewall-config工具配置完防火墙策略之后，无须进行二次确认，因为只要有修改内容，它就自动进行保存。\n下面进行动手实践环节。\n先将当前区域中请求http服务的流量设置为允许放行，但仅限当前生效。具体配置如图所示：\n尝试添加一条防火墙策略规则，使其放行访问8080～8088端口（TCP协议）的流量，并将其设置为永久生效，以达到系统重启后防火墙策略依然生效的目的。在按照下图所示的界面配置完毕之后，还需要在Options菜单中单击Reload Firewalld命令，让配置的防火墙策略立即生效。这与在命令行中使用\u0026ndash;reload参数的效果一样。\n放行访问8080～8088端口的流量：\n让配置的防火墙策略规则立即生效：\n前面在讲解firewall-config工具的功能时，曾经提到了SNAT（Source Network Address Translation，源网络地址转换）技术。SNAT是一种为了解决IP地址匮乏而设计的技术，它可以使得多个内网中的用户通过同一个外网IP接入Internet。该技术的应用非常广泛，甚至可以说我们每天都在使用，只不过没有察觉到罢了。比如，当通过家中的网关设备（无线路由器）访问本书配套站点www.linuxprobe.com时，就用到了SNAT技术。\n大家可以看一下在网络中不使用SNAT技术和使用SNAT技术时的情况。在没有使用SNAT技术的局域网中有多台PC，如果网关服务器没有应用SNAT技术，则互联网中的网站服务器在收到PC的请求数据包，并回送响应数据包时，将无法在网络中找到这个私有网络的IP地址，所以PC也就收不到响应数据包了。在使用SNAT技术处理过的局域网中，由于网关服务器应用了SNAT技术，所以互联网中的网站服务器会将响应数据包发给网关服务器，再由后者转发给局域网中的PC。\n没有使用SNAT技术的网络：\n使用SNAT技术处理过的网络：\n使用iptables命令实现SNAT技术是一件很麻烦的事情，但是在firewall-config中却是小菜一碟了。用户只需按照下图进行配置，并选中Masquerade zone复选框，就自动开启了SNAT技术。\n为了让大家直观查看不同工具在实现相同功能时的区别，针对前面使用firewall-cmd配置的防火墙策略规则，这里使用firewall-config工具进行了重新演示：将本机888端口的流量转发到22端口，且要求当前和长期均有效，具体如下图所示：\n配置本地的端口转发：\n让防火墙效策略规则立即生效：\n用命令配置富规则可真辛苦，幸好我们现在有了图形用户界面的工具。让192.168.10.20主机访问本机的1234端口号，如下图所示。其中Element选项能够根据服务名称、端口号、协议等信息进行匹配；Source与Destination选项后的inverted复选框代表反选功能，将其选中则代表对已填写信息进行反选，即选中填写信息以外的主机地址；Log复选框在选中后，日志不仅会被记录到日志文件中，而且还可以在设置日志的级别（Level）后，再将日志记录到日志文件中，以方便后续的筛查。\n如果生产环境中的服务器有多块网卡在同时提供服务（这种情况很常见），则对内网和对外网提供服务的网卡要选择的防火墙策略区域也是不一样的。也就是说，可以把网卡与防火墙策略区域进行绑定，这样就可以使用不同的防火墙区域策略，对源自不同网卡的流量进行有针对性的监控，效果会更好。\n把网卡与防火墙策略区域进行绑定：\n网卡与策略区域绑定完成：\n最后再提一句，firewall-config工具真的非常实用，很多原本复杂的长命令被图形化按钮替代，设置规则也简单明了，足以应对日常工作。所以再次向大家强调配置防火墙策略的原则—只要能实现所需的功能，用什么工具请随君便。\n服务的访问控制列表 TCP Wrapper是RHEL 6/7系统中默认启用的一款流量监控程序，它能够根据来访主机的地址与本机的目标服务程序做出允许或拒绝的操作。在RHEL 8版本中，它已经被firewalld正式替代。换句话说，Linux系统中其实有两个层面的防火墙，第一种是前面讲到的基于TCP/IP协议的流量过滤工具，而TCP Wrapper服务则是能允许或禁止Linux系统提供服务的防火墙，从而在更高层面保护了Linux系统的安全运行。\nTCP Wrapper服务的防火墙策略由两个控制列表文件所控制，用户可以编辑允许控制列表文件来放行对服务的请求流量，也可以编辑拒绝控制列表文件来阻止对服务的请求流量。控制列表文件修改后会立即生效，系统将会先检查允许控制列表文件（/etc/hosts.allow），如果匹配到相应的允许策略则放行流量；如果没有匹配，则会进一步匹配拒绝控制列表文件（/etc/hosts.deny），若找到匹配项则拒绝该流量。如果这两个文件都没有匹配到，则默认放行流量。\n由于RHEL 8版本已经不再支持TCP Wrapper服务程序，因此我们接下来选择在一台老版本的服务器上进行实验。TCP Wrapper服务的控制列表文件配置起来并不复杂，常用的参数如表所示。\n   客户端类型 示例 满足示例的客户端列表     单一主机 192.168.10.10 IP地址为192.168.10.10的主机   指定网段 192.168.10. IP段为192.168.10.0/24的主机   指定网段 192.168.10.0/255.255.255.0 IP段为192.168.10.0/24的主机   指定DNS后缀 .linuxprobe.com 所有DNS后缀为.linuxprobe.com的主机   指定主机名称 www.linuxprobe.com 主机名称为www.linuxprobe.com的主机   指定所有客户端 ALL 所有主机全部包括在内    在配置TCP Wrapper服务时需要遵循两个原则：\n 编写拒绝策略规则时，填写的是服务名称，而非协议名称； 建议先编写拒绝策略规则，再编写允许策略规则，以便直观地看到相应的效果。  下面编写拒绝策略规则文件，禁止访问本机sshd服务的所有流量（无须修改/etc/hosts.deny文件中原有的注释信息）：\n[root@linuxprobe ~]# vim /etc/hosts.deny # # hosts.deny This file contains access rules which are used to # deny connections to network services that either use # the tcp_wrappers library or that have been # started through a tcp_wrappers-enabled xinetd. # # The rules in this file can also be set up in # /etc/hosts.allow with a \u0026#39;deny\u0026#39; option instead. # # See \u0026#39;man 5 hosts_options\u0026#39; and \u0026#39;man 5 hosts_access\u0026#39; # for information on rule syntax. # See \u0026#39;man tcpd\u0026#39; for information on tcp_wrappers sshd:* [root@linuxprobe ~]# ssh 192.168.10.10 ssh_exchange_identification: read: Connection reset by peer 接下来，在允许策略规则文件中添加一条规则，使其放行源自192.168.10.0/24网段，且访问本机sshd服务的所有流量。可以看到，服务器立刻就放行了访问sshd服务的流量，效果非常直观：\n[root@linuxprobe ~]# vim /etc/hosts.allow # # hosts.allow This file contains access rules which are used to # allow or deny connections to network services that # either use the tcp_wrappers library or that have been # started through a tcp_wrappers-enabled xinetd. # # See \u0026#39;man 5 hosts_options\u0026#39; and \u0026#39;man 5 hosts_access\u0026#39; # for information on rule syntax. # See \u0026#39;man tcpd\u0026#39; for information on tcp_wrappers sshd:192.168.10. [root@linuxprobe ~]# ssh 192.168.10.10 The authenticity of host \u0026#39;192.168.10.10 (192.168.10.10)\u0026#39; can\u0026#39;t be established. ECDSA key fingerprint is 70:3b:5d:37:96:7b:2e:a5:28:0d:7e:dc:47:6a:fe:5c. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added \u0026#39;192.168.10.10\u0026#39; (ECDSA) to the list of known hosts. root@192.168.10.10\u0026#39;s password: Last login: Wed May 4 07:56:29 2021 [root@linuxprobe ~]#  Cockpit 驾驶舱管理工具 首先，Cockpit是一个英文单词，即“（飞机、船或赛车的）驾驶舱、驾驶座”，它用名字传达出了功能丰富的特性。其次，Cockpit是一个基于Web的图形化服务管理工具，对用户相当友好，即便是新手也可以轻松上手。而且它天然具备很好的跨平台性，因此被广泛应用于服务器、容器、虚拟机等多种管理场景。最后，红帽公司对Cockpit也十分看重，直接将它默认安装到了RHEL 8系统中，由此衍生的CentOS和Fedora也都标配有Cockpit。\nCockpit在默认情况下就已经被安装到系统中。下面执行dnf命令对此进行确认：\n[root@linuxprobe ~]# dnf install cockpit Updating Subscription Management repositories. Unable to read consumer identity This system is not registered to Red Hat Subscription Management. You can use subscription-manager to register. AppStream 3.1 MB/s | 3.2 kB 00:00 BaseOS 2.7 MB/s | 2.7 kB 00:00 Package cockpit-185-2.el8.x86_64 is already installed. Dependencies resolved. Nothing to do. Complete! 但是，Cockpit服务程序在RHEL 8版本中没有自动运行，下面将它开启并加入到开机启动项中：\n[root@linuxprobe ~]# systemctl start cockpit [root@linuxprobe ~]# systemctl enable cockpit.socket Created symlink /etc/systemd/system/sockets.target.wants/cockpit.socket → /usr/lib/systemd/system/cockpit.socket. 在Cockpit服务启动后，打开系统自带的浏览器，在地址栏中输入“本机地址:9090”即可访问。由于访问Cockpit的流量会使用HTTPS进行加密，而证书又是在本地签发的，因此还需要进行添加并信任本地证书的操作。\n添加额外允许的证书：\n确认信任本地证书：\n进入Cockpit的登录界面后，输入root管理员的账号与系统密码，单击Log In按钮后即可进入：\n进入Cockpit的Web界面，发现里面可谓“别有洞天”。Cockpit总共分为13个功能模块：系统状态（System）、日志信息（Logs）、硬盘存储（Storage）、网卡网络（Networking）、账户安全（Accounts）、服务程序（Services）、软件仓库（Applications）、报告分析（Diagnostic Reports）、内核排错（Kernel Dump）、SElinux、更新软件（Software Updates）、订阅服务（Subscriptions）、终端界面（Terminal）。下面逐一进行讲解。\n1．System\n进入Cockpit界面后默认显示的便是System（系统）界面，在该界面中能够看到系统架构、版本、主机名与时间等信息，还能够动态地展现出CPU、硬盘、内存和网络的复杂情况，这有点类似于Web版的“Winodws系统任务管理器”，属实好用。\n系统状态界面：\n2．Logs\n这个模块能够提供系统的全部日志，但是同学们可能会好奇，“为什么下图中的内容这么有限呢”？原因出在图中的两个选项中：时间和日志级别。通过这两个选项可以让用户更快地找到所需信息，而不是像/var/log/message文件那样一股脑儿地都抛给用户。\n日志信息界面：\n3．Storage\n这个功能模块是同学们最喜欢的一个模块，原因不是这个模块显示了硬盘的I/O读写负载情况，而是可以让用户通过该界面，用鼠标创建出RAID、LVM、VDO和iSCSI等存储设备。是的，您没有看错，RAID和LVM都可以用鼠标进行创建了，是不是很开心呢？\n硬盘存储界面：\n4．Networking\n既然名为Networking模块，那么动态看网卡的输出和接收值肯定是这个模块的标配功能了。我们不仅可以在这里进行网卡的绑定（Bonding）和聚合（Team），还可以创建桥接网卡及添加VLAN。最下方会单独列出与网卡相关的日志信息。\n网卡网络界面：\n**5．**Accounts\n大家千万别小看Accounts模块，虽然它的账户安全界面有些简陋，只有一个用于创建账户的按钮，但只要点击进入某个用户的管理界面中，马上会发现“别有洞天”——账户管理界面，这个界面中的功能非常丰富，我们在这里可以对用户进行重命名，设置用户的权限，还可以锁定、修改密码以及创建SSH密钥信息。\n账户安全界面：\n账户管理界面：\n6．Services\n在Services功能模块的界面中，可以查看系统中已有的服务列表和运行状态。单击某一服务，进入该服务的管理界面后，可以对具体的服务进行开启、关闭操作。在Services功能模块中设置了服务并将其加入到开机启动项后，在系统重启后也依然会为用户提供服务。\n服务程序界面：\n服务管理界面：\n7．Applications\n后期采用Cockpit或红帽订阅服务安装的软件都会显示在这个功能模块中。\n软件仓库界面：\n8．Diagnostic Report\nDiagnostic Report模块的功能是帮助用户收集及分析系统的信息，找到系统出现问题的原因。单击Create Report按钮后大约两分钟左右，会出现报告生成完毕的弹窗。好吧，摊牌了，这个功能其实很鸡肋，就是将sosreport命令做成了一个网页按钮。\n报告分析界面：\n报告生成完毕：\n9．Kernel Dump\nKernel Dump（Kdump）是一个在系统崩溃、死锁或死机时用来收集内核参数的一个服务。举例来说，如果有一天系统崩溃了，这时Kdump服务就会开始工作，将系统的运行状态和内核数据收集到一个名为dump core的文件中，以便后续让运维人员分析并找出问题所在。由于我们在安装系统时没有启动该服务，所以可以等到后续使用时再开启该功能界面。\n内核排错界面：\n10．SElinux\n下图所示为SELinux服务的控制按钮和警告信息界面。\nSElinux管理界面：\n11．Software Updates\n这里提到的Software Updates并不是我们用来更新其他常规软件的一个界面，而是用来对红帽客户订阅的服务进行更新的界面。用户只有在购买了红帽第三方服务后才能使用这里面的功能。在购买了红帽订阅服务后，用户便可以在这里下载到相应服务程序的最新版本和稳定版本。\n更新软件界面：\n12．Subscriptions\n这里依然是一则红帽公司的“小广告”—如果想成为尊贵的红帽服务用户，要付费购买订阅服务。个人用户无须购买，而且这对我们的后续实验没有任何影响。\n订阅服务界面：\n12．Terminal\n压轴的总是在最后。Cockpit服务提供了Shell终端的在线控制平台，可方便用户通过网页上的终端功能管理服务器。这个功能深受运维人员喜爱。\n终端管理界面\n至此，相信各位读者已经充分掌握了防火墙的管理能力。防火墙管理工具有很多种，我们任选其一即可。在配置后续的服务前，大家要记得检查网络和防火墙的状态，以避免出现服务明明配置正确，但无法从外部访问的情况，最终影响实验效果。\n在 Ubuntu 上使用 UFW\u0026amp;GUFW Ubuntu 20.04 随附了一个称为UFW（非复杂防火墙）的防火墙配置工具。 它是用于管理iptables防火墙规则的用户友好型前端。 它的主要目标是使防火墙的管理变得更容易，或者顾名思义，变得简单。而GUFW是UFW的图形介面。\n检查UFW状态 UFW默认情况下处于禁用状态。 您可以使用以下命令检查UFW服务的状态：\n$ sudo ufw status verbose 输出将显示防火墙状态为非活动：\nStatus: inactive 如果UFW已激活，则输出将类似于以下内容：\nStatus: active UFW默认策略 UFW防火墙的默认行为是阻止所有传入和转发流量，并允许所有出站流量。 这意味着除非您专门打开端口，否则任何尝试访问您的服务器的人都将无法连接。 服务器上运行的应用程序和服务将可以访问外界。\n默认策略在/etc/default/ufw文件中定义，可以通过手动修改文件或使用sudo ufw default \u0026lt;policy\u0026gt; \u0026lt;chain\u0026gt;命令来更改。\n防火墙策略是建立更复杂和用户定义的规则的基础。 通常，最初的UFW默认策略是一个很好的起点。\n应用配置文件 应用程序配置文件是INI格式的文本文件，描述了服务并包含该服务的防火墙规则。 在安装软件包期间，会在/etc/ufw/applications.d目录中创建应用程序配置文件。\n您可以通过键入以下内容列出服务器上所有可用的应用程序配置文件：\n$ sudo ufw app list Available applications: Nginx Full Nginx HTTP Nginx HTTPS OpenSSH 要查找有关特定配置文件和包含的规则的更多信息，请使用以下命令：\n$ sudo ufw app info \u0026#39;Nginx Full\u0026#39; Profile: Nginx Full Title: Web Server (Nginx, HTTP + HTTPS) Description: Small, but very powerful and efficient web server Ports: 80,443/tcp 输出显示“ Nginx Full”配置文件打开了端口80和443。\n您也可以为应用创建自定义配置文件。\n启用UFW 如果要从远程位置连接到Ubuntu，则在启用UFW防火墙之前，必须明确允许传入的SSH连接。 否则，您将无法连接到计算机。\n要将您的UFW防火墙配置为允许传入的SSH连接，请键入以下命令：\n$ sudo ufw allow ssh Rules updated Rules updated (v6) 如果SSH在非标准端口上运行，则需要打开该端口。\n例如，如果您的ssh守护程序侦听端口7722，请输入以下命令以允许该端口上的连接：\n$ sudo ufw allow 7722/tcp 现在已将防火墙配置为允许传入的SSH连接，您可以通过键入以下内容来启用它：\n$ sudo ufw enable Command may disrupt existing ssh connections. Proceed with operation (y|n)? y Firewall is active and enabled on system startup 将警告您启用防火墙可能会破坏现有的ssh连接，只需键入y并单击Enter。\n打开端口 根据系统上运行的应用程序，您可能还需要打开其他端口。 打开端口的一般语法如下：\n$ ufw allow port_number/protocol 以下是有关如何允许HTTP连接的几种方法。\n第一种选择是使用服务名称。 UFW检查/etc/services文件中指定服务的端口和协议：\n$ sudo ufw allow http 您还可以指定端口号和协议：\n$ sudo ufw allow 80/tcp 如果未给出协议，则UFW会同时为tcp和udp创建规则。\n另一个选择是使用应用程序配置文件； 在这种情况下，“ Nginx HTTP”：\n$ sudo ufw allow \u0026#39;Nginx HTTP\u0026#39; UFW还支持使用proto关键字指定协议的另一种语法：\n$ sudo ufw allow proto tcp to any port 80 端口范围\nUFW还允许您打开端口范围。 起始端口和结束端口用冒号（:）分隔，并且您必须指定协议tcp或udp。\n例如，如果要同时在tcp和udp上允许端口从7100到7200，则可以运行以下命令：\n$ sudo ufw allow 7100:7200/tcp 特定的IP地址和端口\n要允许来自给定源IP的所有端口上的连接，请使用from关键字，后跟源地址。\n以下是将IP地址列入白名单的示例：\n$ sudo ufw allow from 64.63.62.61 如果要仅允许给定IP地址访问特定端口，请使用to any port关键字，后跟端口号。\n例如，要允许IP地址为64.63.62.61的计算机访问端口22，请输入：\n$ sudo ufw allow from 64.63.62.61 to any port 22 子网\n允许连接到IP地址子网的语法与使用单个IP地址时的语法相同。 唯一的区别是您需要指定子网掩码。\n下面是一个示例，显示了如何允许访问从192.168.1.1到192.168.1.254的IP地址到端口3360（MySQL ）：\n$ sudo ufw allow from 192.168.1.0/24 to any port 3306 特定网络接口\n要允许在特定的网络接口上进行连接，请使用in on关键字，后跟网络接口(网卡)的名称：\n$ sudo ufw allow in on eth2 to any port 3306 拒绝连接 所有传入连接的默认策略均设置为deny，如果您未更改默认策略，除非您专门打开连接，否则UFW会阻止所有传入连接。\n撰写拒绝规则与撰写允许规则相同； 您只需要使用deny关键字而不是allow。\n假设您打开了端口80和443，并且服务器受到23.24.25.0/24网络的攻击。 要拒绝来自23.24.25.0/24的所有连接，您可以运行以下命令：\n$ sudo ufw deny from 23.24.25.0/24 以下是拒绝访问23.24.25.0/24中的端口80和443的示例，您可以使用以下命令：\n$ sudo ufw deny proto tcp from 23.24.25.0/24 to any port 80,443 删除UFW规则 有两种方法可以通过规则编号和指定实际规则来删除UFW规则。\n按规则号删除规则比较容易，尤其是当您不熟悉UFW时。 要首先通过规则编号删除规则，您需要找到要删除的规则的编号。 要获取编号规则的列表，请使用ufw status numbered命令：\n$ sudo ufw status numbered Status: active To Action From -- ------ ---- [ 1] 22/tcp ALLOW IN Anywhere [ 2] 80/tcp ALLOW IN Anywhere [ 3] 8080/tcp ALLOW IN Anywhere 要删除规则号3，该规则号允许连接到端口8080，请输入：\n$ sudo ufw delete 3 第二种方法是通过指定实际规则来删除规则。 例如，如果您添加了打开端口8069的规则，则可以使用以下命令将其删除：\n$ sudo ufw delete allow 8069 禁用UFW 如果出于任何原因要停止UFW并停用所有规则，则可以使用：\n$ sudo ufw disable 以后，如果您想重新启用UTF并激活所有规则，只需键入：\n$ sudo ufw enable 重设UFW 重置UFW将禁用UFW，并删除所有活动规则。 如果您想还原所有更改并重新开始，这将很有帮助。\n要重置UFW，请输入以下命令：\n$ sudo ufw reset IP伪装 IP伪装是Linux内核中NAT（网络地址转换）的一种变体，它通过重写源IP地址和目标IP地址和端口来转换网络流量。 借助IP伪装，您可以使用一台充当网关的Linux计算机，允许专用网络中的一台或多台计算机与Internet通信。\n使用UFW配置IP伪装涉及几个步骤。\n首先，您需要启用IP转发。 为此，请打开/etc/ufw/sysctl.conf文件，查找并取消注释以下行：net.ipv4.ip_forward = 1：\n$ sudo nano /etc/ufw/sysctl.conf net/ipv4/ip_forward=1 接下来，您需要配置UFW以允许转发数据包。 打开UFW配置文件，找到DEFAULT_FORWARD_POLICY键，然后将值从DROP更改为ACCEPT：\n$ sudo nano /etc/default/ufw DEFAULT_FORWARD_POLICY=\u0026#34;ACCEPT\u0026#34; 现在，您需要在nat表中设置POSTROUTING链的默认策略和伪装规则。 为此，请打开/etc/ufw/before.rules文件，附加以下几行：\n$ sudo nano /etc/ufw/before.rules #NAT table rules *nat :POSTROUTING ACCEPT [0:0] # Forward traffic through eth0 - Change to public network interface -A POSTROUTING -s 10.8.0.0/16 -o eth0 -j MASQUERADE # don\u0026#39;t delete the \u0026#39;COMMIT\u0026#39; line or these rules won\u0026#39;t be processed COMMIT 别忘了在-A POSTROUTING行中替换eth0以匹配公共网络接口的名称：\n完成后，保存并关闭文件。\n最后，通过禁用和重新启用UFW重新加载UFW规则：\n$ sudo ufw disable $ sudo ufw e udev 如果你使用Linux比较长时间了，那你就知道，在对待设备文件这块，Linux改变了几次策略。在Linux早期，设备文件仅仅是是一些带有适当的属性集的普通文件，它由mknod命令创建，文件存放在/dev目录下。后来，采用了devfs, 一个基于内核的动态设备文件系统，他首次出现在2.3.46内核中。Mandrake，Gentoo等Linux分发版本采用了这种方式。devfs创建 的设备文件是动态的。但是devfs有一些严重的限制，从2.6.13版本后移走了。目前取代他的便是文本要提到的udev－－一个用户空间程序。\n目前很多的Linux分发版本采纳了udev的方式，因为它在Linux设备访问，特别是那些对设备有极端需求的站点(比如需要控制上千个硬盘)和热插拔设备(比如USB摄像头和MP3播放器)上解决了几个问题。下面我我们来看看如何管理udev设备。\n实际上，对于那些为磁盘，终端设备等准备的标准配置文件而言，你不需要修改什么。但是，你需要了解udev配置来使用新的或者外来设备，如果不修改配置， 这些设备可能无法访问，或者说Linux可能会采用不恰当的名字，属组或权限来创建这些设备文件。你可能也想知道如何修改RS－232串口，音频设备等文件的属组或者权限。这点在实际的Linux实施中是会遇到的。\n为什么使用udev 在此之前的设备文件管理方法(静态文件和devfs)有几个缺点：\n 不确定的设备映射。特别是那些动态设备，比如USB设备，设备文件到实际设备的映射并不可靠和确定。举一个例子：如果你有两个USB打印机。一个可能称 为/dev/usb/lp0,另外一个便是/dev/usb/lp1。但是到底哪个是哪个并不清楚，lp0,lp1和实际的设备没有一一对应的关系，因为 他可能因为发现设备的顺序，打印机本身关闭等原因而导致这种映射并不确定。理想的方式应该是：两个打印机应该采用基于他们的序列号或者其他标识信息的唯一 设备文件来映射。但是静态文件和devfs都无法做到这点。 没有足够的主/辅设备号。我们知道，每一个设备文件是有两个8位的数字：一个是主设备号 ，另外一个是辅设备号来分配的。这两个8位的数字加上设备类型(块设备或者字符设备)来唯一标识一个设备。不幸的是，关联这些身边的的数字并不足够。 /dev目录下文件太多。一个系统采用静态设备文件关联的方式，那么这个目录下的文件必然是足够多。而同时你又不知道在你的系统上到底有那些设备文件是激活的。 命名不够灵活。尽管devfs解决了以前的一些问题，但是它自身又带来了一些问题。其中一个就是命名不够灵活；你别想非常简单的就能修改设备文件的名字。缺省的devfs命令机制本身也很奇怪，他需要修改大量的配置文件和程序。 内核内存使用，devfs特有的另外一个问题是，作为内核驱动模块，devfs需要消耗大量的内存，特别当系统上有大量的设备时(比如上面我们提到的系统一个上有好几千磁盘时)  udev的目标是想解决上面提到的这些问题，他通采用用户空间(user-space)工具来管理/dev/目录树，他和文件系统分开。知道如何改变缺省配置能让你之大如何定制自己的系统，比如创建设备字符连接，改变设备文件属组，权限等。\nudev配置文件 主要的udev配置文件是/etc/udev/udev.conf。这个文件通常很短，他可能只是包含几行#开头的注释，然后有几行选项：\nudev_root=“/dev/” udev_rules=“/etc/udev/rules.d/” udev_log=“err“ 上面的第二行非常重要，因为他表示udev规则存储的目录，这个目录存储的是以.rules结束的文件。每一个文件处理一系列规则来帮助udev分配名字给设备文件以保证能被内核识别。\n你的/etc/udev/rules.d下面可能有好几个udev规则文件，这些文件一部分是udev包安装的，另外一部分则是可能是别的硬件或者软件包 生成的。比如在Fedora Core 5系统上，sane-backends包就会安装60-libsane.rules文件，另外initscripts包会安装60-net.rules文 件。这些规则文件的文件名通常是两个数字开头，它表示系统应用该规则的顺序。\n规则文件里的规则有一系列的键/值对组成，键/值对之间用逗号(,)分割。每一个键或者是用户匹配键，或者是一个赋值键。匹配键确定规则是否被应用，而赋 值键表示分配某值给该键。这些值将影响udev创建的设备文件。匹配键和赋值键操作符解释见下表：\n   操作符 匹配或赋值 解释     == 匹配 相等比较   != 匹配 不等比较   = 赋值 分配一个特定的值给该键，他可以覆盖之前的赋值。   += 赋值 追加特定的值给已经存在的键   := 赋值 分配一个特定的值给该键，后面的规则不可能覆盖它。    这有点类似我们常见的编程语言，比如C语言。只是这里的键一次可以处理多个值。有一些键在udev规则文件里经常出现，这些键的值可以使用通配符(*,?,甚至范围，比如[0-9])，这些常用键列举如下：\n   键 含义     ACTION 一个时间活动的名字，比如add，当设备增加的时候   KERNEL 在内核里看到的设备名字，比如sd*表示任意SCSI磁盘设备   DEVPATH 内核设备路径，比如/devices/*   SUBSYSTEM 子系统名字，比如sound,net   BUS 总线的名字，比如IDE,USB   DRIVER 设备驱动的名字，比如ide-cdromID 独立于内核名字的设备名字   SYSFS{ value} sysfs属性值，他可以表示任意   ENV{ key} 环境变量，可以表示任意   PROGRAM 可执行的外部程序，如果程序返回0值，该键则认为为真(true)   RESULT 上一个PROGRAM调用返回的标准输出。   NAME 根据这个规则创建的设备文件的文件名。注意：仅仅第一行的NAME描述是有效的，后面的均忽略。 如果你想使用使用两个以上的名字来访问一个设备的话，可以考虑SYMLINK键。   SYMLINK 根据规则创建的字符连接名   OWNER 设备文件的属组   GROUP 设备文件所在的组。   MODE 设备文件的权限，采用8进制   RUN 为设备而执行的程序列表   LABEL 在配置文件里为内部控制而采用的名字标签(下下面的GOTO服务)   GOTO 跳到匹配的规则（通过LABEL来标识），有点类似程序语言中的GOTO   IMPORT{ type} 导入一个文件或者一个程序执行后而生成的规则集到当前文件   WAIT_FOR_SYSFS 等待一个特定的设备文件的创建。主要是用作时序和依赖问题。   PTIONS 特定的选项： last_rule 对这类设备终端规则执行； ignore_device 忽略当前规则； ignore_remove 忽略接下来的并移走请求。all_partitions 为所有的磁盘分区创建设备文件。    我们给出一个列子来解释如何使用这些键。下面的例子来自Fedora Core 5系统的标准配置文件。\nKERNEL==\u0026#34;*\u0026#34;, OWNER=\u0026#34;root\u0026#34; GROUP=\u0026#34;root\u0026#34;, MODE=\u0026#34;0600\u0026#34; KERNEL==\u0026#34;tty\u0026#34;, NAME=\u0026#34;%k\u0026#34;, GROUP=\u0026#34;tty\u0026#34;, MODE=\u0026#34;0666\u0026#34;, OPTIONS=\u0026#34;last_rule\u0026#34; KERNEL==\u0026#34;scd[0-9]*\u0026#34;, SYMLINK+=\u0026#34;cdrom cdrom-%k\u0026#34; KERNEL==\u0026#34;hd[a-z]\u0026#34;, BUS==\u0026#34;ide\u0026#34;, SYSFS{removable}==\u0026#34;1\u0026#34;, SYSFS{device/media}==\u0026#34;cdrom\u0026#34;, SYMLINK+=\u0026#34;cdrom cdrom-%k\u0026#34; ACTION==\u0026#34;add\u0026#34;, SUBSYSTEM==\u0026#34;scsi_device\u0026#34;, RUN+=\u0026#34;/sbin/modprobe sg\u0026#34; 上面的例子给出了5个规则，每一个都是KERNEL或者ACTION键开头：\n 第一个规则是缺省的，他匹配任意被内核识别到的设备，然后设定这些设备的属组是root，组是root，访问权限模式是0600(-rw——-)。这也是一个安全的缺省设置保证所有的设备在默认情况下只有root可以读写 第二个规则也是比较典型的规则了。它匹配终端设备(tty)，然后设置新的权限为0600，所在的组是tty。它也设置了一个特别的设备文件名:%K。在这里例子里，%k代表设备的内核名字。那也就意味着内核识别出这些设备是什么名字，就创建什么样的设备文件名。 第三行开始的KERNEL==”scd[0-9]*”,表示 SCSI CD-ROM 驱动. 它创建一对设备符号连接：cdrom和cdrom-%k。 第四行，开始的 KERNEL==”hd[a-z]“, 表示ATA CDROM驱动器。这个规则创建和上面的规则相同的符号连接。ATA CDROM驱动器需要sysfs值以来区别别的ATA设备，因为SCSI CDROM可以被内核唯一识别。. 第五行以 ACTION==”add”开始，它告诉udev增加 /sbin/modprobe sg 到命令列表，当任意SCSI设备增加到系统后，这些命令将执行。其效果就是计算机应该会增加sg内核模块来侦测新的SCSI设备。  当然，上面仅仅是一小部分例子，如果你的系统采用了udev方式，那你应该可以看到更多的规则。如果你想修改设备的权限或者创建信的符号连接，那么你需要熟读这些规则，特别是要仔细注意你修改的那些与之相关的设备。\n修改你的udev配置 在修改udev配置之前，我们一定要仔细，通常的考虑是：你最好不要修改系统预置的那些规则，特别不要指定影响非常广泛的配置，比如上面例子中的第一行。不正确的配置可能会导致严重的系统问题或者系统根本就无法这个正确的访问设备。\n而我们正确的做法应该是在/etc/udev/rules.d/下创建一个新的规则文件。确定你给出的文件的后缀是rules文件名给出的数字序列应该比标准配置文件高。比如，你可以创建一个名为99-my-udev.rules的规则文件。在你的规则文件中，你可以指定任何你想修改的配置，比如，假设你 修改修改floppy设备的所在组，还准备创建一个新的符号连接/dev/floppy，那你可以这么写：\nKERNEL==”fd[0-9]*“, GROUP=“users“, SYMLINK+=“floppy“ 有些发行版本，比如Fedora，采用了外部脚本来修改某些特定设备的属组，组关系和权限。因此上面的改动可能并不见得生效。如果你遇到了这个问题，你就需要跟踪和修改这个脚本来达到你的目的。或者你可以修改PROGRAM或RUN键的值来做到这点。\n某些规则的修改可能需要更深的挖掘。比如，你可能想在一个设备上使用sysfs信息来唯一标识一个设备。这些信息最好通过udevinfo命令来获取。\n$ udevinfo –a –p $(udevinfo –q path –n /dev/hda) 上面的命令两次使用udevinfo：一次是返回sysfs设备路径(他通常和我们看到的Linux设备文件名所在路径－－/dev/hda－－不同)；第 二次才是查询这个设备路径，结果将是非常常的syfs信息汇总。你可以找到最够的信息来唯一标志你的设备，你可以采用适当的替换udev配置文件中的 SYSFS选项。下面的结果就是上面的命令输出\n[root@localhost rules.d]# udevinfo -a -p $(udevinfo -q path -n /dev/hda1) Udevinfo starts with the device specified by the devpath and then walks up the chain of parent devices. It prints for every device found,all possible attributes in the udev rules key format. A rule to match, can be composed by the attributes of the device and the attributes from one single parent device. looking at device \u0026#39;/block/hda/hda1\u0026#39;: KERNEL==\u0026#34;hda1\u0026#34; SUBSYSTEM==\u0026#34;block\u0026#34; DRIVER==\u0026#34;\u0026#34; ATTR{stat}==\u0026#34; 1133 2268 2 4\u0026#34; ATTR{size}==\u0026#34;208782\u0026#34; ATTR{start}==\u0026#34;63\u0026#34; ATTR{dev}==\u0026#34;3:1\u0026#34; looking at parent device \u0026#39;/block/hda\u0026#39;: KERNELS==\u0026#34;hda\u0026#34; SUBSYSTEMS==\u0026#34;block\u0026#34; DRIVERS==\u0026#34;\u0026#34; ATTRS{stat}==\u0026#34;28905 18814 1234781 302540 34087 133247 849708 981336 0 218340 1283968\u0026#34; ATTRS{size}==\u0026#34;117210240\u0026#34; ATTRS{removable}==\u0026#34;0\u0026#34; ATTRS{range}==\u0026#34;64\u0026#34; ATTRS{dev}==\u0026#34;3:0\u0026#34; looking at parent device \u0026#39;/devices/pci0000:00/0000:00:1f.1/ide0/0.0\u0026#39;: KERNELS==\u0026#34;0.0\u0026#34; SUBSYSTEMS==\u0026#34;ide\u0026#34; DRIVERS==\u0026#34;ide-disk\u0026#34; ATTRS{modalias}==\u0026#34;ide:m-disk\u0026#34; ATTRS{drivename}==\u0026#34;hda\u0026#34; ATTRS{media}==\u0026#34;disk\u0026#34; looking at parent device \u0026#39;/devices/pci0000:00/0000:00:1f.1/ide0\u0026#39;: KERNELS==\u0026#34;ide0\u0026#34; SUBSYSTEMS==\u0026#34;\u0026#34; DRIVERS==\u0026#34;\u0026#34; looking at parent device \u0026#39;/devices/pci0000:00/0000:00:1f.1\u0026#39;: KERNELS==\u0026#34;0000:00:1f.1\u0026#34; SUBSYSTEMS==\u0026#34;pci\u0026#34; DRIVERS==\u0026#34;PIIX_IDE\u0026#34; ATTRS{broken_parity_status}==\u0026#34;0\u0026#34; ATTRS{enable}==\u0026#34;1\u0026#34; ATTRS{modalias}==\u0026#34;pci:v00008086d000024CAsv0000144Dsd0000C009bc01sc01i8a\u0026#34; ATTRS{local_cpus}==\u0026#34;1\u0026#34; ATTRS{irq}==\u0026#34;11\u0026#34; ATTRS{class}==\u0026#34;0x01018a\u0026#34; ATTRS{subsystem_device}==\u0026#34;0xc009\u0026#34; ATTRS{subsystem_vendor}==\u0026#34;0x144d\u0026#34; ATTRS{device}==\u0026#34;0x24ca\u0026#34; ATTRS{vendor}==\u0026#34;0x8086\u0026#34; looking at parent device \u0026#39;/devices/pci0000:00\u0026#39;: KERNELS==\u0026#34;pci0000:00\u0026#34; SUBSYSTEMS==\u0026#34;\u0026#34; DRIVERS==\u0026#34;\u0026#34; 举一个例子：假设你想修改USB扫描仪的配置。通过一系列的尝试，你已经为这个扫描仪标识了Linux设备文件(每次打开扫描仪时，名字都会变)。你可以使 用上面的命令替换这个正确的Linux设备文件名，然后定位输出的采用SYSFS{idVendor}行和SYSFS{idProduct}行。最后你可 以使用这些信息来为这个扫描仪创建新的选项。\nSYSFS{idVendor}==\u0026#34;0686\u0026#34;, SYSFS{idProduct}==\u0026#34;400e\u0026#34;, SYMLINK+=\u0026#34;scanner\u0026#34;, MODE=\u0026#34;0664\u0026#34;, group=\u0026#34;scanner\u0026#34; 上面的例子表示将扫描仪的组设置为scanner，访问权限设置为0664,同时创建一个/dev/scanner的符号连接。\nMounting usb automatically \u0026amp; having usb\u0026rsquo;s label as mountpoint Note for Ubuntu Server 11.10: This script fails on Ubuntu Server 11.10 due to the obsolete vol_id command. vol_id has been superseded by blkid. To fix the script, replace \u0026ldquo;vol_id\u0026rdquo; by \u0026ldquo;blkid -o udev\u0026rdquo; in the udev-auto-mount.sh script.\nI\u0026rsquo;ve been banging my head around this for a while now, and I think I\u0026rsquo;ve found a working solution. This is developed and tested on a Debian-based system, so it should work on Ubuntu. I\u0026rsquo;ll point out the assumptions it makes so it can be adapted to other systems as well.\n It will automatically mount USB drives on plugin, and shouldn\u0026rsquo;t take much to adapt for Firewire. It uses UDEV, so no monkeying with HAL/DeviceKit/GNOME-Anything. It automagically creates a /media/LABEL directory to mount the device to. However, it may interfere with other automounters; I can\u0026rsquo;t test for that. I expect that, with Gnome-VFS active, both may try to do the mount \u0026hellip; if Gnome-VFS fails the mount, it might not configure a desktop icon. Unmounting from Gnome should be possible, but might require gksudo or similar.  I have not tested this on system boot, but the only reason I can see that it might not work is if it tries to mount the USB drive before the system is ready for mounts. If that\u0026rsquo;s the case, you\u0026rsquo;ll probably need one additional tweak to the mount script. (I\u0026rsquo;m checking with ServerFault to see if there\u0026rsquo;s any advice, but not much interest in it over there.)\nOn to it, then.\nUDEV references  Writing udev Rules (the reference for udev rules) man udev (see your system for the latest version) man udevadm (udev admin tool; again see your system for latest) Backup to USB drive on mount (completely different problem, but helpful for understanding the solution)  Background (UDEV? Whuzzat?) UDEV is the kernel\u0026rsquo;s hotplug system. It\u0026rsquo;s what automagically configures the proper devices and device symlinks (eg /dev/disk/by-label/\u0026lt;LABEL\u0026gt;), both at boot time and for devices added while the system is running.\nD-Bus and HAL are used for sending hardware events to listeners like Desktop Environments. So when you log into GNOME and insert a CD or plug in a USB drive, that event follows this chain:\nkernel -\u0026gt; udev -\u0026gt; dbus -\u0026gt; hal -\u0026gt; gnome-vfs/nautilus (mount) And presto, your drive gets mounted. But in a headless system, we don\u0026rsquo;t want to have to log in to get the benefits of automounting.\nUdev Rules Since UDEV lets us write rules and run programs on device insertion, this is an ideal choice. We\u0026rsquo;re going to take advantage of Debian/Ubuntu\u0026rsquo;s existing rules, let them setup the /dev/disk/by-label/\u0026lt;LABEL\u0026gt; symlink for us, and add another rule that will mount the device for us.\nUDEV\u0026rsquo;s rules are kept in /etc/udev/rules.d (and /lib/udev/rules.d on Karmic), and are processed in numerical order. Any file not starting with a number gets processed after the numbered files. On my system, HAL rules are in a file called 90-hal.rules, so I put my rules in 89-local.rules so they get processed before they get to HAL. Primarily, you need to make sure these rules happen after the 60-persistent-storage.rules. local.rules may be good enough.\nPut this in your new rules file:\n# /etc/udev/rules.d/local.rules # /etc/udev/rules.d/89-local.rules # ADD rule: if we have a valid ID_FS_LABEL_ENC, and it's USB, mkdir and mount ENV{ID_FS_LABEL_ENC}==\u0026quot;?*\u0026quot;, ACTION==\u0026quot;add\u0026quot;, SUBSYSTEMS==\u0026quot;usb\u0026quot;, \\ RUN+=\u0026quot;/usr/local/sbin/udev-automounter.sh %k\u0026quot;  Make sure there\u0026rsquo;s no spaces after the \\, just a newline (\\n). Change SUBSYSTEMS==\u0026quot;usb\u0026quot; to SUBSYSTEMS==\u0026quot;usb|ieee1394\u0026quot; for Firewire support. If you want the device to always be owned by a particular user, add an OWNER=\u0026quot;username\u0026quot; clause. If you just need the files owned by a particular user, tweak the mount script instead.  Reading the Rule\nThis adds a program to run to the device\u0026rsquo;s list of programs to run. It identifies USB partition devices by \u0026lt;LABEL\u0026gt;, then passes this information to a script that performs the mount. Specifically, this rule is matching:\n  ENV{ID_FS_LABEL_ENC}==\u0026quot;?\\*\u0026quot; \u0026ndash; an environment variable set by an earlier system rule. Doesn\u0026rsquo;t exist for non-filesystems, so that\u0026rsquo;s why we check for it. We actually want to use ID_FS_LABEL for the mount point, but I haven\u0026rsquo;t convinced UDEV to escape it for me, so we\u0026rsquo;ll let the mount script handle that.\nThis and other environment variables are obtained by udev using the vol_id command (deprecated). It\u0026rsquo;s a handy tool to see nice quick details on a partition:\n$ sudo vol_id /dev/sdc1 ID_FS_TYPE=ext2 ID_FS_UUID=a40d282a-4a24-4593-a0ab-6f2600f920dd ID_FS_LABEL=Travel Dawgs ID_FS_LABEL_ENC=Travel\\x20Dawgs ID_FS_LABEL_SAFE=Travel_Dawgs   ACTION==\u0026quot;add\u0026quot; \u0026ndash; only match add events\u0026hellip;\n  SUBSYSTEMS==\u0026quot;usb\u0026quot; \u0026ndash; only match devices that are on the USB bus. We use SUBSYSTEMS here because this matches against our device\u0026rsquo;s parents; the device we\u0026rsquo;re interested in will actually be SUBSYSTEM==\u0026ldquo;scsi\u0026rdquo;. Matching against a parent USB device avoids adding our program to the internal drives.\n  RUN+=\u0026quot;...\u0026quot; \u0026ndash; not a match, but an action: add this program to the list of programs to run. In the program\u0026rsquo;s arguments, %k gets expanded to the device name (eg sdc1, not /dev/sdc1) and $env{FOO} gets the contents of environment variable FOO.\n  Testing the Rule\nThe first reference link (above) is an excellent UDEV tutorial, but it\u0026rsquo;s slightly out of date. The programs it runs for testing your rules (udevtest in particular) have been replaced by the catch-all udevadm utility.\nAfter you\u0026rsquo;ve added the rule, plug in your device. Give it a few seconds, then check to see what device it\u0026rsquo;s been assigned to with:\n$ ls -l /dev/disk/by-label/* lrwxrwxrwx 1 root root 10 2009-10-25 07:27 label_Foo -\u0026gt; ../../sda1 lrwxrwxrwx 1 root root 10 2009-10-25 07:27 label_Bar -\u0026gt; ../../sdb1 lrwxrwxrwx 1 root root 10 2009-10-25 07:27 label_Baz -\u0026gt; ../../sdc1 If your removeable drive contains label_Baz, it\u0026rsquo;s on device sdc1. Run this and look at the output towards the end:\n$ sudo udevadm test /sys/block/sdc/sdc1 parse_file: reading (...) (many lines about files it reads) import_uevent_var: import into environment: (...) (many lines about env variables) (...) (many lines tracing rule matches \u0026amp; programs run) update_link: found 1 devices with name 'disk/by-label/LABEL_BAZ' update_link: found '/block/sdc/sdc1' for 'disk/by-label/LABEL_BAZ' update_link: compare (our own) priority of '/block/sdc/sdc1' 0 \u0026gt;= 0 update_link: 'disk/by-label/LABEL_BAZ' with target 'sdc1' has the highest priority 0, create it udevtest: run: '/usr/local/sbin/udev-automounter.sh sdc1 LABEL_BAZ' udevtest: run: 'socket:/org/freedesktop/hal/udev_event' udevtest: run: 'socket:@/org/kernel/udev/monitor' Look for the script name from our RUN+= rule in the last few lines (3rd from the bottom in this example). You can see the arguments that would be used for this device. You can run that command now to check that the arguments are sound; if it works on your commandline, it should work automatically when a device is inserted.\nYou can also monitor UDEV events in realtime: run sudo udevadm monitor (see man udevadm for details on the switches). Then just plug in a new device and watch events scroll by. (Probably overkill unless you\u0026rsquo;re into really low-level details\u0026hellip;)\nReloading the Rules\nOnce you\u0026rsquo;ve verified the rule is getting read properly, you need to tell UDEV to reload its rules so the new one takes effect. Use any of these methods (if the first doesn\u0026rsquo;t work, the second should\u0026hellip; but try the first first):\n run sudo udevadm control --reload-rules run sudo /etc/init.d/udev reload reboot  Script! Actually, 2 Scripts\u0026hellip; Here\u0026rsquo;s the first script. Since the program we run needs to complete quickly, this just spins the second script off in the background. Put this in /usr/local/sbin/udev-automounter.sh:\n#!/bin/sh # # USAGE: usb-automounter.sh DEVICE # DEVICE is the actual device node at /dev/DEVICE /usr/local/sbin/udev-auto-mount.sh ${1} \u0026amp; Here\u0026rsquo;s the second script. This does a bit more input checking. Put this in /usr/local/sbin/udev-auto-mount.sh. You may want to tweak the mount options below. This script now handles finding the partition LABEL on its own; UDEV only sends the DEVICE name.\nIf there\u0026rsquo;s a problem mounting drives at boot-time, you can put a nice long sleep 60 in this script, to give the system time to come all the way up before the script attempts to mount the drive.\nI\u0026rsquo;ve given a suggestion in the comments for how to check (run ps to see if a webserver is running), but you\u0026rsquo;ll want to tweak that for your system. I think most any network servers you might be using would suffice for this purpose \u0026ndash; nfsd, smbd, apache, etc. The risk, of course, is that the mount script will fail if the service isn\u0026rsquo;t running, so maybe testing a particular file\u0026rsquo;s existence would be a better solution.\n#!/bin/sh # # USAGE: udev-auto-mount.sh DEVICE # DEVICE is the actual device node at /dev/DEVICE # # This script takes a device name, looks up the partition label and # type, creates /media/LABEL and mounts the partition. Mount options # are hard-coded below. DEVICE=$1 # check input if [ -z \u0026quot;$DEVICE\u0026quot; ]; then exit 1 fi # test that this device isn't already mounted device_is_mounted=`grep ${DEVICE} /etc/mtab` if [ -n \u0026quot;$device_is_mounted\u0026quot; ]; then echo \u0026quot;error: seems /dev/${DEVICE} is already mounted\u0026quot; exit 1 fi # If there's a problem at boot-time, this is where we'd put # some test to check that we're booting, and then run # sleep 60 # so the system is ready for the mount below. # # An example to experiment with: # Assume the system is \u0026quot;booted enough\u0026quot; if the HTTPD server is running. # If it isn't, sleep for half a minute before checking again. # # The risk: if the server fails for some reason, this mount script # will just keep waiting for it to show up. A better solution would # be to check for some file that exists after the boot process is complete. # # HTTPD_UP=`ps -ax | grep httpd | grep -v grep` # while [ -z \u0026quot;$HTTPD_UP\u0026quot; ]; do # sleep 30 # HTTPD_UP=`ps -ax | grep httpd | grep -v grep` # done # pull in useful variables from vol_id, quote everything Just In Case eval `/sbin/vol_id /dev/${DEVICE} | sed 's/^/export /; s/=/=\u0026quot;/; s/$/\u0026quot;/'` if [ -z \u0026quot;$ID_FS_LABEL\u0026quot; ] || [ -z \u0026quot;$ID_FS_TYPE\u0026quot; ]; then echo \u0026quot;error: ID_FS_LABEL is empty! did vol_id break? tried /dev/${DEVICE}\u0026quot; exit 1 fi # test mountpoint - it shouldn't exist if [ ! -e \u0026quot;/media/${ID_FS_LABEL}\u0026quot; ]; then # make the mountpoint mkdir \u0026quot;/media/${ID_FS_LABEL}\u0026quot; # mount the device # # If expecting thumbdrives, you probably want # mount -t auto -o sync,noatime [...] # # If drive is VFAT/NFTS, this mounts the filesystem such that all files # are owned by a std user instead of by root. Change to your user's UID # (listed in /etc/passwd). You may also want \u0026quot;gid=1000\u0026quot; and/or \u0026quot;umask=022\u0026quot;, eg: # mount -t auto -o uid=1000,gid=1000 [...] # # case \u0026quot;$ID_FS_TYPE\u0026quot; in vfat) mount -t vfat -o sync,noatime,uid=1000 /dev/${DEVICE} \u0026quot;/media/${ID_FS_LABEL}\u0026quot; ;; # I like the locale setting for ntfs ntfs) mount -t auto -o sync,noatime,uid=1000,locale=en_US.UTF-8 /dev/${DEVICE} \u0026quot;/media/${ID_FS_LABEL}\u0026quot; ;; # ext2/3/4 don't like uid option ext*) mount -t auto -o sync,noatime /dev/${DEVICE} \u0026quot;/media/${ID_FS_LABEL}\u0026quot; ;; esac # all done here, return successful exit 0 fi exit 1 Super Bonus Cleanup Script! One more script. All this does is unmount the device and remove the mountpoint directories. It assumes it has privs to do this, so you\u0026rsquo;ll need to run it with sudo. This script now takes the full mountpoint on the commandline, eg:\n$ /usr/local/sbin/udev-unmounter.sh \u0026quot;/media/My Random Disk\u0026quot; Put this in /usr/local/sbin/udev-unmounter.sh:\n#!/bin/sh # # USAGE: udev-unmounter.sh MOUNTPT # MOUNTPT is a mountpoint we want to unmount and delete. MOUNTPT=\u0026quot;$1\u0026quot; if [ -z \u0026quot;$MOUNTPT\u0026quot; ]; then exit 1 fi # test mountpoint - it should exist if [ -e \u0026quot;${MOUNTPT}\u0026quot; ]; then # very naive; just run and pray umount -l \u0026quot;${MOUNTPT}\u0026quot; \u0026amp;\u0026amp; rmdir \u0026quot;${MOUNTPT}\u0026quot; \u0026amp;\u0026amp; exit 0 echo \u0026quot;error: ${MOUNTPT} failed to unmount.\u0026quot; exit 1 fi echo \u0026quot;error: ${MOUNTPT} does not exist\u0026quot; exit 1 GPG 前两篇文章，我介绍了RSA算法。\n今天，就接着来看，现实中怎么使用这个算法，对信息加密和解密。这要用到GnuPG软件（简称GPG），它是目前最流行、最好用的加密工具之一。\n什么是GPG 要了解什么是GPG，就要先了解PGP。\n1991年，程序员Phil Zimmermann为了避开政府监视，开发了加密软件PGP。这个软件非常好用，迅速流传开来，成了许多程序员的必备工具。但是，它是商业软件，不能自由使用。所以，自由软件基金会决定，开发一个PGP的替代品，取名为GnuPG。这就是GPG的由来。\nGnuPG 是完整实现了 RFC4880 （即PGP） 所定义的 OpenPGP 标准的自由软件。\nGnuPG 可以加密和签名你的数据和通讯信息，包含一个通用的密钥管理系统以及用于各种公钥目录的访问模块。\nGnuPG 是一个易于与其它程序整合的命令行工具，拥有很多前端程序和函数库。\nGnuPG 还支持 S/MIME 和 Secure Shell (ssh)。\nGPG有许多用途，本文主要介绍文件加密。至于邮件的加密，不同的邮件客户端有不同的设置，请参考Ubuntu网站的介绍。\n本文的使用环境为Linux命令行。如果掌握了命令行，Windows 或 Mac OS 客户端，就非常容易掌握。GPG并不难学，学会了它，从此就能轻松传递加密信息。建议读者一步步跟着教程做，对每条命令都自行测试。\n安装 GPG有两种安装方式。可以下载源码，自己编译安装。\n$ ./configure $ make $ make install 也可以安装编译好的二进制包。\n$ sudo apt-get install gnupg 安装完成后，键入下面的命令：\n$ gpg --help 如果屏幕显示GPG的帮助，就表示安装成功。\n配置 目录位置 GnuPG 用环境变量 $GNUPGHOME 定位配置文件的位置，默认情况下此变量并未被设置，会直接使用 $HOME，所以默认的配置目录是 ~/.gnupg。\n要改变默认位置，执行 $ gpg --homedir path/to/file 或在 startup files 中设置 GNUPGHOME。\n配置文件 默认的配置文件是 ~/.gnupg/gpg.conf 和 ~/.gnupg/dirmngr.conf.\ngnupg 目录的默认 权限 是 700，其中文件的权限是 600. 仅目录的所有者有权读写，访问这些文件。这是基于安全考虑，请不要变更。如果不使用这样的安全权限设置，会收到不安全文件的警告。\n在文件中附加需要的文件：/usr/share/gnupg 包含基本架构文件. gpg，第一次运行时，如果配置文件不存在，会自动复制文件到 ~/.gnupg。\n新用户的默认选项 要给新建用户设定一些默认选项，把配置文件放到 /etc/skel/.gnupg/。系统创建新用户时，就会把文件复制到 GnuPG 目录。还有一个 addgnupghome 命令可以为已有用户创建新 GnuPG 主目录：\n# addgnupghome user1 user2 此命令会将对检查 /home/user1/.gnupg 和 /home/user2/.gnupg，如果用户的 GnuPG 主目录不存在，就会从 skeleton 目录复制文件过去。\n生成密钥 安装成功后，使用 --full-generate-key 参数生成自己的密钥。\n$ gpg --full-generate-key 或用 gpg --gen-key 快速生成。以下使用 gpg2 --full-generate-key 演示。\n回车以后，会跳出一大段文字：\ngpg (GnuPG) 2.2.19; Copyright (C) 2019 Free Software Foundation, Inc. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Please select what kind of key you want: (1) RSA and RSA (default) (2) DSA and Elgamal (3) DSA (sign only) (4) RSA (sign only) (14) Existing key from card Your selection? 第一段是版权声明，然后让用户自己选择加密算法。默认选择第一个选项，表示加密和签名都使用RSA算法。\n然后，系统就会问你密钥的长度。\nRSA keys may be between 1024 and 4096 bits long. What keysize do you want? (3072) 密钥越长越安全。\n接着，设定密钥的有效期。\nPlease specify how long the key should be valid. 0 = key does not expire \u0026lt;n\u0026gt; = key expires in n days \u0026lt;n\u0026gt;w = key expires in n weeks \u0026lt;n\u0026gt;m = key expires in n months \u0026lt;n\u0026gt;y = key expires in n years Key is valid for? (0) 如果密钥只是个人使用，并且你很确定可以有效保管私钥，建议选择第一个选项，即永不过期。回答完上面三个问题以后，系统让你确认。\nIs this correct? (y/N) 输入y，系统就要求你提供个人信息。\nGnuPG needs to construct a user ID to identify your key. Real name: Email address Comment: \u0026ldquo;真实姓名\u0026quot;填入你姓名的英文写法，\u0026ldquo;电子邮件地址\u0026quot;填入你的邮件地址，\u0026ldquo;注释\u0026quot;这一栏可以空着。\n然后，你的\u0026quot;用户ID\u0026quot;生成了。\nYou selected this USER-ID: \u0026#34;Vane Hsiung \u0026lt;1664548605@qq.com\u0026gt;\u0026#34; 系统会让你最后确认一次。\nChange (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? 输入O表示\u0026quot;确定\u0026rdquo;。\n接着，系统会要求你做一些随机的举动，以生成一个随机数。同时系统会让你设定一个私钥的密码。这是为了防止误操作，或者系统被侵入时有人擅自动用私钥。\nWe need to generate a lot of random bytes. It is a good idea to performsome other action (type on the keyboard, move the mouse, utilize thedisks) during the prime generation; this gives the random numbergenerator a better chance to gain enough entropy. 然后，系统就开始生成密钥了，\n几分钟以后，系统提示密钥已经生成了。\ngpg: key B893B73ABC92D2CA marked as ultimately trusted gpg: revocation certificate stored as \u0026#39;\u0026#39;public and secret key created and signed. 请注意上面的字符串\u0026quot;B893B73ABC92D2CA\u0026rdquo;，这是\u0026quot;用户ID\u0026quot;的Hash字符串，可以用来替代\u0026quot;用户ID\u0026rdquo;。\n这时，最好再生成一张\u0026quot;撤销证书\u0026rdquo;，以备以后密钥作废时，可以请求外部的公钥服务器撤销你的公钥。\n$ gpg --gen-revoke [用户ID] 上面的\u0026quot;用户ID\u0026quot;部分，可以填入你的邮件地址或者Hash字符串（以下同）。\n密钥管理 列出密钥\nlist-keys参数列出系统中已有的密钥．\n$ gpg --list-keys 显示结果如下：\ngpg: checking the trustdb gpg: marginals needed: 3 completes needed: 1 trust model: pgp gpg: depth: 0 valid: 1 signed: 0 trust: 0-, 0q, 0n, 0m, 0f, 1u /home/vane/.gnupg/pubring.kbx ----------------------------- pub rsa3072 2021-10-17 [SC] BC158F7500033355B5324CF14C701F8BF2E03463 uid [ultimate] Vane Hsiung \u0026lt;1664548605@qq.com\u0026gt; sub rsa3072 2021-10-17 [E] 第一行显示公钥文件名（pubring.gpg），第二行显示公钥特征（4096位，Hash字符串和生成时间），第三行显示\u0026quot;用户ID\u0026quot;，第四行显示私钥特征。\n如果你要从密钥列表中删除某个密钥，可以使用如下参数。\n$ gpg --delete-secret-keys [用户ID] $ gpg --delete-key [用户ID] 输出密钥\n公钥文件（.gnupg/pubring.gpg）以二进制形式储存，armor参数可以将其转换为ASCII码显示。\n$ gpg --armor --output public-key.txt --export [用户ID] \u0026ldquo;用户ID\u0026quot;指定哪个用户的公钥，output参数指定输出文件名（public-key.txt）。\n类似地，export-secret-keys参数可以转换私钥。\n$ gpg --armor --output private-key.txt --export-secret-keys 上传公钥\n公钥服务器是网络上专门储存用户公钥的服务器。send-keys参数可以将公钥上传到服务器。\n$ gpg --send-keys [用户ID] --keyserver hkp://subkeys.pgp.net 使用上面的命令，你的公钥就被传到了服务器subkeys.pgp.net，然后通过交换机制，所有的公钥服务器最终都会包含你的公钥。\n由于公钥服务器没有检查机制，任何人都可以用你的名义上传公钥，所以没有办法保证服务器上的公钥的可靠性。通常，你可以在网站上公布一个公钥指纹，让其他人核对下载到的公钥是否为真。fingerprint参数生成公钥指纹。\n$ gpg --fingerprint [用户ID] 输入密钥\n除了生成自己的密钥，还需要将他人的公钥或者你的其他密钥输入系统。这时可以使用import参数。\n$ gpg --import [密钥文件] 为了获得他人的公钥，可以让对方直接发给你，或者到公钥服务器上寻找。\n$ gpg --keyserver hkp://subkeys.pgp.net --search-keys [用户ID] 正如前面提到的，我们无法保证服务器上的公钥是否可靠，下载后还需要用其他机制验证．\n加密和解密 加密\n假定有一个文本文件demo.txt，怎样对它加密呢？\nencrypt参数用于加密。\n$ gpg --recipient [用户ID] --output demo.en.txt --encrypt demo.txt recipient参数指定接收者的公钥，output参数指定加密后的文件名，encrypt参数指定源文件。运行上面的命令后，demo.en.txt就是已加密的文件，可以把它发给对方。\n解密\n对方收到加密文件以后，就用自己的私钥解密。\n$ gpg --output demo.de.txt --decrypt demo.en.txt output 指定解密后生成的文件，decrypt参数指定需要解密的文件。运行上面的命令，demo.de.txt就是解密后的文件。\nGPG允许省略decrypt参数。\n$ gpg demo.en.txt 签名 对文件签名\n有时，我们不需要加密文件，只需要对文件签名，表示这个文件确实是我本人发出的。sign参数用来签名。\n$ gpg --sign demo.txt 运行上面的命令后，当前目录下生成demo.txt.gpg文件，这就是签名后的文件。这个文件默认采用二进制储存，如果想生成ASCII码的签名文件，可以使用clearsign参数。\n$ gpg --clearsign demo.txt 运行上面的命令后 ，当前目录下生成demo.txt.asc文件，后缀名asc表示该文件是ASCII码形式的。\n如果想生成单独的签名文件，与文件内容分开存放，可以使用detach-sign参数。　$ gpg --detach-sign demo.txt 运行上面的命令后，当前目录下生成一个单独的签名文件demo.txt.sig。该文件是二进制形式的，如果想采用ASCII码形式，要加上armor参数。　$ gpg --armor --detach-sign demo.txt 签名+加密\n上一节的参数，都是只签名不加密。如果想同时签名和加密，可以使用下面的命令。\n$ gpg --local-user [发信者ID] --recipient [接收者ID] --armor --sign --encrypt demo.txt local-user参数指定用发信者的私钥签名，recipient参数指定用接收者的公钥加密，armor参数表示采用ASCII码形式显示，sign参数表示需要签名，encrypt参数表示指定源文件。\n验证签名\n我们收到别人签名后的文件，需要用对方的公钥验证签名是否为真。verify参数用来验证。\n$ gpg --verify demo.txt.asc demo.txt 举例来说，openvpn网站就提供每一个下载包的gpg签名文件。你可以根据它的说明，验证这些下载包是否为真。\nLinux Kernel 来自 Wikipedia:\n 内核是计算机操作系统的核心组件，对系统有完全的控制。开机时最先启动，然后负责后续的启动工作。它负责处理其它软件的请求，将这些请求转化为中央处理器的数据处理请求。内核还负责管理内存，管理系统和其它打印机、扬声器等外围设备的通讯，是操作系统最基础的部分。\n 内核包安装在/boot/下的文件系统上。为了能够引导到内核，必须适当配置启动加载器。\nKernel module 内核模块是可以按需加载或卸载的内核代码，可以不重启系统就扩充内核的功能。\n要创建内核模块，请阅读此指南。模块可以设置成内置或者动态加载，要编译成可动态加载，需要在内核配置时将模块配置为 M (模块)。\n获取信息 模块保存在 /lib/modules/kernel_release (使用 uname -r 命令显示当前内核版本)。\n注意： 模块名通常使用 (_) 或 - 连接，但是这些符号在 modprobe 命令和 /etc/modprobe.d/ 配置文件中都是可以相互替换的。\n显示当前装入的内核模块：\n$ lsmod 在上面的输出中：\n Module 显示每个模块的名称 Size 显示每个模块的大小（并不是它们占的内存大小） Used by 显示每个模块被使用的次数和使用它们的模块  显然，这里有很多模块。加载的模块数量取决于你的系统和版本以及正在运行的内容。我们可以这样计数：\n$ lsmod | wc -l 67 modules.builtin 文件中列出了所有构建在内核中的模块\n$ more /lib/modules/$(uname -r)/modules.builtin | head -10 kernel/arch/x86/crypto/crc32c-intel.ko kernel/arch/x86/events/intel/intel-uncore.ko kernel/arch/x86/platform/intel/iosf_mbi.ko kernel/mm/zpool.ko kernel/mm/zbud.ko kernel/mm/zsmalloc.ko kernel/fs/binfmt_script.ko kernel/fs/mbcache.ko kernel/fs/configfs/configfs.ko kernel/fs/crypto/fscrypto.ko 显示模块信息：\n$ modinfo module_name 显示所有模块的配置信息：\n$ modprobe -c | less 显示某个模块的配置信息：\n$ modprobe -c | grep module_name 显示一个装入模块使用的选项：\n$ systool -v -m module_name 显示模块的依赖关系：\n$ modprobe --show-depends module_name 使用systemd自动加载模块 目前，所有必要模块的加载均由 udev 自动完成。所以，如果不需要使用任何额外的模块，就没有必要在任何配置文件中添加启动时加载的模块。但是，有些情况下可能需要在系统启动时加载某个额外的模块，或者将某个模块列入黑名单以便使系统正常运行。\n内核模块可以在/etc/modules-load.d/ 下的文件中明确列出，以便systemd在引导过程中加载它们。 每个配置文件都以 /etc/modules-load.d/\u0026lt;program\u0026gt;.conf的样式命名。 配置文件仅包含要加载的内核模块名称列表，以换行符分隔。 空行和第一个非空白字符为#或;的行被忽略。\n$ cat /etc/modules-load.d/virtio-net.conf # Load virtio_net.ko at boot virtio_net 另见modules-load.d(5)。\n手动加载卸载 控制内核模块载入/移除的命令是kmod 软件包提供的, 要手动装入模块的话，执行:\n# modprobe module_name 按文件名加载模块:\n# insmod filename [args] 注意： 如果升级了内核但是没有重启，路径 /usr/lib/modules/$(uname -r)/ 已经不存在。modprobe 会返回错误 1，没有额外的错误信息。如果出现 modprobe 加载失败，请检查模块路径以确认是否是这个问题导致。\n如果要移除一个模块：\n# modprobe -r module_name 或者:\n# rmmod module_name 配置模块参数 手动加载时设置 传递参数的基本方式是使用 modprobe 选项，格式是 key=value：\n# modprobe module_name parameter_name=parameter_value 使用 /etc/modprobe.d/中的文件 要通过配置文件传递参数，在 /etc/modprobe.d/ 中放入任意名称 .conf 文件，加入:\n$ sudo gedit /etc/modprobe.d/myfilename.conf options modname parametername=parametercontents 例如\n$ sudo gedit /etc/modprobe.d/thinkfan.conf # On thinkpads, this lets the thinkfan daemon control fan speed options thinkpad_acpi fan_control=1 注意： 如果要在启动时就修改内核参数(从 init ramdisk 开始)，需要将相应的.conf-文件加入 mkinitcpio.conf 的 FILES 参数中。\n使用内核命令行 如果模块直接编译进内核，也可以通过启动管理器(GRUB, LILO 或 Syslinux)的内核行加入参数：\nmodname.parametername=parametercontents 例如:\nthinkpad_acpi.fan_control=1 别名 $ cat /etc/modprobe.d/myalias.conf # Lets you use \u0026#39;mymod\u0026#39; in MODULES, instead of \u0026#39;really_long_module_name\u0026#39; alias mymod really_long_module_name 有些模块具有别名，以方便其它程序自动装入模块。禁用这些别名可以阻止自动装入，但是仍然可以手动装入。\n$ cat /etc/modprobe.d/modprobe.conf # Prevent autoload of bluetooth alias net-pf-31 off # Prevent autoload of ipv6 alias net-pf-10 off 黑名单 禁用内核模块 对内核模块来说，黑名单是指禁止某个模块装入的机制。当对应的硬件不存在或者装入某个模块会导致问题时很有用。\n有些模块作为 initramfs 的一部分装入。\nmkinitcpio -M 会显示所有自动检测到到模块：要阻止 initramfs 装入某些模块，可以在 /etc/modprobe.d中将它们加入黑名单。并应在映像生成过程中通过modconf挂钩将其添加。\n运行 mkinitcpio -v 会显示各种钩子(例如 filesystem 钩子, SCSI 钩子等)装入的模块。如果您的HOOKS 数组中没有 modconf 钩子（例如，和默认配置不同）则请将该\u0026rdquo;.conf\u0026quot;文件添加到/etc/mkinitcpio.conf中的FILES数组中。一旦您将其列入黑名单，请重新生成 initramfs，然后重新启动。\n使用 /etc/modprobe.d/ 中的文件 在 /etc/modprobe.d/ 中创建 .conf 文件，使用 blacklist 关键字屏蔽不需要的模块，例如如果不想装入 pcspkr 模块：\n$ sudo gedit /etc/modprobe.d/nobeep.conf # Do not load the pcspkr module on boot blacklist pcspkr 注意： blacklist 命令将屏蔽一个模板，所以不会自动装入，但是如果其它非屏蔽模块需要这个模块，系统依然会装入它。\n要避免这个行为，可以让 modprobe 使用自定义的 install 命令，而不是像往常一样将模块插入内核，因此您可以通过以下方式强制模块始终无法加载：\n$ sudo gedit /etc/modprobe.d/blacklist.conf ... install MODULE /bin/true ... 这样就可以 \u0026ldquo;屏蔽\u0026rdquo; 模块及所有依赖它的模块。\n使用内核命令行 提示： 如果模块损坏导致无法引导系统，这将非常有用。\n您也可以从引导加载程序中将模块列入黑名单。\n如Kernel参数.中所述，只需将module_blacklist=modname1,modname2,modname3 添加到引导加载程序的内核行中即可。\n注意： 将多个模块列入黑名单时，请注意，它们之间仅用逗号分隔。 空格或其他内容可能会破坏语法。\nKernel parameters 一共有三种办法，可以给内核传递参数，用于控制其行为方式：\n 在编译内核时（这个最根本，会决定后面两种方法） 内核启动时(通常是在一个启动管理器里设置). 在运行时 (通过修改在 /proc 和 /sys中的文件).  本页面主要是讲第二种方法。\n配置 内核参数可以在启动时临时修改，也可以永久性写到启动管理器的配置文件中，永远起作用。\n下面示例把参数quiet 和 splash 加到启动管理器。\nsystemd-boot   当启动菜单出现时 按 e进入编辑界面:\ninitrd=\\initramfs-linux.img root=/dev/sda2 quiet splash   如果想永久加入参数，编辑 /boot/loader/entries/arch.conf (假设你已经设置好了 EFI system partition) 的options 行:\n  注意：\n 如果没有设置显示启动菜单, 你需要按住Space启动电脑来进入启动菜单 。 如果不能够从启动菜单上进行编辑，修改 /boot/loader/loader.conf 加入 editor 1 来开启编辑功能。  更多信息请参见 systemd-boot .\nGRUB   在菜单出现后按 e 然后将它们添加至 linux 行：\nlinux /boot/vmlinuz-linux root=UUID=978e3e81-8048-4ae1-8a06-aa727458e8ff ro quiet splash 按 b 以便用这些参数启动。\n  要使改变在重启后仍生效，您可以手动编辑 /boot/grub/grub.cfg 中的如上内容。对于初学者，建议编辑 /etc/default/grub 并将您的内核选项添加至 GRUB_CMDLINE_LINUX_DEFAULT 行：\nGRUB_CMDLINE_LINUX_DEFAULT=\u0026quot;quiet splash\u0026quot; 然后重新生成 grub.cfg 文件：\n# grub-mkconfig -o /boot/grub/grub.cfg   有关配置GRUB的更多信息，请参阅 GRUB 。\n发布时间表 内核发布时间表：有吗？ 短的回答是，每两到三个月就有一个新的内核版本发布。长的回答是，这不是一个硬性规定。\n这个意思是，你经常会看到每两到三个月就有一个新的内核版本发布。这是内核维护者团队的目标，但并没有规定新版本必须在前一个版本的 8 周后准时发布的期限。\n新的内核版本（通常）是由 Linus Torvalds 在它准备好的时候发布的。通常是每 2 到 3 个月发布一次。该版本被宣布为“稳定”，一般以 X.Y 的格式编号。\n但这并不是 X.Y 开发的结束。稳定版会有更多的小版本以进行错误的修复。这些小版本在稳定版的内核上又增加了一个点，就像是 X.Y.Z。\n虽然 X.Y（通常）是由 Linux 创造者 Linus Torvalds 发布的，但是维护稳定的 X.Y 内核、合并错误修复和发布 X.Y.Z 版本的责任是由另外的内核开发者负责的。\n一个内核版本支持多长时间？ 和发布一样，一个内核版本支持多长时间也没有固定的日期和时间表。\n一个普通的稳定内核版本通常会被支持两个半月到三个月，这取决于下一个稳定内核版本的发布时间。\n例如，稳定版内核 5.14 会在稳定版内核 5.15 发布后的几周内达到生命末期。结束支持是由该稳定内核版本的维护者在 Linux 内核邮件列表中宣布的。用户和贡献者会被要求切换到新发布的稳定版本。\n但这只适用于正常的稳定内核版本，还有 LTS（长期支持）内核版本，它们的支持期要比 3 个月长得多。\nLTS 内核：它支持多长时间？ LTS 内核也没有固定的发布时间表。通常，每年都有一个 LTS 内核版本，一般是当年的最后一个版本，它至少会被支持两年。但同样，这里也没有固定的规则。\nLTS 内核的维护者可以同意某个 LTS 内核的维护时间超过通常的两年。这个协议是根据必要性和参与的人员来达成的。\n这种情况经常发生在 Android 项目中。由于两年的时间不足以让制造商结束对他们的硬件和软件功能的支持，你经常会发现一些 LTS 内核会被支持六年之久。\n你可以 在 Linux 内核网站上 找到这个信息。\n你的发行版可能没有跟随通常的 Linux 内核版本 如果你检查你的 Linux 内核版本，你可能会发现 你的发行版使用了一个旧的内核。也有可能该发行版提供的内核已经在内核网站上被标记为到达了生命末期。\n不要惊慌。你的发行版会负责修补内核的错误和漏洞。除非你真的在使用一个不知名的 Linux 发行版，否则你可以相信你的发行版会保持它的安全和健全。\n如果你有足够的理由，比如为了支持更新的硬件，你可以自由地在你使用的任何发行版或 Ubuntu 中安装最新的 Linux 内核 。\n如果你想了解更多细节，我已经 在这里解释了为什么你的发行版使用过时的 Linux 内核。\n安装内核 dpkg\n从 kernel.ubuntu.com 网站手动下载可用的最新 Linux 内核：\n linux-image-X.Y.Z-generic-.deb linux-modules-X.Y.Z-generic-.deb  手动安装内核：\n$ sudo dpkg --install *.deb 重启系统，使用新内核：\n$ sudo reboot 检查是否如你所愿：\n$ uname -r apt-get\n不同于上一个方法，这种方法会从 Ubuntu 官方仓库下载、安装内核版本：\n运行：\n$ sudo apt-get upgrade linux-image-generic XanMod Kernel 最新内核集成的一些新特性的确是可以提升性能的。xanmod 内核的安装可以去它们的官方网站来查询，xanmod 内核的特性很多地方都有，官方也写的有很多，不过大多数还是以下几点：\n 改善了 CPU 调度能力 改善了 I/O 的调度能力 增加了一些和性能有关的第三方补丁 使用了最新的 GCC 进行编译 使用了最新的 MicroCode  安装的方式也比较简单，添加源并且更新安装就行了：\n$ echo \u0026#39;deb http://deb.xanmod.org releases main\u0026#39; | sudo tee /etc/apt/sources.list.d/xanmod-kernel.list \u0026amp;\u0026amp; wget -qO - https://dl.xanmod.org/gpg.key | sudo apt-key add - 然后安装，我个人安装的是最新的 5.8.1 的 edge：\n$ sudo apt update \u0026amp;\u0026amp; sudo apt install linux-xanmod-edge 安装完毕后还可以安装最新的微码：\n$ sudo apt update \u0026amp;\u0026amp; sudo apt install linux-xanmod 重启以应用\n$ sudo reboot Zen/Liquorix Kernel  一些内核黑客合作的结果，是适合日常使用的优秀内核 以吞吐量和功耗为代价来换取性能 相对 linux 内核加入了 Fsync 功能。Fsync 是维尔福公司发布的一个可以帮助提升大量多线程应用运行帧率的特殊内核补丁，这对改善游戏性能有很大帮助。在一些采用 .Net 的 wine 游戏中会有 明显的性能提升 如果你使用英伟达显卡，记得更换驱动为相应的 dkms 版本。一般来说较新的显卡安装 nvidia-dkms 即可。DKMS，即 Dynamic Kernel Module System。可以使内核变更（如升级）后自动编译模块，适配新内核。  Questions about: I\u0026rsquo;m not a kernel expert, but my understanding is that there are different ways for the kernel to prioritize tasks to be processed by the CPU. Priority on a server or workstation is different from a gaming PC. The Zen (and Liquorix) kernel alters the way this is done to optimise for gaming and multimedia. From what I can tell, the difference between the Zen and Liquorix kernels is the scheduler used, but are otherwise the same. There\u0026rsquo;s more info here.\nUbuntu Prerequisites:\n$ sudo add-apt-repository ppa:damentz/liquorix \u0026amp;\u0026amp; sudo apt-get update The Liquorix kernel can be installed by way of meta-packages. This will guarantee that the latest kernel is installed on every upgrade.\n64-bit:\n$ sudo apt-get install linux-image-liquorix-amd64 linux-headers-liquorix-amd64 可选内核 切換内核 可以通过修改 /etc/default/grub 中的 GRUB_DEFAULT 值来改变默认启动项。\n查看 grub menu 目前的選項 ：\n$ grep -A100 submenu /boot/grub/grub.cfg |grep menuentry submenu \u0026#39;Advanced options for Ubuntu\u0026#39; $menuentry_id_option \u0026#39;gnulinux-advanced-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026#39; { menuentry \u0026#39;Ubuntu, with Linux 4.4.0-1062-aws\u0026#39; --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option \u0026#39;gnulinux-4.4.0-1062-aws-advanced-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026#39; { menuentry \u0026#39;Ubuntu, with Linux 4.4.0-1062-aws (recovery mode)\u0026#39; --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option \u0026#39;gnulinux-4.4.0-1062-aws-recovery-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026#39; { menuentry \u0026#39;Ubuntu, with Linux 4.4.0-1061-aws\u0026#39; --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option \u0026#39;gnulinux-4.4.0-1061-aws-advanced-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026#39; { menuentry \u0026#39;Ubuntu, with Linux 4.4.0-1061-aws (recovery mode)\u0026#39; --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option \u0026#39;gnulinux-4.4.0-1061-aws-recovery-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026#39; { 接下來修改 grub config 檔案：\n$ sudo nano /etc/default/grup 找到 GRUB_DEFAULT=0 ，將數字 0 改成想用來開機的 kernel，以這個例子來說：\n 0 = \u0026lsquo;Ubuntu, with Linux 4.4.0-1062-aws\u0026rsquo; = \u0026lsquo;gnulinux-4.4.0-1062-aws-advanced-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026rsquo; 1 = \u0026lsquo;Ubuntu, with Linux 4.4.0-1062-aws (recovery mode)\u0026rsquo; = \u0026lsquo;gnulinux-4.4.0-1062-aws-recovery-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026rsquo; 2 = \u0026lsquo;Ubuntu, with Linux 4.4.0-1061-aws\u0026rsquo; = \u0026lsquo;gnulinux-4.4.0-1061-aws-advanced-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026rsquo; 3 = \u0026lsquo;Ubuntu, with Linux 4.4.0-1061-aws (recovery mode)\u0026rsquo; = \u0026lsquo;gnulinux-4.4.0-1061-aws-recovery-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026rsquo;  GRUB 启动项序号从 0 开始计数，0 代表第一个启动项，也是上述选项的默认值，1 表示第二个启动项，以此类推。主菜单和子菜单项之间用 \u0026gt; 隔开。\n下面的例子启动的是主菜单项 \u0026lsquo;Advanced options for Arch Linux\u0026rsquo; 下子菜单的第三项：\n  使用数字编号：\nGRUB_DEFAULT=2 # or GRUB_DEFAULT=\u0026#34;1\u0026gt;2\u0026#34;   使用菜单标题：\nGRUB_DEFAULT=\u0026#34;Advanced options for Ubuntu\u0026gt;Ubuntu, with Linux 4.4.0-1061-aws\u0026#34;   还可以这样：\nGRUB_DEFAULT=\u0026#34;gnulinux-advanced-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026gt;gnulinux-4.4.0-1061-aws-advanced-4a67ec61-9cd5-4a26-b00f-9391a34c8a29\u0026#34;   更新 grup 設定：\n$ sudo update-grub $ sudo reboot   删除旧内核 随着时间的流逝，持续的内核更新会在系统中积聚大量的不再使用的内核，浪费你的磁盘空间。每个内核镜像和其相关联的模块/头文件会占用200-400MB的磁盘空间，因此由不再使用的内核而浪费的磁盘空间会快速地增加。\nGRUB管理器为每个旧内核都维护了一个GRUB入口，以备你想要使用它们。\n作为磁盘清理的一部分，如果你不再使用这些，你可以考虑清理掉这些镜像。\n在删除旧内核之前，记住最好留有2个最近的内核（最新的和上一个版本），以防主要的版本出错。\n在Ubuntu内核镜像包含了以下的包。\n linux-image-: 内核镜像 linux-image-extra-: 额外的内核模块 linux-headers-: 内核头文件  首先检查系统中安装的内核镜像。\n$ dpkg --list | grep linux-image $ dpkg --list | grep linux-headers 在列出的内核镜像中，你可以移除一个特定的版本。\n$ sudo apt-get purge linux-image-3.19.0-15 $ sudo apt-get purge linux-headers-3.19.0-15 上面的命令会删除内核镜像和它相关联的内核模块和头文件。\n注意如果你还没有升级内核那么删除旧内核会自动触发安装新内核。这样在删除旧内核之后，GRUB配置会自动升级来移除GRUB菜单中相关GRUB入口。\n如果你有很多没用的内核，你可以用shell表达式来一次性地删除多个内核。注意这个括号表达式只在bash或者兼容的shell中才有效。\n$ sudo apt-get purge linux-image-3.19.0-{18,20,21,25} $ sudo apt-get purge linux-headers-3.19.0-{18,20,21,25} 上面的命令会删除4个内核镜像：3.19.0-18、3.19.0-20、3.19.0-21 和 3.19.0-25。\n如果GRUB配置由于任何原因在删除旧内核后没有正确升级，你可以尝试手动用update-grub2命令来更新配置。\n$ sudo update-grub2 现在就重启来验证GRUB菜单是否已经正确清理了。\n编写第一个内核模块 容器 Namespace 概念 **namespace 是 Linux 内核用来隔离内核资源的方式。**通过 namespace 可以让一些进程只能看到与自己相关的一部分资源，而另外一些进程也只能看到与它们自己相关的资源，这两拨进程根本就感觉不到对方的存在。具体的实现方式是把一个或多个进程的相关资源指定在同一个 namespace 中。\nLinux namespaces 是对全局系统资源的一种封装隔离，使得处于不同 namespace 的进程拥有独立的全局系统资源，改变一个 namespace 中的系统资源只会影响当前 namespace 里的进程，对其他 namespace 中的进程没有影响。\n用途 实际上，Linux 内核实现 namespace 的一个主要目的就是实现轻量级虚拟化(容器)服务。在同一个 namespace 下的进程可以感知彼此的变化，而对外界的进程一无所知。这样就可以让容器中的进程产生错觉，认为自己置身于一个独立的系统中，从而达到隔离的目的。也就是说 linux 内核提供的 namespace 技术为 docker 等容器技术的出现和发展提供了基础条件。\n我们可以从 docker 实现者的角度考虑该如何实现一个资源隔离的容器。比如是不是可以通过 chroot 命令切换根目录的挂载点，从而隔离文件系统。为了在分布式的环境下进行通信和定位，容器必须要有独立的 IP、端口和路由等，这就需要对网络进行隔离。同时容器还需要一个独立的主机名以便在网络中标识自己。接下来还需要进程间的通信、用户权限等的隔离。最后，运行在容器中的应用需要有进程号(PID)，自然也需要与宿主机中的 PID 进行隔离。也就是说这六种隔离能力是实现一个容器的基础，让我们看看 linux 内核的 namespace 特性为我们提供了什么样的隔离能力：\n上表中的前六种 namespace 正是实现容器必须的隔离技术，至于新近提供的 Cgroup namespace 目前还没有被 docker 采用。相信在不久的将来各种容器也会添加对 Cgroup namespace 的支持。\n发展历史 Linux 在很早的版本中就实现了部分的 namespace，比如内核 2.4 就实现了 mount namespace。大多数的 namespace 支持是在内核 2.6 中完成的，比如 IPC、Network、PID、和 UTS。还有个别的 namespace 比较特殊，比如 User，从内核 2.6 就开始实现了，但在内核 3.8 中才宣布完成。同时，随着 Linux 自身的发展以及容器技术持续发展带来的需求，也会有新的 namespace 被支持，比如在内核 4.6 中就添加了 Cgroup namespace。\nLinux 提供了多个 API 用来操作 namespace，它们是 clone()、setns() 和 unshare() 函数，为了确定隔离的到底是哪项 namespace，在使用这些 API 时，通常需要指定一些调用参数：CLONE_NEWIPC、CLONE_NEWNET、CLONE_NEWNS、CLONE_NEWPID、CLONE_NEWUSER、CLONE_NEWUTS 和 CLONE_NEWCGROUP。如果要同时隔离多个 namespace，可以使用 | (按位或)组合这些参数。同时我们还可以通过 /proc 下面的一些文件来操作 namespace。\n查看进程所属的 namespace\n从版本号为 3.8 的内核开始，/proc/[pid]/ns 目录下会包含进程所属的 namespace 信息，使用下面的命令可以查看当前进程所属的 namespace 信息：\n$ ll /proc/$$/ns total 0 lrwxrwxrwx 1 kurome kurome 0 Mar 3 11:33 cgroup -\u0026gt; \u0026#39;cgroup:[4026531835]\u0026#39; lrwxrwxrwx 1 kurome kurome 0 Mar 3 11:33 ipc -\u0026gt; \u0026#39;ipc:[4026531839]\u0026#39; lrwxrwxrwx 1 kurome kurome 0 Mar 3 11:33 mnt -\u0026gt; \u0026#39;mnt:[4026531840]\u0026#39; lrwxrwxrwx 1 kurome kurome 0 Mar 3 11:33 net -\u0026gt; \u0026#39;net:[4026532008]\u0026#39; lrwxrwxrwx 1 kurome kurome 0 Mar 3 11:33 pid -\u0026gt; \u0026#39;pid:[4026531836]\u0026#39; lrwxrwxrwx 1 kurome kurome 0 Mar 3 11:33 pid_for_children -\u0026gt; \u0026#39;pid:[4026531836]\u0026#39; lrwxrwxrwx 1 kurome kurome 0 Mar 3 11:33 time -\u0026gt; \u0026#39;time:[4026531834]\u0026#39; lrwxrwxrwx 1 kurome kurome 0 Mar 3 11:33 time_for_children -\u0026gt; \u0026#39;time:[4026531834]\u0026#39; lrwxrwxrwx 1 kurome kurome 0 Mar 3 11:33 user -\u0026gt; \u0026#39;user:[4026531837]\u0026#39; lrwxrwxrwx 1 kurome kurome 0 Mar 3 11:33 uts -\u0026gt; \u0026#39;uts:[4026531838]\u0026#39; 首先，这些 namespace 文件都是链接文件。链接文件的内容的格式为 xxx:[inode number]。其中的 xxx 为 namespace 的类型，inode number 则用来标识一个 namespace，我们也可以把它理解为 namespace 的 ID。如果两个进程的某个 namespace 文件指向同一个链接文件，说明其相关资源在同一个 namespace 中。\n其次，在 /proc/[pid]/ns 里放置这些链接文件的另外一个作用是，一旦这些链接文件被打开，只要打开的文件描述符(fd)存在，那么就算该 namespace 下的所有进程都已结束，这个 namespace 也会一直存在，后续的进程还可以再加入进来。\n除了打开文件的方式，我们还可以通过文件挂载的方式阻止 namespace 被删除。比如我们可以把当前进程中的 uts 挂载到 ~/uts 文件：\n$ touch ~/uts $ sudo mount --bind /proc/$$/ns/uts ~/uts 使用 stat 命令检查下结果：\n$ stat ~/uts 很神奇吧，~/uts 的 inode 和链接文件中的 inode number 是一样的，它们是同一个文件。\nclone() 函数 我们可以通过 clone() 在创建新进程的同时创建 namespace。clone() 在 C 语言库中的声明如下：\n/* Prototype for the glibc wrapper function */ #define _GNU_SOURCE #include \u0026lt;sched.h\u0026gt;int clone(int (*fn)(void *), void *child_stack, int flags, void *arg); 实际上，clone() 是在 C 语言库中定义的一个封装(wrapper)函数，它负责建立新进程的堆栈并且调用对编程者隐藏的 clone() 系统调用。Clone() 其实是 linux 系统调用 fork() 的一种更通用的实现方式，它可以通过 flags 来控制使用多少功能。一共有 20 多种 CLONE_ 开头的 falg(标志位) 参数用来控制 clone 进程的方方面面(比如是否与父进程共享虚拟内存等)，下面我们只介绍与 namespace 相关的 4 个参数：\n fn：指定一个由新进程执行的函数。当这个函数返回时，子进程终止。该函数返回一个整数，表示子进程的退出代码。 child_stack：传入子进程使用的栈空间，也就是把用户态堆栈指针赋给子进程的 esp 寄存器。调用进程(指调用 clone() 的进程)应该总是为子进程分配新的堆栈。 flags：表示使用哪些 CLONE_ 开头的标志位，与 namespace 相关的有CLONE_NEWIPC、CLONE_NEWNET、CLONE_NEWNS、CLONE_NEWPID、CLONE_NEWUSER、CLONE_NEWUTS 和 CLONE_NEWCGROUP。 arg：指向传递给 fn() 函数的参数。  setns() 函数 通过 setns() 函数可以将当前进程加入到已有的 namespace 中。setns() 在 C 语言库中的声明如下：\n#define _GNU_SOURCE #include \u0026lt;sched.h\u0026gt;int setns(int fd, int nstype); 和 clone() 函数一样，C 语言库中的 setns() 函数也是对 setns() 系统调用的封装：\n fd：表示要加入 namespace 的文件描述符。它是一个指向 /proc/[pid]/ns 目录中文件的文件描述符，可以通过直接打开该目录下的链接文件或者打开一个挂载了该目录下链接文件的文件得到。 nstype：参数 nstype 让调用者可以检查 fd 指向的 namespace 类型是否符合实际要求。若把该参数设置为 0 表示不检查。  前面我们提到：可以通过挂载的方式把 namespace 保留下来。保留 namespace 的目的是为以后把进程加入这个 namespace 做准备。在 docker 中，使用 docker exec 命令在已经运行着的容器中执行新的命令就需要用到 setns() 函数。为了把新加入的 namespace 利用起来，还需要引入 execve() 系列的函数，该函数可以执行用户的命令，比较常见的用法是调用 /bin/bash 并接受参数运行起一个 shell。\nunshare() 函数 通过 unshare 函数可以在原进程上进行 namespace 隔离。也就是创建并加入新的 namespace 。unshare() 在 C 语言库中的声明如下：\n#define _GNU_SOURCE #include \u0026lt;sched.h\u0026gt;int unshare(int flags); 和前面两个函数一样，C 语言库中的 unshare() 函数也是对 unshare() 系统调用的封装。调用 unshare() 的主要作用就是：不启动新的进程就可以起到资源隔离的效果，相当于跳出原先的 namespace 进行操作。\n系统还默认提供了一个叫 unshare 的命令，其实就是在调用 unshare() 系统调用。下面的 demo 使用 unshare 命令把当前进程的 user namespace 设置成了 root：\n$ whoami nick $ unshare --map-root-user --user sh -c whoami root 控制组 简介 说实话，一些未知的软件应用可能需要被控制或限制——至少是为了稳定性或者某种程度上的安全性。很多时候，一个bug或者仅仅只是烂代码就有可能破坏掉整个机器甚至可能削弱整个生态。幸运的是，有一种方式可以控制应用程序，Linux控制组（cgroups）是一个内核功能，用于限制、记录和隔离一个或多个进程对CPU、内存、磁盘I/O 以及网络的访问及使用。\n即，cgroups(Control Groups) 是 linux 内核提供的一种机制，这种机制可以根据需求把一系列系统任务及其子任务整合(或分隔)到按资源划分等级的不同组内，从而为系统资源管理提供一个统一的框架。简单说，cgroups 可以限制、记录任务组所使用的物理资源。本质上来说，cgroups 是内核附加在程序上的一系列钩子(hook)，通过程序运行时对资源的调度触发相应的钩子以达到资源追踪和限制的目的。\n控制组技术最初是由谷歌开发的，最终在2.6.24版本（2008年1月）中并入Linux内核主线。这项技术被部分重新设计，添加了kernfs（用于分割一些sysfs逻辑），这些改变被合并到3.15和3.16版本的内核中。\n实现 cgroups 的主要目的是为不同用户层面的资源管理提供一个统一化的接口。从单个任务的资源控制到操作系统层面的虚拟化（Linux 容器或者LXC），cgroups 提供了四大功能：\n 资源限制：一个控制组可以配置成不能超过指定的内存限制或是不能使用超过一定数量的处理器或限制使用特定的外围设备。 优先级：一个或者多个控制组可以配置成使用更少或者更多的CPU 时间片数量或者磁盘 IO 带宽，实际上就等同于控制了任务运行的优先级。 记录：一个控制组的资源使用情况会被监督以及测量。 控制：进程组可以被冻结，暂停或者重启。  概念 Task(任务) 在 linux 系统中，内核本身的调度和管理并不对进程和线程进行区分，只是根据 clone 时传入的参数的不同来从概念上区分进程和线程。这里使用 task 来表示系统的一个进程或线程。\nCgroup(控制组) cgroups 中的资源控制以 cgroup 为单位实现。Cgroup 表示按某种资源控制标准划分而成的任务组，包含一个或多个子系统。一个任务可以加入某个 cgroup，也可以从某个 cgroup 迁移到另一个 cgroup。\nSubsystem(子系统) cgroups 中的子系统就是一个资源调度控制器(又叫 controllers)。比如 CPU 子系统可以控制 CPU 的时间分配，内存子系统可以限制内存的使用量。内核版本 4.10.0，支持的 subsystem 如下( cat /proc/cgroups)：\n blkio 对块设备的 IO 进行限制。 cpu 限制 CPU 时间片的分配，与 cpuacct 挂载在同一目录。 cpuacct 生成 cgroup 中的任务占用 CPU 资源的报告，与 cpu 挂载在同一目录。 cpuset 给 cgroup 中的任务分配独立的 CPU(多处理器系统) 和内存节点。 devices 允许或禁止 cgroup 中的任务访问设备。 freezer 暂停/恢复 cgroup 中的任务。 hugetlb 限制使用的内存页数量。 memory 对 cgroup 中的任务的可用内存进行限制，并自动生成资源占用报告。 net_cls 使用等级识别符（classid）标记网络数据包，这让 Linux 流量控制器（tc 指令）可以识别来自特定 cgroup 任务的数据包，并进行网络限制。 net_prio 允许基于 cgroup 设置网络流量(netowork traffic)的优先级。 perf_event 允许使用 perf 工具来监控 cgroup。 pids 限制任务的数量。  Hierarchy(层级) 层级有一系列 cgroup 以一个树状结构排列而成，每个层级通过绑定对应的子系统进行资源控制。层级中的 cgroup 节点可以包含零个或多个子节点，子节点继承父节点挂载的子系统。一个操作系统中可以有多个层级。\n接口 （以下为 Ubuntu 20.04，内核 5.13.0-30-generic）\ncgroups 以文件的方式提供应用接口，我们可以通过 mount 命令来查看 cgroups 默认的挂载点：\n$ mount | grep cgroup tmpfs on /sys/fs/cgroup type tmpfs (ro,nosuid,nodev,noexec,mode=755,inode64) cgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,name=systemd) ... cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset) 第一行的 tmpfs 说明 /sys/fs/cgroup 目录下的文件都是存在于内存中的临时文件。\n第二行的挂载点 /sys/fs/cgroup/systemd 用于 systemd 系统对 cgroups 的支持。\n其余的挂载点则是内核支持的各个子系统的根级层级结构。\n需要注意的是，在使用 systemd 系统的操作系统中，/sys/fs/cgroup 目录都是由 systemd 在系统启动的过程中挂载的，并且挂载为只读的类型。换句话说，系统是不建议我们在 /sys/fs/cgroup 目录下创建新的目录并挂载其它子系统的。这一点与之前的操作系统不太一样。\n下面让我们来探索一下 /sys/fs/cgroup 目录及其子目录下都是些什么：\n$ ls /sys/fs/cgroup blkio cpu,cpuacct freezer misc net_prio rdma cpu cpuset hugetlb net_cls perf_event systemd cpuacct devices memory net_cls,net_prio pids unified /sys/fs/cgroup 目录下是各个子系统的根目录。我们以 memory 子系统为例，看看 memory 目录下都有什么？\n$ ls /sys/fs/cgroup/memory cgroup.clone_children memory.memsw.limit_in_bytes cgroup.event_control memory.memsw.max_usage_in_bytes cgroup.procs memory.memsw.usage_in_bytes cgroup.sane_behavior memory.move_charge_at_immigrate memory.failcnt memory.numa_stat memory.force_empty memory.oom_control memory.kmem.failcnt memory.pressure_level memory.kmem.limit_in_bytes memory.soft_limit_in_bytes memory.kmem.max_usage_in_bytes memory.stat memory.kmem.slabinfo memory.swappiness memory.kmem.tcp.failcnt memory.usage_in_bytes memory.kmem.tcp.limit_in_bytes memory.use_hierarchy memory.kmem.tcp.max_usage_in_bytes notify_on_release memory.kmem.tcp.usage_in_bytes release_agent memory.kmem.usage_in_bytes system.slice memory.limit_in_bytes tasks memory.max_usage_in_bytes user.slice memory.memsw.failcnt 这些文件就是 cgroups 的 memory 子系统中的根级设置。比如 memory.limit_in_bytes 中的数字用来限制进程的最大可用内存，memory.swappiness 中保存着使用 swap 的权重等等。\n手动方法 你可以直接或者间接（通过LXC、libvirt或者Docker）访问及管理控制组，这里我首先介绍使用sysfs以及libgroups库。接下来的示例需要你预先安装一个必须的包。\n$ sudo apt-get install libcgroup1 cgroup-tools 我将使用一个简单的shell脚本文件test.sh作为示例应用程序，它将会在无限while循环中运行以下两个命令。\n$ cat test.sh !/bin/shwhile [ 1 ]; do echo \u0026#34;hello world\u0026#34; sleep 60 done 安装必要的包后，你可以直接通过sysfs的目录结构来配置你的控制组，例如，要在内存子系统中创建一个叫做foo的控制组，只需要在/sys/fs/cgroup/memory底下新建一个叫做foo的目录：\n$ sudo mkdir /sys/fs/cgroup/memory/foo 在我们使用 cgroups 时，最好不要直接在各个子系统的根目录下直接修改其配置文件。推荐的方式是为不同的需求在子系统树中定义不同的节点。\ncgroups 的文件系统会在创建文件目录的时候自动创建配置文件：\n$ ls /sys/fs/cgroup/memory/foo cgroup.clone_children memory.memsw.failcnt cgroup.event_control memory.memsw.limit_in_bytes cgroup.procs memory.memsw.max_usage_in_bytes memory.failcnt memory.memsw.usage_in_bytes memory.force_empty memory.move_charge_at_immigrate memory.kmem.failcnt memory.numa_stat memory.kmem.limit_in_bytes memory.oom_control memory.kmem.max_usage_in_bytes memory.pressure_level memory.kmem.slabinfo memory.soft_limit_in_bytes memory.kmem.tcp.failcnt memory.stat memory.kmem.tcp.limit_in_bytes memory.swappiness memory.kmem.tcp.max_usage_in_bytes memory.usage_in_bytes memory.kmem.tcp.usage_in_bytes memory.use_hierarchy memory.kmem.usage_in_bytes notify_on_release memory.limit_in_bytes tasks memory.max_usage_in_bytes 默认情况下，每个新建的控制组将会继承对系统整个内存池的访问权限。但对于某些应用程序，这些程序拒绝释放已分配的内存并继续分配更多内存，这种默认继承方式显然不是个好主意。要使程序的内存限制变得更为合理，你需要更新文件memory.limit_in_bytes。\n限制控制组foo下运行的任何应用的内存上限为50MB：\n$ echo 50000000 | sudo tee /sys/fs/cgroup/memory/foo/memory.limit_in_bytes 验证设置：\n$ sudo cat memory.limit_in_bytes 49999872 请注意，回读的值始终是内核页面大小的倍数（即4096字节或4KB）。这个值是内存的最小可分配大小。\n启动应用程序test.sh：\n$ sh ~/test.sh 使用进程ID（PID），将应用程序移动到内存控制器底下的控制组foo：\n$ echo 2152 | sudo tee /sys/fs/cgroup/memory/foo/cgroup.procs 使用相同的PID，列出正在运行的进程并验证它是否在正确的控制组下运行：\n$ ps -o cgroup 2152 CGROUP 5:devices:/user.slice,4:pids:/user.slice/user-1000.slice/user@1000.service,3:m... 或者通过 /proc/[pid]/cgroup 来查看指定进程属于哪些 cgroup：\n$ cat /proc/2152/cgroup 13:cpuset:/ 12:blkio:/ 11:misc:/ 10:rdma:/ 9:freezer:/ 8:cpu,cpuacct:/ 7:perf_event:/ 6:hugetlb:/ 5:devices:/user.slice 4:pids:/user.slice/user-1000.slice/user@1000.service 3:memory:/foo #here 2:net_cls,net_prio:/ 1:name=systemd:/user.slice/user-1000.slice/user@1000.service/gnome\\x2dsession\\x2dmanager.slice/gnome-session-manager@ubuntu.service 0::/user.slice/user-1000.slice/user@1000.service/gnome\\x2dsession\\x2dmanager.slice/gnome-session-manager@ubuntu.service 每一行包含用冒号隔开的三列，他们的含义分别是：\n cgroup 树的 ID， 和 /proc/cgroups 文件中的 ID 一一对应。 和 cgroup 树绑定的所有 subsystem，多个 subsystem 之间用逗号隔开。这里 name=systemd 表示没有和任何 subsystem 绑定，只是给他起了个名字叫 systemd。 进程在 cgroup 树中的路径，即进程所属的 cgroup，这个路径是相对于挂载点的相对路径。  你还可以通过读取文件来监控控制组正在使用的资源。在这种情况下，你可以查看你的进程（以及生成的子进程）被分配的内存大小。\n$ cat /sys/fs/cgroup/memory/foo/memory.usage_in_bytes 188416 当进程“迷路”时 现在让我们重新创建相同的场景，但这次我们将控制组foo的内存限制从50MB改为500 bytes：\n$ echo 500 | sudo tee /sys/fs/cgroup/memory/foo/memory.limit_in_bytes 注意：如果任务超出其定义的限制，内核将进行干预，并在某些情况下终止该任务。\n同样，当您重新读取值时，它将始终是内核页面大小的倍数。因此，虽然您将其设置为500字节，但它实际上被设置为4 KB：\n$ cat /sys/fs/cgroup/memory/foo/memory.limit_in_bytes 4096 启动应用程序test.sh，将其移动到控制组下并监视系统日志：\n$ sudo tail -f /var/log/messages ... 请注意，内核的Out-Of-Mempry Killer（也叫做oom-killer 内存不足杀手）在应用程序达到4KB限制时就会介入。它会杀死应用程序，应用程序将不再运行，你可以通过输入以下命令进行验证：\n$ ps -o cgroup 2152 使用libcgroup 之前描述的许多早期步骤都可以通过libcgroup包中提供的管理工具进行简化。例如，使用cgcreate二进制文件的单个命令即可创建sysfs条目和文件。\n输入以下命令即可在内存子系统下创建一个叫做foo的控制组：\n$ sudo cgcreate -g memory:foo 注意：libcgroup提供了一种管理控制组中任务的机制。\n使用与之前相同的方法，你就可以开始设置内存阈值：\n$ echo 50000000 | sudo tee /sys/fs/cgroup/memory/foo/memory.limit_in_bytes 验证新配置的设置：\n$ sudo cat memory.limit_in_bytes 50003968 使用cgexec二进制文件在控制组foo中运行应用程序：\n$ sudo cgexec -g memory:foo ~/test.sh 使用它的进程ID - PID来验证应用程序是否在控制组和子系统（内存）下运行：\n$ ps -o cgroup 2945 CGROUP 6:memory:/foo,1:name=systemd:/user.slice/user-0.slice/session-1.scope 如果您的应用程序不再运行，并且您想要清理并删除控制组，则可以使用二进制文件cgdelete来执行此操作。要从内存控制器下删除控制组foo，请输入：\n$ sudo cgdelete memory:foo 持久组 您也可以通过一个简单的配置文件和服务的启动来完成上述所有操作。您可以在/etc/cgconfig.conf文件中定义所有控制组名称和属性。以下为foo组添加了一些属性：\n$ cat /etc/cgconfig.conf group foo { cpu { cpu.shares = 100; } memory { memory.limit_in_bytes = 5000000; } } cpu.shares选项定义了该组的CPU优先级。默认情况下，所有组都继承1024 shares（CPU share指的是控制组中的任务被分配到的CPU的 time的优先级，即值越大，分配到的CPU time越多，这个值需大于等于2），即100%的CPU time（CPU time是CPU用于处理一个程序所花费的时间）。通过将cpu.shares的值降低到更保守的值（如100），这个组将会被限制只能使用大概10%的CPU time。\n就如之前讨论的，在控制组中运行的进程也可以被限制它能访问的CPUs（内核）的数量。将以下部分添加到同一个配置文件cgconfig.conf中组名底下。\ncpuset { cpuset.cpus=\u0026quot;0-5\u0026quot;; } 有了这个限制，这个控制组会将应用程序绑定到到0核到5核——也就是说，它只能访问系统上的前6个CPU核。\n接下来，您需要使用cgconfig服务加载此配置。首先，启用cgconfig以在系统启动时能够加载上述配置：\n$ sudo systemctl enable cgconfig Create symlink from /etc/systemd/system/sysinit.target.wants/cgconfig.service to /usr/lib/systemd/system/cgconfig.service. 现在，启动cgconfig服务并手动加载相同的配置文件（或者您可以跳过此步骤直接重启系统）：\n$ sudo systemctl start cgconfig 在控制组foo下启动该应用程序并将其绑定到您设置的内存和CPU限制：\n$ sudo cgexec -g memory,cpu,cpuset:foo ~/test.sh \u0026amp; 除了将应用程序启动到预定义的控制组之外，其余所有内容都将在系统重新启动后持续存在。但是，您可以通过定义依赖于cgconfig服务的启动初始脚本来启动该应用程序，自动执行该过程。\n总结 通常来说，限制一个机器上一个或者多个任务的权限是必要的。控制组提供了这项功能，通过使用它，您可以对一些特别重要或无法控制的应用程序实施严格的硬件和软件限制。如果一个应用程序没有设置上限阈值或限制它可以在系统上消耗的内存量，cgroups可以解决这个问题。如果另一个应用程序没有CPU上的限制，那么cgroups可以再一次解决您的问题。您可以通过cgroup完成这么多工作，只需花一点时间，您就可以使用你的操作系统环境恢复稳定性，安全性和健全性。\n使用 Systemd 当 Linux 的 init 系统发展到 systemd 之后，systemd 与 cgroups 发生了融合(或者说 systemd 提供了 cgroups 的使用和管理接口)。\nSystemd 依赖 cgroups\n要理解 systemd 与 cgroups 的关系，我们需要先区分 cgroups 的两个方面：层级结构(A)和资源控制(B)。首先 cgroups 是以层级结构组织并标识进程的一种方式，同时它也是在该层级结构上执行资源限制的一种方式。我们简单的把 cgroups 的层级结构称为 A，把 cgrpups 的资源控制能力称为 B。\n对于 systemd 来说，A 是必须的，如果没有 A，systemd 将不能很好的工作。而 B 则是可选的，如果你不需要对资源进行控制，那么在编译 Linux 内核时完全可以去掉 B 相关的编译选项。\nSystemd 默认挂载的 cgroups 系统\n在系统的开机阶段，systemd 会把支持的 controllers (subsystem 子系统)挂载到默认的 /sys/fs/cgroup/ 目录下面，除了 systemd 目录外，其它目录都是对应的 subsystem。\n/sys/fs/cgroup/systemd 目录是 systemd 维护的自己使用的非 subsystem 的 cgroups 层级结构。换句话说就是，并不允许其它的程序动这个目录下的内容。其实 /sys/fs/cgroup/systemd 目录对应的 cgroups 层级结构就是 systemd 用来使用 cgoups 中 feature A 的。\nCgroup 的默认层级\n过将 cgroup 层级系统与 systemd unit 树绑定，systemd 可以把资源管理的设置从进程级别移至应用程序级别。因此，我们可以使用 systemctl 指令，或者通过修改 systemd unit 的配置文件来管理 unit 相关的资源。\n默认情况下，systemd 会自动创建 slice、scope 和 service unit 的层级来为 cgroup 树提供统一的层级结构。\n系统中运行的所有进程，都是 systemd init 进程的子进程。在资源管控方面，systemd 提供了三种 unit 类型：\n service： 一个或一组进程，由 systemd 依据 unit 配置文件启动。service 对指定进程进行封装，这样进程可以作为一个整体被启动或终止。 scope：一组外部创建的进程。由进程通过 fork() 函数启动和终止、之后被 systemd 在运行时注册的进程，scope 会将其封装。例如：用户会话、 容器和虚拟机被认为是 scope。 slice： 一组按层级排列的 unit。slice 并不包含进程，但会组建一个层级，并将 scope 和 service 都放置其中。真正的进程包含在 scope 或 service 中。在这一被划分层级的树中，每一个 slice 单位的名字对应通向层级中一个位置的路径。  以通过 systemd-cgls 命令来查看 cgroups 的层级结构\nControl group /: -.slice ├─419 bpfilter_umh ├─user.slice │ ├─user-125.slice │ │ ├─session-c1.scope │ │ │ ├─1101 gdm-session-worker [pam/gdm-launch-environment] │ │ │ ├─1158 /usr/lib/gdm3/gdm-x-session dbus-run-session -- gnome-session -\u0026gt; │ │ │ ├─1160 /usr/lib/xorg/Xorg vt1 -displayfd 3 -auth /run/user/125/gdm/Xau\u0026gt; │ │ │ ├─1347 dbus-run-session -- gnome-session --autostart /usr/share/gdm/gr\u0026gt; │ │ │ ├─1348 dbus-daemon --nofork --print-address 4 --session │ │ │ ├─1349 /usr/libexec/gnome-session-binary --systemd --autostart /usr/sh\u0026gt; │ │ │ ├─1352 /usr/libexec/at-spi-bus-launcher │ │ │ ├─1357 /usr/bin/dbus-daemon --config-file=/usr/share/defaults/at-spi2/\u0026gt; │ │ │ ├─1378 /usr/bin/gnome-shell │ │ │ ├─1432 ibus-daemon --panel disable --xim │ │ │ ├─1435 /usr/libexec/ibus-dconf │ │ │ ├─1438 /usr/libexec/ibus-x11 --kill-daemon │ │ │ ├─1440 /usr/libexec/ibus-portal │ │ │ ├─1451 /usr/libexec/at-spi2-registryd --use-gnome-session service、scope 和 slice unit 被直接映射到 cgroup 树中的对象。当这些 unit 被激活时，它们会直接一一映射到由 unit 名建立的 cgroup 路径中。例如，cron.service 属于 system.slice，会直接映射到 cgroup system.slice/cron.service/ 中。 注意，所有的用户会话、虚拟机和容器进程会被自动放置在一个单独的 scope 单元中。\n默认情况下，系统会创建四种 slice：\n -.slice：根 slice system.slice：所有系统 service 的默认位置 user.slice：所有用户会话的默认位置 machine.slice：所有虚拟机和 Linux 容器的默认位置  创建临时的 cgroup\n对资源管理的设置可以是 transient(临时的)，也可以是 persistent (永久的)。我们先来介绍如何创建临时的 cgroup。\n需要使用 systemd-run 命令创建临时的 cgroup，它可以创建并启动临时的 service 或 scope unit，并在此 unit 中运行程序。systemd-run 命令默认创建 service 类型的 unit，比如我们创建名称为 toptest 的 service 运行 top 命令：\n$ sudo systemd-run --unit=toptest --slice=test top -b 然后查看一下 test.slice 的状态：\n$ sudo systemctl status test.slice 创建了一个 test.slice/toptest.service cgroup 层级关系。再看看 toptest.service 的状态：\n$ sudo systemctl status toptest.service top 命令被包装成一个 service 运行在后台了！\n接下来我们就可以通过 systemctl 命令来限制 toptest.service 的资源了。在限制前让我们先来看一看 top 进程的 cgroup 信息：\n$ cat /proc/2850/cgroup 比如我们限制 toptest.service 的 CPUShares 为 600，可用内存的上限为 550M：\n$ sudo systemctl set-property toptest.service CPUShares=600 MemoryLimit=500M 再次检查 top 进程的 cgroup 信息：\n$ cat /proc/2850/cgroup 在 CPU 和 memory 子系统中都出现了 toptest.service 的名字。同时去查看 /sys/fs/cgroup/memory/test.slice 和 /sys/fs/cgroup/cpu/test.slice 目录，这两个目录下都多出了一个 toptest.service 目录。我们设置的 CPUShares=600 MemoryLimit=500M 被分别写入了这些目录下的对应文件中。\n临时 cgroup 的特征是，所包含的进程一旦结束，临时 cgroup 就会被自动释放。比如我们 kill 掉 top 进程，然后再查看 /sys/fs/cgroup/memory/test.slice 和 /sys/fs/cgroup/cpu/test.slice 目录，刚才的 toptest.service 目录已经不见了。\n通过配置文件修改 cgroup\n所有被 systemd 监管的 persistent cgroup(持久的 cgroup)都在 /usr/lib/systemd/system/ 目录中有一个 unit 配置文件。比如我们常见的 service 类型 unit 的配置文件。我们可以通过设置 unit 配置文件来控制应用程序的资源，persistent cgroup 的特点是即便系统重启，相关配置也会被保留。需要注意的是，scope unit 不能以此方式创建。下面让我们为 cron.service 添加 CPU 和内存相关的一些限制，编辑 /lib/systemd/system/cron.service 文件：\n$ sudo vim /lib/systemd/system/cron.service [Service] CPUShares=600 MemoryLimit=500M EnviromentFile=-/etc/default/cron ExecStart=/usr/sbin/cron -f $EXTRA_OPTS IgnoreSIGPIPE=false KillMode=process 然后重新加载配置文件并重启 cron.service：\n$ sudo systemctl daemon-reload $ sudo systemctl restart cron.service 现在去查看 /sys/fs/cgroup/memory/system.slice/cron.service/memory.limit_in_bytes 和 /sys/fs/cgroup/cpu/system.slice/cron.service/cpu.shares 文件，是不是已经包含我们配置的内容了！\n通过 systemctl 命令修改 cgroup\n除了编辑 unit 的配置文件，还可以通过 systemctl set-property 命令来修改 cgroup，这种方式修该的配置也会在重启系统时保存下来。现在我们把 cron.service 的 CPUShares 改为 700：\n$ sudo systemctl set-property cron.service CPUShares=700 查看 /sys/fs/cgroup/cpu/system.slice/cron.service/cpu.shares 文件的内容应该是 700，重启系统后该文件的内容还是 700。\nSystemd-cgtop 命令\n类似于 top 命令，systemd-cgtop 命令显示 cgoups 的实时资源消耗情况。\n通过它我们就可以分析应用使用资源的情况。\nLXC LXC（Linux容器，Linux Container）相当于你运行了一个接近于裸机的虚拟机。这项技术始于2008年，LXC的大部分功能来自于Solaris容器（又叫做Solaries Zones）以及之前的FreeBSD jails技术。 LXC并不是创建一个成熟的虚拟机，而是创建了一个拥有自己进程程和网络空间的虚拟环境，使用命名空间来强制进程隔离并利用内核的控制组（cgroups）功能，该功能可以限制，计算和隔离一个或多个进程的CPU，内存，磁盘I / O和网络使用情况。 您可以将这种用户空间框架想像成是chroot的高级形式。\n chroot 是一个改变当前运行进程以及其子进程的根目录的操作。一个运行在这种环境的程序无法访问根目录外的文件和命令。\n 注意：LXC使用命名空间来强制进程隔离，同时利用内核的控制组来计算以及限制一个或多个进程的CPU，内存，磁盘I / O和网络使用。\n但容器究竟是什么？简短的答案是容器将软件应用程序与操作系统分离，为用户提供干净且最小的Linux环境，与此同时在一个或多个隔离的“容器”中运行其他所有内容。容器的目的是启动一组有限数量的应用程序或服务（通常称为微服务），并使它们在独立的沙盒环境中运行。\n这种隔离可防止在给定容器内运行的进程监视或影响在另一个容器中运行的进程。此外，这些集装箱化服务不会影响或干扰主机。能够将分散在多个物理服务器上的许多服务合并为一个的想法是数据中心选择采用该技术的众多原因之一。\n容器有以下几个特点：\n 安全性：容器里可以运行网络服务，这可以限制安全漏洞或违规行为造成的损害。那些成功利用那个容器的一个或多个应用的安全漏洞的入侵者将会被限制在只能在那个容器中做一些操作。 隔离性：容器允许在同一物理机器上部署一个或多个应用程序，即使这些应用程序必须在不同的域下运行，每个域都需要独占访问其各自的资源。例如，通过将每个容器关联的不同IP地址，在不同容器中运行的多个应用程序可以绑定到同一物理网络接口。 虚拟化和透明性：容器为系统提供虚拟化环境，这个环境可以隐藏或限制系统底层的物理设备或系统配置的可见性。容器背后的一般原则是避免更改运行应用程序的环境，但解决安全性或隔离问题除外。  使用LXC的工具 对于大多数现代Linux发行版，内核都启用了控制组，但您很可能仍需要安装LXC工具。\n对于Ubuntu或Debian，只需键入：\n$ sudo apt-get install lxc 现在，在开始使用这些工具之前，您需要配置您的环境。在此之前，您需要验证当前用户是否同时在/etc/subuid和/etc/subgid中定义了uid和gid：\n$ cat /etc/subuid petros:100000:65536 $ cat /etc/subgid petros:100000:65536 如果~/.config/lxc不存在，则创建该目录，并且把配置文件/etc/lxc/default.conf复制到~/.config/lxc/default.conf.，将以下两行添加到文件末尾：\nlxc.id_map = u 0 100000 65536 lxc.id_map = g 0 100000 65536 结果如下：\n$ cat ~/.config/lxc/default.conf lxc.network.type = veth lxc.network.link = lxcbr0 lxc.network.flags = up lxc.network.hwaddr = 00:16:3e:xx:xx:xx lxc.id_map = u 0 100000 65536 lxc.id_map = g 0 100000 65536 将以下命令添加到/etc/lxc/lxc-usernet文件末尾（把第一列换成你的username）：\npetros veth lxcbr0 10 最快使这些配置生效的方法是重启或者将用户登出再登入。\n重新登录后，请验证当前是否已加载veth网络驱动程序：\n$ lsmod | grep veth veth 16384 0 如果没有，请输入：\n$ sudo modprobe veth 现在您可以使用LXC工具集来下载，运行，管理Linux容器。\n接下来，下载容器镜像并将其命名为“example-container”。当您键入以下命令时，您将看到一长串许多Linux发行版和版本支持的容器：\n$ sudo lxc-create -t download -n example-container 将会有三个弹出框让您分别选择发行版名称（distribution），版本号（release）以及架构（architecture）。请选择以下三个选项：\nDistribution: ubuntu Release: xenial Architecture: amd64 选择后点击Enter，rootfs将在本地下载并配置。出于安全原因，每个容器不附带OpenSSH服务器或用户帐户。同时也不会提供默认的root密码。要更改root密码并登录，必须在容器目录路径中运行lxc-attach或chroot（在启动之后）。\n启动容器：\n$ sudo lxc-start -n example-container -d -d选项表示隐藏容器，它会在后台运行。如果您想要观察boot的过程，只需要将-d换成-F。那么它将在前台运行，登录框出现时结束。\n你可能会遇到如下错误：\n$ sudo lxc-start -n example-container -d lxc-start: tools/lxc_start.c: main: 366 The container failed to start. lxc-start: tools/lxc_start.c: main: 368 To get more details, run the container in foreground mode. lxc-start: tools/lxc_start.c: main: 370 Additional information can be obtained by setting the --logfile and --logpriority options. 如果你遇到了，您需要通过在前台运行lxc-start服务来调试它：\n$ sudo lxc-start -n example-container -F lxc-start: conf.c: instantiate_veth: 2685 failed to create veth pair (vethQ4NS0B and vethJMHON2): Operation not supported lxc-start: conf.c: lxc_create_network: 3029 failed to create netdev lxc-start: start.c: lxc_spawn: 1103 Failed to create the network. lxc-start: start.c: __lxc_start: 1358 Failed to spawn container \u0026#34;example-container\u0026#34;. lxc-start: tools/lxc_start.c: main: 366 The container failed to start. lxc-start: tools/lxc_start.c: main: 370 Additional information can be obtained by setting the --logfile and --logpriority options. 从以上示例，你可以看到模块veth没有被引入，在引入之后，将会解决这个问题。\n之后，打开第二个terminal窗口，验证容器的状态。\n$ sudo lxc-info -n example-container Name: example-container State: RUNNING PID: 1356 IP: 10.0.3.28 CPU use: 0.29 seconds BlkIO use: 16.80 MiB Memory use: 29.02 MiB KMem use: 0 bytes Link: vethPRK7YU TX bytes: 1.34 KiB RX bytes: 2.09 KiB Total bytes: 3.43 KiB 也可以通过另一种方式来查看所有安装的容器，运行命令：\n$ sudo lxc-ls -f NAME STATE AUTOSTART GROUPS IPV4 IPV6 example-container RUNNING 0 - 10.0.3.28 - 但是问题是你仍然不能登录进去，你只需要直接attach到正在运行的容器，创建你的用户，使用passwd命令改变相关的密码。\n$ sudo lxc-attach -n example-container root@example-container:/# root@example-container:/# useradd petros root@example-container:/# passwd petros Enter new UNIX password: Retype new UNIX password: passwd: password updated successfully 更改密码后，您将能够从控制台直接登录到容器，而无需使用lxc-attach命令：\n$ sudo lxc-console -n example-container 如果要通过网络连接到此运行容器，请安装OpenSSH服务器：\n# apt-get install openssh-server 抓取容器的本地IP地址：\n# ip addr show eth0|grep inet inet 10.0.3.25/24 brd 10.0.3.255 scope global eth0 inet6 fe80::216:3eff:fed8:53b4/64 scope link 然后在主机的新的控制台窗口中键入：\n$ ssh 10.0.3.25 瞧！您现在可以SSH到正在运行的容器并键入您的用户名和密码。\n在主机系统上，而不是在容器内，可以观察在启动容器后启动和运行的LXC进程：\n$ ps aux | grep lxc | grep -v grep ... 要停止容器，请键入（在主机）：\n$ sudo lxc-stop -n example-container 停止后，验证容器的状态：\n$ sudo lxc-ls -f NAME STATE AUTOSTART GROUPS IPV4 IPV6 example-container STOPPED 0 - - - $ sudo lxc-info -n example-container Name: example-container State: STOPPED 要彻底销毁容器 - 即从主机system—type清除它：\n$ sudo lxc-destroy -n example-container Destroyed container example-container 销毁后，可以验证是否已将其删除：\n$ sudo lxc-info -n example-container example-container doesn\u0026#39;t exist $ sudo lxc-ls -f 注意：如果您尝试销毁正在运行的容器，该命令将失败并告知您容器仍在运行：\n$ sudo lxc-destroy -n example-container example-container is running 在销毁容器前必须先停止它。\n高级配置 有时，可能需要配置一个或多个容器来完成一个或多个任务。 LXC通过让管理员修改位于/var/lib/lxc中的容器配置文件来简化这一过程：\n$ sudo su # cd /var/lib/lxc # ls example-container 容器的父目录将包含至少两个文件：1）容器配置文件和 2）容器的整个rootfs：\n# cd example-container/ # ls config rootfs 假设您想要在主机系统启动时自动启动名称为example-container的容器。那么您需要将以下行添加到容器的配置文件/var/lib/lxc/example-container/config的尾部：\n# Enable autostart lxc.start.auto = 1 重新启动容器或重新启动主机系统后，您应该看到如下内容：\n$ sudo lxc-ls -f NAME STATE AUTOSTART GROUPS IPV4 IPV6 example-container RUNNING 1 - 10.0.3.25 - 注意 AUTOSTART 字段现在被设置为“1”。\n如果在容器启动时，您希望容器绑定装载主机上的目录路径，请将以下行添加到同一文件的尾部：\n# 将挂载系统路径绑定到本地路径 lxc.mount.entry = /mnt mnt none bind 0 0 通过上面的示例，当容器重新启动时，您将看到容器本地的 / mnt目录可访问的主机/ mnt目录的内容。\n特权与非特权容器 您经常会发现在与LXC相关的内容中讨论特权容器和非特权容器的概念。但它们究竟是什么呢？这个概念非常简单，并且LXC容器可以在任一配置下运行。\n根据设计，无特权容器被认为比特权容器更安全，更保密。无特权容器运行时，容器的root UID映射到主机系统上的非root UID。这使得攻击者即使破解了容器，也难以获得对底层主机的root权限。简而言之，如果攻击者设法通过已知的软件漏洞破坏了您的容器，他们会立即发现自己无法获取任何主机权限。\n特权容器可能使系统暴露于此类攻击。这就是为什么我们最好在特权模式下运行尽量少的容器。确定需要特权访问的容器，并确保付出额外的努力来定期更新并以其他方式锁定它们。\n然而，Docker又是什么呢？ 我花了相当多的时间谈论Linux容器，但是Docker呢？它是生产中部署最多的容器解决方案。自首次推出以来，Docker已经风靡Linux计算世界。 Docker是一种Apache许可的开源容器化技术，旨在自动化在容器内创建和部署微服务这类重复性任务。 Docker将容器视为非常轻量级和模块化的虚拟机。最初，Docker是在LXC之上构建的，但它已经远离了这种依赖，从而带来了更好的开发人员和用户体验。与LXC非常相似，Docker继续使用内核cgroup子系统。该技术不仅仅是运行容器，还简化了创建容器，构建映像，共享构建的映像以及对其进行版本控制的过程。\nDocker主要关注于：\n 可移植性：Docker提供基于镜像的部署模型。这种类型的可移植性允许更简单的方式在多个环境中共享应用程序或服务集合（以及它们的所有依赖）。 版本控制：单个Docker镜像由一系列组合层组成。每当镜像被更改时，都会创建一个新层。例如，每次用户指定命令（例如运行或复制）时，都会创建一个新层。 Docker将重用这些层用于新的容器构建。分层到Docker是它自己的版本控制方法。 回滚：再次，每个Docker镜像都有很多层。如果您不想使用当前运行的层，则可以回滚到以前的版本。这种敏捷性使软件开发人员可以更轻松地持续集成和部署他们的软件技术。 快速部署：配置新硬件通常需要数天时间。并且，安装和配置它的工作量和开销是非常繁重的。使用Docker，您可以在几秒钟将镜像启动并运行，相比于之前，节省了大量的时间。当你使用完一个容器时，你可以轻松地销毁它。  从本质上说，Docker和LXC都非常相似。它们都是用户空间和轻量级虚拟化平台，它们利用cgroup和命名空间来管理资源隔离。但是，两者之间也存在许多明显的差异。\n进程管理 Docker将容器限制为单个进程运行。如果您的应用程序包含X个并发进程，Docker将要求您运行X个容器，每个容器都有自己单独的进程。 LXC不是这样，LXC运行具有传统init进程的容器，反过来，可以在同一容器内托管多个进程。例如，如果要托管LAMP（Linux + Apache + MySQL + PHP）服务器，每个应用程序的每个进程都需要跨越多个Docker容器。\n状态管理 Docker被设计为无状态，意味着它不支持持久存储。有很多方法可以解决这个问题，但同样，只有在进程需要时才需要它。创建Docker镜像时，它将包含只读层。这不会改变。在运行时，如果容器的进程对其内部状态进行任何更改，则将保持内部状态和镜像的当前状态之间的差异，直到对Docker镜像进行提交（创建新层）或直到容器被删除，差异也会消失。\n可移植性 在讨论Docker时，这个词往往被过度使用——因为它是Docker相对于LXC的最重要的优势。 Docker从应用程序中抽象出网络，存储和操作系统细节方面做得更好。这样就形成了一个真正独立于配置的应用程序，保证应用程序的环境始终保持不变，无论启用它的机器配置环境如何。\nDocker旨在使开发人员和系统管理员都受益。它已成为许多DevOps（开发人员+维护人员）工具链中不可或缺的一部分。开发人员可以专注于编写代码，而无需担心最终托管它的系统是什么。使用Docker，无需安装和配置复杂数据库，也无需担心在不兼容的语言工具链版本之间切换。 Docker为维护人员提供了更多的灵活性，通常可以减少托管一些较小和更基本的应用程序所需的物理系统数量。 Docker简化了软件交付。新功能和错误/安全修复程序可以快速到达客户，无需任何麻烦，意外或停机。\n总结 为了基础设施安全性和系统稳定性而隔离进程并不像听起来那么痛苦。 Linux内核提供了所有必要的工具，使简单易用的用户空间应用程序【如LXC（甚至Docker）】能够在隔离的沙盒环境中管理操作系统的微实例及其本地服务。\n沙箱 在计算机安全领域，沙箱(Sandbox)是一种程序的隔离运行机制，其目的是限制不可信进程的权限。沙箱技术经常被用于执行未经测试的或不可信的客户程序。为了避免不可信程序可能破坏其它程序的运行，沙箱技术通过为不可信客户程序提供虚拟化的磁盘、内存以及网络资源，而这种虚拟化手段对客户程序来说是透明的。由于沙箱里的资源被虚拟化（或被间接化），所以沙箱里的不可信程序的恶意行为往往会被限制在沙箱中。\n沙箱技术一直是系统安全领域的挑战，不存在说哪一种方案是足够安全的。沙箱技术方案通常是需要结合多种系统安全技术来实现，采用防御纵深(Defence in Depth)的设计原则，筑建多道防御屏障，尽可能地将安全风险将为最低。下面我们主要讨论如何利用Linux kernel所提供的安全功能来建立有效的沙箱技术。\n在讨论之前，我们简单回顾一下Linux安全模型相关的内容（假设读者已经非常熟悉）：\n(1) 每个进程都有自己的地址空间；\n(2) MMU硬件机制来保证地址空间的隔离；\n(3) Kernel是系统的TCB(Trusted Computing Base)，是安全策略的制定者和执行者；\n(4) 进程是最小的权限边界；\n(5) root具有最高权限，它能控制一切；\n(6) 其它用户受DAC(Discretionary Access Control)限制，如文件系统的UGO权限控制。\n进程是最小的权限边界，其根本原因是MMU能保证进程地址空间的隔离。\nLinux Kernel还提供了与进程降权(drop privilege)相关的一些功能：\n setuid POSIX.1e capability chroot jail Quota control (eg, cgroup, namespace) Linux Container Linux Security Module (LSM)  下面我们会介绍如何在实践中利用这些诀窍来构建一个有效的sandbox.\n权限 ugo Linux 系统中文件的 ugo 权限是 Linux 进行权限管理的基本方式。\n所有者和组 Linux 文件的 ugo 权限把对文件的访问者划分为三个类别：文件的所有者、组和其他人。所谓的 ugo 就是指 user(也称为 owner)、group 和 other 三个单词的首字母组合。\n用户和组的信息分别记录在 /etc/passwd、/etc/group 文件中，这两个文件的内容是任何人都有权查看的，可以直接以读取文本文件的方式查看其内容，其中的每一行代表一个用户。\n文件的所有者\n文件的所有者一般是创建该文件的用户，对该文件具有完全的权限。在一台允许多个用户访问的 Linux 主机上，可以通过文件的所有者来区分一个文件属于某个用户。当然，一个用户也无权查看或更改其它用户的文件。\n文件所属的组\n假如有几个用户合作开发同一个项目，如果每个用户只能查看和修改自己创建的文件就太不方便了，也就谈不上什么合作了。所以需要一个机制允许一个用户查看和修改其它用户的文件，此时就用到组的概念的。我们可以创建一个组，然后把需要合作的用户都添加都这个组中。在设置文件的访问权限时，允许这个组中的用户对该文件进行读取和修改。\n其他人\n如果我想把一个文件共享给系统中的所有用户该怎么办？通过组的方式显然是不合适的，因为需要把系统中的所有用户都添加到一个组中。并且系统中添加了新用户该怎么办，每添加一个新用户就把他添加到这个组中吗？这个问题可以通过其他人的概念解决。在设置文件的访问权限时，允许其他人户对该文件进行读取和修改。\n文件属性 使用 ll 命令可以查看文件的属性信息：\n$ ll Desktop drwxr-xr-x 2 nick nick 4.0K Mar 2 15:06 Desktop  drwxr-xr-x 指明文件的类型和 ugo 权限信息。 2 是对文件的引用计数。 nick 是文件的所有者，文件的所有者一般是创建该文件的用户，对该文件具有完全的权限。 nick 是文件所属的组，我们通过 adduser 命令创建用户时一般会创建一个同名的组，该用户就属于与他同名的组(比如笔者机器上的用户 nick 就属于 nick 组)。当我们创建文件和目录时，其默认所属的组就是所有者所在的组。  其它的信息我们暂时忽略。\n文件类型\ndrwxr-xr-x 的第一个字符描述文件的类型，常见的类型有如下几种：\n d 表示目录 - 表示普通文件 l 表示链接文件 b 表示块设备文件 c 表示字符设备文件 s 表示 socket 文件  ugo 权限信息\n10 个字符，除去第一个表示文件类型的字符，其它 9 个字符表示文件的 ugo 权限信息\n这 9 个字符以三个为一组，都是 rwx 或 - 的组合。其中，r 代表可读(read)、 w 代表可写(write)、 x 代表可执行(execute)。 这三个权限的位置不会改变，如果没有对应的权限，就会以 -(减号)代替。\n*第一组为文件所有者的权限，第二组为文件所属组的权限，第三组为其他人的权限。*其表示的具体含义为：文件所有者具有对文件的读写权限，文件所属组的用户具有对文件读写的权限，而其他人只有读取文件的权限。\n下面详细的解释一下文件读写执行的权限：\n r (read)：可以读取文件的实际内容，比如读取文本文件内的文字等。 w (write)：可以编辑、增加、删除文件的内容(但不含删除该文件)。 x (execute)：该文件具有可以被系统执行的权限。  可以看出，对于文件来说，rwx 主要针对的是文件的内容。\n对目录而言，目录中存储的主要是目录下文件名称的列表，这与普通文件是有些不同的：\n r (read contents in directory) 表示具有读取目录下文件名称的权限，也就是说你可以通过 ls 命令把目录下的文件列表查询出来。 w (modify contents of directory) 具有 w 权限表明你可以在该目录下执行如下的操作：  创建新的文件和目录 删除已经存在的文件与目录(不论该文件的权限为何!) 重命名已存在的文件或目录 移动该目录内文件、目录的位置   x (access directory) 目录虽然不能被执行，但是却具有可以执行的权限。目录的 x 权限表示用户是否可以进入该目标并成为当前的工作目录。注意，如果用户对目录没有 x 权限，则无法查看该目录下的文件的内容(注意与 r 权限的区别)。  综上，如果要允许目录被其他人浏览时，至少要给予 r 和 x 的权限。\n改变权限 在新建文件时会根据创建者的身份和其它的一些设置为文件生成默认的权限。\n接下来我们介绍如何通过命令修改文件权限相关的信息。\n改变文件所有者\n通过 chown 命令可以改变文件的所有者：\n$ sudo chown tester testfile 改变文件所属的组\n通过 chgrp 命令可以改变文件所属的组：\n$ sudo chgrp tester testfile 改变文件的权限\n通过 chmod 命令可以改变文件的权限。对于文件的 rwx 权限，有两种表示方法，数字表示法和字符表示法。\n以数字表示权限的方式如下：\n r: 4 w: 2 x: 1  如果是 rwx 权限就是 4 + 2 + 1 = 7 ，r-x 就是 4 + 1 = 5 ，\u0026mdash; 则为 0。所以 rw-rw-r\u0026ndash; 就可以用 664 来表示。如果我们想把文件的权限修改为 rwxrwxrwx，可以使用下面的命令：\n$ chmod 777 testfile 以字符表示权限的方式如下：用字符 u, g, o 分别代表文件所有者(user)、文件所属的组(group)和其他人(other)，这就是 ugo 权限叫法的由来。只不过还有一个 a 可以表示全部的身份(all)。具体更改权限的语法如下：\nchmod [ugoa][+-=][rwx] 文件/目录 比如我们可以通过下面的命令把 testfile 的权限设为 rw-rw-r\u0026ndash;：\n$ chmod ug=rw,o=r testfile 如果想去掉组的 w 权限并给其他人添加 x 权限可以执行下面的命令：\n$ chmod g-w,o+x testfile 我们还可通过 a 为全部身份设置权限，比如 rwx：\n$ chmod a=rwx testfile 特殊权限 setuid 和 setgid 分别是 set uid ID upon execution 和 set group ID upon execution 的缩写。我们一般会再次把它们缩写为 suid 和 sgid。它们是控制文件访问的权限标志(flag)，它们分别允许用户以可执行文件的 owner 或 owner group 的权限运行可执行文件。\nSUID 在 Linux 中，所有账号的密码记录在 /etc/shadow 这个文件中，并且只有 root 可以读写入这个文件：\n$ ll /etc/shadow -rw-r----- 1 root shadow 1.5K Feb 25 12:46 /etc/shadow 如果另一个普通账号 tester 需要修改自己的密码，就要访问 /etc/shadow 这个文件。但是明明只有 root 才能访问 /etc/shadow 这个文件，这究竟是如何做到的呢？事实上，tester 用户是可以修改 /etc/shadow 这个文件内的密码的，就是通过 SUID 的功能。让我们看看 passwd 程序文件的权限信息：\n$ ll /usr/bin/passwd -rwsr-xr-x 1 root root 67K Jul 15 2021 /usr/bin/passwd 上图红框中的权限信息有些奇怪，owner 的信息为 rws 而不是 rwx。当 s 出现在文件拥有者的 x 权限上时，就被称为 SETUID BITS 或 SETUID ，其特点如下：\n SUID 权限仅对二进制可执行文件有效 如果执行者对于该二进制可执行文件具有 x 的权限，执行者将具有该文件的所有者的权限 本权限仅在执行该二进制可执行文件的过程中有效  下面我们来看 tester 用户是如何利用 SUID 权限完成密码修改的：\n tester 用户对于 /usr/bin/passwd 这个程序具有执行权限，因此可以执行 passwd 程序 passwd 程序的所有者为 root tester 用户执行 passwd 程序的过程中会暂时获得 root 权限 因此 tester 用户在执行 passwd 程序的过程中可以修改 /etc/shadow 文件  但是如果由 tester 用户执行 cat 命令去读取 /etc/shadow 文件确是不行的：\n$ ll /bin/cat -rwxr-xr-x 1 root root 43K Sep 5 2019 /bin/cat 原因很清楚，tester 用户没有读 /etc/shadow 文件的权限，同时 cat 程序也没有被设置 SUID。我们可以通过下图来理解这两种情况：\nSGID 当 s 标志出现在用户组的 x 权限时称为 SGID。SGID 的特点与 SUID 相同，我们通过 /usr/bin/mlocate 程序来演示其用法。mlocate 程序通过查询数据库文件 /var/lib/mlocate/mlocate.db 实现快速的文件查找。 mlocate 程序的权限如下图所示：\n$ ll /usr/bin/mlocate -rwxr-sr-x 1 root mlocate 39520 Nov 18 2014 /usr/bin/mlocate* 很明显，它被设置了 SGID 权限。下面是数据库文件 /var/lib/mlocate/mlocate.db 的权限信息：\n$ ll /var/lib/mlocate/mlocate.db -rw-r----- 1 root mlocate 12101109 Aug 13 07:35 /var/lib/mlocate/mlocate.db 普通用户 tester 执行 mlocate 命令时，tester 就会获得用户组 mlocate 的执行权限，又由于用户组 mlocate 对 mlocate.db 具有读权限，所以 tester 就可以读取 mlocate.db 了。程序的执行过程如下图所示：\n除二进制程序外，SGID 也可以用在目录上。当一个目录设置了 SGID 权限后，它具有如下功能：\n 用户若对此目录具有 r 和 x 权限，该用户能够进入该目录 用户在此目录下的有效用户组将变成该目录的用户组 若用户在此目录下拥有 w 权限，则用户所创建的新文件的用户组与该目录的用户组相同  SBIT 其实 SBIT 与 SUID 和 SGID 的关系并不大。SBIT 是 the restricted deletion flag or sticky bit 的简称。\nSBIT 目前只对目录有效，用来阻止非文件的所有者删除文件。比较常见的例子就是 /tmp 目录：\n$ ls -ld /tmp drwxrwxrwt 22 root root 4096 Mar 2 20:57 /tmp 权限信息中最后一位 t 表明该目录被设置了 SBIT 权限。SBIT 对目录的作用是：当用户在该目录下创建新文件或目录时，仅有自己和 root 才有权力删除。\n设置权限 以数字的方式设置权限\nSUID、SGID、SBIT 权限对应的数字如下：\nSUID-\u0026gt;4 SGID-\u0026gt;2 SBIT-\u0026gt;1 所以如果要为一个文件权限为 \u0026ldquo;-rwxr-xr-x\u0026rdquo; 的文件设置 SUID 权限，需要在原先的 755 前面加上 4，也就是 4755：\n$ chmod 4755 filename 同样，可以用 2 和 1 来设置 SGID 和 SBIT 权限。设置完成后分别会用 s, s, t 代替文件权限中的 x。\n其实，还可能出现 S 和 T 的情况。s 和 t 是替代 x 这个权限的，但是，如果它本身没有 x 这个权限，添加 SUID、SGID、SBIT 权限后就会显示为大写 S 或大写 T。比如我们为一个权限为 666 的文件添加 SUID、SGID、SBIT 权限：\n$ chmod 666 nickfile $ ll nickfile -rw-rw-rw- 1 nick nick 0 Mar 2 21:03 nickfile $ chmod 7666 nickfile $ ll nickfile -rwSrwSrwT 1 nick nick 0 Mar 2 21:03 nickfile 通过符号类型改变权限\n除了使用数字来修改权限，还可以使用符号：\n$ chmod u+s testfile # 为 testfile 文件加上 SUID 权限。 $ chmod g+s testdir # 为 testdir 目录加上 SGID 权限。 $ chmod o+t testdir # 为 testdir 目录加上 SBIT 权限。 umask 默认权限 为了查看用户创建的文件和目录的默认权限，我们用一个普通的用户创建文件 myfile 和目录 mydir 并查看它们的默认权限：\n$ touch myfile $ mkdir mydir $ ll total 4.0K drwxrwxr-x 2 nick nick 4.0K Mar 2 21:09 mydir -rw-rw-r-- 1 nick nick 0 Mar 2 21:09 myfile 目录的权限为 775，文件的权限为 664。默认情况下对于目录来说最大的权限是 777，对于文件来说最大的权限一般为 666(只有可以执行的文件才添加可执行权限)。所以我们创建的文件和目录的共同特点是从最大权限中减其他用户的写权限。而这个被减去的值就是我们常说的 umask。umask 还是 bash 的一个内置命令，默认输出当前用户的 umask 值：\n$ umask 002 注意，umask 显示的值为从默认的最大权限中减去的值。\n默认策略 系统在用户登录时通过 login 程序调用 pam_umask 模块设置用户默认的 umask。从 login 程序的配置文件 /etc/login.defs 中我们可以找到 umask 相关的配置：\n... UMASK 022 ... USERGROUPS_ENAB yes ... 用户的默认 umask 应该是 022，但当 USERGROUPS_ENAB 被设置为 yes 时(默认值)，对于 uid 和 gid 相同且用户名和主组名相同的用户，系统会把其 umask 改为 002。\n于 root 用户的特殊性，它默认的 umask 与其它用户是不同的，其值为 022：\n# umask 0022 第一个 0 表示 8 进制，这里我们可以暂时忽略它。\n命令 umask 是 bash 的一个内置命令，用来显示或设置新建文件/目录的权限掩码(umask)。前面我们以数字的方式输出了用户默认的 umask 值，这次我们以符号的方式进行输出：\n$ umask -S u=rwx,g=rwx,o=rx 以符号输出的就是用户创建目录时的默认权限，也就是 775。\n为了改变用户创建的文件/目录的默认值，我们可以改变 umask 的默认值。\n设置 umask 值\n最简单的方式就是为 umask 命令指定一个数字：\n$ umask 026 026 的含义为：去掉 group 中的写权限，去掉 other 中的读写权限。\n这时创建的文件权限为 640，目录权限为 751。注意，修改 umask 后只有新建的文件和目录受影响，已经存在的文件和目录的权限不会被影响。\n以符号的方式设置 umask 值\n比如下面的命令：\n$ umask u=,g=w,o=rwx 上面的命令表示从 group 中去掉写权限，从 other 中去掉读写执行的权限。\n注意：\u0026quot;=\u0026quot; 号在 umask 命令和 chmod 命令中的作用恰恰相反。在 chmod 命令中，利用它来设置指定的权限，而其余权限则被删除。但是在 umask 命令中，将在原有权限的基础上删除指定的权限。\n在 ~/.bashrc 文件中为用户设置默认的 umask\n如果让用户每次登陆后都执行 umask 命令修改默认的 umask 值是不科学的，我们可以在用户的 ~/.bashrc 文件中执行 umask 命令，这样用户登录后 umask 的值自动就变成了设置的值。把下面的命令添加到 ~/.bashrc 文件的最后一行：\numask 026 与 ACL 如果一个目录没有被设置 default ACL，那么将由 umask 决定新文件的 ACL 权限。这种情况其实就是我们常见的没有 ACL 权限时的情况。比如我们设置 umask 为 026，那么创建的文件和目录的权限就是由它决定的。\n如果一个目录被设置了 default ACL，那么将会由文件创建函数的 mode 参数和目录的 default ACL 共通决定新文件的 ACL 权限，此时 umask 被忽略。还以 umask 026 为例，我们创建一个目录 dir2 并设置 default ACL 权限：\n$ setfacl -m d:u:tester:rwx dir2 $ getfacl dir2 # file: dir2 # owner: nick # group: nick user::rwx group::r-x other::--x default:user::rwx default:user:tester:rwx default:group::rwx default😷:rwx default:other::r-x 然后在 dir2 目录中创建文件 testfile：\n$ dir2 touch testfile $ dir2 ll testfile -rw-rw-r--+ 1 nick nick 0 Mar 2 21:26 testfile 这次 testfile 的权限已经不受 umask 的影响了！\nACL ACL的全称是 Access Control List (访问控制列表) ，一个针对文件/目录的访问控制列表。它在UGO权限管理的基础上为文件系统提供一个额外的、更灵活的权限管理机制。它被设计为UNIX文件权限管理的一个补充。ACL允许你给任何特定的用户或用户组设置任何文件/目录的访问权限。\nACL需要Linux内核和文件系统的配合才能工作，大多数Linux发行版本默认都是支持的。但最好还是能够先检查一下：\n$ sudo tune2fs -l /dev/sda1 | grep \u0026#34;Default mount options:\u0026#34; Default mount options: user_xattr acl 设置权限 可以使用setfacl和getfacl命令来设置或观察文件/目录的acl权限。\n当前用户是 nick，再创建两个用户 tester 和 tester1 用来进行测试：\n$ sudo adduser tester 创建文件 aclfile，检查其默认的权限信息：\n$ touch aclfile $ ll aclfile -rw-rw-r-- 1 nick nick 0 Mar 2 21:40 aclfile $ getfacl aclfile # file: aclfile # owner: nick # group: nick user::rw- group::rw- other::r-- 把用户切换为 tester，发现没有写文件的权限：\n$ echo \u0026#34;hello\u0026#34; \u0026gt;\u0026gt; aclfile bash: aclfile: Permission denied 这是因为 other 没有写 aclfile 文件的权限。\n下面我们为 tester 用户赋予读写 aclfile 文件的权限：\n$ setfacl -m u:tester:rw aclfile 修改成功后再次以 tester 用户的身份向 aclfile 文件写入数据，这次已经可以正常写入了。查看 aclfile 文件的权限：\n$ getfacl aclfile # file: aclfile # owner: nick # group: nick user::rw- user:tester:rw- group::rw- mask::rw- other::r-- 多出了一些信息，其中比较重要的是 user:tester:rw-，就是它让用户 tester 具有了读写 aclfile 的权限。\n针对用户组来设置权限和针对用户的设置几乎一样，只是把小写的 u 换成小写的 g 就行了。\n继承权限 acl 能让创建的子文件或者子文件夹继承父文件夹的权限设置！\n$ mkdir mydir $ ll -d mydir drwxrwxr-x 2 nick nick 4.0K Mar 2 21:09 mydir $ setfacl -m d:u:tester:rwx mydir $ getfacl mydir # file: mydir # owner: nick # group: nick user::rwx group::rwx other::r-x default:user::rwx default:user:tester:rwx default:group::rwx default😷:rwx default:other::r-x 这次多出了一些以 default 开头的行，这些 default 权限信息只能在目录上设置，然后会被目录中创建的文件和目录继承。下面分别在 mydir 目录下创建文件 testfile 和目录 testdir，并查看它们的 acl 权限：\n$ touch testfile $ mkdir testdir $ getfacl testfile # file: testfile # owner: nick # group: nick user::rw- user:tester:rwx group::rwx mask::rw- other::r-- 从上面可以看到文件 testfile 继承了父目录的 acl 权限，因此用户 tester 对它有读写权限。下面再看看 testdir 目录：\n$ getfacl testdir # file: testdir # owner: nick # group: nick user::rwx user:nick:rwx group::rwx mask::rwx other::r-x default:user::rwx default:user:tester:rwx default:group::rwx default😷:rwx default:other::r-x 从图中可以看出，testdir 目录不仅继承了 tester 的访问权限，还继承了父目录上的 default 权限。也就是说我们通过这种方式设置在目录上的权限可以被子目录递归的继承下去。\n操作权限 更改 -m 选项其实是在更改文件和目录的 ACL 权限\n 当一个用户或组的 ACL 权限不存在时，-m 选项执行的是添加操作， 如果一个用户或组的 ACL 权限已经存在时，-m 选项执行的是更新操作。  $ setfacl -m u:tester:rwx aclfile $ setfacl -m u:tester:rw aclfile -set 选项会先清除掉原有的 ACL 权限，然后添加新的权限\n$ setfacl --set u::rw,u:tester:rwx,g::r,o::- aclfile $ getfacl aclfile # file: aclfile # owner: nick # group: nick user::rw- user:tester:rwx group::r-- mask::rwx other::--- 需要注意的是一定要包含 UGO 权限的设置，不能象 -m 一样只包含 ACL 权限。o::- 是另一个需要注意的地方，其完整的写法是 other::-，就像 u::rw 的完整写法是 user::rw- 一样。通常我们可以把 \u0026ldquo;-\u0026rdquo; 省略，但是当权限位只包含 \u0026ldquo;-\u0026rdquo; 时，就至少要保留一个。如果写成了o::，就会报错。\n删除 通过 setfacl 命令的 -x 选项来删除指定用户或组的 ACL 权限，还可以通过 -b 选项来清除文件和目录上所有的 ACL 权限。\n下面通过 -x 选项删除 user tester 的 ACL 权限，注意命令中只指定了用户的名称而没有指定权限信息：\n$ getfacl aclfile # file: aclfile # owner: nick # group: nick user::rw- user:tester:rwx group::rw- mask::rwx other::r-- $ setfacl -x u:tester aclfile $ getfacl aclfile # file: aclfile # owner: nick # group: nick user::rw- group::rw- mask::rw- other::r-- 下面通过 -b 选项一次性删除 aclfile 上所有的 ACL 权限：\n$ setfacl -b aclfile getfacl aclfile # file: aclfile # owner: nick # group: nick user::rw- group::rw- other::r-- 备份和恢复 常见的文件操作命令 cp 和 mv 等都支持 ACL 权限，只是 cp 命令需要加上 -p 参数。但是 tar 等常见的备份工具不会保留目录和文件的 ACL 权限信息。如果希望备份和恢复带有 ACL 权限的文件和目录，可以先把 ACL 权限信息备份到一个文件里，然后再用 -restore 选项来恢复这些信息。\n使用下面的命令导出 acldir 目录的 ACL 权限信息并保存到文件 acldir.acl 文件中：\n$ getfacl -R acldir \u0026gt; acldir.acl 通过下面的命令把它们的 ACL 权限都恢复回来：\n$ setfacl --restore acldir.acl 实现原理 ACL 条目\n进程权限 ugo 权限信息是文件的属性，它指明了用户与文件之间的关系。但是真正操作文件的却是进程，也就是说用户所拥有的文件访问权限是通过进程来体现的。\n概念：\n  用户 对于支持多任务的 Linux 系统来说，用户就是获取资源的凭证。\n  权限 权限用来控制用户对计算机资源(CPU、内存、文件等)的访问，一般会分为认证和授权两步。比如用户先经过认证机制(authentication)登录系统，然后由授权系统(authorization)对用户的操作进行授权。\n  进程 进程是任何支持多道程序设计的操作系统中的基本概念。通常把进程定义为程序执行时的一个实例。因此，如果有 10 个用户同时运行 vi，就会有 10 个独立的进程(尽管它们共享同一份可执行代码)。\n实际上，是进程在帮助我们完成各种任务。进程就是用户访问计算机资源的代理，用户执行的操作其实是带有用户身份信息的进程执行的操作。\n  进程权限 既然是进程在为用户执行具体的操作，那么当用户要访问系统的资源时就必须给进程赋予权限。也就是说进程必须携带发起这个进程的用户的身份信息才能够进行合法的操作。\n  登陆过程 在 Linux 系统启动后，init 系统会 fork 出子进程执行 /sbin/getty 程序等待用户登录。当用户进行登录操作时，该子进程通过 exec 函数开始执行 /bin/login 程序(此时该进程已经变成了 login 进程)。由 login 进程验证我们的用户名和密码并查询 /etc/passwd 和 /etc/shadow 确定其合法性。如果是合法的用户，该进程再次通过 exec 函数执行用户的默认 shell 程序，此时的 login 进程就变成了 shell 进程(笔者机器上是 bash 进程)。并且**该 shell 进程的有效身份被设置成为该用户的身份，之后 fork 此 shell 进程的子进程都会继承该有效身份。**我们可以通过下图来理解用户从 tty 登录系统的过程：\n简单点说就是：用户登录后， shell 进程的有效用户就是该用户。\nuser id 通过 cat /proc/\u0026lt;PID\u0026gt;/status 命令，我们可以查看到进程所属的用户和组相关的信息：\nUid:\t1000\t1000\t1000\t1000 Gid:\t1000\t1000\t1000\t1000 通过 man proc 可以查询到第一行的四个数字分别是 real user id, effective user id, saved set user id 和 filesystem UID，第二行则是对应的组 ID。\nreal user id\nreal user id 是执行进程者的 user id，一般情况下就是用户登录时的 user id。子进程的 real user id 从父进继承。通常这个是不更改的，也不需要更改。比如我以用户 nick 登录 Linux 系统，我接下来运行的所有命令的进程的 real user id 都是 nick 的 user id。\neffective user id\n如果要判断一个进程是否对某个文件有操作权限，验证的是进程的 effective user id，而不是 real user id。\n通常不建议直接使用 root 用户进行操作的，但是在很多情况下，程序可能需要特殊的权限。比如 passwd 程序需要 root 权限才能够为普通用户修改密码，一些 services 程序的操作也经常需要特殊的权限。为此，Linux 中设计了一些特殊的权限（SUID/SGID/SBIT）。这里我们以 passwd 程序为例，为二进制可执行文件 /usr/bin/passwd 设置 set-user-id bit=ON，这个可执行文件被用 exec 启动之后的进程的 effective user id 就是这个可执行文件的 owner id，而并非父进程的 real user id。如果 set-user-id bit=OFF 的时候，这个被 exec 起来的进程的 effective user id 应该是等于进程的 user id 的。\n其实我们通过 ps aux 查看的结果中，第一列显示的就是进程的 effective user。\nsaved set user id\nsaved set user id 相当于是一个 buffer，在 exec 函数启动之后，它会拷贝 effective user id 位的信息覆盖自己。\n对于非 root 用户来说，可以在未来使用 setuid() 函数将 effective user id 设置成为 real user id 或 saved set user id 中的任何一个。但是不允许非 root 用户用 setuid() 函数把 effective user id 设置成为任何第三个 user id。\n对于 root 用户来说，调用 setuid() 的时候，将会设置所有的这三个 user id。\n外部命令 在 shell 中执行的命令分为内部命令和外部命令两种。\n 内部命令：内建的，相当于 shell 的子函数 外部命令：在文件系统的某个路径下的一个可执行文件  外部命令的执行过程如下：\n Shell 通过 fork() 函数建立一个新的子进程，新的子进程为当前 shell 进程的一个副本。 在新的进程里，从 PATH 变量所列出的目录中寻找指定的命令程序。当命令名称包含有斜杠(/)符号时，将略过路径查找步骤。 在新的进程里，通过 exec 系列函数，以所找到的新程序替换 shell 程序并执行。 子进程退出后，最初的 shell 会接着从终端读取并执行下一条命令。  我们通过下面的例子来理解在 shell 中执行外部命令的过程，例子很简单就是通过 cat 命令查看一个文本文件 test.log：\n$ cat test.log 我们先来检查一下当前用户以及相关文件的权限：\n$ uid=1000(nick) gid=1000(nick) groups=1000(nick),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),120(lpadmin),132(lxd),133(sambashare) $ ll /bin/cat -rwxr-xr-x 1 root root 43K Sep 5 2019 /bin/cat $ ll test.log -rw-rw-r-- 1 nick nick 0 Mar 2 23:25 test.log 当前用户 nick 的 real user id 为 1000，/bin/cat 文件的所有者为 root，但是所有人都有执行权限，test.log 文件的所有者为 nick。我们结合下图来介绍 cat test.log 命令的执行过程：\n当我们在 shell 中执行一个外部程序的时候，默认情况下进程的 effective user ID 等于 real user ID，进程的 effective group ID 等于 real group ID(接下来的介绍中省略 group ID)。当我们以用户 nick 登录系统，并在 bash 中键入 cat test.log 命令并回车后。Bash 先通过 fork() 建立一个新的子进程，这个新的子进程是当前 bash 进程的一个副本。新的进程在 PATH 变量指定的路径中搜索 cat 程序，找到 /bin/cat 程序后检查其权限。/bin/cat 程序的所有者为 root，但是其他人具有读和执行的权限，所以新进程可以通过 exec 函数用 cat 程序的代码段替换当前进程中的代码段(把 /bin/cat 程序加载到了内存中，此时的进程已经变成了 cat 进程，cat 进程会从 _start 函数开始执行)。由于 cat 进程是由用户 nick 启动的，所以 cat 进程的 effective user ID 是 1000(nick)。同时 cat 进程的 effective user ID 和 test.log 文件的 owner ID 相同(都是 1000)，所以 cat 进程拥有对此文件的 rw- 权限，那么顺理成章地就可以读写 test.log 文件的内容了。\n脚本 在 shell 中执行脚本的方式和执行外部命令的方式差不多，比如我们要执行下面的脚本：\n$ /bin/bash ./test.sh 这时同样会 fork 出一个子进程。只不过脚本与程序相比没有代码段，也没有 _start 函数，此时 exec 函数就会执行另外一套机制。比如我们在 test.sh 文件的第一行通过 #!/bin/bash 指定了一个解释器，那么解释器程序的代码段会用来替换当前进程的代码段，并且从解释器的 _start 函数开始执行，而这个文本文件被当作命令行参数传给解释器。所以上面的命令执行过程为：Bash 进程 fork/exec 一个子 bash 进程用于执行脚本，子 bash 进程继承父进程的环境变量、用户信息等内容，父进程等待子 bash 进程终止。\n 权限 cgroub sudo fdisk 自动更新 LVM 进程  Capabilities 为了执行权限检查，Linux 区分两类进程：特权进程(其有效用户标识为 0，也就是超级用户 root)和非特权进程(其有效用户标识为非零)。 特权进程绕过所有内核权限检查，而非特权进程则根据进程凭证(通常为有效 UID，有效 GID 和补充组列表)进行完全权限检查。\n以常用的 passwd 命令为例，修改用户密码需要具有 root 权限，而普通用户是没有这个权限的。但是实际上普通用户又可以修改自己的密码，这是怎么回事？在 Linux 的权限控制机制中，有一类比较特殊的权限设置，比如 SUID(Set User ID on execution)。因为程序文件 /bin/passwd 被设置了 SUID 标识，所以普通用户在执行 passwd 命令时，进程是以 passwd 的所有者，也就是 root 用户的身份运行，从而修改密码。\nSUID 虽然可以解决问题，却带来了安全隐患。当运行设置了 SUID 的命令时，通常只是需要很小一部分的特权，但是 SUID 给了它 root 具有的全部权限。因此一旦 被设置了 SUID 的命令出现漏洞，就很容易被利用。也就是说 SUID 机制在增大了系统的安全攻击面。\nLinux 引入了 capabilities 机制对 root 权限进行细粒度的控制，实现按需授权，从而减小系统的安全攻击面。\n简介 从内核 2.2 开始，Linux 将传统上与超级用户 root 关联的特权划分为不同的单元，称为 capabilites。Capabilites 作为线程(Linux 并不真正区分进程和线程)的属性存在，每个单元可以独立启用和禁用。如此一来，权限检查的过程就变成了：在执行特权操作时，如果进程的有效身份不是 root，就去检查是否具有该特权操作所对应的 capabilites，并以此决定是否可以进行该特权操作。比如要向进程发送信号(kill())，就得具有 capability CAP_KILL；如果设置系统时间，就得具有 capability CAP_SYS_TIME。\n下面是从 capabilities man page 中摘取的 capabilites 列表：\n   capability 名称 描述     CAP_AUDIT_CONTROL 启用和禁用内核审计；改变审计过滤规则；检索审计状态和过滤规则   CAP_AUDIT_READ 允许通过 multicast netlink 套接字读取审计日志   CAP_AUDIT_WRITE 将记录写入内核审计日志   CAP_BLOCK_SUSPEND 使用可以阻止系统挂起的特性   CAP_CHOWN 修改文件所有者的权限   CAP_DAC_OVERRIDE 忽略文件的 DAC 访问限制   CAP_DAC_READ_SEARCH 忽略文件读及目录搜索的 DAC 访问限制   CAP_FOWNER 忽略文件属主 ID 必须和进程用户 ID 相匹配的限制   CAP_FSETID 允许设置文件的 setuid 位   CAP_IPC_LOCK 允许锁定共享内存片段   CAP_IPC_OWNER 忽略 IPC 所有权检查   CAP_KILL 允许对不属于自己的进程发送信号   CAP_LEASE 允许修改文件锁的 FL_LEASE 标志   CAP_LINUX_IMMUTABLE 允许修改文件的 IMMUTABLE 和 APPEND 属性标志   CAP_MAC_ADMIN 允许 MAC 配置或状态更改   CAP_MAC_OVERRIDE 覆盖 MAC(Mandatory Access Control)   CAP_MKNOD 允许使用 mknod() 系统调用   CAP_NET_ADMIN 允许执行网络管理任务   CAP_NET_BIND_SERVICE 允许绑定到小于 1024 的端口   CAP_NET_BROADCAST 允许网络广播和多播访问   CAP_NET_RAW 允许使用原始套接字   CAP_SETGID 允许改变进程的 GID   CAP_SETFCAP 允许为文件设置任意的 capabilities   CAP_SETPCAP 参考 capabilities man page   CAP_SETUID 允许改变进程的 UID   CAP_SYS_ADMIN 允许执行系统管理任务，如加载或卸载文件系统、设置磁盘配额等   CAP_SYS_BOOT 允许重新启动系统   CAP_SYS_CHROOT 允许使用 chroot() 系统调用   CAP_SYS_MODULE 允许插入和删除内核模块   CAP_SYS_NICE 允许提升优先级及设置其他进程的优先级   CAP_SYS_PACCT 允许执行进程的 BSD 式审计   CAP_SYS_PTRACE 允许跟踪任何进程   CAP_SYS_RAWIO 允许直接访问 /devport、/dev/mem、/dev/kmem 及原始块设备   CAP_SYS_RESOURCE 忽略资源限制   CAP_SYS_TIME 允许改变系统时钟   CAP_SYS_TTY_CONFIG 允许配置 TTY 设备   CAP_SYSLOG 允许使用 syslog() 系统调用   CAP_WAKE_ALARM 允许触发一些能唤醒系统的东西(比如 CLOCK_BOOTTIME_ALARM 计时器)    程序文件的 capabilities\n在可执行文件的属性中有三个集合来保存三类 capabilities，它们分别是：\n Permitted Inheritable Effective  在进程执行时，Permitted 集合中的 capabilites 自动被加入到进程的 Permitted 集合中。\nInheritable 集合中的 capabilites 会与进程的 Inheritable 集合执行逻辑与操作，以确定进程在执行 execve 函数后哪些 capabilites 被继承。\nEffective 只是一个 bit。如果设置为开启，那么在执行 execve 函数后，Permitted 集合中新增的 capabilities 会自动出现在进程的 Effective 集合中。\n进程的 capabilities\n进程中有五种 capabilities 集合类型，分别是：\n Permitted Inheritable Effective Bounding Ambient  相比文件的 capabilites，进程的 capabilities 多了两个集合，分别是 Bounding 和 Ambient。\n/proc/[pid]/status 文件中包含了进程的五个 capabilities 集合的信息，我们可以通过下面的命名查看当前进程的 capabilities 信息：\n$ cat /proc/$$/status | grep \u0026#39;Cap\u0026#39; CapInh:\t0000000000000000 CapPrm:\t0000000000000000 CapEff:\t0000000000000000 CapBnd:\t000003ffffffffff CapAmb:\t0000000000000000 但是这中方式获得的信息无法阅读，我们需要使用 capsh 命令把它们转义为可读的格式：\n$ capsh --decode=0000003fffffffff 使用 getcap 命令和 setcap 命令分别用来查看和设置程序文件的 capabilities 属性。下面我们演示如何使用 capabilities 代替 ping 命令的 SUID。\n因为 ping 命令在执行时需要访问网络，这就需要获得 root 权限，常规的做法是通过 SUID 实现的(和 passwd 命令相同)：\n$ ll /bin/ping -rwsr-xr-x 1 root root 72K Jan 31 2020 /bin/ping $ ll /usr/bin/passwd -rwsr-xr-x 1 root root 67K Jul 15 2021 /usr/bin/passwd 红框中的 s 说明应用程序文件被设置了 SUID，这样普通用户就可以执行这些命令了。\n移除 ping 命令文件上的 SUID 权限：\n$ sudo chmod 755 /bin/ping $ ping baidu.com ping: socket: Operation not permitted 在移除 SUID 权限后，普通用户在执行 ping 命令时碰到了 \u0026ldquo;ping: socket: Operation not permitted\u0026rdquo; 错误。\n为 ping 命令文件添加 capabilities\n执行 ping 命令所需的 capabilities 为 cap_net_admin 和 cap_net_raw，通过 setcap 命令可以添加它们：\n$ sudo setcap cap_net_admin,cap_net_raw+ep /bin/ping $ getcap /bin/ping /bin/ping = cap_net_admin,cap_net_raw+ep $ ping baidu.com PING baidu.com (220.181.38.148) 56(84) bytes of data. 64 bytes from 220.181.38.148 (220.181.38.148): icmp_seq=1 ttl=46 time=33.3 ms 64 bytes from 220.181.38.148 (220.181.38.148): icmp_seq=2 ttl=46 time=40.9 ms 被赋予合适的 capabilities 后，ping 命令又可以正常工作了，相比 SUID 它只具有必要的特权，在最大程度上减小了系统的安全攻击面。\n如果要移除刚才添加的 capabilities，执行下面的命令：\n$ sudo setcap cap_net_admin,cap_net_raw-ep /bin/ping $ getcap /bin/ping /bin/ping = 命令中的 ep 分别表示 Effective 和 Permitted 集合，+ 号表示把指定的 capabilities 添加到这些集合中，- 号表示从集合中移除(对于 Effective 来说是设置或者清除位)。\n进程 job control 进程组 执行一个命令会创建一个或多个进程，这些进程被称为一个进程组(process group)。进程组中包含一个或多个进程，每个进程都会属于一个进程组，进程组也叫 job。\n每个进程组都有一个领头进程(process group leader)，领头进程的 PID 就是进程组的 ID(process group ID，PGID)，我们可以通过 ps 命令查看进程的 PGID：\n$ ps -o pid,ppid,pgid,comm | cat PID PPID PGID COMMAND 2646 2638 2646 zsh 16823 2646 16823 ps 16824 2646 16823 cat 16823 16824 两个进程属于同一进程组(通过管道符连接的进程属于相同的进程组)。这个进程组中的领头进程为 16823，因此它的 PID 成了进程组的 PGID。\n领头进程可以先退出，这时进程组依然存在并且 PGID 也不会发生变化。在进程组中的所有进程都退出后，进程组的生命周期结束。\n将进程划分到进程组中的主要原因是可以对它们进行统一的管理，说白了就是同时发信号给组内的所有进程，这就是我们接下来要介绍的 job 管理。\n管理 jobs 命令\n使用 vim 打开文件 test.txt，然后按下 ctrl + z，此时 vim 进入了后台：\n$ vim test.txt [1]+ Stopped vim test.txt 输出的第一列方括号中的数字表示 jobID，第二列 Stopped 表示 job 当前的状态，第三列则表示该 job 执行的命令。 使用 jobs 命令可以查看当前会话中的的所有 jobs，此时执行 jobs 命令，输出的结果和上面一样：\n$ jobs [1]+ Stopped vim test.txt \u0026amp; 符\n在命令的后面加上 \u0026amp; 符号，可以直接让 job 运行在后台：\n$ sleep 1000 \u0026amp; [2] 26524 $ jobs [1]+ Stopped vim test.txt [2]- Running sleep 1000 \u0026amp; sleep 命令的 jobID 为 2，状态为 Running。\nfg 命令\nfg 命令是 foreground 的缩写。命令格式为 fg %n，它把当前或指定 ID 的 job 放到前台。下面我们操作一次 job 2：\n$ fg %2 sleep 1000 此时 sleep 命令运行在前台，通过 ctrl + z 我们可以再次把它送回后台：\n$ fg %2 sleep 1000 ^Z [2]+ Stopped sleep 1000 请注意此时 sleep 命令的状态已经变成了 Stopped。\nctrl + z\n严格来说 ctrl + z 并不是一个 job 管理命令，它只是向当前进程发送一个 SIGSTOP 信号，该信号使进程进入暂停(stopped)状态，也就是挂起进程，此状态下，进程状态会被系统保存，此进程会被放置到作业队列中去，从而让出终端。使用 ctrl + z 我们可以暂停正在占用终端的进程而不结束它，然后我们可以使用终端命令来操作此进程。\nbg 命令\nbg 命令是 background 的缩写，命令格式为 bg %n，bg 命令和 ctrl + z 配合可以把前台命令切换到后台去执行。比如刚才我们通过 ctrl + z 把 sleep 命令切到了后台，但变成了 Stopped 状态，此时执行 bg %2 命令可以让 sleep 命令继续在后台执行：\n$ bg %2 [2]+ sleep 1000 \u0026amp; $ jobs [1]+ Stopped vim test.txt [2]- Running sleep 1000 \u0026amp; kill 命令\nkill 命令负责向进程发送信号，当然它也可以向 job 发送信号，在 jobID 前面添加 % 就可以了。比如 SIGCONT 是唤醒一个挂起的进程，所以我们也可以使用下面的命令把处于 Stooped 状态的 sleep 命令唤醒：\n$ jobs [1]+ Stopped sleep 1000 $ kill -SIGCONT %1 $ jobs [1]+ Running sleep 1000 \u0026amp; 杀死进程\n有时候使用 ctrl + c 无法杀死一个正在运行的前台进程，这是因为 ctrl + c 的本质是向进程发送 SIGINT 信号。SIGINT 是用来终止进程的，但是这是一个可以被忽略的信号，如果程序忽略了它，我们就无法通过 ctrl + c 来终止该进程。\n此时我们可以先使用 ctrl + z 把进程切换到后台，然后使用 kill %n(n 为进程的 jobID)来终止进程。kill 命令默认向进程发送 SIGTERM 信号，程序一般会在 SIGTERM 信号的处理函数中正常地终止程序并执行资源清理工作。既然 SIGTERM 信号能够被程序处理，那么它也能够被忽略，所以也无法通过这种方式结束那些顽固的进程。\n杀死进程的终极手段是 kill -SIGKILL PID(kill -9 PID)。SIGKILL 信号是不能被忽略的，所以这一招肯定管用。但是由于它过于强硬，使用这种方式杀死进程后往往会有后遗症，比如进程使用的资源没有在退出前清理干净，常见的例子是用这种方法杀死 vim 进程后会遗留下 .swp 文件。\n暂停 tail 命令的输出\n我们一般会使用 tail -f 命令查看实时的日志，但很多程序产生日志的速度非常快以至于我们跟不上节奏。此时使用 ctrl + s 命令可以暂停日志输出到终端，这样我们就可以仔细的分析当前终端中显示的日志。如果要接着输出日志，可以使用 ctrl + q 命令恢复日志的输出。\n这两个命令的原理是：ctrl + s 会告诉终端暂停，阻塞所有读写操作，即不转发任何数据，只有按了 ctrl + q 后，才会继续。这个功能应该是历史遗留的产物，以前终端和服务器之间没有流量控制功能，所以有可能服务器发送数据过快，导致终端处理不过来，于是需要这样一个命令告诉服务器不要再发了，等终端处理完了后再通知服务器继续。\nsession Linux session 一般是指 shell session。Shell session 是终端中当前的状态，在终端中只能有一个 session。当我们打开一个新的终端时，总会创建一个新的 shell session。\n就进程间的关系来说，session 由一个或多个进程组组成。一般情况下，来自单个登录的所有进程都属于同一个 session。我们可以通过下图来理解进程、进程组和 session 之间的关系：\n会话是由会话中的第一个进程创建的，一般情况下是打开终端时创建的 shell 进程。该进程也叫 session 的领头进程。Session 中领头进程的 PID 也就是 session 的 SID。我们可以通过下面的命令查看 SID：\n$ ps -o pid,ppid,pgid,sid,tty,comm PID PPID PGID SID TT COMMAND 14244 29789 14244 29789 pts/2 ps Session 中的每个进程组被称为一个 job，有一个 job 会成为 session 的前台 job(foreground)，其它的 job 则是后台 job(background)。每个 session 连接一个控制终端(control terminal)，控制终端中的输入被发送给前台 job，从前台 job 产生的输出也被发送到控制终端上。同时由控制终端产生的信号，比如 ctrl + z 等都会传递给前台 job。\n一般情况下 session 和终端是一对一的关系，当我们打开多个终端窗口时，实际上就创建了多个 session。\nSession 的意义在于多个工作(job)在一个终端中运行，其中的一个为前台 job，它直接接收该终端的输入并把结果输出到该终端。其它的 job 则在后台运行。\n诞生与消亡 通常，新的 session 由系统登录程序创建，session 中的领头进程是运行用户登录 shell 的进程。新创建的每个进程都会属于一个进程组，当创建一个进程时，它和父进程在同一个进程组、session 中。\n将进程放入不同 session 的惟一方法是使用 setsid 函数使其成为新 session 的领头进程。这还会将 session 领头进程放入一个新的进程组中。\n当 session 中的所有进程都结束时 session 也就消亡了。实际使用中比如网络断开了，session 肯定是要消亡的。另外就是正常的消亡，比如让 session 的领头进程退出。一般情况下 session 的领头进程是 shell 进程，如果它处于前台，我们可以使用 exit 命令或者是 ctrl + d 让它退出。或者我们可以直接通过 kill 命令杀死 session 的领头进程。这里面的原理是：当系统检测到挂断(hangup)条件时，内核中的驱动会将 SIGHUP 信号发送到整个 session。通常情况下，这会杀死 session 中的所有进程。\nsession 与终端的关系\n如果 session 关联的是伪终端，这个伪终端本身就是随着 session 的建立而创建的，session 结束，那么这个伪终端也会被销毁。\n如果 session 关联的是 tty1-6，tty 则不会被销毁。因为该终端设备是在系统初始化的时候创建的，并不是依赖该会话建立的，所以当 session 退出，tty 仍然存在。只是 init 系统在 session 结束后，会重启 getty 来监听这个 tty。\nnohup 如果我们在 session 中执行了 nohup 等类似的命令，当 session 消亡时，相关的进程并不会随着 session 结束，原因是这些进程不再受 SIGHUP 信号的影响。比如我们执行下面的命令：\n$ nohup sleep 1000 \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp; $ ps -o pid,ppid,pgid,sid,tty,comm PID PPID PGID SID TT COMMAND 7837 7836 7837 7837 pts/0 zsh 7848 7837 7848 7837 pts/0 sleep 7858 7837 7858 7837 pts/0 ps 此时 sleep 进程的 sid 和其它进程是相同的，还可以通过 pstree 命令看到进程间的父子关系。\n$ pstree 如果我们退出当前 session 的领头进程(bash)，sleep 进程并不会退出，这样我们就可以放心的等待该进程运行结果了。\nnohup 并不改变进程的 sid，同时也说明在这种情况中，虽然 session 的领头进程退出了，但是 session 依然没有被销毁(至少 sid 还在被引用)。重新建立连接，通过下面的命令查看 sleep 进程的信息，发现进程的 sid 依然是 7837：\n$ ps -o pid,ppid,pgid,sid,tty,comm PID PPID PGID SID TT COMMAND 7848 1 7848 7837 ? sleep 但是此时的 sleep 已经被系统的 1 号进程 systemd 收养了。\nsetsid setsid 会创建一个新的 session，它的目的是让进程在后台执行命令，实现方式就是让命令进程运行在一个新的与终端脱离的 session 中。看下面的示例：\n$ setsid sleep 1000 查找之下居然没有发现 sleep 进程的踪迹：\n$ ps -o pid,ppid,pgid,sid,tty,comm PID PPID PGID SID TT COMMAND 11162 11161 11162 11162 pts/1 bash 11451 11162 11451 11162 pts/1 ps 通过 grep 查询 sleep 进程的 PID：\n$ ps aux | grep sleep nick 11384 0.0 0.0 6176 840 ? Ss 09:00 0:00 sleep 1000 去查看 sleep 进程所在的 sid，发现是一个新的 session ID，并且没有关联终端：\n$ ps -o pid,ppid,pgid,sid,tty,comm -p 11384 PID PPID PGID SID TT COMMAND 11384 1 11384 11384 ? sleep 当一个进程通过调用 setsid 成为一个新的 session 领头进程时，它会与控制终端断开连接。\n此时通过 pstree 查看进程间的关系，发现 sleep 进程直接被系统的 1 号进程 systemd 收养了。\n控制终端 **控制终端是进程的一个属性。**通过 fork 系统调用创建的子进程会从父进程那里继承控制终端。这样，session 中的所有进程都从 session 领头进程那里继承控制终端。Session 的领头进程称为终端的控制进程(controlling process)。简单点说就是：**一个 session 只能与一个终端关联，这个终端被称为 session 的控制终端(controlling terminal)。**同时只能由 session 的领头进程来建立或者改变终端与 session 的联系。我们可以通过 ps 命令查看进程的控制终端( pts/0 )：\n$ ps -o pid,ppid,pgid,sid,tty,comm PID PPID PGID SID TT COMMAND 17540 17539 17540 17540 pts/0 bash 17550 17540 17540 17540 pts/0 ps 支持 job control 的 shell 必须能够控制在某一时刻由哪个 job 使用终端。否则，可能会有多个 job 试图同时从终端读取数据，这会导致进程在接收用户输入时的混乱。为了防止这种情况发生，shell 必须按照预定的协议与终端驱动程序协作。\nshell 一次只允许一个 job(进程组)访问控制终端。来自控制终端的某些输入会导致信号被发送到与控制终端关联的 job(进程组)中的所有进程。该 job 被称为控制终端上的前台 job。由 shell 管理的其他 job 在不访问终端的情况下，被称为后台 job。\nShell 的职责是通知 job 何时停止何时启动，还要把 job 的信息通知给用户，并提供机制允许用户继续暂停的 job、在前台和后台之间切换 job。比如前台 job 可以无限制的自由使用控制终端，而后台 job 则不可以。当后台 job 中的进程试图从其控制终端读取数据时，通常会向进程组发送 SIGTTIN 信号。这通常会导致该组中的所有进程停止(变成 stopped 状态)。类似地，当后台 job 中的进程试图写入其控制终端时，默认行为是向进程组发送 SIGTTOU 信号，但是否允许写入的控制会更加的复杂。\nTIPS BackupYourSystem Rsync 目的在于恢复系统出现的错误，类似于虚拟机的快照。\n备份\n#!/bin/bash  set -o errexit set -o nounset set -o pipefail readonly SOURCE_DIR=/ readonly BACKUP_DIR=/home/kurome/DataBackup readonly DATETIME=\u0026#34;$(date \u0026#39;+%Y-%m-%d_%H:%M:%S\u0026#39;)\u0026#34; readonly BACKUP_PATH=\u0026#34;${BACKUP_DIR}/${DATETIME}\u0026#34; readonly LATEST_LINK=\u0026#34;${BACKUP_DIR}/latest\u0026#34; rsync -av \\ \t--delete \u0026#34;${SOURCE_DIR}/\u0026#34; \\ \t--link-dest \u0026#34;${LATEST_LINK}\u0026#34; \\ \t--exclude={\u0026#34;dev\u0026#34;,\u0026#34;proc\u0026#34;,\u0026#34;sys\u0026#34;,\u0026#34;tmp\u0026#34;,\u0026#34;run\u0026#34;,\u0026#34;mnt\u0026#34;,\u0026#34;media\u0026#34;,\u0026#34;lost+found\u0026#34;,\u0026#34;Trash\u0026#34;,\u0026#34;Downloads/*\u0026#34;,\u0026#34;DataBackup/*\u0026#34;,\u0026#34;DataPool/*\u0026#34;} \\ \t\u0026#34;${BACKUP_PATH}\u0026#34; rm -rf \u0026#34;${LATEST_LINK}\u0026#34; ln -s \u0026#34;${BACKUP_PATH}\u0026#34; \u0026#34;${LATEST_LINK}\u0026#34; 注意：\n ${SOURCE_DIR}/必须带反斜杠，否则会备份SOURCE_DIR这个目录，而不是这个目录里的内容。 --exclude=\u0026quot;Trash\u0026quot;，Trash被认为为目录，而非文件或文件和目录，并且，它不支持路径~/.local/share/Trash  查看备份大小\n$ sudo du -hs /backup/ 16G\t/backup/ 整个备份为16GB，所花时间 12m。\n通过 crontab 使之每周一12点自动备份：\n$ sudo crontab -e 0 12 * * 1 /path/.backup.sh 还原\n还原的时候，如果带 --delete，那么就会删除备份时 --exclude= 不包含的内容。还原的时候，同名文件内容会恢复到备份时候的状态。\n$ rsync -av 备份目录 源目录 $ rsync -av /backup/latest/ / TAR 目的在于迁移系统到新硬盘。\nBackup\n$ cd / # THIS CD IS IMPORTANT THE FOLLOWING LONG COMMAND IS RUN FROM / $ tar -cvpzf backup.tar.gz \\ --exclude=/backup.tar.gz \\ --exclude=/proc \\ --exclude=/tmp \\ --exclude=/mnt \\ --exclude=/dev \\ --exclude=/sys \\ --exclude=/run \\  --exclude=/media \\  --exclude=/var/log \\ --exclude=/var/cache/apt/archives \\ --exclude=/usr/src/linux-headers* \\  --exclude=/home/*/.gvfs \\ --exclude=/home/*/.cache \\  --exclude=/home/*/.local/share/Trash / Restoring\n$ sudo tar -xvpzf /path/to/backup.tar.gz -C /media/whatever --numeric-owner $ cd /media/whatever $ mkdir /proc /sys /mnt /media For the system to boot, you will need to restore grub. To do this, you will need to reconfigure it in a chroot:\n$ sudo -s for f in dev dev/pts proc ; do mount --bind /$f /media/whatever/$f ; done $ chroot /media/whatever $ dpkg-reconfigure grub-pc You will get a menu asking you what drive(s) grub should be installed on. Choose whatever drive(s) the computer will be booting from.\nFor more information on repairing grub, see [GrubHowto](https://help.ubuntu.com/community/GrubHowto#Backup, Repairing and Reinstalling GRUB)\nOthers Does the UEFI partition either \u0026ldquo;MUST\u0026rdquo; or \u0026ldquo;SHOULD\u0026rdquo; be first for some reason? If so why?\nThe key words \u0026ldquo;SHOULD\u0026rdquo;, \u0026ldquo;MUST\u0026rdquo; and \u0026ldquo;MAY\u0026rdquo; (capitalised) in this answer are to be interpreted as described in RFC 2119.\nAn (U)EFI System Partition (ESP from now on):\n MAY reside at the beginning of the disk and SHOULD be FAT32 because of Windows compatibility.  The only official limit is:\n the ESP MUST reside in the first 2.2 Terabytes of the disk.  So, the ESP MUST reside anywhere in those first 2.2 TB of the disk, but there is absolutely no need for the ESP to be the first partition or reside on the beginning of the disk whatsoever. (It\u0026rsquo;s just that some large company in Redmond, WA advises system integrators differently)\u0026hellip;\nI would put it as the last partition on the disk (if \u0026lt; 2.2TB) as it\u0026rsquo;s only used to load other OSes, but that\u0026rsquo;s just a personal, totally subjective opinion!\nubuntu 20.04 默认 fstab\n# / was on /dev/sda2 during installation UUID=4b66082e-7982-4056-91c2-39cf9177b20f / ext4 errors=remount-ro 0 1 # /boot/efi was on /dev/sda1 during installation UUID=ACEE-47E4 /boot/efi vfat umask=0077 0 1 /swapfile none swap sw 0 0 /boot/efi 是独立分区，而不是 /boot/，如果是 /boot/ 作为独立分区，还原的时候会报错 cannot create symbolic link \u0026lsquo;./initrd.img\u0026rsquo;: Operation not permitted\nAdd Boot Option Manually\nIn Boot Option Name, type Ubuntu, and in File Name select the file grubx64.efi and then Click on \u0026lsquo;OK\u0026rsquo;.\n13 个开源备份解决方案\n  Cronopete\n  Deja Dup\n  Rclone\n  Rdiff-backup\n  Restic\n  Rsync\n  BorgBackup：带有压缩和加密特性以用具有数据去重功能的备份解决方案。它基于 BSD 许可证，支持 Linux、MacOS 和 BSD。\n  UrBackup：它可以做镜像和文件的完整和增量备份；你可以保存整个分区或单个目录。它有 Windows、Linux、和 MacOS 客户端，并且采用 GNU Affero 公共许可证。\n  LuckyBackup：根据其网站介绍，“它是一个易于使用、快速（只传输变化部分，而不是全部数据）、安全（在做任何数据操作之前，先检查所有需要备份的目录，以确保数据安全）、可靠和完全可定制的备份解决方案。它在 GPL 许可证下发行。\n  Casync ：一个可寻址内容的同步解决方案 —— 它设计用于备份、同步、存储和检索大文件系统的多个相关版本。它使用 GNU Lesser 公共许可证。\n  Syncthing：用于在两台计算机之间同步文件。它基于 Mozilla 公共许可证使用，根据其网站介绍，它是安全和私密的。它可以工作于 MacOS、Windows、Linux、FreeBSD、Solaris 和 OpenBSD。\n  Duplicati：一个可工作于 Windows、MacOS 和 Linux 上的、并且支持多种标准协议（比如 FTP、SSH、WebDAV 和云服务）、免费的备份解决方案。它的特性是强大的加密功能，并且它使用 GPL 许可证。\n  Dirvish ：一个基于磁盘的虚拟镜像备份系统，它使用 OSL-3.0 许可证。它要求必须安装有 Rsync、Perl5、SSH。\n  Bacula：允许系统管理员去管理备份、恢复、和跨网络的不同种类计算机上的多种数据的一套计算机程序，它支持在 Linux、FreeBSD、Windows、MacOS、OpenBSD 和 Solaris 上运行，并且它的大部分源代码都是基于 AGPLv3 许可证的。\n  BackupPC：一个高性能的、企业级的、可以备份 Linux、Windows 和 MacOS 系统的 PC 和笔记本电脑上的数据到服务器磁盘上的备份解决方案。它是基于 GPLv3 许可证的。\n  Amanda ：一个使用 C 和 Perl 写的备份系统，它允许系统管理员去备份整个网络中的客户端到一台服务器上的磁带、磁盘或基于云的系统。它是由马里兰大学于 1991 年开发并拥有版权，并且它有一个 BSD 式的许可证。\n  Back in Time ：一个为 Linux 设计的简单的备份实用程序。它提供了命令行和图形用户界面，它们都是用 Python 写的。去执行一个备份，只需要指定存储快照的位置、需要备份的文件夹，和备份频率即可。它使用的是 GPLv2 许可证。\n  Timeshift ：一个 Linux 上的备份实用程序，它类似于 Windows 上的系统恢复和 MacOS 上的时间胶囊。它的 GitHub 仓库上介绍说：“Timeshift 通过定期递增的文件系统快照来保护你的系统。这些快照可以在日后用于数据恢复，以撤销某些对文件系统的修改。”\n  Kup ：一个能够帮助用户备份它们的文件到 USB 驱动器上的备份解决方案，但它也可以用于执行网络备份。它的 GitHub 仓库上介绍说：”当插入你的外部硬盘时，Kup 将自动启动并复制你的最新的修改。“\n  How to make a disk image and restore from it later?/Moving entire Linux installation to another drive\nIt\u0026rsquo;s Clonezilla Live: http://clonezilla.org/\nThe tutorial for Clonezilla can be found here.\nEasy backup/restore of installed system?\nYes you can use remastersys for that.You can see a complete tutorial here\n清理系统 删除不再需要的包 $ sudo apt autoremove APT cache # see the size of this cache $ sudo du -sh /var/cache/apt # remove only the outdated packages $ sudo apt-get autoclean # delete apt cache in its entirety $ sudo apt-get clean apt-get 和软件中心下载的软件包一般放在 /var/cache/apt/archives/ 目录，一般都安装在 /usr/\nJournal logs # check the log size $ journalctl --disk-usage # clear the logs that are older than a certain days $ journalctl --vacuum-time=3d Thumbnails cache # check the size of thumbnail cache $ du -sh ~/.cache/thumbnails $ rm -rf ~/.cache/thumbnails/* Duplicate files Find and remove duplicate files：You can use a GUI tool like FSlint or a command line tool like FDUPES for this task\nOld Linux kernels Remove old Linux kernels\n# List all installed Linux kernels $ sudo dpkg --list \u0026#39;linux-image*\u0026#39; $ apt-get remove linux-image-VERSION 清理 Snap 与 snap 有关的系统文件都存放在 /var/lib/snapd 目录下。根据你所安装的 Snap 包的数量，这个目录的大小可能在几 GB。\n$ sudo du -sh /var/lib/snapd 根据设计，Snap 至少会在你的系统上保留一个你所安装的软件包的旧版本。你可以通过使用 Snap 命令看到这种行为：\n$ snap list --all 你应该看到同一个软件包被列了两次，而且版本和修订号都不同。\n为了释放磁盘空间，你可以删除额外的软件包版本。你怎么知道要删除哪一个呢？你可以看到，这些较旧的软件包被标记为“禁用”。\n#!/bin/bash # Removes old revisions of snaps # CLOSE ALL SNAPS BEFORE RUNNING THIS set -eu snap list --all | awk \u0026#39;/disabled/{print $1, $3}\u0026#39; | while read snapname revision; do snap remove \u0026#34;$snapname\u0026#34; --revision=\u0026#34;$revision\u0026#34; done 命令行技巧 Bash 快捷键 编辑命令\n Ctrl + a ：移到命令行首 Ctrl + e ：移到命令行尾 Ctrl + f ：按字符前移（右向） Ctrl + b ：按字符后移（左向） Alt + f ：按单词前移（右向） Alt + b ：按单词后移（左向） Ctrl + xx：在命令行首和光标之间移动 Ctrl + u ：从光标处删除至命令行首 Ctrl + k ：从光标处删除至命令行尾 Ctrl + w ：从光标处删除至字首 Alt + d ：从光标处删除至字尾 Ctrl + d ：删除光标处的字符 Ctrl + h ：删除光标前的字符 Ctrl + y ：粘贴至光标后 Alt + c ：从光标处更改为首字母大写的单词 Alt + u ：从光标处更改为全部大写的单词 Alt + l ：从光标处更改为全部小写的单词 Ctrl + t ：交换光标处和之前的字符 Alt + t ：交换光标处和之前的单词 Alt + Backspace：与 Ctrl + w 类似，分隔符有些差别  重新执行命令\n Ctrl + r：逆向搜索命令历史 Ctrl + g：从历史搜索模式退出 Ctrl + p：历史中的上一条命令 Ctrl + n：历史中的下一条命令 Alt + .：使用上一条命令的最后一个参数  控制命令\n Ctrl + l：清屏 Ctrl + o：执行当前命令，并选择上一条命令 Ctrl + s：阻止屏幕输出 Ctrl + q：允许屏幕输出 Ctrl + c：终止命令 Ctrl + z：挂起命令  Bang (!) 命令\n !!：执行上一条命令 !blah：执行最近的以 blah 开头的命令，如 !ls !blah:p：仅打印输出，而不执行 !$：上一条命令的最后一个参数，与 Alt + . 相同 !$:p：打印输出 !$ 的内容 !*：上一条命令的所有参数 !*:p：打印输出 !* 的内容 ^blah：删除上一条命令中的 blah ^blah^foo：将上一条命令中的 blah 替换为 foo ^blah^foo^：将上一条命令中所有的 blah 都替换为 foo  你可能不知道的SHELL Shell也叫做命令行界面，它是*nix操作系统下用户和计算机的交互界面。Shell这个词是指操作系统中提供访问内核服务的程序。\n这篇文章向大家介绍Shell一些非广为人知、但却实用有趣的知识，权当品尝shell主食后的甜点吧。\n科普\n先科普几个你可能不知道的事实：\n  Shell几乎是和Unix操作系统一起诞生，第一个Unix Shell是肯·汤普逊（Ken Thompson）以Multics上的Shell为模范在1971年改写而成，并命名Thompson sh。即便是后来流行的bash（shell的一种变体），它的年龄实际上比当前流行的所有的Linux kernel都大，可谓在Linux系统上是先有Shell再有Kernel。\n  当前绝大部分*nix和MacOS操作系统里的默认的Shell都是bash，bash由Brian Fox在1987年创造，全称Bourne Again shell ( bash)。\n  你或许听说除了bash之外，还有Bourne shell ( sh)，Korn shell ( ksh)，C shell （包括 csh and tcsh），但是你知道这个星球上一共存在着大约50多种不同的shell么？想了解他们，请参考 http://www.freebsd.org/ports/shells.html。\n  一些强大的命令\n  在命令行前加空格，该命令不会进入history里。\n  ctrl-x e\n快速启动你的默认编辑器（由变量$EDITOR设置）。\n  为什么说 zsh 是 shell 中的极品？ 色彩高亮\n并不是传统基于正则表达式的色彩高亮，而是真的会判断你输入的是啥的色彩高亮。\n比如一个主题白色代表普通命令或者程序，红色代表错误命令，青色的代表内建命令或者 alias （echo 和 ls ），这些都不是正则判断出来的，是真的去检查的。非零的错误码（上一条命令错误），也可以高亮显示。\n命令提示\n注意，命令提示和补全是两个完全不同的系统，很多时候提示比补全更有用。你输入命令，后面就用灰色给你提示命令的参数，而且是随着你动态输入完每一个字母不断修正变化。\n这个命令提示是基于你的历史命令数据库进行分析的，随着你输入的命令越来越多，提示将会越来越准确和顺手。\n如果你觉得它提示的正确，你可以 CTRL+F 表示采纳，后面就会自动帮你一次性全部输入完了。\n智能补全\n缩写路径补全：\n$ cd /v/w/h 敲一个TAB\n$ cd /var/www/html/ 补全目录、命令参数补全连敲两次TAB进入选择模式，除了 tab/shift+tab 可以前后切换外，你还可以使用光标键上下左右移动。回车表示确认选择，用 CTRL+G 表示退出。\n快速跳转\n输入 cd 后面加一个减号后，按一次 tab 马上就列出本次登陆后去过的最近几次路径，接着根据下面的提示输入数字按回车就过去了，比如输入：\n$ cd -5 \u0026lt;回车\u0026gt; 当然你还可以不输入数字，而是再按一次 tab 进入选择模式，上下键或者 ctrl+n/p 来选择，回车确认，ctrl+g 返回。\n自动跳转\n敲入 z 命令，列出了自从我开始用zsh进入过的目录和他们的权重，进入次数越多，权重越大。z 后面加一个关键词就能跳转到所有匹配的历史路径中权重最高的那个了。空格分隔多个关键字，z会先匹配出第一个来，然后再匹配第二个\u0026hellip;\n使用：“z -l foo\u0026quot; 可以列出包含 foo 的所有历史路径。\n# 按下ALT+O 就执行 cd .. 命令 bindkey -s \u0026#39;\\eo\u0026#39; \u0026#39;cd ..\\n\u0026#39; # 按下 ALT+; 就执行 ls -l 命令 bindkey -s \u0026#39;\\e;\u0026#39; \u0026#39;ls -l\\n\u0026#39; 热键绑定\nzsh 里面使用 bindkey 命令可以设置一系列热键，用来运行某一个 zsh 内部命令或者某个 shell 命令。\n应该知道的LINUX技巧 首先，我想告诉大家，在Unix/Linux下，最有效率技巧的不是操作图形界面，而是命令行操作，因为命令行意味着自动化。\n日常\n  请man bash后查找Readline Key Bindings一节来看看bash的默认热键，比如：Alt-. 把上一次命令的最后一个参数打出来，而Alt-* 则列出你可以输入的命令。\n  回到上一次的工作目录： cd – （回到home是 cd ~）\n  pstree -p 可以帮你显示进程树。\n  使用 pgrep 和 pkill 来找到或是kill 某个名字的进程。 (-f 选项很有用).\n  通过 \u0026lt;(some command) 可以把某命令当成一个文件。示例：比较一个本地文件和远程文件 /etc/hosts： diff /etc/hosts \u0026lt;(ssh somehost cat /etc/hosts)\n  在 bash中，使用重定向到标准输出和标准错误。如： some-command \u0026gt;logfile 2\u0026gt;\u0026amp;1。\n  使用 man ascii 来查看 ASCII 表。\n  系统调试\n  如果你想知道磁盘、CPU、或网络状态，你可以使用 iostat, netstat, top (或更好的 htop), 还有 dstat 命令。你可以很快地知道你的系统发生了什么事。关于这方面的命令，还有iftop, iotop等。\n  要了解内存的状态，你可以使用free和vmstat命令。具体来说，你需要注意 “cached” 的值，这个值是Linux内核占用的内存。还有free的值。\n  如果你要找到哪个socket或进程在使用网络带宽，你可以使用 iftop 或 nethogs。\n  如果你要抓网络包的话，试试 wireshark 或 tshark。\n  了解 strace 和 ltrace。这两个命令可以让你查看进程的系统调用，这有助于你分析进程的hang在哪了，怎么crash和failed的。你还可以用其来做性能profile，使用 -c 选项，你可以使用-p选项来attach上任意一个进程。\n  了解用ldd命令来检查相关的动态链接库。注意：ldd的安全问题\n  使用gdb来调试一个正在运行的进程或分析core dump文件。参看我写的《GDB中应该知道的几个调试方法》\n  学会到 /proc 目录中查看信息。这是一个Linux内核运行时记录的整个操作系统的运行统计和信息，比如： /proc/cpuinfo, /proc/xxx/cwd, /proc/xxx/exe, /proc/xxx/fd/, /proc/xxx/smaps.\n  如果你调试某个东西为什么出错时，sar命令会有用。它可以让你看看 CPU, 内存, 网络, 等的统计信息。\n  使用 dmesg 来查看一些硬件或驱动程序的信息或问题。\n  powerline-shell 不想每次都安装 zsh 与 ohmyzsh？\n$ pip install powerline-shell Add the following to your .bashrc file:\nfunction _update_ps1() { PS1=$(powerline-shell $?) } if [[ $TERM != linux \u0026amp;\u0026amp; ! $PROMPT_COMMAND =~ _update_ps1 ]]; then PROMPT_COMMAND=\u0026#34;_update_ps1; $PROMPT_COMMAND\u0026#34; fi 默认的话，路径会完整显示，会很长\ngenerate the default config at this location using:\n$ mkdir -p ~/.config/powerline-shell \u0026amp;\u0026amp; \\ powerline-shell --generate-config \u0026gt; ~/.config/powerline-shell/config.json Segment Configuration\n{ \u0026#34;segments\u0026#34;: [ \u0026#34;virtual_env\u0026#34;, \u0026#34;username\u0026#34;, \u0026#34;hostname\u0026#34;, \u0026#34;ssh\u0026#34;, \u0026#34;cwd\u0026#34;, \u0026#34;git\u0026#34;, \u0026#34;hg\u0026#34;, \u0026#34;jobs\u0026#34;, \u0026#34;root\u0026#34; ], + \u0026#34;cwd\u0026#34;: + { + \u0026#34;max_depth\u0026#34;: 1 +\t} } 检测硬盘坏道和坏块 硬盘坏道分为物理坏道和逻辑坏道。\n 物理坏道：就是硬盘实体有坏的地方，物理坏道推荐换硬盘，当然也有办法重新分区来隔离坏道，不过可能也用不久，所以不推荐。 逻辑坏道：是磁盘磁道上面的校验信息（ECC）跟磁道的数据对不上号所致。出现这一故障的原因，通常都是因为一些程序的错误操作或是该处扇区的磁介质开始出现不稳定的先兆。物理坏道也是逻辑坏道产生的一种原因。  发现 dmesg：当有硬盘坏道时，通常在dmesg输出的信息中会有 Buffer I/O Error，所以经常检查dmesg的输出可以及时发现是否存在硬盘问题。\n检测 通过fdisk 查看显示所有磁盘或闪存的信息\n$ sudo fdisk -l /dev/sd* 使用 badlocks检查 linux 硬盘上的坏道/坏块\n$ sudo badblocks -s -v /dev/sdb \u0026gt; badsectors.txt 修复 查看上述分区检查出来的坏道信息\n$ tail -f badsectors.txt 先备份数据再修复磁盘。硬盘在使用时不能修复，否则可能存在写并发的问题，所以修复前需要umount对应分区,或使用 Live CD\n$ sudo umount MountPoint umount 分区成功后，修复命令如下，其中-w表示写入修复的，后面是结束（END）和开始（START）块号，注意END在前，START在后。\n$ sudo badblocks -s -w /dev/sdb 205971590 205971595 修复后再次检查\n$ sudo badblocks -s -v /dev/sdb 205971590 205971595 屏蔽 执行e2fsck（针对 ext2/ext3/ext4 文件系统）或fsck命令，命令中还需要用到 badsectors.txt 文件和设备文件。\n# for ext2/ext3/ext4 $ sudo e2fsck -l badsectors.txt /dev/sdb # others $ sudo fsck -l badsectors.txt /dev/sdb 如何探索 從「指令」找到「使用說明」\n找使用說明\n$ man -f ls 閱讀使用說明\n$ man ls $ man 1 ls # 若是「bash」內建的指令，則是可以使用「help」 $ help if 上面的「man 1 ls」，「1」指的是「Manpage Sections」。\n執行下面指令可以看到各個「Section」的簡介。\n$ whatis intro 然後分別執行下面的指令，可以閱讀更詳細的說明\n$ man 1 intro $ man 2 intro $ man 3 intro $ man 4 intro $ man 5 intro $ man 6 intro $ man 7 intro $ man 8 intro 從「指令」找到「所屬套件」\n先透過「whereis」來找到「ls」所在的確切路徑。\n$ whereis ls ls: /bin/ls 然後根據這個結果，再執行下面的指令\n$ rpm -qf /bin/ls $ dpkg -S /bin/ls coreutils-8.32-1.2.x86_64 找「已安裝套件」的「檔案列表」\n$ rpm -ql coreutils $ dpkg -L coreutils Transfer files between Linux and Android  Connect Using USB Cable Apps  KDE Connect/GSConnect Android File Transfer AirDroid   Bluetooth  Xorg vs Wayland X即X11、X Window System，是用于在类UNIX的操作系统上的位图显示的窗口系统，提供了GUI环境的基本框架。X由X.Org Foundation维护，遵守MIT协议，当前参考实现为X.Org Server。在架构方面，X使用了C/S模型，客户端和服务器可以在同一个机器上，也可以在不同的机器上，X作为Server为应用程序这个Client提供显示和I/O服务。\nWayland是一个显示服务协议，服务端为Wayland Compositor，把X的X Server和Compositor合二为一，旨在替换X，作为类Unix操作系统上更现代、简介的窗口系统，遵守MIT协议，提供了Wayland Compositor的参考C语言实现Weston。\n时至今日，原本在X Server中做的事很多已被移到kernel或者单独的库中，因此X Server就显得比较累赘了。Wayland在架构上去掉了这个中间层，将compositor作为display server，使client与compositor直接通信，从而在灵活性和性能等方面上能够比前辈更加出色。\n查看是否使用 wayland\n$ echo $XDG_SESSION_TYPE Fedora、openSUSE 群讨论\nAppImage的制造者就是其中一个。主要反对的是Wayland声称自己取代X11，但在功能集合上二者完全不在一个层面，后者比前者强太多了。\n而他反对红帽的东西主要是因为红帽一直就是Linux桌面领域比较强权的那个企业，比如早期PulseAudio，比如SystemD，早期多灾多难制造了很多麻烦。\n推出一个新技术，在其不完善的前提下就想着取代旧技术，对于旧技术存在的但新技术不存在的功能却完全不考虑过渡方案，导致技术迭代的过程中用户就一次又一次地被抛弃。尤其和微软对比起来，微软在砍掉很重要的旧功能的时候会有完备的过渡方案，并且对于旧技术依然保持极长的支持周期。不过毕竟Windows 8那时候用户啥反应大家也不是不知道。\n能理解，并且我有时候也会有同样的抱怨，刚学会一个新软件，结果过半年这个软件就被下一次更新抛弃了。AppImage的制造者可能是希望Linux桌面能学习一下微软的一些策略。\n至于为什么反对Flatpak，因为Flatpak是红帽随同Wayland、Gnome一起强推的技术。\nX11 为什么强?\n远程应用，只把远程系统的一个应用程序在本机打开。X下面非常轻松，这就是X功能的一部分。微软的RDP也有同样的功能。并且渲染工作是在发起远程连接的那一段完成的。Wayland下面，没有，完全依赖窗口管理器自己提供的功能，而目前能做到的极限就是个VNC。\n统一的图形库，Xlib，Windows下与之对应的是Win32的UI部分。所有X11的窗口管理器都提供稳定且统一的图形库。在Wayland下面，没有，只能给你push一堆像素点，这就意味着Wayland的应用程序的向下兼容性会比原先X的程序更差。\n统一的窗口管理方式，也是X服务器的标准功能之一，在Windows下面我也不知道对标啥，但只要一个桌面环境用了X，那么应用程序就能确保自己使用一个标准的方法就能管理程序窗口，在Windows下也有同样的保障。Wayland下面，没有，完全依赖窗口管理器暴露的API或者无障碍API。\n接上述，统一的自动化工具实现方式。Windows下面的AutoHotkey不知道多少人用过，在X11下面对应的软件是xdotool。在Wayland下面，没有。ydotool先不说它已经被半弃坑了，最主要的是ydotool调用uinput，只能输入不能获得窗口状态。\n程序的可靠性。在X下面，桌面环境或者渲染器崩溃，应用程序依然健在。并且Windows也是如此的。Wayland下面就不是这么一回事了，至少对于Gnome来讲，shell崩溃就会连着所有程序全部崩溃。KDE的Kwin实现了自己的程序留活机制，但这样便从“所有X11桌面都支持”变成了“只有KDE支持”。\nWayland没有上述所有功能的原因很简单，Wayland不是软件、不是具体实现，它只是个标准，用来显示画面的标准。\n是的，没错，这些本来确实应该交给窗口管理器和渲染器完成。但是，Wayland在不支持这些功能的前提下却表示自己是X11的替代品/延续发展，这就非常地有问题，因为Wayland并没有做到功能上的延续。\n而且，Linux桌面下面的向下兼容性问题极度严重，我不想在这再重复一遍。桌面在用X11的时候，至少还能确保X的功能是一致的，无论跑在什么桌面组合上都不用担心兼容性问题，Wayland的出现，只会让原本离散的桌面更加离散。\nwlroots被称作有希望统一Wayland渲染器的实现方式，可惜在此之前Gnome和KDE已经开始做自己的Wayland实现了，这就意味着从X11转向Wayland，至少分裂成了Gnome、KDE和wlroots，其它桌面会不会突然想不开自己做Wayland实现我们也不知道。而且，三家的分裂，难道还不够折磨吗？\n看看Flameshot的Wayland支持，因为发现Gnome和KDE的运行表现不同，于是放弃了Portals API打算等待wlroots的标准，然而wlroots的标准和Gnome的不互通，于是它的支持计划被延期，无ETA。\n再看看Barrier的Wayland支持，它fork的项目是symless的synergy，这是个商业开源软件。Ubuntu 17.04的时候曾经短暂切换到Wayland，那时候symless就计划开始适配Wayland，之后Ubuntu换回X11，于是Wayland适配计划就被放弃。当一部分软件只跟着一部分发行版走、而不考虑整个Linux桌面生态的时候，Linux桌面便从事实上消失了。接下来便只剩Ubuntu桌面、openSUSE桌面、Fedora桌面了，至少对于ISV来讲是这样的，因为不然的话指数级别的适配难度会把开发者累死。\n我并不是在吹X11诋毁Wayland。只是指出现状。我知道这不是Wayland该做的事情，只是问题是：有谁能来做？\n用户关心的是能不能用上对应的功能，Wayland之后功能少了，那用户就会把锅甩给Wayland。\n这也是AppImage创造者一直反感Wayland的原因之一。\n为什么执行自己的程序要在前面加./ shell是如何运行程序的：如果不给出相对路径，或者绝对路径，那么它会经历下面的查找过程。\n alias中查找 内置命令中查找 PATH中查找  $ cd /temp $ ./ls_bak 等同于\n$ /temp/ls_bak shell通常可以执行两种程序，一种是二进制程序，一种是脚本程序。如果是文本程序，且开头没有指定解释程序，则按照shell脚本处理，如果指定了解释程序，则使用解释程序来解释运行；对于二进制程序，则直接创建新的进程即可。\nLTS There is a new release every 6 months (in April and October), with the version number being year.month (e.g.: 16.04 was released in April 2016). Every two years, the April release is a Long Term Support version.\nLTS releases are the ‘enterprise grade’ releases of Ubuntu and are used the most. An estimated 95% of all Ubuntu installations are LTS releases.\nInterim releases (normal releases) will introduce new capabilities from Canonical and upstream open source projects, they serve as a proving ground for these new capabilities.\n All Interim releases (13.04 and later) are only supported for 9 months. All LTS releases (12.04 and later) are supported for five years (now is ten years) on both the desktop and the server.  Now, support means:\n Updates for potential security problems and bugs (not new versions of software) Availability of Commercial support contracts from Canonical Support by Landscape, Canonical\u0026rsquo;s enterprise oriented server management tool set  Ubuntu releases additional versions of the last LTS between releases—such as 14.04.1, that incorporate all of the updates up to this point. This is called a Point-Release (or sometimes snapshot). Those are released every quarter to half year, as needed.\nThe most important thing (for most people) is how long you get to use an install without having to do a release upgrade. A non-LTS version of Ubuntu only gets updates for 9 months from its release so to stay up-to-date —which is critically important— you need to upgrade twice a year; you need to upgrade through every Ubuntu version…\nConversely an Ubuntu LTS release is supported for 5 years and you can upgrade directly from LTS to LTS. This gives you long-lived, solid base to target and test on that makes it super-easy to release-upgrade when you decide to. It\u0026rsquo;s therefore ideal for mass deployment, high-availability systems, and just people who don\u0026rsquo;t like doing release-upgrades.\n设计shell脚本选项 getopt 写shell脚本的时候，通过while、case、shift来设计脚本的命令行选项是一件比较麻烦的事，因为Unix命令行的选项和参数自由度很高，支持短选项和长选项，参数可能是可选的，选项顺序可能是无所谓的，等等。\nbash下的getopt命令可以解析命令行的选项和参数，将散乱、自由的命令行选项和参数进行改造，得到一个完整的、规范化的参数列表，这样再使用while、case和shift进行处理就简单的太多了。\ngetopt有不同的版本，本文介绍的是它的增强版(enhanced)，相比传统的getopt(也称为兼容版本的getopt)，它提供了引号保护的能力。另外，除了不同版本的getopt，bash还有一个内置命令getopts(注意，有个尾随的字符s)，也用来解析命令行选项，但只能解析短选项。\n要验证安装的getopt是增强版的还是传统版的，使用getopt -T判断即可。如果它什么都不输出，则是增强版，此时它的退出状态码为4。如果输出\u0026quot;\u0026ndash;\u0026quot;，则是传统版的getopt，此时它的退出状态码为0。如果想在脚本中进行版本检查，可以参考如下代码：\n$ getopt -T \u0026amp;\u0026gt;/dev/null;[ $? -ne 4 ] \u0026amp;\u0026amp; { echo \u0026#34;not enhanced version\u0026#34;;exit 1; } \u0026hellip;\n在中文介面下，如何只用英文目錄名稱？  先切到英文介面再重新開機，此時 Fedora 會問你要不要將子目錄換為英文名稱（選 Yes），再切回中文介面重新開機，Fedora 會再問你一次要不要更改子目錄為中文名稱（選 No），收工！ LANG=C xdg-user-dirs-gtk-update # 同意更新 xdg-user-dirs-gtk-update # 保留且不再問 手動修正配置文件~/.config/user-dirs.dirs ,然後在主目錄下創建對應目錄,重啟即可解決.  dd 制作U盘启动盘 $ dd bs=4M if=fileName.iso of=/dev/sdx status=progress \u0026amp;\u0026amp; sync Windows 下用 Rufus 且 dd 写入模式\n为什么 Linux 要用 tar.gz，很少用 7Z 或 ZIP？ 因为 7z 和 zip 压缩格式都不能保留 unix 风格的文件权限，比如解压出个可执行文件要重新 chmod chown 才能恢复正常。而 tar 格式可以。而 tar 本身不提供压缩，无非就是把包括所有文件的內容和权限拼成一个文件而己，所以用另外如 gzip 格式压缩。为什么是 gzip，因为几乎所有 linux 都支持而已。\n置默认编辑器 visudo 等操作会打开默认编辑器，在linux中默认编辑器读取EDITOR环境变量，可通过一下命令设置\nexport EDITOR=nano 可将其加入~/.bashrc文件，使得每次登录都可使用\n$ nano ~/.bashrc export EDITOR=nano $ . ~/.bashrc debian系统提供了一个管理工具来设置默认编辑器\n$ sudo update-alternatives --config editor 有两个相似选项\n /usr/bin/vim.basic /usr/bin/vim.tiny  它们的区别：\nim.basic is just plain vanilla Vim (as you can check with apt-file vim.basic or dpkg -S /usr/bin/vim.basic).\nWhile vim.tiny, as the name implies, is a trimmed-down version of Vim (this question explains it further).\n$ vim.tiny --version 通过Linux系统进入 BIOS $ sudo systemctl reboot --firmware-setup 5 Ways to Check CPU Info in Linux  lscpu /proc/cpuinfo lshw hwinfo dmidecodes hardinfo: gui  exFAT 文件系统\n所谓文件系统，就是文件的储存方式。通过文件系统可以准确找到存储在硬盘中的数据。储存设备都需要指定文件系统，计算机才能读写。\nWindows 的文件系统\n  FAT32：是最老的文件系统，所有操作系统都支持，兼容性最好。但是，它是为 32 位计算机设计的，文件不能超过 232 - 1 个字节，也就是不能超过 4GB，分区不能超过 8TB。\n  NTFS：是 Windows 的默认文件系统，用来替换 FAT32。Linux 下有如下方法创建 NTFS 文件系统\n# gparted $ sudo apt-get install gparted # mkntfs $ sudo apt-get install ntfs-3g $ sudo mkntfs --fast --label myUsbDrive /dev/sdb1 # mkfs $ mkfs.ntfs -f -L DiskLabel /dev/sdb1   exFAT：是 FAT32 的 64位升级版，ex 就是 extended 的缩写（表示\u0026quot;扩展的 FAT32\u0026quot;），功能不如 NTFS，但是解决了文件和分区的大小问题，两者最大都可以到 128PB。\n  Linux 的 exFAT 格式化\n$ sudo mkfs.exfat /dev/sdX1 分区表\n所谓硬盘分区，就是指一块硬盘上面，同时存在多个文件系统。每个文件系统管理的区域，就称为一个分区（partition）。\n分区大小、起始位置、结束位置、文件系统等信息，都储存在分区表里面。\n分区表也分成两种格式：MBR 和 GPT。前者是传统格式，兼容性好；后者更现代，功能更强大。\nLogging in as Root in Ubuntu with Live CD $ sudo passwd root How To Download A Large File Faster From Google Drive? Step 1: Fetching Your File ID\n Open your browser and go to your google drive, open login with the account that has the file you wish to download. Locate the file that you wish to download and select it. Right click the file and click on “get shareable link” You don’t need to copy the entire link here; you only need the file ID that we will be using later.  The link will look like this: https://drive.google.com/file/d/XXXXX/view?usp=sharing\nIn this link, you only need to pay attention to the alphanumeric file ID, displayed by XXXXX here.\nStep 2: Getting an OAuth Code\n Visit OAuth 2.0 Playground by clicking here. On the developer’s webpage, in the “Select \u0026amp; authorize APIs” click on the “Drive API v3” option, and select the: https://www.googleapis.com/auth/drive.readonly option from the available options. Once selected click Authorize APIs button on the bottom right corner of the tab. After you click on the Authorize APIs button you will be transferred to the google account login screen. Select the same google account in which you have your file stored. Allow Google OAuth 2.0 to access your drive if asked. When you get redirected back to the OAuth 2.0 playground screen click on the “Exchange Authorization Code for Tokens” button as shown. Copy the newly generated Access Token and save it on your notepad. You will be needing this in the next step.  Step 3: Downloading The File Using A Command Line Script\n$ curl -H \u0026#34;Authorization: Bearer YYYYY\u0026#34; https://www.googleapis.com/drive/v3/files/XXXXX?alt=media -o ZZZZZ In your command, replace “XXXXX” with the file ID from above, “YYYYY” with the access token from above, and “ZZZZZ” with the file name that will be saved (for example, “myFile.mp4” if you’re downloading an mp4 file).\nPress Enter and let the download begin.\nUSB插槽鬆動怎麼辦  手机  充电宝  笔记本  笔记本  nmcheck.gnome.org nmcheck.gnome.org is not malware. It is the gnome network manager connectivity check (for captive portals/hotspots). Click the link and you will see a single text file with a text in it. It should be \u0026ldquo;NetworkManager is online\u0026rdquo;.\nCheck /etc/NetworkManager/NetworkManager.conf. There probably is a section with this in it:\n[Connectivity] uri=http://nmcheck.gnome.org/check_network_status.txt on Ubuntu 20.04 no [Connectivity]  line like accepted answer in /etc/NetworkManager/NetworkManager.conf.\nBut you can disable the auto connectivity check by:\n Go to Settings app Go to Privacy menu On Connectivity tab, uncheck Connectivity Checking  XDG_TEMPLATES_DIR If you drop any files in \u0026ldquo;Templates\u0026rdquo; folder. Then when you right-click and create a new document, you can select any of these files as a basis for the new file.\nIf you have deleted the folder and need to restore this functionality:\n$ gedit ~/.config/user-dirs.dirs Check that there is a line containing the following - if not, add this line.\nXDG_TEMPLATES_DIR=\u0026quot;$HOME/Templates\u0026quot; 软件的稳定性 软件的稳定性其实往往来源于：足够多的使用者与足够多的反馈跟改进。\nLinux系统，在服务器端的大多数常用软件都有足够多的使用者，所以就足够稳定，由于它在服务器端市场占有率远高于微软，所以服务器端就是比微软稳定，很正常的事。\n在桌面端，市场占用率远低于微软，不稳定也是自然的。\n为什么Linux下命令行程序往往又好用又稳定？是因为用户喜欢装逼吗？不是，因为命令行程序是服务器端跟桌面端通用的，而服务器端程序经过了足够多用户的使用，经过了足够的反馈开发迭代，所以稳定。而图形界面只有桌面用户用，桌面占有率那么低，这些程序往往缺乏足够的测试人力也缺乏足够的开发维护人力，所以并不会非常稳定。\n那么，你要想体验Linux稳定，怎么办？答案就是只使用市场占有率高，用户量大，因而获得了充分测试的软件，这就稳定了。比方说只使用服务器端。或者桌面端只使用最常用的那些，例如终端仿真器，浏览器，输入法，gcc编译器之类，肯定是稳定的。\n你看我就用浏览器，输入法，xterm，screen，编程ide，vim，以及一堆命令行的东西，稳定得很啊，六个月才重启一次电脑，重启的那一次还是因为ubuntu升级。\n如何将Google搜索限制为特定语言的结果 只是想在Google搜索中添加有关语言参数的更全面的答案。\n有4种与语言相关的选项。\nWeb界面语言： hl=\n例： www.google.com/search?q=vilnius\u0026amp;hl=lt\nWeb Interface Language Codes hl=zh-CN Chinese (Simplified) hl=zh-TW Chinese (Traditional) hl=en English hl=ja Japanese 指定语言的页面： lr=lang_\n例： www.google.com/search?q=vilnius\u0026amp;lr=lang_lt\nSearch Language Codes lr=lang_zh-CN Chinese (Simplified) lr=lang_zh-TW Chinese (Traditional) lr=lang_en English lr=lang_ja Japanese 来自指定国家/地区的页面： cr=country\n示例：www.google.com/search?q=vilnius\u0026amp;cr=countryLT 请注意，两个国家/地区代码字符必须大写！否则，Google会忽略该参数（自2017年1月3日起）（即使小写字母对于hl=和都适用lr=lang_）。\n还有另一个参数\u0026ndash; gl=用于搜索结果，因为它们将显示在指定的国家/地区。我尝试对其进行测试，但对我而言，不同参数值的结果没有不同。浏览器或我的Google帐户的某些其他参数/设置可能已过时或覆盖了该设置。\nTwo Options to Recover Your PC With Android If your PC is out of action, you can install a new operating system or run a recovery environment thanks to Android. Two solid options are available:\n ISO 2 USB: Lets you burn an ISO file directly to a USB flash drive over USB-OTG. DriveDroid: Enables you to store bootable ISO files on Android. With the paid version, support for Windows 10 installation images is added.  good practice to avoid using sudo su It is good practice to avoid performing more actions as root than you need to. sudo facilitates this by allowing you to run individual commands as root without having to log in as root and without needing an interactive root shell for tasks you would otherwise not run a shell to do. But sudo su is not a \u0026ldquo;backdoor,\u0026rdquo; it is simply a somewhat less elegant way to do what sudo is designed to allow you to do with sudo -s. Similarly, sudo -i is the more elegant way to achieve what sudo su - would get you: a simulated initial login shell whose environment is like what you would get if you could log in as root on the command line. See man sudo.\nSSHFS: How to Mount Remote File Systems Over SSH SSHFS (SSH File System) is a client for mounting a file system located on a remote machine onto your local system through an SSH connection. Using the SFTP (SSH file transfer protocol), the SSHFS command-line tool mounts a physical or virtual disk locally, allowing file transfer between a local and remote machine.\nThis article demonstrates the installation and usage of SSHFS to mount a remote folder or file system over SSH.\nInstall SSHFS $ sudo apt install sshfs Mount a Remote File System on Linux Step 1: Create Mount Point\nCreate a mount point directory in the mnt folder where the remote file system will be mounted:\n$ sudo mkdir /mnt/\u0026lt;folder name\u0026gt; Step 2: Mount the Remote File System Using SSHFS\nMount the remote file system to the created mount point using the SSHFS tool:\n$ sudo sshfs [-o \u0026lt;options\u0026gt;] \u0026lt;remote user\u0026gt;@\u0026lt;remote host\u0026gt;:/\u0026lt;path to remote directory\u0026gt; /mnt/\u0026lt;folder name\u0026gt;/ Enter the login password when requested if using password authentication. If the remote server uses SSH key authorization, provide the path of the private key. For example:\n$ sudo sshfs -o allow_other,IdentityFile=/home/kb/.ssh/id_rsa ubuntu@131.153.142.254:/home/ubuntu/ /mnt/test/ The allow_other option allows access to users other than root.\nStep 3: Unmount a Remote File System on Linux\nLastly, when finished with the mount point, unmount the remote file system with:\n$ sudo umount /mnt/\u0026lt;folder name\u0026gt; img转化成iso IMG是一种文件归档格式（archive format），主要是为了创建磁盘的映像文件（disk image），它可以用来封装存储整个磁盘（通常指软磁盘，Floppy Disk或Diskette）或整片光盘的内容，使用\u0026quot;.IMG\u0026quot;这个扩展名的文件就是利用这种文件格式来创建的。\n.IMG这个文件格式可视为.ISO格式的一种超集合。由于.ISO只能封存使用ISO9660和UDF这两种文件系统的存储介质，意即.ISO只能拿来封存CD或DVD，因此才发展出了.IMG，它是以.ISO格式为基础另外新增可封存使用其它文件系统的存储介质的能力，.IMG可向后兼容于.ISO，如果是拿来封存CD或DVD，则使用.IMG和.ISO这两种格式所产生出来的内容是一样的。\n将img 转化成iso的有 nrg2iso 或 ccd2iso，分别下载如下：\n$ sudo apt-get install nrg2iso $ sudo apt-get install ccd2iso 使用如下：\n$ nrg2iso image.nrg image.iso $ ccd2iso \u0026lt;.img filename\u0026gt; \u0026lt;.iso filename\u0026gt; HWE The Ubuntu LTS enablement (also called HWE or Hardware Enablement) stacks provide newer kernel and X support for existing Ubuntu LTS releases.\nThe 20.04 LTS HWE Stacks continue to follow Rolling Update Model, as has been in use since 16.04 LTS.\nMicrocode 每当听到有人说“这个问题更新一下微码就好了”，就觉得这个哥哥怎么这么迷人，好像在哪里见过。为了也让自己变成这种迷人的哥哥，我也研究了一下到底什么是微码。\n这里说的是跑在CPU处理器上的微码，不是IBM那群人嘴里说的那个微码。如果你之前没和IBM打过交道那就当这段话不存在。\n计算机体系结构是一层又一层的抽象，典型的比如操作系统对底层硬件的抽象。但鲜有人知的是，操作系统和底层硬件，尤其是CPU之间还存在着几层抽象。什么叫抽象，当然有很多种学术流的解释，但我土气一点的解释就是“不关心”，就是“Don’t care”，就是爱咋地咋地。\n用这个模式套用一下我们熟悉的抽象：操作系统要将数据写入磁盘，它不关心怎么操作磁盘；应用要给某个服务器发个数据包，它也不关心怎么操作网卡。\n回到我们的微码上来。我们现在常见的操作系统都是用C语言编写，它相对于汇编语言来说，也算是一种“高级语言”。编译器会将这种高级语言编译成汇编语言。只要C语言编写时“不关心”汇编指令是啥，那么就是相对汇编语言做了一次抽象。\n马上就到微码了。我们知道汇编指令是执行在CPU上的，那么汇编指令会关心在某个具体型号的CPU上是怎么执行的吗？肯定不会的。汇编的一条ADD指令在80286上可以执行，在最新的Icelake上也能执行，但这两个CPU内部早已发生了天翻地覆的变化，执行ADD的操作已经完全不同了。\n换句话说，就是汇编指令并“不关心”是如何在CPU上执行的。\n操作系统不关心如何操作磁盘和网卡，是因为这些都有对应的设备驱动操心。汇编指令不关心具体如何在CPU中执行，这个就是由微码来操心了。所以用类比的方式，可以把微码类比成汇编指令针对某一型号CPU的驱动。\n同样的汇编指令，会由该型号CPU的微码转成可以跑在该CPU上的微操作（Micro-ops/uops）。这些微操作指导CPU的电路完成汇编指令要求的意图。\n在大家还在编写汇编语言代码的时代，微码为汇编语言的编写提供了方便：\n 只关心汇编逻辑，而不用关心CPU内部电路设计和具体的执行方式 方便设计出新的汇编指令，由微码翻译成具体的执行逻辑，比如循环中“变量自减若大于零则转跳”，可以用一条汇编指令代替，脏活累活都交给微码去干 修复或绕过一些很难修复的处理器数字电路中的Bug  上述第二点也为CISC指令集的实现提供了技术基础。因为不可能所有复杂的指令都是由专门的执行复杂指令的硬件来完成的，也是由简单的数字逻辑模块组合而成的。\n在现代CPU里，是存在专门的将汇编指令翻译成微操作的硬件解码器的。但微码依旧存在（就是CPU微架构图中前端那个Microcode sequencer），它作为一个Lookup Table保存在一块ROM中，用来解码复杂的指令，比如浮点运算的指令等。一般是硬件解码器解码得比较快，而用微码解码会比较慢。\n理论上，如果你能更改某一个处理器的微码，那么经它翻译的指令可以变成任意其他的指令。因为它关心指令如何在CPU电路中执行。所以现在升级微码主要是用来解决处理器的稳定和安全性的问题。\n当然你也可以用它模拟自己没有的汇编指令，比如AVX系列，我只要在看到AVX512的汇编之后，把它翻译成两个“SIMD256”或者四个“SIMD128”指令就好了。\n看到这里，你给自己就又加了一层微码的buff。最后贴心地推荐一篇详细说明Microcode怎么执行的文章：Microprocessor Microcode Simple Example\n安装/更新微码 微码就是由 Intel/AMD 提供的 CPU 固件。Linux 的内核可以在引导时更新 CPU 固件，而无需 BIOS 更新。处理器的微码保存在内存中，在每次启动系统时，内核可以更新这个微码。这些来自 Intel/AMD 的微码的更新可以去修复 bug 或者使用补丁来防范 bug。\n查看当前的微码状态：\n$ sudo dmesg | grep microcode 使用包管理器\n$ sudo apt install intel-microcode 必须重启以激活微码更新：\n$ sudo reboot 手动\n只有在你的 CPU 制造商建议这么做的时候，才可以使用下列的方法去更新/安装微码，除此之外，都应该使用上面的方法去更新。大多数 Linux 发行版都可以通过包管理器来维护、更新微码。使用包管理器的方法是经过测试的，对大多数用户来说是最安全的方式。\nAutomatic Light / Dark Mode for GNOME, this shell extension exists: Night Theme Switcher\n将du的输出按文件大小排序 sdu () { du -sk $@ | sort -n | awk \u0026#39; BEGIN { split(\u0026#34;K,M,G,T\u0026#34;, Units, \u0026#34;,\u0026#34;); FS=\u0026#34;\\t\u0026#34;; OFS=\u0026#34;\\t\u0026#34;; } { u = 1; while ($1 \u0026gt;= 1024) { $1 = $1 / 1024; u += 1 } $1 = sprintf(\u0026#34;%.1f%s\u0026#34;, $1, Units[u]); sub(/\\.0/, \u0026#34;\u0026#34;, $1); print $0; }\u0026#39; } 改善触摸板体验 众所周知，Macbook 的触摸板是体验最好的，很多果粉都吹 Macbook 的触摸板用了之后“就不再想要去用鼠标”。\n有一群人搞了一个项目：「Linux Touchpad like Macbook Update」。顾名思义，就是“把 Linux 的触摸板搞的像 Macbook 一样”。\n这个项目的主要作用就是针对现在 Linux 下对于触摸板管理的相关驱动进行一些修改和优化，以提升触摸的使用体验，尤其是包括“多点触摸”等等等。\n$ sudo add-apt-repository ppa:p12/xorg-gestures $ sudo apt-get update 当然，尽管如此，我们也只是在驱动层面改善了触摸，在应用层面还需要另一个工具的帮忙：touchegg\n安装完毕之后你的三指上滑和三指下滑都可以正常使用了，譬如三指上滑是窗口最大化，三指下滑是窗口最小化。\nReset lost root password 警告： 攻击者都可以使用上述方法修改系统，要保证系统安全，请限制物理上的访问，或者使用全磁盘加密。\n使用 LiveCD 通过 LiveCD 可以使用好几种方法：chroot并且使用passwd命令或者擦除密码域条目。任何Linux的LiveCD都可以使用，chroot时它必须匹配已经安装的架构类型。这里仅介绍 chroot 方式，因为这个方法更不容易出错。\n  启动LiveCD，挂载根文件系统.\n  然后通过下列命令重置密码：\n$ passwd --root MOUNT_POINT USER_NAME   卸载根文件系统。\n  重启，记下你的密码。\n  用 Bash 作为 Init   将 init=/bin/bash 内核参数加入启动加载器的启动项.\n  启动后可以看到 Bash 提示符。\n  根文件系统应该是只读挂载，需要以可读写模式重新挂载：\nmount -n -o remount,rw /   用 passwd 创建新的管理员密码。\n  通过 reboot -f 重启，不要再次忘记你的密码。\n  注意： 使用此法时有的键盘不能被初始系统正确加载，你可能不能在bash提示符后输入任何东西。如果出现这种情况，你不得不使用其他方法。\nHow to block internet access to certain programs on Linux The solution for me happened to be straight forward.\n  Create, validate new group; add required users to this group:\n  Create: groupadd no-internet\n  Validate: grep no-internet /etc/group\n  Add user: useradd -g no-internet username\nNote: If you\u0026rsquo;re modifying already existing user you should run: usermod -a -G no-internet userName check with : sudo groups userName\n    Create a script in your path and make it executable:\n  Create: nano /home/username/.local/bin/no-internet\n  Executable: chmod 755 /home/username/.local/bin/no-internet\n  Content:\n#!/bin/bash sg no-internet \u0026quot;$@\u0026quot;     Add iptables rule for dropping network activity for group no-internet:\n  iptables -I OUTPUT 1 -m owner --gid-owner no-internet -j DROP\nNote: Don\u0026rsquo;t forget to make the changes permanent, so it would be applied automatically after reboot. Doing it, depends on your Linux distribution.\n    Check it, for example on Firefox by running: no-internet \u0026quot;firefox\u0026quot;\n  In case you would want to make an exception and allow a program to access local network:\n iptables -A OUTPUT -m owner --gid-owner no-internet -d 192.168.1.0/24 -j ACCEPT iptables -A OUTPUT -m owner --gid-owner no-internet -d 127.0.0.0/8 -j ACCEPT iptables -A OUTPUT -m owner --gid-owner no-internet -j DROP  NOTE: In case of spawning the rules will be maintained. For example, if you run a program with no-internet rule and that program will open browser window, still the rules will be applied.\nHow does Ubuntu make money? Firstly a lot of people work on Ubuntu in their free time (many of them programming, but also those of here for instance answering people\u0026rsquo;s questions). Also some people donate to Ubuntu.\nHowever there is more to the story. Canonical Ltd. is a private company that created and continues to pay for Ubuntu. We know Canonical hadn\u0026rsquo;t been making a profit, but Canonical was initially founded by multi-millionaire Mark Shuttleworth which meant it didn\u0026rsquo;t have to focus on making money right away.\nHowever Canonical is now looking towards to making Ubuntu profitable. (After all, they have 600+ employees to pay every month!) There are some indications this has been successful. Their key revenue streams offer services around Ubuntu:\n Support services (mostly to business) alongside which they sell Landscape Contracting services to businesses (for instance working with OEMs such as Dell, or helping Google with Chrome OS). As Ubuntu makes its way onto mobile phones and TVs then this will grow. Ubuntu Software Centre\u0026rsquo;s paid section (Canonical takes a cut of purchases) The Canonical Store (selling physical Ubuntu branded items) - discontinued Closed-source projects wishing to use Launchpad.net can purchase a license Ubuntu One (online file storage and synchronization service) and Music Store (selling music from within Ubuntu) - discontinued. Amazon referrals. When you search the Ubuntu Dash, you may see Amazon products (unless you have turned it off). Ubuntu takes a cut of these.[ref]  All of these are areas that Canonical hopes will grow.\n启用 TRIM 当我在运行 Linux 的计算机上安装我的第一块固态驱动器（SSD）后，我开始探索如何用好它们。SSD 在操作方式上与传统磁性驱动器不同，并且它们需要在软件上另行处理以达到功能优化。\n在传统磁盘驱动器上，删除时所删除的文件不会从磁盘中完全删除。这就是为什么你可以恢复已删除的文件的原因。基本上，文件系统仅引用磁盘上文件的位置，并且当文件被删除时，该引用被擦除，以允许你在这些空间中写入新数据覆盖原来的数据。然而，对于 SSD，新数据只能写在驱动器上完全新的或已擦除的单元上。因为必须在写入之前清除空间，如果在写入文件时尚未有足够的可用空间，则必须首先擦除该空间。这可能会对性能产生负面影响。\n如果操作系统在写入新数据之前就擦除了未使用的空间，而不是在写入时同时进行擦除，则可以提高文件保存性能。这种做法就是 TRIM。 TRIM 命令本质上允许你的操作系统告诉驱动器哪些区域的数据不再使用，以便擦除它们，加快驱动器将来的写入，可以 SSD 的用户提供更佳的体验。\n在 Linux 中，fstrim 提供此功能，它可以为写入新数据而准备驱动器，并延长驱动器的使用寿命。由于在我使用的 Linux 发行版上 SSD 的 trim 不是自动的，所以必须去调度该操作，否则 SSD 的性能会随着时间的推移而降低。\n为了在驱动器上运行 fstrim，驱动器本身以及其上的文件系统必须支持 TRIM。TRIM SSD 可以在命令行或 cron 任务中手动完成。作为超级用户（使用 su 或 sudo），运行 fstrim / -v 以完成手动 trim，或者设置 cron 任务以在计算机未使用时定期为你运行此命令。对于 fstrim 的完整选项列表请参考它的 man 手册。\n注：可以定期执行fstrim命令，但是不建议在mount / fstab 中使用discard 选项。因为这个选项要求SSD每次删除文件都进行trim操作，比较耗资源，尤其是在文件操作很频繁的时候。所以可以考虑用cron来定期trim。\n硬件支持根据使用的驱动器接口类型如 PCI、ATA、SCSI 还是 SD/MMC 而有所不同。你需要咨询你的 Linux 供应商以了解你的特定发行版是如何支持 TRIM 的。\n例如，红帽提供以下 SSD 磁盘指南。“性能随着所使用的块数接近磁盘容量而降低，性能影响程度因供应商而异，但是所有设备都会遇到一些性能降低。为了解决性能降低问题，主机系统（例如 Linux 内核）使用丢弃请求以通知存储器给定范围的块不再使用。”\nDebian wiki 提供了 SSD 使用的一些基本注意事项：使用 Linux 3.2 或更高版本内核，使用 SSD 的最新固件，使用 EXT4 文件系统，并且“在正常工作负载下有足够的 DRAM 用来操作而不用使用交换空间“。\nreserve 5% of the space By default, ext2/3/4 filesystems reserve 5% of the space to be useable only by root. This is to avoid a normal user completely filling the disk which would then cause system components to fail whenever they next needed to write to the disk.\nYou can see the number of reserved blocks (and lots of other information about the filesystem) by doing:\n$ sudo tune2fs -l /dev/sda8 For a /home partition, it is probably safe to set the reserved fraction to zero:\n$ sudo tune2fs -m 0 /dev/sda8 Which should make an additional ~5GB available.\nChange Partition Label e2label or tune2fs The commands e2label or tune2fs used for changing label of ext2, ext3 and ext4 type partitions.\n# e2label /dev/sda1 ROOT OR # tune2fs –L ROOT_PART /dev/sda1 Here, ROOT and ROOT_PART are the labels to be added to /dev/sda1 which is ext4 formatted partition.\nntfslabel The ntfslabel command used for changing label of NTFS partitions.\n# ntfslabel /dev/sda5 NTFS_DIR mkswap The mkswap command used for changing label of SWAP partition.\nAfter unmounting the filesystem, following command needs to be executed to change the label of swap partition.\n# mkswap -L SWAP_PART /dev/sda5 Where, /dev/sda5 is the SWAP formatted partition.\nexfatlabel The exfatlabel command used for changing the label of exFAT formatted partition.\n# exfatlabel /dev/sda3 EX_PART Disable usb automount $ gsettings get org.gnome.desktop.media-handling automount $ gsettings set org.gnome.desktop.media-handling automount false or use dconf-editor\nCreate an ISO File   Mkisofs\n$ mkisofs -o [filename.iso] [ directory_path] $ mkisofs –o backup.iso /home/tin/Documents/backup   dd\n$ dd if=[source] of=[target.iso] $ sudo dd if= /dev/sdb of= diskimage.iso   Brasero\n$ sudo apt-get install brasero   keychain Squeezing the last drop of convenience out of ssh-agent: Keychain will allow to reuse an ssh-agent between logins, and optionally prompt for passphrases each time the user logs in.\n$ sudo apt install keychain $ vi ~/.bashrc . ~/.keychain/${HOSTNAME}-sh $ keychain ~/.ssh/id_rsa Default .bashrc You don\u0026rsquo;t need to trust this random gist on Github. Heck, it\u0026rsquo;s ~10 years old. Don\u0026rsquo;t you want the latest default - or the default that\u0026rsquo;s specific to your version of Ubuntu?\nYou can find the \u0026ldquo;skeleton\u0026rdquo; file used to initialize new users in ls -a /etc/skel.\nTo copy someone else\u0026rsquo;s comment: just run cp /etc/skel/.bashrc ~/ to copy from that \u0026ldquo;skeleton\u0026rdquo; to your current bashrc.\nuse \u0026lsquo;cp\u0026rsquo; to exclude a specific directory $ shopt -s extglob $ echo images/* images/004.bmp images/033.jpg images/1276338351183.jpg images/2252.png $ echo images/!(*.jpg) images/004.bmp images/2252.png regenerate initramfs To create/recreate/update the initramfs file means to update the initrd.img-* ramdisk files in /boot.\nNote: I prefer to create a totally fresh version by using the -c option, instead of just updating the existing file by using the -u option.\nThe proper command would be:\n$ sudo update-initramfs -c -k $(uname -r) This will create a fresh initrd.img-* file for your currently booted version of Ubuntu.\nHowever, if you can\u0026rsquo;t boot to the current version of Ubuntu, you may have to modify this command, and by booting to an older version of Ubuntu, you can do it this way:\nsudo update-initramfs -c -k 5.11.0-22-generic where the 5.11.0-22-generic part should be replaced with the version of the desired boot kernel.\nTo get more detailed information, type:\n$ man update-initramfs extract a specific file from a tar archive Yes, just give the full stored path of the file after the tarball name.\nExample: suppose you want file etc/apt/sources.list from etc.tar:\n$ tar -xf etc.tar etc/apt/sources.list repair grub When you install Windows, Windows assumes it is the only operating system (OS) on the machine, or at least it does not account for Linux. So it replaces GRUB with its own boot loader. What you have to do is replace the Windows boot loader with GRUB. I\u0026rsquo;ve seen various instructions for replacing GRUB by mucking around with GRUB commands or some such, but to me the easiest way is to simply chroot into your install and run update-grub. chroot is great because it allows you to work on your actual install, instead of trying to redirect things here and there. It is really clean.\nDNS缓存 使用以下命令来检查其状态。\n$ sudo systemctl status systemd-resolved 运行以下命令来检查DNS缓存统计信息。\n$ sudo systemd-resolve --statistics 运行以下命令来清除Ubuntu上的DNS缓存。\n$ sudo systemd-resolve --flush-caches DNS刷新命令不会清除缓存命中和未命中统计信息。 如果要清除所有缓存统计信息，则必须重新启动systemd解析的服务。\n$ sudo systemctl restart systemd-resolved change my username Unix-like operating systems decouple the user name from the user identity, so you may safely change the name without affecting the ID. All permissions, files, etc are tied to your identity (uid), not your username.\nTo manage every aspect of the user database, you use the usermod tool.\nTo change username (it is probably best to do this without being logged in):\nsudo usermod -l newUsername oldUsername This however, doesn\u0026rsquo;t rename the home folder.\nTo change home-folder, use\nsudo usermod -d /home/newHomeDir -m newUsername after you changed the username.\nFor instance, you could logout, drop to a console (Ctrl+Alt+F1), and sudo su - to become true root (as opposed to sudo -s, where $HOME is still /home/yourname.) Maybe you also have to kill some still running processes from this user first. To do so, enter ps -u username, look for the matching PID and kill them by kill PID-number.\nUpdate: as arrange mentioned, some files may reference your old home directory. You can either keep a symlink for backward compatibility, e g ln -s /home/newname /home/oldname or you can change the file contents with sed -i.bak 's/*oldname*/*newname*/g' *list of files* It creates a backup for each file with a .bak extension.\nSome additional information for not so experienced users like me: As I only have ONE user account (administrator), it would not let me change the username (\u0026ldquo;you are already logged in\u0026rdquo; was the response in TTY1 (Ctrl+Alt+F1). To get around this:\n  Login with your old credentials and add a new user, e.g. \u0026ldquo;temporary\u0026rdquo; in TTY1:\nsudo adduser temporary set the password.\n  Allow the temporary user to run sudo by adding the user to sudo group:\nsudo adduser temporary sudo   Log out with the command exit.\n  Return to tty1: Login with the \u0026lsquo;temporary\u0026rsquo; user account and password. Change your username and folder as mentioned above. exit (until you get the login prompt)\n  Go back to TTY7 (Ctrl+Alt+F7) to login on the GUI/normal desktop screen and see if this works.\n  Delete temporary user and folder:\nsudo deluser temporary sudo rm -r /home/temporary   Test Network Speed $ sudo apt install speedtest-cli $ speedtest 蓝牙与WiFi信号干扰 蓝牙和WIFI干扰？把蓝牙掐死就行了\n蓝牙和Wi-Fi信号干扰问题可能你也遇到过，两者主要都是使用2.4GHz频段，导致同时开启时，蓝牙的数据吞吐量会急剧下降，配对设备困难，Wi-Fi间歇性中断，网络受到限制。目前基本没什么办法可以根治这个问题，但你可以下面的方案临时帮你解决一些问题。本文提供了4种方法，可以参考下。\n方法1：连接至5GHz无线网络\n既然知道了问题出在频段冲突上，那么可以考虑购买一个双频（2.4GHz + 5GHz）路由器，并连接至5GHz的Wi-Fi网络。该方法可以彻底解决干扰问题，但银子也是必不可少的。\n方法2：更换Wi-Fi信道\n以TP-Link路由器为例，登录路由器Web管理页，在无线设置-\u0026gt;基本设置中找到信道选项，将其改为1、6、11中的任何一个。这些为2.4GHz的不重叠传输信道，相较于其他信道更稳定一些。\n方法3：开启网卡蓝牙共存功能\n在近几年生产的无线网卡中，都支持蓝牙共存功能，方法是在网络适配器属性的高级选项卡中，找到Bluetooth Collaboration或Bluetooth Coexistence Mode（名称可能有所不同），将其设为启用（Enable）。Windows会自动重新连接Wi-Fi，干扰蓝牙的情况也会有所缓解。\n对于 Linux\n$ lspci -knn | grep Net -A3; lsusb ... Kernel driver in use: ath9k Kernel modules: ath9k ... $ sudo tee /etc/modprobe.d/ath9k.conf \u0026lt;\u0026lt;\u0026lt; \u0026#34;options ath9k btcoex_enable=1\u0026#34; 方法4：远离干扰源\n将蓝牙终端与路由器、微波炉、无绳电话机等使用2.4GHz频段的设备隔开使用。\n然而蓝牙与WIFI干扰确实是头疼的问题：蓝牙鼠标会受到WIFI干扰经常反应迟缓，而蓝牙音箱则会导致WIFI断网，经常上传失败的绝望。。。。\n总之，无线信道的改进还在进行着。。。\nRAM \u0026amp; VRAM VRAM as RAM  MTD vramfs  RAM as VRAM Basically the answer is the operating system threats the whole memory pool for the graphics card, and ram as a virtual memory.\nVirtual memory is paged two ways through a partition like swap, or a image file like in windows.\nThe virtual memory then maps the references to memory when you call int* or \u0026amp;memory. To a physical address on your ram or vram depending on where it\u0026rsquo;s meant to go.\nThe game cannot force the kernel or operating system to allocate virtual memory to a certain place.\nThe kernel will dynamically decide where everything goes, and will write to your hard drive if you overflow the current physical limit.\nThere are tons of articles on virtual memory on windows, bsd and linux. Mac is technically a bsd fork and does use the same methods, and so does the ps4 os.\ntl;dr Basically what you are saying doesn\u0026rsquo;t make sense in terms of virtual memory and this is done automatically( Games automatically use RAM as VRAM when you run out of VRAM. That\u0026rsquo;s why, when you go over your VRAM limit, your FPS drops like a rock ).\nAlso some people in this thread are confusing video memory and virtual memory.\nOptimizing for Gaming This guide is only for Arch and Ubuntu. Any derivatives like Manjaro, Mint, PopOS, etc should also work.\nEnable Multilib Multilib is required by Steam, So if you are running Steam you can skip this step, If you can not find Steam in your repositories this is your issue.\nAdd the architecture.\n$ sudo dpkg --add-architecture i386 Update the package manager\n$ sudo apt-get update Upgrade to newer packages\n$ sudo apt-get dist-upgrade GPU Drivers Having the right GPU drivers is imporant, else games won\u0026rsquo;t run properly.\nManually check which driver you need: https://www.nvidia.com/Download/index.aspx?lang=en-us\nFor Nvidia you need to add a repository\n$ sudo add-apt-repository ppa:graphics-drivers/ppa \u0026amp;\u0026amp; sudo apt-get upgrade For Nvidia 440 you need these packages so install them.\n$ sudo apt install nvidia-graphics-drivers-440 nvidia-settings vulkan vulkan-utils Now reboot\n$ sudo reboot If you use Gnome or GDM you might need to disable Wayland, This is not always the case, But I include it here just in case, If your System won\u0026rsquo;t reboot you can try this\n$ sudo nano /etc/gdm/custom.conf Remove the # in front of the #WaylandEnable=false line and it should force Xorg.\nLinux kernel Installing the newest kernel is generally the easiest kernel switch, There are other kernels available, I will include them later.\nThe easiest way is to use ukuu, First we need to install it.\n$ sudo add-apt-repository ppa:cappelikan/ppa $ sudo apt update $ sudo apt install mainline Now ukuu is installed, in this program you can select the newest stable kernel click install and when you reboot the new kernel is used. Do not remove your old kernel. If anything goes wrong you can select which kernel to boot in the grub screen at startup and remove the kernel that gives you trouble.\nFeral Gamemode gamemode 基本上是一组守护进程/库，它可以按需优化 Linux 系统的游戏性能。它实际上只是让 CPU 在用户玩游戏时自动运行在高性能模式下并帮助 Linux 用户从游戏中获得最佳性能。\n$ sudo apt install gamemode Manual\nInstall the dependencies\n$ sudo apt install meson libsystemd-dev pkg-config ninja-build git libdbus-1-dev libinih-dev Clone the repository\n$ git clone https://github.com/FeralInteractive/gamemode.git Change the directory into the just downloaded folder\n$ cd gamemode Change the tree to the newest version\n$ git checkout 1.5.1 Run the install script\n$ ./bootstrap.sh Usage\nNow that it is installed we need to enable the service with this command\n$ systemctl --user enable gamemoded \u0026amp;\u0026amp; systemctl --user start gamemoded To use gamemode for supertuxkart for example, run this terminal\n$ gamemoderun supertuxkart To use it in Steam edit the launch option for the desired game to\n$ gamemoderun %command% If gamemode does not run try to make it executable:\n$ sudo chmod +x /usr/bin/gamemoderun If gamemoderun does not work for you try this as a launch command:\n$ LD_PRELOAD=$LD_PRELOAD:/usr/lib/x86_64-linux-gnu/libgamemodeauto.so.0 %command% Nvidia Improvements Nvidia users might want to enable all options listed here to improve performance in games\n Force Full Composition Pipeline avoids screen tearing by letting the GPU do all the scaling. Triple Buffer avoids stuttering gameplay It allows for a stream of data instead of chunks of data. IndirectGLXProtocol forces the game to directly communicate with the Nvidia drivers. Coolbits enables your card to be overclocked which gamemode will make use of.  Create a Xorg Config file:\n$ sudo nvidia-xconfig Edit the file with the following command\n$ sudo nano /etc/X11/xorg.conf Add in these lines under the \u0026ldquo;Device\u0026rdquo; section between the other options\nOption \u0026#34;TripleBuffer\u0026#34; \u0026#34;on\u0026#34; Option \u0026#34;Coolbits\u0026#34; \u0026#34;28\u0026#34; Add in these lines under the \u0026ldquo;Screen\u0026rdquo; section between the other options.\nOption \u0026#34;metamodes\u0026#34; \u0026#34;nvidia-auto-select +0+0 {ForceCompositionPipeline=On, ForceFullCompositionPipeline=On}\u0026#34; Option \u0026#34;AllowIndirectGLXProtocol\u0026#34; \u0026#34;off\u0026#34; Try this one with risk, It will be sure to crash GNOME, I am not sure about other DEs\njust add it to the end of the file\nSection \u0026#34;Extensions\u0026#34; Option \u0026#34;Composite\u0026#34; \u0026#34;Disable\u0026#34; EndSection If you run into any problems, just hit CTRL ALT F3 to switch to a different tty login, run the command to edit the file again and put a # in front of the options that are giving you trouble, Most likely the last one\nAlternatively you can just completely remove the file with the following command\n$ sudo rm /etc/X11/xorg.conf Libstrangle Libstrangle is a tool that helps you control framerates but also vsync settings. This is especially handy for games that do not support these features, You would like to half your framerate to make it run better save some power or just give your hardware a break.\nLibstrangle can be used in multiple ways depending on what you want to achieve.\nTo use libstrangle you can simply type strangle and then the amount of frames you want to run. There are some examples below, But the features you will probably use are Vsync which you use by using the -v option, the rules for OpenGL and Vulkan are different, Here is what each number does for the different apis.\n OpenGL 0 Force off, 1 Force on, n - Sync to refresh rate Vulkan 0 Force off, 1 Mailbox mode, 2 Traditional vsync, 3 Adaptive vsync  You can also limit the game depending on the power state of your device, Set it to 60 while charging and on 30 while discharging for example. You do this by adding a second number right after a colon. in example, strangle 60:30. There are more features but they are not that commonly used, you can check the gitlab link above or simply type strangle -h for more information.\nTo limit the framerate of supertuxkart to 30 simply run\n$ strangle 30 supertuxkart To Force enable vsync on 60 fps for an OpenGL Steam game set the launch option to\n$ strangle -v 1 60 %command% To set the framerate of a vulkan game on Steam to 120 fps but 60 on battery power with adaptive vsync set this as your launch command\n$ strangle -v 3 120:60 %command% Mangohud Mangohud is a monitoring tool for Vulkan and OpenGL applications. It can show CPU and GPU usage, temps, But also framerates, frametimes and a lot more.\n$ sudo add-apt-repository ppa:flexiondotorg/mangohud $ sudo apt update $ sudo apt install mangohud To configure it with a GUI you can check out GOverlay below. For a manual configuration you can edit\n$ ~/.config/MangoHud/MangoHud.conf If you want exactly my configuration you can just copy this into it without the need for GOverlay.\nbackground_alpha=0.3 font_size=20 background_color=020202 text_color=ffffff position=top-right no_display toggle_hud=F11 cpu_stats cpu_temp cpu_color=007AFA gpu_stats gpu_temp gpu_color=00BD00 ram ram_color=B3000A vram vram_color=00801B io_read io_write io_color=B84700 arch engine_color=B200B0 frame_timing=1 frametime_color=00ff00 #output_file=/home/houtworm/mangohud_log_  #fps_limit 120 #media_player #toggle_logging=F10 You can tweak all the little things you want here. You can also create different configurations per game by adding a MangoHud.conf file to the game directory.\nTo use it for any game change its launch option to\n$ mangohud %command% To use it with non Steam games use the following command\n$ mangohud supertuxkart Some games might need the 32 bit version, try this if the normal command fails.\n$ mangohud.x86 %command% VKBasalt VKBasalt is a post processing layer for Vulkan which enables you to enhance graphics further. It only works with Vulkan, This includes all Proton games.\n$ git clone https://github.com/DadSchoorse/vkBasalt.git \u0026amp;\u0026amp; cd vkBasalt \u0026amp;\u0026amp; meson --buildtype=release builddir \u0026amp;\u0026amp; ninja -C builddir install To configure it first you need to create a config file, Run the following command to copy the example to a folder you can edit as the user.\n$ mkdir ~/.config/vkBasalt \u0026amp;\u0026amp; cp /usr/share/vkBasalt/vkBasalt.conf.example ~/.config/vkBasalt/vkBasalt.conf You can tweak all the little things you want here. You can also create different configurations per game by adding a vkBasalt.conf file to the game directory.\nTo use VKBasalt for any particular game enter this as a launch option.\nENABLE_VKBASALT=1 %command% You can also start non Steam games this way by typing the following command\nENABLE_VKBASALT=1 supertuxkart GOverlay GOverlay is a Graphical User Interface for managing MangoHud and VKBasalt\n$ sudo apt-get install lazarus git $ git clone https://github.com/benjamimgois/goverlay.git $ cd goverlay $ lazbuild -B goverlay.lpi mesa-demos and vulkan-tools are optional, You need them if you want to show the previews. You can find them in your distros repository\nXbox One Controller xpad works great, is the default on modern Linux distros and supports a wide range of controllers, But if you are like me and you only Xbox One controllers then using xpadneo is much better.\nFor Bluetooth to work with xpad and the Xbox One controllers you need to disable ertm (This is not needed for xpadneo)\ncreate the config file\n$ sudo nano /etc/modprobe.d/xbox_bt.conf Add the following line to the document and save and exit with CTRL + X.\noptions bluetooth disable_ertm=1 xpadneo supports Xbox One controllers wired and over bluetooth, It enables Force Feedback even the vibration inside the triggers, It supports battery level indication, It also fixes the mapping in many many games that where previously unplayable with a Xbox One controller on Linux.\nInstall the dependencies\n$ sudo apt-get install dkms linux-headers-`uname -r` Install xpadneo from Github\n$ git clone https://github.com/atar-axis/xpadneo.git \u0026amp;\u0026amp; cd xpadneo \u0026amp;\u0026amp; sudo ./install.sh Now you should be able to reboot and it should be all good, Having the controllers vibrate for a second when connected is a good indicator that it works.\n认证硬件  Ubuntu certified hardware Red Hat certified hardware  如果不怎么玩游戏的话，建议是直接考虑那些不带独立显卡的笔记本电脑。因为在Linux下双显卡装驱动问题很多。\n说到牌子的话，建议是考虑戴尔笔记本。因为戴尔台式机和笔记本，都是尽可能地去兼容Ubuntu来设计的。这个不是说假话做广告。我也就这个问题，看过了几乎所有戴尔系列产品的技术文档了。基本上都是在支持的操作系统列表中，无一例外地包含了Ubuntu。如果是想买能完美使用Ubuntu的本子，戴尔是首选。戴尔绝大部分笔记本机型都能很好完美兼容Ubuntu。\n还有一个重要原因就是，ubuntu的所属公司，与戴尔公司是有合作的。也正因为如此，Ubuntu默认就包含了dell的大部分硬件通用驱动，甚至硬件底层管理模块都囊括其中。\n功耗控制 针对散热不好的设备或者续航能力不佳的笔记本，功耗控制显得非常必要\n使用 TLP 延长电池寿命及续航  如有需要可参阅 TLP 官方文档 和 archwiki TLP。\n 多年来，Linux 在电池优化方面取得了很大进步，但仍然有一些可选步骤改善笔记本电脑的电池寿命并且延长续航。\nTLP 作为一款自由开源的高级电源管理工具提供开箱即用的默认配置。同时也可以高度定制化，以满足特定需求。\n电压下探  以下方法仅适用于 Intel 四代酷睿 ™ Haswell 及更新 CPU。有关 AMD CPU 和 Intel 四代酷睿 ™ Haswell 之前的 CPU 请参考 archWiki Undervolting CPU。\n 对处理器的电压进行最大限度的下探，在挖掘 CPU 体质的极限的同时，起到既能降低发热，又能最大限度保持性能的效果。\n如果正常操作，降低电压一般不会损害 CPU，一般建议从 50 毫伏进行尝试，每次降压尝试多增加 10 毫伏。只要确保在降低电压前，系统中任务均被正确保存即可。\n降低功率墙 除了电压的下探，同时也可以尝试对处理器的功率墙（TDP）做出降低的限制。比如考虑这种情况 —— 在 CPU 满睿频时，其实不需要默认的那么多功耗来维持，也许在默认功耗的基础上减几瓦，也能维持满睿频，这样就又可以进一步降低温度。对功率墙进行限制不同于对电压进行下探，若限制功率墙的参数较低，这会不可避免的损失较多的性能，但是在散热过差的设备上这也是一个好办法。\n对于功率墙的调整，有些主板在 BIOS 中提供了设置项可以直接调整。对于没有设置项的主板，有的主板是锁定了瞬时和长时功率墙，这种情况就无法调整功率墙了。有的主板 BIOS 随没有提供功率墙调整项，但依旧可以通过命令行设置。\n通过以下的命令可以查看主板是否可以调整功率墙：\ngrep . /sys/class/powercap/intel-rapl/intel-rapl:0/* 2\u0026gt; /dev/null 如果在输出中看到了如下的 enabled 值为 1，即可以调整。第一行的数字代表现有的功率墙限制：\n/sys/class/powercap/intel-rapl/intel-rapl:0/constraint_0_power_limit_uw:100000000 /sys/class/powercap/intel-rapl/intel-rapl:0/enabled:1 具体的调整步骤参考 Set Max TDP of Intel H-series CPU。\n交换文件 在桌面环境中，交换分区或文件用来实现休眠(hibernate)的功能，即将当前环境保存在磁盘的交换文件或分区部分。除此之外，某些特定软件需要 swap 才可以正确运行。交换文件与分区性能相同，且交换文件更为灵活，可随时变更大小，增加与删除。\n$ dd if=/dev/zero of=/swapfile bs=1M count=4096 status=progress #创建4G的交换空间 大小根据需要自定 $ chmod 600 /swapfile #设置正确的权限 $ mkswap /swapfile #格式化swap文件 $ swapon /swapfile #启用swap文件 最后，向/etc/fstab 中追加如下内容：\n/swapfile none swap defaults 0 0 KDE 自身提供开箱即用的睡眠功能(suspend)，即将系统挂起到内存，消耗少量的电量。休眠(hibernate)会将系统挂起到交换分区或文件，几乎不消耗电量。\nQUESTIONS Ubuntu 无法关机 $ sudo vim /etc/systemd/system.conf DefaultTimeoutStartSec=5s DefaultTimeoutStopSec=5s $ sudo systemctl reload DefaultTimeoutStartSec=, DefaultTimeoutStopSec= 设置启动/停止一个单元所允许的最大时长。若仅设置一个整数而没有单位，那么单位是秒。 也可以在整数后面加上时间单位后缀： \u0026ldquo;ms\u0026rdquo;(毫秒), \u0026ldquo;s\u0026rdquo;(秒), \u0026ldquo;min\u0026rdquo;(分钟), \u0026ldquo;h\u0026rdquo;(小时), \u0026ldquo;d\u0026rdquo;(天), \u0026ldquo;w\u0026rdquo;(周) 。 对于 Type=oneshot 类型的 service 单元， 这些选项没有意义(相当于全部被禁用)。 对于其他类型的 service 单元，可以在单元文件中设置 TimeoutStartSec=, TimeoutStopSec=, RestartSec= 以覆盖此处设置的默认值 (参见systemd.service(5))。 对于其他非 service 类型的单元， DefaultTimeoutStartSec= 是 TimeoutSec= 的默认值。\n注1：尽量不要使用上面更改。应该在完全清楚自己的更改造成的影响、产生的作用的前提下，做出更改。\n注2：作为桌面操作系统，如果有硬件驱动或其他各种莫名问题，可以尝试升级到最新版本来解决。\nACPI ERROR: AE_ALREADY_EXISTS These kinds of \u0026ldquo;errors\u0026rdquo; have been discussed ad nauseam, it\u0026rsquo;s simply the kernel telling you that the ACPI information received from the system seems to be incomplete in some way, update your BIOS/UEFI in hopes for a proper fix or ignore the error if you don\u0026rsquo;t notice anything off with your system.\n(And please don\u0026rsquo;t do something dumb like setting acpi=off just to get rid of these messages)\n解压zip乱码 $ unzip -O CP936 xxx.zip 用GBK, GB18030也可以\nCan\u0026rsquo;t run CS:GO at fullscreen  Open Steam Go to the \u0026ldquo;Library\u0026rdquo; Right-click the game which needs to be reconfigured Select \u0026ldquo;Properties\u0026rdquo; from the menu Click the \u0026ldquo;Set launch options\u0026hellip;\u0026rdquo; button type: -full and save  How To Disable Lock In Kubuntu open Workspace \u0026gt; Desktop Behavior \u0026gt; Screen Locking \u0026gt; uncheck Lock screen option\nGnome 3 displays two icons for same app No, there\u0026rsquo;s nothing wrong with your system.\nThe duplicated launcher icons explained:\nThe different icons are different commandline options. Some context applications with call the associated *.desktop icon. The exec option of the icon will depend on how the application is called.\nSome of the Icons you show in your image may be obvious because of the difference in the way they are named. You can see the difference in the way the app is called by right clicking and clicking on properties to see other differences.\nSome of the *.desktop files have a %U argument, used so the application will accept arguments.\nSome of the Launchers are different commands that are called differently and are named differently often by a symbolic link.\nSome exampes from the list in you image are:\nName: Online Accounts Command: unity-control-center credentials Name: Online Accounts Command: Online account credentials and settings Name: Personal File Sharing Command: gnome-file-share-properties Name: Rhythmbox Command: rhythmbox %U Name: Rhythmbox Command rhythmbox-client --select-source %U ssh_exchange_identification: Connection closed by remote host 原因是 Clash 开了 TUN 模式。关闭掉就好了。\nDisk show 129986 TB  (=ↀωↀ=)橘外猫, [2/7/22 11:16 AM] 这个是怎么回事啊\n雪梨, [2/7/22 11:21 AM] 分区表坏了？\n(=ↀωↀ=)橘外猫, [2/7/22 11:21 AM] 直接再分区吗？\n雪梨, [2/7/22 11:21 AM] 请鸽鱼老师看看诶\n雪梨, [2/7/22 11:22 AM] 还能挂载就先备份数据好了\n(=ↀωↀ=)橘外猫, [2/7/22 11:22 AM] 好的\nPegion Fish, [2/7/22 11:25 AM] JMS炸了？ 建议备份数据重建分区表 先重新插一次USB和硬盘\n(=ↀωↀ=)橘外猫, [2/7/22 11:27 AM] 重插了 用fdisk 重建吗？\nPegion Fish, [2/7/22 11:28 AM] 还是不正常？ 硬盘也重新插一下\n(=ↀωↀ=)橘外猫, [2/7/22 11:28 AM] 恩\n雪梨, [2/7/22 11:28 AM] 重建分区表，不是删掉分区再新增分区\n(=ↀωↀ=)橘外猫, [2/7/22 11:30 AM] 断电后自动好了 这是怎么回事啊\nThor Luo Bing-, [2/7/22 11:31 AM] 硬盘清空了\n(=ↀωↀ=)橘外猫, [2/7/22 11:32 AM] 没有，东西还在\nPegion Fish, [2/7/22 11:32 AM] 啊 这不是争产的吗 1T啊 这就是JMS主控抽风\n No Caching mode page found during early boot, I get following error message:\n[sdb] No Caching mode page found [sdb] Assuming drive cache: write through If I understand correctly, this is actually just a harmless info message and not an actual error. sdb is my USB disk, and it does not use caching .\nHard disks have a small amount of RAM cache to speed up write operations. The system can write a chunk of data to the disk cache without actually waiting for it to be written to the disk. This is sometimes called \u0026ldquo;write-back\u0026rdquo; mode. If there is no cache on the disk, data is directly written to it in \u0026ldquo;write-through\u0026rdquo; mode. The Asking for cache data failed warning usually occurs with devices such as USB flash drives, USB card readers, etc. which present themselves as SCSI devices to the system (sdX), but have no cache. The system asks the device: \u0026ldquo;Do you have a cache?\u0026rdquo; and gets no response. So it assumes there is no cache and puts it in \u0026ldquo;write-through\u0026rdquo; mode.\nCertificate verification failed 首先更改源文件，将所有的 https 改成 http ：\n$ sudo vi /etc/apt/sources.list deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse 1234 然后安装/更新证书 ca-certificates：\n$ sudo apt-get update $ sudo apt-get install --reinstall ca-certificates 最后将镜像源文件改回 https：\n$ sudo vi /etc/apt/sources.list deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse $ sudo apt-get update Move and overwrite subdirectories (and files) to parent directory You will have to copy them to the destination and then delete the source, using the commands cp -r * .. followed by rm -rf *.\nI don\u0026rsquo;t think you can \u0026ldquo;merge\u0026rdquo; directories using mv.\nSystem program problem detected The error \u0026ldquo;System program problem detected\u0026rdquo; comes up when a certain application crashes. Ubuntu has a program called Apport that is responsible for detecting such crashes and upon user consent, report these crashes to developers. This process intends to get the problem fixed by the developers.\nHowever it can be very annoying to common users, and there is no point in showing errors to users when they cannot do anything about it themselves. So you might want to disable them.\nRemove crash report files\nThe apport system creates crash report files in the /var/crash directory. These crash report files cause the error message to appear everytime Ubuntu boots.\n$ cd /var/crash $ ls _opt_google_chrome_chrome.1000.crash _usr_lib_chromium-browser_chromium-browser.1000.crash _usr_sbin_ulatencyd.0.crash _usr_share_apport_apport-gtk.1000.crash Just remove the crash report files\n$ sudo rm /var/crash/* After removing all the crash report files, the error message should stop popping up. However if a new crash takes place then it would appear again in future.\nTurn off apport\nAfter removing the old crash reports, if you still get the same error message, then you can completely turn off apport to get rid. Edit the configuration file at /etc/default/apport.\n$ gksudo gedit /etc/default/apport The file would contain something like this\n# set this to 0 to disable apport, or to 1 to enable it # you can temporarily override this with # sudo service apport start force_start=1 enabled=1 Just set the value of enabled to 0, and this will disable apport.\nenabled=0 Save the file and close it. From the next boot onwards, there should be no error messages ever. If you do not want to restart the system then restart apport from the command line.\n$ sudo restart apport ","permalink":"https://sakamotokurome.github.io/posts/ubuntu/","summary":"友邦拓 乌班图 During the first ten years of this HOWTO\u0026rsquo;s life, I reported that from a new user\u0026rsquo;s point of view, all Linux distributions are almost equivalent. But in 2006-2007, an actual best choice emerged: Ubuntu. While other distros have their own areas of strength, Ubuntu is far and away the most accessible to Linux newbies. Beware, though, of the hideous and nigh-unusable \u0026ldquo;Unity\u0026rdquo; desktop interface","title":"Ubuntu"},{"content":"Hexo Hexo 是一个快速、简洁且高效的博客框架。\n安装   安装 Git：\n Windows: Download \u0026amp; install git. Mac: Install it with Homebrew, MacPorts or installer. Linux (Ubuntu, Debian): sudo apt-get install git-core Linux (Fedora, Red Hat, CentOS): sudo yum install git-core    安装 node.js：\n Windows: Install it with nvs (recommended) or nvm. Mac: Install it with Homebrew or MacPorts. Linux (DEB/RPM-based): Install it with NodeSource. Others: Install it through respective package manager. Refer to the guide provided by Node.js.    安装 Hexo：-g 表示全局安装，会将 Hexo 命令加入环境变量中。\n$ npm --registry https://registry.npm.taobao.org install -g hexo-cli # 持久使用镜像 $ npm config set registry https://registry.npm.taobao.org Where do global npm packages get installed\n$ npm root -g   建站 $ hexo init [folder] $ cd \u0026lt;folder\u0026gt; $ npm install 新建完成后，指定文件夹的目录如下：\n. ├── node_modules\t//依赖安装目录 ├── scaffolds\t//模板文件夹，Hexo的模板是指在新建的文章文件中默认填充的内容。 | ├── draft.md\t//草稿模板 | ├── page.md\t//页面模板 | └── post.md\t//文章模板 ├── source\t//资源文件夹 | └── _posts\t//文章目录 ├── themes\t//主题文件夹，Hexo 会根据主题来生成静态页面。 | └── landscape\t//默认主题 ├── .gitignore\t//指定不纳入git版本控制的文件 ├── _config.yml\t//站点配置文件 ├── db.json ├── package.json\t//应用程序的信息 └── package-lock.json source：资源文件夹是存放用户资源的地方。除 _posts 文件夹之外，开头命名为 _ (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。\n配置 您可以在 _config.yml 中修改大部分的配置。\n网站    参数 描述     title 网站标题   subtitle 网站副标题   description 网站描述   keywords 网站的关键词。支持多个关键词。   author 您的名字   language 网站使用的语言。对于简体中文用户来说，使用不同的主题可能需要设置成不同的值，请参考你的主题的文档自行设置，常见的有 zh-Hans和 zh-CN。   timezone 网站时区。Hexo 默认使用您电脑的时区。请参考 时区列表 进行设置，如 America/New_York, Japan, 和 UTC 。一般的，对于中国大陆地区可以使用 Asia/Shanghai。    其中，description主要用于SEO，告诉搜索引擎一个关于您站点的简单描述，通常建议在其中包含您网站的关键词。author参数用于主题显示文章的作者。\n网址    参数 描述 默认值     url 网址, 必须以 http:// 或 https:// 开头    root 网站根目录 url's pathname   permalink 文章的 永久链接 格式 :year/:month/:day/:title/   permalink_defaults 永久链接中各部分的默认值    pretty_urls 改写 permalink 的值来美化 URL    pretty_urls.trailing_index 是否在永久链接中保留尾部的 index.html，设置为 false 时去除 true   pretty_urls.trailing_html 是否在永久链接中保留尾部的 .html, 设置为 false 时去除 (对尾部的 index.html无效) true     网站存放在子目录\n如果您的网站存放在子目录中，例如 http://example.com/blog，则请将您的 url 设为 http://example.com/blog 并把 root 设为 /blog/。\n 例如：\n# 比如，一个页面的永久链接是 http://example.com/foo/bar/index.html pretty_urls: trailing_index: false # 此时页面的永久链接会变为 http://example.com/foo/bar/ 目录    参数 描述 默认值     source_dir 资源文件夹，这个文件夹用来存放内容。 source   public_dir 公共文件夹，这个文件夹用于存放生成的站点文件。 public   tag_dir 标签文件夹 tags   archive_dir 归档文件夹 archives   category_dir 分类文件夹 categories   code_dir Include code 文件夹，source_dir 下的子目录 downloads/code   i18n_dir 国际化（i18n）文件夹 :lang   skip_render 跳过指定文件的渲染。匹配到的文件将会被不做改动地复制到 public 目录中。您可使用 glob 表达式来匹配路径。     例如：\nskip_render: \u0026#34;mypage/**/*\u0026#34; # 将会直接将 `source/mypage/index.html` 和 `source/mypage/code.js` 不做改动地输出到 \u0026#39;public\u0026#39; 目录 # 你也可以用这种方法来跳过对指定文章文件的渲染 skip_render: \u0026#34;_posts/test-post.md\u0026#34; # 这将会忽略对 \u0026#39;test-post.md\u0026#39; 的渲染  提示\n如果您刚刚开始接触 Hexo，通常没有必要修改这一部分的值。\n 文章    参数 描述 默认值     new_post_name 新文章的文件名称 :title.md   default_layout 预设布局 post   auto_spacing 在中文和英文之间加入空格 false   titlecase 把标题转换为 title case false   external_link 在新标签中打开链接 true   external_link.enable 在新标签中打开链接 true   external_link.field 对整个网站（site）生效或仅对文章（post）生效 site   external_link.exclude 需要排除的域名。主域名和子域名如 www 需分别配置 []   filename_case 把文件名称转换为 (1) 小写或 (2) 大写 0   render_drafts 显示草稿 false   post_asset_folder 启动 Asset 文件夹 false   relative_link 把链接改为与根目录的相对位址 false   future 显示未来的文章 true   highlight 代码块的设置, 请参考 Highlight.js 进行设置    prismjs 代码块的设置, 请参考 PrismJS 进行设置      相对地址\n默认情况下，Hexo 生成的超链接都是绝对地址。例如，如果您的网站域名为 example.com,您有一篇文章名为 hello，那么绝对链接可能像这样：http://example.com/hello.html，它是绝对于域名的。相对链接像这样：/hello.html，也就是说，无论用什么域名访问该站点，都没有关系，这在进行反向代理时可能用到。通常情况下，建议使用绝对地址。\n 分类 \u0026amp; 标签    参数 描述 默认值     default_category 默认分类 uncategorized   category_map 分类别名    tag_map 标签别名     日期 / 时间格式 Hexo 使用 Moment.js 来解析和显示时间。\n   参数 描述 默认值     date_format 日期格式 YYYY-MM-DD   time_format 时间格式 HH:mm:ss   updated_option 当 Front Matter 中没有指定 updated 时 updated 的取值 mtime     updated_option\nupdated_option 控制了当 Front Matter 中没有指定 updated 时，updated 如何取值：\n mtime: 使用文件的最后修改时间。这是从 Hexo 3.0.0 开始的默认行为。 date: 使用 date 作为 updated 的值。可被用于 Git 工作流之中，因为使用 Git 管理站点时，文件的最后修改日期常常会发生改变 empty: 直接删除 updated。使用这一选项可能会导致大部分主题和插件无法正常工作。  use_date_for_updated 选项已经被废弃，将会在下个重大版本发布时去除。请改为使用 updated_option: 'date'。\n use_date_for_updated` | 启用以后，如果 Front Matter 中没有指定 `updated`， [`post.updated`](https://hexo.io/zh-cn/docs/configuration) 将会使用 `date` 的值而不是文件的创建时间。在 Git 工作流中这个选项会很有用 | `true 分页    参数 描述 默认值     per_page 每页显示的文章量 (0 = 关闭分页功能) 10   pagination_dir 分页目录 page    扩展    参数 描述     theme 当前主题名称。值为false时禁用主题   theme_config 主题的配置文件。在这里放置的配置会覆盖主题目录下的 _config.yml 中的配置   deploy 部署部分的设置   meta_generator Meta generator 标签。 值为 false 时 Hexo 不会在头部插入该标签    包括或不包括目录和文件\n在 Hexo 配置文件中，通过设置 include/exclude 可以让 Hexo 进行处理或忽略某些目录和文件夹。你可以使用 glob 表达式 对目录和文件进行匹配。\ninclude and exclude options only apply to the source/ folder, whereas ignore option applies to all folders.\n   参数 描述     include Hexo 默认会忽略隐藏文件和文件夹（包括名称以下划线和 . 开头的文件和文件夹，Hexo 的 _posts 和 _data 等目录除外）。通过设置此字段将使 Hexo 处理他们并将它们复制到 source 目录下。   exclude Hexo 会忽略这些文件和目录   ignore Ignore files/folders    举例：\n# Include/Exclude Files/Folders include: - \u0026#34;.nojekyll\u0026#34; # 包括 \u0026#39;source/css/_typing.css\u0026#39; - \u0026#34;css/_typing.css\u0026#34; # 包括 \u0026#39;source/_css/\u0026#39; 中的任何文件，但不包括子目录及其其中的文件。 - \u0026#34;_css/*\u0026#34; # 包含 \u0026#39;source/_css/\u0026#39; 中的任何文件和子目录下的任何文件 - \u0026#34;_css/**/*\u0026#34; exclude: # 不包括 \u0026#39;source/js/test.js\u0026#39; - \u0026#34;js/test.js\u0026#34; # 不包括 \u0026#39;source/js/\u0026#39; 中的文件、但包括子目录下的所有目录和文件 - \u0026#34;js/*\u0026#34; # 不包括 \u0026#39;source/js/\u0026#39; 中的文件和子目录下的任何文件 - \u0026#34;js/**/*\u0026#34; # 不包括 \u0026#39;source/js/\u0026#39; 目录下的所有文件名以 \u0026#39;test\u0026#39; 开头的文件，但包括其它文件和子目录下的单文件 - \u0026#34;js/test*\u0026#34; # 不包括 \u0026#39;source/js/\u0026#39; 及其子目录中任何以 \u0026#39;test\u0026#39; 开头的文件 - \u0026#34;js/**/test*\u0026#34; # 不要用 exclude 来忽略 \u0026#39;source/_posts/\u0026#39; 中的文件。你应该使用 \u0026#39;skip_render\u0026#39;，或者在要忽略的文件的文件名之前加一个下划线 \u0026#39;_\u0026#39; # 在这里配置一个 - \u0026#34;_posts/hello-world.md\u0026#34; 是没有用的。 ignore: # Ignore any folder named \u0026#39;foo\u0026#39;. - \u0026#34;**/foo\u0026#34; # Ignore \u0026#39;foo\u0026#39; folder in \u0026#39;themes/\u0026#39; only. - \u0026#34;**/themes/*/foo\u0026#34; # Same as above, but applies to every subfolders of \u0026#39;themes/\u0026#39;. - \u0026#34;**/themes/**/foo\u0026#34; 列表中的每一项都必须用单引号或双引号包裹起来。\ninclude 和 exclude 并不适用于 themes/ 目录下的文件。如果需要忽略 themes/ 目录下的部分文件或文件夹，可以使用 ignore 或在文件名之前添加下划线 _。\n使用代替配置文件\n可以在 hexo-cli 中使用 --config 参数来指定自定义配置文件的路径。你可以使用一个 YAML 或 JSON 文件的路径，也可以使用逗号分隔（无空格）的多个 YAML 或 JSON 文件的路径。例如：\n# use \u0026#39;custom.yml\u0026#39; in place of \u0026#39;_config.yml\u0026#39; $ hexo server --config custom.yml # use \u0026#39;custom.yml\u0026#39; \u0026amp; \u0026#39;custom2.json\u0026#39;, prioritizing \u0026#39;custom3.yml\u0026#39;, then \u0026#39;custom2.json\u0026#39; $ hexo generate --config custom.yml,custom2.json,custom3.yml 当你指定了多个配置文件以后，Hexo 会按顺序将这部分配置文件合并成一个 _multiconfig.yml。如果遇到重复的配置，排在后面的文件的配置会覆盖排在前面的文件的配置。这个原则适用于任意数量、任意深度的 YAML 和 JSON 文件。\n例如，使用 --options 指定了两个自定义配置文件：\n$ hexo generate --config custom.yml,custom2.json 如果 custom.yml 中指定了 foo: bar，在 custom2.json 中指定了 \u0026quot;foo\u0026quot;: \u0026quot;dinosaur\u0026quot;，那么在 _multiconfig.yml 中你会得到 foo: dinosaur。\n使用代替主题配置文件\n通常情况下，Hexo 主题是一个独立的项目，并拥有一个独立的 _config.yml 配置文件。\n除了自行维护独立的主题配置文件，你也可以在其它地方对主题进行配置。\n配置文件中的 theme_config\n 该特性自 Hexo 2.8.2 起提供\n # _config.yml theme: \u0026#34;my-theme\u0026#34; theme_config: bio: \u0026#34;My awesome bio\u0026#34; foo: bar: \u0026#39;a\u0026#39; # themes/my-theme/_config.yml bio: \u0026#34;Some generic bio\u0026#34; logo: \u0026#34;a-cool-image.png\u0026#34; foo: baz: \u0026#39;b\u0026#39; 最终主题配置的输出是：\n{ bio: \u0026#34;My awesome bio\u0026#34;, logo: \u0026#34;a-cool-image.png\u0026#34;, foo: { bar: \u0026#34;a\u0026#34;, baz: \u0026#34;b\u0026#34; } } 独立的 _config.[theme].yml 文件\n 该特性自 Hexo 5.0.0 起提供\n 独立的主题配置文件应放置于站点根目录下，支持 yml 或 json 格式。需要配置站点 _config.yml 文件中的 theme 以供 Hexo 寻找 _config.[theme].yml 文件。\n# _config.yml theme: \u0026#34;my-theme\u0026#34; # _config.my-theme.yml bio: \u0026#34;My awesome bio\u0026#34; foo: bar: \u0026#39;a\u0026#39; # themes/my-theme/_config.yml bio: \u0026#34;Some generic bio\u0026#34; logo: \u0026#34;a-cool-image.png\u0026#34; foo: baz: \u0026#39;b\u0026#39; 最终主题配置的输出是：\n{ bio: \u0026#34;My awesome bio\u0026#34;, logo: \u0026#34;a-cool-image.png\u0026#34;, foo: { bar: \u0026#34;a\u0026#34;, baz: \u0026#34;b\u0026#34; } }  我们强烈建议你将所有的主题配置集中在一处。如果你不得不在多处配置你的主题，那么这些信息对你将会非常有用：Hexo 在合并主题配置时，Hexo 配置文件中的 theme_config 的优先级最高，其次是 _config.[theme].yml 文件，最后是位于主题目录下的 _config.yml 文件。\n 指令   version 显示 Hexo 版本：\nhexo version   list 列出网站资料：\nhexo list   新建一篇文章：如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。\nhexo new [layout] \u0026lt;title\u0026gt; hexo n [layout] \u0026lt;title\u0026gt;   Hexo 有三种默认布局：\n   布局 路径     post source/_posts   page source   draft source/_drafts      预览草稿，publish 发表草稿：\nhexo server --draft hexo publish [layout] \u0026lt;filename\u0026gt;   clean 清除缓存文件 (db.json) 和已生成的静态文件 (public)：\nhexo clean   generate 生成静态文件：\nhexo generate hexo g   启动 hexo 的内置 Web 服务器：该命令将会调用 Markdown 引擎解析项目中的博客内容生成网页资源，资源将会存于内存中。\nhexo server hexo s --debug\t# 开启调试模式（--debug） hexo s --port 8000\t# 添加 -p / --port 参数来设置 Web 服务监听的端口号 hexo s --static\t# 加 -s / --static 参数，本地改动不触发 hexo 实时解析更新。   deploy 部署网站：\nhexo deploy hexo d   写作   Front-matter： 是文件最上方以 --- 分隔的区域，用于指定个别文件的变量\n--- layout: # 布局 title: # 标题 date: # 建立日期 updated: # 更新日期 comments: # 开启文章的评论功能 tags:\t# 标签 - 标签1 - 标签2 categories: [分类1, 分类2]\t# 分类, 不适用与分页 permalink: # 覆盖文章网址 --- 标签是一种列表结构，而分类是一种树结构。\n  文本居中标签：在引用单行文本时使用\n\u0026lt;blockquote class=\u0026quot;blockquote-center\u0026quot;\u0026gt;blah blah blah\u0026lt;/blockquote\u0026gt;\t# HTML方式 {% centerquote %}blah blah blah{% endcenterquote %}\t# 标签方式 {% cq %} blah blah blah {% endcq %}\t# 标签别名   引用块\n{% blockquote [author[, source]] [link] [source_link_title] %} content {% endblockquote %}   代码块\n``` [language] [title] [url] [link text] code snippet  - `langugae`：语言名称，引导渲染引擎正确解析并高亮显示关键字 - `title`：代码块标题，将会显示在左上角 - `url`：链接地址，如果没有指定 link text 则会在右上角显示 link - `link text`：链接名称，指定 url 后有效，将会显示在右上角 - 如果设置语言为 diff，可以在代码前添加 `+` 和 `-` 来使用如上所示的高亮增删行提示效果，在展示代码改动痕迹时比较实用。   note 标签：通过 note 标签可以为段落添加背景色\n{% note [class] %} 文本内容 (支持行内标签) {% endnote %}  支持的 class 种类包括 default、primary、success、info、warning、danger    label 标签：通过 label 标签可以为文字添加背景色\n{% label [class]@text %}  支持的 class 种类包括 default、primary、success、info、warning、danger    button 按钮：通过 button 标签可以快速添加带有主题样式的按钮\n{% button /path/to/url/, text, icon [class], title %} {% btn /path/to/url/, text, icon [class], title %}   tab 标签：tab 标签用于快速创建 tab 选项卡\n{% tabs [Unique name], [index] %} \u0026lt;!-- tab [Tab caption]@[icon] --\u0026gt; 标签页内容（支持行内标签） \u0026lt;!-- endtab --\u0026gt; {% endtabs %}  Unique name: 全局唯一的 Tab 名称，将作为各个标签页的 id 属性前缀 index: 当前激活的标签页索引，如果未定义则默认选中显示第一个标签页，如果设为 - 1 则默认隐藏所有标签页 Tab caption: 当前标签页的标题，如果不指定则会以 Unique name 加上索引作为标题 icon: 在标签页标题中添加 Font awesome 图标    引用站内链接\n{% post_path slug %} {% post_link slug [title] %}  slug 表示 _post 目录下的 Markdown 文件名。 post_path 标签将会渲染为文章的地址，即 permalink；而 post_link 标签将会渲染为链接，可以通过 title 指定链接标题。    插入 Swig 代码：通过 raw 标签来禁止 Markdown 引擎渲染标签内的内容。该标签通常用于在页面内引入三方脚本实现特殊功能。\n{% raw %} content {% endraw %}   插入 Gist\n{% gist gist_id [filename] %}  gist_id: Gist 仓库页面 url 中最后一段随机字符串 filename: Gist 中的文件名，如果 Gist 中只有一个文件，可以不用指定 filename，如果 Gist 中有多个文件，可以在标签内输入 filename 来指定只引入某个文件，如果没有指定 filename，将会引入 Gist 中的所有文件。    插入图片：\n  Markdown 并不会保存插入的图片资源本身，只是记录了获取资源的链接。\n  相对路径引用的标签插件\n{% asset_img slug [title] %}   slug 是资源文件夹下的图片名\n  Embedding an image using markdown：allows you to embed an image in markdown without using asset_img tag plugin.\npost_asset_folder: true marked: prependRoot: true postAsset: true ![](image.jpg) will be rendered as \u0026lt;img src=\u0026quot;/2020/01/02/foo/image.jpg\u0026quot;\u0026gt;.\n    用Typora编写Hexo博客时能实预览图片\n  思路是在before_post_render阶段将markdown文件中图片的路径转换为asset_img函数。\nnpm install hexo-image-link --save       文章加密\n  Install\nnpm install --save hexo-blog-encrypt   Quick start: Add the \u0026ldquo;password\u0026rdquo; value to your post\u0026rsquo;s front matter like\n--- password: mikemessi ---     Hexo 添加文章时自动打开编辑器\n  在 Hexo 目录下的 scripts 目录中创建一个 JavaScript 脚本文件。通过这个脚本，我们用其来监听 hexo new 这个动作，并在检测到 hexo new 之后，执行编辑器打开的命令。\n  将下列内容写入你的脚本\nvar spawn = require('child_process').exec; hexo.on('new', function(data){ spawn('start \u0026quot;markdown编辑器绝对路径.exe\u0026quot; ' + data.path); });     文章置顶\n--- sticky: true ---   资源文件夹 资源（Asset）代表 source 文件夹中除了文章以外的所有文件。\n文章资源文件夹\npost_asset_folder: true 当资源文件管理功能打开后，Hexo将会在你每一次通过 hexo new [layout] \u0026lt;title\u0026gt; 命令创建新文章时自动创建一个文件夹。这个资源文件夹将会有与这个文章文件一样的名字。将所有与你的文章有关的资源放在这个关联文件夹中之后，你可以通过相对路径来引用它们。\n部署 持续集成（Continuous Integration，简称 CI）\nSimply Push to Deploy：热部署，只需要将代码 push 到 Git 远程仓库即可自动构建及更新。\nNetlify\nGitHub Action：\n  Add your ssh key pair\n  Run the following terminal command, replacing the email with one connected to your GitHub account.\nssh-keygen -t rsa -C \u0026#34;username@example.com\u0026#34; Windows 下自定义 ssh key 文件需写成 GIT\\BlogSrc/.ssh/id_rsa\n  In Github Pages repo: Add the contents of the public key（id_rsa.pub） within your repositories deploy keys menu. You can find this option by going to Settings \u0026gt; Deploy Keys, you can name the public key whatever you want, but you do need to give it write access.\n  In hexo source code repo: Add the contents of the private key（id_rsa） to the Settings \u0026gt; Secrets menu as DEPLOY_KEY.\n    Configure github workflows：Create a workflow .yml file in your .github/workflows directory.\nname: Deploy on: [push] jobs: build: runs-on: ubuntu-latest name: A job to deploy blog. steps: - name: Checkout uses: actions/checkout@v1 with: submodules: true # Checkout private submodules(themes or something else). # Caching dependencies to speed up workflows. (GitHub will remove any cache entries that have not been accessed in over 7 days.) - name: Cache node modules uses: actions/cache@v1 id: cache with: path: node_modules key: ${{ runner.os }}-node-${{ hashFiles(\u0026#39;**/package-lock.json\u0026#39;) }} restore-keys: | ${{ runner.os }}-node- - name: Install Dependencies if: steps.cache.outputs.cache-hit != \u0026#39;true\u0026#39; run: npm ci # Deploy hexo blog website. - name: Deploy id: deploy uses: sma11black/hexo-action@v1.0.3 with: deploy_key: ${{ secrets.DEPLOY_KEY }} user_name: your github username  # (or delete this input setting to use bot account) user_email: your github useremail  # (or delete this input setting to use bot account) commit_msg: ${{ github.event.head_commit.message }}  # (or delete this input setting to use hexo default settings) # Use the output from the `deploy` step(use for test action) - name: Get the output run: | echo \u0026#34;${{ steps.deploy.outputs.notify }}\u0026#34;   一键部署\n  新建一个空的 repository（没有init任何内容）。你的 repository 必须直接命名为 \u0026lt;你的 GitHub 用户名.github.io\u0026gt;。从而能通过 \u0026lt;你的 GitHub 用户名.github.io\u0026gt; 域名直接访问你的blog。\n  安装 hexo-deployer-git。\nnpm install hexo-deployer-git --save   修改_config.yml配置。\ndeploy: type: git repo: git@github.com:yourname/yourname.github.io.git branch: master   生成站点文件并推送至远程库。执行 hexo clean \u0026amp; hexo deploy。\n  登入 Github，在库设置（Repository Settings）中将默认分支设置为_config.yml配置中的分支名称。稍等片刻（Blog 不会立马加载出来，需多刷新几下），您的站点就会显示在您的Github Pages中。\n  这是如何发生的：当执行 hexo deploy 时，Hexo 会将 public 目录中的文件和目录推送至 _config.yml 中指定的远端仓库和分支中，并且完全覆盖该分支下的已有内容。\n  部署分支与写作分支：hexo d 部署到 GitHub 的是 hexo 编译后的文件，不包含源文件。可以利用git的分支管理，将源文件上传到 GitHub。一个好的实践是放在两个不同的 Git 仓库中。\n  主题 创建 Hexo 主题非常容易，您只要在 themes 文件夹内，新增一个任意名称的文件夹，并修改 _config.yml 内的 theme 设定，即可切换主题。\n _config.yml：主题的配置文件。和 Hexo 配置文件不同，主题配置文件修改时会自动更新，无需重启 Hexo Server。 languages：语言文件夹。 layout：布局文件夹。 scripts：脚本文件夹。 source：资源文件夹。  在 GitHub 搜索 Hexo 即可找到流行的 Hexo 主题。各主题都有相应的使用文档。\n其他 列表之后不能立即接一个代码块，否则会解析出错。如\n- ```bash code... ``` 一行代码没有问题\n- `code` 首页展示最新博客 index_generator: path: \u0026#39;\u0026#39; per_page: 10 - order_by: -date + order_by: {updated: -1}  -updated_option: \u0026#39;mtime\u0026#39; +updated_option: \u0026#39;date\u0026#39; Are there more order options?\n  Api Document：https://hexojs.github.io/warehouse/Query.html#sort\n  sort(orderby, orderopt) → {Query}\n  Example:\nquery.sort('date', -1); query.sort({date: -1, title: 1}); query.sort('-date title');   If the order equals to -1, desc or descending, the data will be returned in reversed order.\n  Parameters:\n   Name Type Attributes     orderby String Object   order String Number        Sort is to sort the object properties (Page-Variables), refer to the above document for details。\n   Variable Description Type     page.title Article title string   page.date Article created date Moment.js object   page.updated Article last updated date Moment.js object      hexo-generator-index\nconst posts = locals.posts.sort(config.index_generator.order_by);   updated_option\nupdated_option 控制了当 Front Matter 中没有指定 updated 时，updated 如何取值：\n mtime: 使用文件的最后修改时间。这是从 Hexo 3.0.0 开始的默认行为。 date: 使用 date 作为 updated 的值。可被用于 Git 工作流之中，因为使用 Git 管理站点时，文件的最后修改日期常常会发生改变 empty: 直接删除 updated。使用这一选项可能会导致大部分主题和插件无法正常工作。    NexT Getting Started Installation\n  Installation\ncd hexo-site npm install hexo-theme-next   Usage, theme config file\ntheme: next   Update\ncd hexo-site npm update hexo-theme-next   Configuration\nInstalled through npm\ncp node_modules/hexo-theme-next/_config.yml _config.next.yml Theme Settings Choosing Scheme:\nBy using Scheme NexT gives you different views. And nearly all config can be used by those Schemes.\n# next/_config.yml scheme: Muse Configuring Favicon:\nBy default the Hexo site use NexT favicons in hexo-site/themes/next/source/images/ directory with different size for different device.\nYou can replace them with your own favicons.\nFor example, you can put your favicons in hexo-site/source/images/ directory. Then you need to rename them and change the settings in favicon section in theme config file.\nCreative Commons:\nNexT supports the display of Creative Commons 4.0 International License in sidebar and post.\n# next/_config.yml creative_commons: license: by-nc-sa sidebar: true post: false language: en 通行的版权协议是一种限制性的协议，就是说，只有它明文许可你可以做的事，你才能做，否则就是侵权行为。\n而\u0026quot;开放内容许可证\u0026quot;（open content licenses）只明文禁止使用者不能做的事，除此以外，可以随意使用这些作品。创作共用许可证（Creative Commons licenses，简称cc），就是这样一种许可证。\n使用创作共用许可证，作者可以选择保留四种权利：\n 署名（Attribution，简写为by）：必须提到原作者。 非商业用途（Noncommercial，简写为nc）：不得用于盈利性目的。 禁止演绎（No Derivative Works，简写为nd）：不得修改原作品。 相同方式共享（Share Alike，简写为sa）：如果允许修改原作品，那么必须使用相同的许可证发布。  Configuring Menu Items:\nMenu settings items have format Key: /link/ || icon which contains 3 values:\n Key → is the name of menu item (home, archives, etc.). /link/ → is the target link to relative url inside your site. icon → is the name of Font Awesome icon.  To customize menu items, edit the following content in theme config file\nmenu: home: / || fa fa-home about: /about/ || fa fa-user tags: /tags/ || fa fa-tags archives: /archives/ || fa fa-archive Google Calendar Page\nschedule: /schedule/ || fa fa-calendar sitemap：为了让博文被google或百度检索，需要使用hexo的sitemap功能。\nsitemap: /sitemap.xml || fa fa-sitemap   Install\nnpm install hexo-generator-sitemap --save   Hexo Config\nsitemap: path: sitemap.xml   Except home and archives, all custom pages under menu section need to be created manually!\nSidebar Setting\nConfiguring Avatar：\nPut your avatar under site directory source/uploads/ (create directory if it doesn\u0026rsquo;t exists).And then change option to url: /uploads/avatar.png.\navatar: url: /uploads/avatar.png rounded: true 点击头像回到首页：\n主要是将\u0026lt;img class=\u0026quot;site-author-image\u0026quot; ... /\u0026gt;加入到\u0026lt;a href=\u0026quot;/\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;。\nSidebar Social Links：\n  Edit the social section in theme config file as following:\nsocial: GitHub: https://github.com/yourname || fab fa-github E-Mail: mailto:yourname@example.com || fa fa-envelope   取消社交图标前的小圆点：\n# create hexo-site/source/_data/styles.styl .links-of-author a, .links-of-author .exturl { \u0026amp;:before { display: none; } }   Sidebar Blogrolls (友链):\nlinks: Title1: https://example.com/ Sidebar TOC:\ntoc: number: false expand_all: true max_depth: 5 Footer\nSite Footer Icon:\nBy default NexT shows red heart icon between year and copyright information in the footer.\nfooter: icon: animated: true Site Copyright Name:\nBy default NexT shows the name of author from site config file.\nfooter: copyright: YourName Site Platform Information:\nBy default NexT shows Hexo and Theme \u0026amp; scheme information.\nfooter: powered: false Site Beian Information:\nBeian information is for Chinese users.\nfooter: beian: enable: true icp: 京ICP备 1234567890号-1 gongan_id: 1234567890 gongan_num: 京公网安备 1234567890号 gongan_icon_url: /uploads/beian.png Post Settings\nPreamble Text:\nYou can use following ways to show summary of articles and a Read More button.\nUse \u0026lt;!-- more --\u0026gt; in your article to break your article manually, which is recommended by Hexo. (recommended)\nIf you have added description and set its value to your article summary in front-matter, NexT excerpts description as preamble text in homepage by default. Without description, the full contents would be the preamble text in homepage.\nPost Wordcount:\n  Installation\ncd hexo-site npm install hexo-word-counter hexo clean   Hexo Config\nsymbols_count_time: total_symbols: false\t# By default NexT shows the number of all posts words in footer section. total_time: false\t# By default NexT shows the estimated reading time of all posts in footer section.    Donate Settings:\n  Get your WeChat / Alipay receive money QRcode image(s) and put into source/images .\n  Set needed values in theme config file:\nreward_settings: enable: true animation: false comment: Buy me a coffee reward: wechatpay: /images/wechatpay.png alipay: /images/alipay.png   Follow Me:\nfollow_me: WeChat: /images/wechat_channel.jpg || fab fa-weixin RSS: /atom.xml || fa fa-rss  安装RSS插件  npm i hexo-generator-feed  配置站点配置文件(/_config.yml)的Extensions  plugin: - hexo-generator-feed # Feed Atom feed: type: atom path: atom.xml limit: 20  编辑主题配置文件(/theme/next/_config.yml)的social links，开启RSS的页面功能  rss: /atom.xml  关注RSS：把 https://vanehsiung.github.io/atom.xml 复制到RSS阅读器上，就能关注了。  Custom Pages\nCustom Page Support:\n  Adding New Page\ncd hexo-site hexo new page tags   Setting Front-matter Values\n--- title: Tags date: title: 2020-11-14 22:50:2 type: \u0026quot;tags\u0026quot; ---   Editting Menu\nmenu: tags: /tags/ || fa fa-tags   Custom 404 Page:\n  Create a new page called 404\ncd hexo-site hexo new page 404 --- title: 404 permalink: /404.html\t# 在 Github Docs 中 Github Pages 章有写 comments: false ---   Make sure relative_link is disabled in site config file\nrelative_link: false   Whether users can be redirected to the 404 page depends on the settings of the website hosting service or web server, not Hexo.\n  为 GitHub Pages 站点创建自定义 404 页面\n  Misc Theme Settings\nMobile Devices Adaptation:\nreduce padding/margin indents on devices with narrow width\nmobile_layout_economy: true Codeblock Style:\nNexT uses the Highlight.js and Prism package to support code highlight\n  Read Hexo\u0026rsquo;s documentation on Syntax Highlighting first, and set it up in site config file（在 _config.yml 中开启 Highlight 或 Prism）\nhighlight: enable: true   Preview all available Code Highlight themes here: NexT Highlight Theme Preview\n  Change the value of theme and prism to choose the highlight style you like\ntheme: light: xcode   NexT supports the copy-and-paste functionality of codeblock\ncodeblock: copy_button: enable: true style: mac\t# Mac Panel风格代码块 Back To Top:\nback2top: scrollpercent: true Fonts Customization：\nfont: enable: true host: https://fonts.loli.net global: family: Architects Daughter, Ma Shan Zheng codes: family: Share Tech Mono   host：查看字体与使用字体的网址是不一样的；可能不能查看字体，但可以使用字体\n  查看 Google Fonts，使用 Google Fonts https://fonts.googleapis.com，以下为镜像\n  https://fonts.loli.net\n  https://fonts.googleapis.cnpmjs.org\n  https://fonts.proxy.ustclug.org\n      查看谷歌字体中文版，使用 https://fonts.font.im\n  技巧：先放 latin 文字，再放 chinese 文字，就可以分别定制英文与中文（有些中文字体包含英文字母）。手机无法显示自定义的中文字体，但可以显示自定义的英文字体。\n  SEO\nSEO Setting:\nNext provides useful options for better Search Engine Optimization (SEO).\nBy default a canonical link tag is created in Hexo after you have set up your URL url: http://example.com in site config file.\n# theme config file disable_baidu_transformation: true index_with_subtitle: true exturl: true Webmaster Tools:\n  Google Webmaster Tools\n  Login to Google Webmaster Tools and go to verification methods and choose HTML Tag, you will get some code:\n\u0026lt;meta name=\u0026quot;google-site-verification\u0026quot; content=\u0026quot;XXXXXXXXXXXXXXXXXXXXXXX\u0026quot;\u0026gt;   Copy XXXXXXXXXXXXXXXXXXXXXXX value of content key.Edit theme config file and add or change google_site_verification section:\ngoogle_site_verification: XXXXXXXXXXXXXXXXXXXXXXX   submit sitemap\n  That the new console says \u0026lsquo;couldnt fetch\u0026rsquo; is a bug in the console. Pending is the real status!\n    Bing Webmaster Tools\n  Login to Bing Webmaster Tools and go to verification methods and choose HTML Tag, you will get some code:\n\u0026lt;meta name=\u0026quot;msvalidate.01\u0026quot; content=\u0026quot;XXXXXXXXXXXXXXXXXXXXXXX\u0026quot;\u0026gt;   Copy XXXXXXXXXXXXXXXXXXXXXXX value of content key. Edit theme config file and add or change bing_site_verification section:\nbing_site_verification: XXXXXXXXXXXXXXXXXXXXXXX   submit sitemap\n  Bing 收录最快，立马就可以看到\n    Baidu Webmaster Tools\n  Login to Baidu Webmaster Tools and go to verification methods and choose HTML Tag, you will get some code:\n\u0026lt;meta name=\u0026quot;baidu-site-verification\u0026quot; content=\u0026quot;XXXXXXXXXXXXXXXXXXXXXXX\u0026quot;\u0026gt;   Copy XXXXXXXXXXXXXXXXXXXXXXX value of content key.Edit theme config file and add or change baidu_site_verification section:\nbaidu_site_verification: XXXXXXXXXXXXXXXXXXXXXXX   Push the url to baidu automatically\nbaidu_push: true   submit sitemap\n    Third-party Services Comment Systems\nLiveRe (Korea):\n  Create an account or log into LiveRe, click on the installation button and select the free city version, then click on the install now button.\n  Copy the data-uid field in the installation code to get your LiveRe UID.\n  Add the obtained LiveRe UID to the livere_uid section in the theme config file as following:\nlivere_uid:   Valine (China)：\n  Create an account or log into LeanCloud, and then click on the bottom left corner to create the application in dashboard.\n  Go to the application you just created, select Settings → App Keys in the lower left corner, and you will see your APP ID and APP Key.\n  Edit configurations in valine section in the theme config file as following:\nvaline: enable: true appId: appKey:   评论数据管理：请自行登录Leancloud应用管理。具体步骤：登录\u0026gt;选择你创建的应用\u0026gt;存储\u0026gt;选择Class Comment\n  Statistics and Analytics\nAnalytics Tools:\n  Baidu Analytics (China)\n  Login to Baidu Analytics and locate to site code getting page.\n  Copy the script ID after hm.js?.\n  Edit theme config file and change section baidu_analytics to your script ID.\nbaidu_analytics:     Google Analytics\n  Create an account and log into Google Analytics.\n  Edit theme config file and fill tracking_id under section google_analytics with your Google track ID. Google track ID always starts with UA- (最新版 Google Analytics 是 G-).\ngoogle_analytics: tracking_id: G-XXXXXXXX only_pageview: false     Counting Tools:\nBusuanzi Counting (China), Edit busuanzi_count option in theme config file.\n不蒜子是基于域名来进行统计计算的。数据比百度统计多很多。网络不好的话，数据与图标不一定显示得出来。\nbusuanzi_count: enable: true Search Services\nLocal Search:\nThis search method is recommended for most users.\n  Installation\nnpm install hexo-generator-searchdb   Hexo Config\nsearch: path: search.xml field: post content: true format: html   NexT Config\nlocal_search: enable: true   External Libraries\nPJAX：\n  You can enable it by setting value pjax to true in theme config file.\npjax: true   It listens to every click on links you want (by default all of them).When an internal link is clicked, Pjax fetches the page\u0026rsquo;s HTML via AJAX.\n  Please use the absolute path of the image or Hexo asset_img tag in your posts, otherwise the images may fail to load during Pjax refresh.\n  例子：添加音乐播放器并保持跳转时不中断播放状态；fireworks 特效更流畅，不存在点击链接时的卡顿现象（点击链接时不会触发fireworks）。\n  Fancybox:\nA jQuery lightbox script for displaying images, videos and more.\nfancybox: true Lazyload:\nIt delays loading of images in long web pages. Images outside of viewport will not be loaded before user scrolls to them.\nlazyload: true Progress Bar:\nNProgress will automatically monitor your Ajax requests, event loop lag, document ready state and elements on your page to decide on the progress.\nnprogress: enable: true spinner: false Canvas Ribbon：\ncanvas_ribbon: enable: true size: 300\t# The width of the ribbon. alpha: 0.6\t# The transparency of the ribbon. zIndex: -1\t# The display level of the ribbon. 粒子漂浮聚合：\n该功能由 theme-next-canvas-nest 插件提供：\n  Create a file named footer.njk  in hexo/source/_data directory, Edit this file and add the following content\n\u0026lt;script color=\u0026quot;0,0,255\u0026quot; opacity=\u0026quot;0.5\u0026quot; zIndex=\u0026quot;-1\u0026quot; count=\u0026quot;99\u0026quot; src=\u0026quot;https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;   In the NexT _config.yml, uncomment footer under the custom_file_path section.\ncustom_file_path: footer: source/_data/footer.njk   Tag Plugins Mermaid\n  Settings\nmermaid: enable: true   Usage\n{% mermaid type %} {% endmermaid %}   Advanced Settings Custom Files\n  uncomment under the section in theme config file.stylecustom_file_path。\ncustom_file_path: head: source/_data/head.njk header: source/_data/header.njk ...   Edit in site root directory and add files:source/_data/...。\n  Then use it。\n  Stylus 是 CSS 的预处理框架，给 CSS 添加了可编程的特性。Stylus支持三种注释，单行注释（//)，多行注释(/* */)。\n  Nunjucks 是 jinja2 的 javascript 的实现，可以使用 {# and #} 来写注释，渲染时将会去除所有的注释。\n  不要直接修改 model 文件，而要使用 custom file，方便之后升级。\n  Front Matter\n--- photos: /uploads/png.png --- Misc Settings 想要什么功能可以搜一下，看是否有现成的 model 可以使用。\n网易云音乐\n 在网页版云音乐中找到歌曲，点击生成外链播放器 根据个人喜好选择播放器尺寸和播放模式 将获取到的 iframe 代码添加到页面中  Aplayer 音频播放器\n  借助 hexo-tag-aplayer 插件，可以通过标签的形式方便快捷的插入音频组件。\n  Installation\nnpm install --save hexo-tag-aplayer   Usage\n{% aplayer \u0026quot;title\u0026quot; \u0026quot;author\u0026quot; \u0026quot;url\u0026quot; [\u0026quot;picture_url\u0026quot;, \u0026quot;narrow\u0026quot;, \u0026quot;autoplay\u0026quot;, \u0026quot;width:xxx\u0026quot;, \u0026quot;lrc:xxx\u0026quot;] %}  title: 曲目标题 author: 曲目作者 url: 音乐文件 URL 地址 picture_url: (可选) 音乐对应的图片地址 narrow: （可选）播放器袖珍风格 autoplay: (可选) 自动播放，移动端浏览器暂时不支持此功能 width:xxx: (可选) 播放器宽度 (默认: 100%) lrc:xxx: （可选）歌词文件 URL 地址    当开启 Hexo 的 文章资源文件夹功能时，可直接引用\n{% aplayer \u0026quot;Caffeine\u0026quot; \u0026quot;Jeff Williams\u0026quot; \u0026quot;caffeine.mp3\u0026quot; \u0026quot;picture.jpg\u0026quot; \u0026quot;lrc:caffeine.txt\u0026quot; %}   Dpalyer 视频播放器\n  Installation\nnpm install hexo-tag-dplayer --save   Usage\n{% dplayer \u0026quot;url=video-url\u0026quot; \u0026quot;pic=image-url\u0026quot; ... [\u0026quot;key=value\u0026quot;] %}   部分重要 key\n 播放器  autoplay：是否开启视频自动播放，默认为 fasle loop：是否开启视频循环播放，默认为 false screenshot：是否开启截图，默认为 false mutex：是否禁止多个播放器同时播放，默认为 true dmunlimited：是否开启海量弹幕模式，默认为 false preload：预加载模式，可选 note metadata auto theme：主题色 lang：语言，可选 en zh-cn zh-tw logo：左上角的 Logo volume：默认音量，默认为 0.7 width：播放器宽度 height：播放器长度   视频  url：视频链接 pic：视频封面 thumbnails：视频缩略图，可以使用 DPlayer-thumbnails 生成 vidtype：视频类型，可选 auto hls flv dash 或其他自定义类型   字幕  suburl：字幕链接 subtype：字幕类型，可选 webvtt ass，目前只支持 webvtt subbottom：字幕距离播放器底部的距离，如 10px 10% subcolor：字幕颜色   弹幕  id：弹幕 id api：弹幕 api token：弹幕后端验证 token addition：额外外挂弹幕 dmuser：弹幕用户名 maximum：弹幕最大数量      看板娘\n该功能由 hexo-helper-live2d 插件支持\n  Installation\nnpm install --save hexo-helper-live2d   Config：在站点配置文件中设置，主题配置文件中设置没用\nlive2d: enable: true scriptFrom: local pluginRootPath: live2dw/ pluginJsPath: lib/ pluginModelPath: assets/ tagMode: false log: false model: use: live2d-widget-model-shizuku display: position: right width: 150 height: 300 mobile: show: true react: opacity: 0.7   Models：可以从 hexo live2d 模型预览 里找到你喜欢的角色，然后根据 live2d-widget-models 中提供的方法来下载模型数据.\nnpm install live2d-widget-model-shizuku   Fireworks\n一个鼠标点击动画特效\nnpm install next-theme/hexo-next-fireworks activate-power-mode\n一个为博客添加酷炫打字特效的插件\n  编辑 /hexo-site/source/_data/footer.njk\n\u0026lt;script src=\u0026quot;https://cdn.jsdelivr.net/gh/suyin-long/activate-power-mode@1.0/dist/activate-power-mode.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; POWERMODE.colorful = true; // make power mode colorful POWERMODE.shake = false; // turn off shake document.body.addEventListener('input', POWERMODE); \u0026lt;/script\u0026gt;   取消footer: source/_data/footer.njk的注释\n  搞怪网页标题\n  编辑 /hexo-site/source/_data/head.njk，添加\n{# 搞怪网页标题 #} {% if theme.title_trick.enable %} \u0026lt;script\u0026gt; var OriginTitile = document.title; var titleTime; document.addEventListener(\u0026quot;visibilitychange\u0026quot;, function() { if (document.hidden) { document.title = \u0026quot;{{ theme.title_trick.leave }}\u0026quot;; clearTimeout(titleTime); } else { document.title = \u0026quot;{{ theme.title_trick.enter }}\u0026quot;; titleTime = setTimeout(function() { document.title = OriginTitile; }, 2000); } }); \u0026lt;/script\u0026gt; {% endif %}   在主题配置文件中添加\n# a trick on website title title_trick: enable: true leave: \u0026#34;(つェ⊂)我藏好了哦~\u0026#34; enter: \u0026#34;(*´∇｀*) 被你发现啦~\u0026#34;   我先是放在 sorce/_data/head.njk 中，问题是改变一次标题后就只显示网址。我认为 script 可能在 \u0026lt;title\u0026gt; 之前加载，所以就放在 source/_data/header.njk，正常运行。\n  Hexo NexT Three\n  Install\nnpm install next-theme/hexo-next-three   Configure\n# JavaScript 3D library. # Dependencies: https://github.com/next-theme/hexo-next-three three: enable: true defer: true cdn: waves: enable: false cdn: lines: enable: false cdn: sphere: enable: false cdn:   hexo-cake-moon-menu\n  How to use\nnpm install hexo-cake-moon-menu   Config: In hexo _config.yml\nmoon_menu: back2top: enable: true icon: fas fa-chevron-up func: back2top order: -1 back2bottom: enable: true icon: fas fa-chevron-down func: back2bottom order: -2   permalink\n  默认的文章 url 地址为 http://yoursite.com/:year/:month/:day/:title/，这种 url 格式层级太多，并且如果文章标题是中文的话可能会发生转义而出现一堆乱码，不利于搜索引擎的爬取分析，因此建议在站点配置中修改 permalink 的格式来简化页面 url，并尽量采用英文命名 Markdown 文件。(这个根据个人选择，我认为有更有组织的文件结构更重要)\n  这个 front matter 必须是 html 文件，文件会生成到 public 根目录。\n --- permalink: /post-name.html ---   robots.txt\nrobots.txt（统一小写）是一种存放于网站根目录下的ASCII编码的文本文件，它通常告诉网络搜索引擎的漫游器（又称网络蜘蛛），此网站中的哪些内容是不应被搜索引擎的漫游器获取的，哪些是可以被漫游器获取的。\nrobots.txt在线生成器\nCDN CDN 的全称是(Content Delivery Network)，即内容分发网络。其目的是通过在现有的 Internet 中增加一层新的CACHE(缓存)层，将网站的内容发布到最接近用户的网络“边缘”的节点，使用户可以就近取得所需的内容，提高用户访问网站的响应速度。从技术上全面解决由于网络带宽小、用户访问量大、网点分布不均等原因，提高用户访问网站的响应速度。\nCDN 工作原理 传统访问过程：\n 用户输入访问的域名，操作系统向 LocalDns 查询域名的ip地址 LocalDns 向 ROOT DNS 查询域名的授权服务器（这里假设LocalDns缓存过期） ROOT DNS 将域名授权 dns 记录回应给 LocalDns LocalDns 得到域名的授权 dns 记录后，继续向域名授权 dns 查询域名的 ip 地址 域名授权 dns 查询域名记录后，回应给 LocalDns LocalDns 将得到的域名 ip 地址，回应给用户端 用户得到域名 ip 地址后，访问站点服务器 站点服务器应答请求，将内容返回给客户端  CDN 访问过程：\n 用户输入访问的域名，操作系统向 LocalDns 查询域名的 ip 地址 LocalDns 向 ROOT DNS 查询域名的授权服务器（这里假设LocalDns缓存过期） ROOT DNS 将域名授权 dns 记录回应给 LocalDns LocalDns 得到域名的授权 dns 记录后，继续向域名授权 dns 查询域名的 ip 地址 域名授权 dns 查询域名记录后（一般是CNAME），回应给 LocalDns LocalDns 得到域名记录后，向智能调度 DNS 查询域名的 ip 地址 智能调度 DNS 根据一定的算法和策略，将最适合的 CDN 节点 ip 地址回应给 LocalDns LocalDns 将得到的域名 ip 地址，回应给用户端 用户得到域名 ip 地址后，访问站点服务器 CDN 节点服务器应答请求，将内容返回给客户端  参考 CDN加速原理\nNPM npm makes it easy for JavaScript developers to share and reuse code, and it makes it easy to update the code that you\u0026rsquo;re sharing.\n基本：\n  package.json 和 package-lock.json\n package.json 执行 npm init 命令生成，描述项目模块信息 package-lock.json 执行 npm install 命令生成，描述模块来源及依赖信息，可删除    安装模块：\n  全局安装\nnpm install -g 模块名称   本地安装：读取 package.json 并下载模块到 node_modules 的目录，模块分为两类 dependencies 和devDependencies，分别对应生产环境需要的安装包和开发环境需要的安装包\nnpm install \u0026lt;package_name\u0026gt; # 在安装模块的时候，可以通过指定参数来修改 package.json 文件 npm install \u0026lt;package_name\u0026gt; --save npm install \u0026lt;package_name\u0026gt; --save-dev     更新模块\nnpm update   卸载模块\nnpm uninstall -g \u0026lt;package_name\u0026gt; npm uninstall \u0026lt;package_name\u0026gt; # 卸载模块的同时，也从 package.json 文件中移除 npm uninstall --save \u0026lt;package_name\u0026gt; npm uninstall --save-dev \u0026lt;package_name\u0026gt;   解决问题：\n  Ubuntu 安装最新 LTS 版本：官方教程，Windows 版本更好\nsudo mkdir -p /usr/local/lib/nodejs sudo tar -xJvf node-$VERSION-$DISTRO.tar.xz -C /usr/local/lib/nodejs vi ~/.profile # Nodejs VERSION=v10.15.0 DISTRO=linux-x64 export PATH=/usr/local/lib/nodejs/node-$VERSION-$DISTRO/bin:$PATH . ~/.profile\t# Refresh profile sudo ln -s /usr/local/lib/nodejs/node-$VERSION-$DISTRO/bin/node /usr/bin/node   查看 npm 配置\nnpm config list -l npm config ls   配置镜像：淘宝镜像不好用，特对对于 update\nnpm config set registry https://registry.npmjs.org --global   配置 NPM 不做严格的 SSL 校验\nnpm config set strict-ssl false   npm ERR! Unexpected end of JSON input while parsing near \u0026hellip;\nnpm cache clean --force   npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents：不管\n  npm ERR! code EINTEGRITY\ngrep -ir \u0026quot;sha1-WYr+VHVbKGilMw0q/51Ou1Mgm2U\u0026quot; ~/.npm\t# wanted sha1 npm cache clean --force grep -ir \u0026quot;sha1-WYr+VHVbKGilMw0q/51Ou1Mgm2U\u0026quot; ~/.npm npm install   getaddrinfo EAI_AGAIN registry.npmjs.org：网络问题，重新运行 npm install\n  升级为最新稳定版本的 node.js：超慢\nsudo npm cache clean -f sudo npm install -g n\t# n 是 Node版本管理控制器 sudo n stable   NPM 中文文档\nGreat Blogs yearito ，suyin ，yleao ，dlzhang\nVersion    Name Version     npm 7.0.8   hexo 5.2.0   hexo-theme-next 8.0.2    ","permalink":"https://sakamotokurome.github.io/posts/hexo/","summary":"Hexo Hexo 是一个快速、简洁且高效的博客框架。 安装 安装 Git： Windows: Download \u0026amp; install git. Mac: Install it with Homebrew, MacPorts or installer. Linux (Ubuntu, Debian): sudo apt-get install git-core Linux (Fedora, Red Hat, CentOS): sudo yum install git-core 安装 node.js： Windows: Install it with","title":"Hexo"},{"content":"Workspace：工作区，Index / Stage：暂存区，Repository：仓库区（或本地仓库），Remote：远程仓库\n远程仓库 安装，windows需要处理换行符 sudo yum install git 设置姓名和邮箱地址 git config --global user.name \u0026#34;Vane Hsiung\u0026#34; git config --global user.email \u0026#34;1664548605@qq.com\u0026#34; 提高输出可读性 git config --global color.ui auto 设置文件   显示当前的 Git 配置\ngit config --list cat ~/.giconfig   编辑Git配置文件\ngit config -e [--global]   设置SSH，添加认证密码 ssh-keygen -t rsa -C \u0026#34;1664548605@qq.com\u0026#34; 添加公开密钥 将下面的密钥添加到 GitHub 设置中的 SSH key 中\ncat ~/.ssh/id_rsa.pub 查看是否认证和通信成功 ssh -T git@github.com 获取远程仓库 clone 后默认在 master 分支下自动将 origin 设置为远程仓库标识符\ngit clone SSH 提速：\ngit clone SSH --depth=1 加上 \u0026ndash;depth 会只下载一个 commit，所以内容少了很多，速度也就上去了。\n而且下载下来的内容是可以继续提交新的 commit、创建新的分支的。不影响后续开发，只是不能切换到历史 commit 和历史分支。\n在一些场景下还是比较有用的：当需要切换到历史分支的时候也可以计算需要几个 commit，然后再指定 depth，这样也可以提高速度。\n获取远程非master分支 -b 后是新建分支名称\ngit checkout -b branchName origin/branchName 获取指定分支 使用git拉代码时可以使用 -b 指定分支，拉取 develop 分支代码：\ngit clone -b develop http://gitslab.yiqing.com/declare/about.git 查看当前项目拉的是哪个分支的代码详情：\ngit branch -v 查看分支上的递交情况:\ngit show-branch 获取最新的远程仓库分支 远程仓库拉取代码并合并到本地，可简写为 git pull 等同于 git fetch \u0026amp;\u0026amp; git merge\ngit pull \u0026lt;远程主机名\u0026gt; \u0026lt;远程分支名\u0026gt;:\u0026lt;本地分支名\u0026gt; # 取回远程仓库的变化，并与本地分支合并 git pull origin branchName # 使用rebase的模式进行合并 git pull --rebase \u0026lt;远程主机名\u0026gt; \u0026lt;远程分支名\u0026gt;:\u0026lt;本地分支名\u0026gt; # 获取远程仓库特定分支的更新 git fetch \u0026lt;远程主机名\u0026gt; \u0026lt;分支名\u0026gt; # 获取远程仓库所有分支的更新 git fetch --all 问题：For those who found this searching for an answer to fatal: 'origin/remote-branch-name' is not a commit and a branch 'local-branch-name' cannot be created from it, you may also want to try this first:\ngit fetch --all 与 git pull 不同的是 git fetch 操作仅仅只会拉取远程的更改，不会自动进行 merge 操作。对你当前的代码没有影响。\ngit rebase 让你的提交记录更加清晰可读\nrebase 翻译为变基，他的作用和 merge 很相似，用于把一个分支的修改合并到当前分支上。\n即逐个应用了 mater 分支的更改，然后以 master 分支最后的提交作为基点，再逐个应用 feature 的每个更改。\n大部分情况下，rebase 的过程中会产生冲突的，此时，就需要手动解决冲突，然后使用依次 git add  、git rebase --continue  的方式来处理冲突，完成 rebase 的过程，如果不想要某次 rebase 的结果，那么需要使用 git rebase --skip  来跳过这次 rebase 操作。\ngit merge 和 git rebase 的区别\n不同于 git rebase 的是，git merge 在不是 fast-forward（快速合并）的情况下，会产生一条额外的合并记录，类似 Merge branch 'xxx' into 'xxx' 的一条提交信息。\n另外，在解决冲突的时候，用 merge 只需要解决一次冲突即可，简单粗暴，而用 rebase 的时候 ，需要依次解决每次的冲突，才可以提交。\n同一台电脑配置多个 GItHub 账号 在日常使用 git 作为仓库使用的时候，有时可能会遇到这样的一些情况：\n 有两个 github 账号，一台电脑怎么同时连接这两个账号进行维护呢？ 自己用一个 github 账号，平时用来更新自己的一些资料；公司使用的 gitlab（也是 git 的衍生产品）  如下是解决方案：\n  创建默认 SSH Key\nssh-keygen -t rsa -C \u0026#34;one@example.com\u0026#34;   将公钥添加到 one@example.com 的 GitHub SSH key 中。\n  测试 ssh key 是否成功\nssh -T git@github.com   如果设置过全局，则清除 git 的全局设置\n# 查看当前配置 git config --list # 取消 global user.name user.email git config --global --unset user.name git config --global --unset user.email   生成另外一个账号新的SSH keys\nssh-keygen -t rsa -C \u0026#34;two@example.com\u0026#34; 私钥需重命名，如 id_rsa_two。然后将对应的公钥添加到two@example.com的 Github SSH key 中。\n  需添加新私钥到 SSH agent 中，因为默认只读取 id_rsa\n# Windows 在管理员下运行 Get-Service ssh-agent Set-Service ssh-agent -StartupType Manual Start-Service ssh-agent # Linux eval `ssh-agent -s` # 添加私钥 ssh-add ~/.ssh/id_rsa_new unable to start ssh-agent service\nCould not open a connection to your authentication agent\n  配置 ~/.ssh/config 文件，用于配置私钥对应的服务器\n# Default github user(one@example.com) Host git@github.com HostName github.com User \u0026#34;Your GitHub Account Name\u0026#34; IdentityFile ~/.ssh/id_rsa # another user(two@example.com) # 建一个别名，新建的帐号使用这个别名做克隆和更新 # \u0026#34;Host\u0026#34; 如果带了 \u0026#34;git@\u0026#34;，如 \u0026#34;git@two.github.com\u0026#34;，就会连接到 two.github.com # \u0026#34;Host\u0026#34; 没有带 \u0026#34;git@\u0026#34;，就会正确的连接到 github.com Host two.github.com HostName github.com User \u0026#34;Your GitHub Account Name\u0026#34; IdentityFile ~/.ssh/id_rsa_two 测试\n# default ssh -T git@github.com # another ssh -T git@two.github.com   使用\n# default git remote add origin git@github.com:one/demo.git # another git remote add origin git@two.github.com:two/demo.git   设置每个项目的自己的 user.name 和 user.email\ngit config user.email \u0026#34;two@example.com\u0026#34; git config user.name \u0026#34;two\u0026#34;   Git 中 HTTPS 和 SSH 的 Clone 方式区别  HTTPS：不管是谁，拿到url随便clone，但是在push的时候需要验证用户名和密码； SSH：clone的项目你必须是拥有者或者管理员，而且需要在clone前添加SSH Key。SSH 在push的时候，是不需要输入用户名的，如果配置SSH key的时候设置了密码，则需要输入密码的。  本地仓库 初始化仓库 生成 .git 目录, 也就是当前目录的仓库，当前目录称为“附属于该仓库的工作树”\ngit init [project-name] 查看仓库的状态 git status\t# 显示有变更的文件 向暂存区添加文件   添加指定文件到暂存区\ngit add [file1] [file2] ...   添加指定目录到暂存区，包括子目录\ngit add [dir]   添加当前目录的所有文件到暂存区\ngit add .   删除工作区文件，并且将这次删除放入暂存区\ngit rm [file1] [file2] ...   改名文件，并且将这个改名放入暂存区\ngit mv [file-original] [file-renamed]   原理（git add 为如下两步简写）：\n  为 example.txt 创建一个副本。git hash-object 命令把 example.txt 的当前内容压缩成二进制文件，称为一个 Git 对象，保存在 .git/objects 目录。并计算当前内容的哈希值，前 2 个字符作为目录名，后 38 个字符作为该对象的文件名\ngit hash-object -w example.txt 二进制对象里面会保存一些元数据，如果想看该文件原始的文本内容，需用git cat-file命令\ngit cat-file -p e69de29bb2d1d6434b8b29ae775ad8c2e48c5391   所有变动的文件，Git 都记录在\u0026quot;暂存区\u0026quot;，git update-index 命令用于在暂存区记录一个发生变动的文件\ngit update-index --add --cacheinfo 100644 e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 example.txt git ls-files 命令显示暂存区当前内容\ngit ls-files --stage   查看更改前后的差别 习惯：git commit 前先 git diff HEAD\ngit diff 默认查看工作树和暂存区的差别\nHEAD查看工作树与最新提交的差别，HEAD 为指向当前分支中最新一次提交的指针，HEAD^ 指向 HEAD 的前一个提交，HEAD~6 则是 HEAD 之前的第6个提交。每一个分支都是一个文本文件，保存在 .git/refs/heads/ 目录中，文件的内容是最新提交的哈希值\ngit diff [HEAD] 将暂存区中文件保存到仓库历史记录中 -m 用于记录一行信息；不加 -m 记录详细信息，会新开编辑器进行编辑\n  相当与 git add 与 git commit\ngit commit -am \u0026#34;Message\u0026#34;\t  提交暂存区的指定文件到仓库区\ngit commit [file1] [file2] ... -m \u0026#34;Message\u0026#34;   提交工作区自上次commit之后的变化，直接到仓库区\ngit commit -a   提交时显示所有diff信息\ngit commit -v   原理（git commit -m \u0026quot;first commit\u0026quot; 为如下两步简写）：\n  git write-tree 命令保存当前的目录结构，生成一个 Git 对象\ngit write-tree   git commit-tree 命令用目录结构 Git 对象生成一个 Git 对象，需添加提交说明，-p 参数用来指定父提交\necho \u0026#34;first commit\u0026#34; | git e5a60f66d9966270c835343d4facc1c4bf44ed7a -p c9053865e9dff393fd2f7a92a18f9bd7f2caa7fa   修改提交信息 产生一个新的提交对象，替换掉上一次提交产生的提交对象\ngit commit --amend -m \u0026#34;Message\u0026#34; 重做上一次 commit，并包括指定文件的新变化\ngit commit --amend [file1] [file2] ... 压缩历史 用于拼错单词等简单的错误，选定当前分支中包含 HEAD（最新提交）在内的 number 个最新历史记录为对象并在编辑器中打开，pick 为合并对象，fixup 为被合并对象，最后 pick 提交信息会保留\ngit rebase -i HEAD~[number] 查看提交日志   --pretty=short 用于只显示第一行简述信息\n  FileName 为文件名或目录名，只显示指定文件的日志\n  -p 用于显示文件的改动\n  --stat 显示 commit 历史，以及每次 commit 发生变更的文件\ngit log [--pretty=short][FileName][-p][--stat]\t# 显示当前分支的版本历史   查看文件每次提交的diff\ngit log -p FileName   搜索提交历史，根据关键词\ngit log -S [keyword]   显示某个 commit 之后的所有变动，每个commit占据一行\ngit log [tag] HEAD --pretty=format:%s   显示某个 commit 之后的所有变动，其\u0026quot;提交说明\u0026quot;必须符合搜索条件\ngit log [tag] HEAD --grep feature   显示某个文件的版本历史，包括文件改名\ngit log --follow [file] git whatchanged [file]   git log 的运行过程\n 查找 HEAD 指针对应的分支 找到分支的最新提交 找到父节点（前一个提交） 依此类推，显示当前分支的所有提交  查看当前仓库操作日志 git reflog 怎么查看当前的git分支是基于哪个分支创建的\ngit reflog --date=local | grep \u0026lt;branchname\u0026gt;\n类似于如下\n6b3db1f HEAD@{Fri Jul 9 16:05:23 2021}: checkout: moving from development to feature/api_xiongwen_dump 可知 feature/api_xiongwen_dump 基于 development\n从暂存区撤销文件 停止追踪指定文件，但该文件会保留在工作区\ngit rm --cached [filename] 撤销提交 在当前提交后面，新增一次提交，抵消掉上一次提交导致的所有变化\ngit revert HEAD 想抵消多个提交，必须在命令行依次指定这些提交\ngit revert [倒数第一个提交] [倒数第二个提交] 回溯历史版本   重置暂存区的指定文件，与上一次 commit 保持一致，但工作区不变\ngit reset [file]   重置暂存区与工作区，与上一次 commit 保持一致\ngit reset --hard   让最新提交的指针回到以前某个时点，该时点之后的提交都从历史中消失\ngit reset 目标时间点哈希值\t# 重置当前分支的指针为指定 commit，同时重置暂存区，但工作区不变   默认情况下，git reset不改变工作区的文件（但会改变暂存区），--hard参数可以让工作区里面的文件也回到以前的状态\ngit reset --hard 目标时间点哈希值\t# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致   重置当前 HEAD 为指定 commit，但保持暂存区和工作区不变\ngit reset --keep [commit]   添加远程仓库 origin 为远程仓库的标识符\ngit remote add origin SSH\t# 增加一个新的远程仓库，并命名 git remote -v\t# 显示所有远程仓库 git remote show [remote]\t# 显示某个远程仓库的信息 推送至远程仓库  推送的是当前分支 -u 在推送的同时将远程仓库的（origin仓库）的 branch 分支设为本地仓库当前分支的 upstream（上游） 运行 git pull 从远程仓库获取内容时，就可以省略参数  git push [-u origin branchName]\t# 上传本地指定分支到远程仓库 git push --set-upstream origin [branchName]\t# To push the current branch and set the remote as upstream 如果每次 git push 都需要输入账号和密码\n  首先在 git 工作目录下：\ngit config [--global] credential.helper store   然后执行一次 git pull，这次输入账号和密码之后就不用再输入了。\n  Git push existing repo to a new and different remote repo server? 需求：从公司的账户 clone repo 到本地，添加注释，pull 到自己账户的私有 repo 中。\n Create a new repo at github. git remote rename origin upstream git remote add origin URL_TO_GITHUB_REPO git push origin master  Now you can work with it just like any other github repo. To pull in patches from upstream, simply run git pull upstream master \u0026amp;\u0026amp; git push origin master.\n分支 创建并切换分支 # 切换分支，并更新工作区 git checkout branchName\t#切换至上一分支 git checkout -\t# 新建一个分支，并切换到该分支 git checkout -b branchName\t# 新建本地分支，但不切换 git branch \u0026lt;branch-name\u0026gt; # 新建一个分支，指向指定commit git branch [branch] [commit]\t# 新建一个分支，与指定的远程分支建立追踪关系 git branch --track [branch] [remote-branch]\t以图表形式查看分支 git log --graph 显示分支 # 列出所有本地分支 git branch\t# 列出所有远程分支 git branch -r\t# 同时显示本地仓库和远程仓库的分支信息 git branch -a\t# 用于创建分支 git branch branchName\t# 本地分支对应哪个远程分支 git branch -vv 合并分支  --no-ff 用于记录本次分支合并 消除冲突：打开冲突的文件，在编辑器中改为想要的样子  git merge [--no-ff] branchName\t# 合并指定分支到当前分支 git cherry-pick [commit]\t# 选择一个 commit，合并进当前分支 删除分支   删除分支\n# 删除本地分支 git branch -d [branch-name]   删除远程分支\ngit push origin --delete [branch-name] git branch -dr [remote/branch]   撤销工作区的文件修改   先找暂存区，如果该文件有暂存的版本，则恢复该版本，否则恢复上一次提交的版本\ngit checkout -- [filename]   恢复某个 commit 的指定文件到暂存区和工作区\ngit checkout [commit] [file]   恢复暂存区的所有文件到工作区\ngit checkout .   分支重命名   重命名本地分支：\n  在当前分支时\ngit branch -m new_branch_name   当不在当前分支时\ngit branch -m old_branch_name new_branch_name     重命名远端分支：\n假设是在当前分支，并且远端分支与本地分支名是一致的重命名本地分支\ngit branch -m new_branch_name 删除远程分支\ngit push --delete origin old_branch_name 上传新命名的本地分支\ngit push origin new_branch_name 关联修改后的本地分支与远程分支\ngit branch --set-upstream-to origin/new_branch_name   标签   列出所有 tag\ngit tag   新建一个 tag 在当前commit\ngit tag [tag]   新建一个tag在指定commit\ngit tag [tag] [commit]   删除本地 tag\ngit tag -d [tag]   删除远程 tag\ngit push origin :refs/tags/[tagName]   查看 tag 信息\ngit show [tag]   提交指定 tag\ngit push [remote] [tag]   提交所有tag\ngit push [remote] --tags   新建一个分支，指向某个tag\ngit checkout -b [branch] [tag]   Git Ignore git 为我们提供了一个 .gitignore 文件，只要在这个文件中申明哪些文件你不希望添加到git中去，这样当你使用 git add . 的时候这些文件就会被自动忽略掉。\n经实验，可以为每一个平行非包含的目录设定一个 .gitignore。\nPull Request 当你想更正别人仓库里的错误时，要走一个流程：\n 先 fork 别人的仓库，相当于拷贝一份，相信我，不会有人直接让你改修原仓库的。 clone 到本地分支，做一些 bug fix。 发起 pull request 给原仓库，让他看到你修改的 bug。 原仓库 review 这个 bug，如果是正确的话，就会 merge 到他自己的项目中  至此，整个 pull request 的过程就结束了。\n拉取请求，就是请求对方拉取我本地仓库的 bug fix，合并到对方的 repo 中。以对方的视角来看，我的本地仓库就是一个远程仓库。因为我们是在请求对方做什么，所以要以对方视角来看，即 pull，因为对方可能同意，也可能不同意，所以是请求，即 pull request。\nGitHub Hosts GitHub520 本项目无需安装任何程序，通过修改本地 hosts 文件，试图解决：\n GitHub 访问速度慢的问题 GitHub 项目中的图片显示不出的问题  花 5 分钟时间，让你\u0026quot;爱\u0026quot;上 GitHub。\n# GitHub520 Host Start 140.82.112.26 alive.github.com 140.82.114.25 live.github.com 185.199.108.154 github.githubassets.com 140.82.113.22 central.github.com 185.199.108.133 desktop.githubusercontent.com 185.199.108.153 assets-cdn.github.com 185.199.108.133 camo.githubusercontent.com 185.199.108.133 github.map.fastly.net 199.232.69.194 github.global.ssl.fastly.net 140.82.113.4 gist.github.com 185.199.108.153 github.io 140.82.114.3 github.com 140.82.114.5 api.github.com 185.199.108.133 raw.githubusercontent.com 185.199.108.133 user-images.githubusercontent.com 185.199.108.133 favicons.githubusercontent.com 185.199.108.133 avatars5.githubusercontent.com 185.199.108.133 avatars4.githubusercontent.com 185.199.108.133 avatars3.githubusercontent.com 185.199.108.133 avatars2.githubusercontent.com 185.199.108.133 avatars1.githubusercontent.com 185.199.108.133 avatars0.githubusercontent.com 185.199.108.133 avatars.githubusercontent.com 140.82.112.10 codeload.github.com 52.216.170.203 github-cloud.s3.amazonaws.com 52.217.98.76 github-com.s3.amazonaws.com 52.216.164.3 github-production-release-asset-2e65be.s3.amazonaws.com 52.216.160.147 github-production-user-asset-6210df.s3.amazonaws.com 52.217.103.12 github-production-repository-file-5c1aeb.s3.amazonaws.com 185.199.108.153 githubstatus.com 64.71.168.201 github.community 185.199.108.133 media.githubusercontent.com # Update time: 2021-07-04T08:07:49+08:00 # Star me GitHub url: https://github.com/521xueweihan/GitHub520 # GitHub520 Host End GitHub Pages 使用 GitHub GitHub Pages 是一项静态站点托管服务，它直接从 GitHub 上的仓库获取 HTML、CSS 和 JavaScript 文件，（可选）通过构建过程运行文件，然后发布网站。\n有三种类型的 GitHub Pages 站点：项目、用户和组织。 项目站点连接到 GitHub 上托管的特定项目。 用户和组织站点连接到特定的 GitHub 帐户。\nTo publish a user site, you must create a repository owned by your user account that\u0026rsquo;s named \u0026lt;username.github.io\u0026gt;. Repositories using the legacy \u0026lt;username.github.com\u0026gt; naming scheme will still be published, but visitors will be redirected from http(s)://\u0026lt;username.github.com\u0026gt; to http(s)://\u0026lt;username.github.io. If both a \u0026lt;username.github.com\u0026gt; and \u0026lt;username.github.io\u0026gt; repository exist, only the \u0026lt;username.github.io\u0026gt; repository will be published.\nGitHub Pages sites are publicly available on the internet, even if the repository for the site is private or internal. 如果站点的仓库中有敏感数据，您可能想要在发布前删除它。\nGitHub Pages 站点的发布来源是存储站点源文件的分支和文件夹。用户和组织站点的默认发布源是仓库默认分支的根目录。 项目站点的默认发布来源是 gh-pages 分支的根目录。\n您可以创建自己的静态文件或使用静态站点生成器为您构建站点。默认情况下，GitHub Pages 将使用 Jekyll 来构建您的站点。\nGitHub Pages 站点受到以下使用限制的约束：\n GitHub Pages source repositories have a recommended limit of 1GB. 发布的 GitHub Pages 站点不得超过 1 GB。 GitHub Pages sites have a soft bandwidth limit of 100GB per month. GitHub Pages sites have a soft limit of 10 builds per hour.  可在 Repository 的 Settings 中配置 GitHub Pages 站点的发布源或取消发布 GitHub Pages 站点。\n使用 jekyll Github Docs 与 Jekyll 文档不一致，Windows 并未正式支持 Jekyll。\n使用 Hexo 我选择 Hexo，一个是安装简单；一个是文档好。\nGitHub Actions GitHub Actions 是什么 持续集成由很多操作组成，比如自动抓取代码、运行测试、登录远程服务器、发布到第三方服务等。GitHub 把这些操作就称为 actions。\n很多操作在不同项目里面是类似的，可以共享。GitHub 允许开发者把每个操作写成独立的脚本文件，存放到代码仓库，使得其他开发者可以引用。\n可在官方市场与 awesome actions 找 action。\nworkflow 文件 GitHub Actions 的配置文件叫做 workflow 文件，存放在代码仓库的 .github/workflows 目录。\nworkflow 文件采用 YAML 格式，一个库可以有多个 workflow 文件。GitHub 发现 .github/workflows 目录里有 .yml 文件，就会自动运行该文件。\n配置字段：\n  name：工作流程的名称。如果省略 name，GitHub 将其设置为相对于仓库根目录的工作流程文件路径\n  on：必要，触发工作流程的 GitHub 事件的名称\non: [push, pull_request]   on.\u0026lt;push|pull_request\u0026gt;.\u0026lt;branches|tags\u0026gt;：您可以将工作流配置为在特定分支或标记上运行\non: push: branches: - main - \u0026#39;mona/octocat\u0026#39; - \u0026#39;releases/**\u0026#39; tags: - v1 - v1.*    jobs：工作流程运行包括一项或多项作业。每项作业必须关联一个 ID\n  jobs.\u0026lt;job_id\u0026gt;.name：job_id 里面的 name 字段是任务的说明\njobs: my_first_job: name: My first job my_second_job: name: My second job   jobs.\u0026lt;job_id\u0026gt;.needs：作业默认是并行运行。needs字段指定当前任务的运行顺序\njobs: job1: job2: needs: job1 job3: needs: [job1, job2] 此例中作业执行顺序：job1、job2、job3\n  jobs.\u0026lt;job_id\u0026gt;.runs-on：必需，运行作业的机器类型\nruns-on: ubuntu-latest     jobs.\u0026lt;job_id\u0026gt;.steps：作业包含一系列任务，称为 steps\n  jobs.\u0026lt;job_id\u0026gt;.steps.name：步骤名称\n  jobs.\u0026lt;job_id\u0026gt;.steps.uses：引用的 Actions\nsteps: # Reference a specific commit - uses: actions/setup-node@74bc508 # Reference a minor version of a release - uses: actions/setup-node@v1.2 # Reference a branch - uses: actions/setup-node@main   jobs.\u0026lt;job_id\u0026gt;.steps.run：使用操作系统 shell 运行命令行程序\n- name: Clean install dependencies and build run: |npm ci npm run build     参考 GitHub Actions 入门教程\nGitHub Actions\n持续集成（Continuous integration，简称CI） 概念 持续集成指的是，频繁地（一天多次）将代码合并（集成）到主干源码仓库。在 CI 中可以通过自动化等手段高频率地去获取产品反馈并响应反馈的过程。\n流程  提交：开发者向代码仓库提交代码 测试（第一轮）：代码仓库对提交的代码跑自动化测试  单元测试：针对函数或模块的测试 集成测试：针对整体产品的某个功能的测试，又称功能测试 端对端测试：从用户界面直达数据库的全链路测试   构建：将源码转换为可以运行的实际代码，会安装依赖，配置各种资源等。常用的构建工具如下  Jenkins：开源 Travis Codeship Strider：开源   测试（第二轮）：第二轮是全面测试 部署：直接部署 回滚：当前版本发生问题，回滚到上一个版本的构建结果  Commit message 社区有多种 Commit Message Conventions。本文介绍 Angular 规范。\n格式化的 Commit message 好处   提供更多的历史信息，方便浏览\ngit log HEAD --pretty=format:%s   可以过滤某些 commit，便于查找信息\ngit log HEAD --grep feature   可以直接从 commit 生成 Change Log\n  Commit message 的格式 \u0026lt;type\u0026gt;(\u0026lt;scope\u0026gt;): \u0026lt;subject\u0026gt; // 空一行 \u0026lt;body\u0026gt; // 空一行 \u0026lt;footer\u0026gt;   Header 只有一行\n type 用于说明 commit 的类别  feat：新功能 fix：修补bug docs：文档 style： 格式 refactor：重构 test：增加测试 chore：构建过程或辅助工具的变动 Revert：当前 commit 用于撤销以前的 commit   scope 用于说明 commit 影响的范围 subject 是 commit 目的的简短描述  以动词开头，使用第一人称现在时 第一个字母小写 结尾不加句号      Body 部分是对本次 commit 的详细描述\n  Footer\n  不兼容变动：如果当前代码与上一个版本不兼容，则以 BREAKING CHANGE 开头，后面是对变动的描述、以及变动理由和迁移方法\n  关闭 Issue：如果当前 commit 针对某个issue，那么可以在 Footer 部分关闭这个 issue\nCloses #123, #245, #992     Commitizen Commitizen 是一个撰写 Commit message 的工具\n  Install the Commitizen cli tools\nnpm install commitizen -g   Initialize your project to use the cz-conventional-changelog adapter\ncommitizen init cz-conventional-changelog --save-dev --save-exact   以后，凡是用到 git commit 命令，一律改为使用 git cz。\n  参考 Commit message 和 Change log 编写指南\nYAML（YAML Ain\u0026rsquo;t a Markup Language） YAML 是专门用来写配置文件的语言\n简介 规则：\n 大小写敏感 使用缩进表示层级关系 缩进时不允许使用 Tab 键，只允许使用空格。 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可 # 表示注释，从这个字符一直到行尾，都会被解析器忽略 对象和数组可以结合使用，形成复合结构  对象 一组键值对\nanimal: pets 行内表示法\nhash: { name: Steve, foo: bar }  数组 一组连词线开头的行\n- Cat - Dog - Goldfish 数据结构的子成员是一个数组，则可以在该项下面缩进一个空格\n- - Cat - Dog - Goldfish 行内表示法\nanimal: [Cat, Dog] 纯量   字符串：字符串默认不使用引号表示\nstr: 这是一行字符串 包含空格或特殊字符，需要放在引号之中，单引号和双引号都可以使用，双引号不会对特殊字符转义\nstr: \u0026#39;内容： 字符串\u0026#39; 单引号之中如果还有单引号，必须连续使用两个单引号转义\nstr: \u0026#39;labor\u0026#39;\u0026#39;s day\u0026#39; 字符串可以写成多行，从第二行开始，必须有一个单空格缩进。换行符会被转为空格\nstr: 这是一段 多行 字符串 多行字符串可以使用|保留换行符，也可以使用\u0026gt;折叠换行\nthis: |Foo Bar that: \u0026gt;Foo Bar +表示保留文字块末尾的换行，-表示删除字符串末尾的换行\ns1: | Foo s2: |+ Foo s3: |- Foo 字符串之中可以插入 HTML 标记\nmessage: | \u0026lt;p style=\u0026#34;color: red\u0026#34;\u0026gt; 段落 \u0026lt;/p\u0026gt;   参考 YAML 语言教程\nThe Official YAML Web Site\n开源许可证 一般情况下，软件的源代码只由编写者拥有，而开源（即开放源代码，Open Source Code）是指一种更自由的软件发布模式。简单来说，开源软件的特点就是把软件程序和源代码文件一起打包提供给用户，让用户在不受限制地使用某个软件功能的基础上还可以对代码按需修改，让软件更贴合硬件环境，让功能更符合工作需求。用户还可以将其编制成衍生产品再发布出去。用户一般享有使用自由、复制自由、修改自由、创建衍生品自由，以及收费自由。是的，您没有看错，用户具备创建衍生品和收费的自由。这也就是说，可以对一个开源软件进行深度定制化加工。如果修改过的程序更加好用，或者颇具新的特色，只要符合原作者的许可要求，我们就完全可以合法地将软件进行商标注册，以商业版的形式再发布出去，只要有新用户使用您的软件并支付相应的费用，那就是您的收入。这也正好符合了黑客和极客对自由的追求，因此在合作与竞争中，国内外的开源社区慢慢生长出了强健的根基，人气也非常高。\n但是，如果开源软件只单纯追求“自由”而牺牲了程序员的利益，这肯定会影响程序员的创作热情。为了平衡两者的关系，截至目前，世界上已经有100多种被开源促进组织（OSI，Open Source Initiative）确认的开源许可证，用于保护开源工作者的权益。对于那些只知道一味抄袭、篡改、破解或者盗版他人作品的不法之徒，终归会在某一天收到法院的传票。\n考虑到大家没准儿以后会以开源工作者的身份编写出一款畅销软件，因此刘遄老师根据开源促进组织的推荐建议以及实际使用情况，为大家筛选出了程序员最喜欢的前6名的开源许可证，并教大家怎么从中进行选择。提前了解最热门的开源许可证，并在未来选择一个合适的可最大程度地保护自己软件权益的开源许可证，这对创业公司来讲能起到事半功倍的作用。\n开源许可证总览：https://opensource.org/licenses/alphabetical\nTips：上述提到的“开源许可证”与“开源许可协议”的含义完全相同，只不过是英文翻译后两种不同的叫法，这里不作区别。\nTips：自由软件基金会（Free Software Foundation，FSF）是一个非营利组织，其使命是在全球范围内促进计算机用户的自由，捍卫所有软件用户的权利。\n大家经常会在开源社区中看到Copyleft这个单词，这是一个由自由软件运动所发展出的概念，中文被翻译为“著佐权”或者“公共版权”。与Copyright截然相反，Copyleft不会限制使用者复制、修改或再发布软件。\n此外，大家应该经常会听到别人说开源软件是free的，没错，开源软件就是自由的。这里的free千万不要翻译成“免费”，这样就大错特错了，这与您去酒吧看到的“第一杯免费”的意思可相差甚远。\n下面我们来看一下程序员最喜欢的前6名的开源许可证，以及它们各自赋予用户的权利。\nGPL **GNU通用公共许可证（**General Public License，GPL）：目前广泛使用的开源软件许可协议之一，用户享有运行、学习、共享和修改软件的自由。GPL最初是自由软件基金会创始人Richard Stallman起草的，其版本目前已经发展到了第3版。GPL的目的是保证程序员在开源社区中所做的工作对整个世界是有益的，所开发的软件也是自由的，并极力避免开源软件被私有化以及被无良软件公司所剥削。\n现在，只要软件中包含了遵循GPL许可证的产品或代码，该软件就必须开源、免费，因此这个许可证并不适合商业收费软件。遵循该许可证的开源软件数量极其庞大，包括Linux内核在内的大多数的开源软件都是基于GPL许可证的。GPL赋予了用户著名的五大自由。\n **使用自由：**允许用户根据需要自由使用这个软件。\n**复制自由：**允许把软件复制到任何人的计算机中，并且不限制复制的数量。\n**修改自由：**允许开发人员增加或删除软件的功能，但软件修改后必须依然基于GPL许可证。\n**衍生自由：**允许用户深度定制化软件后，为软件注册自己的新商标，再发行衍生品的自由。\n**收费自由：**允许在各种媒介上出售该软件，但必须提前让买家知道这个软件是可以免费获得的。因此，一般来讲，开源软件都是通过为用户提供有偿服务的形式来营利的。\n LGPL 较宽松通用公共许可证（Lesser GPL, LGPL）：一个主要为保护类库权益而设计的GPL开源协议。与标准GPL许可证相比，LGPL允许商业软件以类库引用的方式使用开源代码，而不用将其产品整体开源，因此普遍被商业软件用来引用类库代码。简单来说，就是针对使用了基于LGPL许可证的开源代码，在涉及这部分代码，以及修改过或者衍生出来的代码时，都必须继续采用LGPL协议，除此以外的其他代码则不强制要求。\n如果您觉得LGPL许可证更多地是关注对类库文件的保护，而不是软件整体，那就对了。因为该许可证最早的名字是Library GPL，即GPL类库开源许可证，保护的对象有glibc、GTK widget toolkit等类库文件。\nBSD **伯克利软件发布版（**Berkeley Software Distribution, BSD）许可证：另一款被广泛使用的开源软件许可协议。相较于GPL许可证，BSD更加宽松，适合于商业用途。用户可以使用、修改和重新发布遵循该许可证的软件，并且可以将软件作为商业软件发布和销售，前提是需要满足下面3个条件。\n 如果再发布的软件中包含开源代码，则源代码必须继续遵循BSD许可证。\n如果再发布的软件中只有二进制程序，则需要在相关文档或版权文件中声明原始代码遵循了BSD许可证。\n不允许用原始软件的名字、作者名字或机构名称进行市场推广。\n Apache Apache许可证（Apache License）：顾名思义，是由Apache软件基金会负责发布和维护的开源许可协议。作为当今世界上最大的开源基金会，Apache不仅因此协议而出名，还因市场占有率第一的Web服务器软件而享誉行业。目前使用最广泛的Apache许可证是2004年发行的2.0版本，它在为开发人员提供版权及专利许可的同时，还允许用户拥有修改代码及再发布的自由。该许可证非常适合用于商业软件，现在热门的Hadoop、Apache HTTP Server、MongoDB等项目都是基于该许可证研发的。程序开发人员在开发遵循该许可证的软件时，要严格遵守下面4个条件。\n 该软件及其衍生品必须继续使用Apache许可证。\n如果修改了程序源代码，需要在文档中进行声明。\n若软件是基于他人的源代码编写而成的，则需要保留原始代码的许可证、商标、专利声明及原作者声明的其他内容信息。\n如果再发布的软件中有声明文件，则需在此文件中注明基于了Apache许可证及其他许可证。\n MIT MIT许可证（Massachusetts Institute of Technology License）：源于麻省理工学院，又称为X11协议。MIT许可证是目前限制最少的开源许可证之一，用户可以使用、复制、修改、再发布软件，而且只要在修改后的软件源代码中保留原作者的许可信息即可，因此普遍被商业软件（例如jQuery与Node.js）所使用。也就是说，MIT许可证宽松到一个新境界，即用户只要在代码中声明了MIT许可证和版权信息，就可以去做任何事情，而无须承担任何责任。\nMPL **Mozilla公共许可证（**Mozilla Public License，MPL）：于1998年初由Netscape公司的Mozilla小组设计，原因是它们认为GPL和BSD许可证不能很好地解决开发人员对源代码的需求和收益之间的平衡关系，因此便将这两个协议进行融合，形成了MPL。2012年年初，Mozilla基金会发布了MPL 2.0版本（目前为止也是最新的版本），后续被用在Firefox、Thunderbird等诸多产品上。最新版的MPL公共许可证有以下特点。\n 在使用基于MPL许可证的源代码时，后续只需要继续开源这部分特定代码即可，新研发的软件不用完全被该许可证控制。\n开发人员可以将基于MPL、GPL、BSD等多种许可证的代码一起混合使用。\n开发人员在发布新软件时，必须附带一个专门用于说明该程序的文件，内容要有原始代码的修改时间和修改方式。\n 总结 估计大家在看完上面琳琅满目的许可证后，会心生怨念：“这不都差不多吗？到底该选哪个呢？”写到这里时，刘遄老师也是一脸无助：“到底该怎么让大家进行选择呢？”搜肠刮肚之际突然眼前一亮，乌克兰程序员Paul Bagwell创作的一幅流程图正好对刚才讲过的这6款开源许可证进行了汇总归纳，具体如下图所示。\n开源许可证的选择流程图\n众所周知，绝大部分的开源软件在安装完毕之后即可使用，很难在软件界面中找到相关的收费信息。所以经常会有同学提问：“刘老师，开源社区的程序员总要吃饭的呀，他们是靠什么营利呢？”针对这个问题，网络上好像只有两种声音：\n **情怀——**开源社区的程序员觉悟好，本领强，写代码纯粹是为了兴趣以及造福社会；\n**服务——**先让用户把软件安装上，等用好、用习惯之后，再通过提供一些维护服务来营利。\n 这两种解释都各有道理，但是不够全面。读者也不要把开源软件和商业软件完全对立起来，因为好的项目也需要好的运营模式。就开源软件来讲，营利模式具体包括以下5种。\n 多条产品线：如MySQL数据库便有个人版和企业版两个版本，即个人版完全免费，起到了很好的推广作用；企业版则通过销售授权许可来营利。\n技术服务型：JBoss应用服务器便是典型代表，JBoss软件可自由免费使用，软件提供方通过技术文档、培训课程以及定制开发服务来盈利。\n软硬件结合：比如IBM公司在出售服务器时，一般会为用户捆绑销售AIX或Linux系统来确保硬件设施的营利。\n技术出版物：比如O\u0026rsquo;Reilly既是一家开源公司，也是一家出版商，诸多优秀图书都是由O\u0026rsquo;Reilly出版的。\n品牌和口碑：微软公司曾多次表示支持开源社区。大家对此可能会感到意外，但这是真的！Visual Studio Code、PowerShell、TypeScript等软件均已开源。大家是不是瞬间就对微软公司好感倍增了呢？买一份正版系统表示支持也就是人之常情了。\n SSH 原理与运用 数字签名与数字证书 鲍勃有两把钥匙，一把是公钥，另一把是私钥。\n鲍勃把公钥送给他的朋友们——帕蒂、道格、苏珊——每人一把。\n苏珊要给鲍勃写一封保密的信。她写完后用鲍勃的公钥加密，就可以达到保密的效果。\n鲍勃收信后，用私钥解密，就看到了信件内容。只要鲍勃的私钥不泄露，这封信就是安全的，即使落在别人手里，也无法解密。\n鲍勃给苏珊回信，决定采用\u0026quot;数字签名\u0026quot;。他写完后先用Hash函数，生成信件的摘要（digest）。\n然后，鲍勃使用私钥，对这个摘要加密，生成\u0026quot;数字签名\u0026quot;（signature）。\n鲍勃将这个签名，附在信件下面，一起发给苏珊。\n苏珊收信后，取下数字签名，用鲍勃的公钥解密，得到信件的摘要。由此证明，这封信确实是鲍勃发出的。\n苏珊再对信件本身使用Hash函数，将得到的结果，与上一步得到的摘要进行对比。如果两者一致，就证明这封信未被修改过。\n复杂的情况出现了。道格想欺骗苏珊，他偷偷使用了苏珊的电脑，用自己的公钥换走了鲍勃的公钥。此时，苏珊实际拥有的是道格的公钥，但是还以为这是鲍勃的公钥。因此，道格就可以冒充鲍勃，用自己的私钥做成\u0026quot;数字签名\u0026quot;，写信给苏珊，让苏珊用假的鲍勃公钥进行解密。\n后来，苏珊感觉不对劲，发现自己无法确定公钥是否真的属于鲍勃。她想到了一个办法，要求鲍勃去找\u0026quot;证书中心\u0026quot;（certificate authority，简称CA），为公钥做认证。证书中心用自己的私钥，对鲍勃的公钥和一些相关信息一起加密，生成\u0026quot;数字证书\u0026quot;（Digital Certificate）。\n鲍勃拿到数字证书以后，就可以放心了。以后再给苏珊写信，只要在签名的同时，再附上数字证书就行了。\n苏珊收信后，用CA的公钥解开数字证书，就可以拿到鲍勃真实的公钥了，然后就能证明\u0026quot;数字签名\u0026quot;是否真的是鲍勃签的。\n远程登录   1995年，芬兰学者 Tatu Ylonen 设计了 SSH 协议，用于计算机之间的加密登录。本文针对的实现是 OpenSSH。\n  基本用法：\n  假定你要以用户名 user，登录远程主机 host\nssh user@host   如果本地用户名与远程用户名一致，登录时可以省略用户名\nssh host   SSH 的默认端口是 22，使用 p 参数修这个端口\nssh -p 2222 user@host     中间人攻击（Man-in-the-middle attack）\n  SSH 加密登录过程\n 远程主机收到用户的登录请求，把自己的公钥发给用户。 用户使用这个公钥，将登录密码加密后，发送给远程主机。 远程主机用自己的私钥，解密登录密码，如果密码正确，就同意用户登录。      中间人攻击：攻击者插在用户与远程主机之间，用伪造的公钥，获取用户的登录密码，再用这个密码登录远程主机。\n  口令登录：第一次登录远程主机时，会询问是否接受远程主机公钥（是否继续连接），并显示公钥指纹——公钥长度较长（这里采用RSA算法，长达 1024 位），很难比对，所以对其进行MD5计算，将它变成一个 128 位的指纹。用户通过比对远程网站上贴出的公钥指纹，决定是否接受这个远程主机的公钥。当远程主机的公钥被接受以后，它就会被保存在文件 $HOME/.ssh/known_hosts 之中。\n  公钥登录：省去口令登录每次都必须输入密码的步骤。用户将自己的公钥储存在远程主机上，登录的时候，远程主机会向用户发送一段随机字符串，用户用自己的私钥加密后，再发回来，远程主机用事先储存的公钥进行解密，如果成功，就证明用户是可信的，直接允许登录shell，不再要求密码。\n  ssh-keygen\n在 $HOME/.ssh/ 目录下生成两个文件：公钥 id_rsa.pub 和私钥 id_rsa。\n    远程操作与端口转发   SSH 可以在用户和远程主机之间，建立命令和数据的传输通道\n  绑定本地端口：让那些不加密的网络连接，全部改走 SSH 连接\nssh -D 8080 user@host 建立一个 socket，去监听本地的 8080 端口。一旦有数据传向那个端口，就自动把它转移到 SSH 连接上面，发往远程主机。\n  本地端口转发：假定 host1 是本地主机，host2 是远程主机。由于种种原因，这两台主机之间无法连通。但是，另外还有一台 host3，可以同时连通前面两台主机。因此，很自然的想法就是，通过 host3，将 host1 连上 host2。\nssh -L 2121:host2:21 host3 L 参数接受三个值——\u0026ldquo;本地端口:目标主机:目标主机端口\u0026rdquo;。SSH 绑定本地端口 2121，指定 host3 将所有的数据转发到目标主机 host2 的 21 端口。本地端口转发使得 host1 和 host3 之间仿佛形成一个数据传输的秘密隧道，因此又被称为\u0026quot;SSH 隧道\u0026quot;。\n  远程端口转发：host1 与 host2 之间无法连通，必须借助 host3 转发，而 host3 是一台内网机器，它可以连接外网的 host1，但是反过来就不行。解决办法是从 host3 上建立与 host1 的 SSH 连接，然后在 host1 上使用这条连接。在 host3 执行下面的命令\nssh -R 2121:host2:21 host1 R 参数也是接受三个值——\u0026ldquo;远程主机端口:目标主机:目标主机端口\u0026rdquo;。它让 host1 监听它自己的 2121 端口，然后将所有数据经由 host3，转发到 host2 的 21 端口。\n  GitHub Packages Learn to safely publish and consume packages, store your packages alongside your code, and share your packages privately with your team or publicly with the open source community. You can also automate your packages with GitHub Actions.\nTip \u0026amp; Questions Repository size limits for GitHub.com Hard limits:\n Individual files in a repository are strictly limited to a 100 MB maximum size limit. Repositories have a hard size limit of 100GB.  解决SSH自动断线问题 在连接远程SSH服务的时候，经常会发生长时间后的断线，或者无响应（无法再键盘输入）。 总体来说有两个方法：\n一、客户端定时发送心跳\nputty、SecureCRT、XShell都有这个功能，设置请自行搜索\n此外在Linux下：\n  修改本机/etc/ssh/ssh_config\n# vim /etc/ssh/ssh_config   添加\nServerAliveInterval 30 ServerAliveCountMax 100 即每隔30秒，向服务器发出一次心跳。若超过100次请求，都没有发送成功，则会主动断开与服务器端的连接。\n  二、服务器端定时向客户端发送心跳（一劳永逸）\n  修改服务器端 ssh配置 /etc/ssh/sshd_config\n# vim /etc/ssh/sshd_config   添加\nClientAliveInterval 30 ClientAliveCountMax 6 ClientAliveInterval表示每隔多少秒，服务器端向客户端发送心跳，是的，你没看错。\n下面的ClientAliveInterval表示上述多少次心跳无响应之后，会认为Client已经断开。\n所以，总共允许无响应的时间是60*3=180秒。\n  new mode 100755 出现\n$ git diff filename old mode 100644 new mode 100755 但是文件内容并没有发生改变\n产生这个问题的原因就是：filemode的变化，文件chmod后其文件某些位是改变了的，如果严格的比较原文件和chmod后的文件，两者是有区别的，但是源代码通常只关心文本内容，因此chmod产生的变化应该忽略，所以设置一下：\n$ git config --add core.filemode false ","permalink":"https://sakamotokurome.github.io/posts/git/","summary":"Workspace：工作区，Index / Stage：暂存区，Repository：仓库区（或本地仓库），Remote：远程仓库 远程仓库 安装，","title":"Git"},{"content":"Fedora [fəˈdɔrə] 费多拉\nFedora 定制版 为什么 Linus Torvalds 用 Fedora  2008：linus对发行版的要求是\u0026quot;易安装，比较贴近上游\u0026quot;即可。 2010年的时候，他指出了Fedora 14的一个bug。 2011年Fedora 15换Gnome3作为默认DE了，Linus直言\u0026quot;unholy mess\u0026quot; ，然后转投XFCE。 2011年末，Linus提出并修补了openSUSE中Xorg的一个严重bug。 2013年5月：Linus尝试将自己手头的MacBook Air装上Linux，把几个大的发行版全部都试了一遍。发现只有Fedora能正常工作。 之后的所有消息就是各种fedora了  SELinux 长久以来，每当遇到授权问题或者新安装的主机，我的第一反应是通过setenforce 0命令禁用SELinux，来减少产生的权限问题，但是这并不是一个良好的习惯。这篇文章尝试对SELinux的基本概念和用法进行简单介绍，并且提供一些更深入的资料。\nLinux下默认的接入控制是DAC，其特点是资源的拥有者可以对他进行任何操作（读、写、执行）。当一个进程准备操作资源时，Linux内核会比较进程和资源的UID和GID，如果权限允许，就可以进行相应的操作。此种方式往往会带来一些问题，如果一个进程是以root的身份运行，也就意味着他能够对系统的任何资源进行操作，而且不被限制。 假如我们的软件存在漏洞呢？这个往往是一个灾难性的问题。因此，就引出了另外的一种安全接入控制机制MAC，Linux下的一种现实是SELinux，也就是我们将要讨论的内容。\n基本概念 Mandatory Access Control (MAC) SELinux 属于MAC的具体实现，增强了Linux系统的安全性。MAC机制的特点在于，资源的拥有者，并不能决定谁可以接入到资源。具体决定是否可以接入到资源，是基于安全策略。而安全策略则是有一系列的接入规则组成，并仅有特定权限的用户有权限操作安全策略。\n一个简单的例子，则是一个程序如果要写入某个目录下的文件，在写入之前，一个特定的系统代码，将会依据进程的Context和资源的Context查询安全策略，并且根据安全策略决定是否允许写入文件。\nFlask Security Architecture SELinux的软件设计架构是参照Flask，Flask是一种灵活的操作系统安全架构，并且在Fluke research operating system中得到了实现。Flask的主要特点是把安全策略执行代码和安全策略决策代码，划分成了两个组件。安全策略决策代码在Flask架构中称作Security Server。除了这两个组件以外，另外一个组件Vector Cache(AVC), 主要提供策略决策结果的缓存，以此提高Security Server的性能。其具体执行流程为，安全策略执行代码通过AVC查询Security Server的安全策略决策结果，并将其缓存以备下次使用。\nLinux Security Module 前面两部分介绍了MAC机制和Flask架构，最终SELinux的实现是依赖于Linux提供的Linux Security Module框架简称为LSM。其实LSM的名字并不是特别准确，因为他并不是Linux模块，而是一些列的hook，同样也不提供任何的安全机制。LSM的的重要目标是提供对linux接入控制模块的支持。\nLSM 在内核数据结构中增加了安全字段，并且在重要的内核代码（系统调用）中增加了hook。可以在hook中注册回调函数对安全字段进行管理，以及执行接入控制。\nSELinux Security Enhanced Linux(SELinux) 为Linux 提供了一种增强的安全机制，其本质就是回答了一个“Subject是否可以对Object做Action?”的问题，例如 Web服务可以写入到用户目录下面的文件吗？其中Web服务就是Subject而文件就是Object，写入对应的就是Action。\n依照上面的例子，我们引入了几个概念，分别是Subject、Object、Action、以及例子没有体现出来的Context：\n Subject: 在SELinux里指的就是进程，也就是操作的主体。 Object： 操作的目标对象，例如 文件 Action： 对Object做的动作，例如 读取、写入或者执行等等 Context： Subject和Object都有属于自己的Context，也可以称作为Label。Context有几个部分组成，分别是SELinux User、SELinux Role、SELinux Type、SELinux Level。  用户程序执行的系统调用（例如读取文件），都要被SELinux依据安全策略进行检查。如果安全策略允许操作，则继续，否则将会抛出错误信息给应用程序。SELinux决策的同时还需要Subject和Object的Context信息，确定所属的User、Role和Type等信息，以此查询对应的安全策略进行决策。SELinux同样也使用了AVC机制用于缓存决策结果，以此来提高性能。\nSELinux Context 进程和文件都有属于自己的Context信息，Context分为几个部分，分别是 SELinux User、Role、Type 和一个可选的Level信息。SELinux在运行过程中将使用这些信息查询安全策略进行决策。\n SELinux User：每一个Linux用户都会映射到SELinux用户，每一个SELinux User都会对应相应的Role。 SELinux Role：每个Role也对应几种SELinux Type，并且充当了User和Type的‘中间人’ SELinux Type：安全策略使用SELinux Type制定规则，定义何种Domian（Type）的Subject，可以接入何种Type的Object。  显示进程的Context\n# ps -Z LABEL PID TTY TIME CMD unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 9509 pts/1 00:00:00 sudo unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 9515 pts/1 00:00:00 su unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 9516 pts/1 00:00:00 bash unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 9544 pts/1 00:00:00 ps 显示文件的Context信息\n# ls -Z system_u:object_r:admin_home_t:s0 anaconda-ks.cfg 临时修改文件的 SELinux Type\n# chcon -t httpd_sys_content_t file-name 恢复Context信息\n# restorecon [选项] \u0026lt;文件或目录 1\u0026gt; [\u0026lt;文件或目录 2\u0026gt;...]    选项 功能     -v 打印操作过程   -R 递归操作    添加目录的默认安全上下文\n如果提示找不到命令的话请安装 policycoreutils-python 软件包\n# semanage fcontext -a -t \u0026lt;文件安全上下文中的类型字段\u0026gt; \u0026#34;\u0026lt;目录（后面不加斜杠）\u0026gt;(/.*)?\u0026#34; 注：目录或文件的默认安全上下文可以通过 semanage fcontext -l 命令配合 grep 过滤查看。\n为 Nginx 新增一个网站目录 /usr/share/nginx/html2 之后，需要为其设置与原目录相同的默认安全上下文。\n# semanage fcontext -a -t httpd_sys_content_t \u0026#34;/usr/share/nginx/html2(/.*)?\u0026#34; 添加某类进程允许访问的端口\n# semanage port -a -t \u0026lt;服务类型\u0026gt; -p \u0026lt;协议\u0026gt; \u0026lt;端口号\u0026gt; 注：各种服务类型所允许的端口号可以通过 semanage port -l 命令配合 grep 过滤查看。\n为 Nginx 需要使用 10080 的端口用于 HTTP 服务。\nsemanage port -a -t http_port_t -p tcp 10080 SELinux 的运行状态 SELinux 有三个运行状态，分别是disabled, permissive 和 enforcing\n Disable： 禁用SELinux，不会给任何新资源打Label，如果重新启用的话，将会给资源重新打上Lable，过程会比较缓慢。 Permissive：如果违反安全策略，并不会真正的执行拒绝操作，替代的方式是记录一条log信息。 Enforcing: 默认模式，SELinux的正常状态，会实际禁用违反策略的操作  查看当前的运行状态\n# getenforceEnforcing 临时改变运行状态为Permissive\n# setenforce 0# getenforcePermissive 临时改变运行状态为 Enforcing\n# setenforce 1# getenforceEnforcing 使用sestatus可以查看完整的状态信息\n# sestatusSELinux status: enabledSELinuxfs mount: /sys/fs/selinuxSELinux root directory: /etc/selinuxLoaded policy name: targetedCurrent mode: enforcingMode from config file: enforcingPolicy MLS status: enabledPolicy deny_unknown status: allowedMax kernel policy version: 30 怎么启用SELinux 如果您的环境中禁用了 SELinux，则可以通过编辑 /etc/selinux/config 并设置 SELINUX=permissive 来启用 SElinux。由于 SELinux 当前尚未启用，因此最好不要将其设为立即强制执行，因为此时系统可能会出现误标记的事件，它会妨碍系统的正常启动。\n您可以在根目录中创建名为 .autorelabel 的空文件，然后重新启动，以此来强制系统自动为整个文件系统重新标记SELinux。如果系统中错误过多，应在允许模式下重新启动，以确保启动成功。重新标记所有内容后，利用 /etc/selinux/config 将 SELinux 设置为强制模式并重新启动，或运行 setenforce 1。\n如果系统管理员不太熟悉命令行，还可以选择用于管理 SELinux 的图形工具。\n针对 Linux 发行版中内置的系统，SELinux 提供了一道额外的防护层。保持开启 SELinux，就能在系统遭到破坏时保护您的系统。\nSELinux Log SELinux 的Log日志默认记录在/var/log/audit/audit.log\n# cat /var/log/audit/audit.logtype=AVC msg=audit(1223024155.684:49): avc: denied { getattr } for pid=2000 comm=\u0026#34;httpd\u0026#34; path=\u0026#34;/var/www/html/file1\u0026#34; dev=dm-0 ino=399185 scontext=unconfined_u:system_r:httpd_t:s0 tcontext=system_u:object_r:samba_share_t:s0 tclass=file /var/log/message 也会记录相应的信息，例如：\nMay 7 18:55:56 localhost setroubleshoot: SELinux is preventing httpd (httpd_t) \u0026#34;getattr\u0026#34; to /var/www/html/file1 (samba_share_t). For complete SELinux messages. run sealert -l de7e30d6-5488-466d-a606-92c9f40d316d SELinux 配置文件 SELinux的配置文件位于/etc/selinux/config。默认配置文件主要两部分，一个是SELinux的运行状态和SELinuxType。直接在配置文件中修改SELinux将会在下次启动时生效。\n# This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX=enforcing # SELINUXTYPE= can take one of these two values: # targeted - Targeted processes are protected, # mls - Multi Level Security protection. SELINUXTYPE=targeted SELinux Booleans Booleans允许在运行时修改SELinux安全策略。\n列出所有的Booleans选项\n# semanage boolean -l SELinux boolean State Default Description smartmon_3ware (off , off) Determine whether smartmon can... mpd_enable_homedirs (off , off) Determine whether mpd can traverse... 您可以通过运行 getsebool -a，找出系统中已设置的布尔值。\n临时修改httpd_can_network_connect_db状态为开启\n# setsebool [选项] \u0026lt;规则名称\u0026gt; \u0026lt;on|off\u0026gt; # setsebool httpd_can_network_connect_db on    选项 功能     -P 重启依然生效    Tips\u0026amp;Questions flatpak Cannot install apps. - Error: Failed to read commit it works for me:\nsudo flatpak repair Cannot open acess to console, the root account is locked\u0026hellip; 先是添加一个 LV 到 /etc/fstab，结果开机报错，原因是写错了：\nTime out ...Dependency failed for ... 结束后就 Cannot open acess to console, the root account is locked，什么也干不了，只能强制关机。\n解决方案是重启进入 Fedora Live CD，挂载 root，修改 /etc/fstab。但是无法挂载，挂载的是 Fedora Live CD 的 root，我 TM 佛了，原因应该是这两个名一模一样，Live CD 覆盖了 root。最后是用 Ubntu Live CD 解决。\n这告诉我们，不要只有一个 Live CD。这还告诉我们，先找自己的原因才能有耐心去解决问题。\ndmesg-x86/cpu: SGX disabled by BIOS SGX技术的分析和研究\nsnd_hda_codec_hdmi hdaudioC0D2: Monitor plugged-in, Failed to power up codec ret=[-13] set Kernel parameters，要使改变在重启后仍生效，您可以手动编辑 /boot/grub/grub.cfg。对于初学者，建议编辑 /etc/default/grub 并将您的内核选项添加至 GRUB_CMDLINE_LINUX_DEFAULT 行：\nGRUB_CMDLINE_LINUX_DEFAULT=\u0026quot;snd_hda_codec_hdmi.enable_silent_stream=0\u0026quot; 然后重新生成 grub.cfg 文件：\n# grub2grub-mkconfig2 -o /boot/grub2/grub.cfg Speed Up DNF 尝试更改参数\n$ sudo vi /etc/dnf/dnf.conf fastestmirror=true max_parallel_downloads=10 metadata_expire=2d  fastermirror 选择最快的镜像 max_parallel_downloads 一次下载多个包  尝试更换为清华源。\n如果在更新过程中某个小包下载不了，导致无法更新，尝试只使用 ipv4\n$ sudo dnf update -4 -v -y 第三方源 rpmfusion 第一步下载基础包(开源和闭源)， 这里我们使用bfsu来下载，以避免网络问题，终端输入:\nsudo yum install --nogpgcheck https://mirrors.bfsu.edu.cn/rpmfusion/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm https://mirrors.bfsu.edu.cn/rpmfusion/nonfree/fedora/rpmfusion-nonfree-release-$(rpm -E %fedora).noarch.rpm 第二步，使用bfsu镜像\nsudo sed -e \u0026#39;s/metalink/#metalink/g\u0026#39; -e \u0026#39;s|#baseurl=http://download1.rpmfusion.org/|baseurl Fedorafun 这里有一些国内常用软件，以及一些开源软件,终端输入：\nsudo sh -c \u0026#34;echo \u0026#39;[fedorafun] name=fedorafun baseurl=https://repo.fedora.fun/ enabled=1 countme=1 metadata_expire=7d repo_gpgcheck=0 type=rpm gpgcheck=0 skip_if_unavailable=False\u0026#39; \u0026gt; /etc/yum.repos.d/fedorafun.repo\u0026#34; CentOS Red Hat Enterprise Linux Developer Subscription Need to log in to download RHEL.\n怎样使用 Red Hat Subscription Manager (RHSM) 将系统注册到红帽客户门户网站？\n# subscription-manager register --username \u0026lt;username\u0026gt; --password \u0026lt;password\u0026gt; --auto-attach 配置 Red Hat Enterprise Linux 8 中基本系统设置的指南\nFrey\u0026rsquo;s Blog\n 所有文章 分类   关于多线程 概述 每个正在系统上运行的程序都是一个进程。每个进程包含一到N个线程。进程也可能是整个程序或者是部分程序的动态执行。线程是一组指令的集合，或者是程序的特殊段，它可以在程序里独立执行。也可以把它理解为代码运行的上下文。所以线程基本上是轻量级的进程，它负责在单个程序里执行多任务。通常由操作系统负责多个线程的调度和执行。线程是程序中一个单一的顺序控制流程。在单个程序中同时运行多个线程完成不同的工作,称为多线程。\n线程和进程的区别在于,子进程和父进程有不同的代码和数据空间,而多个线程则共享数据空间,每个线程有自己的执行堆栈和程序计数器为其执行上下文.多线程主要是为了节约CPU时间,发挥利用,根据具体情况而定. 线程的运行中需要使用计算机的内存资源和CPU。\n同步多线程（SMT）是一种在一个CPU 的时钟周期内能够执行来自多个线程的指令的硬件多线程技术。本质上，同步多线程是一种将线程级并行处理（多CPU）转化为指令级并行处理（同一CPU）的方法。 同步多线程是单个物理处理器从多个硬件线程上下文同时分派指令的能力。同步多线程用于在商用环境中及为周期/指令（CPI）计数较高的工作负载创造性能优势。 处理器采用超标量结构，最适于以并行方式读取及运行指令。同步多线程使您可在同一处理器上同时调度两个应用程序，从而利用处理器的超标量结构性质。\n超线程（HT, Hyper-Threading）是英特尔研发的一种技术，于2002年发布。通过此技术，英特尔实现在一个实体CPU中，提供两个逻辑线程。\n其实可以将SMT和HT理解为一个技术。\n Hyper-threading (officially called Hyper- ThreadingTechnology or HT Technology, and abbreviated as HTT orHT) is Intel’s proprietary simultaneous multithreading (SMT) implementation used to improve parallelization ofcomputations (doing multiple tasks at once) performed onx86 microprocessors.\n来自 https://cn.bing.com/search?q=intel+ht\u0026amp;go=%E6%8F%90%E4%BA%A4\u0026amp;qs=ds\u0026amp;form=QBLHCN\n 与多进程的区别  “进程——资源分配的最小单位，线程——程序执行的最小单位”\n 实际应用中基本上都是“进程+线程”的结合方式，千万不要真的陷入一种非此即彼的误区。\n   对比维度 多进程 多线程 总结     数据共享、同步 数据共享复杂，需要用IPC；数据是分开的，同步简单 因为共享进程数据，数据共享简单，但也是因为这个原因导致同步复杂 各有优势   内存、CPU 占用内存多，切换复杂，CPU利用率低 占用内存少，切换简单，CPU利用率高 线程占优   创建销毁、切换 创建销毁、切换复杂，速度慢 创建销毁、切换简单，速度很快 线程占优   编程、调试 编程简单，调试简单 编程复杂，调试复杂 进程占优   可靠性 进程间不会互相影响 一个线程挂掉将导致整个进程挂掉 进程占优   分布式 适应于多核、多机分布式；如果一台机器不够，扩展到多台机器比较简单 适应于多核分布式 进程占优     需要注意：   1）需要频繁创建销毁的优先用线程\n2）需要进行大量计算的优先使用线程\n3）强相关的处理用线程，弱相关的处理用进程\n一般的Server需要完成如下任务：消息收发、消息处理。“消息收发”和“消息处理”就是弱相关的任务，而“消息处理”里面可能又分为“消息解码”、“业务处理”，这两个任务相对来说相关性就要强多了。因此“消息收发”和“消息处理”可以分进程设计，“消息解码”、“业务处理”可以分线程设计。当然这种划分方式不是一成不变的，也可以根据实际情况进行调整。\n4）可能要扩展到多机分布的用进程，多核分布的用线程\n5）都满足需求的情况下，用你最熟悉、最拿手的方式\n来自 https://blog.csdn.net/lishenglong666/article/details/8557215\n 如何使用？ 需要CPU、BIOS、操作系统、应用软件都支持多线程技术才可以。\n支持多线程的CPU Power CPU 支持的SMT技术：\n Simultaneous multithreading (SMT) is a processor technology that allows multiple instruction streams (threads) to run concurrently on the same physical processor, improving overall throughput. To the operating system, each hardware thread is treated as an independent logical processor. Single-threaded (ST) execution mode is also supported.\n来自 https://www.ibm.com/support/knowledgecenter/SSFHY8_6.2/reference/am5gr_f0106.html?view=embed\n Intel CPU 支持的HT技术：\n Intel® Hyper-Threading Technology (Intel® HT Technology) uses processor resources more efficiently, enabling multiple threads to run on each core. As a performance feature, it also increases processor throughput, improving overall performance on threaded software. Intel® HT Technology is available on the latest Intel® Core™ vPro™ processors, the Intel® Core™ processor family, the Intel® Core™ M processor family, and the Intel® Xeon® processor family. By combining one of these Intel® processors and chipsets with an operating system and BIOS supporting Intel® HT Technology.\n来自 https://www.intel.com/content/www/us/en/architecture-and-technology/hyper-threading/hyper-threading-technology.html\n SMT/HT支持情况  Intel CPU : 2 Thread/Core Power9 CPU： 8 Thread /Core Sparc: 8 Thread /Core  RHEL7/CentOS7 \u0026amp; Intel CPU BIOS 中修改SMT/HT 的设置，使用这种方式Enable或者Disable后，将永久生效，需要重启。\nHyper-Threading Technology BIOS Setup Options For Intel® Desktop/Server Boards setup option location is the main menu of the BIOS setup program. • Located on the same menu screen that already had Processor Type, Processor Speed, System Bus Speed, and other related processor fields. • Setup Option Text ○ The field is called Hyper-Threading Technology. • Setup Option Values ○ The setup option values are Enabled and Disabled. • Setup Option Help Text 来自 \u0026lt;https://www.intel.com/content/www/us/en/support/articles/000007645/boards-and-kits/desktop-boards.html\u0026gt; RHEL/CentOS操作系统中查看多线程情况：（更多信息：https://access.redhat.com/solutions/rhel-smt）\n# lscpu | grep -e Socket -e Core -e Thread Thread(s) per core: 2 # 线程数 Core(s) per socket: 6 # core 数量 Socket(s): 2 或者\n# grep -H . /sys/devices/system/cpu/cpu*/topology/thread_siblings_list | sort -n -t ':' -k 2 -u # 显示 /sys/devices/system/cpu/cpu0/topology/thread_siblings_list:0 # 表示HT关闭 # 显示 /sys/devices/system/cpu/cpu0/topology/thread_siblings_list:0-1 # 表示 HT 启用 操作系统层关闭多线程有几种办法：\n 方法一：使用nosmt启动参数，需要新的x86 CPU，需要重启  # grubby --args=nosmt --update-kernel=DEFAULT # grub2-mkconfig -o /boot/grub/grub.conf # 创建新的grub.conf # reboot #重启  方法二：临时关闭，重启后失效  # echo off \u0026gt; /sys/devices/system/cpu/smt/control /sys/devices/system/cpu/smt/control: This file allows to read out the SMT control state and provides the ability to disable or (re)enable SMT. The possible states are: ============== =================================================== on SMT is supported by the CPU and enabled. All logical CPUs can be onlined and offlined without restrictions. off SMT is supported by the CPU and disabled. Only the so called primary SMT threads can be onlined and offlined without restrictions. An attempt to online a non-primary sibling is rejected forceoff Same as 'off' but the state cannot be controlled. Attempts to write to the control file are rejected. notsupported The processor does not support SMT. It's therefore not affected by the SMT implications of L1TF. Attempts to write to the control file are rejected. ============== =================================================== The possible states which can be written into this file to control SMT state are: - on - off - forceoff /sys/devices/system/cpu/smt/active: This file reports whether SMT is enabled and active, i.e. if on any physical core two or more sibling threads are online. AIX \u0026amp; Power Power9 CPU默认支持8线程，使用smtctl命令可以查看和修改 smt级别。更多内容查看https://www.ibm.com/support/knowledgecenter/ssw_aix_72/com.ibm.aix.cmds5/smtctl.htm\n 查看 SMT level  smtctl  临时修改 SMT level, # 可以是 1, 2, 4 or 8，重启后将恢复原来的smt level  smtctl -t 2 -w now  修改 SMT level永久生效，# 可以是 1, 2, 4 or 8，完成后需要使用bosboot创建启动设备   smtctl -t 4 -w boot bosboot -a # Creates complete boot image and device. RHEL7 \u0026amp; Power OpenPower CPU 默认支持4线程，安装RHEL后可以使用开源的工具 ppc64_cpu进行查看和修改多线程（更多查看 https://github.com/ibm-power-utilities/powerpc-utils）。\nppc64_cpu --------- This allows users to set the smt state, smt-snooze-delay and other settings on ppc64 processors. It also allows users to control the number of processor cores which are online (not in the sleep state). 来自 \u0026lt;https://github.com/ibm-power-utilities/powerpc-utils\u0026gt; 1，查看 SMT level\nppc64_cpu --smt 2，修改 SMT 级别， # is 1, 2, 4 or on\nppc64_cpu --smt=# 3， 关闭 smt支持\nppc64_cpu --smt=off 其他 oracle数据库 Oracle Database 在12c之前windows平台下支持多线程，Unix和Linux只支持多进程模式。在Oracle Database 12c中，Oracle引入了多线程模式，允许在Windows平台之外的Unix、Linux系统使用多线程模式，结合多进程与多线程模式，Oracle可以改进进程管理与性能。\n通过设置初始化参数threaded_execution，可以启用或关闭多线程模式，该参数缺省值为False，设置为TRUE启用12c的这个新特性：\nSQL\u0026gt; show parameter threaded_exec NAME TYPE VALUE --- threaded_execution boolean FALSE SQL\u0026gt; alter system set threaded_execution=true scope=spfile; System altered. 该参数重新启动数据库后生效，但是注意，多线程模式，不支持操作系统认证，不能直接启动数据库，需要提供SYS的密码认证后方能启动数据库：\nSQL\u0026gt; shutdown immediate; SQL\u0026gt; startup ORA-01017: invalid username/password; logon denied # 需要通过用户名和密码登录数据库。 用ps -ef 检查一下进程/线程：\n[oracle@enmocoredb dbs]$ ps -ef|grep ora_ oracle 27404 1 0 17:00 ? 00:00:00 ora_pmon_core oracle 27406 1 0 17:00 ? 00:00:00 ora_psp0_core oracle 27408 1 3 17:00 ? 00:00:05 ora_vktm_core oracle 27412 1 0 17:00 ? 00:00:00 ora_u004_core oracle 27418 1 0 17:00 ? 00:00:00 ora_u005_core oracle 27424 1 0 17:00 ? 00:00:00 ora_dbw0_core 其中U\u0026lt;NNN\u0026gt;进程是共享线程的\u0026quot;容器进程\u0026quot;，每个进程可以容纳100个线程。 来自 https://www.eygle.com/archives/2013/07/oracle_database_12c_multithreaded_model.html 连接热点   打开WIFI\nifconfig interface up   查看所有可用的无线网络信号\niw wlp2s0 scan | grep SSID   连接无线网\nwpa_supplicant -B -i wlp2s0 -c \u0026lt;(wpa_passphrase \u0026#34;SSID\u0026#34; \u0026#34;passwd\u0026#34;)   分配IP地址\ndhclient interface   查看无线网卡地址信息，有ip地址表示网络连接成功\nifconfig interface   PPPOE （ADSL）拨号上网   安装拨号软件\ndnf install rp-pppoe* ppp*   设定\npppoe-setup   拨号上网\npppoe-stoppppoe-start   安装中文输入法   安装 fcitx\ndnf install fcitx-im fcitx-configtool fcitx-googlepinyin   配置\n$ nano ~/.xprofile # or ~/.bashrc export GTK_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=\u0026#34;@im=fcitx\u0026#34;   fcitx 没图标：重装fcitx，在fcitx配置里关掉Kimpanel\n  关闭触摸板 $ dnf install xorg-x11-apps synclient TouchpadOff=1\t# 关闭 synclient TouchpadOff=0\t# 开启 用 MTP 挂载手机   安装jmtpfs\ndnf install jmtpfs   查看手机 “busnum”和“devnum”\njmptfs -l   建立挂载点\nmkdir /media/dir   挂载手机\njmtpfs -device=busnum,devnum /media/dir/   查找依赖 $ yum whatprovide package $ dnf provides package 默认字体 CentOS 默认字体目录 /lib/kbd/consolefonts\n纯命令行是不能使用系统之外的字体的。\nCentOS Minimal + Xfce base 源与 epel 源，使用用阿里镜像: https://developer.aliyun.com/mirror/\n  安装Xfce4，先安装 Xfce 可以保证不安装多余的包\ndnf group listdnf groupinstall Xfce   安装 X Window system\ndnf groupinstall \u0026#34;X Window system\u0026#34;   验证\nsystemctl isolate graphical.target   设置\n# 设置成命令模式systemctl set-default multi-user.target\t# 设置成图形模式systemctl set-default graphical.target\t   安装中文字体和中文输入法楷体字体\ndnf install cjkuni-ukai-fonts   输入法需要安装如下包：\n ibus， 这个包里有ibus-daemon这个平台服务器程序和ibus这个配置助手。 ibus-libpinyin， 这个是ibus平台下具体的拼音输入法。 im-chooser,这个是输入法平台选择助手程序。 执行im-chooser，选择输入法平台和输入法。重新登录系统。    xfce 主题\n 网站：xfce-look.org 主题目录： /usr/share/themes 或 ~/.themes 图标鼠标目录： /usr/share/icons 或 ~/.icons 壁纸： /usr/share/background , /usr/share/wallpapers Plank    EPEL EPEL的全称叫 Extra Packages for Enterprise Linux 。EPEL是由 Fedora 社区打造，为 RHEL 及衍生发行版如 CentOS、Scientific Linux 等提供高质量软件包的项目。装上了 EPEL之后，就相当于添加了一个第三方源。\n如果你知道rpmfusion.org的话，拿 rpmfusion 做比较还是很恰当的，rpmfusion 主要为桌面发行版提供大量rpm包（只有开源驱动才能进官方源，想要闭源驱动装rpmfusion），而EPEL则为服务器版本提供大量的rpm包，而且大多数rpm包在官方 repository 中是找不到的。\nopenSUSE /ˌoʊpənˈsuːzə/\n为什么选择 openSUSE Free and Open Source 确定你心目中的贡献者们是什么样的，从而聚拢到这样的人。\n狭义的自由开源概念 狭义的自由开源概念是：自由地开放源代码。即：软件作者把源代码公开发布，给予你修改并二次发布的权利。就这样，没别的了。\n测试、调试、故障受理与修复、接受新功能请求、接受代码合并请求、接受别人的帮助、用户社区建立、互动、整个自由开源生态的维护，统统都是完全没有，谁愿意干谁干，跟我没有关系。或者这么说：“写完拉倒”，哪怕洪水滔天。这从 GPL 许可证的“无保声明”中可以看出端倪。\n广义的自由开源概念 实际上如果你看过操作系统革命你就会明白：开放源代码其实并不是这一运动想要实现的全部，它的最终目的是普及自由精神，建立自由社区。\n目前这一精神在自由开源软件上的表现有：\n 源代码开源。 来自软件所有者的开发门槛为零。 不重新发明轮子。如果有已有实现并可以扩展，那么扩展它。 文档开源。使用维基等。 组织并形成用户互助社区。积极帮助用户（在不影响开发的前提下）。同时在开发上尽量面向用户，把用户的反应纳入到重大修改的考量因素当中去，积极采纳合理意见。 积极回应故障汇报并提供修复。 积极回应新功能请求。能做的做，不能做的解释原因寻求理解。 形成良性的贡献者添加内容和用户反馈渠道。 重视并维护由类似软件共同组成的生态的和谐稳定。（简单说就是：我开发 KDE 是因为 GNOME 满足不了我的需求，而不是为了搞死 GNOME。）  现在您可以拿来同狭义的自由开源概念做比较，发现如果说狭义的自由开源概念只是指某种行为，那么广义的自由开源概念已经是指一种氛围了。\nopenSUSE 秉持的自由开源概念 openSUSE 项目是完全做到“广义的自由开源概念”的社区。\n同时我们一直持有的相关理念还有：\n 积极的与上游合作。不“内化”补丁或修改，除非上游出于种种原因不收。 积极的为整个生态着想。 不搞歧视或二等公民。 尊重许可证、版权甚至是专利  如果你认同这些，那么您适合这个社区。\n配置 Install 语言请选择 English，因为 Linux 需要经常使用 Terminal，中文家目录并不方便。\n分区请选择默认的 btrfs 文件系统，有需要选择 Guided setup 和 Expert Partitioner。\nUse Snapper 默认开启。\nopenSUSE 镜像 我们官方的态度是不鼓励直接使用镜像的。\n因为比起「其它」发行版，我们 openSUSE 的技术力量比较强，开发了两个东西。\n一个叫做 Metalink，意思是这个格式（BT、Megalink 磁力链一样的格式）可以自动从 BT/FTP/HTTP 同时下载。\n另一个叫做 MirrorBrain，意思是我把所有的镜像地址隐藏起来，只暴露出一个中央服务器，所有人只需使用这个中央服务器（download.opensuse.org ），它会根据你的 IP 地理位置为你分配一个离你最近的镜像，但是在你那边显示的依旧是来自 download.opensuse.org。而如何分配是根据镜像管理员和中央服务器管理员当初的协定来确定的，比如镜像每月能够承受的流量、所愿意扮演的角色（是区域中心、地标式的镜像比如北交大、中科大，还是小镜像）等。\n而根据 openSUSE 软件源的构造，所有的 RPM 包都是从镜像获得的，所有的 metadata（元数据）都是从主镜像（位于德国）获得的，所以你源刷新的慢，只能证明你被我们光荣伟大的放火长城拖住了，而不能证明 openSUSE 项目有错，也代表不了你下载 RPM 包时的速度。\n申报自己为官方镜像。\nUninstall Discover Discover is the software center that is shipped with Plasma 5. Discover is infamous for its crashes, and it’s not a very good app overall. On top of that, it also adds redundancy since we already have Yast.\nYou can safely remove Discover:\nOpen Yast → Software Management → Search for `discover` → Right-click → Delete → Toggle #1 (deinstallation of discover packages) → Accept or\nsudo zypper remove packagekit 在 System Tray Setting 里面关闭 Software Updates 的通知。\n取消推荐的软件包 \u0026amp; 删除模组 打开 YaST ，点击 软件管理 ，再点击左上角的 依赖项 ，取消勾选 安装被推荐的软件包 。这样你的电脑就不会在某次更新后出现一些不是你主动安装的软件包。\n在 软件管理 页面，点击 视图，选择 模组 ，然后你就能看到按模组分类的包。例如你可以在此页面直接用鼠标右键单击 游戏 ，选择 不安装 或 卸载，卸载全部的预装的 KDE/Gnome 游戏包。\nUpdate System openSUSE Leap 是 openSUSE 打造定期释出的 Linux 发行版本的一种全新方式。 Leap 使用 SUSE Linux Enterprise（SLE） 的源代码，使 Leap 具有其它 Linux 发行版无法比拟的稳定性，并将其与社区开发相结合，为用户、开发人员和系统管理员提供最佳的 Linux 体验。贡献者和企业为 Leap 所做的贡献使它成为了提供成熟的软件包的 SLE 和提供最新的软件包的 Tumbleweed 这两者之间的桥梁。\nLeap 用户将会定期收到安全更新和补丁修复，如果你希望应用这些更新，在终端下用 Root 运行：\nsudo zypper patch zypper patch 只会更新列在 patchinfo 上面的包。\n有时，第三方软件源会提供一些功能性的更新，如果你希望应用这些更新，在终端下用 Root 运行：\nsudo zypper update OBS Package Installer \u0026amp; Flatpak 如果你想在终端直接查找来自 OBS 的软件包，你可以先安装 opi，同理添加 fltapak 仓库。\nsudo zypper in opi sudo flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo 然后输入你想要查找的软件包的名称，例如你要安装 qbittorrent enhanced edition ，你可以：\n$ opi qbittorrent $ flathub install netease 中文社区源是 openSUSE 中文社区的开发者们为用户构建、打包和收录一些发起自中文 Linux 圈子的软件或中文 Linux 圈子常用的软件。\nAdd Community Repositories That’s where community repositories come in. The most important one is Packman. For Leap:\nsudo zypper ar -cfp 90 'https://ftp.gwdg.de/pub/linux/misc/packman/suse/openSUSE_Leap_$releasever/' packman Open RPM with Yast Select any RPM package → Right-click → Properties → File Type Options → Move Yast to the first place → Apply Install Multimedia Codecs openSUSE 默认是没有部分多媒体编解码器的，包括家喻户晓的 MP3、AVI 等。这是因为它们是受限媒体格式。具体解释见openSUSE 编解码器一键安装、常见编解码器对应软件包/源说明、及版权须知。\nsudo zypper in opi \u0026amp;\u0026amp; opi codecs or, In order to install the H264/AVC support on your system, type in:\nsudo zypper install x264 libx265-130 libx264-148 或者通过 Packman 安装解码器\nzypper ar -cfp 90 https://mirrors.ustc.edu.cn/packman/suse/openSUSE_Leap_$releasever packmansudo zypper refreshsudo zypper dist-upgrade --from packman --allow-vendor-changesudo zypper install --from packman ffmpeg gstreamer-plugins-{good,bad,ugly,libav} libavcodec-full vlc-codecs Turn on Night Color Night color reduces the amount of blue light at night.\nOpen System Settings → Display and Monitor → Night Color → Activate Night Color → Apply Theme 在系统设置 startup and shutdown 下载使用个主题，因为默认主题输入密码的时候密码总是没有居中，跑到上面去了。\n或者，使用一个全局主题，例如 Layan。\nDisable touchpad 对于 touchpad 选择 Disable touchpad when mouse is pulgged in\n用户字体 Dolphin 下单击安装字体目录为\n/home/用户名/.fonts 如果下载好的字体文件无法直接点开安装（例如 *.ttc），或者字体太多，不想一个一个地安装，可以将字体文件全部放到字体文件夹中。然后运行：\nfc-cache -fv 输入法 在Yast中安装第二语言，就会自动安装fcitx并添加中文支持。\n词库\nFcitx 的 Libpinyin 可以直接在线导入搜狗细胞词库。不需要安装sougou输入法。\n需要安装 fcitx-pinyin-tools/fcitx-table-tools 这两个包，以添加处理词库的工具。\nsudo zypper in fcitx-pinyin-tools fcitx-table-tools 词库少了的话，也不好用，但是一次只能导入一个细胞词库。网上可以找到比较全的词库包。\n通过 7zr 解压过后将所有 txt 词库拷贝到 ~/.config/fcitx/libpinyin/importdict 即可。\n7zr x txt.7z 搜狗拼音\nsudo opi sogou-pinyin cloudpinyin\n根据文档，可以使用 libpinyin + cloudpinyin，哪怕不用导入词典，依旧很好用。果然，还是云词库的力量强大。\nsudo zypper in fcitx-cloudpinyin 默认的云输入引擎是 Google ，国内直接访问很不流畅，你可以打开输入法的配置，点击 Addon Config，找到 Cloud Pinyin ，点击右侧的设置，在弹出的窗口中，将 Google 替换为 Baidu 。\nKDE Connect KDE Connect 是一款能够方便手机与电脑进行连接的应用。\n 文件互传 共享剪贴板 远程输入 响铃，即既可以用电脑来找手机，也可以用手机找电脑。 幻灯片遥控器 多媒体控制 执行命令 共享通知  默认 kdeconnect 在防火墙那边是没放开的，要操作一下\nsudo firewall-cmd --zone=public --permanent --add-service=kdeconnect-kdesudo firewall-cmd --reload 装入 NTFS 分区   安装 ntfs-3g。\nsudo zypper in ntfs-3g   创建一个要充当安装点的目录，如 ~/mounts/windows。\nmkdir ~/mounts/windows   确定所需的 Windows 分区。\nsudo fdisk -l   以读写模式装入分区。使用相应的 Windows 分区替换占位符 DEVICE：\nntfs-3g /dev/DEVICE MOUNT POINT 要在只读模式下使用 Windows 分区，请追加 -o ro\nntfs-3g /dev/DEVICE MOUNT POINT -o ro ntfs-3g 命令使用当前用户 (UID) 和组 (GID) 装入给定设备。如果要为其他用户设置写权限，请使用命令 id  USER 获取 UID 和 GID 值的输出。设置方式：\nid usernamentfs-3g /dev/DEVICE MOUNT POINT -o uid=1000,gid=100   要卸载资源，请运行 fusermount -u 安装点。\n  任务栏透明化 Go to System Settings | Window Management | Window Rules. Press New\u0026hellip; button. Give some description to the new rule, Dock Transparency, for example. Then select only Dock (panel) in \u0026ldquo;Window type\u0026rdquo; field.\n之后在 Appearance \u0026amp; Fixes 中调整 opacity。\nBtrfs 文件系统似乎是内核中比较稳定的部分，多年来，人们一直使用 ext2/3，ext 文件系统以其卓越的稳定性成为了事实上的 Linux 标准文件系统。近年来 ext2/3 暴露出了一些扩展性问题，于是便催生了 ext4 。在 2008 年发布的 Linux2.6.19 内核中集成了 ext4 的 dev 版本。 2.6.28 内核发布时，ext4 结束了开发版，开始接受用户的使用。似乎 ext 就将成为 Linux 文件系统的代名词。然而当您阅读很多有关 ext4 的文章时，会发现都不约而同地提到了 btrfs，并认为 ext4 将是一个过渡的文件系统。 ext4 的作者 Theodore Tso 也盛赞 btrfs 并认为 btrfs 将成为下一代 Linux 标准文件系统。 Oracle，IBM， Intel 等厂商也对 btrfs 表现出了极大的关注，投入了资金和人力。为什么 btrfs 如此受人瞩目呢。这便是本文首先想探讨的问题。\nKevin Bowling 有一篇介绍各种文件系统的文章，在他看来，ext2/3 等文件系统属于“古典时期”。文件系统的新时代是 2005 年由 Sun 公司的 ZFS 开创的。 ZFS 代表” last word in file system ”，意思是此后再也不需要开发其他的文件系统了。 ZFS 的确带来了很多崭新的观念，对文件系统来讲是一个划时代的作品。\n如果您比较 btrfs 的特性，将会发现 btrfs 和 ZFS 非常类似。也许我们可以认为 btrfs 就是 Linux 社区对 ZFS 所作出的回应。从此往后在 Linux 中也终于有了一个可以和 ZFS 相媲美的文件系统。\nBtrfs 的特性 您可以在 btrfs 的主页上看到 btrfs 的特性列表。我自作主张，将那张列表分成了四大部分。\n首先是扩展性 (scalability) 相关的特性，btrfs 最重要的设计目标是应对大型机器对文件系统的扩展性要求。 Extent，B-Tree 和动态 inode 创建等特性保证了 btrfs 在大型机器上仍有卓越的表现，其整体性能而不会随着系统容量的增加而降低。\n其次是数据一致性 (data integrity) 相关的特性。系统面临不可预料的硬件故障，Btrfs 采用 COW 事务技术来保证文件系统的一致性。 btrfs 还支持 checksum，避免了 silent corrupt 的出现。而传统文件系统则无法做到这一点。\n第三是和多设备管理相关的特性。 Btrfs 支持创建快照 (snapshot)，和克隆 (clone) 。 btrfs 还能够方便的管理多个物理设备，使得传统的卷管理软件变得多余。\n最后是其他难以归类的特性。这些特性都是比较先进的技术，能够显著提高文件系统的时间 / 空间性能，包括延迟分配，小文件的存储优化，目录索引等。\n扩展性相关的特性 B-Tree\nbtrfs 文件系统中所有的 metadata 都由 BTree 管理。使用 BTree 的主要好处在于查找，插入和删除操作都很高效。可以说 BTree 是 btrfs 的核心。\n一味地夸耀 BTree 很好很高效也许并不能让人信服，但假如稍微花费一点儿时间看看 ext2/3 中元数据管理的实现方式，便可以反衬出 BTree 的优点。\n妨碍 ext2/3 扩展性的一个问题来自其目录的组织方式。目录是一种特殊的文件，在 ext2/3 中其内容是一张线性表格。\n图中展示了一个 ext2 目录文件的内容，该目录中包含四个文件。分别是 \u0026ldquo;home1\u0026rdquo;，\u0026ldquo;usr\u0026rdquo;，\u0026ldquo;oldfile\u0026rdquo; 和 \u0026ldquo;sbin\u0026rdquo; 。如果需要在该目录中查找目录 sbin，ext2 将遍历前三项，直至找到 sbin 这个字符串为止。\n这种结构在文件个数有限的情况下是比较直观的设计，但随着目录下文件数的增加，查找文件的时间将线性增长。 2003 年，ext3 设计者开发了目录索引技术，解决了这个问题。目录索引使用的数据结构就是 BTree 。如果同一目录下的文件数超过 2K，inode 中的 i_data 域指向一个特殊的 block 。在该 block 中存储着目录索引 BTree 。 BTree 的查找效率高于线性表，\n但为同一个元数据设计两种数据结构总是不太优雅。在文件系统中还有很多其他的元数据，用统一的 BTree 管理是非常简单而优美的设计。\nBtrfs 内部所有的元数据都采用 BTree 管理，拥有良好的可扩展性。 btrfs 内部不同的元数据由不同的 Tree 管理。在 superblock 中，有指针指向这些 BTree 的根。如图 2 所示：\nFS Tree 管理文件相关的元数据，如 inode，dir 等； Chunk tree 管理设备，每一个磁盘设备都在 Chunk Tree 中有一个 item ； Extent Tree 管理磁盘空间分配，btrfs 每分配一段磁盘空间，便将该磁盘空间的信息插入到 Extent tree 。查询 Extent Tree 将得到空闲的磁盘空间信息； Tree of tree root 保存很多 BTree 的根节点。比如用户每建立一个快照，btrfs 便会创建一个 FS Tree 。为了管理所有的树，btrfs 采用 Tree of tree root 来保存所有树的根节点； checksum Tree 保存数据块的校验和。\n基于 Extent 的文件存储\n现代很多文件系统都采用了 extent 替代 block 来管理磁盘。 Extent 就是一些连续的 block，一个 extent 由起始的 block 加上长度进行定义。\nExtent 能有效地减少元数据开销。为了进一步理解这个问题，我们还是看看 ext2 中的反面例子。\next2/3 以 block 为基本单位，将磁盘划分为多个 block 。为了管理磁盘空间，文件系统需要知道哪些 block 是空闲的。 Ext 使用 bitmap 来达到这个目的。 Bitmap 中的每一个 bit 对应磁盘上的一个 block，当相应 block 被分配后，bitmap 中的相应 bit 被设置为 1 。这是很经典也很清晰的一个设计，但不幸的是当磁盘容量变大时，bitmap 自身所占用的空间也将变大。这就导致了扩展性问题，随着存储设备容量的增加，bitmap 这个元数据所占用的空间也随之增加。而人们希望无论磁盘容量如何增加，元数据不应该随之线形增加，这样的设计才具有可扩展性。\n下图比较了 block 和 extent 的区别：\n在 ext2/3 中，10 个 block 需要 10 个 bit 来表示；在 btrfs 中则只需要一个元数据。对于大文件，extent 表现出了更加优异的管理性能。\nExtent 是 btrfs 管理磁盘空间的最小单位，由 extent tree 管理。 Btrfs 分配 data 或 metadata 都需要查询 extent tree 以便获得空闲空间的信息。\n动态 inode 分配\n为了理解动态 inode 分配，还是需要借助 ext2/3 。下表列举了 ext2 文件系统的限制：\n限制最大文件数量文件系统空间大小 V / 8192\n比如 100G 大小的文件系统中，能创建的文件个数最大为 131072\n下图显示了 ext2 的磁盘布局：\n在 ext2 中 inode 区是被预先固定分配的，且大小固定，比如一个 100G 的分区中，inode table 区中只能存放 131072 个 inode，这就意味着不可能创建超过 131072 个文件，因为每一个文件都必须有一个唯一的 inode 。\n为了解决这个问题，必须动态分配 inode 。每一个 inode 只是 BTree 中的一个节点，用户可以无限制地任意插入新的 inode，其物理存储位置是动态分配的。所以 btrfs 没有对文件个数的限制。\n针对 SSD 的优化支持\nSSD 是固态存储 Solid State Disk 的简称。在过去的几十年中，CPU/RAM 等器件的发展始终遵循着摩尔定律，但硬盘 HDD 的读写速率却始终没有飞跃式的发展。磁盘 IO 始终是系统性能的瓶颈。\nSSD 采用 flash memory 技术，内部没有磁盘磁头等机械装置，读写速率大幅度提升。 flash memory 有一些不同于 HDD 的特性。 flash 在写数据之前必须先执行擦除操作；其次，flash 对擦除操作的次数有一定的限制，在目前的技术水平下，对同一个数据单元最多能进行约 100 万次擦除操作，因此，为了延长 flash 的寿命，应该将写操作平均到整个 flash 上。\nSSD 在硬件内部的微代码中实现了 wear leveling 等分布写操作的技术，因此系统无须再使用特殊的 MTD 驱动和 FTL 层。虽然 SSD 在硬件层面做了很多努力，但毕竟还是有限。文件系统针对 SSD 的特性做优化不仅能提高 SSD 的使用寿命，而且能提高读写性能。 Btrfs 是少数专门对 SSD 进行优化的文件系统。 btrfs 用户可以使用 mount 参数打开对 SSD 的特殊优化处理。\nBtrfs 的 COW 技术从根本上避免了对同一个物理单元的反复写操作。如果用户打开了 SSD 优化选项，btrfs 将在底层的块空间分配策略上进行优化：将多次磁盘空间分配请求聚合成一个大小为 2M 的连续的块。大块连续地址的 IO 能够让固化在 SSD 内部的微代码更好的进行读写优化，从而提高 IO 性能。\n数据一致性相关的特性 COW 事务\n理解 COW 事务，必须首先理解 COW 和事务这两个术语。\n所谓 COW，即每次写磁盘数据时，先将更新数据写入一个新的 block，当新数据写入成功之后，再更新相关的数据结构指向新 block 。\nCOW 只能保证单一数据更新的原子性。但文件系统中很多操作需要更新多个不同的元数据，比如创建文件需要修改以下这些元数据：\n 修改 extent tree，分配一段磁盘空间 创建一个新的 inode，并插入 FS Tree 中 增加一个目录项，插入到 FS Tree 中  任何一个步骤出错，文件便不能创建成功，因此可以定义为一个事务。\n下面将演示一个 COW 事务。\nA 是 FS Tree 的根节点，新的 inode 的信息将被插入节点 C 。首先，btrfs 将 inode 插入一个新分配的 block C ’中，并修改上层节点 B，使其指向新的 block C ’；修改 B 也将引发 COW，以此类推，引发一个连锁反应，直到最顶层的 Root A 。当整个过程结束后，新节点 A ’变成了 FS Tree 的根。但此时事务并未结束，superblock 依然指向 A 。\n接下来，修改目录项（E 节点），同样引发这一过程，从而生成新的根节点 A ’’。\n此时，inode 和目录项都已经写入磁盘，可以认为事务已经结束。 btrfs 修改 superblock，使其指向 A ’’，如下图所示：\nCOW 事务能够保证文件系统的一致性，并且系统 Reboot 之后不需要执行 fsck 。因为 superblock 要么指向新的 A ’’，要么指向 A，无论哪个都是一致的数据。\nChecksum\nChecksum 技术保证了数据的可靠性，避免 silent corruption 现象。由于硬件原因，从磁盘上读出的数据会出错。比如 block A 中存放的数据为 0x55，但读取出来的数据变是 0x54，因为读取操作并未报错，所以这种错误不能被上层软件所察觉。\n解决这个问题的方法是保存数据的校验和，在读取数据后检查校验和。如果不符合，便知道数据出现了错误。\next2/3 没有校验和，对磁盘完全信任。而不幸的是，磁盘的错误始终存在，不仅发生在廉价的 IDE 硬盘上，昂贵的 RAID 也存在 silent corruption 问题。而且随着存储网络的发展，即使数据从磁盘读出正确，也很难确保能够安全地穿越网络设备。\nbtrfs 在读取数据的同时会读取其相应的 checksum 。如果最终从磁盘读取出来的数据和 checksum 不相同，btrfs 会首先尝试读取数据的镜像备份，如果数据没有镜像备份，btrfs 将返回错误。写入磁盘数据之前，btrfs 计算数据的 checksum 。然后将 checksum 和数据同时写入磁盘。\nBtrfs 采用单独的 checksum Tree 来管理数据块的校验和，把 checksum 和 checksum 所保护的数据块分离开，从而提供了更严格的保护。假如在每个数据 block 的 header 中加入一个域保存 checksum，那么这个数据 block 就成为一个自己保护自己的结构。这种结构下有一种错误无法检测出来，比如本来文件系统打算从磁盘上读 block A，但返回了 block B，由于 checksum 在 block 内部，因此 checksum 依旧是正确的。 btrfs 采用 checksum tree 来保存数据块的 checksum，避免了上述问题。\nBtrfs 采用 crc32 算法计算 checksum，在将来的开发中会支持其他类型的校验算法。为了提高效率，btrfs 将写数据和 checksum 的工作分别用不同的内核线程并行执行。\n多设备管理相关的特性 每个 Unix 管理员都曾面临为用户和各种应用分配磁盘空间的任务。多数情况下，人们无法事先准确地估计一个用户或者应用在未来究竟需要多少磁盘空间。磁盘空间被用尽的情况经常发生，此时人们不得不试图增加文件系统空间。传统的 ext2/3 无法应付这种需求。\n很多卷管理软件被设计出来满足用户对多设备管理的需求，比如 LVM 。 Btrfs 集成了卷管理软件的功能，一方面简化了用户命令；另一方面提高了效率。\n多设备管理\nBtrfs 支持动态添加设备。用户在系统中增加新的磁盘之后，可以使用 btrfs 的命令将该设备添加到文件系统中。\n为了灵活利用设备空间，Btrfs 将磁盘空间划分为多个 chunk 。每个 chunk 可以使用不同的磁盘空间分配策略。比如某些 chunk 只存放 metadata，某些 chunk 只存放数据。一些 chunk 可以配置为 mirror，而另一些 chunk 则可以配置为 stripe 。这为用户提供了非常灵活的配置可能性。\nSubvolume\nSubvolume 是很优雅的一个概念。即把文件系统的一部分配置为一个完整的子文件系统，称之为 subvolume 。\n采用 subvolume，一个大的文件系统可以被划分为多个子文件系统，这些子文件系统共享底层的设备空间，在需要磁盘空间时便从底层设备中分配，类似应用程序调用 malloc() 分配内存一样。可以称之为存储池。这种模型有很多优点，比如可以充分利用 disk 的带宽，可以简化磁盘空间的管理等。\n所谓充分利用 disk 的带宽，指文件系统可以并行读写底层的多个 disk，这是因为每个文件系统都可以访问所有的 disk 。传统的文件系统不能共享底层的 disk 设备，无论是物理的还是逻辑的，因此无法做到并行读写。\n所谓简化管理，是相对于 LVM 等卷管理软件而言。采用存储池模型，每个文件系统的大小都可以自动调节。而使用 LVM，如果一个文件系统的空间不够了，该文件系统并不能自动使用其他磁盘设备上的空闲空间，而必须使用 LVM 的管理命令手动调节。\nSubvolume 可以作为根目录挂载到任意 mount 点。 subvolume 是非常有趣的一个特性，有很多应用。\n假如管理员只希望某些用户访问文件系统的一部分，比如希望用户只能访问 /var/test/ 下面的所有内容，而不能访问 /var/ 下面其他的内容。那么便可以将 /var/test 做成一个 subvolume 。 /var/test 这个 subvolume 便是一个完整的文件系统，可以用 mount 命令挂载。比如挂载到 /test 目录下，给用户访问 /test 的权限，那么用户便只能访问 /var/test 下面的内容了。\n快照和克隆\n快照是对文件系统某一时刻的完全备份。建立快照之后，对文件系统的修改不会影响快照中的内容。这是非常有用的一种技术。\n比如数据库备份。假如在时间点 T1，管理员决定对数据库进行备份，那么他必须先停止数据库。备份文件是非常耗时的操作，假如在备份过程中某个应用程序修改了数据库的内容，那么将无法得到一个一致性的备份。因此在备份过程中数据库服务必须停止，对于某些关键应用这是不能允许的。\n利用快照，管理员可以在时间点 T1 将数据库停止，对系统建立一个快照。这个过程一般只需要几秒钟，然后就可以立即重新恢复数据库服务。此后在任何时候，管理员都可以对快照的内容进行备份操作，而此时用户对数据库的修改不会影响快照中的内容。当备份完成，管理员便可以删除快照，释放磁盘空间。\n快照一般是只读的，当系统支持可写快照，那么这种可写快照便被称为克隆。克隆技术也有很多应用。比如在一个系统中安装好基本的软件，然后为不同的用户做不同的克隆，每个用户使用自己的克隆而不会影响其他用户的磁盘空间。非常类似于虚拟机。\nBtrfs 支持 snapshot 和 clone 。这个特性极大地增加了 btrfs 的使用范围，用户不需要购买和安装昂贵并且使用复杂的卷管理软件。下面简要介绍一下 btrfs 实现快照的基本原理。\n如前所述 Btrfs 采用 COW 事务技术，从图 COW transaction 3 可以看到，COW 事务结束后，如果不删除原来的节点 A,C,E，那么 A,C,E,D,F 依然完整的表示着事务开始之前的文件系统。这就是 snapshot 实现的基本原理。\nBtrfs 采用引用计数决定是否在事务 commit 之后删除原有节点。对每一个节点，btrfs 维护一个引用计数。当该节点被别的节点引用时，该计数加一，当该节点不再被别的节点引用时，该计数减一。当引用计数归零时，该节点被删除。对于普通的 Tree Root, 引用计数在创建时被加一，因为 Superblock 会引用这个 Root block 。很明显，初始情况下这棵树中的所有其他节点的引用计数都为一。当 COW 事务 commit 时，superblock 被修改指向新的 Root A ’’，原来 Root block A 的引用计数被减一，变为零，因此 A 节点被删除。 A 节点的删除会引发其子孙节点的引用计数也减一，图 COW transaction 3 中的 B，C 节点的引用计数因此也变成了 0，从而被删除。 D,E 节点在 COW 时，因为被 A ’’所引用，计数器加一，因此计数器这时并未归零，从而没有被删除。\n创建 Snapshot 时，btrfs 将的 Root A 节点复制到 sA，并将 sA 的引用计数设置为 2 。在事务 commit 的时候，sA 节点的引用计数不会归零，从而不会被删除，因此用户可以继续通过 Root sA 访问 snapshot 中的文件。\n软件 RAID\nRAID 技术有很多非常吸引人的特性，比如用户可以将多个廉价的 IDE 磁盘组合为 RAID0 阵列，从而变成了一个大容量的磁盘； RAID1 和更高级的 RAID 配置还提供了数据冗余保护，从而使得存储在磁盘中的数据更加安全。\nBtrfs 很好的支持了软件 RAID，RAID 种类包括 RAID0,RAID1 和 RAID10.\nBtrfs 缺省情况下对 metadata 进行 RAID1 保护。前面已经提及 btrfs 将设备空间划分为 chunk，一些 chunk 被配置为 metadata，即只存储 metadata 。对于这类 chunk，btrfs 将 chunk 分成两个条带，写 metadata 的时候，会同时写入两个条带内，从而实现对 metadata 的保护。\n其他特性 Btrfs 主页上罗列的其他特性不容易分类，这些特性都是现代文件系统中比较先进的技术，能够提高文件系统的时间或空间效率。\nDelay allocation\n延迟分配技术能够减少磁盘碎片。在 Linux 内核中，为了提高效率，很多操作都会延迟。\n在文件系统中，小块空间频繁的分配和释放会造成碎片。延迟分配是这样一种技术，当用户需要磁盘空间时，先将数据保存在内存中。并将磁盘分配需求发送给磁盘空间分配器，磁盘空间分配器并不立即分配真正的磁盘空间。只是记录下这个请求便返回。\n磁盘空间分配请求可能很频繁，所以在延迟分配的一段时间内，磁盘分配器可以收到很多的分配请求，一些请求也许可以合并，一些请求在这段延迟期间甚至可能被取消。通过这样的“等待”，往往能够减少不必要的分配，也有可能将多个小的分配请求合并为一个大的请求，从而提高 IO 效率。\nInline file\n系统中往往存在大量的小文件，比如几百个字节或者更小。如果为其分配单独的数据 block，便会引起内部碎片，浪费磁盘空间。 btrfs 将小文件的内容保存在元数据中，不再额外分配存放文件数据的磁盘块。改善了内部碎片问题，也增加了文件的访问效率。\n上图显示了一个 BTree 的叶子节点。叶子中有两个 extent data item 元数据，分别用来表示文件 file1 和 file2 所使用的磁盘空间。\n假设 file1 的大小仅为 15 个字节； file2 的大小为 1M 。如图所示，file2 采用普通的 extent 表示方法：extent2 元数据指向一段 extent，大小为 1M，其内容便是 file2 文件的内容。\n而对于 file1， btrfs 会把其文件内容内嵌到元数据 extent1 中。如果不采用 inline file 技术。如虚线所示，extent1 指向一个最小的 extent，即一个 block，但 file1 有 15 个字节，其余的空间便成为了碎片空间。\n采用 inline 技术，读取 file1 时只需要读取元数据 block，而无需先读取 extent1 这个元数据，再读取真正存放文件内容的 block，从而减少了磁盘 IO 。\n得益于 inline file 技术，btrfs 处理小文件的效率非常高，也避免了磁盘碎片问题。\nDirectory index\n当一个目录下的文件数目巨大时，目录索引可以显著提高文件搜索时间。 Btrfs 本身采用 BTree 存储目录项，所以在给定目录下搜索文件的效率是非常高的。\n然而，btrfs 使用 BTree 管理目录项的方式无法同时满足 readdir 的需求。 readdir 是 POSIX 标准 API，它要求返回指定目录下的所有文件，并且特别的，这些文件要按照 inode number 排序。而 btrfs 目录项插入 BTree 时的 Key 并不是 Inode number，而是根据文件名计算的一个 hash 值。这种方式在查找一个特定文件时非常高效，但却不适于 readdir 。为此，btrfs 在每次创建新的文件时，除了插入以 hash 值为 Key 的目录项外，还同时插入另外一种目录项索引，该目录项索引的 KEY 以 sequence number 作为 BTree 的键值。这个 sequence number 在每次创建新文件时线性增加。因为 Inode number 也是每次创建新文件时增加的，所以 sequence number 和 inode number 的顺序相同。以这种 sequence number 作为 KEY 在 BTree 中查找便可以方便的得到一个以 inode number 排序的文件列表。\n另外以 sequence number 排序的文件往往在磁盘上的位置也是相邻的，所以以 sequence number 为序访问大量文件会获得更好的 IO 效率。\n压缩\n大家都曾使用过 zip，winrar 等压缩软件，将一个大文件进行压缩可以有效节约磁盘空间。 Btrfs 内置了压缩功能。\n通常人们认为将数据写入磁盘之前进行压缩会占用很多的 CPU 计算时间，必然降低文件系统的读写效率。但随着硬件技术的发展，CPU 处理时间和磁盘 IO 时间的差距不断加大。在某些情况下，花费一定的 CPU 时间和一些内存，但却能大大节约磁盘 IO 的数量，这反而能够增加整体的效率。\n比如一个文件不经过压缩的情况下需要 100 次磁盘 IO 。但花费少量 CPU 时间进行压缩后，只需要 10 次磁盘 IO 就可以将压缩后的文件写入磁盘。在这种情况下，IO 效率反而提高了。当然，这取决于压缩率。目前 btrfs 采用 zlib 提供的 DEFALTE/INFLATE 算法进行压缩和解压。在将来，btrfs 应该可以支持更多的压缩算法，满足不同用户的不同需求。\n目前 btrfs 的压缩特性还存在一些不足，当压缩使能后，整个文件系统下的所有文件都将被压缩，但用户可能需要更细粒度的控制，比如针对不同的目录采用不同的压缩算法，或者禁止压缩。我相信，btrfs 开发团队将在今后的版本中解决这个问题。\n对于某些类型的文件，比如 jpeg 文件，已经无法再进行压缩。尝试对其压缩将纯粹浪费 CPU 。为此，当对某文件的若干个 block 压缩后发现压缩率不佳，btrfs 将不会再对文件的其余部分进行压缩操作。这个特性在某种程度上提高了文件系统的 IO 效率。\n预分配\n很多应用程序有预先分配磁盘空间的需要。他们可以通过 posix_fallocate 接口告诉文件系统在磁盘上预留一部分空间，但暂时并不写入数据。如果底层文件系统不支持 fallocate，那么应用程序只有使用 write 预先写一些无用信息以便为自己预留足够的磁盘空间。\n由文件系统来支持预留空间更加有效，而且能够减少磁盘碎片，因为所有的空间都是一次分配，因而更有可能使用连续的空间。 Btrfs 支持 posix_fallocate 。\n总结 至此，我们对 btrfs 的很多特性进行了较为详细的探讨，但 btrfs 能提供的特性却并不止这些。 btrfs 正处于试验开发阶段，还将有更多的特性。\nBtrfs 也有一个重要的缺点，当 BTree 中某个节点出现错误时，文件系统将失去该节点之下的所有的文件信息。而 ext2/3 却避免了这种被称为”错误扩散”的问题。\n但无论怎样，希望您和我一样，开始认同 btrfs 将是 Linux 未来最有希望的文件系统。\nBtrfs 使用 了解了 btrfs 的特性，想必您一定想亲身体验一下 btrfs 的使用。本章将简要介绍如何使用 btrfs 。\n要使用一些用户空间工具的话，需要 安装 基础操作必须的 btrfs-progs 软件包。\n创建文件系统 单一设备上的文件系统\n要在分区 /dev/partition 上创建一个 Btrfs 文件系统，执行：\n# mkfs.btrfs -L mylabel /dev/partition Btrfs 用于元数据的默认节点大小 (nodesize) 为 16KB，而用于数据的默认扇区大小 (sectorsize) 等于页面大小 (page size) 并会自动检测。 要对元数据使用较大的节点大小 (必须为扇区大小的倍数，最大允许 64KB)，请通过 -n 开关为 nodesize 指定一个值。如下例所示，使用 32KB 块大小：\n# mkfs.btrfs -L mylabel -n 32k /dev/partition 注意： 根据 mkfs.btrfs(8) § OPTIONS 手册页内容：“较小的节点大小会增加碎片，但也会让 B-trees 更高，进而使得锁定争用（locking contention）更少。较高的节点大小则能有更好的打包（packing）和更少的碎片，但代价是，更新元数据块时会使用更多的内存”。\n多设备文件系统 RAID\n多个设备可以用来创建一组 RAID。支持的 RAID 级别有 RAID 0、RAID 1、RAID 10、RAID 5 和 RAID 6。从 5.5 版本内核开始，新增对 RAID1c3 和 RAID1c4 的支持，分别是 3 份冗余和 4 份冗余的 RAID 1。可以使用 -d 和 -m 参数分别为数据和元数据配置 RAID 等级。默认情况下，数据有一份副本（single），元数据则被镜像（RAID1）。\n# mkfs.btrfs -d single -m raid1 /dev/part1 /dev/part2 ... subvolume 创建子卷\n要创建一个子卷:\n# btrfs subvolume create /path/to/subvolume 列出子卷列表\n要列出当前路径 (path) 下的子卷和它们的 ID:\n# btrfs subvolume list -p path 删除子卷\n要删除一个子卷:\n# btrfs subvolume delete /path/to/subvolume 自 Linux 4.18 起, 用户可以像移除常规目录一样删除一个子卷 (用 rm -r, rmdir 命令)。\n挂载子卷\n可以使用 subvol=*/path/to/subvolume* 或 subvolid=*objectid* 挂载标志来安装子卷，就像文件系统分区一样。\n$ sudo mount /dev/sdb1 -o subvol=projects /tmp/projects$ sudo mount /dev/sdb1 -o subvolid=261 /tmp/projects 使用 Btrfs 快照进行增量备份 *快照(snapshot)*是 Btrfs 的一个有趣的功能。快照是一个子卷的副本。生成快照是立即的。然而，生成快照与执行 rsync 或 cp 不同，快照并不是一创建就会占用空间。\n 编者注：来自 BTRFS Wiki：快照简单的来说就是一个子卷，它使用 Btrfs 的 COW 功能与其他子卷共享其数据（和元数据）。\n 占用的空间将随着原始子卷或快照本身（如果它是可写的）的数据变化而增加。子卷中已添加/修改的文件和已删除的文件仍然存在于快照中。这是一种方便的备份方式。\n使用快照进行备份\n快照驻留在子卷所在的同一磁盘上。你可以像浏览普通目录一样浏览它，并按照生成快照时的状态恢复文件的副本。顺便说一下，在快照子卷的同一磁盘上生成快照并不是一个理想的备份策略：如果硬盘坏了，快照也会丢失。快照的一个有趣的功能是可以将快照发送到另一个位置。快照可以被发送到外部硬盘或通过 SSH 发送到远程系统（目标文件系统也需要格式化为 Btrfs）。要实现这个，需要使用命令 btrfs send 和 btrfs receive。\n生成快照\n要使用 btrfs send 和 btrfs receive 命令，重要的是要将快照创建为只读，而快照默认是可写的。\n要创建一个快照:\n# btrfs subvolume snapshot source [dest/]name source为要创建快照的对象，[dest/]name为快照安放路径。\n下面的命令将对 /home 子卷进行快照。请注意 -r 标志代表只读。\nsudo btrfs subvolume snapshot -r /home /.snapshots/home-day1 快照的名称可以是当前日期，而不是 day1，比如 home-$(date +%Y%m%d)。快照看起来像普通的子目录。你可以把它们放在任何你喜欢的地方。目录 /.snapshots 可能是一个不错的选择，以保持它们的整洁和避免混淆。\n 编者注：快照不会对自己进行递归快照。如果你创建了一个子卷的快照，子卷所包含的每一个子卷或快照都会被映射到快照里面的一个同名的空目录。\n 使用 btrfs send 进行备份\n在本例中，U 盘中的目标 Btrfs 卷被挂载为 /run/media/user/mydisk/bk。发送快照到目标卷的命令是：\nsudo btrfs send /.snapshots/home-day1 | sudo btrfs receive /run/media/user/mydisk/bk 这被称为初始启动，它相当于一个完整的备份。这个任务需要一些时间，取决于 /home 目录的大小。显然，后续的增量发送只需要更短的时间。\n增量备份\n快照的另一个有用的功能是能够以增量的方式执行发送任务。让我们再来生成一个快照。\nsudo btrfs subvolume snapshot -r /home /.snapshots/home-day2 为了执行增量发送任务，需要指定上一个快照作为基础，并且这个快照必须存在于源文件和目标文件中。请注意 -p 选项。\nsudo btrfs send -p /.snapshot/home-day1 /.snapshot/home-day2 | sudo btrfs receive /run/media/user/mydisk/bk 再来一次（一天之后）：\nsudo btrfs subvolume snapshot -r /home /.snapshots/home-day3sudo btrfs send -p /.snapshot/home-day2 /.snapshot/home-day3 | sudo btrfs receive /run/media/user/mydisk/bk 清理\n操作完成后，你可以保留快照。但如果你每天都执行这些操作，你可能最终会有很多快照。这可能会导致混乱，并可能会在你的磁盘上使用大量的空间。因此，如果你认为你不再需要一些快照，删除它们是一个很好的建议。\n请记住，为了执行增量发送，你至少需要最后一个快照。这个快照必须存在于源文件和目标文件中。\nsudo btrfs subvolume delete /.snapshot/home-day1sudo btrfs subvolume delete /.snapshot/home-day2sudo btrfs subvolume delete /run/media/user/mydisk/bk/home-day1sudo btrfs subvolume delete /run/media/user/mydisk/bk/home-day2 注意：第 3 天的快照被保存在源文件和目标文件中。这样，明天（第 4 天），你就可以执行新的增量 btrfs send。\n最后的建议是，如果 U 盘的空间很大，可以考虑在目标盘中保留多个快照，而在源盘中只保留最后一个快照。\n压缩 给现存文件启用压缩，可使用 btrfs filesystem defragment -c alg 命令，alg 处可选填为 zlib，lzo 或 zstd。举例来说，要用 zstd 方式给整个文件系统重新压缩，执行下列命令：\n# btrfs filesystem defragment -r -v -c zstd / 要在新的 Btrfs 分区上安装 Arch Linux 时就启用压缩功能 (充分利用压缩特性)，请在 挂载 文件系统时使用 compress 选项：mount -o compress=zstd /dev/sd*xY* /mnt/。在配置过程中，请在 fstab 中把 compress=zstd 添加到根目录文件系统的挂载选项里。\nBtrfs 和 LVM-ext4 两者的共性 尽管两个文件系统之间存在核心差异，但 Btrfs 和 LVM-ext4 实际上有很多共同之处。两者都是成熟且经过充分测试的存储技术。从 Fedora Core 的早期开始，就一直在使用 LVM，而 ext4 在 2009 年成为 Fedora 11 的默认设置。Btrfs 在 2009 年并入 Linux 主线内核，并且 Facebook 广泛使用了该文件系统。SUSE Linux Enterprise 12 在 2014 年使其成为默认文件系统。因此，它在生产环境中也有着长久的运行时间。\n这两个系统都能很好地防止因意外停电而导致的文件系统损坏，尽管它们的实现方式不同。它们支持的配置包括使用单盘设置和跨越多个设备，并且这两种配置都能够创建近乎即时的快照。有各种工具可以帮助管理这两种系统，包括命令行和图形界面。这两种解决方案在家用台式机和高端服务器上都同样有效。\nLVM-ext4 的优势 ext4 文件系统 专注于高性能和可伸缩性，没有太多额外的花哨之处。它能有效地防止长时间后的碎片化，并当碎片化出现后提供了 很好的工具。ext4 之所以坚如磐石，是因为它构建在前代的 ext3 文件系统之上，带来了多年的系统内测试和错误修复。\nLVM-ext4 环境中的大多数高级功能都来自 LVM 本身。LVM 位于文件系统的“下方”，这意味着它支持任何文件系统。逻辑卷Logical volume（LV）是通用的块设备，因此 虚拟机可以直接使用它们。这种灵活性使得每个逻辑卷都可以使用合适的文件系统，用合适的选项应对各种情况。这种分层方法还遵循了“小工具协同工作”的 Unix 哲学。\n从硬件抽象出来的卷组volume group（VG）允许 LVM 创建灵活的逻辑卷。每个逻辑卷都提取自同一个存储池，但具有自己的设置。调整卷的大小比调整物理分区的大小容易得多，因为没有数据有序放置的限制。LVM 物理卷physical volume（PV）可以是任意数量的分区，甚至可以在系统运行时在设备之间移动。\nLVM 支持只读和读写的 快照，这使得从活动系统创建一致的备份变得很容易。每个快照都有一个定义的大小，更改源卷或快照卷将占用其中的空间。又或者，逻辑卷也可以是稀疏配置池thinly provisioned pool的一部分。这允许快照自动使用池中的数据，而不是使用在创建卷时定义的固定大小的块。\n有多个磁盘驱动器的 LVM\n当有多个设备时，LVM 才真正大放异彩。它原生支持大多数 RAID 级别，每个逻辑卷可以具有不同的 RAID 级别。LVM 将自动为 RAID 配置选择适当的物理设备，或者用户可以直接指定它。基本的 RAID 支持包括用于性能的数据条带化（RAID0）和用于冗余的镜像（RAID1）。逻辑卷也可以使用 RAID5、RAID6 和 RAID10 等高级设置。LVM RAID 支持已经成熟，因为 LVM 在底层使用的 设备映射器（dm） 和 多设备（md） 内核支持， 与 mdadm 使用的一样。\n对于具有快速和慢速驱动器的系统，逻辑卷也可以是 缓存卷。经典示例是 SSD 和传统磁盘驱动器的组合。缓存卷使用较快的驱动器来存储更频繁访问的数据（或用作写缓存），而慢速的驱动器则用于处理大量数据。\nLVM 中大量稳定的功能以及 ext4 的可靠性在既往的使用中早已被证明了。当然，功能越多就越复杂。在配置 LVM 时，要找到合适的功能选项是很有挑战性的。对于单驱动器的台式机系统，LVM 的功能（例如 RAID 和缓存卷）不适用。但是，逻辑卷比物理分区更灵活，快照也很有用。对于正常的桌面使用，LVM 的复杂性会成为典型的用户可能遇到的问题恢复的障碍。\nBtrfs 的优势 从前几代文件系统中学到的经验指导了构建到 Btrfs 的功能设计。与 ext4 不同，它可以直接跨越多个设备，因此它具有通常仅在卷管理器中才能找到的功能。它还具有 Linux 文件系统空间中独有的功能（ZFS 具有相似的功能集，但不要指望它在 Linux 内核中出现）。\nBtrfs 的主要功能\n也许最重要的功能是对所有数据进行校验和checksumming。校验和与写时复制copy-on-write（COW）一起，提供了在意外断电后确保文件系统完整性的 关键方法。更独特的是，校验和可以检测数据本身中的错误。悄然的数据损坏（有时也称为 bitrot）比大多数人意识到的更常见。如果没有主动验证，损坏最终可能会传播到所有可用的备份中。这使得用户没有有效的副本。通过透明地校验所有数据，Btrfs 能够立即检测到任何此类损坏。启用正确的 dup 或 raid 选项，文件系统也可以透明地修复损坏。\n写时复制也是 Btrfs 的基本功能，因为它在提供文件系统完整性和即时子卷快照方面至关重要。从公共子卷创建快照后，快照会自动共享底层数据。另外，事后的重复数据删除deduplication 使用相同的技术来消除相同的数据块。单个文件可以通过使用 cp 的 reflink 选项 来使用 COW 功能。reflink 副本对于复制大型文件（例如虚拟机镜像）特别有用，这些文件往往随着时间的推移具有大部分相同的数据。\nBtrfs 支持跨越多个设备，而无需卷管理器。多设备支持可提供数据镜像功能以实现冗余和条带化以提高性能。此外，还实验性地支持更高级的 RAID 级别，例如 RAID 5 和 RAID 6。与标准 RAID 设置不同，Btrfs 的 RAID1 实际上允许奇数个设备。例如，它可以使用 3 个设备，即使它们的大小不同。\n所有 RAID 和 dup 选项都是在文件系统级别指定的。因此，各个子卷不能使用不同的选项。请注意，使用多设备的 RAID1 选项意味着即使一个设备发生故障，卷中的所有数据都是可用的，并且校验功能可以保持数据本身的完整性。这超出了当前典型的 RAID 设置所能提供的范围。\n附加功能\nBtrfs 还支持快速简便的远程备份。子卷快照可以 发送到远程系统 进行存储。通过利用文件系统中固有的 COW 元数据，这些传输通过仅发送先前发送的快照中的增量更改而非常有效。诸如 snapper 之类的用户应用程序使管理这些快照变得容易。\n另外，Btrfs 卷可以具有 透明压缩 功能，并且 chattr +c 可以标记进行压缩的单个文件或目录。压缩不仅可以减少数据消耗的空间，还可以通过减少写入操作量来帮助延长 SSD 的寿命。压缩当然会带来额外的 CPU 开销，但是有很多选项就可以权衡取舍。\nBtrfs 集成了文件系统和卷管理器功能，这意味着总体维护比 LVM-ext4 更简单。当然，这种集成的灵活性较低，但是对于大多数台式机甚至服务器而言，设置已足够。\nLVM 上使用 Btrfs Btrfs 可以 就地转换 ext3/ext4 文件系统。就地转换意味着无需将数据复制出来然后再复制回去。数据块本身甚至都不需要修改。因此，对于现有的 LVM-ext4 系统，一种选择是将 LVM 保留在原处，然后简单地将 ext4 转换为 Btrfs。虽然可行且受支持，但有一些原因使它不是最佳选择。\nBtrfs 的吸引力之一是与卷管理器集成的文件系统所带来的更轻松的管理。要是在 LVM 之上运行，对于系统维护，仍然要对额外的卷管理器进行一些设置。同样，LVM 设置通常具有多个固定大小的逻辑卷，并具有独立文件系统。虽然 Btrfs 支持给定的计算机上的多个卷，但是许多不错的功能都需要单一卷具有多个子卷。如果每个 LVM 卷都有一个独立的 Btrfs 卷，则用户仍然需要手动管理固定大小的 LVM 卷。虽然能够收缩挂载的 Btrfs 文件系统的能力确实使处理固定大小的卷的工作变得更轻松。通过在线收缩功能，就无需启动 实时镜像 了。\n在使用 Btrfs 的多设备支持时，必须仔细考虑逻辑卷的物理位置。对于 Btrfs 而言，每个逻辑卷都是一个单独的物理设备，如果实际情况并非如此，则某些数据可用性功能可能会做出错误的决定。例如，如果单个驱动器发生故障，对数据使用 RAID1 通常可以提供保护。如果实际逻辑卷在同一物理设备上，则没有冗余。\n如果强烈需要某些特定的 LVM 功能，例如原始块设备或高速缓存的逻辑卷，则在 LVM 之上运行 Btrfs 是有意义的。在这种配置下，Btrfs 仍然提供其大多数优点，例如校验和和易于发送的增量快照。尽管使用 LVM 会产生一些操作开销，但 Btrfs 的这种开销并不比任何其他文件系统大。\n总结 当尝试在 Btrfs 和 LVM-ext4 之间进行选择时，没有一个正确的答案。每个用户都有独特的要求，并且同一用户可能拥有具有不同需求的不同系统。看一下每个配置的功能集，并确定是否有令人心动的功能。如果没有，坚持默认值没有错。选择这两种设置都有很好的理由。\nSnapper Snapper 是 openSUSE 下用于创建和管理文件系统快照（以下简称快照）的工具。快照保存了文件系统在某个时间点的状态，从而可以轻松实现系统回滚或数据备份。\nSnapper 可以在 Btrfs 文件系统（推荐）及采用 XFS 或 Ext4 文件系统的 LVM 精简配置卷上使用，本文主要介绍在 Btrfs 文件系统上使用 Snapper 的方法。\n快照类型 Snapper 快照可分为两大类型：\n 快照对：由一对快照组成，在进行某项操作前拍摄一个“前快照”（pre），操作后再拍摄一个“后快照”（post），从而可以比较两个快照对差异而撤销该操作。快照对是一一对应的，如果删除了某一快照，则对应的快照也会被删除。 单一快照（single）：由一个单独的快照组成，与其他快照没有特殊联系。可用于备份或回滚整个系统等操作。  快照对和单一快照既可以手动创建，也可以根据配置自动创建。自动创建的快照又可分为三种类型：\n 时间线快照：每小时自动创建的单一快照。 安装快照：在安装软件包前后自动创建的一对快照对。可用于撤销软件包更改。 管理快照：在使用 YaST 管理系统前后自动创建的一堆快照对。可用于撤销配置更改。  这三种自动创建的快照均可单独启用和配置，从而提供了极大的灵活性。\n默认配置 要在分区或 Btrfs 子卷启用快照，需要创建配置文件。Snapper 的配置文件存储在 /etc/snapper/configs 中。\n如果你的根分区大于 16 GB，并且在安装 openSUSE 时使用默认分区配置，则根分区的配置文件应已被自动创建。默认配置启用了安装快照和管理快照，并排除了部分目录，可以满足大多数需求。以下列表显示了排除的所有目录：\n  /boot/grub2/i386-pc、/boot/grub2/x86_64-efi、/boot/grub2/powerpc-ieee1275、/boot/grub2/s390x-emu\n不能回滚引导加载程序配置。上面列出的目录是架构专属目录。前两个目录位于 AMD64/Intel 64 计算机上，后两个目录分别位于 IBM POWER 和 IBM Z 上。\n  /home\n如果独立的分区中没有 /home，便会将该目录排除以免在回滚时发生数据丢失。\n  /opt、/var/opt\n第三方产品通常安装到 /opt 下。排除此目录是为了防止在回滚时卸装这些应用程序。\n  /srv\n包含 Web 和 FTP 服务器的数据。排除此目录是为了防止在回滚时发生数据丢失。\n  /tmp、/var/tmp、/var/cache、/var/crash\n包含临时文件和超速缓存的所有目录都会排除在快照范围之外。\n  /usr/local\n在手动安装软件时会用到此目录。系统会将该目录排除以免在回滚时卸载这些安装的软件。\n  /var/lib/libvirt/images\n使用 libvirt 管理的虚拟机映像的默认位置。为确保回滚期间虚拟机映像不会替换为旧版本而被排除。默认情况下，此子卷是使用写入时不复制选项创建的。\n  /var/lib/mailman、/var/spool\n包含邮件或邮件队列的目录会排除，以免在回滚后造成邮件丢失。\n  /var/lib/bind\n包含 DNS 服务器的区域数据。排除该目录是为了确保回滚后名称服务器仍能运作。\n  /var/lib/mariadb、/var/lib/mysql、/var/lib/pgqsl\n这些目录包含数据库数据。默认情况下，这些子卷是使用写入时不复制选项创建的。\n  /var/log\n日志文件所在的位置。排除该目录是为了在对受损的系统进行回滚后能够对日志文件进行分析。\n  如果你希望使用 openSUSE 的默认配置，但在安装 openSUSE 时未开启快照功能，可以使用以下命令创建根分区的默认配置文件：\n注意： 要使用该默认配置文件，请确保根分区大小至少为 16 GB，并使用 openSUSE 安装程序建议的包含子卷的 Btrfs 根文件系统（安装程序默认分区设置）\nsnapper -c root create-config / 确保 snapper-zypp-plugin 软件包已安装以启用安装快照：\nzypper install snapper-zypp-plugin 手动配置 创建和装入新子卷 系统支持在 / 层次下创建新的子卷，并永久性装入该卷。此类子卷将从快照中排除。切勿在现有快照中创建此类子卷，因为在回滚之后，您将无法再删除快照。\nSUSE Linux Enterprise Server 上配置了 /@/ 子卷，该子卷充当永久性子卷（例如 /opt、/srv、/home 等）的独立根目录。您创建和永久装入的任何新子卷都需要在这个初始根文件系统中创建。\n为此，请运行以下命令。在此示例中，从 /dev/sda2 创建了一个新子卷 /usr/important。\nsudo mount /dev/sda2 -o subvol=@ /mntsudo btrfs subvolume create /mnt/usr/importantsudo umount /mnt /etc/fstab 中的相应项需类似于：\n/dev/sda2 /usr/important btrfs subvol=@/usr/important 0 0 提示：子卷可能包含经常更改的文件，例如虚拟化的磁盘映像、数据库文件或日志文件。如果是这样，可考虑对此卷禁用写入时复制功能，以免复制磁盘块。可在 /etc/fstab 中使用 nodatacow 装入选项来实现此目的：\n/dev/sda2 /usr/important btrfs nodatacow,subvol=@/usr/important 0 0 或者，要为单个文件或目录禁用写入时复制功能，请使用命令 chattr +C 路径。\n创建配置文件 希望在特定分区或子卷启用快照，可以以下命令创建相应的配置文件：\nsnapper -c 配置文件名 create-config 分区或子卷的挂载点 这将根据 /etc/snapper/config-templates/default 提供的默认值创建配置文件。\n注意： 在创建配置文件前请确保目标分区或子卷已被创建。不能为同一分区或子卷创建多个配置文件。\n例如，为防止回滚时数据丢失，默认的根分区配置排除了 /home 目录，可以使用上述命令为 /home 创建配置文件：\nsnapper -c home create-config /home 该命令会使用 /etc/snapper/config-templates/default 提供的默认值创建 /etc/snapper/configs/home 文件。\n可以使用\nsnapper list-configs 查看现有配置文件。\n启用/禁用自动快照 你可以选择性地启用/禁用自动创建的快照类型：\n启用时间线快照\nsnapper -c 配置文件名 set-config \u0026quot;TIMELINE_CREATE=yes\u0026quot; 禁用时间线快照\nsnapper -c 配置文件名 set-config \u0026quot;TIMELINE_CREATE=no\u0026quot; 时间线快照默认会启用，但根分区除外。\n注意： 以下两种快照包含的内容由安装的软件包或修改的配置而定，与特定分区或子卷无关。默认为启用状态。\n启用安装快照\nzypper install snapper-zypp-plugin 禁用安装快照\nzypper remove snapper-zypp-plugin 使用 YaST 或 Zypper 安装包时所创建的快照会由 snapper-zypp-plugin 进行处理。何时创建快照由 XML 配置文件 /etc/snapper/zypp-plugin.conf 定义。\n启用管理快照\n在 /etc/sysconfig/yast2 中将 USE_SNAPPER 设置为 yes 禁用管理快照\n在 /etc/sysconfig/yast2 中将 USE_SNAPPER 设置为 no 配置文件参数 Snapper 的行为由配置文件参数定义，除了直接使用文本编辑器编辑配置文件外，还可以使用\nsnapper -c 配置文件名称 set-config \u0026quot;参数名称=参数\u0026quot; 修改配置文件参数。\n以下对几个常用配置案例进行说明，完整的参数说明可参阅 snapper-configs(5) ：\nman snapper-configs 允许普通用户管理快照\n默认情况下仅 root 用户可以管理快照，要允许普通用户或组管理快照，可运行：\nsnapper -c 配置文件名称 set-config \u0026quot;ALLOW_USERS=用户名\u0026quot; \u0026quot;ALLOW_GROUPS=组名\u0026quot; \u0026quot;SYNC_ACL=yes\u0026quot; 必须配置“SYNC_ACL=yes”以允许普通用户访问快照所在目录。\n自动清理旧快照\n为防止快照占据全部磁盘空间，Snapper 提供了几种自动清理旧快照的机制，可通过一系列参数配置自动清理过程：\n   清理机制 说明 启用选项 配置参数 含义 备注     编号 根据快照编号进行清理 NUMBER_CLEANUP=yes NUMBER_LIMIT=数字或范围 定义要保留的快照数量。 如果启用了定额支持，应使用范围。如果未启用定额支持，应使用单个数字。   NUMBER_LIMIT_IMPORTANT=数字或范围 定义要保留的含 important 标签的快照数量，内核更新等的安装快照自带该标签。       NUMBER_MIN_AGE=秒 定义满足上述条件的快照被清理前最少应保留的时间。0 表示无限制。       时间线 根据快照创建时间进行清理 TIMELINE_CLEANUP=yes TIMELINE_LIMIT_HOURLY=数字或范围 定义要保留的每小时首张快照的数量。 如果启用了定额支持，应使用范围。如果未启用定额支持，应使用单个数字。   TIMELINE_LIMIT_DAILY=数字或范围 定义要保留的每日首张快照的数量。       TIMELINE_LIMIT_WEEKLY=数字或范围 定义要保留的每周首张快照的数量，此处的周由星期一开始。       TIMELINE_LIMIT_MONTHLY=数字或范围 定义要保留的每月首张快照的数量。       TIMELINE_LIMIT_YEARLY=数字或范围 定义要保留的每年首张快照的数量。       TIMELINE_MIN_AGE=秒 定义满足上述条件的快照被清理前最少应保留的时间。0 表示无限制。       无差异快照对 清理没有差异的快照对。如运行 Yast2 后未作任何修改，则自动清理创建的管理快照。 EMPTY_PRE_POST_CLEANUP=yes EMPTY_PRE_POST_CLEANUP=秒 定义无差异快照对被清理前最少应保留的时间。0 表示无限制。    磁盘定额 定义快照可占用空间的百分比 运行snapper setup-quota SPACE_LIMIT=表示百分比的小数 定义快照可占用空间的百分比 仅支持 Btrfs 文件系统需至少启用编号或时间线清理算法中的一个启用定额支持后，编号和时间线清理算法的部分参数应当使用范围值。清理算法会清理快照至上限值，如果未满足定额配置则在下限值范围内尽量清理快照以满足定额。    管理配置文件 可以使用 snapper 命令快速管理配置文件：\n列出配置文件\nsnapper list-configs 显示特定的配置文件\nsnapper -c 配置文件名称 get-config 删除配置文件\nsnapper -c 配置文件名称 delete-config 快照管理 可以使用 snapper 工具或 Yast2 模块进行查看、创建、比较快照等操作。\nsnapper 工具提供了一系列子命令，可以在文本界面进行快照管理。本节介绍了一些常用命令和参数，更多信息可参阅 snapper(8)：\nman snapper 注意： 管理快照时可使用 “-c 配置文件名” 指定配置文件，如未指定则默认使用 root 配置文件，下述示例均未指定配置文件。\n查看快照\nsnapper list 将列出 root 配置的所有快照。\n可以使用 “-t” 参数列出特定类型的快照。\n例如，列出 root 配置下的所有快照对：\nsnapper list -t pre-post 列出 home 配置下的所有单一快照：\nsnapper -c home list -t single 你还可以使用\nsnapper list -a 列出所有配置下的快照。\n创建快照\nsnapper create 将使用 root 配置文件创建一个单一快照。\n可以使用“-t”参数指定快照类型（默认值为 single），使用“-d”参数添加描述。手动创建的快照默认不会自动被清理，使用“\u0026ndash;cleanup-algorithm”参数指定自动清理算法。还可以使用“\u0026ndash;userdata”参数定义自定义数据（如 important 标记）。\n例如，创建当前系统的单一快照，标记为重要，并指定时间线清理算法：\nsnapper create -t single --description \u0026quot;系统快照\u0026quot; --userdata \u0026quot;important=yes\u0026quot; --cleanup-algorithm timeline 要创建一个快照对，首先创建一个前快照，使用“\u0026ndash;print-number”选项以列出快照编号：\nsnapper create -t pre --print-number --description \u0026quot;Before\u0026quot; 假设列出的快照编号为 30，将其作为“\u0026ndash;pre-number”参数的值创建后快照：\nsnapper create -t post --pre-number 30 --description \u0026quot;After\u0026quot; 你也可以使用\nsnapper create --command \u0026quot;要运行的命令\u0026quot; 以自动创建运行命令前后的快照对。\n比较快照\n有两种比较方法：\nsnapper status \u0026lt;第一个快照编号\u0026gt;..\u0026lt;第二个快照编号\u0026gt; //第一个快照的创建时间要早于第二个 将显示您在两个快照时间内修改的全部文件的路径和文件名。\n例如，下述命令可以比较当前系统状态与 161 号快照的差异：\nsnapper status 161..0 //0 表示当前系统，它不是快照，但你可以认为是比所有快照都新的一个快照。 第二种：\nsnapper diff \u0026lt;第一个快照编号\u0026gt;..\u0026lt;第二个快照编号\u0026gt; 文件名 将以 diff 的格式显示指定文件的差异，如果未指定文件名，将显示所有文件的差异。\n撤销修改\nsnapper undochange \u0026lt;修改前的快照编号\u0026gt;..\u0026lt;修改后的快照编号\u0026gt; \u0026lt;文件名\u0026gt; 比如你误删除了某个文件，可以使用：\nsnapper undochange \u0026lt;删除文件前的快照编号\u0026gt;..0 文件名 //0 表示当前系统，它不是快照，但你可以认为是比所有快照都新的一个快照。 来撤销。\n删除快照\nsnapper delete 快照编号或范围 例如，要删除 16 号快照：\nsnapper delete 16 要删除 10 号到 15 号快照：\nsnapper delete 10-15 可以结合“-s”参数以在删除快照后立刻释放可用空间而不必等待 Btrfs 进程回收。\n回滚整个系统\nSUSE Linux Enterprise Server 上包含的 GRUB 2 版本可以从 Btrfs 快照进行引导。与 Snapper 的回滚功能相结合，就能恢复配置错误的系统。只有针对默认 Snapper 配置（根）创建的快照才可引导。\n注意： 要回滚整个系统，请确保根文件系统为 openSUSE 安装程序默认的带子卷的 Btrfs 文件系统。从 SUSE Linux Enterprise Server 15 开始，只有在根分区的默认子卷配置未更改过的情况下，才支持系统回滚。\n如果因为更新或病毒等原因导致系统出现重大错误，并保留了错误前的快照，则可以回滚整个系统到错误前的状态。\nsnapper rollback 要回滚的快照编号 该命令将创建当前系统状态的只读快照 A 及指定编号快照的可读写快照 B，并使用快照 B 替换根分区的默认子卷，重新启动系统后即可实现回滚。\n你还可以在引导系统时选择Start bootloader from a read-only snapshot，以引导想要回滚的快照，在检查无误后在引导的快照中执行：\nsnapper rollback 不指定快照编号时，将创建根分区默认子卷（即原系统）的只读快照 A 和当前系统（即目前引导的快照）的可读写快照 B，并使用快照 B 替换根分区的默认子卷，重新启动系统后选择默认引导项即可实现回滚。\nFirewall-cmd firewall-cmd(firewalld command line client) 是 firewalld 的主要命令行工具。它可以用来获取 firewalld 的状态信息，获取运行时和永久环境的防火墙配置，也可以用来修改这些配置。\n基本概念 firewalld 将所有的网络数据流量划分为多个区域，再根据数据包的源IP地址或传入网络接口等条件，将数据流量转入相应区域的防火墙规则中。\n block：拒绝所有传入的网络连接。只有从系统内部发起的网络连接才可能有效； dmz：隔离区域也称为非军事化区域，为您的局域网提供有限的访问权限，并且只允许选定的传入端口； drop：终止所有传入链接，只允许传出的链接； external：对路由器类型的连接很有用。你需要局域网和广域网的接口来进行伪装（NAT）才能正常工作。 home：适用于家庭电脑，如局域网内的笔记本电脑和台式机，您可以信任其他电脑。只允许选定的 TCP/IP 端口； internal：用于内部网络，当你几乎信任局域网内的其他服务器或计算机时； public（系统默认值）：适用于始终处于公共区域的云服务器或托管在您处的服务器。您不信任网络上的任何其他计算机和服务器。您只允许使用所需的端口和服务； trusted：允许任何的网络链接； work：适用于您信任您的同事和其他服务器的工作场所。  查看默认区域：\n$ firewall-cmd --get-default-zone 当 NetworkManager 添加新的接口连接（如 eth0 或 ens3）时，它们将被连接到默认的区域。通过运行以下命令进行验证：\n$ firewall-cmd --get-active-zones 服务（services） 服务是一个包含了本地端口、协议、源端口、目的地和防火墙帮助模块 (firewall helper modules) 的列表。\n查询服务 # 查询当前区域允许的服务 $ sudo firewall-cmd --list-services # 查询特定区域允许的服务 $ sudo firewall-cmd --list-services --zone=[区域] # 查询全部区域的服务或防火墙规则 $ sudo firewall-cmd --list-all-zones 如查询与 public 相关的防火墙规则或服务：\n$ sudo firewall-cmd --list-all --zone=public public (active) target: default icmp-block-inversion: no interfaces: wlan0 sources: services: dhcpv6-client ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: 在该查询结果中，默认区域是 public ，允许的服务是 dhcpv6-client 。\n删除服务 $ sudo firewall-cmd --remove-service=[服务] --permanent --zone=[区域] $ sudo firewall-cmd --reload \u0026ndash;permanent 指定永久规则则。运行时的 firewalld 配置更改是临时性的，当你重新启动 openSUSE 或 firewalld 时，它们就会消失。而永久规则则不受影响。\n添加服务 $ sudo firewall-cmd --add-service=[服务] --permanent --zone=[区域] $ sudo firewall-cmd --reload sudo 许多命令和系统实用程序都需要以 root 身份运行才能执行。为了确保安全和避免发生意外运行危险命令，通常建议不要直接以 root 身份登录。建议的做法是以非特权的普通用户身份工作，并使用 sudo 命令来运行需要较高特权的命令。\n在 SUSE Linux Enterprise Server 上，sudo 默认配置与 su 的工作方式类似。但是，sudo 可让用户以高度可配置的方式使用任何其他用户的特权来运行命令。这样，便可为某些用户和组指派具有特定特权的角色。举例来说，可以允许组 users 的成员使用 wilber 的特权运行命令。通过禁止指定任何命令选项，可以进一步限制对命令的权限。虽然 su 始终需要 root 口令才能使用 PAM 进行身份验证，但是您可以将 sudo 配置为使用您自己的身份凭证进行身份验证。这样就不需要共享 root 口令，从而提高了安全性。\nsudo 基本用法 虽然 sudo 简单易用，功能却十分强大。\n运行单个命令 以普通用户身份登录后，您可以在命令前加上 sudo 以 root 身份运行任何命令。按照提示输入口令后，如果身份验证成功，您便能以 root 身份运行命令：\n# id -un 命令会打印当前用户的登录名 $ id -un tux # 在输入过程中不会显示口令，无论是明文还是密文均不显示。  $ sudo id -un root\u0026#39;s password: root # 只有以 sudo 开头的命令才会使用较高的特权运行。如果是不带 sudo 前缀的相同命令，仍会使用当前用户的特权运行。  $ id -un tux # 在限定时间内，您无需再次输入 root 口令。  $ sudo id -un root I/O 重定向的工作方式与您预期的可能不同：\n$ sudo echo s \u0026gt; /proc/sysrq-trigger bash: /proc/sysrq-trigger: Permission denied $ sudo cat \u0026lt; /proc/1/maps bash: /proc/1/maps: Permission denied 只有 echo/cat 二进制会使用较高特权运行，重定向则由用户外壳使用用户特权执行。您可以按启动外壳中所述启动外壳，也可以使用 dd 实用程序来启动：\n$ echo s | sudo dd of=/proc/sysrq-trigger $ sudo dd if=/proc/1/maps | cat 启动外壳 必须在每条命令前加上 sudo 可能很繁琐。虽然可以将外壳指定为命令 sudo bash，但还是建议您使用以下其中一种内置机制来启动外壳：\n  sudo -s (\u0026lt;命令\u0026gt;)\n启动 SHELL 环境变量所指定的外壳或目标用户的默认外壳。如果给定了命令，则会将该命令传递给外壳（使用 -c 选项），否则外壳会以交互模式运行。\n$ sudo -s root's password: $ exit   sudo -i (\u0026lt;命令\u0026gt;)\n  与 -s 类似，但是会将外壳启动为登录外壳。也就是说，系统会对外壳的启动文件（.profile 等）进行处理，并会将当前的工作目录设置为目标用户的主目录。\n$ sudo -i root's password: $ exit   环境变量 默认情况下，sudo 不会传播环境变量：\n$ ENVVAR=test env | grep ENVVAR ENVVAR=test $ ENVVAR=test sudo env | grep ENVVAR root's password: $ 输出为空即表明在使用 sudo 运行的命令的环境中不存在环境变量 ENVVAR。\n此行为可通过 env_reset 选项进行更改，请参见下文有用的标志和选项。\n配置 sudo sudo 是一个非常灵活的工具，提供各种配置选项。\n注意：如果您不小心将自己锁定在 sudo 之外，则可以使用 su - 及 root 口令来获取 root 外壳。要修复该错误，请运行 visudo。\n编辑配置文件 sudo 的主要策略配置文件为 /etc/sudoers。如果此文件中存在错误，您可能便会无法进入系统，因此强烈建议您使用 visudo 来编辑配置文件。此举可防止同时更改打开的文件，并会在保存修改之前检查语法错误。\n您还可以通过设置 EDITOR 环境变量来使用除 vi 以外的编辑器（不论名字如何），例如：\n$ sudo EDITOR=/usr/bin/nano visudo 不过，/etc/sudoers 文件本身是由系统包提供的，更新时这些修改可能会取消。因此，建议您将自定义配置放到 /etc/sudoers.d/ 目录下的文件中。该目录下的任何文件都会自动纳入系统中。要在该子目录下创建或编辑文件，请运行：\nsudo visudo -f /etc/sudoers.d/NAME 或者，使用其他编辑器（例如 nano）：\nsudo EDITOR=/usr/bin/nano visudo -f /etc/sudoers.d/NAME 注意：/etc/sudoers 中的 #includedir 命令（用于 /etc/sudoers.d）会忽略以 ~（波浪号）结尾或包含 .（点）的文件。\n关于 visudo 命令的详细信息，请运行 man 8 visudo。\nsudoers 基本配置语法 在 sudoers 配置文件中，有两种类型的选项：字符串和标志。字符串可以包含任何值，而标志则只能在“ON”或“OFF”之间切换。sudoers 配置文件最重要的语法构造为：\n# Everything on a line after a # gets ignored, Defaults !insults # Disable the insults flag Defaults env_keep += \u0026quot;DISPLAY HOME\u0026quot; # Add DISPLAY and HOME to env_keep tux ALL = NOPASSWD: /usr/bin/frobnicate, PASSWD: /usr/bin/journalctl  #include 和 #includedir 这两个普通命令例外。其后跟数字，用于指定 UID。 去除 ! 可将指定的标志设置为“ON”。  有用的标志和选项\n   选项名称 说明 示例     targetpw 此标志控制调用用户是需要输入目标用户（例如 root）的口令 (ON) 还是需要输入调用用户的口令 (OFF)。 Defaults targetpw # Turn targetpw flag ON   rootpw 如果设置了该选项，sudo 会提示输入 root 口令，而非目标用户或调用者的口令。默认值为“OFF”。 Defaults !rootpw # Turn rootpw flag OFF   env_reset 如果设置了该选项，sudo 会构造一个仅包含 TERM、PATH、HOME、MAIL、SHELL、LOGNAME、USER、USERNAME 和 SUDO_* 集的最小环境。此外，会从调用环境导入 env_keep 中列出的变量。默认值为“ON”。 Defaults env_reset # Turn env_reset flag ON   env_keep env_reset 标志设为“ON”时要保留的环境变量列表。 # Set env_keep to contain EDITOR and PROMPT Defaults env_keep = \u0026quot;EDITOR PROMPT\u0026quot; Defaults env_keep += \u0026quot;JRE_HOME\u0026quot; # Add JRE_HOME Defaults env_keep -= \u0026quot;JRE_HOME\u0026quot; # Remove JRE_HOME   env_delete env_reset 标志设为“OFF”时要去除的环境变量列表。 # Set env_delete to contain EDITOR and PROMPT Defaults env_delete = \u0026quot;EDITOR PROMPT\u0026quot; Defaults env_delete += \u0026quot;JRE_HOME\u0026quot; # Add JRE_HOME Defaults env_delete -= \u0026quot;JRE_HOME\u0026quot; # Remove JRE_HOME    还可以使用 Defaults 令牌为用户、主机和命令集合创建别名。并且，可以仅将选项应用到特定用户集。\n关于 /etc/sudoers 配置文件的详细信息，请参见 man 5 sudoers。\nsudoers 中的规则 sudoers 配置中的规则可能会非常复杂，因此本节仅涉及基本内容。每个规则都遵循基本模式（[] 标记的是可选部分）：\n#Who Where As whom Tag What User_List Host_List = [(User_List)] [NOPASSWD:|PASSWD:] Cmnd_List   User_List\n一个或多个（用 , 分隔）标识符：用户名、格式为 %GROUPNAME 的组或格式为 #UID 的用户 ID。可以使用 ! 前缀来取反。\n  Host_List\n一个或多个（用 , 分隔）标识符：（完全限定的）主机名或 IP 地址。可以使用 ! 前缀来取反。Host_List 的惯常选项为 ALL。\n  NOPASSWD:|PASSWD:\n如果用户在 NOPASSWD: 后面运行的命令与 CMDSPEC 匹配，系统不会提示用户输入口令。\nPASSWD 为默认选项，仅当两个选项位于同一行时才需要指定它：\ntux ALL = PASSWD: /usr/bin/foo, NOPASSWD: /usr/bin/bar   Cmnd_List\n一个或多个（用 , 分隔）区分符：可执行文件的路径，后跟允许使用的自变量或什么也不跟。\n/usr/bin/foo # Anything allowed /usr/bin/foo bar # Only \u0026quot;/usr/bin/foo bar\u0026quot; allowed /usr/bin/foo \u0026quot;\u0026quot; # No arguments allowed   ALL 可以用作 User_List、Host_List 和 Cmnd_List。\n允许 tux 在无需输入口令的情况下以 root 身份运行所有命令的规则：\ntux ALL = NOPASSWD: ALL 允许 tux 运行 systemctl restart apache2 的规则：\ntux ALL = /usr/bin/systemctl restart apache2 允许 tux 在不带自变量的情况下以 admin 身份运行 wall 的规则：\ntux ALL = (admin) /usr/bin/wall \u0026quot;\u0026quot; 警告：以下类型的构造\nALL ALL = ALL 在没有 Defaults targetpw 的情况下切勿使用，否则任何人都能以 root 身份运行命令。\n常见使用情况 尽管默认配置对于简单的设置和桌面环境通常已经够用，但是自定义配置非常有用。\n在无需 root 口令的情况下使用 sudo 在具有特殊限制（“用户 X 只能以 root” 身份运行命令 Y）的情况下，无法实现此目的。在其他情况下，还是建议进行某种分隔。按照惯例，组 wheel 的成员能以 root 身份运行所有带有 sudo 的命令。\n  将自己添加到 wheel 组\n如果您自己的用户帐户尚不是 wheel 组的成员，请添加该帐户，具体做法是运行 sudo usermod -a -G wheel 用户名然后注销并再次登录。运行 groups 用户名以确认更改是否成功。\n  将使用调用用户的口令进行身份验证的选项设为默认设置。\n使用 visudo 创建文件 /etc/sudoers.d/userpw并添加：\nDefaults !targetpw   选择新默认规则。\n根据是否想要用户重新输入口令，取消对 /etc/sudoers 中特定行的注释，并将默认规则注释掉。\n## Uncomment to allow members of group wheel to execute any command # %wheel ALL=(ALL) ALL ## Same thing without a password # %wheel ALL=(ALL) NOPASSWD: ALL   提高默认规则的限制性\n将 /etc/sudoers 中允许一切操作的规则注释掉或去除：\nALL ALL=(ALL) ALL # WARNING! Only use this together with 'Defaults targetpw'!   警告：切勿漏掉这一步，否则任何用户都能以 root 身份执行任何命令。\n  测试配置\n尝试以 wheel 的成员和非成员身份运行 sudo。\n# user tux $ groups users wheel $ sudo id -un tux's password: root # use wilber $ groups users $ sudo id -un wilber is not in the sudoers file. This incident will be reported.   对 X.Org 应用程序使用 sudo 在使用 sudo 启动图形应用程序时，可能会出现以下错误：\n$ sudo xterm xterm: Xt error: Can't open display: %s xterm: DISPLAY is not set YaST 会选择 ncurses 界面而非图形界面。\n要在通过 sudo 启动的应用程序中使用 X.Org，需要传播环境变量 DISPLAY 和 XAUTHORITY。要进行此项配置，请创建文件 /etc/sudoers.d/xorg并添加下面一行：\nDefaults env_keep += \u0026quot;DISPLAY XAUTHORITY\u0026quot; 如尚未设置 XAUTHORITY 变量，请按如下方式设置：\nexport XAUTHORITY=~/.Xauthority 现在，X.Org 应用程序便可正常运行：\nsudo yast2 Zypper Zypper 是用于安装、更新和去除包的命令行包管理器。它还可管理储存库。这一点对于完成远程软件管理任务或从外壳脚本管理软件尤其有用。\n一般使用 Zypper 的常用语法为：\nzypper [--global-options] COMMAND [--command-options] [arguments] 有关常规选项和所有命令的列表，请参见 zypper help。要获取有关特定命令的帮助，请键入 zypper help 命令。\n  Zypper 命令\n执行 Zypper 最简单的方式是，键入其名称后跟一个命令。例如，要将所有需要的增补程序应用于系统，请使用：\n$ sudo zypper patch   全局选项\n此外，您还可以选择使用一个或多个全局选项，只需在命令前面键入它们即可：\n$ sudo zypper --non-interactive patch 在上面的示例中，选项 --non-interactive 表示在不询问任何问题的情况下运行命令（自动应用默认回答）。\n  命令特定的选项\n要使用特定于某个命令的选项，请紧接在该命令后面键入这些选项：\n$ sudo zypper patch --auto-agree-with-licenses 在上面的示例中，--auto-agree-with-licenses 用于将所有需要的增补程序应用于系统，不要求您确认任何许可条款，而是自动接受许可条款。\n  自变量\n某些命令需要一个或多个自变量。例如，使用 install 命令时，需要指定您要安装的一个或多个包：\n$ sudo zypper install mplayer 某些选项还需要单个自变量。用以下命令可列出所有已知模式：\n$ zypper search -t pattern   您可以组合上述所有模式。例如，下面的命令在冗长模式下运行时将安装 mc and vim 包（来自 factory 储存库）：\n$ sudo zypper -v install --from factory mc vim --from 选项确保了在从指定储存库请求包时保留所有储存库的启用状态（用于解析任何依赖项）。\n多数 Zypper 命令都有 dry-run 选项，它模拟给定的命令。它可用于测试。\n$ sudo zypper remove --dry-run MozillaFirefox Zypper 支持 --userdata 字符串全局选项。您可以使用此选项指定一个将会写入 Zypper 的日志文件和插件（例如 Btrfs 插件）的字符串。它可以用于标记和标识日志文件中的事务。\n$ sudo zypper --userdata STRING patch 使用 Zypper 安装和删除软件 要安装或去除包，请使用以下命令：\n$ sudo zypper install PACKAGE_NAME$ sudo zypper remove PACKAGE_NAME 警告：不要去除必需的系统包，例如 glibc 、zypper、kernel。如果去除这些包，系统可能会变得不稳定，或完全停止工作。\n选择要安装或去除的包 可以使用 zypper install 和 zypper remove 命令通过多种方法来找到包。\n  按确切的包名称\n$ sudo zypper install MozillaFirefox   按确切的包名称和版本号\n$ sudo zypper install MozillaFirefox-52.2   按储存库别名和包名称\n$ sudo zypper install mozilla:MozillaFirefox 其中 mozilla 是用于安装的储存库别名。\n  使用通配符按包名称\n您可以选择名称以特定字符串开头或结尾的所有包。使用通配符要小心，特别是去除包的时候。以下命令将安装名称以“Moz”开头的所有包：\n$ sudo zypper install 'Moz*' 提示：在调试问题时，您有时需要临时安装大量的 -debuginfo 包，以获取有关正在运行的进程的详细信息。在调试会话完成后，如果您需要清理环境，请运行以下命令：\n$ sudo zypper remove '*-debuginfo'   按功能\n例如，要安装不知道名称的包，这些功能就很有用。下面的命令将安装包 MozillaFirefox：\n$ sudo zypper install firefox   按功能、硬件体系结构或版本\n  所需硬件体系结构的名称需要追加在功能的后面，两者以句点分隔。例如，要指定 AMD64/Intel 64 体系结构（在 Zypper 中命名为 x86_64），请使用：\n$ sudo zypper install 'firefox.x86_64'   版本必须追加到字符串的末尾，并且前面必须带有一个运算符：\u0026lt;（小于）、\u0026lt;=（小于等于）、=（等于）、\u0026gt;=（大于等于）或 \u0026gt;（大于）。\n$ sudo zypper install 'firefox\u0026gt;=52.2'   还可以指定硬件体系结构与版本组合要求：\n$ sudo zypper install 'firefox.x86_64\u0026gt;=52.2'     按 RPM 文件的路径\n您还可以指定包的本地或远程路径：\n$ sudo zypper install /tmp/install/MozillaFirefox.rpm$ sudo zypper install http://download.example.com/MozillaFirefox.rpm   同时安装和去除包 要同时安装和去除包，请使用 +/- 修饰符。要安装 emacs 并同时去除 vim ，请使用：\n$ sudo zypper install emacs -vim 要去除 emacs 并同时安装 vim ，请使用：\n$ sudo zypper remove emacs +vim 为避免 - 开头的包名称被解释为命令行选项，要始终把它用作第二个自变量。如果做不到这点，在它之前加上 --：\n$ sudo zypper install -emacs +vim # Wrong$ sudo zypper install vim -emacs # Correct$ sudo zypper install -- -emacs +vim # Correct$ sudo zypper remove emacs +vim # Correct 清理已去除包的依赖项 如果您想将在指定的包去除后不再需要的所有包（随指定的包）自动去除，请使用 --clean-deps 选项：\n$ sudo zypper rm PACKAGE_NAME --clean-deps 在脚本中使用 Zypper 默认情况下，在安装或删除选定包之前发生问题时，Zypper 会要求确认。您可以使用 --non-interactive 选项覆盖此行为。必须在实际命令（install、remove 和 patch）的前面指定此选项，如下所示：\n$ sudo zypper --non-interactive install PACKAGE_NAME 该选项允许在脚本和 cron 任务中使用 Zypper。\n安装或下载源包 要安装某个包的对应源代码包，请使用：\n$ zypper source-install PACKAGE_NAME 以 root 身份执行时，源包的默认安装位置为 /usr/src/packages/；以用户身份运行时，则为 ~/rpmbuild。可以在本地 rpm 配置中更改这些值。\n使用此命令还会安装指定包的版本依赖项。如果不想执行此操作，请添加开关 -D：\n$ sudo zypper source-install -D PACKAGE_NAME 要只安装版本依赖项，请使用 -d。\n$ sudo zypper source-install -d PACKAGE_NAME 当然，只有当储存库列表中启用了含有源包的储存库时，才能这样做（默认添加但不启用它）。\n可使用以下方法来获取储存库中所有源包的列表：\n$ zypper search -t srcpackage 您也可以将所有已安装软件包的源包下载到本地目录。要下载源包，请使用：\n$ zypper source-download 默认的下载目录是 /var/cache/zypper/source-download。您可以使用 --directory 选项更改下载目录。若只想显示缺失或多余的包而不进行下载或删除任何内容，请使用 --status 选项。要删除多余的源包，请使用 --delete 选项。要禁用删除，请使用 --no-delete 选项。\n从禁用的储存库安装包 通常，您只能安装或刷新来自启用的储存库的包。--plus-content 标记选项可帮助您指定要刷新的、要在当前 Zypper 会话期间暂时启用的，以及要在会话完成后禁用的储存库。\n例如，要启用可以提供其他 -debuginfo 或 -debugsource 包的储存库，请使用 --plus-content debug。可以多次指定此选项。\n要暂时启用此类“调试”储存库以安装特定的 -debuginfo 包，请按如下所示使用该选项：\n$ sudo zypper --plus-content debug \\ install \u0026quot;debuginfo(build-id)=eb844a5c20c70a59fc693cd1061f851fb7d046f4\u0026quot; 对于缺少的 debuginfo 包，gdb 将会报告 build-id 字符串。\n实用程序 要校验所有依赖项是否仍然满足，并修复缺少的依赖项，请使用：\n$ zypper verify 除了依赖项必须满足外，某些包还“推荐”其他包。只有在实际可用并可安装时才会安装这些推荐包。如果推荐的包在推荐它们的包已安装（通过添加其他包或硬件）之后才可用，请使用以下命令：\n$ sudo zypper install-new-recommends 此命令在插入网络摄像头或 Wi-Fi 设备后非常有用。如果可用，它将安装设备驱动程序和相关软件。只有在满足特定硬件依赖项后，才可安装驱动程序和相关软件。\n使用 Zypper 更新软件 用 Zypper 更新软件有三种方式：安装包、安装包的新版本或更新整个分发包。最后一种方式可通过 zypper dist-upgrade 来实现。\n安装全部所需的增补程序 要安装所有适用于您系统的正式发布的增补程序，请运行：\n$ sudo zypper patch 系统将会检查您计算机上配置的储存库中提供的所有增补程序是否与您的安装相关。如果相关（未分为可选或功能类别），则会立即安装这些增补程序。\n如果即将安装的增补程序所包含的更改要求重引导系统，您会在重引导前收到警告。\n单纯使用 zypper patch 命令不会应用来自第三方储存库的包。要同时更新第三方储存库，请使用 with-update 命令选项，如下所示：\n$ sudo zypper patch --with update 要额外安装可选增补程序，请使用：\n$ sudo zypper patch --with-optional 要安装与特定 Bugzilla 问题相关的所有增补程序，请使用：\n$ sudo zypper patch --bugzilla=NUMBER 要安装与特定 CVE 数据库项相关的所有增补程序，请使用：\n$ sudo zypper patch --cve=NUMBER 例如，要安装 CVE 编号为 CVE-2010-2713 的安全增补程序，请执行：\n$ sudo zypper patch --cve=CVE-2010-2713 如果只想安装影响 Zypper 和包管理本身的增补程序，请使用：\n$ sudo zypper patch --updatestack-only 请记住，如果您使用了 updatestack-only 命令选项，将会丢弃原本还会更新其他储存库的其他命令选项。\n列出增补程序 为了让您确定增补程序是否可用，Zypper 允许您查看以下信息：\n  所需增补程序的数目\n要列出所需增补程序（适用于您的系统但尚未安装的增补程序）的数目，请使用 patch-check：\n$ zypper patch-checkLoading repository data...Reading installed packages...5 patches needed (1 security patch) 可以结合 --updatestack-only 选项使用此命令，以便仅列出影响 Zypper 和包管理本身的增补程序。\n  所需增补程序的列表\n要列出全部所需的增补程序（适用于您的系统但尚未安装的增补程序），请使用 list-patches：\n$ zypper list-patchesLoading repository data...Reading installed packages...Repository | Name | Version | Category | Status | Summary---------------+-------------+---------+----------+---------+---------SLES12-Updates | SUSE-2014-8 | 1 | security | needed | openssl: Update for OpenSSL   所有增补程序的列表\n要列出可用的所有增补程序，而不管它们是否已安装或适用于您的安装，请使用 zypper patches。\n还可以列出并安装与特定问题相关的增补程序。要列出特定的增补程序，请使用带以下选项的 zypper list-patches 命令：\n  按 Bugzilla 问题\n要列出与 Bugzilla 问题相关的全部所需增补程序，请使用 --bugzilla 选项。\n要列出针对特定 Bug 的增补程序，您也可以指定 Bug 编号：--bugzilla=编号。要搜索与多个 Bugzilla 问题相关的增补程序，请在 bug 编号之间添加逗号，例如：\n$ zypper list-patches --bugzilla=972197,956917   按 CVE 编号\n要列出与 CVE（公共漏洞和披露）数据库中某个项相关的全部所需增补程序，请使用 --cve 选项。\n要列出针对特定 CVE 数据库项的增补程序，您也可以指定 CVE 编号：--cve=*编号*。要搜索与多个 CVE 数据库项相关的增补程序，请在 CVE 编号之间添加逗号，例如：\n$ zypper list-patches --bugzilla=CVE-2016-2315,CVE-2016-2324     要列出所有增补程序而不管是否需要安装它们，请另外使用 --all 选项。例如，要列出指派有 CVE 编号的所有增补程序，请使用：\n$ zypper list-patches --all --cveIssue | No. | Patch | Category | Severity | Status------+---------------+-------------------+-------------+-----------+----------cve | CVE-2015-0287 | SUSE-SLE-Module.. | recommended | moderate | neededcve | CVE-2014-3566 | SUSE-SLE-SERVER.. | recommended | moderate | not needed[...] 安装新的包版本 如果某个安装源只包含新包，但未提供增补程序，则 zypper patch 不会产生任何作用。要使用可用的较新版本更新所有已安装的包（同时还要保持系统完整性），请使用︰\n$ sudo zypper update 要更新个别包，请用更新或安装命令指定包：\n$ sudo zypper update PACKAGE_NAME$ sudo zypper install PACKAGE_NAME 可使用此命令来获取所有新的可安装包的列表：\n$ zypper list-updates 请注意，此命令只会列出符合以下准则的包︰\n 与已安装的包拥有相同的供应商， 由至少与已安装包拥有相同优先级的储存库提供， 可安装（满足所有依赖项）。  所有新的可用包（无论是否可安装）的列表可通过以下方式获取：\n$ sudo zypper list-updates --all 要找出新包无法安装的原因，请使用上面所述的 zypper install 或 zypper update 命令。\n识别孤立的包 每当您从 Zypper 中去除某个储存库或者升级系统时，某些包可能会进入“孤立”状态。这些孤立的包不再属于任何活动储存库。以下命令可以列出这些包：\n$ sudo zypper packages --orphaned 借助此列表，您可以确定是否仍然需要某个包，或者是否可以安全去除某个包。\n识别使用已删除文件的进程和服务 在增补、更新或去除包时，系统上可能有一些正在运行的进程会继续使用更新或去除后已被删除的文件。运行 zypper ps 可以列出使用已删除文件的进程。如果此类进程属于某个已知的服务，则会列出服务名称，方便您重启动该服务。默认情况下，zypper ps 会显示一个表：\nPID | PPID | UID | User | Command | Service | Files------+------+-----+-------+--------------+--------------+-------------------814 | 1 | 481 | avahi | avahi-daemon | avahi-daemon | /lib64/ld-2.19.s-\u0026gt; | | | | | | /lib64/libdl-2.1-\u0026gt; | | | | | | /lib64/libpthrea-\u0026gt; | | | | | | /lib64/libc-2.19-\u0026gt;[...]  PID：进程的 ID PPID：父进程的 ID UID：运行进程的用户的 ID User：运行进程的用户的登录名 Command：用于执行进程的命令 Service：服务名称（仅当命令与系统服务关联时才显示） Files：已删除文件的列表  通过如下方式可控制 zypper ps 的输出格式：\n  zypper ps -s\n创建一份简短表格，其中不会显示已删除的文件。\nPID | PPID | UID | User | Command | Service------+------+------+---------+--------------+--------------814 | 1 | 481 | avahi | avahi-daemon | avahi-daemon817 | 1 | 0 | root | irqbalance | irqbalance1567 | 1 | 0 | root | sshd | sshd1761 | 1 | 0 | root | master | postfix1764 | 1761 | 51 | postfix | pickup | postfix1765 | 1761 | 51 | postfix | qmgr | postfix2031 | 2027 | 1000 | tux | bash |   zypper ps -ss\n仅显示与系统服务关联的进程。\nPID | PPID | UID | User | Command | Service------+------+------+---------+--------------+--------------814 | 1 | 481 | avahi | avahi-daemon | avahi-daemon817 | 1 | 0 | root | irqbalance | irqbalance1567 | 1 | 0 | root | sshd | sshd1761 | 1 | 0 | root | master | postfix1764 | 1761 | 51 | postfix | pickup | postfix1765 | 1761 | 51 | postfix | qmgr | postfix   zypper ps -sss\n仅显示使用已删除文件的系统服务。\navahi-daemonirqbalancepostfixsshd   zypper ps --print \u0026quot;systemctl status %s\u0026quot;\n显示用于检索可能需要重启动的服务状态信息的命令。\nsystemctl status avahi-daemonsystemctl status irqbalancesystemctl status postfixsystemctl status sshd   用 Zypper 管理安装源 Zypper 的所有安装或增补程序命令均基于已知安装源列表。要列出系统已知的所有储存库，请使用命令：\n$ zypper repos 结果将类似于与以下输出：\n# | Alias | Name | Enabled | Refresh--+--------------+---------------+---------+--------1 | SLEHA-12-GEO | SLEHA-12-GEO | Yes | No2 | SLEHA-12 | SLEHA-12 | Yes | No3 | SLES12 | SLES12 | Yes | No 当在各个命令中指定储存库时，可以使用别名、URI 或 zypper repos 命令输出中的储存库编号。储存库别名是用于储存库处理命令中的储存库名称的简短版本。请注意，在修改储存库列表后，储存库编号可能会更改。别名本身不会更改。\n默认情况下不显示储存库的 URI 或优先级之类的细节。用以下命令可以列出所有细节：\n$ zypper repos -d 添加安装源 要添加安装源，请运行\n$ sudo zypper addrepo URI ALIAS URI 可以是因特网储存库、网络资源、目录、CD 或 DVD。ALIAS 是储存库的唯一简写标识符。您可以随意选择别名，前提是它必须唯一。如果指定的别名已在使用，Zypper 将发出警告。\n刷新储存库 zypper 可让您从配置的储存库中提取包的更改。要提取更改，请运行：\n$ sudo zypper refresh 注意：有些命令默认会自动执行 refresh，因此您不需要明确运行该命令。\n使用 refresh 命令时搭配 --plus-content 选项还可查看已禁用储存库中的更改：\n$ sudo zypper --plus-content refresh 该选项虽然会提取储存库中的更改，但会使禁用储存库的状态保持不变，即仍为禁用。\n删除储存库 要从列表中去除某个储存库，请将命令 zypper removerepo 与要删除的储存库的别名或编号结合使用。例如\n$ sudo zypper removerepo 1$ sudo zypper removerepo \u0026quot;SLEHA-12-GEO\u0026quot; 修改储存库 用 zypper modifyrepo 启用或禁用储存库。您还可以用该命令更改储存库的属性（例如刷新行为、名称或优先级）。以下命令将会启用名为 updates 的储存库、打开自动刷新并将其优先级设置为 20：\n$ sudo zypper modifyrepo -er -p 20 'updates' 修改储存库并不局限于单个储存库 —— 您也可以对组执行该操作︰\n -a：所有储存库 -l：本地储存库 -t：远程储存库 -m 类型：特定类型的储存库（其中类型可以是以下之一：http、https、ftp、cd、dvd、dir、file、cifs、smb、nfs、hd 和 iso）  要重命名安装源别名，请使用 renamerepo 命令。以下示例将别名从 Mozilla Firefox 更改为 firefox：\n$ sudo zypper renamerepo 'Mozilla Firefox' firefox 用 Zypper 查询储存库和包 Zypper 提供各种查询储存库或包的方式。要获取所有可用的产品、模式、包或增补程序的列表，请使用以下命令：\n$ zypper products$ zypper patterns$ zypper packages$ zypper patches 要查询特定包的所有储存库，请使用 search。要获得有关特定包的信息，请使用 info 命令。\n搜索软件 zypper search 命令可对包名或（视情况）对包摘要和说明执行搜索。括在 / 中的字符串会解译为正则表达式。默认情况下搜索不区分大小写。\n  执行简单搜索来查找包含 fire 的包名称\n$ zypper search \u0026quot;fire\u0026quot;   执行简单搜索来查找确切的包 MozillaFirefox\n$ zypper search --match-exact \u0026quot;MozillaFirefox\u0026quot;   同时在包描述和摘要中搜索\n$ zypper search -d fire   仅显示尚未安装的包\n$ zypper search -u fire   显示包含字符串 fir 且该字符串后面不是 e 的包\n$ zypper se \u0026quot;/fir[^e]/\u0026quot;   搜索特定功能 要搜索提供特殊功能的包，请使用命令 what-provides。例如，如果您想知道哪个包提供 Perl 模块 SVN::Core，请使用以下命令：\n$ zypper what-provides 'perl(SVN::Core)' what-provides 包名 与 rpm -q --whatprovides 包名 类似，不过 RPM 只能查询 RPM 数据库（即所有已安装的包的数据库）。另一方面，Zypper 将告诉您任意储存库的功能的提供商，而非仅已安装的储存库功能的提供商。\n显示包信息 要查询个别包，请使用 info 命令，并用完整包名称作为自变量。这会显示有关某个包的详细信息。如果包名与储存库中的所有包名都不匹配，该命令会输出非包匹配项的详细信息。如果您请求特定类型（通过使用 -t 选项），但该类型不存在，该命令会输出其他可用的匹配项，但不提供详细信息。\n如果您指定源包，该命令会显示基于该源包构建的二进制包。如果您指定二进制包，该命令会输出用来构建该二进制包的源包。\n如果还要显示该包必需/推荐的包，则使用选项 --requires 和 --recommends：\nzypper info --requires MozillaFirefox 显示生命周期信息 要检查您的产品和所支持包的生命周期，请如下所示使用 zypper lifecycle 命令：\n$ zypper lifecycleProduct end of supportCodestream: SUSE Linux Enterprise Server 15 2028-04-23 SUSE Linux Enterprise Server 15 n/a*Module end of supportBasesystem Module 2021-07-31No packages with end of support different from product.*) See https://www.suse.com/lifecycle for latest information 配置 Zypper Zypper 现在随附配置文件，允许您永久更改 Zypper 的行为（系统范围或用户特定）。要进行系统范围更改，请编辑 /etc/zypp/zypper.conf。要进行用户特定的更改，请编辑 ~/.zypper.conf。如果 ~/.zypper.conf 尚不存在，您可以使用 /etc/zypp/zypper.conf 作为模板：将其复制到 ~/.zypper.conf 并根据您的喜好进行调整。请参见文件中的注释，获取有关可用选项的帮助。\n查错 如果您在访问配置的储存库中的包时遇到问题（例如，尽管您知道某个包在某个储存库中，但 Zypper 找不到该包），刷新储存库或许可以解决问题：\nsudo zypper refresh 如果不起作用，则尝试\nsudo zypper refresh -fdb 这会强制完全刷新和重构建数据库，包括强制下载原始元数据。\nBtrfs 文件系统上的 Zypper 回滚功能 如果根分区上使用的是 Btrfs 文件系统，且系统中安装了 snapper，当 Zypper 提交对文件系统所做的更改以创建相应的文件系统快照时，会自动调用 snapper。这些快照可用于还原 Zypper 进行的任何更改。\nRPM RPM（RPM 程序包管理器）用于管理软件包。其主要程命令为 rpm 和 rpmbuild。用户、系统管理员和包构建人员可以查询强大的 RPM 数据库以获得有关已安装软件的详细信息。\nrpm 有五种模式：安装、卸装（或更新）软件包、重构建 RPM 数据库、查询 RPM 库或独立 RPM 存档、对包执行完整性检查以及对包签名。rpmbuild 可用于从原始源构建可安装的包。\n用特殊的二进制格式对可安装 RPM 存档进行打包。这些存档由要安装的程序文件和某些元信息组成，这些元信息供 rpm 在安装过程中配置软件包使用或者储存在 RPM 数据库中进行存档。RPM 存档通常具有扩展名 .rpm。\n对于一些包，软件开发所需的组件（库、报头、包含文件等）已纳入独立的包中。只有当您要自己编译软件时才需要这些开发包（例如最新的 GNOME 包）。可以通过扩展名 -devel 确定这些开发包，例如包 alsa-devel 和 gimp-devel。\n校验包真实性 RPM 包具有 GPG 签名。要校验 RPM 包的签名，请使用 rpm --checksig PACKAGE-1.2.3.rpm 命令确定该包是来自 SUSE 还是另一个可信机构。特别建议对来自因特网的更新包使用此命令。\n修复操作系统中的问题时，您可能需要将问题临时修复 (PTF) 安装到生产系统中。SUSE 提供的包已使用特殊的 PTF 密钥签名。要手动导入该密钥，请使用以下命令：\nsudo rpm --import \\/usr/share/doc/packages/suse-build-key/suse_ptf_key.asc 导入该密钥后，您可以在系统上安装 PTF 包。\n管理包：安装、更新和卸装 安装 RPM 存档的步骤通常十分简单，执行运行：rpm -i PACKAGE.rpm。使用此命令可以安装包，但前提是满足其依赖关系并且不与其他包冲突。如果出现错误消息，rpm 将请求那些需要安装的包以满足依赖关系要求。在后台，RPM 数据库确保不出现冲突 － 一个特定文件只能属于一个包。通过选择不同的选项，您可以强制 rpm 忽略这些默认设置，但这只供专家用户使用。否则，将影响系统的完整性并可能使系统无法更新。\n选项 -U 或 --upgrade 以及 -F 或 --freshen 可用于更新包（例如，rpm -F PACKAGE.rpm）。此命令将删除旧版本的文件并立即安装新文件。两个版本之间的差别是：-U 安装系统中以前不存在的包，而 -F 只更新以前安装的包。更新时，rpm 使用以下策略小心更新配置文件：\n 如果配置文件未被系统管理员更改，则 rpm 将安装适当文件的新版本。系统管理员无需执行任何操作。 如果配置文件在更新前曾被系统管理员更改，则 rpm 会以扩展名 .rpmorig 或 .rpmsave（备份文件）保存更改的文件，并安装新包中的版本。仅当原先安装的文件和较新的版本不同时，才执行此操作。如果是这种情况，则将备份文件（.rpmorig 或 .rpmsave）与新安装的文件进行比较，并在新文件中再次进行更改。之后，请删除所有 .rpmorig 和 .rpmsave 文件，以免以后的更新出现问题。 如果配置文件已存在并且 .spec 文件中指定了 noreplace 标签，则出现 .rpmnew 文件。  更新后，在使用 .rpmsave 和 .rpmnew 文件进行比较后应将它们删除，从而防止它们阻碍以后的更新。如果 RPM 数据库以前未能识别文件，则将为其指派扩展名 .rpmorig。 否则，将使用 .rpmsave。换句话说，.rpmorig 是从异系统格式更新为 RPM 的结果。而 .rpmsave 是从较早的 RPM 更新为较新的 RPM 的结果。.rpmnew 不提供任何有关系统管理员是否对配置文件进行过任何更改的信息。/var/adm/rpmconfigcheck 中提供这些文件的列表。不覆盖某些配置文件（如 /etc/httpd/httpd.conf）以允许继续进行操作。\n-U 开关的作用并不完全等同于使用 -e 选项进行卸载以及使用 -i 选项进行安装，它还有其他作用。只要可能，就可以使用 -U。\n要去除包，请输入 rpm -e PACKAGE。仅当不存在未解决的依赖项问题时，此命令才会删除包。例如，只要有其他程序需要 Tcl/Tk，理论上就不能删除它。即使是在这种情况下，RPM 也会向数据库寻求帮助。如果出于任何原因无法进行此删除操作（即使不存在其他依赖项），则最好使用选项 --rebuilddb 重构建 RPM 数据库。\n增量 RPM 包 增量 RPM 包包含旧版本和新版本的 RPM 包之间的差别。在旧 RPM 上应用增量 RPM 将得到全新的 RPM。不需要旧 RPM 的副本，因为增量 RPM 也可以与已安装的 RPM 一起工作。增量 RPM 包的大小甚至比增补程序 RPM 小，这有利于通过因特网传送更新包。缺点是，涉及增量 RPM 的更新操作与使用纯粹 RPM 或增补程序 RPM 进行更新的情况相比，占用的 CPU 周期要长得多。\nmakedeltarpm 和 applydelta 二进制文件是增量 RPM 套件（包 deltarpm）的一部分，可帮助您创建和应用增量 RPM 包。使用以下命令可以创建名为 new.delta.rpm 的增量 RPM。以下命令假设 old.rpm 和 new.rpm 是存在的：\nsudo makedeltarpm old.rpm new.rpm new.delta.rpm 如果旧包已经安装，则使用 applydeltarpm 可以从文件系统重新构建新的 RPM：\nsudo applydeltarpm new.delta.rpm new.rpm 如果不访问文件系统而从旧 RPM 得到它，请使用 -r 选项：\nsudo applydeltarpm -r old.rpm new.delta.rpm new.rpm RPM 查询 带 -q 选项的 rpm 将启动查询，如此用户便可查看 RPM 存档（通过添加选项 -p）并查询已安装包的 RPM 数据库。可以使用多个开关指定所需信息的类型。\n   选项 含义     -i 包信息   -l 文件列表   -f FILE 查询包含文件 FILE 的包（必须使用 FILE 指定完整路径）   -s 带有状态信息的文件列表（间接指定 -l）   -d 仅列出文档文件（间接指定 -l）   -c 仅列出配置文件（间接指定 -l）   --dump 带有完整详细信息的文件列表（将用于 -l、-c 或 -d）   --provides 列出包中可被另一个包通过 --requires 请求的功能   --requires, -R 包需要的功能   --scripts 安装脚本（预安装、后安装、卸载）    例如，命令 rpm -q -i wget 显示\nName : wgetVersion : 1.14Release : 17.1Architecture: x86_64Install Date: Mon 30 Jan 2017 14:01:29 CETGroup : Productivity/Networking/Web/UtilitiesSize : 2046483License : GPL-3.0+Signature : RSA/SHA256, Thu 08 Dec 2016 07:48:44 CET, Key ID 70af9e8139db7c82Source RPM : wget-1.14-17.1.src.rpmBuild Date : Thu 08 Dec 2016 07:48:34 CETBuild Host : sheep09Relocations : (not relocatable)Packager : https://www.suse.com/Vendor : SUSE LLC \u0026lt;https://www.suse.com/\u0026gt;URL : http://www.gnu.org/software/wget/Summary : A Tool for Mirroring FTP and HTTP ServersDescription :Wget enables you to retrieve WWW documents or FTP files from a server.This can be done in script files or via the command line.Distribution: SUSE Linux Enterprise 12 只有当您指定带有完整路径的完整文件名时，选项 -f 才起作用。根据需要提供任意多个文件名。例如：\nrpm -q -f /bin/rpm /usr/bin/wgetrpm-4.11.2-15.1.x86_64wget-1.14-17.1.x86_64 如果只知道部分文件名，则可以使用外壳脚本。当运行所显示的脚本时，将部分文件名以参数的形式传递给脚本。\n#! /bin/shfor i in $(rpm -q -a -l | grep $1); do echo \u0026quot;\\\u0026quot;$i\\\u0026quot; is in package:\u0026quot; rpm -q -f $i echo \u0026quot;\u0026quot;done rpm -q --changelog PACKAGE 命令会按日期排序显示有关特定包的详细更改信息列表。\n借助已安装的 RPM 数据库，可以进行校验检查。使用 -V 或 --verify 启动这些检查。使用此选项，rpm 显示安装后已被更改的包中的所有文件。rpm 使用 8 个字符符号给出有关以下更改的一些提示：\n   符号 含义     5 MD5 校验和   S 文件大小   L 符号链接   T 修改时间   D 主要和次要设备编号   U 拥有者   G 组   M 方式（权限和文件类型）    对于配置文件，将输出字母 c。例如，对于 /etc/wgetrc（wget 包）的更改：\nrpm -V wgetS.5....T c /etc/wgetrc RPM 数据库的文件被放置在 /var/lib/rpm 中。如果分区 /usr 的大小为 1 GB，则此数据库可能会占用将近 30 MB，特别是在完全更新之后。如果数据库比预期大得多，则最好使用选项 --rebuilddb 重构建数据库。在执行此操作之前，制作旧数据库的备份。cron 脚本 cron.daily 每天制作数据库的副本（用 gzip 打包）并将这些副本储存在 /var/adm/backup/rpmdb 中。副本的数目是由 /etc/sysconfig/backup 中的变量 MAX_RPMDB_BACKUPS（默认值为 5）控制的。对于 1 GB 的 /usr，单个备份的大小大约为 1 MB。\n安装和编译源包 所有源包都带有 .src.rpm 扩展名（源 RPM）。\n源包可以从安装媒体复制到硬盘并使用 YaST 解压缩。但是，在包管理器中它们不会被标记为已安装 ([i])。这是因为源包不是在 RPM 数据库中输入的。只有已安装的操作系统软件列在 RPM 数据库中。安装源包时，只将源代码添加到系统中。\n以下目录必须可用于 /usr/src/packages 中的 rpm 和 rpmbuild（除非在诸如 /etc/rpmrc 这样的文件中指定自定义设置）：\n  SOURCES\n代表原始源（.tar.bz2 或 .tar.gz 文件等）和特定于发布版本的调整（多为 .diff 或 .patch 文件）\n  SPECS\n代表 .spec 文件，类似于元 Makefile，该文件控制构建进程\n  BUILD\n在此目录中解压缩、增补和编译所有源\n  RPMS\n储存完整的二进制包的位置\n  SRPMS\n这里是源 RPM\n  使用 YaST 安装源包时，将在 /usr/src/packages 中安装所有需要的组件：源和调整在 SOURCES 中，相关的 .spec 文件在 SPECS 中。\n警告：不要对系统组件（glibc、rpm 等）进行试验，因为这样做会影响系统的稳定性。\n下面的示例使用 wget.src.rpm 包。安装源包后，应具有类似以下列表中的文件：\n/usr/src/packages/SOURCES/wget-1.11.4.tar.bz2/usr/src/packages/SOURCES/wgetrc.patch/usr/src/packages/SPECS/wget.spec rpmbuild -bX /usr/src/packages/SPECS/wget.spec 会启动编译。X 是通配符，代表构建进程的不同阶段。以下简要描述：\n  -bp\n在 /usr/src/packages/BUILD 中准备源：解压和打增补程序。\n  -bc\n执行与 -bp 相同的操作，但还进行编译。\n  -bi\n执行与 -bp 相同的操作，但还安装生成的软件。注意：如果包不支持 BuildRoot 功能，则可能会重写配置文件。\n  -bb\n执行与 -bi 相同的操作，但还创建二进制包。如果编译成功，二进制包应该在 /usr/src/packages/RPMS 中。\n  -ba\n执行与 -bb 相同的操作，但还创建源 RPM。如果编译成功，二进制包应该在 /usr/src/packages/SRPMS 中。\n  --short-circuit\n跳过某些步骤。\n  现在可以使用 rpm -i 或最好使用 rpm -U 来安装创建的二进制 RPM。使用 rpm 进行安装使它显示在 RPM 数据库中。\n使用 build 编译 RPM 包 许多包存在的风险是构建进程中会将许多不需要的文件添加到正在运行的系统中。为防止发生这种情况，请使用 build，它将创建构建包的已定义环境。要建立这一 chroot 环境，build 脚本必须和完整的包树结构一起提供。可以通过 NFS 或从 DVD 使用硬盘上的此树。使用 build --rpms DIRECTORY 设置位置。与 rpm 不同，build 命令在源目录中查找 .spec 文件。要用系统中 /media/dvd 下装入的 DVD 构建 wget（如上例所示），请以 root 用户身份使用以下命令：\ncd /usr/src/packages/SOURCES/mv ../SPECS/wget.spec .build --rpms /media/dvd/suse/ wget.spec 随后，将在 /var/tmp/build-root 建立一个最小的环境。在此环境中构建包。完成后，生成的包位于 /var/tmp/build-root/usr/src/packages/RPMS 中。\nbuild 脚本提供多个其他选项。例如，使脚本优先选择您自己的 RPM、忽略构建环境的初始化或者将 rpm 命令限制在上述阶段之一。\n用于 RPM 存档和 RPM 数据库的工具 Midnight Commander (mc) 可以显示 RPM 存档的内容并复制部分内容。它将存档表示为虚拟文件系统，提供 Midnight Commander 所有常用的菜单选项。使用 F3 键显示 HEADER。使用光标键和 Enter 键查看存档结构。使用 F5 键复制部分存档。\n拥有全部功能的包管理器将作为 YaST 模块提供。\nPackman 什么是 Packman ？ openSUSE 的 Packman 是 Package man 的缩写。意即指一群打包狂组成的团体。他们在尊重并重视版权的基础上做一些规避专利的事。总之，他们想要自由打包从多媒体到大型软件到游戏到甚至是自己的回收站的所有内容。\nPackman 和 openSUSE 的关系 Packman 不隶属于任何 openSUSE 官方，是独立于 openSUSE 社区之外的社区，只是基于 openSUSE 打给 openSUSE 用的软件包。注意 openSUSE 社区也是官方，同样有在专利法最为严苛的美国和欧洲注册，这也是为什么 OBS 不能打包专利软件的原因，另一个原因是 OBS 的服务器坐落于德国诺伦堡。\nPackman 的资源来自于成员捐献，不能和 openSUSE 官方有任何的联系，也就是说即使是 SuSE 的捐献，也要放弃一切权利。不能像社区董事会那样，主席要由 SuSE 指定，一般是 SuSE 员工。\nPackman 欢迎大学和社区为它做镜像。\nPackman 收纳什么样的软件 ？ 由于英文的 free 很有迷惑性（大部分外国人喜欢用法语 Libre，也就是自由）：\n 这里的自由，仍然不包括商业和私有软件，版权产品应该尊重他们自有的分发渠道。也就是说，这里仍然不做盗版，也不做免费使用的商业软件。不规避版权，只规避专利。版权同样是保护 Linux 下的开源作品不被盗版的力量，而专利则是大公司用来牟利的工具。 这里只接纳由于或有专利纠纷而不能存在于官方构建服务中的软件。比如 FFMPEG，MPLAYER，MP3, AMULE。和依赖它们的软件。以及可以自由分发的软件，并且愿意允许从源代码编译。  也就是说，大部分时候这里的软件都是 FOSS/LOSS （自由和开源软件），而不是免费软件。而且是存在或有专利纠纷的软件，想想看什么软件最容易发生专利纠纷呢？ 多媒体。于是 Packman 里有那么多多媒体软件也就不奇怪了。\n另外 Packman 还允许两类软件：发行版中长期不更新的软件的最新版，和发行版中没有的软件。但这是 FTP 做源的时代延续下来的。目前这两类软件都建议走 OBS 流程来做，因为 OBS 的服务器比 Packman 的多快好省。\nTips\u0026amp;Questions 解决KDE下KDE Wallet重装系统后每次登陆需要输入密码 在每次重装或者配置桌面后kdewallet总是在登陆系统之后提示输入密码，虽然在输入密码后能够继续正常使用，但是每次登陆系统都需要输入一次密码还是很烦人的。\n出现的原因：\n在重新配置桌面或者重装系统之后KDE Wallet所需要的一些必备需要依赖组件未能找到，所以导致不能正确运行KDE Wallet，所以只要安装其所需的组件即可。而其所需的但是未能自动安装的依赖组件正是 pam_kwallet，kwallet-pam 与 GnuPG keys 不兼容，所以 KDE Wallet 必须使用 blowfish 加密方式。\n解决方案 ：\n安装缺失的组件\nsudo zypper in pam_kwallet 为了保险起见，查看个人目录下是否存在~/.kde4/share/apps/kwallet文件夹，如果存在则将其删除或者重命名以避免出现冲突，并且还需要确定使用的钱包名为kdewallet并且密码为当前用户的密码。\n如此便可完全正常使用KDE Wallet\n解决方案参考arch wiki的KDE Wallet小节中。\nCould not open a connection to your authentication agent 执行ssh-add时出现\nssh-agent bash 无法读取 exfat 、 .7z 和 .rar sudo zypper in fuse-exfat exfat-utilssudo zypper in p7zip-fullsudo zypper in unrar 不关闭单击运行 Dolphin 默认单击运行，多数人都熟悉双击运行，但是其实只要点击文件左上角的加号，就可以不运行，相当于双击下的单击选择文件。\n杀死窗口 按 CTRL + ESC ，启动系统卫士，点击 工具 ，然后点击 杀死窗口 ，然后点击你想干掉的窗口。\n主题 不是我喜欢黑暗主题，而是热门的好看的主题都是黑暗主题。所以尝试如下：\n 全局黑暗主题为 Sweet chrome 黑暗主题  系统设置 Theme 使用 GTK+，可以使标题栏，设置菜单栏为黑暗，但是网页、设置页为白色。 Chrome 黑暗模式：在网址栏输入 chrome://flags/#enable-force-dark，启用。可以使设置页面黑暗，网页黑暗，但是进入 segmentfault，你会发现 segment 不见了。 安装 dark reader 插件。可以使网页黑暗，比 chrome 自带表现要好。但是打开新页面时，还是有短暂的白色。   Firefox 黑暗主题  设置页的颜色会与系统一致，也就是与 chrome 相反。 firefox theme 会改变标题栏、设置菜单栏颜色。    实际上你会发现，无法达到一致的黑暗，反而使得眼睛不舒服，所以我放弃了黑暗主题。\n亮色混合主题：\n Global Theme 为 openSUSE Plasma 为 Edna-light Window Decorations 为 Edna-light Font 为 Source Hans Sans CN 和 Jet Brains Moon Icon 为 Papirus SSDM Theme 为 chili for plasma kconsole 主题为 sweet 开始改为 application dashboard  实际你会发现，混合主题没有一个单独主题搭配的那么协调。\n窗体内容亮色，其他部分为黑暗，即标准主题:\n 全局主题 Sweet Colors 为 Breeze，使得 window 内容为亮色 Window Decorations 为 sweet-dark-transparent，设置标题栏 Icon 为 Papirus SSDM Theme 为 sweet fcitx 为 dartmouth。  感觉可以。\nDesktop Effects：\n Magic Lamp 400ms Wobbly Windows  不如不要。\nopenSUSE 的默认 /etc/sudoers Defaults targetALL ALL=(ALL) ALLroot ALL=(ALL) ALL 并把root密码设置为安装时用户密码。\n这导致你在装完系统后，如果改了密码，依旧需要通过原来的密码获取 root 权限。\nvscode keychain issues for KDE $ sudo zypper in gnome-keyring 提示添加密码的时候为空就行了，否则每次启动 vscode 都需要输入一次密码。\nNVIDIA 有两种为英伟达（NVIDIA）显卡提供的驱动：\n 为 NVIDIA 硬件提供的自由开源的驱动名叫 nouveau。 来自 NVIDIA 厂商自己的驱动名为 nvidia，但由于许可证问题，它不能直接被集成进入 openSUSE 。  添加 Nvdia 软件源\n# zypper addrepo --refresh 'https://download.nvidia.com/opensuse/leap/$releasever' NVIDIA 确定显卡型号\n# hwinfo --gfxcard | grep Model 安装驱动\n# zypper in x11-video-nvidiaG05 重启确认是否加载\n# lsmod | grep nvidia 常用软件 Typora 字体 如果 Typora 字体如上面那样，每个字大小不一样：\n  整个应用的语言设置为英语\n  在 conf.user.json 指定字体\n{ \u0026#34;defaultFontFamily\u0026#34;: { \u0026#34;standard\u0026#34;: \u0026#34;Source Han Sans CN\u0026#34;, //String - Defaults to \u0026#34;Times New Roman\u0026#34;.  \u0026#34;serif\u0026#34;: \u0026#34;Source Han Sans CN\u0026#34;, // String - Defaults to \u0026#34;Times New Roman\u0026#34;.  \u0026#34;sansSerif\u0026#34;: \u0026#34;Source Han Sans CN\u0026#34;, // String - Defaults to \u0026#34;Arial\u0026#34;.  \u0026#34;monospace\u0026#34;: \u0026#34;JetBrains Mono\u0026#34; // String - Defaults to \u0026#34;Courier New\u0026#34;.  } }   flatpak run: Invalid MIT-MAGIC-COOKIE-1 key rm .Xauthority Linux Deploy 准备 一个 Root 了的 Android 手机\nBusy Box：Linux Deploy 支撑软件。\nLinux deploy：Linux 系统支撑软件。\n安装 Busy Box 点击安装，等待程序自行运行，在界面中输出 ## END 后退出程序。\nLinux deploy  点击左图左上角部分，选择 设置，在设置界面中找到PATH变量，赋予其值 /system/xbin。 建议开启 锁定Wifi 功能。 接着退回主界面，点击右下角部分。 发行版 看个人喜好选择，Debian 系（Debian，Kaili，Ubuntu）较热门。 架构 默认。 源 默认。如果下的慢的话，就仿照默认的源换为国内的源，如 USTC MIRRORS，但是不要特意去换源，官方的源用的了的话官方的源最好。 安装路径 ：安装在手机自带的存储空间中，则在路径开头加上${ENV_DIR}；安装在 sdcard 中，加上${EXTERNAL_STORAGE}。 文件系统 ：推荐 ext4。 用户名 和 密码 自定义。 DNS 默认。 本地化 ：简体中文可以选择 zh_CN.UTF-8，建议选择 en_US.UTF-8 。 挂载列表：添加访问手机内容的目录，手机目录：挂载点，如 /sdcard:/mnt，之后会自动挂载。 开启SSH。 图形界面功能，需要的话就选 XFce 为桌面，XFce`是轻量级桌面环境。 退出系统设置界面，点击主界面右上角，选择安装。 等待程序自行安装Linux系统，开始时会自动创造一个4G左右大小的img文件，这个是默认的大小，你可以根据你手机的容量自定义，创造文件需要一点时间，屏幕会很安静，再然后会安装各种东西，屏幕会输出很多信息，根据你的源的速度，等待时间不等，看到 \u0026lt;\u0026lt;\u0026lt;deploy 则安装完毕。如果中间没有 failed 则安装成功。安装失败的话就需要重新安装，换个快一点的网，或者好一点的源。 注意：安装完毕后要先点击停止按钮，再按启动按钮。这个很重要，不然你就得重装了。  使用   Andorid 端用 ConnectBox\n  Windows用 putty ，图形界面用 VNC Viewer。VNC Viewer 直接搜主机IP就行，VNC Server 在你选择安装图形界面功能时就自动安装了，不需要再安装 vnc4server。\n  Linux 输入ssh username@hostname就行。\n  其他   安装后如果用 vnc viewer 只有一个点的话，可以换一个发行版，我尝试的 CentOS 有这个问题。\n  Linux连的时候出现 WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!：\nssh-keygen -R + 输入服务器的IP   altarch 架构的手机 CentOS 系统换源\ncp CentOS-7-armhfp.repo CentOS-Base.repo mv CentOS-7-armhfp.repo CentOS-7-armhfp.repo.backup vi CentOS-Base.repo baseurl=https://mirrors.ustc.edu.cn/centos-altarch/7.6.1810/os/armhfp/ yum makecache yum update   如果你之前没有安装VNC的话，现在又想装：\nyum -y install tigervnc-server   ","permalink":"https://sakamotokurome.github.io/posts/distributions/","summary":"Fedora [fəˈdɔrə] 费多拉 Fedora 定制版 为什么 Linus Torvalds 用 Fedora 2008：linus对发行版的要求是\u0026quot;易安装，比较贴近上游\u0026quot;即可。 201","title":"Distributions"},{"content":" The goals of the FreeBSD Project are to provide software that may be used for any purpose and without strings attached. Many of us have a significant investment in the code (and project) and would certainly not mind a little financial compensation now and then, but we are definitely not prepared to insist on it. We believe that our first and foremost \u0026ldquo;mission\u0026rdquo; is to provide code to any and all comers, and for whatever purpose, so that the code gets the widest possible use and provides the widest possible benefit. This is, I believe, one of the most fundamental goals of Free Software and one that we enthusiastically support.\nThat code in our source tree which falls under the GNU General Public License (GPL) or Library General Public License (LGPL) comes with slightly more strings attached, though at least on the side of enforced access rather than the usual opposite. Due to the additional complexities that can evolve in the commercial use of GPL software we do, however, prefer software submitted under the more relaxed BSD license when it is a reasonable option to do so.\nJordan Hubbard - FreeBSD Handbook\n Install FreeBSD BIOS Disable unused and unwanted options.\nInstall   To put the image on the pendrive we will use the dd tool available on almost any Mac OS X (macOS) and Linux system. For Windows You will have to download it from here – dd for windows( bs=1M on Linux/Windows ).（可用 Rufus 替代）\nsudo dd if=FreeBSD-11.1-RELEASE-amd64-memstick.img of=/dev/da1 bs=1m   When we have a new machine there is always a problem with new name for it. The RFC 1178 Choosing a Name for Your Computer from 1990 year tries to address that issue\n  We will use ZFS because we want to use Boot Environments with sysutils/beadm port.\n Hit [ENTER] on the Pool Type/Disks to select target disk to install FreeBSD on. Now (in FreeBSD 12.x) it is possible to install FreeBSD on GELI encrypted root on ZFS pool without any additional partitions or filesystems. You need to select is Yes for the Encryption part . I advice using GPT (BIOS+UEFI) as it will support both system types so when you are running BIOS system now and will move the disk to other system that boots with UEFI it will also just work out of the box. We will set SWAP size to 0 (no SWAP) as it will not be needed. If we will need SWAP in the future, then we will create ZVOL on ZFS and use it as a SWAP device.     Select services as shown below.   Enable all security hardening features as shown below.  X11 Window System X 最初設計是以網路為中心，採用 “client-server” 架構。在此架構下 “X 伺服器” 在有鍵盤、螢幕、滑鼠的電腦上運作。該伺服器負責的工作包含管理顯示、處理來自鍵盤、滑鼠的輸入及來自其他設備)的輸入或輸出。\n每個 X 應用程式，如 XTerm、Firefox 都是 “客戶端”。\n視窗管理程式規定螢幕上的視窗該長什麼樣、要如何移動滑鼠指標、 要用什麼鍵來在視窗切換、每個視窗的標題列長相，及是否該有關閉按鈕，等等。視窗管理程式負責滑鼠指標的聚焦政策。 聚焦政策指的是如何決定使用中及接收鍵盤輸入的視窗。通常較為人熟悉的聚焦政策叫做 “click-to-focus”，這個模式中，滑鼠點選到的視窗便會處於作用中 (Active) 的狀態。\nKDE 與 GNOME 會被稱作桌面環境是因為包含了完整常用桌面作業的應用程式。\nBIOS or UEFI If you find a device that is not supported by any ‘accelerated’driver like intel or nvidia. You would use vesa driver (Video Electronics Standards Association) while booting in BIOS mode and You will use scfb driver (System Console Frame Buffer) while booting on UEFI mode. This can be checked by\nsudo sysctl machdep.bootmethod Packages sudo pkg install xorg Xorg Configuration   顯示卡、顯示器以及輸入裝置會自動偵測，無須任何手動設置。除非自動設置失敗，否則請勿建立 xorg.conf 或執行 -configure 步驟。\n  加入要執行 Xorg 的使用者到 video 或 wheel 群組，以便在可用時能開啟 3D 加速。要加入使用者 jru 到任一個可用的群組：\nsudo pw groupmod video -m jru || pw groupmod wheel -m jru   Login Class(可解决中文乱码，powershell 字符显示方形)\nAdd this login class to the /etc/login.conf file.\nvideo:\\  :charset=UTF-8:\\  :lang=en_US.UTF-8:\\  :tc=default: Rebuild the login class database.\nsudo cap_mkdb /etc/login.conf Lets set the login class to video for the vuk user.\nsudo pw usermod -L video -n vuk How the account looks after setting the login class.\nsudo grep vuk /etc/master.passwd vuk:{REMOVED}:1000:1000:video:0:0:vuk:/home/vuk:/bin/sh Now logout and login again to make that work. View the changes through the locale command.\n  显卡驱动：使用多檔，每一個檔案只設定一個指定項目會較傳統使用單一 /etc/X11/xorg.conf 設定來的簡單。完整路徑為 /usr/local/etc/X11/xorg.conf.d/。（安装 intel 显卡驱动与 nvidia 驱动难，scfb 与 vesa 驱动无法调整分辨率）\nsudo vi /usr/local/etc/X11/xorg.conf.d/driver-intel.conf Section \u0026#34;Device\u0026#34; Identifier \u0026#34;Card0\u0026#34; Driver \u0026#34;scfb\u0026#34; BusID \u0026#34;PCI:0:2:0\u0026#34; EndSection 若有多張顯示卡，可取消註解 BusID identifier 然後設定為想要的顯示卡，顯示卡的 Bus ID 清單可以使用 pciconf -lv | grep -B3 display 取得。\n  手動設定\n  設定檔可由 Xorg 根據偵測到的硬體產生，這個檔案對一開始自訂設定很有幫助。\nXorg -configure   設定檔會儲存至 /root/xorg.conf.new，做任何需要的更改，然後使用以下指令測試該檔案：\nXorg -config /root/xorg.conf.new 在新設定檔調整與測試過後，便可分開成較小的檔案放置到正常的位置 /usr/local/etc/X11/xorg.conf.d/。\n    Install Desktop Enviroment   FreeBSD 桌面发行版\n GhostBSD 是 FreeBSD 桌面发行版，注意使用 Official 版本，不能直接使用 FreeBSD 源升级。 nomadbsd 是个非常漂亮的 FreeBSD 桌面发行版 ，德国产。 可以在虚拟机里面安装 FreeBSD 桌面发行版，然后找到自己想用的桌面工具，再定制自己的 FreeBSD 桌面。    Install Desktop Environment\nsudo pkg install gnome3 sudo pkg install gnome3-lite sudo pkg install x11/kde5 sudo pkg install xfce sudo pkg install mate   Install/Enable Display Manager: You have to decide how You want to start your X11 Window Server, you may login in plan text console and then type xinit or startx to read your ~/.xinitrc configuration and daemons (The difference between xinit and startx is that startx command executes xinit command with arguments.) or You may want to use X11 Login manager such as xdm/sddm/slim with ~/.xsession configuration to load after successful login.\nsudo pkg install xdm sudo pkg install slim\t# xfce,mate，slim 有个 slim-themes 软件包 sudo pkg install x11/sddm\t# kde While xinit run commands based on the ~/.xinitrc file the XDM login manager looks for the ~/.xsession file. As You will be loading same stuff regardless of the startup method we will create a link of ~/.xsession pointing to the ~/.xinitrc file. This way either method You choose You will always end with started X11 session.\nln -s ~/.xinitrc ~/.xsession One more case about the ~/.xinitrc (or ~/.xsession) file. It is interpreted as a shell script (and yes you can do if/then/else/fi and case/esac or for/while POSIX shell scripting in it) but it does not need to be executable. The last command in this file MUST NOT to be put in the background (must be without the \u0026amp; char at the end) because the X11 session will end.\n  Setting\nsudo vi /etc/ttys\t# xdm ttyv8 \u0026#34;/usr/local/bin/xdm -nodaemon\u0026#34; xterm on secure sudo vi /etc/fstab\t# gnome, kde proc /proc procfs rw 0 0 sudo vi /etc/rc.conf moused_enalbe=\u0026#34;YES\u0026#34; dbus_enable=\u0026#34;YES\u0026#34;\t# gnome, kde, xfce hald_enable=\u0026#34;YES\u0026#34;\t# gnome, kde, mate gdm_enalbe=\u0026#34;YES\u0026#34;\t# gnome 启动 sddm_enable=\u0026#34;YES\u0026#34;\t# kde 启动 slim_enable=\u0026#34;YES\u0026#34;\t# xfce,mate gnome_enable=\u0026#34;YES\u0026#34;\t# gnome 服务   slim Usage(Failed to execute login command)\nsudo vi ~/.xinitrc exec mate-session\t# mate exec xfce4-session\t# xfce   Components   Window Manager: Openbox\u0026hellip;\n  Status Bar: Also known as information bar, the place on the screen that would provide You needed information such as current date and time, CPU, RAM and storage usage, current network information or battery status.\n  While Xmobar is nice solution it comes with about 2 GB of dependencies of Haskell and Haskell libraries.\n  While Polybar can look very nice on screenshots it is a lot more heavy on resources and is limited only to modules/features that were implemented in it.\n  I have used Conky for quite long time but after recent tests I made Dzen2 is a lot less on resources then Conky while doing the same thing.\n    Task Bar: A taskbar is an element of a graphical user interface which has various purposes. It typically shows which programs are currently running.\n  You can use classic taskbar like XFCE Panel used in the XFCE desktop environment.\n  You can also configure Tint2 that way. But it only shows applications that are active on the current desktop.\n  One of the greatest taskbars of all time was/is the Mac OS X Dock (now macOS Dock). It also has an indicator showing if application is launched. Currently the best and lightest solution for providing the dock-like functionality on open desktops seems to be Plank.\n    Application Launcher: While not being any crucial role of the desktop environment it have its uses and sometimes save time.\nLets start with resources, the Rofi implementation of application launcher uses almost 3 times more RAM then Dmenu solution.\n  Desktop with Dmenu launched and with alc characters inserted to ‘filter’ commands in the search of a calculator application.\n  The Rofi requires simple command.\nrofi -show run -theme solarized_alternate -font \u0026#34;Monaco 8\u0026#34;     Blue Light Spectrum Suppress: Automatically adjusts color temperature of the screen according to your current time in your location.\n  While F.lux (closed source) does not provide a native binary for FreeBSD it does offer such binary for Linux and as FreeBSD provides Linux Binary Compatibility its possible to use it on FreeBSD. To use F.lux just start it in the ~/.xinitrc or ~/.xsession file like that.\n~/path/to/bin/xflux -l 33.54321 -g 11.12345 \u0026amp; Of course 33.54321 is latitude and 11.12345 is longitude of your localization.\n  Redshift is the solution that I propose to use as open source blue light spectrum suppressor. Similarly like with the F.lux to start Redshift just put it in the ~/.xinitrc or ~/.xsession file like that.\nredshift -l 33.54321:11.12345 -g 0.9 \u0026amp;   Someone else suggested trying sctd which is sct but rewritten/modified to be a daemon that will automatically change the color temperature during the day (or night). The sctd uses smaller about of RAM memory, uses less libraries and size of these libraries is smaller then what redshfit needs.\n    Binary 套件 搜寻软件：FreeBSD Ports、FreshPorts\n因編譯選項不同，有些 Port 會有多個版本可使用。\n  USTC Mirrors：注意使用 Latest 源，有很多流行软件。创建 /usr/local/etc/pkg/repos/FreeBSD.conf 覆盖官方源 /etc/pkg/FreeBSD.conf 配置\nsudo vi /usr/local/etc/pkg/repos/FreeBSD.conf FreeBSD: { url: \u0026#34;pkg+http://mirrors.ustc.edu.cn/freebsd-pkg/${ABI}/latest\u0026#34;, } sudo pkg update -f\t# 更新索引   163 Mirrors\n url: \u0026quot;pkg+http://mirrors.163.com/freebsd-pkg/${ABI}/latest\u0026quot;,   要啟動 (Bootstrap) 系統，請執行\nsudo /usr/sbin/pkg   當升級原使用舊版 pkg_* 工具的既有系統時，必須將資料庫轉換成新的格式\nsudo pkg2ng   Update the available remote repositories as listed in pkg.conf\nsudo pkg update   Search for a package\nsudo pkg search perl   在指定要安裝的套件時，最好使用 Port 來源來指定該應用程式，Port 來源是指應用程式在 Port 樹中的路徑\nsudo pkg search -o perl   Install a package: Installing must specify a unique origin or version otherwise it will try installing all matches\nsudo pkg install perl-5.14   列出已經安裝的 Port 中有那些已過時\nsudo pkg version -l \u0026#34;\u0026lt;\u0026#34;   Upgrade from remote repository\nsudo pkg upgrade   Delete an installed package\nsudo pkg delete perl-5.14   Remove unneeded dependencies\nsudo pkg autoremove   List installed packages\nsudo pkg info   Display information about installed packages\nsudo pkg info perl-5.14   Show the pkg-message of a package\nsudo pkg info -D perl-5.14   要查詢已安在系統上的軟體是否有任何已知的漏洞\nsudo pkg audit -F   因為相依所安裝的套件稱作自動 (Automatic) 套件，而非自動套件即套件被安裝的原因不是因為其他套件所相依\nsudo pkg prime-list\t# deprecated   Clean the local cache of fetched remote packages\nsudo pkg clean   Packages\nsudo pkg install linux-sublime3 sudo pkg install mysql180-server mysql180-client   Port 套件 優點：\n 可更改編譯選項 部份軟體的授權條款中禁止以 Binary 格式發佈。 這種軟體必須以原始碼發佈並由終端使用者編譯。 原始碼可套用自訂的修補。  Port 中並不含實際的原始碼，在編譯 Port 解壓縮時會自動下載的原始碼到 /usr/ports/distfiles。\n  USTC Mirrors：在 /etc/make.conf 中添加以下内容\nMASTER_SITE_OVERRIDE?=http://mirrors.ustc.edu.cn/freebsd-ports/distfiles/${DIST_SUBDIR}/   163 Mirrors\nMASTER_SITE_OVERRIDE?=http://mirrors.163.com/freebsd-ports/distfiles/${DIST_SUBDIR}/   安裝 Port 套件集：下載壓縮後的 Port 套件集快照 (Snapshot) 到 /var/db/portsnap\nsudo portsnap fetch   第一次執行 Portsnap 時，要先解壓縮快照到 /usr/ports\nsudo portsnap extract   執行以下指令來更新 /usr/ports\nsudo portsnap fetch sudo portsnap update   要找到 Port 所在的分類\nsudo whereis lsof   使用 Port 套件集內建的搜尋機制來找軟體\nsudo cd /usr/ports sudo make search name=lsof sudo make quicksearch name=lsof\t# 不接受多資訊   若要進行更有深度的搜尋\nsudo make search key=string sudo make quicksearch key=string   一次設定所有Port 編譯選項\nsudo make config-recursive   重新進入 Port 的編譯選項清單\nsudo make config\t# or sudo make showconfig\t# or sudo make rmconfig   編譯並安裝 Port\nsudo cd /usr/ports/sysutils/lsof sudo make install   編譯在 /usr/ports Port 並安裝到 /usr/home/example/local\nsudo make WRKDIRPREFIX=../ports PREFIX=../local install   安裝過程中會建立工作用的子目錄用來儲存編譯時暫存的檔案。可移除此目錄來節省磁碟空間並漸少往後升級新版 Port 時造成問題\nsudo make clean   移除已安裝的 Port\nsudo cd /usr/ports/sysutils/lsof sudo make deinstall   Example\ncd /usr/ports/java/linux-oracle-jdk18 sudo make install   安裝後的注意事項：\n 大部份應用程式安裝會在 /usr/local/etc 安裝至少一個預設的設定檔。 應用程式提供的文件會安裝到 /usr/local/share/doc。 部份應用程式會以服務的方式執行，在啟動應用程式前前需要加入設定到 /etc/rc.conf。這些應用程式通常會安裝啟動 Script 到 /usr/local/etc/rc.d。  Linux® Binary 相容性 FreeBSD 提供 Linux® Binary 的相容性，允許使用者在 FreeBSD 系統上不需要修改就可以安裝和執行大部份的 Linux® Binary。\n最好不要直接安装 Linux 的软件，而使用 FreeBSD 源中的 Linux 软件，一般以 linux-package 命名。\n  載入 Linux® 核心模組\nsudo kldload linux   對 64-位元的相容性\nsudo kldload linux64   確認模組已載入\nsudo kldstat   安裝基本的 Linux® 程式庫和 Binary\nsudo pkg install emulators/linux_base-c7   Add the following line\nsudo vi /etc/fstab linprocfs /compat/linux/proc\tlinprocfs\trw\t0\t0 linsysfs /compat/linux/sys\tlinsysfs\trw\t0\t0 tmpfs /compat/linux/dev/shm\ttmpfs\trw,mode=1777\t0\t0   開機時開啟 Linux® 相容性\nsudo vi /etc/rc.conf linux_enable=\u0026#34;YES\u0026#34;   安裝 Linux® ELF Binary\nsudo brandelf -t Linux my-linux-elf-binary   安裝以 Linux® RPM 為基礎的應用程式,需先安裝 archivers/rpm4 套件或 Port\nsudo pkg install rpm4 sudo cd /compat/linux sudo rpm2cpio \u0026lt; /path/to/linux.archive.rpm | cpio -id   手動安裝其他程式庫   在 Linux® 系統，可使用 ldd 來找出應用程式需要哪個共用程式庫\nldd linuxdoom libXt.so.3 (DLL Jump 3.1) =\u0026gt; /usr/X11/lib/libXt.so.3.1.0   複製 Linux® 系統輸出結果中最後一欄需要的的檔案到 FreeBSD 系統的 /compat/linux。 複製完後，建立符號連結 (Symbolic link) 至輸出結果第一欄的名稱\n/compat/linux/usr/X11/lib/libXt.so.3.1.0 /compat/linux/usr/X11/lib/libXt.so.3 -\u0026gt; libXt.so.3.1.0   自訂核心 為何要編譯自訂的核心? 自訂核心有許多項優點，如：\n 加速開機，因為自訂的核心只需要偵測您系統上存在的硬體，所以讓啟動所花的過程更流暢快速。 減少記憶體使用，自訂的核心通常會比 GENERIC 核心使用更少的記憶體，這很重要，因為核心必須一直存放在實體記憶體內。 支援額外的硬體，自訂的核心可以增加一些 GENERIC 核心沒有提供的硬體支援。  偵測系統硬體   dmesg or /var/run/dmesg.boot or /var/log/messages\n  pciconf -lv\n  在 man指令加上 -k 旗標可列出有包含指定裝置品牌或名稱的手冊頁面清單：man -k Intel\n  設定檔 /usr/src/sys 下子目錄代表著支援的硬體架構 (Architecture)，每個支援的硬體架構中會有 conf 子目錄，裡面含有供該架構使用的 GENERIC 核心設定檔。\n說明在GENERIC 同目錄的 NOTES 檔案中。所有架構通用選項，參考 /usr/src/sys/conf/NOTES。\n备份与恢复 dump \u0026amp; restore FreeBSD 系统的备份就是对系统文件的打包，然后放到一个安全的地方，使用的打包工具是 dump；FreeBSD 系统的恢复就是把你保存好的系统文件从安全的地方里面拿出来放到你的硬盘上去，使用的恢复工具是 restore；\n  需要备份的目录：\n / 这个目录存放很多基本工具，包括内核，需要备份； /home 用户数据，需要备份； /usr 很多工具以及系统的源代码都放在这里面，需要备份； /usr/local 所有安装的软件基本上都在这里，需要备份； /var 系统的日志，ports系统的数据库，需要备份；    备份方法：以 / 目录为例，把移动硬盘挂载在 /mnt/fender_01 目录，/ 目录对应硬盘上面的 /dev/ad12s1a 分区，备份整个目录的命令如下：\ndump -0Lauf /mnt/fender_01/dump/ad12sa1.dump /dev/ad12s1a  -0 备份所有的文件系统中的内容，也就是不使用增量备份； -f 指定备份结果存放的文件名； -a 告诉 dump 不考虑备份的介质的大小问题，早期备份使用磁带，dump 会预先计算一下需要的空间，使用这个选项告诉 dump 忽略这个问题； -u 告诉 dump 更新一下 /etc/dumpdates，这个文件记录了你在系统上搜有的备份活动； -L 备份已经挂载的文件系统时需要，这个选项会使用 UFS2 的 snapshot 功能来保证文件系统的一致性。    恢复方法\n  恢复 / 以外的目录：以恢复 /home 目录为例，重启系统进入单用户模式，挂载 /tmp 分区，挂载移动硬盘，这时备份生成的文件保存在 /mnt/01/dump/dev/ad12s1h.dump，格式化 /dev/ad12s1h：\nnewfs -U /dev/ad12s1h\t# -U 选型来打开 softupdate 挂载这个分区，例如 /mnt/02/，恢复目录：\ncd /mnt/02 restore -rf /mnt/01/dump/ad12s1h.dump   恢复 /：因为 restore 在 / 目录中，所以不能使用上面方法恢复 / 目录。解决办法是使用 freebsd_livefs_cd 启动系统。\n    备份 MBR\n  备份\ndd if=/dev/da0 of=/path/to/mbr.img bs=512 count=1   恢复\ndd if=/path/to/mbr.img of=/dev/da0 bs=512 count=1     参考：FreeBSD dump 备份\nrsync（remote sync） 可以在本地计算机与远程计算机之间，或者两个本地目录之间同步文件，且仅传输有变动的部分。\n  将源目录同步到目标目录\nrsync -r source1 source2 destination\t# -r 表示递归，即包含子目录 rsync -a source/ destination\t# -a 除了可以递归同步以外，还可以同步元信息（比如修改时间、权限等）   排除文件：同步时排除某些文件或目录，这时可以用 --exclude 参数指定排除模式，多个排除模式，可以用多个 --exclude 参数\nrsync -av --exclude dir source/ destination\t# 排除所有 TXT 文件   增量备份：除了源目录与目标目录直接比较，rsync 还支持使用基准目录，即将源目录与基准目录之间变动的部分，同步到目标目录。--link-dest 参数用来指定同步时的基准目录。\nrsync -a --delete --link-dest /compare/path /source/path /target/path   远程同步：rsync 默认使用 SSH 进行远程登录和数据传输\nrsync -av source/ username@remote_host:destination\t# 将本地内容同步到远程服务器 rsync -av username@remote_host:source/ destination\t# 将远程内容同步到本地   使用 rsync 来备份系统\nrsync -aH --delete --exclude dir --link-dest /compare/path source destination  -H 选项用来保持硬链接 默认情况下，rsync 只确保源目录的所有内容（明确排除的文件除外）都复制到目标目录。它不会使两个目录保持相同，并且不会删除文件。如果你想让那些在源目录里被删除的文件在目标目录里也被删除，那么你可以加上 --delete 选项来删除。--delete 参数会使得 destination 成为 source 的一个镜像。    参考：rsync 用法教程，使用 rsync 来备份 Linux 系统\nZ 檔案系統 (ZFS) ZFS 的設計目標主要有三個：\n 資料完整性：所有資料都會有一個資料的校驗碼 (checksum)，資料寫入時會計算校驗碼然後一併寫入，往後讀取資料時會再計算一次校驗碼，若校驗碼與當初寫入時不相符，便可偵測到資料錯誤，此時若有可用的資料備援 (Data redundancy)，ZFS 會嘗試自動修正錯誤。 儲存池：實體的儲存裝置都會先被加入到一個儲存池 (Pool)，這個共用的儲存池可用來配置儲存空間，儲存池的空間可被所有的檔案系統使用且透過加入新的儲存裝置來增加空間。 效能：提供多個快取機制來增加效能。先進、以記憶體為基礎的讀取快取可使用 ARC。第二層以磁碟為基礎的讀取快取可使用 L2ARC，以磁碟為基礎的同步寫入快取則可使用 ZIL。  Others Screen resolution on FreeBSD on VirtualBox 问题描述：在virtualbox虚拟机下，无法改变桌面分辨率为1366x768\nVBoxManage setextradata \u0026#34;FreeBSD\u0026#34; VBoxInternal2/EfiGraphicsResolution 1366x768 Disable the Forward/Back buttons on my mouse 问题描述：浏览网页时，鼠标滑轮滚动浏览器就会前进后退。\nSalved：\n  执行下面命令后，上下滑动鼠标滑轮，看看映射到那些button，一般是buttons 8 and 9\nsudo xev | grep -A2 ButtonPress   then disable button 8 and 9（前提是有上面的问题，否则就不要禁）\nsudo vi ~/.Xmodmap pointer = 1 2 3 4 5 6 7 0 0 0 0 0   test it with the command,command automatically when you log in; if yours doesn\u0026rsquo;t, arrange for it to run when X starts.\nsudo xmodmap ~/.Xmodmap   Install chinese font sudo pkg install zh-CJKUnifonts\t# CJK（中日韩统一表意文字） 设单使用模式为不安全 sudo vi /etc/ttys console none\tunknown off insecure No space left on device 问题描述：使用 pkg update 时提示这个问题。原因是 /tmp is too small。\nSalved:\nsudo vi /etc/fstab tmpfs\t/tmp\ttmpfs\trw,size=256000000\t0\t0\t# size 以Byte为单位 VirtualBox™ guest additions sudo cd /usr/ports/emulators/virtualbox-ose-additions \u0026amp;\u0026amp; make install clean sudo vi /etc/rc.conf vboxguest_enable=\u0026#34;YES\u0026#34; vboxservice_enable=\u0026#34;YES\u0026#34; vboxservice_flags=\u0026#34;--disable-timesync\u0026#34;\t# 若有使用 ntpd或 ntpdate，便可關閉主機時間同步功能 Fish Fish 是\u0026quot;the friendly interactive shell\u0026quot;的简称，最大特点就是方便易用。\nFish 会自动在光标后面给出建议，表示可能的选项，颜色为灰色。如果采纳建议，可以按下→或Control + F。如果只采纳一部分，可以按下Alt + →。\n输入命令时，Fish 会自动显示匹配的上一条历史记录。如果没有匹配的历史记录，Fish 会猜测可能的结果，自动补全各种输入。\nHow to start things at boot time   主流的桌面环境都自带应用程序自启动设置程序。\n  These directories are defined in /etc/defaults/rc.conf（主要是运行脚本）\n  Default startup directory is /usr/local/etc/rc.d/. if you need the files to be executed in a specific order, try numbering the files. For example:\n000This.Will.Run.First.sh 020This.Will.Run.Next.sh 030And.Then.This.sh   deprecated: /etc/rc.local\n    DSBAutostart is a Qt program that allows you to add commands to be executed at session start.\n（本质就是在 .xinitrc 调用程序指令，GUI 程序开机启动都需放入 .xinitrc，在 Xorg 启动后运行）\n  Installation\ncd /usr/ports/x11/dsbautostart \u0026amp;\u0026amp; make install distclean   Usage\n  Manual\n  Setup: Add the following command to your ~/.xinitrc, or to your window manager\u0026rsquo;s startup script (e.g. ~/.config/openbox/autostart.sh)\nsh ~/.config/DSB/autostart.sh\u0026amp;   ~/.config/DSB/autostart.sh\nPlank\u0026amp;     GUI: Setting -\u0026gt; DSBAutostart -\u0026gt; Add Command, example plank, then Save and Quit\n      FreeBSD Insall Oracle JDK  安装 Linux Compact 在 /usr/ports/java/linux-oracle-jdk18 运行 sudo make install 根据提示在 Oracle Java Archive 下载需要的 JDK 版本安装包，复制到 /usr/ports/distfiles 在 /usr/ports/java/linux-oracle-jdk18 运行 sudo make install，安装成功  FreeBSD Install Python and pip sudo pkg install python python --version Python 3.7.9 sudo pkg install py37-pip 简化启动 FreeBSD 默认启动过程相当详细，包含大量调试信息以及内核消息。\n Add the boot_mute=YES option to the /boot/loader.conf file. Add autoboot_delay=2 parameter to the /boot/loader.conf file. Add rc_startmsgs=\u0026quot;NO\u0026quot; to your /etc/rc.conf file.  连接网络 If You will have attached LAN cable and your interface is em0 (check ifconfig command output) then dhclient em0 command should grant You the working connection to the Internet – assuming that You have DHCP server on that network.\nifconfig em0 up dhclient em0 To test the network connectivity use the ping command.\nping -c 3 freebsd.org If You would like to connect to the World with wireless connection then here are the needed commands. First lets check what wireless card You have.\nsysctl net.wlan.devices We will now create wlan virtual device on top of our iwn0 device and bring it up.\nifconfig wlan0 create wlandev iwn0 ifconfig wlan0 up We can scan for existing nearby WiFi access points if needed.\nifconfig wlan0 scan Now we need to add the desired WiFi network to the /etc/wpa_supplicant.conf file as shown below.\nnetwork={ ssid=\u0026quot;WIFI-NETWORK-NAME\u0026quot; psk=\u0026quot;PASSWORD\u0026quot; } Then You may connect to it using the wpa_supplicant daemon. Hit the [CTRL]+[Z] key combination to put the process into suspended state. Then we type the bg command to put it back into running state, but in the background so we can continue to type next commands.\nwpa_supplicant -i wlan0 -c /etc/wpa_supplicant.conf Now we will request for the IP address from the access point DHCP server.\ndhclient wlan0 How To Add and Remove Users on FreeBSD   Add a User: adduser\n  Grant Sudo Privileges: On FreeBSD, users that are members of the wheel group are allowed to use sudo. This is due to the following line in the default sudoers file, /usr/local/etc/sudoers\n%wheel ALL=(ALL) NOPASSWD: ALL   Remove a User: rmuser\n  Lock a User Account: pw lock username\n  Unlock a User: pw unlock username\n  其他 NetBSD: huaweicloud、aliyun、tsinghua\nOpenBSD: huaweicloud、aliyun、tsinghua\n一篇好文：FreeBSD的现状和未来\nFreeBSD Desktop\nFreeBSD 使用手冊\n","permalink":"https://sakamotokurome.github.io/posts/freebsd/","summary":"The goals of the FreeBSD Project are to provide software that may be used for any purpose and without strings attached. Many of us have a significant investment in the code (and project) and would certainly not mind a little financial compensation now and then, but we are definitely not prepared to insist on it. We believe that our first and foremost \u0026ldquo;mission\u0026rdquo; is to provide code to any and","title":"FreeBSD"},{"content":"Just a little conversation\nAbout give me your picture\nOn the cover of a magazine\nOn the cover of a magazine\nJust a little conversation\nBut how long it might take one?\nTo get along with such thing?\nTo get along with such thing?\nBut everybody knows\nIt\u0026rsquo;s easier to fall apart\nJust a little conversation\nAbout give me your picture\nOn the cover of a magazine\nOn the cover of a magazine\n  ","permalink":"https://sakamotokurome.github.io/posts/conversation/","summary":"Just a little conversation\nAbout give me your picture\nOn the cover of a magazine\nOn the cover of a magazine\nJust a little conversation\nBut how long it might take one?\nTo get along with such thing?\nTo get along with such thing?\nBut everybody knows\nIt\u0026rsquo;s easier to fall apart\nJust a little conversation\nAbout give me your picture\nOn the cover of a magazine\nOn the cover of a magazine","title":"Conversation"},{"content":"","permalink":"https://sakamotokurome.github.io/links/","summary":"","title":""}]